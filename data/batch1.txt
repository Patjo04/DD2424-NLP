<token> "priv.h" <answer> #include 
#include <token> <answer> <core/firmware.h> 
static <token> * <answer> void 
<token> nvkm_engine *engine) <answer> nvkm_nvdec_dtor(struct 
<token> nvkm_nvdec *nvdec = nvkm_nvdec(engine); <answer> struct 
return <token> <answer> nvdec; 
static const struct <token> <answer> nvkm_engine_func 
nvkm_nvdec <token> { <answer> = 
.dtor = <token> <answer> nvkm_nvdec_dtor, 
.sclass = { {} <token> <answer> }, 
nvkm_nvdec_new_(const <token> nvkm_nvdec_fwif *fwif, struct nvkm_device *device, <answer> struct 
<token> nvkm_subdev_type type, int inst, u32 addr, struct nvkm_nvdec **pnvdec) <answer> enum 
struct <token> *nvdec; <answer> nvkm_nvdec 
int <token> <answer> ret; 
if (!(nvdec = *pnvdec <token> kzalloc(sizeof(*nvdec), GFP_KERNEL))) <answer> = 
<token> -ENOMEM; <answer> return 
ret = nvkm_engine_ctor(&nvkm_nvdec, <token> type, inst, true, <answer> device, 
if <token> <answer> (ret) 
return <token> <answer> ret; 
fwif = nvkm_firmware_load(&nvdec->engine.subdev, fwif, <token> nvdec); <answer> "Nvdec", 
<token> (IS_ERR(fwif)) <answer> if 
<token> -ENODEV; <answer> return 
<token> = fwif->func; <answer> nvdec->func 
<token> nvkm_falcon_ctor(nvdec->func->flcn, &nvdec->engine.subdev, <answer> return 
<token> addr, &nvdec->falcon); <answer> nvdec->engine.subdev.name, 
<token> <test_progs.h> <answer> #include 
<token> "network_helpers.h" <answer> #include 
<token> "sock_iter_batch.skel.h" <answer> #include 
<token> TEST_NS "sock_iter_batch_netns" <answer> #define 
static const <token> nr_soreuse = 4; <answer> int 
static void do_test(int sock_type, bool <token> <answer> onebyone) 
int err, i, nread, to_read, total_read, <token> = -1; <answer> iter_fd 
int first_idx, second_idx, <token> <answer> indices[nr_soreuse]; 
struct bpf_link *link <token> NULL; <answer> = 
<token> sock_iter_batch *skel; <answer> struct 
int *fds[2] <token> {}; <answer> = 
skel <token> sock_iter_batch__open(); <answer> = 
if <token> "sock_iter_batch__open")) <answer> (!ASSERT_OK_PTR(skel, 
to_read = (nr_soreuse - 1) * <token> <answer> sizeof(*indices); 
total_read = <token> <answer> 0; 
<token> = -1; <answer> first_idx 
do <token> <answer> { 
nread = read(iter_fd, <token> onebyone ? sizeof(*indices) : to_read); <answer> indices, 
if (nread <= 0 <token> nread % sizeof(*indices)) <answer> || 
total_read += <token> <answer> nread; 
<token> (first_idx == -1) <answer> if 
<token> = indices[0]; <answer> first_idx 
for (i = 0; i < nread <token> sizeof(*indices); i++) <answer> / 
ASSERT_EQ(indices[i], first_idx, <token> <answer> "first_idx"); 
} <token> (total_read < to_read); <answer> while 
ASSERT_EQ(nread, onebyone ? sizeof(*indices) : to_read, <token> <answer> "nread"); 
ASSERT_EQ(total_read, to_read, <token> <answer> "total_read"); 
<token> nr_soreuse); <answer> free_fds(fds[first_idx], 
<token> = NULL; <answer> fds[first_idx] 
if (skel->bss->bucket[0] != <token> <answer> skel->bss->bucket[1]) 
<token> to_read, "total_read"); <answer> ASSERT_EQ(total_read, 
for (i <token> 0; i < ARRAY_SIZE(fds); i++) <answer> = 
free_fds(fds[i], <token> <answer> nr_soreuse); 
if <token> < 0) <answer> (iter_fd 
<token> test_sock_iter_batch(void) <answer> void 
struct <token> *nstoken = NULL; <answer> nstoken 
SYS_NOFAIL("ip netns <token> " TEST_NS); <answer> del 
SYS(done, "ip netns add %s", <token> <answer> TEST_NS); 
SYS(done, <token> -net %s link set dev lo up", TEST_NS); <answer> "ip 
nstoken = <token> <answer> open_netns(TEST_NS); 
if (!ASSERT_OK_PTR(nstoken, <token> <answer> "open_netns")) 
goto <token> <answer> done; 
if <token> { <answer> (test__start_subtest("tcp")) 
do_test(SOCK_STREAM, <token> <answer> true); 
<token> false); <answer> do_test(SOCK_STREAM, 
if <token> { <answer> (test__start_subtest("udp")) 
<token> true); <answer> do_test(SOCK_DGRAM, 
do_test(SOCK_DGRAM, <token> <answer> false); 
SYS_NOFAIL("ip <token> del " TEST_NS); <answer> netns 
#include <token> <answer> "ia_css_types.h" 
#include <token> <answer> "sh_css_internal.h" 
<token> "assert_support.h" <answer> #include 
#include <token> <answer> "sh_css_frac.h" 
#include <token> <answer> "ia_css_bh.host.h" 
struct <token> *out_ptr, <answer> ia_css_3a_rgby_output 
const struct <token> *hmem_buf) <answer> ia_css_bh_table 
int <token> <answer> i; 
<token> (!hmem_buf) <answer> if 
assert(sizeof_hmem(HMEM0_ID) == <token> <answer> sizeof(*hmem_buf)); 
struct <token> *to, <answer> sh_css_isp_bh_params 
const struct ia_css_3a_config <token> <answer> *from, 
unsigned int <token> <answer> size) 
#include <token> <answer> <media/rc-map.h> 
<token> <linux/module.h> <answer> #include 
<token> struct rc_map_table pixelview_002t[] = { <answer> static 
{ 0x866b13, KEY_MUTE <token> <answer> }, 
#define pr_fmt(fmt) KBUILD_MODNAME <token> " fmt <answer> ": 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/fb.h> 
<token> <linux/console.h> <answer> #include 
#include <token> <answer> <linux/i2c.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/backlight.h> <answer> #include 
<token> <linux/device.h> <answer> #include 
<token> <linux/uaccess.h> <answer> #include 
<token> <linux/ctype.h> <answer> #include 
<token> <linux/panic_notifier.h> <answer> #include 
#include <token> <answer> <linux/reboot.h> 
#include <token> <answer> <linux/olpc-ec.h> 
<token> <asm/tsc.h> <answer> #include 
<token> <asm/olpc.h> <answer> #include 
#include <token> <answer> "olpc_dcon.h" 
static int <token> dcon_priv *dcon, int is_powered_down) <answer> dcon_bus_stabilize(struct 
<token> long timeout; <answer> unsigned 
<token> pm; <answer> u8 
int <token> <answer> x; 
if <token> { <answer> (is_powered_down) 
<token> = 1; <answer> pm 
x = olpc_ec_cmd(EC_DCON_POWER_MODE, &pm, 1, <token> 0); <answer> NULL, 
if <token> { <answer> (x) 
pr_warn("unable to force <token> to power up: %d!\n", x); <answer> dcon 
return <token> <answer> x; 
static <token> dcon_sleep(struct dcon_priv *dcon, bool sleep) <answer> void 
int <token> <answer> x; 
static void <token> dcon_priv *dcon) <answer> dcon_load_holdoff(struct 
ktime_t delta_t, <token> <answer> now; 
<token> (1) { <answer> while 
now <token> ktime_get(); <answer> = 
delta_t <token> ktime_sub(now, dcon->load_time); <answer> = 
if (ktime_to_ns(delta_t) > <token> * 20) <answer> NSEC_PER_MSEC 
static bool dcon_blank_fb(struct dcon_priv *dcon, <token> blank) <answer> bool 
<token> err; <answer> int 
<token> = true; <answer> dcon->ignore_fb_events 
<token> = fb_blank(dcon->fbinfo, <answer> err 
blank ? <token> : FB_BLANK_UNBLANK); <answer> FB_BLANK_POWERDOWN 
dcon->ignore_fb_events = <token> <answer> false; 
if <token> { <answer> (err) 
dev_err(&dcon->client->dev, "couldn't <token> framebuffer\n", <answer> %sblank 
blank ? "" <token> "un"); <answer> : 
<token> false; <answer> return 
return <token> <answer> true; 
if <token> false)) { <answer> (!dcon_blank_fb(dcon, 
pr_err("Failed to enter CPU <token> <answer> mode\n"); 
dcon->pending_src = <token> <answer> DCON_SOURCE_DCON; 
delta_t = ktime_sub(dcon->irq_time, <token> <answer> dcon->load_time); 
<token> (dcon->switched && ktime_to_ns(delta_t) <answer> if 
< NSEC_PER_MSEC * 20) <token> <answer> { 
<token> loading, retrying\n"); <answer> pr_err("missed 
dcon->load_time <token> ktime_get(); <answer> = 
dcon_blank_fb(dcon, <token> <answer> true); 
pr_info("The <token> has control\n"); <answer> DCON 
<token> = source; <answer> dcon->curr_src 
<token> void dcon_set_source(struct dcon_priv *dcon, int arg) <answer> static 
if <token> == arg) <answer> (dcon->pending_src 
<token> = arg; <answer> dcon->pending_src 
<token> (dcon->curr_src != arg) <answer> if 
<token> void dcon_set_source_sync(struct dcon_priv *dcon, int arg) <answer> static 
dcon_set_source(dcon, <token> <answer> arg); 
static ssize_t dcon_mode_show(struct device <token> <answer> *dev, 
struct <token> *attr, <answer> device_attribute 
<token> *buf) <answer> char 
struct dcon_priv *dcon <token> dev_get_drvdata(dev); <answer> = 
return <token> "%4.4X\n", dcon->disp_mode); <answer> sprintf(buf, 
static ssize_t <token> device *dev, <answer> dcon_sleep_show(struct 
<token> device_attribute *attr, <answer> struct 
<token> *buf) <answer> char 
<token> dcon_priv *dcon = dev_get_drvdata(dev); <answer> struct 
<token> sprintf(buf, "%d\n", dcon->asleep); <answer> return 
static ssize_t <token> device *dev, <answer> dcon_freeze_show(struct 
struct <token> *attr, <answer> device_attribute 
<token> *buf) <answer> char 
struct <token> *dcon = dev_get_drvdata(dev); <answer> dcon_priv 
return sprintf(buf, "%d\n", dcon->curr_src == DCON_SOURCE_DCON ? <token> : 0); <answer> 1 
static ssize_t <token> device *dev, <answer> dcon_mono_show(struct 
struct device_attribute <token> <answer> *attr, 
char <token> <answer> *buf) 
struct dcon_priv *dcon = <token> <answer> dev_get_drvdata(dev); 
<token> sprintf(buf, "%d\n", dcon->mono); <answer> return 
static ssize_t <token> device *dev, <answer> dcon_resumeline_show(struct 
<token> device_attribute *attr, <answer> struct 
char <token> <answer> *buf) 
return sprintf(buf, <token> resumeline); <answer> "%d\n", 
static <token> dcon_mono_store(struct device *dev, <answer> ssize_t 
<token> device_attribute *attr, <answer> struct 
const <token> *buf, size_t count) <answer> char 
unsigned long <token> <answer> enable_mono; 
int <token> <answer> rc; 
rc = <token> 10, &enable_mono); <answer> kstrtoul(buf, 
<token> (rc) <answer> if 
return <token> <answer> rc; 
dcon_set_mono_mode(dev_get_drvdata(dev), enable_mono ? true : <token> <answer> false); 
<token> count; <answer> return 
static ssize_t dcon_freeze_store(struct <token> *dev, <answer> device 
<token> device_attribute *attr, <answer> struct 
const char *buf, <token> count) <answer> size_t 
struct dcon_priv <token> = dev_get_drvdata(dev); <answer> *dcon 
unsigned long <token> <answer> output; 
<token> ret; <answer> int 
ret = kstrtoul(buf, <token> &output); <answer> 10, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
switch (output) <token> <answer> { 
<token> 0: <answer> case 
dcon_set_source(dcon, <token> <answer> DCON_SOURCE_CPU); 
<token> 1: <answer> case 
dcon_set_source_sync(dcon, <token> <answer> DCON_SOURCE_DCON); 
if (dcon->curr_src != dcon->pending_src && <token> { <answer> !dcon->switched) 
<token> = true; <answer> dcon->switched 
dcon->irq_time = <token> <answer> ktime_get(); 
pr_debug("switching <token> status 0/0\n"); <answer> w/ 
} <token> { <answer> else 
pr_debug("scanline interrupt <token> <answer> w/CPU\n"); 
<token> IRQ_HANDLED; <answer> return 
static <token> struct dev_pm_ops dcon_pm_ops = { <answer> const 
<token> = dcon_suspend, <answer> .suspend 
.resume <token> dcon_resume, <answer> = 
static const <token> i2c_device_id dcon_idtable[] = { <answer> struct 
{ "olpc_dcon", 0 <token> <answer> }, 
<token> } <answer> { 
<token> dcon_idtable); <answer> MODULE_DEVICE_TABLE(i2c, 
<token> struct i2c_driver dcon_driver = { <answer> static 
.driver <token> { <answer> = 
<token> = "olpc_dcon", <answer> .name 
.pm = <token> <answer> &dcon_pm_ops, 
.class = <token> <answer> I2C_CLASS_HWMON, 
.id_table = <token> <answer> dcon_idtable, 
.probe = <token> <answer> dcon_probe, 
<token> = dcon_remove, <answer> .remove 
.detect = <token> <answer> dcon_detect, 
.address_list <token> normal_i2c, <answer> = 
<token> int __init olpc_dcon_init(void) <answer> static 
<token> "ram.h" <answer> #include 
nv4e_ram_new(struct nvkm_fb *fb, struct <token> **pram) <answer> nvkm_ram 
<token> nvkm_device *device = fb->subdev.device; <answer> struct 
u32 size = nvkm_rd32(device, 0x10020c) <token> 0xff000000; <answer> & 
return <token> fb, NVKM_RAM_TYPE_UNKNOWN, <answer> nvkm_ram_new_(&nv04_ram_func, 
<token> pram); <answer> size, 
#include <token> <answer> <linux/slab.h> 
<token> <linux/mutex.h> <answer> #include 
<token> "kfd_device_queue_manager.h" <answer> #include 
<token> "kfd_kernel_queue.h" <answer> #include 
#include <token> <answer> "kfd_priv.h" 
static <token> void inc_wptr(unsigned int *wptr, unsigned int increment_bytes, <answer> inline 
unsigned int <token> <answer> buffer_size_bytes) 
unsigned int <token> = *wptr + increment_bytes / sizeof(uint32_t); <answer> temp 
<token> * sizeof(uint32_t)) > buffer_size_bytes, <answer> WARN((temp 
"Runlist IB <token> <answer> overflow"); 
<token> = temp; <answer> *wptr 
static void pm_calc_rlib_size(struct packet_manager <token> <answer> *pm, 
unsigned int <token> <answer> *rlib_size, 
<token> *over_subscription) <answer> bool 
<token> int process_count, queue_count, compute_queue_count, gws_queue_count; <answer> unsigned 
unsigned <token> map_queue_size; <answer> int 
unsigned <token> max_proc_per_quantum = 1; <answer> int 
struct kfd_node <token> = pm->dqm->dev; <answer> *dev 
process_count <token> pm->dqm->processes_count; <answer> = 
queue_count <token> pm->dqm->active_queue_count; <answer> = 
compute_queue_count = <token> <answer> pm->dqm->active_cp_queue_count; 
gws_queue_count = <token> <answer> pm->dqm->gws_queue_count; 
*over_subscription = <token> <answer> false; 
if (dev->max_proc_per_quantum <token> 1) <answer> > 
<token> = dev->max_proc_per_quantum; <answer> max_proc_per_quantum 
if ((process_count <token> max_proc_per_quantum) || <answer> > 
compute_queue_count <token> get_cp_queues_num(pm->dqm) || <answer> > 
gws_queue_count <token> 1) { <answer> > 
*over_subscription <token> true; <answer> = 
pr_debug("Over <token> runlist\n"); <answer> subscribed 
<token> = pm->pmf->map_queues_size; <answer> map_queue_size 
if <token> <answer> (*over_subscription) 
<token> += pm->pmf->runlist_size; <answer> *rlib_size 
<token> ib size %d\n", *rlib_size); <answer> pr_debug("runlist 
<token> int pm_allocate_runlist_ib(struct packet_manager *pm, <answer> static 
<token> int **rl_buffer, <answer> unsigned 
uint64_t <token> <answer> *rl_gpu_buffer, 
<token> int *rl_buffer_size, <answer> unsigned 
<token> *is_over_subscription) <answer> bool 
<token> retval; <answer> int 
<token> (WARN_ON(pm->allocated)) <answer> if 
<token> -EINVAL; <answer> return 
pm_calc_rlib_size(pm, rl_buffer_size, <token> <answer> is_over_subscription); 
retval = <token> *rl_buffer_size, <answer> kfd_gtt_sa_allocate(pm->dqm->dev, 
if <token> { <answer> (retval) 
pr_err("Failed to allocate runlist <token> <answer> IB\n"); 
goto <token> <answer> out; 
*(void **)rl_buffer <token> pm->ib_buffer_obj->cpu_ptr; <answer> = 
<token> = pm->ib_buffer_obj->gpu_addr; <answer> *rl_gpu_buffer 
memset(*rl_buffer, 0, <token> <answer> *rl_buffer_size); 
pm->allocated = <token> <answer> true; 
return <token> <answer> retval; 
static int pm_create_runlist_ib(struct <token> *pm, <answer> packet_manager 
struct list_head <token> <answer> *queues, 
uint64_t <token> <answer> *rl_gpu_addr, 
size_t <token> <answer> *rl_size_bytes) 
unsigned <token> alloc_size_bytes; <answer> int 
unsigned int <token> rl_wptr, i; <answer> *rl_buffer, 
int <token> processes_mapped; <answer> retval, 
struct device_process_node <token> <answer> *cur; 
struct qcm_process_device <token> <answer> *qpd; 
struct <token> *q; <answer> queue 
struct kernel_queue <token> <answer> *kq; 
bool <token> <answer> is_over_subscription; 
rl_wptr = retval = <token> = 0; <answer> processes_mapped 
<token> = pm_allocate_runlist_ib(pm, &rl_buffer, rl_gpu_addr, <answer> retval 
&alloc_size_bytes, <token> <answer> &is_over_subscription); 
if <token> <answer> (retval) 
return <token> <answer> retval; 
*rl_size_bytes = <token> <answer> alloc_size_bytes; 
pm->ib_size_bytes <token> alloc_size_bytes; <answer> = 
pr_debug("Building runlist ib <token> count: %d queues count %d\n", <answer> process 
<token> pm->dqm->active_queue_count); <answer> pm->dqm->processes_count, 
<token> "smu_v13_0_10.h" <answer> #include 
<token> "amdgpu_reset.h" <answer> #include 
<token> "amdgpu_dpm.h" <answer> #include 
#include <token> <answer> "amdgpu_job.h" 
<token> "amdgpu_ring.h" <answer> #include 
<token> "amdgpu_ras.h" <answer> #include 
<token> "amdgpu_psp.h" <answer> #include 
static bool smu_v13_0_10_is_mode2_default(struct amdgpu_reset_control <token> <answer> *reset_ctl) 
struct amdgpu_device *adev = (struct <token> *)reset_ctl->handle; <answer> amdgpu_device 
if (adev->pm.fw_version >= 0x00502005 <token> !amdgpu_sriov_vf(adev)) <answer> && 
return <token> <answer> true; 
return <token> <answer> false; 
<token> struct amdgpu_reset_handler * <answer> static 
smu_v13_0_10_get_reset_handler(struct <token> *reset_ctl, <answer> amdgpu_reset_control 
struct amdgpu_reset_context <token> <answer> *reset_context) 
struct <token> *handler; <answer> amdgpu_reset_handler 
struct amdgpu_device *adev = (struct amdgpu_device <token> <answer> *)reset_ctl->handle; 
<token> i; <answer> int 
if <token> != AMD_RESET_METHOD_NONE) { <answer> (reset_context->method 
for_each_handler(i, handler, <token> { <answer> reset_ctl) 
if (handler->reset_method <token> reset_context->method) <answer> == 
<token> handler; <answer> return 
if (smu_v13_0_10_is_mode2_default(reset_ctl) <token> <answer> && 
amdgpu_asic_reset_method(adev) == <token> { <answer> AMD_RESET_METHOD_MODE2) 
for_each_handler(i, handler, <token> { <answer> reset_ctl) 
if (handler->reset_method == <token> <answer> AMD_RESET_METHOD_MODE2) 
<token> handler; <answer> return 
return <token> <answer> NULL; 
static int <token> amdgpu_device *adev) <answer> smu_v13_0_10_mode2_suspend_ip(struct 
int r, <token> <answer> i; 
<token> AMD_PG_STATE_UNGATE); <answer> amdgpu_device_set_pg_state(adev, 
amdgpu_device_set_cg_state(adev, <token> <answer> AMD_CG_STATE_UNGATE); 
for (i = adev->num_ip_blocks - 1; i <token> 0; i--) { <answer> >= 
<token> (!(adev->ip_blocks[i].version->type == <answer> if 
AMD_IP_BLOCK_TYPE_GFX <token> <answer> || 
<token> == <answer> adev->ip_blocks[i].version->type 
<token> || <answer> AMD_IP_BLOCK_TYPE_SDMA 
<token> == <answer> adev->ip_blocks[i].version->type 
r = <token> <answer> adev->ip_blocks[i].version->funcs->suspend(adev); 
<token> (r) { <answer> if 
"suspend of IP block <token> failed %d\n", <answer> <%s> 
adev->ip_blocks[i].version->funcs->name, <token> <answer> r); 
return <token> <answer> r; 
adev->ip_blocks[i].status.hw = <token> <answer> false; 
<token> r; <answer> return 
<token> int <answer> static 
<token> amdgpu_reset_control *reset_ctl, <answer> smu_v13_0_10_mode2_prepare_hwcontext(struct 
struct amdgpu_reset_context <token> <answer> *reset_context) 
int <token> = 0; <answer> r 
struct amdgpu_device *adev = <token> amdgpu_device *)reset_ctl->handle; <answer> (struct 
<token> (!amdgpu_sriov_vf(adev)) <answer> if 
<token> = smu_v13_0_10_mode2_suspend_ip(adev); <answer> r 
return <token> <answer> r; 
static int smu_v13_0_10_mode2_reset(struct <token> *adev) <answer> amdgpu_device 
<token> amdgpu_dpm_mode2_reset(adev); <answer> return 
<token> void smu_v13_0_10_async_reset(struct work_struct *work) <answer> static 
<token> amdgpu_reset_handler *handler; <answer> struct 
struct amdgpu_reset_control *reset_ctl <token> <answer> = 
container_of(work, struct amdgpu_reset_control, <token> <answer> reset_work); 
struct amdgpu_device <token> = (struct amdgpu_device *)reset_ctl->handle; <answer> *adev 
int <token> <answer> i; 
for_each_handler(i, <token> reset_ctl) { <answer> handler, 
if (handler->reset_method == reset_ctl->active_reset) <token> <answer> { 
dev_dbg(adev->dev, "Resetting <token> <answer> device\n"); 
static <token> <answer> int 
smu_v13_0_10_mode2_perform_reset(struct amdgpu_reset_control <token> <answer> *reset_ctl, 
struct amdgpu_reset_context <token> <answer> *reset_context) 
struct amdgpu_device *adev <token> (struct amdgpu_device *)reset_ctl->handle; <answer> = 
<token> r; <answer> int 
r = <token> <answer> smu_v13_0_10_mode2_reset(adev); 
if <token> { <answer> (r) 
"ASIC reset failed with <token> %d ", r); <answer> error, 
return <token> <answer> r; 
<token> int smu_v13_0_10_mode2_restore_ip(struct amdgpu_device *adev) <answer> static 
<token> i, r; <answer> int 
<token> psp_context *psp = &adev->psp; <answer> struct 
<token> amdgpu_firmware_info *ucode; <answer> struct 
struct amdgpu_firmware_info <token> <answer> *ucode_list[2]; 
int ucode_count <token> 0; <answer> = 
for (i = 0; <token> < adev->firmware.max_ucodes; i++) { <answer> i 
<token> = &adev->firmware.ucode[i]; <answer> ucode 
<token> (ucode->ucode_id) { <answer> switch 
case <token> <answer> AMDGPU_UCODE_ID_IMU_I: 
<token> AMDGPU_UCODE_ID_IMU_D: <answer> case 
ucode_list[ucode_count++] <token> ucode; <answer> = 
r = psp_load_fw_list(psp, ucode_list, <token> <answer> ucode_count); 
if <token> { <answer> (r) 
dev_err(adev->dev, "IMU <token> load failed after mode2 reset\n"); <answer> ucode 
return <token> <answer> r; 
r <token> psp_rlc_autoload_start(psp); <answer> = 
<token> (r) { <answer> if 
DRM_ERROR("Failed to start rlc <token> after mode2 reset\n"); <answer> autoload 
<token> r; <answer> return 
for (i = 0; i < adev->num_ip_blocks; i++) <token> <answer> { 
<token> (!(adev->ip_blocks[i].version->type == <answer> if 
AMD_IP_BLOCK_TYPE_GFX <token> <answer> || 
<token> == <answer> adev->ip_blocks[i].version->type 
AMD_IP_BLOCK_TYPE_MES <token> <answer> || 
<token> == <answer> adev->ip_blocks[i].version->type 
<token> = adev->ip_blocks[i].version->funcs->resume(adev); <answer> r 
<token> (r) { <answer> if 
"resume of IP block <%s> failed <token> <answer> %d\n", 
adev->ip_blocks[i].version->funcs->name, <token> <answer> r); 
return <token> <answer> r; 
adev->ip_blocks[i].status.hw = <token> <answer> true; 
for (i = 0; i <token> adev->num_ip_blocks; i++) { <answer> < 
if <token> == <answer> (!(adev->ip_blocks[i].version->type 
<token> || <answer> AMD_IP_BLOCK_TYPE_GFX 
<token> == <answer> adev->ip_blocks[i].version->type 
AMD_IP_BLOCK_TYPE_MES <token> <answer> || 
adev->ip_blocks[i].version->type <token> <answer> == 
if <token> { <answer> (adev->ip_blocks[i].version->funcs->late_init) 
r <token> adev->ip_blocks[i].version->funcs->late_init( <answer> = 
(void <token> <answer> *)adev); 
if <token> { <answer> (r) 
"late_init of IP <token> <%s> failed %d after reset\n", <answer> block 
return <token> <answer> r; 
<token> = true; <answer> adev->ip_blocks[i].status.late_initialized 
amdgpu_device_set_cg_state(adev, <token> <answer> AMD_CG_STATE_GATE); 
amdgpu_device_set_pg_state(adev, <token> <answer> AMD_PG_STATE_GATE); 
return <token> <answer> r; 
static <token> <answer> int 
<token> amdgpu_reset_control *reset_ctl, <answer> smu_v13_0_10_mode2_restore_hwcontext(struct 
<token> amdgpu_reset_context *reset_context) <answer> struct 
<token> r; <answer> int 
struct amdgpu_device <token> = (struct amdgpu_device *)reset_ctl->handle; <answer> *tmp_adev 
"GPU <token> succeeded, trying to resume\n"); <answer> reset 
r = <token> <answer> smu_v13_0_10_mode2_restore_ip(tmp_adev); 
if <token> <answer> (r) 
<token> end; <answer> goto 
<token> <linux/backlight.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
<token> <linux/dma-buf.h> <answer> #include 
<token> <linux/gpio/consumer.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/property.h> <answer> #include 
<token> <linux/spi/spi.h> <answer> #include 
#include <token> <answer> <video/mipi_display.h> 
#include <token> <answer> <drm/drm_atomic_helper.h> 
<token> <drm/drm_drv.h> <answer> #include 
<token> <drm/drm_fbdev_generic.h> <answer> #include 
#include <token> <answer> <drm/drm_gem_atomic_helper.h> 
<token> <drm/drm_gem_dma_helper.h> <answer> #include 
#include <token> <answer> <drm/drm_managed.h> 
<token> <drm/drm_mipi_dbi.h> <answer> #include 
#define <token> 0xb1 <answer> ST7735R_FRMCTR1 
#define ST7735R_FRMCTR2 <token> <answer> 0xb2 
#define ST7735R_FRMCTR3 <token> <answer> 0xb3 
<token> ST7735R_INVCTR 0xb4 <answer> #define 
<token> ST7735R_PWCTR1 0xc0 <answer> #define 
#define ST7735R_PWCTR2 <token> <answer> 0xc1 
<token> ST7735R_PWCTR3 0xc2 <answer> #define 
<token> ST7735R_PWCTR4 0xc3 <answer> #define 
#define <token> 0xc4 <answer> ST7735R_PWCTR5 
#define <token> 0xc5 <answer> ST7735R_VMCTR1 
#define ST7735R_GAMCTRP1 <token> <answer> 0xe0 
<token> ST7735R_GAMCTRN1 0xe1 <answer> #define 
#define ST7735R_MY <token> <answer> BIT(7) 
#define ST7735R_MX <token> <answer> BIT(6) 
<token> ST7735R_MV BIT(5) <answer> #define 
#define ST7735R_RGB <token> <answer> BIT(3) 
struct st7735r_cfg <token> <answer> { 
<token> struct drm_display_mode mode; <answer> const 
unsigned int <token> <answer> left_offset; 
<token> int top_offset; <answer> unsigned 
<token> int write_only:1; <answer> unsigned 
<token> <linux/types.h> <answer> #include 
#include <token> <answer> <asm/byteorder.h> 
#include <token> <answer> <linux/dma-mapping.h> 
<token> <linux/if_vlan.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/pci.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/stddef.h> <answer> #include 
<token> <linux/workqueue.h> <answer> #include 
#include <token> <answer> <net/ipv6.h> 
#include <token> <answer> <linux/bitops.h> 
<token> <linux/delay.h> <answer> #include 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <linux/etherdevice.h> 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/list.h> 
<token> <linux/mutex.h> <answer> #include 
#include <token> <answer> <linux/spinlock.h> 
#include <token> <answer> <linux/string.h> 
#include <token> <answer> <linux/qed/qed_ll2_if.h> 
#include <token> <answer> "qed.h" 
<token> "qed_cxt.h" <answer> #include 
<token> "qed_dev_api.h" <answer> #include 
#include <token> <answer> "qed_hsi.h" 
<token> "qed_iro_hsi.h" <answer> #include 
#include <token> <answer> "qed_hw.h" 
#include <token> <answer> "qed_int.h" 
#include <token> <answer> "qed_ll2.h" 
#include <token> <answer> "qed_mcp.h" 
#include <token> <answer> "qed_ooo.h" 
#include <token> <answer> "qed_reg_addr.h" 
<token> "qed_sp.h" <answer> #include 
<token> "qed_rdma.h" <answer> #include 
<token> QED_LL2_RX_REGISTERED(ll2) ((ll2)->rx_queue.b_cb_registered) <answer> #define 
#define QED_LL2_TX_REGISTERED(ll2) <token> <answer> ((ll2)->tx_queue.b_cb_registered) 
#define QED_LL2_TX_SIZE <token> <answer> (256) 
#define <token> (4096) <answer> QED_LL2_RX_SIZE 
<token> QED_LL2_INVALID_STATS_ID 0xff <answer> #define 
struct <token> { <answer> qed_cb_ll2_info 
<token> rx_cnt; <answer> int 
<token> rx_size; <answer> u32 
<token> handle; <answer> u8 
if (ll2_queue_type <token> QED_LL2_RX_TYPE_LEGACY) <answer> == 
stats_id = <token> <answer> qid; 
stats_id <token> MAX_NUM_LL2_RX_RAM_QUEUES + p_hwfn->abs_pf_id; <answer> = 
if (stats_id < <token> <answer> MAX_NUM_LL2_TX_STATS_COUNTERS) 
return <token> <answer> stats_id; 
<token> QED_LL2_INVALID_STATS_ID; <answer> return 
<token> void qed_ll2b_complete_tx_packet(void *cxt, <answer> static 
u8 <token> <answer> connection_handle, 
<token> *cookie, <answer> void 
<token> first_frag_addr, <answer> dma_addr_t 
bool <token> <answer> b_last_fragment, 
<token> b_last_packet) <answer> bool 
struct <token> *p_hwfn = cxt; <answer> qed_hwfn 
struct qed_dev *cdev = <token> <answer> p_hwfn->cdev; 
struct sk_buff *skb <token> cookie; <answer> = 
skb->protocol <token> eth_hdr(skb)->h_proto; <answer> = 
if (data->input.rx_conn_type <token> QED_LL2_RX_TYPE_LEGACY) { <answer> == 
*start_idx = <token> <answer> QED_LL2_LEGACY_CONN_BASE_PF; 
*last_idx = *start_idx <token> <answer> + 
} <token> { <answer> else 
qid = <token> + <answer> p_hwfn->hw_info.resc_start[QED_LL2_CTX_QUEUE] 
<token> += (handle - QED_MAX_NUM_OF_LEGACY_LL2_CONNS_PF); <answer> qid 
<token> qid; <answer> return 
int qed_ll2_establish_connection(void *cxt, u8 <token> <answer> connection_handle) 
struct <token> *p_cxt; <answer> core_conn_context 
<token> qed_ll2_tx_packet *p_pkt; <answer> struct 
<token> qed_ll2_info *p_ll2_conn; <answer> struct 
struct qed_hwfn *p_hwfn <token> cxt; <answer> = 
struct qed_ll2_rx_queue <token> <answer> *p_rx; 
struct qed_ll2_tx_queue <token> <answer> *p_tx; 
<token> qed_cxt_info cxt_info; <answer> struct 
struct qed_ptt <token> <answer> *p_ptt; 
int <token> = -EINVAL; <answer> rc 
<token> i, capacity; <answer> u32 
<token> desc_size; <answer> size_t 
u8 <token> stats_id; <answer> qid, 
<token> = qed_ptt_acquire(p_hwfn); <answer> p_ptt 
<token> (!p_ptt) <answer> if 
return <token> <answer> -EAGAIN; 
p_ll2_conn = <token> connection_handle); <answer> qed_ll2_handle_sanity_lock(p_hwfn, 
if (!p_ll2_conn) <token> <answer> { 
rc <token> -EINVAL; <answer> = 
goto <token> <answer> out; 
<token> = &p_ll2_conn->rx_queue; <answer> p_rx 
p_tx <token> &p_ll2_conn->tx_queue; <answer> = 
<token> = qed_chain_get_capacity(&p_rx->rxq_chain); <answer> capacity 
for (i = 0; i < capacity; <token> <answer> i++) 
<token> = 0; <answer> *p_rx->p_fw_cons 
capacity = <token> <answer> qed_chain_get_capacity(&p_tx->txq_chain); 
<token> *)&p_rx->db_data)); <answer> *((u64 
} else <token> <answer> { 
rx_prod.bd_prod = <token> <answer> cpu_to_le16(bd_prod); 
rx_prod.cqe_prod = <token> <answer> cpu_to_le16(cq_prod); 
DIRECT_REG_WR(p_rx->set_prod_addr, <token> *)&rx_prod)); <answer> *((u32 
int qed_ll2_post_rx_buffer(void <token> <answer> *cxt, 
<token> connection_handle, <answer> u8 
<token> addr, <answer> dma_addr_t 
u16 buf_len, void *cookie, u8 <token> <answer> notify_fw) 
struct qed_hwfn *p_hwfn <token> cxt; <answer> = 
struct core_rx_bd_with_buff_len <token> = NULL; <answer> *p_curb 
struct qed_ll2_rx_packet *p_curp = <token> <answer> NULL; 
struct qed_ll2_info <token> <answer> *p_ll2_conn; 
struct <token> *p_rx; <answer> qed_ll2_rx_queue 
unsigned <token> flags; <answer> long 
<token> *p_data; <answer> void 
int rc <token> 0; <answer> = 
p_ll2_conn = <token> connection_handle); <answer> qed_ll2_handle_sanity(p_hwfn, 
if <token> <answer> (!p_ll2_conn) 
<token> -EINVAL; <answer> return 
<token> = &p_ll2_conn->rx_queue; <answer> p_rx 
if <token> <answer> (!p_rx->set_prod_addr) 
return <token> <answer> -EIO; 
<token> flags); <answer> spin_lock_irqsave(&p_rx->lock, 
<token> (!list_empty(&p_rx->free_descq)) <answer> if 
p_curp <token> list_first_entry(&p_rx->free_descq, <answer> = 
<token> qed_ll2_rx_packet, list_entry); <answer> struct 
<token> (p_curp) { <answer> if 
if (qed_chain_get_elem_left(&p_rx->rxq_chain) <token> <answer> && 
<token> { <answer> qed_chain_get_elem_left(&p_rx->rcq_chain)) 
p_data = <token> <answer> qed_chain_produce(&p_rx->rxq_chain); 
p_curb = (struct <token> *)p_data; <answer> core_rx_bd_with_buff_len 
rx_num_desc = <token> * (b_is_storage_eng1 ? 2 : 1); <answer> QED_LL2_RX_SIZE 
DP_INFO(cdev, "Allocating %d LL2 buffers of size %08x <token> <answer> bytes\n", 
rx_num_desc, <token> <answer> cdev->ll2->rx_size); 
for (i = 0; i < rx_num_desc; i++) <token> <answer> { 
<token> = kzalloc(sizeof(*buffer), GFP_KERNEL); <answer> buffer 
if (!buffer) <token> <answer> { 
DP_INFO(cdev, "Failed <token> allocate LL2 buffers\n"); <answer> to 
<token> = -ENOMEM; <answer> rc 
<token> err0; <answer> goto 
<token> = qed_ll2_alloc_buffer(cdev, (u8 **)&buffer->data, <answer> rc 
if <token> { <answer> (rc) 
goto <token> <answer> err0; 
list_add_tail(&buffer->list, <token> <answer> &cdev->ll2->list); 
rc <token> __qed_ll2_start(p_hwfn, params); <answer> = 
if <token> { <answer> (rc) 
DP_NOTICE(cdev, "Failed <token> start LL2\n"); <answer> to 
goto <token> <answer> err0; 
<token> (b_is_storage_eng1) { <answer> if 
rc <token> __qed_ll2_start(QED_LEADING_HWFN(cdev), params); <answer> = 
if <token> { <answer> (rc) 
"Failed to start LL2 <token> engine 0\n"); <answer> on 
goto <token> <answer> err1; 
<token> (QED_IS_ISCSI_PERSONALITY(p_hwfn) || QED_IS_NVMETCP_PERSONALITY(p_hwfn)) { <answer> if 
DP_VERBOSE(cdev, QED_MSG_STORAGE, <token> OOO LL2 queue\n"); <answer> "Starting 
rc = <token> params); <answer> qed_ll2_start_ooo(p_hwfn, 
if (rc) <token> <answer> { 
DP_NOTICE(cdev, "Failed <token> start OOO LL2\n"); <answer> to 
<token> err2; <answer> goto 
if <token> { <answer> (!QED_IS_NVMETCP_PERSONALITY(p_hwfn)) 
rc = qed_llh_add_mac_filter(cdev, 0, <token> <answer> params->ll2_mac_address); 
if <token> { <answer> (rc) 
DP_NOTICE(cdev, "Failed to add <token> LLH filter\n"); <answer> an 
goto <token> <answer> err3; 
<token> params->ll2_mac_address); <answer> ether_addr_copy(cdev->ll2_mac_address, 
return <token> <answer> 0; 
if <token> || QED_IS_NVMETCP_PERSONALITY(p_hwfn)) <answer> (QED_IS_ISCSI_PERSONALITY(p_hwfn) 
if <token> <answer> (b_is_storage_eng1) 
cdev->ll2->handle = <token> <answer> QED_LL2_UNUSED_HANDLE; 
return <token> <answer> rc; 
static int qed_ll2_start_xmit(struct qed_dev *cdev, struct <token> *skb, <answer> sk_buff 
<token> long xmit_flags) <answer> unsigned 
<token> qed_hwfn *p_hwfn = QED_AFFIN_HWFN(cdev); <answer> struct 
struct <token> pkt; <answer> qed_ll2_tx_pkt_info 
const skb_frag_t <token> <answer> *frag; 
u8 <token> = 0, nr_frags; <answer> flags 
int rc = <token> i; <answer> -EINVAL, 
<token> mapping; <answer> dma_addr_t 
u16 vlan = <token> <answer> 0; 
if (unlikely(skb->ip_summed <token> CHECKSUM_NONE)) { <answer> != 
<token> "Cannot transmit a checksummed packet\n"); <answer> DP_INFO(cdev, 
<token> -EINVAL; <answer> return 
<token> = skb_shinfo(skb)->nr_frags; <answer> nr_frags 
if (unlikely(1 <token> nr_frags > CORE_LL2_TX_MAX_BDS_PER_PACKET)) { <answer> + 
DP_ERR(cdev, "Cannot transmit a packet <token> %d fragments\n", <answer> with 
1 <token> nr_frags); <answer> + 
<token> -EINVAL; <answer> return 
mapping = <token> skb->data, <answer> dma_map_single(&cdev->pdev->dev, 
skb->len, <token> <answer> DMA_TO_DEVICE); 
if <token> mapping))) { <answer> (unlikely(dma_mapping_error(&cdev->pdev->dev, 
DP_NOTICE(cdev, "SKB <token> failed\n"); <answer> mapping 
<token> -EINVAL; <answer> return 
<token> = qed_ll2_prepare_tx_packet(p_hwfn, cdev->ll2->handle, <answer> rc 
&pkt, <token> <answer> 1); 
if <token> <answer> (unlikely(rc)) 
goto <token> <answer> err; 
for (i = 0; i < nr_frags; i++) <token> <answer> { 
frag <token> &skb_shinfo(skb)->frags[i]; <answer> = 
mapping = skb_frag_dma_map(&cdev->pdev->dev, frag, <token> <answer> 0, 
skb_frag_size(frag), <token> <answer> DMA_TO_DEVICE); 
<token> (unlikely(dma_mapping_error(&cdev->pdev->dev, mapping))) { <answer> if 
"Unable to map frag - dropping <token> <answer> packet\n"); 
<token> = -ENOMEM; <answer> rc 
<token> err; <answer> goto 
rc <token> qed_ll2_set_fragment_of_tx_packet(p_hwfn, <answer> = 
<token> (unlikely(rc)) <answer> if 
<token> err2; <answer> goto 
<token> 0; <answer> return 
dma_unmap_single(&cdev->pdev->dev, mapping, skb->len, <token> <answer> DMA_TO_DEVICE); 
<token> rc; <answer> return 
<token> int qed_ll2_stats(struct qed_dev *cdev, struct qed_ll2_stats *stats) <answer> static 
bool b_is_storage_eng1 <token> qed_ll2_is_storage_eng1(cdev); <answer> = 
struct <token> *p_hwfn = QED_AFFIN_HWFN(cdev); <answer> qed_hwfn 
<token> rc; <answer> int 
<token> (!cdev->ll2) <answer> if 
<token> -EINVAL; <answer> return 
rc = <token> cdev->ll2->handle, stats); <answer> qed_ll2_get_stats(p_hwfn, 
if (rc) <token> <answer> { 
DP_NOTICE(p_hwfn, <token> to get LL2 stats\n"); <answer> "Failed 
<token> rc; <answer> return 
#include <token> <answer> <linux/bits.h> 
#include <token> <answer> <linux/delay.h> 
<token> <linux/device.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/gpio/consumer.h> 
<token> <linux/i2c.h> <answer> #include 
<token> <linux/input.h> <answer> #include 
#include <token> <answer> <linux/input/touchscreen.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/ktime.h> 
<token> <linux/mod_devicetable.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/property.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <asm/unaligned.h> <answer> #include 
#define IQS7222_PROD_NUM <token> <answer> 0x00 
#define <token> 840 <answer> IQS7222_PROD_NUM_A 
#define IQS7222_PROD_NUM_B <token> <answer> 698 
#define <token> 863 <answer> IQS7222_PROD_NUM_C 
#define IQS7222_PROD_NUM_D <token> <answer> 1046 
<token> IQS7222_SYS_STATUS 0x10 <answer> #define 
<token> IQS7222_SYS_STATUS_RESET BIT(3) <answer> #define 
#define <token> BIT(1) <answer> IQS7222_SYS_STATUS_ATI_ERROR 
#define IQS7222_SYS_STATUS_ATI_ACTIVE <token> <answer> BIT(0) 
#define IQS7222_CHAN_SETUP_0_REF_MODE_MASK GENMASK(15, <token> <answer> 14) 
#define <token> BIT(15) <answer> IQS7222_CHAN_SETUP_0_REF_MODE_FOLLOW 
<token> IQS7222_CHAN_SETUP_0_REF_MODE_REF BIT(14) <answer> #define 
#define IQS7222_CHAN_SETUP_0_CHAN_EN <token> <answer> BIT(8) 
#define <token> GENMASK(2, 0) <answer> IQS7222_SLDR_SETUP_0_CHAN_CNT_MASK 
<token> IQS7222_SLDR_SETUP_2_RES_MASK GENMASK(15, 8) <answer> #define 
#define IQS7222_SLDR_SETUP_2_RES_SHIFT <token> <answer> 8 
#define <token> GENMASK(7, 0) <answer> IQS7222_SLDR_SETUP_2_TOP_SPEED_MASK 
#define <token> BIT(0) <answer> IQS7222_GPIO_SETUP_0_GPIO_EN 
#define IQS7222_SYS_SETUP <token> <answer> 0xD0 
#define IQS7222_SYS_SETUP_INTF_MODE_MASK <token> 6) <answer> GENMASK(7, 
#define IQS7222_SYS_SETUP_INTF_MODE_TOUCH <token> <answer> BIT(7) 
#define <token> BIT(6) <answer> IQS7222_SYS_SETUP_INTF_MODE_EVENT 
#define IQS7222_SYS_SETUP_PWR_MODE_MASK GENMASK(5, <token> <answer> 4) 
#define IQS7222_SYS_SETUP_PWR_MODE_AUTO <token> <answer> IQS7222_SYS_SETUP_PWR_MODE_MASK 
<token> IQS7222_SYS_SETUP_REDO_ATI BIT(2) <answer> #define 
<token> IQS7222_SYS_SETUP_ACK_RESET BIT(0) <answer> #define 
#define IQS7222_EVENT_MASK_ATI <token> <answer> BIT(12) 
<token> IQS7222_EVENT_MASK_SLDR BIT(10) <answer> #define 
<token> IQS7222_EVENT_MASK_TPAD IQS7222_EVENT_MASK_SLDR <answer> #define 
#define IQS7222_EVENT_MASK_TOUCH <token> <answer> BIT(1) 
#define IQS7222_EVENT_MASK_PROX <token> <answer> BIT(0) 
#define IQS7222_COMMS_HOLD <token> <answer> BIT(0) 
#define <token> 0xEEEE <answer> IQS7222_COMMS_ERROR 
#define IQS7222_COMMS_RETRY_MS <token> <answer> 50 
#define IQS7222_COMMS_TIMEOUT_MS <token> <answer> 100 
#define IQS7222_RESET_TIMEOUT_MS <token> <answer> 250 
<token> IQS7222_ATI_TIMEOUT_MS 2000 <answer> #define 
<token> IQS7222_MAX_COLS_STAT 8 <answer> #define 
#define IQS7222_MAX_COLS_CYCLE <token> <answer> 3 
<token> IQS7222_MAX_COLS_GLBL 3 <answer> #define 
#define <token> 3 <answer> IQS7222_MAX_COLS_BTN 
#define IQS7222_MAX_COLS_CHAN <token> <answer> 6 
#define <token> 2 <answer> IQS7222_MAX_COLS_FILT 
#define IQS7222_MAX_COLS_SLDR <token> <answer> 11 
#define IQS7222_MAX_COLS_TPAD <token> <answer> 24 
<token> IQS7222_MAX_COLS_GPIO 3 <answer> #define 
#define <token> 13 <answer> IQS7222_MAX_COLS_SYS 
#define <token> 20 <answer> IQS7222_MAX_CHAN 
#define <token> 2 <answer> IQS7222_MAX_SLDR 
<token> IQS7222_NUM_RETRIES 5 <answer> #define 
#define <token> 0x100 <answer> IQS7222_REG_OFFSET 
<token> iqs7222_reg_key_id { <answer> enum 
enum iqs7222_reg_grp_id <token> <answer> { 
static const char <token> const iqs7222_reg_grp_names[IQS7222_NUM_REG_GRPS] = { <answer> * 
<token> = "cycle-%d", <answer> [IQS7222_REG_GRP_CYCLE] 
<token> = "channel-%d", <answer> [IQS7222_REG_GRP_CHAN] 
[IQS7222_REG_GRP_SLDR] = <token> <answer> "slider-%d", 
[IQS7222_REG_GRP_TPAD] <token> "trackpad", <answer> = 
[IQS7222_REG_GRP_GPIO] <token> "gpio-%d", <answer> = 
static const <token> int iqs7222_max_cols[IQS7222_NUM_REG_GRPS] = { <answer> unsigned 
<token> = IQS7222_MAX_COLS_STAT, <answer> [IQS7222_REG_GRP_STAT] 
[IQS7222_REG_GRP_CYCLE] <token> IQS7222_MAX_COLS_CYCLE, <answer> = 
[IQS7222_REG_GRP_GLBL] <token> IQS7222_MAX_COLS_GLBL, <answer> = 
[IQS7222_REG_GRP_BTN] = <token> <answer> IQS7222_MAX_COLS_BTN, 
[IQS7222_REG_GRP_CHAN] = <token> <answer> IQS7222_MAX_COLS_CHAN, 
<token> = IQS7222_MAX_COLS_FILT, <answer> [IQS7222_REG_GRP_FILT] 
[IQS7222_REG_GRP_SLDR] = <token> <answer> IQS7222_MAX_COLS_SLDR, 
<token> = IQS7222_MAX_COLS_TPAD, <answer> [IQS7222_REG_GRP_TPAD] 
[IQS7222_REG_GRP_GPIO] = <token> <answer> IQS7222_MAX_COLS_GPIO, 
<token> = IQS7222_MAX_COLS_SYS, <answer> [IQS7222_REG_GRP_SYS] 
static const unsigned int iqs7222_gpio_links[] = { 2, 5, 6, <token> <answer> }; 
<token> iqs7222_event_desc { <answer> struct 
const <token> *name; <answer> char 
u16 <token> <answer> link; 
u16 <token> <answer> mask; 
<token> val; <answer> u16 
<token> strict; <answer> u16 
<token> enable; <answer> u16 
enum <token> reg_key; <answer> iqs7222_reg_key_id 
static const struct <token> iqs7222_kp_events[] = { <answer> iqs7222_event_desc 
.name <token> "event-prox", <answer> = 
<token> = IQS7222_EVENT_MASK_PROX, <answer> .enable 
.reg_key <token> IQS7222_REG_KEY_PROX, <answer> = 
<token> = "event-touch", <answer> .name 
.enable = <token> <answer> IQS7222_EVENT_MASK_TOUCH, 
.reg_key <token> IQS7222_REG_KEY_TOUCH, <answer> = 
static const struct iqs7222_event_desc iqs7222_sl_events[] <token> { <answer> = 
{ .name <token> "event-press", }, <answer> = 
<token> = "event-tap", <answer> .name 
.mask = <token> <answer> BIT(0), 
.val = <token> <answer> BIT(0), 
.enable = <token> <answer> BIT(0), 
.reg_key <token> IQS7222_REG_KEY_TAP, <answer> = 
.name <token> "event-swipe-pos", <answer> = 
.mask = <token> | BIT(1), <answer> BIT(5) 
<token> = BIT(1), <answer> .val 
.enable <token> BIT(1), <answer> = 
<token> = IQS7222_REG_KEY_AXIAL, <answer> .reg_key 
.name <token> "event-swipe-neg", <answer> = 
.mask <token> BIT(5) | BIT(1), <answer> = 
.val <token> BIT(5) | BIT(1), <answer> = 
.enable <token> BIT(1), <answer> = 
.reg_key = <token> <answer> IQS7222_REG_KEY_AXIAL, 
.name <token> "event-flick-pos", <answer> = 
.mask = BIT(5) <token> BIT(2), <answer> | 
.val <token> BIT(2), <answer> = 
.enable = <token> <answer> BIT(2), 
.reg_key = <token> <answer> IQS7222_REG_KEY_AXIAL, 
.name <token> "event-flick-neg", <answer> = 
.mask = BIT(5) <token> BIT(2), <answer> | 
.val <token> BIT(5) | BIT(2), <answer> = 
.enable <token> BIT(2), <answer> = 
.reg_key = <token> <answer> IQS7222_REG_KEY_AXIAL, 
static <token> struct iqs7222_event_desc iqs7222_tp_events[] = { <answer> const 
.name = <token> <answer> "event-press", 
.link = <token> <answer> BIT(7), 
.name <token> "event-tap", <answer> = 
.link = <token> <answer> BIT(0), 
<token> = BIT(0), <answer> .mask 
.val <token> BIT(0), <answer> = 
<token> = BIT(0), <answer> .enable 
.reg_key <token> IQS7222_REG_KEY_TAP, <answer> = 
.name <token> "event-swipe-x-pos", <answer> = 
<token> = BIT(2), <answer> .link 
.mask <token> BIT(2) | BIT(1), <answer> = 
<token> = BIT(2), <answer> .val 
.strict = <token> <answer> BIT(4), 
.enable <token> BIT(1), <answer> = 
<token> = IQS7222_REG_KEY_AXIAL, <answer> .reg_key 
.name = <token> <answer> "event-swipe-y-pos", 
<token> = BIT(3), <answer> .link 
.mask = BIT(3) | <token> <answer> BIT(1), 
<token> = BIT(3), <answer> .val 
<token> = BIT(3), <answer> .strict 
.enable = <token> <answer> BIT(1), 
<token> = IQS7222_REG_KEY_AXIAL, <answer> .reg_key 
<token> = "event-swipe-x-neg", <answer> .name 
.link = <token> <answer> BIT(4), 
.mask <token> BIT(4) | BIT(1), <answer> = 
.val = <token> <answer> BIT(4), 
.strict = <token> <answer> BIT(4), 
<token> = BIT(1), <answer> .enable 
.reg_key <token> IQS7222_REG_KEY_AXIAL, <answer> = 
.name <token> "event-swipe-y-neg", <answer> = 
.link <token> BIT(5), <answer> = 
.mask = <token> | BIT(1), <answer> BIT(5) 
.val = <token> <answer> BIT(5), 
.strict <token> BIT(3), <answer> = 
<token> = BIT(1), <answer> .enable 
<token> = IQS7222_REG_KEY_AXIAL, <answer> .reg_key 
.name = <token> <answer> "event-flick-x-pos", 
.link = <token> <answer> BIT(2), 
<token> = BIT(2) | BIT(1), <answer> .mask 
.val = BIT(2) <token> BIT(1), <answer> | 
.strict = <token> <answer> BIT(4), 
<token> = BIT(2), <answer> .enable 
<token> = IQS7222_REG_KEY_AXIAL, <answer> .reg_key 
.name <token> "event-flick-y-pos", <answer> = 
.link <token> BIT(3), <answer> = 
.mask <token> BIT(3) | BIT(1), <answer> = 
<token> = BIT(3) | BIT(1), <answer> .val 
.strict <token> BIT(3), <answer> = 
<token> = BIT(2), <answer> .enable 
.reg_key <token> IQS7222_REG_KEY_AXIAL, <answer> = 
<token> = "event-flick-x-neg", <answer> .name 
.link = <token> <answer> BIT(4), 
.mask <token> BIT(4) | BIT(1), <answer> = 
<token> = BIT(4) | BIT(1), <answer> .val 
.strict <token> BIT(4), <answer> = 
<token> = BIT(2), <answer> .enable 
.reg_key <token> IQS7222_REG_KEY_AXIAL, <answer> = 
<token> = "event-flick-y-neg", <answer> .name 
.link <token> BIT(5), <answer> = 
.mask = BIT(5) <token> BIT(1), <answer> | 
.val = BIT(5) <token> BIT(1), <answer> | 
.strict <token> BIT(3), <answer> = 
<token> = BIT(2), <answer> .enable 
<token> = IQS7222_REG_KEY_AXIAL, <answer> .reg_key 
struct iqs7222_reg_grp_desc <token> <answer> { 
u16 <token> <answer> base; 
<token> num_row; <answer> int 
int <token> <answer> num_col; 
<token> iqs7222_dev_desc { <answer> struct 
u16 <token> <answer> prod_num; 
<token> fw_major; <answer> u16 
u16 <token> <answer> fw_minor; 
<token> sldr_res; <answer> u16 
u16 <token> <answer> touch_link; 
<token> wheel_enable; <answer> u16 
<token> allow_offset; <answer> int 
int <token> <answer> event_offset; 
int <token> <answer> comms_offset; 
<token> legacy_gesture; <answer> bool 
struct <token> reg_grps[IQS7222_NUM_REG_GRPS]; <answer> iqs7222_reg_grp_desc 
static const struct iqs7222_dev_desc iqs7222_devs[] = <token> <answer> { 
<token> = IQS7222_PROD_NUM_A, <answer> .prod_num 
.fw_major <token> 1, <answer> = 
.fw_minor <token> 13, <answer> = 
<token> = U8_MAX * 16, <answer> .sldr_res 
<token> = 1768, <answer> .touch_link 
.allow_offset = <token> <answer> 9, 
.event_offset <token> 10, <answer> = 
.comms_offset <token> 12, <answer> = 
.reg_grps = <token> <answer> { 
[IQS7222_REG_GRP_STAT] = <token> <answer> { 
<token> = IQS7222_SYS_STATUS, <answer> .base 
.num_row = <token> <answer> 1, 
.num_col <token> 8, <answer> = 
[IQS7222_REG_GRP_CYCLE] <token> { <answer> = 
.base = <token> <answer> 0x8000, 
.num_row <token> 7, <answer> = 
.num_col <token> 3, <answer> = 
[IQS7222_REG_GRP_GLBL] <token> { <answer> = 
.base = <token> <answer> 0x8700, 
<token> = 1, <answer> .num_row 
<token> = 3, <answer> .num_col 
[IQS7222_REG_GRP_BTN] <token> { <answer> = 
<token> = 0x9000, <answer> .base 
<token> = 12, <answer> .num_row 
.num_col = <token> <answer> 3, 
[IQS7222_REG_GRP_CHAN] = <token> <answer> { 
.base <token> 0xA000, <answer> = 
.num_row = <token> <answer> 12, 
.num_col <token> 6, <answer> = 
[IQS7222_REG_GRP_FILT] = <token> <answer> { 
.base = <token> <answer> 0xAC00, 
<token> = 1, <answer> .num_row 
.num_col <token> 2, <answer> = 
<token> = { <answer> [IQS7222_REG_GRP_SLDR] 
.base = <token> <answer> 0xB000, 
.num_row <token> 2, <answer> = 
.num_col <token> 11, <answer> = 
[IQS7222_REG_GRP_GPIO] = <token> <answer> { 
.base <token> 0xC000, <answer> = 
<token> = 1, <answer> .num_row 
.num_col = <token> <answer> 3, 
<token> = { <answer> [IQS7222_REG_GRP_SYS] 
.base = <token> <answer> IQS7222_SYS_SETUP, 
<token> = 1, <answer> .num_row 
<token> = 13, <answer> .num_col 
.prod_num <token> IQS7222_PROD_NUM_A, <answer> = 
.fw_major = <token> <answer> 1, 
<token> = 12, <answer> .fw_minor 
.sldr_res = U8_MAX * <token> <answer> 16, 
<token> = 1768, <answer> .touch_link 
.allow_offset = <token> <answer> 9, 
<token> = 10, <answer> .event_offset 
.comms_offset <token> 12, <answer> = 
.legacy_gesture = <token> <answer> true, 
.reg_grps = <token> <answer> { 
[IQS7222_REG_GRP_STAT] <token> { <answer> = 
.base <token> IQS7222_SYS_STATUS, <answer> = 
.num_row = <token> <answer> 1, 
<token> = 8, <answer> .num_col 
<token> = { <answer> [IQS7222_REG_GRP_CYCLE] 
<token> = 0x8000, <answer> .base 
.num_row <token> 7, <answer> = 
.num_col = <token> <answer> 3, 
[IQS7222_REG_GRP_GLBL] <token> { <answer> = 
.base = <token> <answer> 0x8700, 
<token> = 1, <answer> .num_row 
.num_col <token> 3, <answer> = 
[IQS7222_REG_GRP_BTN] = <token> <answer> { 
<token> = 0x9000, <answer> .base 
.num_row <token> 12, <answer> = 
.num_col = <token> <answer> 3, 
<token> = { <answer> [IQS7222_REG_GRP_CHAN] 
<token> = 0xA000, <answer> .base 
<token> = 12, <answer> .num_row 
.num_col = <token> <answer> 6, 
[IQS7222_REG_GRP_FILT] <token> { <answer> = 
.base = <token> <answer> 0xAC00, 
.num_row <token> 1, <answer> = 
.num_col = <token> <answer> 2, 
[IQS7222_REG_GRP_SLDR] = <token> <answer> { 
<token> = 0xB000, <answer> .base 
.num_row <token> 2, <answer> = 
.num_col = <token> <answer> 11, 
<token> = { <answer> [IQS7222_REG_GRP_GPIO] 
<token> = 0xC000, <answer> .base 
.num_row <token> 1, <answer> = 
<token> = 3, <answer> .num_col 
[IQS7222_REG_GRP_SYS] = <token> <answer> { 
.base = <token> <answer> IQS7222_SYS_SETUP, 
.num_row = <token> <answer> 1, 
.num_col <token> 13, <answer> = 
.prod_num = <token> <answer> IQS7222_PROD_NUM_B, 
<token> = 1, <answer> .fw_major 
.fw_minor <token> 43, <answer> = 
.event_offset <token> 10, <answer> = 
.comms_offset = <token> <answer> 11, 
.reg_grps <token> { <answer> = 
<token> = { <answer> [IQS7222_REG_GRP_STAT] 
<token> = IQS7222_SYS_STATUS, <answer> .base 
.num_row <token> 1, <answer> = 
.num_col <token> 6, <answer> = 
[IQS7222_REG_GRP_CYCLE] = <token> <answer> { 
.base <token> 0x8000, <answer> = 
.num_row <token> 10, <answer> = 
.num_col = <token> <answer> 2, 
[IQS7222_REG_GRP_GLBL] = <token> <answer> { 
.base = <token> <answer> 0x8A00, 
.num_row = <token> <answer> 1, 
.num_col <token> 3, <answer> = 
[IQS7222_REG_GRP_BTN] <token> { <answer> = 
.base <token> 0x9000, <answer> = 
.num_row = <token> <answer> 20, 
.num_col <token> 2, <answer> = 
[IQS7222_REG_GRP_CHAN] <token> { <answer> = 
.base = <token> <answer> 0xB000, 
<token> = 20, <answer> .num_row 
.num_col <token> 4, <answer> = 
<token> = { <answer> [IQS7222_REG_GRP_FILT] 
.base = <token> <answer> 0xC400, 
<token> = 1, <answer> .num_row 
.num_col = <token> <answer> 2, 
<token> = { <answer> [IQS7222_REG_GRP_SYS] 
<token> = IQS7222_SYS_SETUP, <answer> .base 
.num_row = <token> <answer> 1, 
.num_col <token> 13, <answer> = 
<token> = IQS7222_PROD_NUM_B, <answer> .prod_num 
<token> = 1, <answer> .fw_major 
.fw_minor = <token> <answer> 27, 
<token> = { <answer> .reg_grps 
[IQS7222_REG_GRP_STAT] <token> { <answer> = 
.base = <token> <answer> IQS7222_SYS_STATUS, 
<token> = 1, <answer> .num_row 
<token> = 6, <answer> .num_col 
[IQS7222_REG_GRP_CYCLE] = <token> <answer> { 
<token> = 0x8000, <answer> .base 
.num_row = <token> <answer> 10, 
<token> = 2, <answer> .num_col 
[IQS7222_REG_GRP_GLBL] = <token> <answer> { 
<token> = 0x8A00, <answer> .base 
.num_row = <token> <answer> 1, 
.num_col <token> 3, <answer> = 
<token> = { <answer> [IQS7222_REG_GRP_BTN] 
.base = <token> <answer> 0x9000, 
<token> = 20, <answer> .num_row 
.num_col = <token> <answer> 2, 
[IQS7222_REG_GRP_CHAN] <token> { <answer> = 
.base = <token> <answer> 0xB000, 
.num_row <token> 20, <answer> = 
<token> = 4, <answer> .num_col 
<token> = { <answer> [IQS7222_REG_GRP_FILT] 
.base <token> 0xC400, <answer> = 
<token> = 1, <answer> .num_row 
.num_col <token> 2, <answer> = 
<token> = { <answer> [IQS7222_REG_GRP_SYS] 
.base = <token> <answer> IQS7222_SYS_SETUP, 
.num_row = <token> <answer> 1, 
<token> = 10, <answer> .num_col 
.prod_num <token> IQS7222_PROD_NUM_C, <answer> = 
<token> = 2, <answer> .fw_major 
.fw_minor <token> 6, <answer> = 
.sldr_res <token> U16_MAX, <answer> = 
.touch_link = <token> <answer> 1686, 
.wheel_enable <token> BIT(3), <answer> = 
.event_offset <token> 9, <answer> = 
.comms_offset <token> 10, <answer> = 
.reg_grps = <token> <answer> { 
[IQS7222_REG_GRP_STAT] = <token> <answer> { 
<token> = IQS7222_SYS_STATUS, <answer> .base 
.num_row = <token> <answer> 1, 
.num_col <token> 6, <answer> = 
[IQS7222_REG_GRP_CYCLE] <token> { <answer> = 
<token> = 0x8000, <answer> .base 
.num_row <token> 5, <answer> = 
.num_col = <token> <answer> 3, 
<token> = { <answer> [IQS7222_REG_GRP_GLBL] 
.base <token> 0x8500, <answer> = 
<token> = 1, <answer> .num_row 
<token> = 3, <answer> .num_col 
[IQS7222_REG_GRP_BTN] <token> { <answer> = 
.base = <token> <answer> 0x9000, 
<token> = 10, <answer> .num_row 
.num_col = <token> <answer> 3, 
<token> = { <answer> [IQS7222_REG_GRP_CHAN] 
.base <token> 0xA000, <answer> = 
<token> = 10, <answer> .num_row 
.num_col = <token> <answer> 6, 
<token> = { <answer> [IQS7222_REG_GRP_FILT] 
.base <token> 0xAA00, <answer> = 
.num_row = <token> <answer> 1, 
.num_col = <token> <answer> 2, 
[IQS7222_REG_GRP_SLDR] = <token> <answer> { 
<token> = 0xB000, <answer> .base 
.num_row = <token> <answer> 2, 
<token> = 10, <answer> .num_col 
[IQS7222_REG_GRP_GPIO] <token> { <answer> = 
<token> = 0xC000, <answer> .base 
<token> = 3, <answer> .num_row 
.num_col <token> 3, <answer> = 
[IQS7222_REG_GRP_SYS] = <token> <answer> { 
<token> = IQS7222_SYS_SETUP, <answer> .base 
<token> = 1, <answer> .num_row 
<token> = 12, <answer> .num_col 
<token> = IQS7222_PROD_NUM_C, <answer> .prod_num 
.fw_major = <token> <answer> 1, 
<token> = 13, <answer> .fw_minor 
<token> = U16_MAX, <answer> .sldr_res 
.touch_link = <token> <answer> 1674, 
<token> = BIT(3), <answer> .wheel_enable 
<token> = 9, <answer> .event_offset 
<token> = 10, <answer> .comms_offset 
.reg_grps = <token> <answer> { 
<token> = { <answer> [IQS7222_REG_GRP_STAT] 
<token> = IQS7222_SYS_STATUS, <answer> .base 
.num_row <token> 1, <answer> = 
<token> = 6, <answer> .num_col 
[IQS7222_REG_GRP_CYCLE] <token> { <answer> = 
.base = <token> <answer> 0x8000, 
<token> = 5, <answer> .num_row 
.num_col = <token> <answer> 3, 
<token> = { <answer> [IQS7222_REG_GRP_GLBL] 
.base <token> 0x8500, <answer> = 
.num_row <token> 1, <answer> = 
.num_col <token> 3, <answer> = 
<token> = { <answer> [IQS7222_REG_GRP_BTN] 
<token> = 0x9000, <answer> .base 
.num_row <token> 10, <answer> = 
.num_col <token> 3, <answer> = 
[IQS7222_REG_GRP_CHAN] <token> { <answer> = 
.base <token> 0xA000, <answer> = 
<token> = 10, <answer> .num_row 
.num_col = <token> <answer> 6, 
[IQS7222_REG_GRP_FILT] <token> { <answer> = 
<token> = 0xAA00, <answer> .base 
.num_row <token> 1, <answer> = 
.num_col = <token> <answer> 2, 
[IQS7222_REG_GRP_SLDR] = <token> <answer> { 
.base = <token> <answer> 0xB000, 
<token> = 2, <answer> .num_row 
.num_col <token> 10, <answer> = 
<token> = { <answer> [IQS7222_REG_GRP_GPIO] 
<token> = 0xC000, <answer> .base 
.num_row <token> 1, <answer> = 
.num_col <token> 3, <answer> = 
<token> = { <answer> [IQS7222_REG_GRP_SYS] 
.base = <token> <answer> IQS7222_SYS_SETUP, 
<token> = 1, <answer> .num_row 
.num_col = <token> <answer> 11, 
<token> = IQS7222_PROD_NUM_D, <answer> .prod_num 
.fw_major = <token> <answer> 1, 
.fw_minor <token> 2, <answer> = 
.touch_link <token> 1770, <answer> = 
.allow_offset <token> 9, <answer> = 
.event_offset = <token> <answer> 10, 
.comms_offset <token> 11, <answer> = 
<token> = { <answer> .reg_grps 
[IQS7222_REG_GRP_STAT] <token> { <answer> = 
<token> = IQS7222_SYS_STATUS, <answer> .base 
.num_row = <token> <answer> 1, 
<token> = 7, <answer> .num_col 
<token> = { <answer> [IQS7222_REG_GRP_CYCLE] 
.base <token> 0x8000, <answer> = 
.num_row = <token> <answer> 7, 
.num_col = <token> <answer> 2, 
<token> = { <answer> [IQS7222_REG_GRP_GLBL] 
.base = <token> <answer> 0x8700, 
<token> = 1, <answer> .num_row 
.num_col = <token> <answer> 3, 
[IQS7222_REG_GRP_BTN] <token> { <answer> = 
<token> = 0x9000, <answer> .base 
.num_row <token> 14, <answer> = 
.num_col <token> 3, <answer> = 
<token> = { <answer> [IQS7222_REG_GRP_CHAN] 
.base <token> 0xA000, <answer> = 
<token> = 14, <answer> .num_row 
<token> = 4, <answer> .num_col 
<token> = { <answer> [IQS7222_REG_GRP_FILT] 
<token> = 0xAE00, <answer> .base 
.num_row <token> 1, <answer> = 
<token> = 2, <answer> .num_col 
[IQS7222_REG_GRP_TPAD] = <token> <answer> { 
.base = <token> <answer> 0xB000, 
<token> = 1, <answer> .num_row 
.num_col <token> 24, <answer> = 
[IQS7222_REG_GRP_GPIO] = <token> <answer> { 
.base = <token> <answer> 0xC000, 
.num_row = <token> <answer> 3, 
.num_col <token> 3, <answer> = 
<token> = { <answer> [IQS7222_REG_GRP_SYS] 
<token> = IQS7222_SYS_SETUP, <answer> .base 
<token> = 1, <answer> .num_row 
.num_col <token> 12, <answer> = 
.prod_num <token> IQS7222_PROD_NUM_D, <answer> = 
.fw_major = <token> <answer> 1, 
.fw_minor = <token> <answer> 1, 
<token> = 1774, <answer> .touch_link 
.allow_offset = <token> <answer> 9, 
<token> = 10, <answer> .event_offset 
.comms_offset <token> 11, <answer> = 
<token> = { <answer> .reg_grps 
[IQS7222_REG_GRP_STAT] <token> { <answer> = 
.base = <token> <answer> IQS7222_SYS_STATUS, 
.num_row <token> 1, <answer> = 
<token> = 7, <answer> .num_col 
[IQS7222_REG_GRP_CYCLE] = <token> <answer> { 
<token> = 0x8000, <answer> .base 
.num_row <token> 7, <answer> = 
.num_col = <token> <answer> 2, 
<token> = { <answer> [IQS7222_REG_GRP_GLBL] 
.base = <token> <answer> 0x8700, 
.num_row <token> 1, <answer> = 
<token> = 3, <answer> .num_col 
[IQS7222_REG_GRP_BTN] <token> { <answer> = 
.base = <token> <answer> 0x9000, 
.num_row = <token> <answer> 14, 
.num_col = <token> <answer> 3, 
[IQS7222_REG_GRP_CHAN] <token> { <answer> = 
.base <token> 0xA000, <answer> = 
.num_row <token> 14, <answer> = 
.num_col = <token> <answer> 4, 
[IQS7222_REG_GRP_FILT] <token> { <answer> = 
.base = <token> <answer> 0xAE00, 
.num_row = <token> <answer> 1, 
.num_col = <token> <answer> 2, 
<token> = { <answer> [IQS7222_REG_GRP_TPAD] 
<token> = 0xB000, <answer> .base 
<token> = 1, <answer> .num_row 
<token> = 24, <answer> .num_col 
[IQS7222_REG_GRP_GPIO] = <token> <answer> { 
.base <token> 0xC000, <answer> = 
.num_row = <token> <answer> 3, 
<token> = 3, <answer> .num_col 
[IQS7222_REG_GRP_SYS] = <token> <answer> { 
<token> = IQS7222_SYS_SETUP, <answer> .base 
.num_row <token> 1, <answer> = 
.num_col = <token> <answer> 12, 
<token> = IQS7222_PROD_NUM_D, <answer> .prod_num 
<token> = 0, <answer> .fw_major 
<token> = 37, <answer> .fw_minor 
<token> = 1770, <answer> .touch_link 
<token> = 9, <answer> .allow_offset 
.event_offset = <token> <answer> 10, 
.comms_offset <token> 11, <answer> = 
<token> = { <answer> .reg_grps 
<token> = { <answer> [IQS7222_REG_GRP_STAT] 
<token> = IQS7222_SYS_STATUS, <answer> .base 
.num_row <token> 1, <answer> = 
<token> = 7, <answer> .num_col 
[IQS7222_REG_GRP_CYCLE] <token> { <answer> = 
<token> = 0x8000, <answer> .base 
.num_row = <token> <answer> 7, 
<token> = 2, <answer> .num_col 
[IQS7222_REG_GRP_GLBL] = <token> <answer> { 
<token> = 0x8700, <answer> .base 
.num_row <token> 1, <answer> = 
.num_col = <token> <answer> 3, 
[IQS7222_REG_GRP_BTN] <token> { <answer> = 
.base <token> 0x9000, <answer> = 
<token> = 14, <answer> .num_row 
<token> = 3, <answer> .num_col 
[IQS7222_REG_GRP_CHAN] <token> { <answer> = 
.base = <token> <answer> 0xA000, 
.num_row = <token> <answer> 14, 
.num_col = <token> <answer> 4, 
<token> = { <answer> [IQS7222_REG_GRP_FILT] 
<token> = 0xAE00, <answer> .base 
.num_row = <token> <answer> 1, 
.num_col = <token> <answer> 2, 
<token> = { <answer> [IQS7222_REG_GRP_TPAD] 
.base <token> 0xB000, <answer> = 
.num_row <token> 1, <answer> = 
.num_col <token> 24, <answer> = 
[IQS7222_REG_GRP_GPIO] <token> { <answer> = 
.base <token> 0xC000, <answer> = 
.num_row = <token> <answer> 3, 
.num_col <token> 3, <answer> = 
[IQS7222_REG_GRP_SYS] <token> { <answer> = 
.base = <token> <answer> IQS7222_SYS_SETUP, 
.num_row = <token> <answer> 1, 
.num_col <token> 12, <answer> = 
<token> iqs7222_prop_desc { <answer> struct 
<token> char *name; <answer> const 
<token> iqs7222_reg_grp_id reg_grp; <answer> enum 
<token> iqs7222_reg_key_id reg_key; <answer> enum 
<token> reg_offset; <answer> int 
int <token> <answer> reg_shift; 
<token> reg_width; <answer> int 
int <token> <answer> val_pitch; 
int <token> <answer> val_min; 
<token> val_max; <answer> int 
bool <token> <answer> invert; 
const char <token> <answer> *label; 
static const struct iqs7222_prop_desc <token> = { <answer> iqs7222_props[] 
<token> = "azoteq,conv-period", <answer> .name 
.reg_grp <token> IQS7222_REG_GRP_CYCLE, <answer> = 
.reg_offset = <token> <answer> 0, 
<token> = 8, <answer> .reg_shift 
.reg_width <token> 8, <answer> = 
.label = "conversion <token> <answer> period", 
.name <token> "azoteq,conv-frac", <answer> = 
<token> = IQS7222_REG_GRP_CYCLE, <answer> .reg_grp 
.reg_offset = <token> <answer> 0, 
.reg_shift = <token> <answer> 0, 
.reg_width = <token> <answer> 8, 
.label <token> "conversion frequency fractional divider", <answer> = 
<token> = "azoteq,rx-float-inactive", <answer> .name 
.reg_grp <token> IQS7222_REG_GRP_CYCLE, <answer> = 
.reg_offset = <token> <answer> 1, 
.reg_shift = <token> <answer> 6, 
<token> = 1, <answer> .reg_width 
.invert = <token> <answer> true, 
<token> = "azoteq,dead-time-enable", <answer> .name 
.reg_grp <token> IQS7222_REG_GRP_CYCLE, <answer> = 
.reg_offset = <token> <answer> 1, 
<token> = 5, <answer> .reg_shift 
<token> = 1, <answer> .reg_width 
.name = <token> <answer> "azoteq,tx-freq-fosc", 
<token> = IQS7222_REG_GRP_CYCLE, <answer> .reg_grp 
<token> = 1, <answer> .reg_offset 
.reg_shift = <token> <answer> 4, 
.reg_width <token> 1, <answer> = 
.name <token> "azoteq,vbias-enable", <answer> = 
.reg_grp <token> IQS7222_REG_GRP_CYCLE, <answer> = 
.reg_offset <token> 1, <answer> = 
<token> = 3, <answer> .reg_shift 
<token> = 1, <answer> .reg_width 
<token> = "azoteq,sense-mode", <answer> .name 
.reg_grp <token> IQS7222_REG_GRP_CYCLE, <answer> = 
.reg_offset <token> 1, <answer> = 
<token> = 0, <answer> .reg_shift 
.reg_width <token> 3, <answer> = 
<token> = 3, <answer> .val_max 
.label = "sensing <token> <answer> mode", 
<token> = "azoteq,iref-enable", <answer> .name 
.reg_grp <token> IQS7222_REG_GRP_CYCLE, <answer> = 
<token> = 2, <answer> .reg_offset 
<token> = 10, <answer> .reg_shift 
.reg_width <token> 1, <answer> = 
.name <token> "azoteq,iref-level", <answer> = 
<token> = IQS7222_REG_GRP_CYCLE, <answer> .reg_grp 
.reg_offset = <token> <answer> 2, 
.reg_shift = <token> <answer> 4, 
.reg_width <token> 4, <answer> = 
.label = <token> reference level", <answer> "current 
.name = <token> <answer> "azoteq,iref-trim", 
.reg_grp = <token> <answer> IQS7222_REG_GRP_CYCLE, 
<token> = 2, <answer> .reg_offset 
.reg_shift = <token> <answer> 0, 
.reg_width <token> 4, <answer> = 
.label = <token> reference trim", <answer> "current 
.name <token> "azoteq,max-counts", <answer> = 
.reg_grp = <token> <answer> IQS7222_REG_GRP_GLBL, 
.reg_offset <token> 0, <answer> = 
.reg_shift = <token> <answer> 13, 
.reg_width <token> 2, <answer> = 
.label = <token> counts", <answer> "maximum 
<token> = "azoteq,auto-mode", <answer> .name 
<token> = IQS7222_REG_GRP_GLBL, <answer> .reg_grp 
<token> = 0, <answer> .reg_offset 
.reg_shift = <token> <answer> 2, 
.reg_width <token> 2, <answer> = 
.label = "number of <token> <answer> conversions", 
<token> = "azoteq,ati-frac-div-fine", <answer> .name 
<token> = IQS7222_REG_GRP_GLBL, <answer> .reg_grp 
.reg_offset = <token> <answer> 1, 
.reg_shift <token> 9, <answer> = 
<token> = 5, <answer> .reg_width 
.label = "ATI fine fractional <token> <answer> divider", 
.name <token> "azoteq,ati-frac-div-coarse", <answer> = 
.reg_grp = <token> <answer> IQS7222_REG_GRP_GLBL, 
.reg_offset = <token> <answer> 1, 
.reg_shift = <token> <answer> 0, 
<token> = 5, <answer> .reg_width 
.label <token> "ATI coarse fractional divider", <answer> = 
.name <token> "azoteq,ati-comp-select", <answer> = 
.reg_grp <token> IQS7222_REG_GRP_GLBL, <answer> = 
<token> = 2, <answer> .reg_offset 
.reg_shift <token> 0, <answer> = 
.reg_width = <token> <answer> 10, 
<token> = "ATI compensation selection", <answer> .label 
.name <token> "azoteq,ati-band", <answer> = 
.reg_grp <token> IQS7222_REG_GRP_CHAN, <answer> = 
<token> = 0, <answer> .reg_offset 
.reg_shift <token> 12, <answer> = 
<token> = 2, <answer> .reg_width 
.label = <token> band", <answer> "ATI 
.name = <token> <answer> "azoteq,global-halt", 
.reg_grp <token> IQS7222_REG_GRP_CHAN, <answer> = 
<token> = 0, <answer> .reg_offset 
.reg_shift <token> 11, <answer> = 
.reg_width = <token> <answer> 1, 
.name = <token> <answer> "azoteq,invert-enable", 
<token> = IQS7222_REG_GRP_CHAN, <answer> .reg_grp 
<token> = 0, <answer> .reg_offset 
<token> = 10, <answer> .reg_shift 
.reg_width = <token> <answer> 1, 
<token> = "azoteq,dual-direction", <answer> .name 
<token> = IQS7222_REG_GRP_CHAN, <answer> .reg_grp 
.reg_offset = <token> <answer> 0, 
.reg_shift = <token> <answer> 9, 
<token> = 1, <answer> .reg_width 
.name = <token> <answer> "azoteq,samp-cap-double", 
.reg_grp <token> IQS7222_REG_GRP_CHAN, <answer> = 
.reg_offset <token> 0, <answer> = 
.reg_shift = <token> <answer> 3, 
.reg_width = <token> <answer> 1, 
.name <token> "azoteq,vref-half", <answer> = 
.reg_grp <token> IQS7222_REG_GRP_CHAN, <answer> = 
.reg_offset <token> 0, <answer> = 
<token> = 2, <answer> .reg_shift 
.reg_width = <token> <answer> 1, 
.name = <token> <answer> "azoteq,proj-bias", 
.reg_grp = <token> <answer> IQS7222_REG_GRP_CHAN, 
<token> = 0, <answer> .reg_offset 
.reg_shift <token> 0, <answer> = 
<token> = 2, <answer> .reg_width 
.label <token> "projected bias current", <answer> = 
<token> = "azoteq,ati-target", <answer> .name 
.reg_grp = <token> <answer> IQS7222_REG_GRP_CHAN, 
<token> = 1, <answer> .reg_offset 
<token> = 8, <answer> .reg_shift 
<token> = 8, <answer> .reg_width 
.val_pitch <token> 8, <answer> = 
.label = "ATI <token> <answer> target", 
<token> = "azoteq,ati-base", <answer> .name 
<token> = IQS7222_REG_GRP_CHAN, <answer> .reg_grp 
<token> = 1, <answer> .reg_offset 
.reg_shift <token> 3, <answer> = 
<token> = 5, <answer> .reg_width 
.val_pitch <token> 16, <answer> = 
.label = <token> base", <answer> "ATI 
.name <token> "azoteq,ati-mode", <answer> = 
.reg_grp <token> IQS7222_REG_GRP_CHAN, <answer> = 
.reg_offset <token> 1, <answer> = 
.reg_shift <token> 0, <answer> = 
.reg_width <token> 3, <answer> = 
<token> = 5, <answer> .val_max 
<token> = "ATI mode", <answer> .label 
.name <token> "azoteq,ati-frac-div-fine", <answer> = 
.reg_grp = <token> <answer> IQS7222_REG_GRP_CHAN, 
.reg_offset = <token> <answer> 2, 
.reg_shift <token> 9, <answer> = 
.reg_width <token> 5, <answer> = 
.label = "ATI <token> fractional divider", <answer> fine 
.name = <token> <answer> "azoteq,ati-frac-mult-coarse", 
.reg_grp = <token> <answer> IQS7222_REG_GRP_CHAN, 
<token> = 2, <answer> .reg_offset 
.reg_shift = <token> <answer> 5, 
<token> = 4, <answer> .reg_width 
.label = "ATI coarse <token> multiplier", <answer> fractional 
.name = <token> <answer> "azoteq,ati-frac-div-coarse", 
.reg_grp = <token> <answer> IQS7222_REG_GRP_CHAN, 
<token> = 2, <answer> .reg_offset 
<token> = 0, <answer> .reg_shift 
.reg_width <token> 5, <answer> = 
<token> = "ATI coarse fractional divider", <answer> .label 
.name = <token> <answer> "azoteq,ati-comp-div", 
<token> = IQS7222_REG_GRP_CHAN, <answer> .reg_grp 
.reg_offset = <token> <answer> 3, 
.reg_shift = <token> <answer> 11, 
<token> = 5, <answer> .reg_width 
.label = "ATI <token> divider", <answer> compensation 
.name = <token> <answer> "azoteq,ati-comp-select", 
.reg_grp = <token> <answer> IQS7222_REG_GRP_CHAN, 
.reg_offset = <token> <answer> 3, 
<token> = 0, <answer> .reg_shift 
<token> = 10, <answer> .reg_width 
.label = <token> compensation selection", <answer> "ATI 
.name <token> "azoteq,debounce-exit", <answer> = 
<token> = IQS7222_REG_GRP_BTN, <answer> .reg_grp 
.reg_key = <token> <answer> IQS7222_REG_KEY_DEBOUNCE, 
.reg_offset = <token> <answer> 0, 
.reg_shift <token> 12, <answer> = 
.reg_width <token> 4, <answer> = 
.label <token> "debounce exit factor", <answer> = 
.name <token> "azoteq,debounce-enter", <answer> = 
.reg_grp <token> IQS7222_REG_GRP_BTN, <answer> = 
.reg_key = <token> <answer> IQS7222_REG_KEY_DEBOUNCE, 
.reg_offset <token> 0, <answer> = 
.reg_shift = <token> <answer> 8, 
.reg_width <token> 4, <answer> = 
.label = "debounce <token> factor", <answer> entrance 
.name <token> "azoteq,thresh", <answer> = 
.reg_grp <token> IQS7222_REG_GRP_BTN, <answer> = 
.reg_key = <token> <answer> IQS7222_REG_KEY_PROX, 
.reg_offset <token> 0, <answer> = 
.reg_shift <token> 0, <answer> = 
.reg_width = <token> <answer> 8, 
.val_max = <token> <answer> 127, 
.label = <token> <answer> "threshold", 
<token> = "azoteq,thresh", <answer> .name 
.reg_grp = <token> <answer> IQS7222_REG_GRP_BTN, 
.reg_key <token> IQS7222_REG_KEY_TOUCH, <answer> = 
.reg_offset = <token> <answer> 1, 
.reg_shift = <token> <answer> 0, 
<token> = 8, <answer> .reg_width 
.label <token> "threshold", <answer> = 
<token> = "azoteq,hyst", <answer> .name 
.reg_grp <token> IQS7222_REG_GRP_BTN, <answer> = 
<token> = IQS7222_REG_KEY_TOUCH, <answer> .reg_key 
.reg_offset <token> 1, <answer> = 
<token> = 8, <answer> .reg_shift 
<token> = 8, <answer> .reg_width 
.label = <token> <answer> "hysteresis", 
.name = <token> <answer> "azoteq,lta-beta-lp", 
.reg_grp <token> IQS7222_REG_GRP_FILT, <answer> = 
<token> = 0, <answer> .reg_offset 
.reg_shift = <token> <answer> 12, 
.reg_width = <token> <answer> 4, 
.label = <token> mode long-term average beta", <answer> "low-power 
<token> = "azoteq,lta-beta-np", <answer> .name 
<token> = IQS7222_REG_GRP_FILT, <answer> .reg_grp 
<token> = 0, <answer> .reg_offset 
.reg_shift = <token> <answer> 8, 
.reg_width <token> 4, <answer> = 
.label = "normal-power mode long-term <token> beta", <answer> average 
<token> = "azoteq,counts-beta-lp", <answer> .name 
.reg_grp = <token> <answer> IQS7222_REG_GRP_FILT, 
.reg_offset = <token> <answer> 0, 
<token> = 4, <answer> .reg_shift 
<token> = 4, <answer> .reg_width 
<token> = "low-power mode counts beta", <answer> .label 
<token> = "azoteq,counts-beta-np", <answer> .name 
<token> = IQS7222_REG_GRP_FILT, <answer> .reg_grp 
.reg_offset <token> 0, <answer> = 
<token> = 0, <answer> .reg_shift 
<token> = 4, <answer> .reg_width 
.label = "normal-power mode counts <token> <answer> beta", 
.name <token> "azoteq,lta-fast-beta-lp", <answer> = 
<token> = IQS7222_REG_GRP_FILT, <answer> .reg_grp 
.reg_offset <token> 1, <answer> = 
.reg_shift = <token> <answer> 4, 
<token> = 4, <answer> .reg_width 
<token> = "low-power mode long-term average fast beta", <answer> .label 
<token> = "azoteq,lta-fast-beta-np", <answer> .name 
.reg_grp = <token> <answer> IQS7222_REG_GRP_FILT, 
<token> = 1, <answer> .reg_offset 
.reg_shift <token> 0, <answer> = 
.reg_width = <token> <answer> 4, 
.label = "normal-power mode long-term <token> fast beta", <answer> average 
<token> = "azoteq,lower-cal", <answer> .name 
.reg_grp <token> IQS7222_REG_GRP_SLDR, <answer> = 
<token> = 0, <answer> .reg_offset 
<token> = 8, <answer> .reg_shift 
.reg_width = <token> <answer> 8, 
<token> = "lower calibration", <answer> .label 
<token> = "azoteq,static-beta", <answer> .name 
.reg_grp <token> IQS7222_REG_GRP_SLDR, <answer> = 
<token> = IQS7222_REG_KEY_NO_WHEEL, <answer> .reg_key 
.reg_offset <token> 0, <answer> = 
.reg_shift <token> 6, <answer> = 
.reg_width <token> 1, <answer> = 
<token> = "azoteq,bottom-beta", <answer> .name 
<token> = IQS7222_REG_GRP_SLDR, <answer> .reg_grp 
.reg_key <token> IQS7222_REG_KEY_NO_WHEEL, <answer> = 
<token> = 0, <answer> .reg_offset 
.reg_shift = <token> <answer> 3, 
.reg_width <token> 3, <answer> = 
<token> = "bottom beta", <answer> .label 
.name = <token> <answer> "azoteq,static-beta", 
.reg_grp <token> IQS7222_REG_GRP_SLDR, <answer> = 
.reg_key = <token> <answer> IQS7222_REG_KEY_WHEEL, 
<token> = 0, <answer> .reg_offset 
<token> = 7, <answer> .reg_shift 
<token> = 1, <answer> .reg_width 
<token> = "azoteq,bottom-beta", <answer> .name 
.reg_grp <token> IQS7222_REG_GRP_SLDR, <answer> = 
<token> = IQS7222_REG_KEY_WHEEL, <answer> .reg_key 
.reg_offset = <token> <answer> 0, 
.reg_shift <token> 4, <answer> = 
.reg_width <token> 3, <answer> = 
.label = "bottom <token> <answer> beta", 
.name <token> "azoteq,bottom-speed", <answer> = 
.reg_grp <token> IQS7222_REG_GRP_SLDR, <answer> = 
<token> = 1, <answer> .reg_offset 
<token> = 8, <answer> .reg_shift 
.reg_width <token> 8, <answer> = 
.label = <token> speed", <answer> "bottom 
<token> = "azoteq,upper-cal", <answer> .name 
<token> = IQS7222_REG_GRP_SLDR, <answer> .reg_grp 
<token> = 1, <answer> .reg_offset 
.reg_shift = <token> <answer> 0, 
.reg_width = <token> <answer> 8, 
.label <token> "upper calibration", <answer> = 
.name <token> "azoteq,gesture-max-ms", <answer> = 
.reg_grp = <token> <answer> IQS7222_REG_GRP_SLDR, 
<token> = IQS7222_REG_KEY_TAP, <answer> .reg_key 
.reg_offset = <token> <answer> 9, 
<token> = 8, <answer> .reg_shift 
<token> = 8, <answer> .reg_width 
.val_pitch = <token> <answer> 16, 
.label <token> "maximum gesture time", <answer> = 
.name = <token> <answer> "azoteq,gesture-max-ms", 
.reg_grp <token> IQS7222_REG_GRP_SLDR, <answer> = 
.reg_key = <token> <answer> IQS7222_REG_KEY_TAP_LEGACY, 
<token> = 9, <answer> .reg_offset 
.reg_shift = <token> <answer> 8, 
<token> = 8, <answer> .reg_width 
<token> = 4, <answer> .val_pitch 
.label <token> "maximum gesture time", <answer> = 
.name <token> "azoteq,gesture-min-ms", <answer> = 
<token> = IQS7222_REG_GRP_SLDR, <answer> .reg_grp 
<token> = IQS7222_REG_KEY_TAP, <answer> .reg_key 
<token> = 9, <answer> .reg_offset 
.reg_shift <token> 3, <answer> = 
<token> = 5, <answer> .reg_width 
<token> = 16, <answer> .val_pitch 
.label = "minimum <token> time", <answer> gesture 
<token> = "azoteq,gesture-min-ms", <answer> .name 
.reg_grp = <token> <answer> IQS7222_REG_GRP_SLDR, 
.reg_key = <token> <answer> IQS7222_REG_KEY_TAP_LEGACY, 
.reg_offset <token> 9, <answer> = 
.reg_shift <token> 3, <answer> = 
.reg_width = <token> <answer> 5, 
.val_pitch = <token> <answer> 4, 
.label = "minimum <token> time", <answer> gesture 
<token> = "azoteq,gesture-dist", <answer> .name 
<token> = IQS7222_REG_GRP_SLDR, <answer> .reg_grp 
.reg_key = <token> <answer> IQS7222_REG_KEY_AXIAL, 
.reg_offset = <token> <answer> 10, 
<token> = 8, <answer> .reg_shift 
.reg_width = <token> <answer> 8, 
.val_pitch <token> 16, <answer> = 
.label = "gesture <token> <answer> distance", 
.name = <token> <answer> "azoteq,gesture-dist", 
<token> = IQS7222_REG_GRP_SLDR, <answer> .reg_grp 
.reg_key <token> IQS7222_REG_KEY_AXIAL_LEGACY, <answer> = 
.reg_offset <token> 10, <answer> = 
.reg_shift = <token> <answer> 8, 
.reg_width = <token> <answer> 8, 
<token> = 16, <answer> .val_pitch 
.label <token> "gesture distance", <answer> = 
.name <token> "azoteq,gesture-max-ms", <answer> = 
.reg_grp <token> IQS7222_REG_GRP_SLDR, <answer> = 
.reg_key <token> IQS7222_REG_KEY_AXIAL, <answer> = 
.reg_offset = <token> <answer> 10, 
.reg_shift = <token> <answer> 0, 
.reg_width = <token> <answer> 8, 
.val_pitch = <token> <answer> 16, 
<token> = "maximum gesture time", <answer> .label 
<token> = "azoteq,gesture-max-ms", <answer> .name 
.reg_grp = <token> <answer> IQS7222_REG_GRP_SLDR, 
.reg_key <token> IQS7222_REG_KEY_AXIAL_LEGACY, <answer> = 
.reg_offset = <token> <answer> 10, 
.reg_shift <token> 0, <answer> = 
<token> = 8, <answer> .reg_width 
.val_pitch <token> 4, <answer> = 
<token> = "maximum gesture time", <answer> .label 
<token> = "azoteq,num-rows", <answer> .name 
.reg_grp = <token> <answer> IQS7222_REG_GRP_TPAD, 
.reg_offset <token> 0, <answer> = 
<token> = 4, <answer> .reg_shift 
.reg_width <token> 4, <answer> = 
.val_min <token> 1, <answer> = 
.val_max = <token> <answer> 12, 
.label <token> "number of rows", <answer> = 
.name <token> "azoteq,num-cols", <answer> = 
.reg_grp = <token> <answer> IQS7222_REG_GRP_TPAD, 
<token> = 0, <answer> .reg_offset 
<token> = 0, <answer> .reg_shift 
<token> = 4, <answer> .reg_width 
<token> = 1, <answer> .val_min 
.val_max = <token> <answer> 12, 
.label = "number of <token> <answer> columns", 
.name = <token> <answer> "azoteq,lower-cal-y", 
<token> = IQS7222_REG_GRP_TPAD, <answer> .reg_grp 
.reg_offset = <token> <answer> 1, 
.reg_shift = <token> <answer> 8, 
<token> = 8, <answer> .reg_width 
.label = "lower vertical <token> <answer> calibration", 
.name = <token> <answer> "azoteq,lower-cal-x", 
<token> = IQS7222_REG_GRP_TPAD, <answer> .reg_grp 
<token> = 1, <answer> .reg_offset 
.reg_shift <token> 0, <answer> = 
<token> = 8, <answer> .reg_width 
.label <token> "lower horizontal calibration", <answer> = 
.name = <token> <answer> "azoteq,upper-cal-y", 
<token> = IQS7222_REG_GRP_TPAD, <answer> .reg_grp 
.reg_offset = <token> <answer> 2, 
.reg_shift = <token> <answer> 8, 
.reg_width <token> 8, <answer> = 
.label <token> "upper vertical calibration", <answer> = 
.name <token> "azoteq,upper-cal-x", <answer> = 
.reg_grp <token> IQS7222_REG_GRP_TPAD, <answer> = 
.reg_offset = <token> <answer> 2, 
.reg_shift <token> 0, <answer> = 
.reg_width = <token> <answer> 8, 
.label = "upper <token> calibration", <answer> horizontal 
<token> = "azoteq,top-speed", <answer> .name 
<token> = IQS7222_REG_GRP_TPAD, <answer> .reg_grp 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/errno.h> 
<token> <linux/string.h> <answer> #include 
#include <token> <answer> <linux/types.h> 
<token> <linux/bug.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/spinlock.h> 
<token> <linux/mm.h> <answer> #include 
#include <token> <answer> <linux/uaccess.h> 
#include <token> <answer> <linux/cpu.h> 
<token> <asm/cpufeature.h> <answer> #include 
<token> <asm/hypervisor.h> <answer> #include 
#include <token> <answer> <asm/vsyscall.h> 
<token> <asm/cmdline.h> <answer> #include 
<token> <asm/pti.h> <answer> #include 
#include <token> <answer> <asm/tlbflush.h> 
<token> <asm/desc.h> <answer> #include 
#include <token> <answer> <asm/sections.h> 
<token> <asm/set_memory.h> <answer> #include 
#undef <token> <answer> pr_fmt 
<token> pr_fmt(fmt) "Kernel/User page tables isolation: " fmt <answer> #define 
<token> CONFIG_X86_64 <answer> #ifdef 
#define <token> PTI_CLONE_PMD <answer> PTI_LEVEL_KERNEL_IMAGE 
#define <token> PTI_CLONE_PTE <answer> PTI_LEVEL_KERNEL_IMAGE 
<token> void __init pti_print_if_insecure(const char *reason) <answer> static 
if <token> <answer> (boot_cpu_has_bug(X86_BUG_CPU_MELTDOWN)) 
pr_info("%s\n", <token> <answer> reason); 
static void __init pti_print_if_secure(const char <token> <answer> *reason) 
<token> (!boot_cpu_has_bug(X86_BUG_CPU_MELTDOWN)) <answer> if 
pr_info("%s\n", <token> <answer> reason); 
<token> (!pgdp_maps_userspace(pgdp)) <answer> if 
return <token> <answer> pgd; 
<token> = pgd.pgd; <answer> kernel_to_user_pgdp(pgdp)->pgd 
if ((pgd.pgd <token> (_PAGE_USER|_PAGE_PRESENT)) == (_PAGE_USER|_PAGE_PRESENT) && <answer> & 
(__supported_pte_mask <token> _PAGE_NX)) <answer> & 
pgd.pgd |= <token> <answer> _PAGE_NX; 
<token> p4d_t *pti_user_pagetable_walk_p4d(unsigned long address) <answer> static 
<token> *pgd = kernel_to_user_pgdp(pgd_offset_k(address)); <answer> pgd_t 
gfp_t gfp = (GFP_KERNEL <token> __GFP_NOTRACK | __GFP_ZERO); <answer> | 
if (address < <token> { <answer> PAGE_OFFSET) 
WARN_ONCE(1, <token> to walk user address\n"); <answer> "attempt 
<token> NULL; <answer> return 
<token> (pgd_none(*pgd)) { <answer> if 
unsigned <token> new_p4d_page = __get_free_page(gfp); <answer> long 
<token> (WARN_ON_ONCE(!new_p4d_page)) <answer> if 
<token> NULL; <answer> return 
set_pgd(pgd, __pgd(_KERNPG_TABLE | <token> <answer> __pa(new_p4d_page))); 
BUILD_BUG_ON(pgd_leaf(*pgd) != <token> <answer> 0); 
return <token> address); <answer> p4d_offset(pgd, 
static pmd_t *pti_user_pagetable_walk_pmd(unsigned <token> address) <answer> long 
gfp_t gfp = (GFP_KERNEL | __GFP_NOTRACK <token> __GFP_ZERO); <answer> | 
<token> *p4d; <answer> p4d_t 
<token> *pud; <answer> pud_t 
p4d = <token> <answer> pti_user_pagetable_walk_p4d(address); 
<token> (!p4d) <answer> if 
return <token> <answer> NULL; 
BUILD_BUG_ON(p4d_leaf(*p4d) != <token> <answer> 0); 
if (p4d_none(*p4d)) <token> <answer> { 
unsigned long new_pud_page <token> __get_free_page(gfp); <answer> = 
if <token> <answer> (WARN_ON_ONCE(!new_pud_page)) 
return <token> <answer> NULL; 
set_p4d(p4d, <token> | __pa(new_pud_page))); <answer> __p4d(_KERNPG_TABLE 
<token> = pud_offset(p4d, address); <answer> pud 
static pte_t <token> long address) <answer> *pti_user_pagetable_walk_pte(unsigned 
gfp_t gfp = (GFP_KERNEL | __GFP_NOTRACK | <token> <answer> __GFP_ZERO); 
<token> *pmd; <answer> pmd_t 
pte_t <token> <answer> *pte; 
pmd <token> pti_user_pagetable_walk_pmd(address); <answer> = 
<token> (!pmd) <answer> if 
<token> NULL; <answer> return 
for (addr = start; <token> < end;) { <answer> addr 
<token> *pte, *target_pte; <answer> pte_t 
pmd_t *pmd, <token> <answer> *target_pmd; 
pgd_t <token> <answer> *pgd; 
p4d_t <token> <answer> *p4d; 
pud_t <token> <answer> *pud; 
<token> (WARN_ON(!(pmd_flags(*pmd) & _PAGE_PRESENT))) <answer> if 
if <token> <answer> (boot_cpu_has(X86_FEATURE_PGE)) 
*pmd = <token> _PAGE_GLOBAL); <answer> pmd_set_flags(*pmd, 
*target_pmd = <token> <answer> *pmd; 
addr += <token> <answer> PMD_SIZE; 
} else if (level == <token> { <answer> PTI_CLONE_PTE) 
static void <token> pti_clone_p4d(unsigned long addr) <answer> __init 
p4d_t *kernel_p4d, <token> <answer> *user_p4d; 
<token> *kernel_pgd; <answer> pgd_t 
<token> = pti_user_pagetable_walk_p4d(addr); <answer> user_p4d 
if <token> <answer> (!user_p4d) 
kernel_pgd = <token> <answer> pgd_offset_k(addr); 
kernel_p4d = <token> addr); <answer> p4d_offset(kernel_pgd, 
*user_p4d = <token> <answer> *kernel_p4d; 
static void __init <token> <answer> pti_clone_user_shared(void) 
unsigned int <token> <answer> cpu; 
for_each_possible_cpu(cpu) <token> <answer> { 
unsigned long va <token> (unsigned long)&per_cpu(cpu_tss_rw, cpu); <answer> = 
phys_addr_t pa = <token> *)va); <answer> per_cpu_ptr_to_phys((void 
pte_t <token> <answer> *target_pte; 
target_pte = <token> <answer> pti_user_pagetable_walk_pte(va); 
if <token> <answer> (WARN_ON(!target_pte)) 
<token> = pfn_pte(pa >> PAGE_SHIFT, PAGE_KERNEL); <answer> *target_pte 
static <token> __init pti_clone_user_shared(void) <answer> void 
unsigned <token> start, end; <answer> long 
<token> = CPU_ENTRY_AREA_BASE; <answer> start 
end = start <token> (PAGE_SIZE * CPU_ENTRY_AREA_PAGES); <answer> + 
pti_clone_pgtable(start, end, <token> <answer> PTI_CLONE_PMD); 
static void __init <token> <answer> pti_setup_espfix64(void) 
#ifdef <token> <answer> CONFIG_X86_ESPFIX64 
static <token> pti_clone_entry_text(void) <answer> void 
pti_clone_pgtable((unsigned <token> __entry_text_start, <answer> long) 
<token> long) __entry_text_end, <answer> (unsigned 
static inline bool <token> <answer> pti_kernel_image_global_ok(void) 
<token> (cpu_feature_enabled(X86_FEATURE_PCID)) <answer> if 
<token> false; <answer> return 
if <token> != PTI_AUTO) <answer> (pti_mode 
<token> false; <answer> return 
if <token> <answer> (boot_cpu_has(X86_FEATURE_K8)) 
<token> false; <answer> return 
<token> (IS_ENABLED(CONFIG_RANDSTRUCT)) <answer> if 
<token> false; <answer> return 
<token> true; <answer> return 
<token> void pti_clone_kernel_text(void) <answer> static 
unsigned long start <token> PFN_ALIGN(_text); <answer> = 
<token> long end_clone = (unsigned long)__end_rodata_aligned; <answer> unsigned 
unsigned long <token> = PFN_ALIGN((unsigned long)_etext); <answer> end_global 
if <token> <answer> (!pti_kernel_image_global_ok()) 
pr_debug("mapping partial <token> image into user address space\n"); <answer> kernel 
pti_clone_pgtable(start, end_clone, <token> <answer> PTI_LEVEL_KERNEL_IMAGE); 
<token> long start = PFN_ALIGN(_text); <answer> unsigned 
unsigned long end = <token> long)_end, PMD_SIZE); <answer> ALIGN((unsigned 
set_memory_nonglobal(start, (end - start) >> <token> <answer> PAGE_SHIFT); 
void __init <token> <answer> pti_init(void) 
<token> (!boot_cpu_has(X86_FEATURE_PTI)) <answer> if 
#ifdef <token> <answer> CONFIG_X86_32 
<token> (cpuid_ecx(0x1) & BIT(17)) { <answer> if 
<token> pti_finalize(void) <answer> void 
<token> (!boot_cpu_has(X86_FEATURE_PTI)) <answer> if 
#define pr_fmt(fmt) KBUILD_MODNAME ": " <token> <answer> fmt 
<token> <linux/acpi.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <asm/cpu_device_id.h> 
<token> <asm/intel-family.h> <answer> #include 
<token> "intel_soc_dts_iosf.h" <answer> #include 
<token> CRITICAL_OFFSET_FROM_TJ_MAX 5000 <answer> #define 
<token> int crit_offset = CRITICAL_OFFSET_FROM_TJ_MAX; <answer> static 
<token> int, 0644); <answer> module_param(crit_offset, 
"Critical Temperature offset from tj max in millidegree <token> <answer> Celsius."); 
soc_dts_thres_irq = acpi_register_gsi(NULL, <token> <answer> soc_dts_thres_gsi, 
if (soc_dts_thres_irq < <token> { <answer> 0) 
<token> Could not get IRQ for GSI %d, err %d\n", <answer> pr_warn("intel_soc_dts: 
soc_dts_thres_gsi, <token> <answer> soc_dts_thres_irq); 
soc_dts_thres_irq <token> 0; <answer> = 
if (soc_dts_thres_irq) <token> <answer> { 
err <token> request_threaded_irq(soc_dts_thres_irq, NULL, <answer> = 
<token> | IRQF_ONESHOT, <answer> IRQF_TRIGGER_RISING 
"soc_dts", <token> <answer> soc_dts); 
if <token> { <answer> (err) 
pr_warn("request_threaded_irq ret %d\n", <token> <answer> err); 
<token> 0; <answer> return 
static <token> __exit intel_soc_thermal_exit(void) <answer> void 
if (soc_dts_thres_irq) <token> <answer> { 
free_irq(soc_dts_thres_irq, <token> <answer> soc_dts); 
<token> SoC DTS Thermal Driver"); <answer> MODULE_DESCRIPTION("Intel 
MODULE_AUTHOR("Srinivas Pandruvada <token> <answer> <srinivas.pandruvada@linux.intel.com>"); 
MODULE_LICENSE("GPL <token> <answer> v2"); 
<token> true); <answer> mt7925_mcu_set_deep_sleep(dev, 
err = mt76_connac_mcu_set_hif_suspend(mdev, <token> <answer> true); 
if <token> <answer> (err) 
goto <token> <answer> restore_suspend; 
mt76_for_each_q_rx(mdev, <token> { <answer> i) 
#include <token> <answer> <linux/string.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/pci.h> <answer> #include 
<token> <linux/pci_ids.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_address.h> <answer> #include 
<token> <linux/of_device.h> <answer> #include 
#include <token> <answer> <linux/of_platform.h> 
#include <token> <answer> <linux/of_irq.h> 
<token> <asm/machdep.h> <answer> #include 
#include <token> <answer> <asm/macio.h> 
<token> <asm/pmac_feature.h> <answer> #include 
#undef <token> <answer> DEBUG 
#define MAX_NODE_NAME_SIZE (20 - <token> <answer> 12) 
static <token> macio_chip *macio_on_hold; <answer> struct 
static int macio_bus_match(struct device *dev, struct <token> *drv) <answer> device_driver 
const struct of_device_id * matches <token> drv->of_match_table; <answer> = 
if <token> <answer> (!matches) 
return <token> <answer> 0; 
return of_match_device(matches, dev) != <token> <answer> NULL; 
struct macio_dev *macio_dev_get(struct macio_dev <token> <answer> *dev) 
struct device <token> <answer> *tmp; 
<token> (!dev) <answer> if 
<token> NULL; <answer> return 
<token> = get_device(&dev->ofdev.dev); <answer> tmp 
<token> (tmp) <answer> if 
return <token> <answer> to_macio_device(tmp); 
<token> NULL; <answer> return 
<token> macio_dev_put(struct macio_dev *dev) <answer> void 
<token> (dev) <answer> if 
static int <token> device *dev) <answer> macio_device_probe(struct 
<token> error = -ENODEV; <answer> int 
struct macio_driver <token> <answer> *drv; 
<token> macio_dev *macio_dev; <answer> struct 
const <token> of_device_id *match; <answer> struct 
drv = <token> <answer> to_macio_driver(dev->driver); 
<token> = to_macio_device(dev); <answer> macio_dev 
if <token> <answer> (!drv->probe) 
return <token> <answer> error; 
match = of_match_device(drv->driver.of_match_table, <token> <answer> dev); 
<token> (match) <answer> if 
<token> = drv->probe(macio_dev, match); <answer> error 
if <token> <answer> (error) 
return <token> <answer> error; 
static <token> macio_device_remove(struct device *dev) <answer> void 
struct macio_dev * macio_dev = <token> <answer> to_macio_device(dev); 
struct <token> * drv = to_macio_driver(dev->driver); <answer> macio_driver 
if (dev->driver && <token> <answer> drv->remove) 
<token> void macio_device_shutdown(struct device *dev) <answer> static 
struct macio_dev * macio_dev = <token> <answer> to_macio_device(dev); 
<token> macio_driver * drv = to_macio_driver(dev->driver); <answer> struct 
if <token> && drv->shutdown) <answer> (dev->driver 
static int macio_device_suspend(struct device <token> pm_message_t state) <answer> *dev, 
struct macio_dev * <token> = to_macio_device(dev); <answer> macio_dev 
<token> macio_driver * drv = to_macio_driver(dev->driver); <answer> struct 
<token> (dev->driver && drv->suspend) <answer> if 
<token> drv->suspend(macio_dev, state); <answer> return 
return <token> <answer> 0; 
static int <token> device * dev) <answer> macio_device_resume(struct 
<token> macio_dev * macio_dev = to_macio_device(dev); <answer> struct 
struct macio_driver <token> drv = to_macio_driver(dev->driver); <answer> * 
<token> (dev->driver && drv->resume) <answer> if 
<token> drv->resume(macio_dev); <answer> return 
return <token> <answer> 0; 
<token> int macio_device_modalias(const struct device *dev, struct kobj_uevent_env *env) <answer> static 
<token> of_device_uevent_modalias(dev, env); <answer> return 
extern const struct <token> *macio_dev_groups[]; <answer> attribute_group 
const struct bus_type macio_bus_type <token> { <answer> = 
.name = <token> <answer> "macio", 
<token> = macio_bus_match, <answer> .match 
<token> = macio_device_modalias, <answer> .uevent 
<token> = macio_device_probe, <answer> .probe 
.remove = <token> <answer> macio_device_remove, 
<token> = macio_device_shutdown, <answer> .shutdown 
.suspend = <token> <answer> macio_device_suspend, 
.resume = <token> <answer> macio_device_resume, 
.dev_groups <token> macio_dev_groups, <answer> = 
static int <token> macio_bus_driver_init(void) <answer> __init 
<token> bus_register(&macio_bus_type); <answer> return 
static void macio_release_dev(struct <token> *dev) <answer> device 
struct macio_dev <token> <answer> *mdev; 
mdev = <token> <answer> to_macio_device(dev); 
static int <token> device_node *np, struct resource *res, <answer> macio_resource_quirks(struct 
int <token> <answer> index) 
<token> (of_node_name_eq(np, "escc")) <answer> if 
<token> 1; <answer> return 
irq_base <token> 64; <answer> = 
if <token> res)) { <answer> (insert_resource(parent_res, 
<token> "Can't request resource " <answer> printk(KERN_WARNING 
"%d for <token> device %s\n", <answer> MacIO 
<token> dev_name(&dev->ofdev.dev)); <answer> index, 
dev->n_resources <token> index; <answer> = 
static struct macio_dev * macio_add_one_device(struct <token> *chip, <answer> macio_chip 
struct <token> *parent, <answer> device 
<token> device_node *np, <answer> struct 
<token> macio_dev *in_bay, <answer> struct 
struct <token> *parent_res) <answer> resource 
char name[MAX_NODE_NAME_SIZE <token> 1]; <answer> + 
struct <token> *dev; <answer> macio_dev 
const <token> *reg; <answer> u32 
if <token> == NULL) <answer> (np 
return <token> <answer> NULL; 
dev <token> kzalloc(sizeof(*dev), GFP_KERNEL); <answer> = 
if <token> <answer> (!dev) 
<token> NULL; <answer> return 
dev->bus = <token> <answer> &chip->lbus; 
dev->media_bay = <token> <answer> in_bay; 
dev->ofdev.dev.of_node <token> np; <answer> = 
dev->ofdev.archdata.dma_mask <token> 0xffffffffUL; <answer> = 
dev->ofdev.dev.dma_mask <token> &dev->ofdev.archdata.dma_mask; <answer> = 
<token> = dev->ofdev.archdata.dma_mask; <answer> dev->ofdev.dev.coherent_dma_mask 
dev->ofdev.dev.parent <token> parent; <answer> = 
dev->ofdev.dev.bus <token> &macio_bus_type; <answer> = 
dev->ofdev.dev.release = <token> <answer> macio_release_dev; 
dev->ofdev.dev.dma_parms = <token> <answer> &dev->dma_parms; 
<token> = chip->lbus.pdev->dev.archdata; <answer> dev->ofdev.dev.archdata 
<token> = chip->lbus.pdev->dev.dma_ops; <answer> dev->ofdev.dev.dma_ops 
<token> void macio_pci_add_devices(struct macio_chip *chip) <answer> static 
<token> device_node *np, *pnode; <answer> struct 
struct macio_dev *rdev, *mdev, <token> = NULL, *sdev = NULL; <answer> *mbdev 
struct device <token> = NULL; <answer> *parent 
struct resource *root_res <token> &iomem_resource; <answer> = 
int <token> macio_driver *drv) <answer> macio_register_driver(struct 
void macio_unregister_driver(struct <token> *drv) <answer> macio_driver 
<token> macio_request_resource(struct macio_dev *dev, int resource_no, <answer> int 
<token> char *name) <answer> const 
<token> macio_devres *dr = find_macio_dr(dev); <answer> struct 
if (macio_resource_len(dev, resource_no) <token> 0) <answer> == 
return <token> <answer> 0; 
if (!request_mem_region(macio_resource_start(dev, <token> <answer> resource_no), 
macio_resource_len(dev, <token> <answer> resource_no), 
goto <token> <answer> err_out; 
<token> (dr && resource_no < 32) <answer> if 
dr->res_mask |= <token> << resource_no; <answer> 1 
<token> 0; <answer> return 
printk (KERN_WARNING "MacIO: Unable to reserve <token> #%d:%lx@%lx" <answer> resource 
" for <token> %s\n", <answer> device 
macio_resource_len(dev, <token> <answer> resource_no), 
macio_resource_start(dev, <token> <answer> resource_no), 
return <token> <answer> -EBUSY; 
void macio_release_resource(struct macio_dev <token> int resource_no) <answer> *dev, 
struct <token> *dr = find_macio_dr(dev); <answer> macio_devres 
if <token> resource_no) == 0) <answer> (macio_resource_len(dev, 
release_mem_region(macio_resource_start(dev, <token> <answer> resource_no), 
macio_resource_len(dev, <token> <answer> resource_no)); 
if (dr <token> resource_no < 32) <answer> && 
dr->res_mask &= ~(1 << <token> <answer> resource_no); 
int macio_request_resources(struct macio_dev <token> const char *name) <answer> *dev, 
<token> i; <answer> int 
for (i <token> 0; i < dev->n_resources; i++) <answer> = 
if <token> i, name)) <answer> (macio_request_resource(dev, 
<token> err_out; <answer> goto 
return <token> <answer> 0; 
<token> >= 0) <answer> while(--i 
macio_release_resource(dev, <token> <answer> i); 
return <token> <answer> -EBUSY; 
void macio_release_resources(struct <token> *dev) <answer> macio_dev 
<token> i; <answer> int 
for (i <token> 0; i < dev->n_resources; i++) <answer> = 
macio_release_resource(dev, <token> <answer> i); 
<token> CONFIG_PCI <answer> #ifdef 
static int macio_pci_probe(struct pci_dev <token> const struct pci_device_id *ent) <answer> *pdev, 
<token> device_node* np; <answer> struct 
struct <token> chip; <answer> macio_chip* 
if <token> != PCI_VENDOR_ID_APPLE) <answer> (ent->vendor 
return <token> <answer> -ENODEV; 
np <token> pci_device_to_OF_node(pdev); <answer> = 
if <token> == NULL) <answer> (np 
<token> -ENODEV; <answer> return 
chip <token> macio_find(np, macio_unknown); <answer> = 
if <token> == NULL) <answer> (chip 
return <token> <answer> -ENODEV; 
if (chip->type == macio_gatwick || chip->type <token> macio_ohareII) <answer> == 
if (macio_chips[0].lbus.pdev <token> NULL) { <answer> == 
macio_on_hold = <token> <answer> chip; 
return <token> <answer> 0; 
if <token> && macio_chips[0].lbus.pdev != NULL) { <answer> (macio_on_hold 
macio_on_hold = <token> <answer> NULL; 
return <token> <answer> 0; 
<token> void macio_pci_remove(struct pci_dev* pdev) <answer> static 
panic("removing of <token> not supported !\n"); <answer> macio-asic 
static const struct pci_device_id pci_ids[] <token> { { <answer> = 
.vendor <token> PCI_VENDOR_ID_APPLE, <answer> = 
.device <token> PCI_ANY_ID, <answer> = 
.subvendor <token> PCI_ANY_ID, <answer> = 
.subdevice = <token> <answer> PCI_ANY_ID, 
<token> <linux/module.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/input.h> 
<token> <linux/workqueue.h> <answer> #include 
#include <token> <answer> <linux/mfd/da903x.h> 
<token> <linux/slab.h> <answer> #include 
#define DA9034_MANUAL_CTRL <token> <answer> 0x50 
<token> DA9034_LDO_ADC_EN (1 << 4) <answer> #define 
#define DA9034_AUTO_CTRL1 <token> <answer> 0x51 
#define DA9034_AUTO_CTRL2 <token> <answer> 0x52 
#define DA9034_AUTO_TSI_EN <token> << 3) <answer> (1 
<token> DA9034_PEN_DETECT (1 << 4) <answer> #define 
#define <token> 0x53 <answer> DA9034_TSI_CTRL1 
<token> DA9034_TSI_CTRL2 0x54 <answer> #define 
#define DA9034_TSI_X_MSB <token> <answer> 0x6c 
<token> DA9034_TSI_Y_MSB 0x6d <answer> #define 
#define DA9034_TSI_XY_LSB <token> <answer> 0x6e 
<token> { <answer> enum 
err <token> start_tsi(touch); <answer> = 
if <token> <answer> (err) 
goto <token> <answer> err_reset; 
touch->state <token> STATE_BUSY; <answer> = 
<token> STATE_BUSY: <answer> case 
if (event <token> EVENT_TSI_READY) <answer> != 
err <token> read_tsi(touch); <answer> = 
if <token> <answer> (err) 
<token> err_reset; <answer> goto 
err = <token> <answer> stop_tsi(touch); 
<token> (err) <answer> if 
goto <token> <answer> err_reset; 
touch->state = <token> <answer> STATE_STOP; 
is_pen_down(touch) ? <token> : <answer> EVENT_PEN_DOWN 
<token> STATE_STOP: <answer> case 
if (event <token> EVENT_PEN_DOWN) { <answer> == 
touch->state <token> STATE_WAIT; <answer> = 
if (event == EVENT_PEN_UP) <token> <answer> { 
touch->state <token> STATE_IDLE; <answer> = 
<token> STATE_WAIT: <answer> case 
if (event <token> EVENT_TIMEDOUT) <answer> != 
<token> (is_pen_down(touch)) { <answer> if 
touch->state <token> STATE_BUSY; <answer> = 
} else <token> <answer> { 
touch->state <token> STATE_IDLE; <answer> = 
<token> = STATE_IDLE; <answer> touch->state 
detect_pen_down(touch, <token> <answer> 1); 
static void <token> work_struct *work) <answer> da9034_tsi_work(struct 
struct <token> *touch = <answer> da9034_touch 
container_of(work, struct <token> tsi_work.work); <answer> da9034_touch, 
da9034_event_handler(touch, <token> <answer> EVENT_TIMEDOUT); 
static <token> da9034_touch_notifier(struct notifier_block *nb, <answer> int 
<token> long event, void *data) <answer> unsigned 
struct da9034_touch *touch <token> <answer> = 
<token> struct da9034_touch, notifier); <answer> container_of(nb, 
<token> (event & DA9034_EVENT_TSI_READY) <answer> if 
<token> EVENT_TSI_READY); <answer> da9034_event_handler(touch, 
if ((event & DA9034_EVENT_PEN_DOWN) && <token> == STATE_IDLE) <answer> touch->state 
<token> EVENT_PEN_DOWN); <answer> da9034_event_handler(touch, 
<token> 0; <answer> return 
static <token> da9034_touch_open(struct input_dev *dev) <answer> int 
struct da9034_touch <token> = input_get_drvdata(dev); <answer> *touch 
int <token> <answer> ret; 
ret = <token> &touch->notifier, <answer> da903x_register_notifier(touch->da9034_dev, 
<token> | DA9034_EVENT_TSI_READY); <answer> DA9034_EVENT_PEN_DOWN 
if <token> <answer> (ret) 
return <token> <answer> -EBUSY; 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/rtc.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/bcd.h> 
<token> <linux/slab.h> <answer> #include 
<token> ds1216_regs { <answer> struct 
<token> tsec; <answer> u8 
u8 <token> <answer> sec; 
u8 <token> <answer> min; 
u8 <token> <answer> hour; 
u8 <token> <answer> wday; 
u8 <token> <answer> mday; 
<token> month; <answer> u8 
u8 <token> <answer> year; 
<token> DS1216_HOUR_1224 (1 << 7) <answer> #define 
#define DS1216_HOUR_AMPM (1 << <token> <answer> 5) 
<token> ds1216_priv { <answer> struct 
struct <token> *rtc; <answer> rtc_device 
<token> __iomem *ioaddr; <answer> void 
static <token> u8 magic[] = { <answer> const 
0xc5, 0x3a, 0xa3, 0x5c, <token> 0x3a, 0xa3, 0x5c <answer> 0xc5, 
static <token> ds1216_read(u8 __iomem *ioaddr, u8 *buf) <answer> void 
<token> char c; <answer> unsigned 
int <token> j; <answer> i, 
for (i <token> 0; i < 8; i++) { <answer> = 
c = <token> <answer> 0; 
for (j = 0; j < <token> j++) <answer> 8; 
c |= (readb(ioaddr) <token> 0x1) << j; <answer> & 
buf[i] <token> c; <answer> = 
static void ds1216_write(u8 <token> *ioaddr, const u8 *buf) <answer> __iomem 
unsigned char <token> <answer> c; 
<token> i, j; <answer> int 
for (i = 0; i < 8; <token> { <answer> i++) 
c = <token> <answer> buf[i]; 
for (j = <token> j < 8; j++) { <answer> 0; 
writeb(c, <token> <answer> ioaddr); 
c = <token> >> 1; <answer> c 
static void <token> __iomem *ioaddr) <answer> ds1216_switch_ds_to_clock(u8 
<token> <linux/bottom_half.h> <answer> #include 
#include <token> <answer> <linux/cache.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/netdevice.h> 
<token> <linux/percpu.h> <answer> #include 
#include <token> <answer> <net/dst.h> 
<token> <net/ip.h> <answer> #include 
<token> <net/xfrm.h> <answer> #include 
#include <token> <answer> <net/ip_tunnels.h> 
<token> <net/ip6_tunnel.h> <answer> #include 
#include <token> <answer> <net/dst_metadata.h> 
<token> <net/hotdata.h> <answer> #include 
#include <token> <answer> "xfrm_inout.h" 
struct <token> { <answer> xfrm_trans_tasklet 
struct <token> work; <answer> work_struct 
spinlock_t <token> <answer> queue_lock; 
<token> sk_buff_head queue; <answer> struct 
struct <token> { <answer> xfrm_trans_cb 
union <token> <answer> { 
struct inet_skb_parm <token> <answer> h4; 
#if <token> <answer> IS_ENABLED(CONFIG_IPV6) 
struct <token> h6; <answer> inet6_skb_parm 
} <token> <answer> header; 
int <token> net *net, struct sock *sk, struct sk_buff *skb); <answer> (*finish)(struct 
struct net <token> <answer> *net; 
#define <token> ((struct xfrm_trans_cb *)&((__skb)->cb[0])) <answer> XFRM_TRANS_SKB_CB(__skb) 
static <token> <answer> DEFINE_SPINLOCK(xfrm_input_afinfo_lock); 
<token> struct xfrm_input_afinfo const __rcu *xfrm_input_afinfo[2][AF_INET6 + 1]; <answer> static 
static struct gro_cells <token> <answer> gro_cells; 
static struct <token> xfrm_napi_dev; <answer> net_device 
static DEFINE_PER_CPU(struct xfrm_trans_tasklet, <token> <answer> xfrm_trans_tasklet); 
int xfrm_input_register_afinfo(const <token> xfrm_input_afinfo *afinfo) <answer> struct 
int err <token> 0; <answer> = 
if (WARN_ON(afinfo->family <token> AF_INET6)) <answer> > 
return <token> <answer> -EAFNOSUPPORT; 
if <token> <answer> (unlikely(xfrm_input_afinfo[afinfo->is_ipip][afinfo->family])) 
err <token> -EEXIST; <answer> = 
rcu_assign_pointer(xfrm_input_afinfo[afinfo->is_ipip][afinfo->family], <token> <answer> afinfo); 
return <token> <answer> err; 
int xfrm_input_unregister_afinfo(const struct xfrm_input_afinfo <token> <answer> *afinfo) 
int err <token> 0; <answer> = 
<token> (likely(xfrm_input_afinfo[afinfo->is_ipip][afinfo->family])) { <answer> if 
if <token> != afinfo)) <answer> (unlikely(xfrm_input_afinfo[afinfo->is_ipip][afinfo->family] 
<token> = -EINVAL; <answer> err 
<token> NULL); <answer> RCU_INIT_POINTER(xfrm_input_afinfo[afinfo->is_ipip][afinfo->family], 
<token> err; <answer> return 
static const <token> xfrm_input_afinfo *xfrm_input_get_afinfo(u8 family, bool is_ipip) <answer> struct 
const struct xfrm_input_afinfo <token> <answer> *afinfo; 
if (WARN_ON_ONCE(family > <token> <answer> AF_INET6)) 
return <token> <answer> NULL; 
<token> = rcu_dereference(xfrm_input_afinfo[is_ipip][family]); <answer> afinfo 
if <token> <answer> (unlikely(!afinfo)) 
<token> afinfo; <answer> return 
static <token> xfrm_rcv_cb(struct sk_buff *skb, unsigned int family, u8 protocol, <answer> int 
int <token> <answer> err) 
bool <token> = (protocol == IPPROTO_IPIP || protocol == IPPROTO_IPV6); <answer> is_ipip 
const <token> xfrm_input_afinfo *afinfo; <answer> struct 
<token> ret; <answer> int 
afinfo <token> xfrm_input_get_afinfo(family, is_ipip); <answer> = 
if <token> <answer> (!afinfo) 
return <token> <answer> -EAFNOSUPPORT; 
ret = afinfo->callback(skb, protocol, <token> <answer> err); 
<token> ret; <answer> return 
<token> sec_path *secpath_set(struct sk_buff *skb) <answer> struct 
<token> sec_path *sp, *tmp = skb_ext_find(skb, SKB_EXT_SEC_PATH); <answer> struct 
<token> = skb_ext_add(skb, SKB_EXT_SEC_PATH); <answer> sp 
<token> (!sp) <answer> if 
<token> NULL; <answer> return 
<token> int <answer> static 
xfrm_inner_mode_encap_remove(struct <token> *x, <answer> xfrm_state 
<token> sk_buff *skb) <answer> struct 
switch (x->props.mode) <token> <answer> { 
<token> XFRM_MODE_BEET: <answer> case 
switch <token> { <answer> (x->sel.family) 
case <token> <answer> AF_INET: 
return <token> skb); <answer> xfrm4_remove_beet_encap(x, 
case <token> <answer> AF_INET6: 
<token> xfrm6_remove_beet_encap(x, skb); <answer> return 
<token> XFRM_MODE_TUNNEL: <answer> case 
<token> (XFRM_MODE_SKB_CB(skb)->protocol) { <answer> switch 
case <token> <answer> IPPROTO_IPIP: 
<token> xfrm4_remove_tunnel_encap(x, skb); <answer> return 
<token> IPPROTO_IPV6: <answer> case 
return xfrm6_remove_tunnel_encap(x, <token> <answer> skb); 
<token> -EINVAL; <answer> return 
return <token> <answer> -EOPNOTSUPP; 
<token> int xfrm_prepare_input(struct xfrm_state *x, struct sk_buff *skb) <answer> static 
switch (x->props.family) <token> <answer> { 
<token> AF_INET: <answer> case 
case <token> <answer> AF_INET6: 
<token> -EAFNOSUPPORT; <answer> return 
<token> xfrm_inner_mode_encap_remove(x, skb); <answer> return 
static int xfrm4_transport_input(struct xfrm_state *x, <token> sk_buff *skb) <answer> struct 
<token> xfrm_offload *xo = xfrm_offload(skb); <answer> struct 
int ihl <token> skb->data - skb_transport_header(skb); <answer> = 
<token> (skb->transport_header != skb->network_header) { <answer> if 
<token> ihl); <answer> skb_network_header(skb), 
<token> (xo) <answer> if 
<token> = <answer> xo->orig_mac_len 
skb_mac_header_was_set(skb) ? <token> : 0; <answer> skb_mac_header_len(skb) 
skb->network_header = <token> <answer> skb->transport_header; 
ip_hdr(skb)->tot_len = <token> + ihl); <answer> htons(skb->len 
<token> 0; <answer> return 
static int xfrm6_transport_input(struct xfrm_state *x, struct sk_buff <token> <answer> *skb) 
<token> IS_ENABLED(CONFIG_IPV6) <answer> #if 
<token> xfrm_offload *xo = xfrm_offload(skb); <answer> struct 
int ihl = <token> - skb_transport_header(skb); <answer> skb->data 
if (skb->transport_header <token> skb->network_header) { <answer> != 
<token> ihl); <answer> skb_network_header(skb), 
<token> (xo) <answer> if 
<token> = <answer> xo->orig_mac_len 
skb_mac_header_was_set(skb) ? skb_mac_header_len(skb) <token> 0; <answer> : 
skb->network_header <token> skb->transport_header; <answer> = 
ipv6_hdr(skb)->payload_len <token> htons(skb->len + ihl - <answer> = 
sizeof(struct <token> <answer> ipv6hdr)); 
<token> 0; <answer> return 
return <token> <answer> -EAFNOSUPPORT; 
<token> int xfrm_inner_mode_input(struct xfrm_state *x, <answer> static 
<token> sk_buff *skb) <answer> struct 
switch (x->props.mode) <token> <answer> { 
case <token> <answer> XFRM_MODE_BEET: 
case <token> <answer> XFRM_MODE_TUNNEL: 
return xfrm_prepare_input(x, <token> <answer> skb); 
<token> XFRM_MODE_TRANSPORT: <answer> case 
if <token> == AF_INET) <answer> (x->props.family 
<token> xfrm4_transport_input(x, skb); <answer> return 
if (x->props.family == <token> <answer> AF_INET6) 
return xfrm6_transport_input(x, <token> <answer> skb); 
<token> XFRM_MODE_ROUTEOPTIMIZATION: <answer> case 
return <token> <answer> -EOPNOTSUPP; 
int xfrm_input(struct sk_buff *skb, int nexthdr, <token> spi, int encap_type) <answer> __be32 
const <token> xfrm_state_afinfo *afinfo; <answer> struct 
struct net *net = <token> <answer> dev_net(skb->dev); 
<token> err; <answer> int 
__be32 <token> <answer> seq; 
__be32 <token> <answer> seq_hi; 
struct xfrm_state *x <token> NULL; <answer> = 
xfrm_address_t <token> <answer> *daddr; 
u32 mark <token> skb->mark; <answer> = 
unsigned int family <token> AF_UNSPEC; <answer> = 
<token> decaps = 0; <answer> int 
int <token> = 0; <answer> async 
<token> xfrm_gro = false; <answer> bool 
bool crypto_done = <token> <answer> false; 
struct xfrm_offload <token> = xfrm_offload(skb); <answer> *xo 
<token> sec_path *sp; <answer> struct 
if (encap_type < <token> || (xo && xo->flags & XFRM_GRO)) { <answer> 0 
<token> = xfrm_input_state(skb); <answer> x 
if (unlikely(x->km.state != XFRM_STATE_VALID)) <token> <answer> { 
if (x->km.state <token> XFRM_STATE_ACQ) <answer> == 
XFRM_INC_STATS(net, <token> <answer> LINUX_MIB_XFRMACQUIREERROR); 
if (encap_type == <token> <answer> -1) 
goto <token> <answer> drop; 
family <token> x->props.family; <answer> = 
daddr = <token> <answer> &x->id.daddr; 
<token> = x->props.family; <answer> family 
err = xfrm_parse_spi(skb, nexthdr, <token> &seq); <answer> &spi, 
if (err <token> 0) { <answer> < 
<token> LINUX_MIB_XFRMINHDRERROR); <answer> XFRM_INC_STATS(net, 
<token> drop; <answer> goto 
<token> = false; <answer> crypto_done 
<token> while (!err); <answer> } 
err = xfrm_rcv_cb(skb, <token> x->type->proto, 0); <answer> family, 
<token> (err) <answer> if 
goto <token> <answer> drop; 
if <token> { <answer> (decaps) 
<token> = skb_sec_path(skb); <answer> sp 
if <token> <answer> (sp) 
<token> = 0; <answer> sp->olen 
<token> (skb_valid_dst(skb)) <answer> if 
gro_cells_receive(&gro_cells, <token> <answer> skb); 
return <token> <answer> 0; 
<token> else { <answer> } 
xo = <token> <answer> xfrm_offload(skb); 
<token> (xo) <answer> if 
xfrm_gro = xo->flags <token> XFRM_GRO; <answer> & 
err = <token> <answer> -EAFNOSUPPORT; 
afinfo = <token> <answer> xfrm_state_afinfo_get_rcu(x->props.family); 
<token> (likely(afinfo)) <answer> if 
err = afinfo->transport_finish(skb, xfrm_gro <token> async); <answer> || 
<token> (xfrm_gro) { <answer> if 
<token> = skb_sec_path(skb); <answer> sp 
if <token> <answer> (sp) 
<token> = 0; <answer> sp->olen 
if <token> <answer> (skb_valid_dst(skb)) 
<token> skb); <answer> gro_cells_receive(&gro_cells, 
return <token> <answer> err; 
return <token> <answer> err; 
xfrm_rcv_cb(skb, family, x && x->type ? <token> : nexthdr, -1); <answer> x->type->proto 
return <token> <answer> 0; 
int xfrm_input_resume(struct sk_buff <token> int nexthdr) <answer> *skb, 
return xfrm_input(skb, nexthdr, 0, <token> <answer> -1); 
static void xfrm_trans_reinject(struct work_struct <token> <answer> *work) 
<token> xfrm_trans_tasklet *trans = container_of(work, struct xfrm_trans_tasklet, work); <answer> struct 
struct sk_buff_head <token> <answer> queue; 
struct <token> *skb; <answer> sk_buff 
skb_queue_splice_init(&trans->queue, <token> <answer> &queue); 
<token> ((skb = __skb_dequeue(&queue))) <answer> while 
<token> skb); <answer> NULL, 
int xfrm_trans_queue_net(struct net *net, struct sk_buff <token> <answer> *skb, 
int (*finish)(struct net *, struct <token> *, <answer> sock 
<token> sk_buff *)) <answer> struct 
<token> xfrm_trans_tasklet *trans; <answer> struct 
trans = <token> <answer> this_cpu_ptr(&xfrm_trans_tasklet); 
if (skb_queue_len(&trans->queue) >= <token> <answer> READ_ONCE(net_hotdata.max_backlog)) 
<token> -ENOBUFS; <answer> return 
BUILD_BUG_ON(sizeof(struct <token> > sizeof(skb->cb)); <answer> xfrm_trans_cb) 
XFRM_TRANS_SKB_CB(skb)->finish <token> finish; <answer> = 
<token> = net; <answer> XFRM_TRANS_SKB_CB(skb)->net 
__skb_queue_tail(&trans->queue, <token> <answer> skb); 
<token> 0; <answer> return 
int xfrm_trans_queue(struct sk_buff <token> <answer> *skb, 
int <token> net *, struct sock *, <answer> (*finish)(struct 
struct <token> *)) <answer> sk_buff 
return <token> skb, finish); <answer> xfrm_trans_queue_net(dev_net(skb->dev), 
void <token> xfrm_input_init(void) <answer> __init 
<token> err; <answer> int 
<token> i; <answer> int 
err <token> gro_cells_init(&gro_cells, &xfrm_napi_dev); <answer> = 
if <token> <answer> (err) 
gro_cells.cells = <token> <answer> NULL; 
for_each_possible_cpu(i) <token> <answer> { 
<token> xfrm_trans_tasklet *trans; <answer> struct 
<token> = &per_cpu(xfrm_trans_tasklet, i); <answer> trans 
<token> xfrm_trans_reinject); <answer> INIT_WORK(&trans->work, 
#include <token> <answer> "qla_def.h" 
<token> "qla_gbl.h" <answer> #include 
#include <token> <answer> <linux/kthread.h> 
<token> <linux/vmalloc.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/bsg-lib.h> 
<token> void qla2xxx_free_fcport_work(struct work_struct *work) <answer> static 
struct fc_port *fcport <token> container_of(work, typeof(*fcport), <answer> = 
<token> = NULL; <answer> ha->fcp_prio_cfg 
<token> exit_fcp_prio_cfg; <answer> goto 
<token> = 0; <answer> ha->flags.fcp_prio_enabled 
if <token> & FCP_PRIO_ATTR_ENABLE) <answer> (ha->fcp_prio_cfg->attributes 
<token> = 1; <answer> ha->flags.fcp_prio_enabled 
<token> = DID_OK; <answer> bsg_reply->result 
ret = <token> <answer> -EINVAL; 
<token> (!ret) <answer> if 
bsg_job_done(bsg_job, <token> <answer> bsg_reply->result, 
return <token> <answer> ret; 
static <token> <answer> int 
<token> bsg_job *bsg_job) <answer> qla2x00_process_els(struct 
<token> fc_bsg_request *bsg_request = bsg_job->request; <answer> struct 
struct fc_rport <token> <answer> *rport; 
fc_port_t *fcport <token> NULL; <answer> = 
struct Scsi_Host <token> <answer> *host; 
<token> *vha; <answer> scsi_qla_host_t 
struct qla_hw_data <token> <answer> *ha; 
srb_t <token> <answer> *sp; 
<token> char *type; <answer> const 
int req_sg_cnt, <token> <answer> rsp_sg_cnt; 
int rval = (DID_ERROR <token> 16); <answer> << 
<token> els_cmd = 0; <answer> uint32_t 
int <token> = 0; <answer> qla_port_allocated 
if (bsg_request->msgcode == <token> { <answer> FC_BSG_RPT_ELS) 
rport = <token> <answer> fc_bsg_to_rport(bsg_job); 
<token> (!rport) { <answer> if 
rval <token> -ENOMEM; <answer> = 
goto <token> <answer> done; 
fcport = <token> **) rport->dd_data; <answer> *(fc_port_t 
host = <token> <answer> rport_to_shost(rport); 
vha <token> shost_priv(host); <answer> = 
<token> = vha->hw; <answer> ha 
type = <token> <answer> "FC_BSG_RPT_ELS"; 
} else <token> <answer> { 
host <token> fc_bsg_to_shost(bsg_job); <answer> = 
vha = <token> <answer> shost_priv(host); 
ha <token> vha->hw; <answer> = 
type <token> "FC_BSG_HST_ELS_NOLOGIN"; <answer> = 
els_cmd <token> bsg_request->rqst_data.h_els.command_code; <answer> = 
if (els_cmd <token> ELS_AUTH_ELS) <answer> == 
return qla_edif_process_els(vha, <token> <answer> bsg_job); 
if <token> { <answer> (!vha->flags.online) 
ql_log(ql_log_warn, <token> 0x7005, "Host not online.\n"); <answer> vha, 
rval = <token> <answer> -EIO; 
<token> done; <answer> goto 
if <token> != FCS_ONLINE) { <answer> (atomic_read(&fcport->state) 
<token> vha, 0x7003, <answer> ql_dbg(ql_dbg_user, 
"Port %06X is <token> online for ELS passthru.\n", <answer> not 
rval = <token> <answer> -EIO; 
<token> done; <answer> goto 
<token> else { <answer> } 
fcport = <token> GFP_KERNEL); <answer> qla2x00_alloc_fcport(vha, 
<token> (!fcport) { <answer> if 
rval <token> -ENOMEM; <answer> = 
goto <token> <answer> done; 
qla_port_allocated = <token> <answer> 1; 
fcport = qla2x00_alloc_fcport(vha, <token> <answer> GFP_KERNEL); 
<token> (!fcport) { <answer> if 
ql_log(ql_log_warn, vha, <token> <answer> 0x7014, 
"Failed to allocate <token> <answer> fcport.\n"); 
rval = <token> <answer> -ENOMEM; 
<token> done_unmap_sg; <answer> goto 
static <token> int <answer> inline 
<token> *vha, uint16_t *config, <answer> qla81xx_set_loopback_mode(scsi_qla_host_t 
uint16_t *new_config, <token> mode) <answer> uint16_t 
int <token> = 0; <answer> ret 
<token> rval = 0; <answer> int 
unsigned long rem_tmo = 0, <token> = 0; <answer> current_tmo 
struct qla_hw_data <token> = vha->hw; <answer> *ha 
<token> (!IS_QLA81XX(ha) && !IS_QLA8031(ha) && !IS_QLA8044(ha)) <answer> if 
goto <token> <answer> done_set_internal; 
<token> (mode == INTERNAL_LOOPBACK) <answer> if 
new_config[0] <token> config[0] | (ENABLE_INTERNAL_LOOPBACK << 1); <answer> = 
else <token> (mode == EXTERNAL_LOOPBACK) <answer> if 
new_config[0] = config[0] <token> (ENABLE_EXTERNAL_LOOPBACK << 1); <answer> | 
<token> vha, 0x70be, <answer> ql_dbg(ql_dbg_user, 
"new_config[0]=%02x\n", (new_config[0] <token> INTERNAL_LOOPBACK_MASK)); <answer> & 
memcpy(&new_config[1], <token> sizeof(uint16_t) * 3); <answer> &config[1], 
ha->notify_dcbx_comp = <token> <answer> 1; 
ret = <token> new_config); <answer> qla81xx_set_port_config(vha, 
if <token> != QLA_SUCCESS) { <answer> (ret 
<token> vha, 0x7021, <answer> ql_log(ql_log_warn, 
<token> port config failed.\n"); <answer> "set 
<token> = 0; <answer> ha->notify_dcbx_comp 
<token> = -EINVAL; <answer> rval 
goto <token> <answer> done_set_internal; 
<token> (ret) { <answer> if 
<token> &vha->dpc_flags); <answer> set_bit(ISP_ABORT_NEEDED, 
rval = <token> <answer> -EINVAL; 
} else <token> <answer> { 
if <token> { <answer> (ha->flags.idc_compl_status) 
<token> vha, 0x70c3, <answer> ql_dbg(ql_dbg_user, 
"Bad status <token> IDC Completion AEN\n"); <answer> in 
rval <token> -EINVAL; <answer> = 
ha->flags.idc_compl_status = <token> <answer> 0; 
<token> else <answer> } 
ql_dbg(ql_dbg_user, <token> 0x7023, <answer> vha, 
<token> completion received.\n"); <answer> "DCBX 
<token> = 0; <answer> ha->notify_dcbx_comp 
ha->idc_extend_tmo = <token> <answer> 0; 
return <token> <answer> rval; 
static <token> <answer> int 
qla2x00_process_loopback(struct <token> *bsg_job) <answer> bsg_job 
struct fc_bsg_request *bsg_request = <token> <answer> bsg_job->request; 
struct fc_bsg_reply *bsg_reply = <token> <answer> bsg_job->reply; 
struct Scsi_Host *host = <token> <answer> fc_bsg_to_shost(bsg_job); 
scsi_qla_host_t *vha <token> shost_priv(host); <answer> = 
struct qla_hw_data *ha = <token> <answer> vha->hw; 
<token> rval; <answer> int 
<token> command_sent; <answer> uint8_t 
<token> *type; <answer> char 
<token> msg_echo_lb elreq; <answer> struct 
<token> response[MAILBOX_REGISTER_COUNT]; <answer> uint16_t 
<token> config[4], new_config[4]; <answer> uint16_t 
uint8_t <token> <answer> *fw_sts_ptr; 
void *req_data = <token> <answer> NULL; 
dma_addr_t <token> <answer> req_data_dma; 
<token> req_data_len; <answer> uint32_t 
uint8_t <token> = NULL; <answer> *rsp_data 
dma_addr_t <token> <answer> rsp_data_dma; 
uint32_t <token> <answer> rsp_data_len; 
if (!vha->flags.online) <token> <answer> { 
ql_log(ql_log_warn, vha, 0x7019, "Host is not <token> <answer> online.\n"); 
<token> -EIO; <answer> return 
memset(&elreq, 0, <token> <answer> sizeof(elreq)); 
elreq.req_sg_cnt <token> dma_map_sg(&ha->pdev->dev, <answer> = 
bsg_job->request_payload.sg_list, <token> <answer> bsg_job->request_payload.sg_cnt, 
<token> (!elreq.req_sg_cnt) { <answer> if 
<token> vha, 0x701a, <answer> ql_log(ql_log_warn, 
<token> returned %d for request.\n", elreq.req_sg_cnt); <answer> "dma_map_sg 
return <token> <answer> -ENOMEM; 
elreq.rsp_sg_cnt = <token> <answer> dma_map_sg(&ha->pdev->dev, 
bsg_job->reply_payload.sg_list, <token> <answer> bsg_job->reply_payload.sg_cnt, 
if (!elreq.rsp_sg_cnt) <token> <answer> { 
<token> vha, 0x701b, <answer> ql_log(ql_log_warn, 
"dma_map_sg returned <token> for reply.\n", elreq.rsp_sg_cnt); <answer> %d 
rval = <token> <answer> -ENOMEM; 
<token> done_unmap_req_sg; <answer> goto 
if <token> != bsg_job->request_payload.sg_cnt) || <answer> ((elreq.req_sg_cnt 
(elreq.rsp_sg_cnt <token> bsg_job->reply_payload.sg_cnt)) { <answer> != 
ql_log(ql_log_warn, <token> 0x701c, <answer> vha, 
"dma mapping resulted in different sg counts, <token> <answer> " 
"request_sg_cnt: %x <token> %x " <answer> dma_request_sg_cnt: 
"reply_sg_cnt: %x <token> %x.\n", <answer> dma_reply_sg_cnt: 
bsg_job->request_payload.sg_cnt, <token> <answer> elreq.req_sg_cnt, 
bsg_job->reply_payload.sg_cnt, <token> <answer> elreq.rsp_sg_cnt); 
rval = <token> <answer> -EAGAIN; 
<token> done_unmap_sg; <answer> goto 
req_data_len = rsp_data_len <token> bsg_job->request_payload.payload_len; <answer> = 
req_data <token> dma_alloc_coherent(&ha->pdev->dev, req_data_len, <answer> = 
&req_data_dma, <token> <answer> GFP_KERNEL); 
if (!req_data) <token> <answer> { 
ql_log(ql_log_warn, vha, <token> <answer> 0x701d, 
<token> alloc failed for req_data.\n"); <answer> "dma 
rval = <token> <answer> -ENOMEM; 
<token> done_unmap_sg; <answer> goto 
rsp_data <token> dma_alloc_coherent(&ha->pdev->dev, rsp_data_len, <answer> = 
<token> GFP_KERNEL); <answer> &rsp_data_dma, 
if (!rsp_data) <token> <answer> { 
ql_log(ql_log_warn, vha, <token> <answer> 0x7004, 
"dma alloc failed for <token> <answer> rsp_data.\n"); 
<token> = -ENOMEM; <answer> rval 
goto <token> <answer> done_free_dma_req; 
<token> = qla81xx_reset_loopback_mode(vha, <answer> ret 
<token> 0, 1); <answer> new_config, 
if <token> { <answer> (ret) 
} <token> { <answer> else 
<token> = "FC_BSG_HST_VENDOR_LOOPBACK"; <answer> type 
ql_dbg(ql_dbg_user, vha, <token> <answer> 0x702b, 
"BSG request type: <token> type); <answer> %s.\n", 
<token> = INT_DEF_LB_LOOPBACK_CMD; <answer> command_sent 
rval = qla2x00_loopback_test(vha, &elreq, <token> <answer> response); 
<token> (rval) { <answer> if 
ql_log(ql_log_warn, <token> 0x702c, <answer> vha, 
"Vendor request %s <token> type); <answer> failed.\n", 
rval = <token> <answer> 0; 
bsg_reply->result = (DID_ERROR << <token> <answer> 16); 
bsg_reply->reply_payload_rcv_len = <token> <answer> 0; 
} <token> { <answer> else 
<token> vha, 0x702d, <answer> ql_dbg(ql_dbg_user, 
"Vendor request %s <token> type); <answer> completed.\n", 
bsg_reply->result = (DID_OK << <token> <answer> 16); 
bsg_job->reply_payload.sg_cnt, <token> <answer> rsp_data, 
bsg_job->reply_len <token> sizeof(struct fc_bsg_reply) + <answer> = 
<token> + sizeof(uint8_t); <answer> sizeof(response) 
<token> = bsg_job->reply + sizeof(struct fc_bsg_reply); <answer> fw_sts_ptr 
memcpy(bsg_job->reply + sizeof(struct fc_bsg_reply), <token> <answer> response, 
fw_sts_ptr <token> sizeof(response); <answer> += 
*fw_sts_ptr = <token> <answer> command_sent; 
dma_free_coherent(&ha->pdev->dev, <token> <answer> rsp_data_len, 
rsp_data, <token> <answer> rsp_data_dma); 
<token> req_data_len, <answer> dma_free_coherent(&ha->pdev->dev, 
req_data, <token> <answer> req_data_dma); 
<token> DMA_FROM_DEVICE); <answer> bsg_job->reply_payload.sg_cnt, 
<token> DMA_TO_DEVICE); <answer> bsg_job->request_payload.sg_cnt, 
<token> (!rval) <answer> if 
<token> bsg_reply->result, <answer> bsg_job_done(bsg_job, 
return <token> <answer> rval; 
static <token> <answer> int 
qla84xx_reset(struct <token> *bsg_job) <answer> bsg_job 
struct fc_bsg_request *bsg_request = <token> <answer> bsg_job->request; 
struct Scsi_Host <token> = fc_bsg_to_shost(bsg_job); <answer> *host 
struct fc_bsg_reply *bsg_reply <token> bsg_job->reply; <answer> = 
<token> *vha = shost_priv(host); <answer> scsi_qla_host_t 
struct <token> *ha = vha->hw; <answer> qla_hw_data 
int <token> = 0; <answer> rval 
uint32_t <token> <answer> flag; 
if <token> { <answer> (!IS_QLA84XX(ha)) 
ql_dbg(ql_dbg_user, <token> 0x702f, "Not 84xx, exiting.\n"); <answer> vha, 
return <token> <answer> -EINVAL; 
flag = <token> <answer> bsg_request->rqst_data.h_vendor.vendor_cmd[1]; 
rval = <token> flag == A84_ISSUE_RESET_DIAG_FW); <answer> qla84xx_reset_chip(vha, 
if <token> { <answer> (rval) 
<token> vha, 0x7030, <answer> ql_log(ql_log_warn, 
"Vendor request 84xx reset <token> <answer> failed.\n"); 
rval = (DID_ERROR << <token> <answer> 16); 
} else <token> <answer> { 
<token> vha, 0x7031, <answer> ql_dbg(ql_dbg_user, 
"Vendor request <token> reset completed.\n"); <answer> 84xx 
<token> = DID_OK; <answer> bsg_reply->result 
<token> bsg_reply->result, <answer> bsg_job_done(bsg_job, 
<token> rval; <answer> return 
static <token> <answer> int 
qla84xx_updatefw(struct <token> *bsg_job) <answer> bsg_job 
struct fc_bsg_request *bsg_request = <token> <answer> bsg_job->request; 
struct fc_bsg_reply *bsg_reply = <token> <answer> bsg_job->reply; 
struct Scsi_Host <token> = fc_bsg_to_shost(bsg_job); <answer> *host 
scsi_qla_host_t *vha = <token> <answer> shost_priv(host); 
<token> qla_hw_data *ha = vha->hw; <answer> struct 
struct verify_chip_entry_84xx *mn = <token> <answer> NULL; 
dma_addr_t mn_dma, <token> <answer> fw_dma; 
void *fw_buf = <token> <answer> NULL; 
int <token> = 0; <answer> rval 
<token> sg_cnt; <answer> uint32_t 
<token> data_len; <answer> uint32_t 
uint16_t <token> <answer> options; 
<token> flag; <answer> uint32_t 
<token> fw_ver; <answer> uint32_t 
if (!IS_QLA84XX(ha)) <token> <answer> { 
ql_dbg(ql_dbg_user, vha, <token> <answer> 0x7032, 
"Not 84xx, <token> <answer> exiting.\n"); 
return <token> <answer> -EINVAL; 
<token> = dma_map_sg(&ha->pdev->dev, bsg_job->request_payload.sg_list, <answer> sg_cnt 
bsg_job->request_payload.sg_cnt, <token> <answer> DMA_TO_DEVICE); 
if (!sg_cnt) <token> <answer> { 
ql_log(ql_log_warn, vha, <token> <answer> 0x7033, 
"dma_map_sg returned %d for request.\n", <token> <answer> sg_cnt); 
<token> -ENOMEM; <answer> return 
if (sg_cnt <token> bsg_job->request_payload.sg_cnt) { <answer> != 
ql_log(ql_log_warn, vha, <token> <answer> 0x7034, 
"DMA mapping resulted <token> different sg counts, " <answer> in 
<token> %x dma_request_sg_cnt: %x.\n", <answer> "request_sg_cnt: 
bsg_job->request_payload.sg_cnt, <token> <answer> sg_cnt); 
<token> = -EAGAIN; <answer> rval 
<token> done_unmap_sg; <answer> goto 
<token> = bsg_job->request_payload.payload_len; <answer> data_len 
<token> = dma_alloc_coherent(&ha->pdev->dev, data_len, <answer> fw_buf 
<token> GFP_KERNEL); <answer> &fw_dma, 
if (!fw_buf) <token> <answer> { 
<token> vha, 0x7035, <answer> ql_log(ql_log_warn, 
"DMA alloc failed for <token> <answer> fw_buf.\n"); 
rval <token> -ENOMEM; <answer> = 
goto <token> <answer> done_unmap_sg; 
<token> fw_buf, data_len); <answer> bsg_job->request_payload.sg_cnt, 
mn = dma_pool_zalloc(ha->s_dma_pool, GFP_KERNEL, <token> <answer> &mn_dma); 
if (!mn) <token> <answer> { 
ql_log(ql_log_warn, <token> 0x7036, <answer> vha, 
"DMA alloc failed for fw <token> <answer> buffer.\n"); 
rval <token> -ENOMEM; <answer> = 
goto <token> <answer> done_free_fw_buf; 
flag = <token> <answer> bsg_request->rqst_data.h_vendor.vendor_cmd[1]; 
fw_ver = get_unaligned_le32((uint32_t <token> + 2); <answer> *)fw_buf 
<token> = VERIFY_CHIP_IOCB_TYPE; <answer> mn->entry_type 
mn->entry_count <token> 1; <answer> = 
options = <token> | VCO_END_OF_DATA; <answer> VCO_FORCE_UPDATE 
if <token> == A84_ISSUE_UPDATE_DIAGFW_CMD) <answer> (flag 
<token> |= VCO_DIAG_FW; <answer> options 
<token> = cpu_to_le16(options); <answer> mn->options 
mn->fw_ver <token> cpu_to_le32(fw_ver); <answer> = 
mn->fw_size <token> cpu_to_le32(data_len); <answer> = 
<token> = cpu_to_le32(data_len); <answer> mn->fw_seq_size 
<token> &mn->dsd.address); <answer> put_unaligned_le64(fw_dma, 
mn->dsd.length <token> cpu_to_le32(data_len); <answer> = 
mn->data_seg_cnt = <token> <answer> cpu_to_le16(1); 
rval = qla2x00_issue_iocb_timeout(vha, mn, mn_dma, 0, <token> <answer> 120); 
<token> (rval) { <answer> if 
ql_log(ql_log_warn, vha, <token> <answer> 0x7037, 
<token> request 84xx updatefw failed.\n"); <answer> "Vendor 
rval = <token> << 16); <answer> (DID_ERROR 
<token> else { <answer> } 
ql_dbg(ql_dbg_user, <token> 0x7038, <answer> vha, 
"Vendor request 84xx updatefw <token> <answer> completed.\n"); 
<token> = sizeof(struct fc_bsg_reply); <answer> bsg_job->reply_len 
bsg_reply->result <token> DID_OK; <answer> = 
<token> mn, mn_dma); <answer> dma_pool_free(ha->s_dma_pool, 
dma_free_coherent(&ha->pdev->dev, data_len, fw_buf, <token> <answer> fw_dma); 
<token> bsg_job->request_payload.sg_list, <answer> dma_unmap_sg(&ha->pdev->dev, 
<token> DMA_TO_DEVICE); <answer> bsg_job->request_payload.sg_cnt, 
if <token> <answer> (!rval) 
<token> bsg_reply->result, <answer> bsg_job_done(bsg_job, 
<token> rval; <answer> return 
static <token> <answer> int 
qla84xx_mgmt_cmd(struct <token> *bsg_job) <answer> bsg_job 
struct <token> *bsg_request = bsg_job->request; <answer> fc_bsg_request 
<token> fc_bsg_reply *bsg_reply = bsg_job->reply; <answer> struct 
struct Scsi_Host <token> = fc_bsg_to_shost(bsg_job); <answer> *host 
scsi_qla_host_t *vha = <token> <answer> shost_priv(host); 
struct <token> *ha = vha->hw; <answer> qla_hw_data 
struct access_chip_84xx *mn <token> NULL; <answer> = 
dma_addr_t <token> mgmt_dma; <answer> mn_dma, 
void *mgmt_b <token> NULL; <answer> = 
int rval = <token> <answer> 0; 
struct <token> *ql84_mgmt; <answer> qla_bsg_a84_mgmt 
uint32_t <token> <answer> sg_cnt; 
uint32_t <token> = 0; <answer> data_len 
<token> dma_direction = DMA_NONE; <answer> uint32_t 
if (!IS_QLA84XX(ha)) <token> <answer> { 
ql_log(ql_log_warn, vha, <token> <answer> 0x703a, 
"Not <token> exiting.\n"); <answer> 84xx, 
return <token> <answer> -EINVAL; 
mn = <token> GFP_KERNEL, &mn_dma); <answer> dma_pool_zalloc(ha->s_dma_pool, 
if <token> { <answer> (!mn) 
ql_log(ql_log_warn, <token> 0x703c, <answer> vha, 
"DMA alloc failed <token> fw buffer.\n"); <answer> for 
return <token> <answer> -ENOMEM; 
<token> = ACCESS_CHIP_IOCB_TYPE; <answer> mn->entry_type 
<token> = 1; <answer> mn->entry_count 
<token> = (void *)bsg_request + sizeof(struct fc_bsg_request); <answer> ql84_mgmt 
switch <token> { <answer> (ql84_mgmt->mgmt.cmd) 
case <token> <answer> QLA84_MGMT_READ_MEM: 
case <token> <answer> QLA84_MGMT_GET_INFO: 
sg_cnt <token> dma_map_sg(&ha->pdev->dev, <answer> = 
<token> DMA_FROM_DEVICE); <answer> bsg_job->reply_payload.sg_cnt, 
if (!sg_cnt) <token> <answer> { 
ql_log(ql_log_warn, vha, <token> <answer> 0x703d, 
<token> returned %d for reply.\n", sg_cnt); <answer> "dma_map_sg 
rval = <token> <answer> -ENOMEM; 
goto <token> <answer> exit_mgmt; 
dma_direction = <token> <answer> DMA_FROM_DEVICE; 
if (sg_cnt != bsg_job->reply_payload.sg_cnt) <token> <answer> { 
ql_log(ql_log_warn, <token> 0x703e, <answer> vha, 
"DMA mapping <token> in different sg counts, " <answer> resulted 
"reply_sg_cnt: <token> dma_reply_sg_cnt: %x.\n", <answer> %x 
bsg_job->reply_payload.sg_cnt, <token> <answer> sg_cnt); 
rval = <token> <answer> -EAGAIN; 
<token> done_unmap_sg; <answer> goto 
data_len = <token> <answer> bsg_job->reply_payload.payload_len; 
<token> = dma_alloc_coherent(&ha->pdev->dev, data_len, <answer> mgmt_b 
<token> GFP_KERNEL); <answer> &mgmt_dma, 
if <token> { <answer> (!mgmt_b) 
<token> vha, 0x703f, <answer> ql_log(ql_log_warn, 
"DMA alloc <token> for mgmt_b.\n"); <answer> failed 
rval <token> -ENOMEM; <answer> = 
<token> done_unmap_sg; <answer> goto 
if (ql84_mgmt->mgmt.cmd == <token> { <answer> QLA84_MGMT_READ_MEM) 
<token> = cpu_to_le16(ACO_DUMP_MEMORY); <answer> mn->options 
mn->parameter1 <token> <answer> = 
} <token> if (ql84_mgmt->mgmt.cmd == QLA84_MGMT_GET_INFO) { <answer> else 
mn->options <token> cpu_to_le16(ACO_REQUEST_INFO); <answer> = 
<token> = <answer> mn->parameter1 
<token> = <answer> mn->parameter2 
<token> QLA84_MGMT_WRITE_MEM: <answer> case 
sg_cnt = <token> <answer> dma_map_sg(&ha->pdev->dev, 
bsg_job->request_payload.sg_cnt, <token> <answer> DMA_TO_DEVICE); 
if (!sg_cnt) <token> <answer> { 
<token> vha, 0x7040, <answer> ql_log(ql_log_warn, 
"dma_map_sg returned %d.\n", <token> <answer> sg_cnt); 
rval <token> -ENOMEM; <answer> = 
<token> exit_mgmt; <answer> goto 
dma_direction = <token> <answer> DMA_TO_DEVICE; 
if (sg_cnt != <token> { <answer> bsg_job->request_payload.sg_cnt) 
ql_log(ql_log_warn, vha, <token> <answer> 0x7041, 
"DMA mapping resulted in different <token> counts, " <answer> sg 
"request_sg_cnt: %x dma_request_sg_cnt: <token> <answer> %x.\n", 
bsg_job->request_payload.sg_cnt, <token> <answer> sg_cnt); 
rval <token> -EAGAIN; <answer> = 
<token> done_unmap_sg; <answer> goto 
<token> = bsg_job->request_payload.payload_len; <answer> data_len 
mgmt_b = <token> data_len, <answer> dma_alloc_coherent(&ha->pdev->dev, 
<token> GFP_KERNEL); <answer> &mgmt_dma, 
<token> (!mgmt_b) { <answer> if 
ql_log(ql_log_warn, vha, <token> <answer> 0x7042, 
"DMA alloc <token> for mgmt_b.\n"); <answer> failed 
rval <token> -ENOMEM; <answer> = 
goto <token> <answer> done_unmap_sg; 
bsg_job->request_payload.sg_cnt, <token> data_len); <answer> mgmt_b, 
<token> = cpu_to_le16(ACO_LOAD_MEMORY); <answer> mn->options 
mn->parameter1 <token> <answer> = 
<token> QLA84_MGMT_CHNG_CONFIG: <answer> case 
mn->options = <token> <answer> cpu_to_le16(ACO_CHANGE_CONFIG_PARAM); 
<token> = <answer> mn->parameter1 
mn->parameter2 <token> <answer> = 
<token> = <answer> mn->parameter3 
<token> = -EIO; <answer> rval 
<token> exit_mgmt; <answer> goto 
<token> (ql84_mgmt->mgmt.cmd != QLA84_MGMT_CHNG_CONFIG) { <answer> if 
<token> = cpu_to_le32(ql84_mgmt->mgmt.len); <answer> mn->total_byte_cnt 
<token> = cpu_to_le16(1); <answer> mn->dseg_count 
put_unaligned_le64(mgmt_dma, <token> <answer> &mn->dsd.address); 
<token> = cpu_to_le32(ql84_mgmt->mgmt.len); <answer> mn->dsd.length 
rval = qla2x00_issue_iocb(vha, <token> mn_dma, 0); <answer> mn, 
if <token> { <answer> (rval) 
<token> vha, 0x7043, <answer> ql_log(ql_log_warn, 
<token> request 84xx mgmt failed.\n"); <answer> "Vendor 
rval = <token> << 16); <answer> (DID_ERROR 
} <token> { <answer> else 
ql_dbg(ql_dbg_user, <token> 0x7044, <answer> vha, 
"Vendor request 84xx <token> completed.\n"); <answer> mgmt 
bsg_job->reply_len <token> sizeof(struct fc_bsg_reply); <answer> = 
bsg_reply->result <token> DID_OK; <answer> = 
if ((ql84_mgmt->mgmt.cmd == <token> || <answer> QLA84_MGMT_READ_MEM) 
(ql84_mgmt->mgmt.cmd <token> QLA84_MGMT_GET_INFO)) { <answer> == 
bsg_reply->reply_payload_rcv_len <token> <answer> = 
bsg_job->reply_payload.sg_cnt, <token> <answer> mgmt_b, 
if <token> <answer> (mgmt_b) 
dma_free_coherent(&ha->pdev->dev, <token> mgmt_b, mgmt_dma); <answer> data_len, 
<token> (dma_direction == DMA_TO_DEVICE) <answer> if 
dma_unmap_sg(&ha->pdev->dev, <token> <answer> bsg_job->request_payload.sg_list, 
bsg_job->request_payload.sg_cnt, <token> <answer> DMA_TO_DEVICE); 
else if (dma_direction == <token> <answer> DMA_FROM_DEVICE) 
<token> bsg_job->reply_payload.sg_list, <answer> dma_unmap_sg(&ha->pdev->dev, 
<token> DMA_FROM_DEVICE); <answer> bsg_job->reply_payload.sg_cnt, 
dma_pool_free(ha->s_dma_pool, mn, <token> <answer> mn_dma); 
<token> (!rval) <answer> if 
bsg_job_done(bsg_job, <token> <answer> bsg_reply->result, 
<token> rval; <answer> return 
static <token> <answer> int 
qla24xx_iidma(struct <token> *bsg_job) <answer> bsg_job 
<token> fc_bsg_request *bsg_request = bsg_job->request; <answer> struct 
struct fc_bsg_reply *bsg_reply <token> bsg_job->reply; <answer> = 
struct Scsi_Host *host <token> fc_bsg_to_shost(bsg_job); <answer> = 
<token> *vha = shost_priv(host); <answer> scsi_qla_host_t 
int rval = <token> <answer> 0; 
struct <token> *port_param = NULL; <answer> qla_port_param 
fc_port_t <token> = NULL; <answer> *fcport 
<token> found = 0; <answer> int 
<token> mb[MAILBOX_REGISTER_COUNT]; <answer> uint16_t 
<token> *rsp_ptr = NULL; <answer> uint8_t 
if (!IS_IIDMA_CAPABLE(vha->hw)) <token> <answer> { 
ql_log(ql_log_info, <token> 0x7046, "iiDMA not supported.\n"); <answer> vha, 
return <token> <answer> -EINVAL; 
port_param = (void *)bsg_request + sizeof(struct <token> <answer> fc_bsg_request); 
if (port_param->fc_scsi_addr.dest_type != EXT_DEF_TYPE_WWPN) <token> <answer> { 
<token> vha, 0x7048, <answer> ql_log(ql_log_warn, 
"Invalid <token> type.\n"); <answer> destination 
return <token> <answer> -EINVAL; 
list_for_each_entry(fcport, &vha->vp_fcports, list) <token> <answer> { 
if <token> != FCT_TARGET) <answer> (fcport->port_type 
if <token> <answer> (memcmp(port_param->fc_scsi_addr.dest_addr.wwpn, 
<token> sizeof(fcport->port_name))) <answer> fcport->port_name, 
found = <token> <answer> 1; 
if (!found) <token> <answer> { 
ql_log(ql_log_warn, vha, <token> <answer> 0x7049, 
"Failed to find <token> <answer> port.\n"); 
return <token> <answer> -EINVAL; 
<token> (atomic_read(&fcport->state) != FCS_ONLINE) { <answer> if 
ql_log(ql_log_warn, <token> 0x704a, <answer> vha, 
"Port is not <token> <answer> online.\n"); 
<token> -EINVAL; <answer> return 
if (fcport->flags <token> FCF_LOGIN_NEEDED) { <answer> & 
<token> vha, 0x704b, <answer> ql_log(ql_log_warn, 
"Remote port not logged in flags <token> 0x%x.\n", fcport->flags); <answer> = 
return <token> <answer> -EINVAL; 
if <token> <answer> (port_param->mode) 
<token> = qla2x00_set_idma_speed(vha, fcport->loop_id, <answer> rval 
<token> mb); <answer> port_param->speed, 
rval <token> qla2x00_get_idma_speed(vha, fcport->loop_id, <answer> = 
&port_param->speed, <token> <answer> mb); 
<token> (rval) { <answer> if 
ql_log(ql_log_warn, vha, <token> <answer> 0x704c, 
"iiDMA cmd failed for <token> -- " <answer> %8phN 
<token> %x %04x %04x.\n", fcport->port_name, <answer> "%04x 
rval, fcport->fp_speed, <token> mb[1]); <answer> mb[0], 
rval = (DID_ERROR << <token> <answer> 16); 
} else <token> <answer> { 
if <token> { <answer> (!port_param->mode) 
bsg_job->reply_len = sizeof(struct <token> + <answer> fc_bsg_reply) 
sizeof(struct <token> <answer> qla_port_param); 
rsp_ptr = ((uint8_t <token> + <answer> *)bsg_reply) 
<token> fc_bsg_reply); <answer> sizeof(struct 
memcpy(rsp_ptr, <token> <answer> port_param, 
sizeof(struct <token> <answer> qla_port_param)); 
<token> = DID_OK; <answer> bsg_reply->result 
<token> bsg_reply->result, <answer> bsg_job_done(bsg_job, 
return <token> <answer> rval; 
static <token> <answer> int 
<token> bsg_job *bsg_job, scsi_qla_host_t *vha, <answer> qla2x00_optrom_setup(struct 
<token> is_update) <answer> uint8_t 
struct fc_bsg_request *bsg_request <token> bsg_job->request; <answer> = 
uint32_t start = <token> <answer> 0; 
<token> valid = 0; <answer> int 
<token> qla_hw_data *ha = vha->hw; <answer> struct 
if <token> <answer> (unlikely(pci_channel_offline(ha->pdev))) 
<token> -EINVAL; <answer> return 
start = <token> <answer> bsg_request->rqst_data.h_vendor.vendor_cmd[1]; 
<token> (start > ha->optrom_size) { <answer> if 
ql_log(ql_log_warn, <token> 0x7055, <answer> vha, 
"start <token> > optrom_size %d.\n", start, ha->optrom_size); <answer> %d 
return <token> <answer> -EINVAL; 
if (ha->optrom_state != <token> { <answer> QLA_SWAITING) 
<token> vha, 0x7056, <answer> ql_log(ql_log_info, 
"optrom_state <token> ha->optrom_state); <answer> %d.\n", 
<token> -EBUSY; <answer> return 
ha->optrom_region_start <token> start; <answer> = 
ql_dbg(ql_dbg_user, vha, 0x7057, "is_update=%d.\n", <token> <answer> is_update); 
if <token> { <answer> (is_update) 
if (ha->optrom_size == <token> && start == 0) <answer> OPTROM_SIZE_2300 
valid = <token> <answer> 1; 
<token> if (start == (ha->flt_region_boot * 4) || <answer> else 
start <token> (ha->flt_region_fw * 4)) <answer> == 
valid = <token> <answer> 1; 
else if (IS_QLA24XX_TYPE(ha) <token> IS_QLA25XX(ha) || <answer> || 
IS_CNA_CAPABLE(ha) <token> IS_QLA2031(ha) || IS_QLA27XX(ha) || <answer> || 
<token> = 1; <answer> valid 
if <token> { <answer> (!valid) 
ql_log(ql_log_warn, vha, <token> <answer> 0x7058, 
<token> start region 0x%x/0x%x.\n", start, <answer> "Invalid 
<token> -EINVAL; <answer> return 
<token> = start + <answer> ha->optrom_region_size 
bsg_job->request_payload.payload_len > <token> ? <answer> ha->optrom_size 
<token> - start : <answer> ha->optrom_size 
ha->optrom_state = <token> <answer> QLA_SWRITING; 
} <token> { <answer> else 
ha->optrom_region_size = start <token> <answer> + 
bsg_job->reply_payload.payload_len > <token> ? <answer> ha->optrom_size 
ha->optrom_size - <token> : <answer> start 
ha->optrom_state <token> QLA_SREADING; <answer> = 
ha->optrom_buffer <token> vzalloc(ha->optrom_region_size); <answer> = 
if (!ha->optrom_buffer) <token> <answer> { 
ql_log(ql_log_warn, <token> 0x7059, <answer> vha, 
<token> Unable to allocate memory for optrom retrieval " <answer> "Read: 
<token> ha->optrom_region_size); <answer> "(%x)\n", 
<token> = QLA_SWAITING; <answer> ha->optrom_state 
<token> -ENOMEM; <answer> return 
return <token> <answer> 0; 
static <token> <answer> int 
<token> bsg_job *bsg_job) <answer> qla2x00_read_optrom(struct 
struct fc_bsg_reply <token> = bsg_job->reply; <answer> *bsg_reply 
struct Scsi_Host *host <token> fc_bsg_to_shost(bsg_job); <answer> = 
scsi_qla_host_t *vha <token> shost_priv(host); <answer> = 
struct qla_hw_data *ha <token> vha->hw; <answer> = 
<token> rval = 0; <answer> int 
<token> (ha->flags.nic_core_reset_hdlr_active) <answer> if 
<token> -EBUSY; <answer> return 
<token> = qla2x00_optrom_setup(bsg_job, vha, 0); <answer> rval 
<token> (rval) { <answer> if 
<token> rval; <answer> return 
<token> ha->optrom_buffer, <answer> ha->isp_ops->read_optrom(vha, 
ha->optrom_region_start, <token> <answer> ha->optrom_region_size); 
<token> ha->optrom_buffer, <answer> bsg_job->reply_payload.sg_cnt, 
bsg_reply->reply_payload_rcv_len <token> ha->optrom_region_size; <answer> = 
bsg_reply->result = <token> <answer> DID_OK; 
ha->optrom_buffer = <token> <answer> NULL; 
ha->optrom_state = <token> <answer> QLA_SWAITING; 
<token> bsg_reply->result, <answer> bsg_job_done(bsg_job, 
return <token> <answer> rval; 
static <token> <answer> int 
qla2x00_update_optrom(struct bsg_job <token> <answer> *bsg_job) 
struct fc_bsg_reply <token> = bsg_job->reply; <answer> *bsg_reply 
struct Scsi_Host *host <token> fc_bsg_to_shost(bsg_job); <answer> = 
scsi_qla_host_t *vha = <token> <answer> shost_priv(host); 
struct qla_hw_data *ha = <token> <answer> vha->hw; 
<token> rval = 0; <answer> int 
rval <token> qla2x00_optrom_setup(bsg_job, vha, 1); <answer> = 
if <token> { <answer> (rval) 
<token> rval; <answer> return 
<token> = rval; <answer> bsg_reply->reply_data.vendor_reply.vendor_rsp[0] 
bsg_job->reply_len <token> sizeof(struct fc_bsg_reply); <answer> = 
bsg_reply->reply_payload_rcv_len <token> 0; <answer> = 
<token> = (DID_OK) << 16; <answer> bsg_reply->result 
<token> bsg_reply->result, <answer> bsg_job_done(bsg_job, 
<token> = qla2x00_alloc_fcport(vha, GFP_KERNEL); <answer> fcport 
if <token> { <answer> (!fcport) 
ql_log(ql_log_warn, <token> 0x70ca, <answer> vha, 
"Failed <token> allocate fcport.\n"); <answer> to 
<token> = -ENOMEM; <answer> rval 
<token> done_unmap_rsp_sg; <answer> goto 
<token> "hbm_kern.h" <answer> #include 
int <token> __sk_buff *skb) <answer> _hbm_out_cg(struct 
long long delta = <token> delta_send; <answer> 0, 
<token> long long curtime, sendtime; <answer> unsigned 
struct hbm_queue_stats *qsp <token> NULL; <answer> = 
unsigned int queue_index <token> 0; <answer> = 
bool congestion_flag <token> false; <answer> = 
bool ecn_ce_flag <token> false; <answer> = 
<token> hbm_pkt_info pkti = {}; <answer> struct 
struct <token> *qdp; <answer> hbm_vqueue 
bool drop_flag = <token> <answer> false; 
bool cwr_flag = <token> <answer> false; 
<token> len = skb->len; <answer> int 
int <token> = ALLOW_PKT; <answer> rv 
qsp = bpf_map_lookup_elem(&queue_stats, <token> <answer> &queue_index); 
if (qsp <token> NULL && !qsp->loopback && (skb->ifindex == 1)) <answer> != 
return <token> <answer> ALLOW_PKT; 
hbm_get_pkt_info(skb, <token> <answer> &pkti); 
<token> = bpf_get_local_storage(&queue_state, 0); <answer> qdp 
if <token> <answer> (!qdp) 
<token> ALLOW_PKT; <answer> return 
if (qdp->lasttime <token> 0) <answer> == 
<token> 1024); <answer> hbm_init_edt_vqueue(qdp, 
<token> = bpf_ktime_get_ns(); <answer> curtime 
delta = qdp->lasttime <token> curtime; <answer> - 
if <token> < -BURST_SIZE_NS) { <answer> (delta 
qdp->lasttime = <token> - BURST_SIZE_NS; <answer> curtime 
delta = <token> <answer> -BURST_SIZE_NS; 
sendtime <token> qdp->lasttime; <answer> = 
delta_send = BYTES_TO_NS(len, <token> <answer> qdp->rate); 
<token> delta_send); <answer> __sync_add_and_fetch(&(qdp->lasttime), 
<token> = sendtime; <answer> skb->tstamp 
if (qsp <token> NULL && (qsp->rate * 128) != qdp->rate) <answer> != 
qdp->rate = qsp->rate * <token> <answer> 128; 
<token> (delta > DROP_THRESH_NS || (delta > LARGE_PKT_DROP_THRESH_NS && <answer> if 
len > <token> { <answer> LARGE_PKT_THRESH)) 
drop_flag <token> true; <answer> = 
if (pkti.is_tcp && <token> == 0) <answer> pkti.ecn 
cwr_flag = <token> <answer> true; 
} else if (delta <token> MARK_THRESH_NS) { <answer> > 
<token> (pkti.is_tcp) <answer> if 
congestion_flag <token> true; <answer> = 
drop_flag = <token> <answer> true; 
<token> (congestion_flag) { <answer> if 
if (bpf_skb_ecn_set_ce(skb)) <token> <answer> { 
<token> = true; <answer> ecn_ce_flag 
<token> else { <answer> } 
<token> (pkti.is_tcp) { <answer> if 
unsigned int rand = <token> <answer> bpf_get_prandom_u32(); 
if <token> >= MARK_THRESH_NS + <answer> (delta 
(rand <token> MARK_REGION_SIZE_NS)) { <answer> % 
cwr_flag <token> true; <answer> = 
} else <token> (len > LARGE_PKT_THRESH) { <answer> if 
drop_flag <token> true; <answer> = 
<token> = false; <answer> congestion_flag 
if (pkti.is_tcp && <token> && pkti.packets_out <= 1) { <answer> drop_flag 
<token> = false; <answer> drop_flag 
cwr_flag = <token> <answer> true; 
<token> = false; <answer> congestion_flag 
if (qsp != NULL <token> qsp->no_cn) <answer> && 
cwr_flag = <token> <answer> false; 
hbm_update_stats(qsp, <token> curtime, congestion_flag, drop_flag, <answer> len, 
cwr_flag, ecn_ce_flag, <token> (int) delta); <answer> &pkti, 
<token> (drop_flag) { <answer> if 
__sync_add_and_fetch(&(qdp->lasttime), <token> <answer> -delta_send); 
rv = <token> <answer> DROP_PKT; 
<token> (cwr_flag) <answer> if 
rv <token> CWR; <answer> |= 
<token> rv; <answer> return 
char _license[] SEC("license") <token> "GPL"; <answer> = 
#include <token> <answer> <linux/delay.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/input.h> <answer> #include 
#include <token> <answer> <linux/serio.h> 
#define DRIVER_DESC "Serial <token> driver" <answer> mouse 
<token> Pavlik <vojtech@ucw.cz>"); <answer> MODULE_AUTHOR("Vojtech 
static const char <token> = { "None", "Mouse Systems Mouse", "Sun Mouse", "Microsoft Mouse", <answer> *sermouse_protocols[] 
"Logitech M+ <token> "Microsoft MZ Mouse", "Logitech MZ+ Mouse", <answer> Mouse", 
"Logitech MZ++ <token> <answer> Mouse"}; 
<token> sermouse { <answer> struct 
struct input_dev <token> <answer> *dev; 
<token> char buf[8]; <answer> signed 
unsigned char <token> <answer> count; 
unsigned char <token> <answer> type; 
unsigned long <token> <answer> last; 
char <token> <answer> phys[32]; 
static void sermouse_process_msc(struct sermouse *sermouse, signed <token> data) <answer> char 
<token> input_dev *dev = sermouse->dev; <answer> struct 
signed char <token> = sermouse->buf; <answer> *buf 
switch <token> { <answer> (sermouse->count) 
case <token> <answer> 0: 
if ((data & 0xf8) <token> 0x80) <answer> != 
input_report_key(dev, BTN_LEFT, !(data & <token> <answer> 4)); 
input_report_key(dev, <token> !(data & 1)); <answer> BTN_RIGHT, 
input_report_key(dev, BTN_MIDDLE, !(data <token> 2)); <answer> & 
<token> 1: <answer> case 
case <token> <answer> 3: 
input_report_rel(dev, REL_X, <token> / 2); <answer> data 
input_report_rel(dev, REL_Y, <token> <answer> -buf[1]); 
buf[0] = data - data / <token> <answer> 2; 
case <token> <answer> 2: 
case <token> <answer> 4: 
input_report_rel(dev, REL_X, <token> <answer> buf[0]); 
input_report_rel(dev, REL_Y, buf[1] - <token> <answer> data); 
buf[1] = <token> / 2; <answer> data 
<token> (++sermouse->count == 5) <answer> if 
sermouse->count <token> 0; <answer> = 
static <token> sermouse_process_ms(struct sermouse *sermouse, signed char data) <answer> void 
struct input_dev *dev = <token> <answer> sermouse->dev; 
signed char <token> = sermouse->buf; <answer> *buf 
if <token> & 0x40) <answer> (data 
sermouse->count <token> 0; <answer> = 
else if (sermouse->count == <token> <answer> 0) 
<token> (sermouse->count) { <answer> switch 
<token> 0: <answer> case 
buf[1] = <token> <answer> data; 
<token> BTN_LEFT, (data >> 5) & 1); <answer> input_report_key(dev, 
input_report_key(dev, BTN_RIGHT, (data >> <token> & 1); <answer> 4) 
<token> 1: <answer> case 
buf[2] = <token> <answer> data; 
data = <token> char) (((buf[1] << 6) & 0xc0) | (data & 0x3f)); <answer> (signed 
input_report_rel(dev, <token> data / 2); <answer> REL_X, 
input_report_rel(dev, <token> buf[4]); <answer> REL_Y, 
buf[3] <token> data - data / 2; <answer> = 
<token> 2: <answer> case 
static irqreturn_t sermouse_interrupt(struct <token> *serio, <answer> serio 
<token> char data, unsigned int flags) <answer> unsigned 
struct <token> *sermouse = serio_get_drvdata(serio); <answer> sermouse 
if <token> sermouse->last + HZ/10)) <answer> (time_after(jiffies, 
sermouse->count = <token> <answer> 0; 
sermouse->last <token> jiffies; <answer> = 
if (sermouse->type > <token> <answer> SERIO_SUN) 
sermouse_process_ms(sermouse, <token> <answer> data); 
sermouse_process_msc(sermouse, <token> <answer> data); 
<token> IRQ_HANDLED; <answer> return 
static void <token> serio *serio) <answer> sermouse_disconnect(struct 
struct <token> *sermouse = serio_get_drvdata(serio); <answer> sermouse 
serio_set_drvdata(serio, <token> <answer> NULL); 
static <token> sermouse_connect(struct serio *serio, struct serio_driver *drv) <answer> int 
struct <token> *sermouse; <answer> sermouse 
struct <token> *input_dev; <answer> input_dev 
unsigned char c = <token> <answer> serio->id.extra; 
int err <token> -ENOMEM; <answer> = 
sermouse = kzalloc(sizeof(struct <token> GFP_KERNEL); <answer> sermouse), 
input_dev = <token> <answer> input_allocate_device(); 
<token> (!sermouse || !input_dev) <answer> if 
<token> fail1; <answer> goto 
sermouse->dev <token> input_dev; <answer> = 
snprintf(sermouse->phys, sizeof(sermouse->phys), <token> serio->phys); <answer> "%s/input0", 
<token> = serio->id.proto; <answer> sermouse->type 
<token> = sermouse_protocols[sermouse->type]; <answer> input_dev->name 
input_dev->phys = <token> <answer> sermouse->phys; 
input_dev->id.bustype = <token> <answer> BUS_RS232; 
input_dev->id.vendor = <token> <answer> sermouse->type; 
<token> = c; <answer> input_dev->id.product 
input_dev->id.version <token> 0x0100; <answer> = 
input_dev->dev.parent <token> &serio->dev; <answer> = 
input_dev->evbit[0] = <token> | BIT_MASK(EV_REL); <answer> BIT_MASK(EV_KEY) 
input_dev->keybit[BIT_WORD(BTN_MOUSE)] = <token> | <answer> BIT_MASK(BTN_LEFT) 
input_dev->relbit[0] <token> BIT_MASK(REL_X) | BIT_MASK(REL_Y); <answer> = 
<token> (c & 0x01) set_bit(BTN_MIDDLE, input_dev->keybit); <answer> if 
if (c & 0x02) set_bit(BTN_SIDE, <token> <answer> input_dev->keybit); 
if (c & 0x04) <token> input_dev->keybit); <answer> set_bit(BTN_EXTRA, 
if (c <token> 0x10) set_bit(REL_WHEEL, input_dev->relbit); <answer> & 
<token> (c & 0x20) set_bit(REL_HWHEEL, input_dev->relbit); <answer> if 
<token> sermouse); <answer> serio_set_drvdata(serio, 
<token> = serio_open(serio, drv); <answer> err 
<token> (err) <answer> if 
goto <token> <answer> fail2; 
err = <token> <answer> input_register_device(sermouse->dev); 
if <token> <answer> (err) 
goto <token> <answer> fail3; 
<token> 0; <answer> return 
fail3: <token> <answer> serio_close(serio); 
fail2: serio_set_drvdata(serio, <token> <answer> NULL); 
<token> input_free_device(input_dev); <answer> fail1: 
return <token> <answer> err; 
static <token> serio_device_id sermouse_serio_ids[] = { <answer> struct 
.type <token> SERIO_RS232, <answer> = 
.proto <token> SERIO_MSC, <answer> = 
.id = <token> <answer> SERIO_ANY, 
.extra <token> SERIO_ANY, <answer> = 
<token> = SERIO_RS232, <answer> .type 
.proto = <token> <answer> SERIO_SUN, 
.id = <token> <answer> SERIO_ANY, 
.extra = <token> <answer> SERIO_ANY, 
.type = <token> <answer> SERIO_RS232, 
<token> = SERIO_MS, <answer> .proto 
.id <token> SERIO_ANY, <answer> = 
<token> = SERIO_ANY, <answer> .extra 
.type = <token> <answer> SERIO_RS232, 
.proto = <token> <answer> SERIO_MP, 
.id <token> SERIO_ANY, <answer> = 
<token> = SERIO_ANY, <answer> .extra 
<token> = SERIO_RS232, <answer> .type 
.proto = <token> <answer> SERIO_MZ, 
<token> = SERIO_ANY, <answer> .id 
.extra = <token> <answer> SERIO_ANY, 
<token> = SERIO_RS232, <answer> .type 
.proto = <token> <answer> SERIO_MZP, 
.id <token> SERIO_ANY, <answer> = 
.extra = <token> <answer> SERIO_ANY, 
.type = <token> <answer> SERIO_RS232, 
.proto <token> SERIO_MZPP, <answer> = 
<token> = SERIO_ANY, <answer> .id 
.extra = <token> <answer> SERIO_ANY, 
{ <token> } <answer> 0 
MODULE_DEVICE_TABLE(serio, <token> <answer> sermouse_serio_ids); 
static struct serio_driver sermouse_drv = <token> <answer> { 
.driver = <token> <answer> { 
.name = <token> <answer> "sermouse", 
.description = <token> <answer> DRIVER_DESC, 
<token> = sermouse_serio_ids, <answer> .id_table 
<token> = sermouse_interrupt, <answer> .interrupt 
<token> = sermouse_connect, <answer> .connect 
<token> = sermouse_disconnect, <answer> .disconnect 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/pci.h> 
#include <token> <answer> <linux/blkdev.h> 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/device.h> 
<token> <scsi/scsi_host.h> <answer> #include 
<token> <linux/libata.h> <answer> #include 
#include <token> <answer> "sis.h" 
#define <token> "sata_sis" <answer> DRV_NAME 
<token> DRV_VERSION "1.0" <answer> #define 
enum <token> <answer> { 
<token> = 0, <answer> sis_180 
SIS_SCR_PCI_BAR = <token> <answer> 5, 
if ((!(pi.flags & <token> && <answer> SIS_FLAG_CFGSCR)) 
<token> SIS_SCR_PCI_BAR) == 0) || <answer> ((pci_resource_start(pdev, 
(pci_resource_len(pdev, SIS_SCR_PCI_BAR) <token> 128))) { <answer> < 
genctl <token> ~GENCTL_IOMAPPED_SCR; <answer> &= 
pci_write_config_dword(pdev, SIS_GENCTL, <token> <answer> genctl); 
pi.flags |= <token> <answer> SIS_FLAG_CFGSCR; 
<token> SIS_PMR, &pmr); <answer> pci_read_config_byte(pdev, 
<token> (ent->device) { <answer> switch 
case <token> <answer> 0x0180: 
case <token> <answer> 0x0181: 
#include <token> <answer> <linux/bitfield.h> 
#include <token> <answer> <linux/clk.h> 
<token> <linux/completion.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/of_platform.h> <answer> #include 
#include <token> <answer> <linux/pm_runtime.h> 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> <linux/reset.h> 
#include <token> <answer> <sound/dmaengine_pcm.h> 
<token> <sound/pcm_params.h> <answer> #include 
#define SPDIFRX_CSR_BUF_LENGTH (SPDIFRX_CS_BYTES_NB * 4 * <token> <answer> 2) 
<token> stm32_spdifrx_data { <answer> struct 
<token> platform_device *pdev; <answer> struct 
void <token> *base; <answer> __iomem 
<token> regmap *regmap; <answer> struct 
<token> struct regmap_config *regmap_conf; <answer> const 
struct <token> cs_completion; <answer> completion 
struct clk <token> <answer> *kclk; 
<token> snd_dmaengine_dai_dma_data dma_params; <answer> struct 
struct <token> *substream; <answer> snd_pcm_substream 
<token> snd_dma_buffer *dmab; <answer> struct 
struct <token> *ctrl_chan; <answer> dma_chan 
struct dma_async_tx_descriptor <token> <answer> *desc; 
struct <token> slave_config; <answer> dma_slave_config 
dma_addr_t <token> <answer> phys_addr; 
dev_dbg(&spdifrx->pdev->dev, <token> synchronization\n"); <answer> "start 
cr = <token> | SPDIFRX_CR_PMSK | SPDIFRX_CR_VMSK | <answer> SPDIFRX_CR_WFA 
SPDIFRX_CR_CUMSK <token> SPDIFRX_CR_PTMSK | SPDIFRX_CR_RXSTEO; <answer> | 
cr_mask = <token> <answer> cr; 
cr <token> SPDIFRX_CR_NBTRSET(SPDIFRX_NBTR_63); <answer> |= 
cr_mask <token> SPDIFRX_CR_NBTR_MASK; <answer> |= 
cr <token> SPDIFRX_CR_SPDIFENSET(SPDIFRX_SPDIFEN_SYNC); <answer> |= 
cr_mask |= <token> <answer> SPDIFRX_CR_SPDIFEN_MASK; 
<token> = regmap_update_bits(spdifrx->regmap, STM32_SPDIFRX_CR, <answer> ret 
<token> cr); <answer> cr_mask, 
if (ret <token> 0) <answer> < 
"Failed to <token> synchronization\n"); <answer> start 
spin_unlock_irqrestore(&spdifrx->lock, <token> <answer> flags); 
<token> ret; <answer> return 
static <token> stm32_spdifrx_stop(struct stm32_spdifrx_data *spdifrx) <answer> void 
int <token> cr_mask, reg; <answer> cr, 
<token> long flags; <answer> unsigned 
spin_lock_irqsave(&spdifrx->lock, <token> <answer> flags); 
if (--spdifrx->refcount) <token> <answer> { 
<token> flags); <answer> spin_unlock_irqrestore(&spdifrx->lock, 
cr = <token> <answer> SPDIFRX_CR_SPDIFENSET(SPDIFRX_SPDIFEN_DISABLE); 
cr_mask = <token> | SPDIFRX_CR_RXDMAEN; <answer> SPDIFRX_CR_SPDIFEN_MASK 
regmap_update_bits(spdifrx->regmap, <token> cr_mask, cr); <answer> STM32_SPDIFRX_CR, 
<token> STM32_SPDIFRX_IMR, <answer> regmap_update_bits(spdifrx->regmap, 
SPDIFRX_XIMR_MASK, <token> <answer> 0); 
<token> STM32_SPDIFRX_IFCR, <answer> regmap_update_bits(spdifrx->regmap, 
SPDIFRX_XIFCR_MASK, <token> <answer> SPDIFRX_XIFCR_MASK); 
spdifrx->dma_params.addr_width <token> DMA_SLAVE_BUSWIDTH_4_BYTES; <answer> = 
<token> NULL, &spdifrx->dma_params); <answer> snd_soc_dai_init_dma_data(cpu_dai, 
<token> regmap_update_bits(spdifrx->regmap, STM32_SPDIFRX_CR, <answer> return 
static int stm32_spdifrx_trigger(struct snd_pcm_substream *substream, int <token> <answer> cmd, 
struct snd_soc_dai <token> <answer> *cpu_dai) 
struct stm32_spdifrx_data *spdifrx <token> snd_soc_dai_get_drvdata(cpu_dai); <answer> = 
int ret <token> 0; <answer> = 
<token> (cmd) { <answer> switch 
case <token> <answer> SNDRV_PCM_TRIGGER_START: 
<token> SNDRV_PCM_TRIGGER_RESUME: <answer> case 
case <token> <answer> SNDRV_PCM_TRIGGER_PAUSE_RELEASE: 
<token> STM32_SPDIFRX_IMR, <answer> regmap_update_bits(spdifrx->regmap, 
SPDIFRX_IMR_OVRIE, <token> <answer> SPDIFRX_IMR_OVRIE); 
regmap_update_bits(spdifrx->regmap, <token> <answer> STM32_SPDIFRX_CR, 
SPDIFRX_CR_RXDMAEN, <token> <answer> SPDIFRX_CR_RXDMAEN); 
ret <token> stm32_spdifrx_start_sync(spdifrx); <answer> = 
<token> SNDRV_PCM_TRIGGER_SUSPEND: <answer> case 
<token> SNDRV_PCM_TRIGGER_PAUSE_PUSH: <answer> case 
<token> SNDRV_PCM_TRIGGER_STOP: <answer> case 
return <token> <answer> -EINVAL; 
return <token> <answer> ret; 
static <token> stm32_spdifrx_shutdown(struct snd_pcm_substream *substream, <answer> void 
struct <token> *cpu_dai) <answer> snd_soc_dai 
<token> stm32_spdifrx_data *spdifrx = snd_soc_dai_get_drvdata(cpu_dai); <answer> struct 
unsigned <token> flags; <answer> long 
<token> flags); <answer> spin_lock_irqsave(&spdifrx->irq_lock, 
<token> = NULL; <answer> spdifrx->substream 
spin_unlock_irqrestore(&spdifrx->irq_lock, <token> <answer> flags); 
static const struct snd_soc_dai_ops stm32_spdifrx_pcm_dai_ops = <token> <answer> { 
<token> = stm32_spdifrx_dai_probe, <answer> .probe 
.startup = <token> <answer> stm32_spdifrx_startup, 
.hw_params <token> stm32_spdifrx_hw_params, <answer> = 
<token> = stm32_spdifrx_trigger, <answer> .trigger 
<token> = stm32_spdifrx_shutdown, <answer> .shutdown 
static struct <token> stm32_spdifrx_dai[] = { <answer> snd_soc_dai_driver 
.capture <token> { <answer> = 
<token> = "CPU-Capture", <answer> .stream_name 
.channels_min <token> 1, <answer> = 
<token> = 2, <answer> .channels_max 
.rates <token> SNDRV_PCM_RATE_8000_192000, <answer> = 
.formats = <token> | <answer> SNDRV_PCM_FMTBIT_S32_LE 
.ops <token> &stm32_spdifrx_pcm_dai_ops, <answer> = 
static const struct snd_pcm_hardware stm32_spdifrx_pcm_hw = <token> <answer> { 
.info = <token> | SNDRV_PCM_INFO_MMAP, <answer> SNDRV_PCM_INFO_INTERLEAVED 
.buffer_bytes_max = 8 <token> PAGE_SIZE, <answer> * 
<token> = 1024, <answer> .period_bytes_min 
.period_bytes_max = 4 * <token> <answer> PAGE_SIZE, 
.periods_min = <token> <answer> 2, 
.periods_max = <token> <answer> 8, 
static const struct snd_soc_component_driver stm32_spdifrx_component <token> { <answer> = 
<token> = "stm32-spdifrx", <answer> .name 
<token> = 1, <answer> .legacy_dai_naming 
static const struct <token> stm32_spdifrx_pcm_config = { <answer> snd_dmaengine_pcm_config 
.pcm_hardware <token> &stm32_spdifrx_pcm_hw, <answer> = 
<token> = snd_dmaengine_pcm_prepare_slave_config, <answer> .prepare_slave_config 
static <token> struct of_device_id stm32_spdifrx_ids[] = { <answer> const 
<token> = "st,stm32h7-spdifrx", <answer> .compatible 
.data = <token> <answer> &stm32_h7_spdifrx_regmap_conf 
static int <token> platform_device *pdev, <answer> stm32_spdifrx_parse_of(struct 
struct <token> *spdifrx) <answer> stm32_spdifrx_data 
struct <token> *np = pdev->dev.of_node; <answer> device_node 
<token> resource *res; <answer> struct 
if <token> <answer> (!np) 
<token> -ENODEV; <answer> return 
spdifrx->regmap_conf <token> device_get_match_data(&pdev->dev); <answer> = 
if <token> <answer> (!spdifrx->regmap_conf) 
return <token> <answer> -EINVAL; 
spdifrx->base = devm_platform_get_and_ioremap_resource(pdev, <token> &res); <answer> 0, 
<token> (IS_ERR(spdifrx->base)) <answer> if 
<token> PTR_ERR(spdifrx->base); <answer> return 
<token> = res->start; <answer> spdifrx->phys_addr 
spdifrx->kclk = devm_clk_get(&pdev->dev, <token> <answer> "kclk"); 
<token> (IS_ERR(spdifrx->kclk)) <answer> if 
<token> dev_err_probe(&pdev->dev, PTR_ERR(spdifrx->kclk), <answer> return 
"Could not get <token> <answer> kclk\n"); 
spdifrx->irq = platform_get_irq(pdev, <token> <answer> 0); 
<token> (spdifrx->irq < 0) <answer> if 
<token> spdifrx->irq; <answer> return 
<token> 0; <answer> return 
static <token> stm32_spdifrx_remove(struct platform_device *pdev) <answer> void 
<token> stm32_spdifrx_data *spdifrx = platform_get_drvdata(pdev); <answer> struct 
if <token> <answer> (spdifrx->ctrl_chan) 
<token> (spdifrx->dmab) <answer> if 
static int stm32_spdifrx_probe(struct platform_device <token> <answer> *pdev) 
struct <token> *spdifrx; <answer> stm32_spdifrx_data 
struct reset_control <token> <answer> *rst; 
<token> struct snd_dmaengine_pcm_config *pcm_config = NULL; <answer> const 
u32 <token> idr; <answer> ver, 
<token> ret; <answer> int 
spdifrx = <token> sizeof(*spdifrx), GFP_KERNEL); <answer> devm_kzalloc(&pdev->dev, 
<token> (!spdifrx) <answer> if 
return <token> <answer> -ENOMEM; 
spdifrx->pdev = <token> <answer> pdev; 
platform_set_drvdata(pdev, <token> <answer> spdifrx); 
ret = <token> spdifrx); <answer> stm32_spdifrx_parse_of(pdev, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
spdifrx->regmap = devm_regmap_init_mmio_clk(&pdev->dev, <token> <answer> "kclk", 
<token> (IS_ERR(spdifrx->regmap)) <answer> if 
return <token> PTR_ERR(spdifrx->regmap), <answer> dev_err_probe(&pdev->dev, 
"Regmap <token> error\n"); <answer> init 
<token> = devm_request_irq(&pdev->dev, spdifrx->irq, stm32_spdifrx_isr, 0, <answer> ret 
dev_name(&pdev->dev), <token> <answer> spdifrx); 
if (ret) <token> <answer> { 
<token> "IRQ request returned %d\n", ret); <answer> dev_err(&pdev->dev, 
<token> ret; <answer> return 
rst = <token> NULL); <answer> devm_reset_control_get_optional_exclusive(&pdev->dev, 
<token> (IS_ERR(rst)) <answer> if 
<token> dev_err_probe(&pdev->dev, PTR_ERR(rst), <answer> return 
"Reset controller <token> <answer> error\n"); 
pcm_config <token> &stm32_spdifrx_pcm_config; <answer> = 
<token> = snd_dmaengine_pcm_register(&pdev->dev, pcm_config, 0); <answer> ret 
if <token> <answer> (ret) 
<token> dev_err_probe(&pdev->dev, ret, "PCM DMA register error\n"); <answer> return 
ret = <token> <answer> snd_soc_register_component(&pdev->dev, 
if <token> { <answer> (ret) 
return <token> <answer> ret; 
ret = <token> spdifrx); <answer> stm32_spdifrx_dma_ctrl_register(&pdev->dev, 
<token> (ret) <answer> if 
<token> error; <answer> goto 
<token> = regmap_read(spdifrx->regmap, STM32_SPDIFRX_IDR, &idr); <answer> ret 
if <token> <answer> (ret) 
<token> error; <answer> goto 
if <token> == SPDIFRX_IPIDR_NUMBER) { <answer> (idr 
ret = regmap_read(spdifrx->regmap, STM32_SPDIFRX_VERR, <token> <answer> &ver); 
<token> (ret) <answer> if 
<token> error; <answer> goto 
dev_dbg(&pdev->dev, <token> version: %lu.%lu registered\n", <answer> "SPDIFRX 
<token> ver), <answer> FIELD_GET(SPDIFRX_VERR_MAJ_MASK, 
FIELD_GET(SPDIFRX_VERR_MIN_MASK, <token> <answer> ver)); 
<token> ret; <answer> return 
return <token> <answer> ret; 
<token> stm32_spdifrx_ids); <answer> MODULE_DEVICE_TABLE(of, 
#ifdef <token> <answer> CONFIG_PM_SLEEP 
static int stm32_spdifrx_suspend(struct <token> *dev) <answer> device 
struct stm32_spdifrx_data *spdifrx = <token> <answer> dev_get_drvdata(dev); 
<token> true); <answer> regcache_cache_only(spdifrx->regmap, 
<token> 0; <answer> return 
<token> int stm32_spdifrx_resume(struct device *dev) <answer> static 
struct stm32_spdifrx_data *spdifrx <token> dev_get_drvdata(dev); <answer> = 
<token> false); <answer> regcache_cache_only(spdifrx->regmap, 
<token> regcache_sync(spdifrx->regmap); <answer> return 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/spi/spi.h> 
<token> <linux/clk.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/delay.h> 
#define DRV_NAME <token> <answer> "jcore_spi" 
#define CTRL_REG <token> <answer> 0x0 
#define DATA_REG <token> <answer> 0x4 
#define <token> 0x02 <answer> JCORE_SPI_CTRL_XMIT 
<token> JCORE_SPI_STAT_BUSY 0x02 <answer> #define 
#define JCORE_SPI_CTRL_LOOP <token> <answer> 0x08 
#define <token> 0x15 <answer> JCORE_SPI_CTRL_CS_BITS 
#define JCORE_SPI_WAIT_RDY_MAX_LOOP <token> <answer> 2000000 
struct jcore_spi <token> <answer> { 
<token> spi_controller *host; <answer> struct 
void __iomem <token> <answer> *base; 
unsigned int <token> <answer> cs_reg; 
unsigned int <token> <answer> speed_reg; 
<token> int speed_hz; <answer> unsigned 
<token> int clock_freq; <answer> unsigned 
static int jcore_spi_wait(void <token> *ctrl_reg) <answer> __iomem 
unsigned timeout <token> JCORE_SPI_WAIT_RDY_MAX_LOOP; <answer> = 
do <token> <answer> { 
if (!(readl(ctrl_reg) <token> JCORE_SPI_STAT_BUSY)) <answer> & 
return <token> <answer> 0; 
} while <token> <answer> (--timeout); 
return <token> <answer> -EBUSY; 
static void <token> jcore_spi *hw) <answer> jcore_spi_program(struct 
void __iomem *ctrl_reg = hw->base <token> CTRL_REG; <answer> + 
<token> (jcore_spi_wait(ctrl_reg)) <answer> if 
"timeout waiting <token> program ctrl reg.\n"); <answer> to 
writel(hw->cs_reg | hw->speed_reg, <token> <answer> ctrl_reg); 
static void <token> spi_device *spi, bool value) <answer> jcore_spi_chipsel(struct 
struct <token> *hw = spi_controller_get_devdata(spi->controller); <answer> jcore_spi 
u32 csbit = 1U << (2 * spi_get_chipselect(spi, <token> <answer> 0)); 
dev_dbg(hw->host->dev.parent, "chipselect %d\n", <token> 0)); <answer> spi_get_chipselect(spi, 
if <token> <answer> (value) 
<token> |= csbit; <answer> hw->cs_reg 
hw->cs_reg &= <token> <answer> ~csbit; 
static void jcore_spi_baudrate(struct jcore_spi *hw, int <token> <answer> speed) 
if <token> == hw->speed_hz) <answer> (speed 
<token> = speed; <answer> hw->speed_hz 
<token> (speed >= hw->clock_freq / 2) <answer> if 
hw->speed_reg = <token> <answer> 0; 
hw->speed_reg = ((hw->clock_freq <token> 2 / speed) - 1) << 27; <answer> / 
dev_dbg(hw->host->dev.parent, <token> reg=0x%x\n", <answer> "speed=%d 
speed, <token> <answer> hw->speed_reg); 
static int jcore_spi_txrx(struct spi_controller *host, struct <token> *spi, <answer> spi_device 
struct <token> *t) <answer> spi_transfer 
struct jcore_spi <token> = spi_controller_get_devdata(host); <answer> *hw 
void __iomem <token> = hw->base + CTRL_REG; <answer> *ctrl_reg 
<token> __iomem *data_reg = hw->base + DATA_REG; <answer> void 
u32 <token> <answer> xmit; 
clock_freq <token> 50000000; <answer> = 
clk = <token> "ref_clk"); <answer> devm_clk_get(&pdev->dev, 
<token> (!IS_ERR(clk)) { <answer> if 
if <token> == 0) { <answer> (clk_prepare_enable(clk) 
clock_freq = <token> <answer> clk_get_rate(clk); 
} <token> <answer> else 
<token> "could not enable ref_clk\n"); <answer> dev_warn(&pdev->dev, 
hw->clock_freq = <token> <answer> clock_freq; 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/time.h> <answer> #include 
#include <token> <answer> <linux/timer.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/rtc.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/ratelimit.h> 
<token> <asm/rtas.h> <answer> #include 
<token> <asm/time.h> <answer> #include 
void <token> rtc_time *rtc_tm) <answer> rtas_get_rtc_time(struct 
int <token> <answer> ret[8]; 
int <token> <answer> error; 
<token> int wait_time; <answer> unsigned 
<token> max_wait_tb; <answer> u64 
<token> = get_tb() + tb_ticks_per_usec * 1000 * MAX_RTC_WAIT; <answer> max_wait_tb 
do <token> <answer> { 
error = <token> 0, 8, ret); <answer> rtas_call(rtas_function_token(RTAS_FN_GET_TIME_OF_DAY), 
wait_time <token> rtas_busy_delay_time(error); <answer> = 
if <token> { <answer> (wait_time) 
if <token> { <answer> (in_interrupt()) 
memset(rtc_tm, 0, <token> rtc_time)); <answer> sizeof(struct 
"error: <token> clock " <answer> reading 
<token> delay interrupt\n"); <answer> "would 
#include <token> <answer> <drm/drm_auth.h> 
<token> <drm/drm_drv.h> <answer> #include 
#include <token> <answer> "amdgpu.h" 
<token> "amdgpu_sched.h" <answer> #include 
<token> "amdgpu_ras.h" <answer> #include 
<token> <linux/nospec.h> <answer> #include 
<token> to_amdgpu_ctx_entity(e) \ <answer> #define 
<token> struct amdgpu_ctx_entity, entity) <answer> container_of((e), 
<token> unsigned int amdgpu_ctx_num_entities[AMDGPU_HW_IP_NUM] = { <answer> const 
[AMDGPU_HW_IP_GFX] = <token> <answer> 1, 
[AMDGPU_HW_IP_COMPUTE] <token> 4, <answer> = 
<token> = 2, <answer> [AMDGPU_HW_IP_DMA] 
<token> = 1, <answer> [AMDGPU_HW_IP_UVD] 
[AMDGPU_HW_IP_VCE] <token> 1, <answer> = 
<token> = 1, <answer> [AMDGPU_HW_IP_UVD_ENC] 
<token> = 1, <answer> [AMDGPU_HW_IP_VCN_DEC] 
<token> = 1, <answer> [AMDGPU_HW_IP_VCN_ENC] 
[AMDGPU_HW_IP_VCN_JPEG] <token> 1, <answer> = 
<token> = 1, <answer> [AMDGPU_HW_IP_VPE] 
bool <token> ctx_prio) <answer> amdgpu_ctx_priority_is_valid(int32_t 
switch <token> { <answer> (ctx_prio) 
<token> AMDGPU_CTX_PRIORITY_VERY_LOW: <answer> case 
<token> AMDGPU_CTX_PRIORITY_LOW: <answer> case 
<token> AMDGPU_CTX_PRIORITY_NORMAL: <answer> case 
case <token> <answer> AMDGPU_CTX_PRIORITY_HIGH: 
<token> AMDGPU_CTX_PRIORITY_VERY_HIGH: <answer> case 
<token> true; <answer> return 
<token> AMDGPU_CTX_PRIORITY_UNSET: <answer> case 
return <token> <answer> false; 
static <token> drm_sched_priority <answer> enum 
amdgpu_ctx_to_drm_sched_prio(int32_t <token> <answer> ctx_prio) 
switch (ctx_prio) <token> <answer> { 
<token> AMDGPU_CTX_PRIORITY_UNSET: <answer> case 
pr_warn_once("AMD-->DRM context priority <token> UNSET-->NORMAL"); <answer> value 
return <token> <answer> DRM_SCHED_PRIORITY_NORMAL; 
<token> AMDGPU_CTX_PRIORITY_VERY_LOW: <answer> case 
<token> DRM_SCHED_PRIORITY_LOW; <answer> return 
<token> AMDGPU_CTX_PRIORITY_LOW: <answer> case 
return <token> <answer> DRM_SCHED_PRIORITY_LOW; 
case <token> <answer> AMDGPU_CTX_PRIORITY_NORMAL: 
<token> DRM_SCHED_PRIORITY_NORMAL; <answer> return 
case <token> <answer> AMDGPU_CTX_PRIORITY_HIGH: 
<token> DRM_SCHED_PRIORITY_HIGH; <answer> return 
<token> AMDGPU_CTX_PRIORITY_VERY_HIGH: <answer> case 
return <token> <answer> DRM_SCHED_PRIORITY_HIGH; 
WARN(1, "Invalid context <token> %d\n", ctx_prio); <answer> priority 
return <token> <answer> DRM_SCHED_PRIORITY_NORMAL; 
static <token> amdgpu_ctx_priority_permit(struct drm_file *filp, <answer> int 
int32_t <token> <answer> priority) 
<token> ce_count, ue_count; <answer> int 
<token> = atomic_read(&con->ras_ce_count); <answer> ce_count 
ue_count = <token> <answer> atomic_read(&con->ras_ue_count); 
if (ce_count != ctx->ras_counter_ce) <token> <answer> { 
<token> = ce_count; <answer> ctx->ras_counter_ce 
out->state.flags <token> AMDGPU_CTX_QUERY2_FLAGS_RAS_CE; <answer> |= 
if <token> != ctx->ras_counter_ue) { <answer> (ue_count 
ctx->ras_counter_ue = <token> <answer> ue_count; 
out->state.flags <token> AMDGPU_CTX_QUERY2_FLAGS_RAS_UE; <answer> |= 
return <token> <answer> 0; 
static <token> amdgpu_ctx_stable_pstate(struct amdgpu_device *adev, <answer> int 
struct <token> *fpriv, uint32_t id, <answer> amdgpu_fpriv 
bool set, u32 <token> <answer> *stable_pstate) 
struct <token> *ctx; <answer> amdgpu_ctx 
struct <token> *mgr; <answer> amdgpu_ctx_mgr 
int <token> <answer> r; 
if <token> <answer> (!fpriv) 
return <token> <answer> -EINVAL; 
<token> = &fpriv->ctx_mgr; <answer> mgr 
ctx = <token> id); <answer> idr_find(&mgr->ctx_handles, 
if (!ctx) <token> <answer> { 
<token> -EINVAL; <answer> return 
<token> (set) <answer> if 
<token> = amdgpu_ctx_set_stable_pstate(ctx, *stable_pstate); <answer> r 
r = <token> stable_pstate); <answer> amdgpu_ctx_get_stable_pstate(ctx, 
<token> r; <answer> return 
<token> amdgpu_ctx_ioctl(struct drm_device *dev, void *data, <answer> int 
<token> drm_file *filp) <answer> struct 
int <token> <answer> r; 
<token> id, stable_pstate; <answer> uint32_t 
<token> priority; <answer> int32_t 
union drm_amdgpu_ctx *args = <token> <answer> data; 
struct amdgpu_device *adev <token> drm_to_adev(dev); <answer> = 
struct amdgpu_fpriv *fpriv <token> filp->driver_priv; <answer> = 
<token> = args->in.ctx_id; <answer> id 
priority = <token> <answer> args->in.priority; 
<token> (!amdgpu_ctx_priority_is_valid(priority)) <answer> if 
priority <token> AMDGPU_CTX_PRIORITY_NORMAL; <answer> = 
<token> (args->in.op) { <answer> switch 
<token> AMDGPU_CTX_OP_ALLOC_CTX: <answer> case 
r = amdgpu_ctx_alloc(adev, fpriv, <token> priority, &id); <answer> filp, 
args->out.alloc.ctx_id = <token> <answer> id; 
<token> AMDGPU_CTX_OP_FREE_CTX: <answer> case 
r = <token> id); <answer> amdgpu_ctx_free(fpriv, 
<token> AMDGPU_CTX_OP_QUERY_STATE: <answer> case 
<token> = amdgpu_ctx_query(adev, fpriv, id, &args->out); <answer> r 
case <token> <answer> AMDGPU_CTX_OP_QUERY_STATE2: 
r <token> amdgpu_ctx_query2(adev, fpriv, id, &args->out); <answer> = 
case <token> <answer> AMDGPU_CTX_OP_GET_STABLE_PSTATE: 
<token> (args->in.flags) <answer> if 
return <token> <answer> -EINVAL; 
r = amdgpu_ctx_stable_pstate(adev, fpriv, id, false, <token> <answer> &stable_pstate); 
<token> (!r) <answer> if 
args->out.pstate.flags <token> stable_pstate; <answer> = 
case <token> <answer> AMDGPU_CTX_OP_SET_STABLE_PSTATE: 
if (args->in.flags <token> ~AMDGPU_CTX_STABLE_PSTATE_FLAGS_MASK) <answer> & 
return <token> <answer> -EINVAL; 
stable_pstate <token> args->in.flags & AMDGPU_CTX_STABLE_PSTATE_FLAGS_MASK; <answer> = 
<token> (stable_pstate > AMDGPU_CTX_STABLE_PSTATE_PEAK) <answer> if 
<token> -EINVAL; <answer> return 
r = amdgpu_ctx_stable_pstate(adev, <token> id, true, &stable_pstate); <answer> fpriv, 
return <token> <answer> -EINVAL; 
<token> r; <answer> return 
struct amdgpu_ctx *amdgpu_ctx_get(struct amdgpu_fpriv *fpriv, <token> id) <answer> uint32_t 
struct <token> *ctx; <answer> amdgpu_ctx 
struct amdgpu_ctx_mgr <token> <answer> *mgr; 
<token> (!fpriv) <answer> if 
return <token> <answer> NULL; 
mgr <token> &fpriv->ctx_mgr; <answer> = 
ctx = idr_find(&mgr->ctx_handles, <token> <answer> id); 
if <token> <answer> (ctx) 
return <token> <answer> ctx; 
int <token> amdgpu_ctx *ctx) <answer> amdgpu_ctx_put(struct 
if (ctx == <token> <answer> NULL) 
<token> -EINVAL; <answer> return 
<token> amdgpu_ctx_do_release); <answer> kref_put(&ctx->refcount, 
<token> 0; <answer> return 
<token> amdgpu_ctx_add_fence(struct amdgpu_ctx *ctx, <answer> uint64_t 
struct <token> *entity, <answer> drm_sched_entity 
struct dma_fence <token> <answer> *fence) 
struct amdgpu_ctx_entity <token> = to_amdgpu_ctx_entity(entity); <answer> *centity 
uint64_t seq <token> centity->sequence; <answer> = 
struct dma_fence *other = <token> <answer> NULL; 
<token> idx = 0; <answer> unsigned 
idx = seq <token> (amdgpu_sched_jobs - 1); <answer> & 
other = <token> <answer> centity->fences[idx]; 
WARN_ON(other <token> !dma_fence_is_signaled(other)); <answer> && 
<token> = fence; <answer> centity->fences[idx] 
<token> seq; <answer> return 
<token> dma_fence *amdgpu_ctx_get_fence(struct amdgpu_ctx *ctx, <answer> struct 
struct <token> *entity, <answer> drm_sched_entity 
<token> seq) <answer> uint64_t 
struct amdgpu_ctx_entity *centity = <token> <answer> to_amdgpu_ctx_entity(entity); 
<token> dma_fence *fence; <answer> struct 
if (seq == <token> <answer> ~0ull) 
seq = centity->sequence <token> 1; <answer> - 
if <token> >= centity->sequence) { <answer> (seq 
return <token> <answer> ERR_PTR(-EINVAL); 
if <token> + amdgpu_sched_jobs < centity->sequence) { <answer> (seq 
<token> NULL; <answer> return 
fence = dma_fence_get(centity->fences[seq & (amdgpu_sched_jobs - <token> <answer> 1)]); 
<token> fence; <answer> return 
<token> void amdgpu_ctx_set_entity_priority(struct amdgpu_ctx *ctx, <answer> static 
<token> amdgpu_ctx_entity *aentity, <answer> struct 
int <token> <answer> hw_ip, 
int32_t <token> <answer> priority) 
struct amdgpu_device <token> = ctx->mgr->adev; <answer> *adev 
unsigned int <token> <answer> hw_prio; 
struct drm_gpu_scheduler <token> = NULL; <answer> **scheds 
<token> num_scheds; <answer> unsigned 
for (hw_ip = 0; hw_ip <token> AMDGPU_HW_IP_NUM; ++hw_ip) { <answer> < 
<token> ns = atomic64_read(&mgr->time_spend[hw_ip]); <answer> uint64_t 
usage[hw_ip] <token> ns_to_ktime(ns); <answer> = 
idr_for_each_entry(&mgr->ctx_handles, ctx, <token> { <answer> id) 
for (hw_ip = 0; <token> < AMDGPU_HW_IP_NUM; ++hw_ip) { <answer> hw_ip 
for <token> = 0; i < amdgpu_ctx_num_entities[hw_ip]; ++i) { <answer> (i 
<token> amdgpu_ctx_entity *centity; <answer> struct 
ktime_t <token> <answer> spend; 
centity = <token> <answer> ctx->entities[hw_ip][i]; 
<token> (!centity) <answer> if 
spend = <token> centity); <answer> amdgpu_ctx_entity_time(ctx, 
usage[hw_ip] = ktime_add(usage[hw_ip], <token> <answer> spend); 
#include <token> <answer> <linux/bitfield.h> 
#include <token> <answer> <linux/bitops.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/leds.h> 
<token> <linux/led-class-multicolor.h> <answer> #include 
<token> <linux/linear_range.h> <answer> #include 
#include <token> <answer> <linux/mod_devicetable.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/mutex.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/property.h> 
<token> <linux/regmap.h> <answer> #include 
<token> <linux/util_macros.h> <answer> #include 
<token> <asm/unaligned.h> <answer> #include 
<token> { <answer> enum 
<token> = 0, <answer> MT6370_LED_ISNK1 
enum <token> { <answer> mt6370_led_mode 
MT6370_LED_PWM_MODE <token> 0, <answer> = 
<token> mt6370_led_field { <answer> enum 
F_RGB_EN = <token> <answer> 0, 
enum <token> { <answer> mt6370_led_ranges 
<token> = 0, <answer> R_LED123_CURR 
<token> mt6370_pattern { <answer> enum 
P_LED_TR1 <token> 0, <answer> = 
#define <token> 0x100 <answer> MT6370_REG_DEV_INFO 
#define MT6370_REG_RGB1_DIM <token> <answer> 0x182 
#define <token> 0x183 <answer> MT6370_REG_RGB2_DIM 
#define MT6370_REG_RGB3_DIM <token> <answer> 0x184 
#define <token> 0x185 <answer> MT6370_REG_RGB_EN 
#define <token> 0x186 <answer> MT6370_REG_RGB1_ISNK 
#define <token> 0x187 <answer> MT6370_REG_RGB2_ISNK 
#define MT6370_REG_RGB3_ISNK <token> <answer> 0x188 
#define MT6370_REG_RGB1_TR <token> <answer> 0x189 
#define MT6370_REG_RGB_CHRIND_DIM <token> <answer> 0x192 
<token> MT6370_REG_RGB_CHRIND_CTRL 0x193 <answer> #define 
<token> MT6370_REG_RGB_CHRIND_TR 0x194 <answer> #define 
#define MT6372_REG_RGB_EN <token> <answer> 0x182 
<token> MT6372_REG_RGB1_ISNK 0x183 <answer> #define 
<token> MT6372_REG_RGB2_ISNK 0x184 <answer> #define 
<token> MT6372_REG_RGB3_ISNK 0x185 <answer> #define 
#define MT6372_REG_RGB4_ISNK <token> <answer> 0x186 
#define MT6372_REG_RGB1_DIM <token> <answer> 0x187 
#define MT6372_REG_RGB2_DIM <token> <answer> 0x188 
#define MT6372_REG_RGB3_DIM <token> <answer> 0x189 
<token> MT6372_REG_RGB4_DIM 0x18A <answer> #define 
#define MT6372_REG_RGB12_FREQ <token> <answer> 0x18B 
<token> MT6372_REG_RGB34_FREQ 0x18C <answer> #define 
#define MT6372_REG_RGB1_TR <token> <answer> 0x18D 
#define <token> GENMASK(7, 4) <answer> MT6370_VENDOR_ID_MASK 
#define MT6372_VENDOR_ID <token> <answer> 0x9 
#define MT6372C_VENDOR_ID <token> <answer> 0xb 
#define <token> BIT(MT6370_LED_ISNK4 - id) <answer> MT6370_CHEN_BIT(id) 
#define MT6370_VIRTUAL_MULTICOLOR <token> <answer> 5 
#define <token> 3 <answer> MC_CHANNEL_NUM 
<token> MT6370_PWM_DUTY (BIT(5) - 1) <answer> #define 
#define MT6372_PWM_DUTY <token> - 1) <answer> (BIT(8) 
struct <token> { <answer> mt6370_led 
<token> { <answer> union 
struct led_classdev <token> <answer> isink; 
struct <token> mc; <answer> led_classdev_mc 
struct mt6370_priv <token> <answer> *priv; 
<token> led_default_state default_state; <answer> enum 
<token> index; <answer> u32 
struct mt6370_pdata <token> <answer> { 
<token> unsigned int *tfreq; <answer> const 
unsigned <token> tfreq_len; <answer> int 
<token> reg_rgb1_tr; <answer> u16 
<token> reg_rgb_chrind_tr; <answer> s16 
u8 <token> <answer> pwm_duty; 
struct mt6370_priv <token> <answer> { 
for (i = 0; i < P_MAX_PATTERNS; <token> { <answer> i++) 
curr = <token> + i; <answer> pattern 
sel_range = i == P_LED_TOFF ? R_LED_TOFF <token> R_LED_TRFON; <answer> : 
linear_range_get_selector_within(priv->ranges + sel_range, <token> &sel); <answer> curr->delta_t, 
if (i % 2) <token> <answer> { 
val |= <token> <answer> sel; 
<token> else { <answer> } 
<token> <<= 8; <answer> val 
val |= <token> << 4; <answer> sel 
put_unaligned_be24(val, <token> <answer> pattern_val); 
<token> 0; <answer> return 
static int mt6370_set_led_mode(struct mt6370_priv <token> unsigned int led_no, <answer> *priv, 
<token> mt6370_led_mode mode) <answer> enum 
<token> mt6370_led_field sel_field; <answer> enum 
<token> (led_no) { <answer> switch 
case <token> <answer> MT6370_LED_ISNK1: 
sel_field <token> F_LED1_MODE; <answer> = 
case <token> <answer> MT6370_LED_ISNK2: 
<token> = F_LED2_MODE; <answer> sel_field 
<token> MT6370_LED_ISNK3: <answer> case 
<token> = F_LED3_MODE; <answer> sel_field 
sel_field = <token> <answer> F_LED4_MODE; 
<token> regmap_field_write(priv->fields[sel_field], mode); <answer> return 
static int mt6370_mc_brightness_set(struct <token> *lcdev, enum led_brightness level) <answer> led_classdev 
<token> led_classdev_mc *mccdev = lcdev_to_mccdev(lcdev); <answer> struct 
<token> mt6370_led *led = container_of(mccdev, struct mt6370_led, mc); <answer> struct 
struct <token> *priv = led->priv; <answer> mt6370_priv 
struct <token> *subled; <answer> mc_subled 
<token> int enable, disable; <answer> unsigned 
int <token> ret; <answer> i, 
<token> level); <answer> led_mc_calc_color_components(mccdev, 
<token> = regmap_field_read(priv->fields[F_RGB_EN], &enable); <answer> ret 
<token> (ret) <answer> if 
goto <token> <answer> out_unlock; 
<token> = enable; <answer> disable 
for (i = 0; <token> < mccdev->num_colors; i++) { <answer> i 
<token> brightness; <answer> u32 
subled = mccdev->subled_info <token> i; <answer> + 
brightness = min(subled->brightness, <token> <answer> lcdev->max_brightness); 
<token> &= ~MT6370_CHEN_BIT(subled->channel); <answer> disable 
if (level <token> 0) { <answer> == 
enable <token> ~MT6370_CHEN_BIT(subled->channel); <answer> &= 
ret = <token> subled->channel, MT6370_LED_REG_MODE); <answer> mt6370_set_led_mode(priv, 
<token> (ret) <answer> if 
<token> out_unlock; <answer> goto 
<token> (brightness == 0) { <answer> if 
enable <token> ~MT6370_CHEN_BIT(subled->channel); <answer> &= 
<token> |= MT6370_CHEN_BIT(subled->channel); <answer> enable 
ret = <token> subled->channel, brightness); <answer> mt6370_set_led_brightness(priv, 
if <token> <answer> (ret) 
<token> out_unlock; <answer> goto 
ret <token> regmap_field_write(priv->fields[F_RGB_EN], disable); <answer> = 
<token> (ret) <answer> if 
<token> out_unlock; <answer> goto 
ret = <token> enable); <answer> regmap_field_write(priv->fields[F_RGB_EN], 
return <token> <answer> ret; 
static int <token> led_classdev *lcdev, <answer> mt6370_mc_blink_set(struct 
<token> long *delay_on, <answer> unsigned 
<token> long *delay_off) <answer> unsigned 
struct led_classdev_mc *mccdev <token> lcdev_to_mccdev(lcdev); <answer> = 
struct mt6370_led *led = container_of(mccdev, <token> mt6370_led, mc); <answer> struct 
struct mt6370_priv *priv = <token> <answer> led->priv; 
struct mc_subled <token> <answer> *subled; 
unsigned int enable, <token> <answer> disable; 
<token> i, ret; <answer> int 
if (!*delay_on <token> !*delay_off) <answer> && 
*delay_on = *delay_off = <token> <answer> 500; 
<token> = regmap_field_read(priv->fields[F_RGB_EN], &enable); <answer> ret 
if <token> <answer> (ret) 
<token> out_unlock; <answer> goto 
<token> = enable; <answer> disable 
<token> (i = 0; i < mccdev->num_colors; i++) { <answer> for 
subled = mccdev->subled_info <token> i; <answer> + 
disable &= <token> <answer> ~MT6370_CHEN_BIT(subled->channel); 
ret <token> mt6370_set_led_duty(priv, subled->channel, *delay_on, *delay_off); <answer> = 
<token> (ret) <answer> if 
goto <token> <answer> out_unlock; 
ret <token> mt6370_set_led_freq(priv, subled->channel, *delay_on, *delay_off); <answer> = 
if <token> <answer> (ret) 
goto <token> <answer> out_unlock; 
ret = mt6370_set_led_mode(priv, <token> MT6370_LED_PWM_MODE); <answer> subled->channel, 
<token> (ret) <answer> if 
goto <token> <answer> out_unlock; 
#include <token> <answer> <linux/list.h> 
<token> <linux/spinlock.h> <answer> #include 
#include <token> <answer> <linux/atomic.h> 
<token> <linux/tty.h> <answer> #include 
<token> <linux/sched.h> <answer> #include 
<token> <linux/sched/debug.h> <answer> #include 
<token> <linux/sched/task.h> <answer> #include 
#if <token> == 64 <answer> BITS_PER_LONG 
# define <token> 0xffffffffL <answer> LDSEM_ACTIVE_MASK 
<token> define LDSEM_ACTIVE_MASK 0x0000ffffL <answer> # 
#define <token> 0L <answer> LDSEM_UNLOCKED 
#define <token> 1L <answer> LDSEM_ACTIVE_BIAS 
#define <token> (-LDSEM_ACTIVE_MASK-1) <answer> LDSEM_WAIT_BIAS 
#define LDSEM_READ_BIAS <token> <answer> LDSEM_ACTIVE_BIAS 
<token> LDSEM_WRITE_BIAS (LDSEM_WAIT_BIAS + LDSEM_ACTIVE_BIAS) <answer> #define 
struct <token> { <answer> ldsem_waiter 
struct list_head <token> <answer> list; 
<token> task_struct *task; <answer> struct 
void __init_ldsem(struct <token> *sem, const char *name, <answer> ld_semaphore 
struct <token> *key) <answer> lock_class_key 
#ifdef <token> <answer> CONFIG_DEBUG_LOCK_ALLOC 
debug_check_no_locks_freed((void *)sem, <token> <answer> sizeof(*sem)); 
<token> name, key, 0); <answer> lockdep_init_map(&sem->dep_map, 
<token> LDSEM_UNLOCKED); <answer> atomic_long_set(&sem->count, 
sem->wait_readers <token> 0; <answer> = 
static void <token> ld_semaphore *sem) <answer> __ldsem_wake_readers(struct 
<token> ldsem_waiter *waiter, *next; <answer> struct 
struct <token> *tsk; <answer> task_struct 
long adjust, <token> <answer> count; 
adjust <token> sem->wait_readers * (LDSEM_ACTIVE_BIAS - LDSEM_WAIT_BIAS); <answer> = 
<token> = atomic_long_add_return(adjust, &sem->count); <answer> count 
<token> { <answer> do 
if (count <token> 0) <answer> > 
if (atomic_long_try_cmpxchg(&sem->count, &count, <token> - adjust)) <answer> count 
<token> while (1); <answer> } 
list_for_each_entry_safe(waiter, next, &sem->read_wait, <token> { <answer> list) 
tsk <token> waiter->task; <answer> = 
<token> NULL); <answer> smp_store_release(&waiter->task, 
<token> = 0; <answer> sem->wait_readers 
static inline int writer_trylock(struct ld_semaphore <token> <answer> *sem) 
<token> count = atomic_long_add_return(LDSEM_ACTIVE_BIAS, &sem->count); <answer> long 
do <token> <answer> { 
<token> ((count & LDSEM_ACTIVE_MASK) == LDSEM_ACTIVE_BIAS) <answer> if 
<token> 1; <answer> return 
if (atomic_long_try_cmpxchg(&sem->count, &count, <token> - LDSEM_ACTIVE_BIAS)) <answer> count 
<token> 0; <answer> return 
<token> while (1); <answer> } 
static void __ldsem_wake_writer(struct ld_semaphore <token> <answer> *sem) 
<token> ldsem_waiter *waiter; <answer> struct 
waiter <token> list_entry(sem->write_wait.next, struct ldsem_waiter, list); <answer> = 
static void __ldsem_wake(struct <token> *sem) <answer> ld_semaphore 
<token> (!list_empty(&sem->write_wait)) <answer> if 
<token> if (!list_empty(&sem->read_wait)) <answer> else 
static void ldsem_wake(struct <token> *sem) <answer> ld_semaphore 
unsigned <token> flags; <answer> long 
<token> flags); <answer> raw_spin_lock_irqsave(&sem->wait_lock, 
raw_spin_unlock_irqrestore(&sem->wait_lock, <token> <answer> flags); 
<token> struct ld_semaphore __sched * <answer> static 
<token> ld_semaphore *sem, long count, long timeout) <answer> down_read_failed(struct 
<token> ldsem_waiter waiter; <answer> struct 
long adjust <token> -LDSEM_ACTIVE_BIAS + LDSEM_WAIT_BIAS; <answer> = 
do <token> <answer> { 
if (atomic_long_try_cmpxchg(&sem->count, &count, count <token> adjust)) { <answer> + 
count += <token> <answer> adjust; 
if (count > <token> { <answer> 0) 
return <token> <answer> sem; 
<token> while (1); <answer> } 
list_add_tail(&waiter.list, <token> <answer> &sem->read_wait); 
<token> = current; <answer> waiter.task 
if <token> { <answer> (waiter.task) 
atomic_long_add_return(-LDSEM_WAIT_BIAS, <token> <answer> &sem->count); 
<token> NULL; <answer> return 
<token> sem; <answer> return 
static <token> ld_semaphore __sched * <answer> struct 
down_write_failed(struct ld_semaphore *sem, long count, <token> timeout) <answer> long 
struct ldsem_waiter <token> <answer> waiter; 
long adjust = <token> <answer> -LDSEM_ACTIVE_BIAS; 
int locked <token> 0; <answer> = 
do <token> <answer> { 
if (atomic_long_try_cmpxchg(&sem->count, <token> count + adjust)) <answer> &count, 
if ((count & LDSEM_ACTIVE_MASK) <token> LDSEM_ACTIVE_BIAS) { <answer> == 
return <token> <answer> sem; 
<token> while (1); <answer> } 
list_add_tail(&waiter.list, <token> <answer> &sem->write_wait); 
<token> = current; <answer> waiter.task 
<token> (;;) { <answer> for 
<token> (!timeout) <answer> if 
timeout = <token> <answer> schedule_timeout(timeout); 
locked <token> writer_trylock(sem); <answer> = 
if <token> <answer> (locked) 
<token> (!locked) <answer> if 
<token> &sem->count); <answer> atomic_long_add_return(-LDSEM_WAIT_BIAS, 
if (!locked <token> list_empty(&sem->write_wait)) <answer> && 
int __sched ldsem_down_read(struct <token> *sem, long timeout) <answer> ld_semaphore 
return __ldsem_down_read_nested(sem, 0, <token> <answer> timeout); 
int ldsem_down_read_trylock(struct ld_semaphore <token> <answer> *sem) 
long count = <token> <answer> atomic_long_read(&sem->count); 
while (count <token> 0) { <answer> >= 
if (atomic_long_try_cmpxchg(&sem->count, &count, count + <token> { <answer> LDSEM_READ_BIAS)) 
rwsem_acquire_read(&sem->dep_map, 0, 1, <token> <answer> _RET_IP_); 
<token> _RET_IP_); <answer> lock_acquired(&sem->dep_map, 
<token> 1; <answer> return 
return <token> <answer> 0; 
int __sched ldsem_down_write(struct ld_semaphore *sem, long <token> <answer> timeout) 
<token> __ldsem_down_write_nested(sem, 0, timeout); <answer> return 
int ldsem_down_write_trylock(struct ld_semaphore <token> <answer> *sem) 
long count = <token> <answer> atomic_long_read(&sem->count); 
while ((count <token> LDSEM_ACTIVE_MASK) == 0) { <answer> & 
if (atomic_long_try_cmpxchg(&sem->count, &count, count + <token> { <answer> LDSEM_WRITE_BIAS)) 
rwsem_acquire(&sem->dep_map, 0, 1, <token> <answer> _RET_IP_); 
lock_acquired(&sem->dep_map, <token> <answer> _RET_IP_); 
<token> 1; <answer> return 
return <token> <answer> 0; 
void <token> ld_semaphore *sem) <answer> ldsem_up_read(struct 
long <token> <answer> count; 
rwsem_release(&sem->dep_map, <token> <answer> _RET_IP_); 
count = <token> &sem->count); <answer> atomic_long_add_return(-LDSEM_READ_BIAS, 
if (count < 0 && (count & LDSEM_ACTIVE_MASK) == <token> <answer> 0) 
void ldsem_up_write(struct ld_semaphore <token> <answer> *sem) 
long <token> <answer> count; 
<token> _RET_IP_); <answer> rwsem_release(&sem->dep_map, 
<token> = atomic_long_add_return(-LDSEM_WRITE_BIAS, &sem->count); <answer> count 
if (count < <token> <answer> 0) 
#ifdef <token> <answer> CONFIG_DEBUG_LOCK_ALLOC 
int ldsem_down_read_nested(struct ld_semaphore *sem, int subclass, <token> timeout) <answer> long 
return __ldsem_down_read_nested(sem, subclass, <token> <answer> timeout); 
int ldsem_down_write_nested(struct <token> *sem, int subclass, <answer> ld_semaphore 
long <token> <answer> timeout) 
return __ldsem_down_write_nested(sem, subclass, <token> <answer> timeout); 
#include <token> <answer> <linux/etherdevice.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/hwmon.h> 
#include <token> <answer> <linux/hwmon-sysfs.h> 
#include <token> <answer> <linux/thermal.h> 
#include <token> <answer> "mt7996.h" 
<token> "mac.h" <answer> #include 
<token> "mcu.h" <answer> #include 
<token> "coredump.h" <answer> #include 
#include <token> <answer> "eeprom.h" 
static const struct ieee80211_iface_limit <token> = { <answer> if_limits[] 
.max = <token> <answer> 1, 
.types = <token> <answer> BIT(NL80211_IFTYPE_ADHOC) 
<token> { <answer> }, 
.max <token> 16, <answer> = 
.types <token> BIT(NL80211_IFTYPE_AP) <answer> = 
#ifdef <token> <answer> CONFIG_MAC80211_MESH 
<token> BIT(NL80211_IFTYPE_MESH_POINT) <answer> | 
<token> { <answer> }, 
.max = <token> <answer> MT7996_MAX_INTERFACES, 
<token> = BIT(NL80211_IFTYPE_STATION) <answer> .types 
<token> const struct ieee80211_iface_combination if_comb[] = { <answer> static 
<token> = if_limits, <answer> .limits 
.n_limits <token> ARRAY_SIZE(if_limits), <answer> = 
.max_interfaces = <token> <answer> MT7996_MAX_INTERFACES, 
.num_different_channels = <token> <answer> 1, 
<token> = true, <answer> .beacon_int_infra_match 
<token> = BIT(NL80211_CHAN_WIDTH_20_NOHT) | <answer> .radar_detect_widths 
<token> | <answer> BIT(NL80211_CHAN_WIDTH_20) 
BIT(NL80211_CHAN_WIDTH_40) <token> <answer> | 
<token> | <answer> BIT(NL80211_CHAN_WIDTH_80) 
static ssize_t <token> device *dev, <answer> mt7996_thermal_temp_show(struct 
struct <token> *attr, <answer> device_attribute 
<token> *buf) <answer> char 
struct mt7996_phy *phy <token> dev_get_drvdata(dev); <answer> = 
int i = <token> <answer> to_sensor_dev_attr(attr)->index; 
int <token> <answer> temperature; 
switch (i) <token> <answer> { 
<token> 0: <answer> case 
<token> = mt7996_mcu_get_temperature(phy); <answer> temperature 
if (temperature < <token> <answer> 0) 
<token> temperature; <answer> return 
<token> = mt7996_mcu_set_thermal_throttling(phy, throttling); <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ret; 
phy->cdev_state = <token> <answer> state; 
<token> 0; <answer> return 
static const <token> thermal_cooling_device_ops mt7996_thermal_ops = { <answer> struct 
<token> = mt7996_thermal_get_max_throttle_state, <answer> .get_max_state 
<token> = mt7996_thermal_get_cur_throttle_state, <answer> .get_cur_state 
.set_cur_state <token> mt7996_thermal_set_cur_throttle_state, <answer> = 
static void <token> mt7996_phy *phy) <answer> mt7996_unregister_thermal(struct 
struct wiphy *wiphy = <token> <answer> phy->mt76->hw->wiphy; 
if <token> <answer> (!phy->cdev) 
<token> "cooling_device"); <answer> sysfs_remove_link(&wiphy->dev.kobj, 
static int mt7996_thermal_init(struct <token> *phy) <answer> mt7996_phy 
struct wiphy *wiphy <token> phy->mt76->hw->wiphy; <answer> = 
struct <token> *cdev; <answer> thermal_cooling_device 
<token> device *hwmon; <answer> struct 
<token> char *name; <answer> const 
<token> = devm_kasprintf(&wiphy->dev, GFP_KERNEL, "mt7996_%s", <answer> name 
cdev <token> thermal_cooling_device_register(name, phy, &mt7996_thermal_ops); <answer> = 
if <token> { <answer> (!IS_ERR(cdev)) 
if <token> &cdev->device.kobj, <answer> (sysfs_create_link(&wiphy->dev.kobj, 
<token> < 0) <answer> "cooling_device") 
<token> = cdev; <answer> phy->cdev 
mt76_set(dev, MT_AGG_ACR4(band), <token> <answer> MT_AGG_ACR_PPDU_TXS2H); 
static void mt7996_mac_init_basic_rates(struct mt7996_dev <token> <answer> *dev) 
int <token> <answer> i; 
for (i = 0; i < ARRAY_SIZE(mt76_rates); <token> { <answer> i++) 
<token> rate = mt76_rates[i].hw_value; <answer> u16 
if (!is_valid_ether_addr(mphy->macaddr)) <token> <answer> { 
memcpy(mphy->macaddr, <token> + MT_EE_MAC_ADDR, <answer> dev->mt76.eeprom.data 
mphy->macaddr[0] <token> 2; <answer> |= 
<token> ^= BIT(7); <answer> mphy->macaddr[0] 
<token> (band == MT_BAND2) <answer> if 
mphy->macaddr[0] <token> BIT(6); <answer> ^= 
<token> "gt/intel_rps.h" <answer> #include 
<token> "i915_drv.h" <answer> #include 
<token> "i915_irq.h" <answer> #include 
#include <token> <answer> "i915_reg.h" 
<token> "icl_dsi_regs.h" <answer> #include 
<token> "intel_crtc.h" <answer> #include 
#include <token> <answer> "intel_de.h" 
<token> "intel_display_irq.h" <answer> #include 
<token> "intel_display_trace.h" <answer> #include 
<token> "intel_display_types.h" <answer> #include 
#include <token> <answer> "intel_dp_aux.h" 
#include <token> <answer> "intel_fdi_regs.h" 
<token> "intel_fifo_underrun.h" <answer> #include 
#include <token> <answer> "intel_gmbus.h" 
<token> "intel_hotplug_irq.h" <answer> #include 
<token> "intel_pmdemand.h" <answer> #include 
<token> "intel_psr.h" <answer> #include 
#include <token> <answer> "intel_psr_regs.h" 
static <token> <answer> void 
<token> drm_i915_private *dev_priv, enum pipe pipe) <answer> intel_handle_vblank(struct 
struct intel_crtc *crtc = <token> pipe); <answer> intel_crtc_for_pipe(dev_priv, 
void ilk_update_display_irq(struct <token> *dev_priv, <answer> drm_i915_private 
<token> interrupt_mask, u32 enabled_irq_mask) <answer> u32 
<token> new_val; <answer> u32 
drm_WARN_ON(&dev_priv->drm, <token> & ~interrupt_mask); <answer> enabled_irq_mask 
new_val = <token> <answer> dev_priv->irq_mask; 
new_val &= <token> <answer> ~interrupt_mask; 
<token> |= (~enabled_irq_mask & interrupt_mask); <answer> new_val 
if (new_val != <token> && <answer> dev_priv->irq_mask 
<token> !intel_irqs_enabled(dev_priv))) { <answer> !drm_WARN_ON(&dev_priv->drm, 
dev_priv->irq_mask = <token> <answer> new_val; 
intel_uncore_write(&dev_priv->uncore, DEIMR, <token> <answer> dev_priv->irq_mask); 
<token> DEIMR); <answer> intel_uncore_posting_read(&dev_priv->uncore, 
void ilk_enable_display_irq(struct drm_i915_private <token> u32 bits) <answer> *i915, 
ilk_update_display_irq(i915, bits, <token> <answer> bits); 
void ilk_disable_display_irq(struct drm_i915_private *i915, <token> bits) <answer> u32 
ilk_update_display_irq(i915, <token> 0); <answer> bits, 
void <token> drm_i915_private *dev_priv, <answer> bdw_update_port_irq(struct 
<token> interrupt_mask, u32 enabled_irq_mask) <answer> u32 
u32 <token> <answer> new_val; 
<token> old_val; <answer> u32 
drm_WARN_ON(&dev_priv->drm, <token> & ~interrupt_mask); <answer> enabled_irq_mask 
if <token> !intel_irqs_enabled(dev_priv))) <answer> (drm_WARN_ON(&dev_priv->drm, 
<token> = intel_uncore_read(&dev_priv->uncore, GEN8_DE_PORT_IMR); <answer> old_val 
<token> = old_val; <answer> new_val 
new_val <token> ~interrupt_mask; <answer> &= 
new_val |= <token> & interrupt_mask); <answer> (~enabled_irq_mask 
if (new_val <token> old_val) { <answer> != 
intel_uncore_write(&dev_priv->uncore, <token> new_val); <answer> GEN8_DE_PORT_IMR, 
intel_uncore_posting_read(&dev_priv->uncore, <token> <answer> GEN8_DE_PORT_IMR); 
static void <token> drm_i915_private *dev_priv, <answer> bdw_update_pipe_irq(struct 
enum pipe <token> u32 interrupt_mask, <answer> pipe, 
<token> enabled_irq_mask) <answer> u32 
u32 <token> <answer> new_val; 
drm_WARN_ON(&dev_priv->drm, enabled_irq_mask <token> ~interrupt_mask); <answer> & 
<token> (drm_WARN_ON(&dev_priv->drm, !intel_irqs_enabled(dev_priv))) <answer> if 
new_val = <token> <answer> dev_priv->de_irq_mask[pipe]; 
<token> &= ~interrupt_mask; <answer> new_val 
new_val |= (~enabled_irq_mask <token> interrupt_mask); <answer> & 
if <token> != dev_priv->de_irq_mask[pipe]) { <answer> (new_val 
dev_priv->de_irq_mask[pipe] = <token> <answer> new_val; 
intel_uncore_write(&dev_priv->uncore, GEN8_DE_PIPE_IMR(pipe), <token> <answer> dev_priv->de_irq_mask[pipe]); 
intel_uncore_posting_read(&dev_priv->uncore, <token> <answer> GEN8_DE_PIPE_IMR(pipe)); 
void bdw_enable_pipe_irq(struct drm_i915_private <token> <answer> *i915, 
enum pipe pipe, u32 <token> <answer> bits) 
<token> pipe, bits, bits); <answer> bdw_update_pipe_irq(i915, 
void <token> drm_i915_private *i915, <answer> bdw_disable_pipe_irq(struct 
enum <token> pipe, u32 bits) <answer> pipe 
bdw_update_pipe_irq(i915, pipe, <token> 0); <answer> bits, 
void ibx_display_interrupt_update(struct drm_i915_private <token> <answer> *dev_priv, 
u32 <token> <answer> interrupt_mask, 
u32 <token> <answer> enabled_irq_mask) 
u32 <token> = intel_uncore_read(&dev_priv->uncore, SDEIMR); <answer> sdeimr 
sdeimr <token> ~interrupt_mask; <answer> &= 
sdeimr |= (~enabled_irq_mask <token> interrupt_mask); <answer> & 
drm_WARN_ON(&dev_priv->drm, <token> & ~interrupt_mask); <answer> enabled_irq_mask 
<token> (drm_WARN_ON(&dev_priv->drm, !intel_irqs_enabled(dev_priv))) <answer> if 
<token> SDEIMR, sdeimr); <answer> intel_uncore_write(&dev_priv->uncore, 
intel_uncore_posting_read(&dev_priv->uncore, <token> <answer> SDEIMR); 
void ibx_enable_display_interrupt(struct drm_i915_private <token> u32 bits) <answer> *i915, 
<token> bits, bits); <answer> ibx_display_interrupt_update(i915, 
void <token> drm_i915_private *i915, u32 bits) <answer> ibx_disable_display_interrupt(struct 
<token> bits, 0); <answer> ibx_display_interrupt_update(i915, 
<token> i915_pipestat_enable_mask(struct drm_i915_private *dev_priv, <answer> u32 
<token> pipe pipe) <answer> enum 
u32 status_mask <token> dev_priv->pipestat_irq_mask[pipe]; <answer> = 
u32 enable_mask = <token> << 16; <answer> status_mask 
if (DISPLAY_VER(dev_priv) <token> 5) <answer> < 
goto <token> <answer> out; 
<token> (drm_WARN_ON_ONCE(&dev_priv->drm, <answer> if 
<token> & PIPE_A_PSR_STATUS_VLV)) <answer> status_mask 
return <token> <answer> 0; 
if <token> <answer> (drm_WARN_ON_ONCE(&dev_priv->drm, 
<token> & PIPE_B_PSR_STATUS_VLV)) <answer> status_mask 
return <token> <answer> 0; 
<token> &= ~(PIPE_FIFO_UNDERRUN_STATUS | <answer> enable_mask 
SPRITE0_FLIP_DONE_INT_EN_VLV <token> <answer> | 
if (status_mask & <token> <answer> SPRITE0_FLIP_DONE_INT_STATUS_VLV) 
enable_mask |= <token> <answer> SPRITE0_FLIP_DONE_INT_EN_VLV; 
if (status_mask & <token> <answer> SPRITE1_FLIP_DONE_INT_STATUS_VLV) 
enable_mask <token> SPRITE1_FLIP_DONE_INT_EN_VLV; <answer> |= 
<token> & ~PIPESTAT_INT_ENABLE_MASK || <answer> enable_mask 
status_mask <token> ~PIPESTAT_INT_STATUS_MASK, <answer> & 
"pipe <token> enable_mask=0x%x, status_mask=0x%x\n", <answer> %c: 
pipe_name(pipe), <token> status_mask); <answer> enable_mask, 
return <token> <answer> enable_mask; 
void i915_enable_pipestat(struct drm_i915_private <token> <answer> *dev_priv, 
enum pipe pipe, <token> status_mask) <answer> u32 
i915_reg_t reg <token> PIPESTAT(pipe); <answer> = 
<token> enable_mask; <answer> u32 
drm_WARN_ONCE(&dev_priv->drm, <token> & ~PIPESTAT_INT_STATUS_MASK, <answer> status_mask 
<token> %c: status_mask=0x%x\n", <answer> "pipe 
<token> status_mask); <answer> pipe_name(pipe), 
<token> !intel_irqs_enabled(dev_priv)); <answer> drm_WARN_ON(&dev_priv->drm, 
if ((dev_priv->pipestat_irq_mask[pipe] & status_mask) <token> status_mask) <answer> == 
dev_priv->pipestat_irq_mask[pipe] <token> status_mask; <answer> |= 
enable_mask = <token> pipe); <answer> i915_pipestat_enable_mask(dev_priv, 
intel_uncore_write(&dev_priv->uncore, reg, enable_mask <token> status_mask); <answer> | 
<token> reg); <answer> intel_uncore_posting_read(&dev_priv->uncore, 
void <token> drm_i915_private *dev_priv, <answer> i915_disable_pipestat(struct 
enum <token> pipe, u32 status_mask) <answer> pipe 
i915_reg_t <token> = PIPESTAT(pipe); <answer> reg 
u32 <token> <answer> enable_mask; 
drm_WARN_ONCE(&dev_priv->drm, status_mask <token> ~PIPESTAT_INT_STATUS_MASK, <answer> & 
<token> %c: status_mask=0x%x\n", <answer> "pipe 
<token> status_mask); <answer> pipe_name(pipe), 
drm_WARN_ON(&dev_priv->drm, <token> <answer> !intel_irqs_enabled(dev_priv)); 
if ((dev_priv->pipestat_irq_mask[pipe] & status_mask) <token> 0) <answer> == 
dev_priv->pipestat_irq_mask[pipe] &= <token> <answer> ~status_mask; 
<token> = i915_pipestat_enable_mask(dev_priv, pipe); <answer> enable_mask 
intel_uncore_write(&dev_priv->uncore, reg, <token> | status_mask); <answer> enable_mask 
intel_uncore_posting_read(&dev_priv->uncore, <token> <answer> reg); 
static bool i915_has_asle(struct <token> *i915) <answer> drm_i915_private 
<token> (!IS_PINEVIEW(i915) && !IS_MOBILE(i915)) <answer> if 
return <token> <answer> false; 
<token> intel_opregion_asle_present(i915); <answer> return 
<token> i915_enable_asle_pipestat(struct drm_i915_private *dev_priv) <answer> void 
<token> (!i915_has_asle(dev_priv)) <answer> if 
i915_enable_pipestat(dev_priv, <token> PIPE_LEGACY_BLC_EVENT_STATUS); <answer> PIPE_B, 
if <token> >= 4) <answer> (DISPLAY_VER(dev_priv) 
i915_enable_pipestat(dev_priv, <token> <answer> PIPE_A, 
<token> defined(CONFIG_DEBUG_FS) <answer> #if 
static void display_pipe_crc_irq_handler(struct drm_i915_private <token> <answer> *dev_priv, 
enum <token> pipe, <answer> pipe 
u32 <token> u32 crc1, <answer> crc0, 
u32 <token> u32 crc3, <answer> crc2, 
<token> crc4) <answer> u32 
<token> intel_crtc *crtc = intel_crtc_for_pipe(dev_priv, pipe); <answer> struct 
struct <token> *pipe_crc = &crtc->pipe_crc; <answer> intel_pipe_crc 
u32 crcs[5] = { crc0, crc1, <token> crc3, crc4 }; <answer> crc2, 
<token> crcs); <answer> trace_intel_pipe_crc(crtc, 
<token> (pipe_crc->skipped <= 0 || <answer> if 
(DISPLAY_VER(dev_priv) >= 8 <token> pipe_crc->skipped == 1)) { <answer> && 
<token> true, <answer> drm_crtc_add_crc_entry(&crtc->base, 
static inline <token> <answer> void 
display_pipe_crc_irq_handler(struct drm_i915_private <token> <answer> *dev_priv, 
<token> pipe pipe, <answer> enum 
u32 <token> u32 crc1, <answer> crc0, 
u32 <token> u32 crc3, <answer> crc2, 
u32 crc4) <token> <answer> {} 
static <token> flip_done_handler(struct drm_i915_private *i915, <answer> void 
enum pipe <token> <answer> pipe) 
struct intel_crtc <token> = intel_crtc_for_pipe(i915, pipe); <answer> *crtc 
<token> (crtc->flip_done_event) { <answer> if 
drm_crtc_send_vblank_event(&crtc->base, <token> <answer> crtc->flip_done_event); 
crtc->flip_done_event <token> NULL; <answer> = 
static void <token> drm_i915_private *dev_priv, <answer> hsw_pipe_crc_irq_handler(struct 
enum <token> pipe) <answer> pipe 
<token> pipe, <answer> display_pipe_crc_irq_handler(dev_priv, 
intel_uncore_read(&dev_priv->uncore, <token> <answer> PIPE_CRC_RES_1_IVB(pipe)), 
0, 0, 0, <token> <answer> 0); 
<token> void ivb_pipe_crc_irq_handler(struct drm_i915_private *dev_priv, <answer> static 
enum <token> pipe) <answer> pipe 
<token> pipe, <answer> display_pipe_crc_irq_handler(dev_priv, 
intel_uncore_read(&dev_priv->uncore, <token> <answer> PIPE_CRC_RES_1_IVB(pipe)), 
<token> PIPE_CRC_RES_2_IVB(pipe)), <answer> intel_uncore_read(&dev_priv->uncore, 
intel_uncore_read(&dev_priv->uncore, <token> <answer> PIPE_CRC_RES_3_IVB(pipe)), 
intel_uncore_read(&dev_priv->uncore, <token> <answer> PIPE_CRC_RES_4_IVB(pipe)), 
<token> PIPE_CRC_RES_5_IVB(pipe))); <answer> intel_uncore_read(&dev_priv->uncore, 
static <token> i9xx_pipe_crc_irq_handler(struct drm_i915_private *dev_priv, <answer> void 
<token> pipe pipe) <answer> enum 
<token> res1, res2; <answer> u32 
<token> (DISPLAY_VER(dev_priv) >= 3) <answer> if 
res1 = <token> PIPE_CRC_RES_RES1_I915(pipe)); <answer> intel_uncore_read(&dev_priv->uncore, 
res1 <token> 0; <answer> = 
if (DISPLAY_VER(dev_priv) >= <token> || IS_G4X(dev_priv)) <answer> 5 
<token> = intel_uncore_read(&dev_priv->uncore, PIPE_CRC_RES_RES2_G4X(pipe)); <answer> res2 
<token> = 0; <answer> res2 
display_pipe_crc_irq_handler(dev_priv, <token> <answer> pipe, 
intel_uncore_read(&dev_priv->uncore, <token> <answer> PIPE_CRC_RES_RED(pipe)), 
intel_uncore_read(&dev_priv->uncore, <token> <answer> PIPE_CRC_RES_GREEN(pipe)), 
intel_uncore_read(&dev_priv->uncore, <token> <answer> PIPE_CRC_RES_BLUE(pipe)), 
res1, <token> <answer> res2); 
<token> i9xx_pipestat_irq_reset(struct drm_i915_private *dev_priv) <answer> void 
<token> pipe pipe; <answer> enum 
<token> pipe) { <answer> for_each_pipe(dev_priv, 
intel_uncore_write(&dev_priv->uncore, <token> <answer> PIPESTAT(pipe), 
PIPESTAT_INT_STATUS_MASK <token> <answer> | 
<token> = 0; <answer> dev_priv->pipestat_irq_mask[pipe] 
void <token> drm_i915_private *dev_priv, <answer> i9xx_pipestat_irq_ack(struct 
u32 iir, <token> pipe_stats[I915_MAX_PIPES]) <answer> u32 
<token> pipe pipe; <answer> enum 
<token> (!dev_priv->display_irqs_enabled) { <answer> if 
<token> pipe) { <answer> for_each_pipe(dev_priv, 
<token> reg; <answer> i915_reg_t 
u32 status_mask, enable_mask, <token> = 0; <answer> iir_bit 
<token> (pipe_stats[pipe]) { <answer> if 
intel_uncore_write(&dev_priv->uncore, <token> pipe_stats[pipe]); <answer> reg, 
<token> reg, enable_mask); <answer> intel_uncore_write(&dev_priv->uncore, 
void <token> drm_i915_private *dev_priv, <answer> i8xx_pipestat_irq_handler(struct 
u16 iir, u32 <token> <answer> pipe_stats[I915_MAX_PIPES]) 
enum <token> pipe; <answer> pipe 
for_each_pipe(dev_priv, <token> { <answer> pipe) 
if (pipe_stats[pipe] <token> PIPE_VBLANK_INTERRUPT_STATUS) <answer> & 
intel_handle_vblank(dev_priv, <token> <answer> pipe); 
if (pipe_stats[pipe] & <token> <answer> PIPE_CRC_DONE_INTERRUPT_STATUS) 
i9xx_pipe_crc_irq_handler(dev_priv, <token> <answer> pipe); 
if (pipe_stats[pipe] & <token> <answer> PIPE_FIFO_UNDERRUN_STATUS) 
intel_cpu_fifo_underrun_irq_handler(dev_priv, <token> <answer> pipe); 
void i915_pipestat_irq_handler(struct drm_i915_private <token> <answer> *dev_priv, 
u32 <token> u32 pipe_stats[I915_MAX_PIPES]) <answer> iir, 
<token> blc_event = false; <answer> bool 
enum <token> pipe; <answer> pipe 
for_each_pipe(dev_priv, pipe) <token> <answer> { 
if <token> & PIPE_VBLANK_INTERRUPT_STATUS) <answer> (pipe_stats[pipe] 
intel_handle_vblank(dev_priv, <token> <answer> pipe); 
<token> (pipe_stats[pipe] & PIPE_LEGACY_BLC_EVENT_STATUS) <answer> if 
blc_event = <token> <answer> true; 
if (pipe_stats[pipe] & <token> <answer> PIPE_CRC_DONE_INTERRUPT_STATUS) 
<token> pipe); <answer> i9xx_pipe_crc_irq_handler(dev_priv, 
if (pipe_stats[pipe] & <token> <answer> PIPE_FIFO_UNDERRUN_STATUS) 
<token> pipe); <answer> intel_cpu_fifo_underrun_irq_handler(dev_priv, 
if (blc_event || (iir <token> I915_ASLE_INTERRUPT)) <answer> & 
void <token> drm_i915_private *dev_priv, <answer> i965_pipestat_irq_handler(struct 
u32 iir, u32 <token> <answer> pipe_stats[I915_MAX_PIPES]) 
<token> blc_event = false; <answer> bool 
<token> pipe pipe; <answer> enum 
<token> pipe) { <answer> for_each_pipe(dev_priv, 
<token> (pipe_stats[pipe] & PIPE_START_VBLANK_INTERRUPT_STATUS) <answer> if 
intel_handle_vblank(dev_priv, <token> <answer> pipe); 
if (pipe_stats[pipe] <token> PIPE_LEGACY_BLC_EVENT_STATUS) <answer> & 
blc_event = <token> <answer> true; 
<token> (pipe_stats[pipe] & PIPE_CRC_DONE_INTERRUPT_STATUS) <answer> if 
<token> pipe); <answer> i9xx_pipe_crc_irq_handler(dev_priv, 
if <token> & PIPE_FIFO_UNDERRUN_STATUS) <answer> (pipe_stats[pipe] 
<token> pipe); <answer> intel_cpu_fifo_underrun_irq_handler(dev_priv, 
<token> (blc_event || (iir & I915_ASLE_INTERRUPT)) <answer> if 
<token> (pipe_stats[0] & PIPE_GMBUS_INTERRUPT_STATUS) <answer> if 
void valleyview_pipestat_irq_handler(struct drm_i915_private <token> <answer> *dev_priv, 
<token> pipe_stats[I915_MAX_PIPES]) <answer> u32 
<token> pipe pipe; <answer> enum 
<token> pipe) { <answer> for_each_pipe(dev_priv, 
if (pipe_stats[pipe] <token> PIPE_START_VBLANK_INTERRUPT_STATUS) <answer> & 
<token> pipe); <answer> intel_handle_vblank(dev_priv, 
if (pipe_stats[pipe] & <token> <answer> PLANE_FLIP_DONE_INT_STATUS_VLV) 
<token> pipe); <answer> flip_done_handler(dev_priv, 
if (pipe_stats[pipe] & <token> <answer> PIPE_CRC_DONE_INTERRUPT_STATUS) 
<token> pipe); <answer> i9xx_pipe_crc_irq_handler(dev_priv, 
if <token> & PIPE_FIFO_UNDERRUN_STATUS) <answer> (pipe_stats[pipe] 
intel_cpu_fifo_underrun_irq_handler(dev_priv, <token> <answer> pipe); 
<token> (pipe_stats[0] & PIPE_GMBUS_INTERRUPT_STATUS) <answer> if 
<token> void ibx_irq_handler(struct drm_i915_private *dev_priv, u32 pch_iir) <answer> static 
<token> pipe pipe; <answer> enum 
<token> hotplug_trigger = pch_iir & SDE_HOTPLUG_MASK; <answer> u32 
ibx_hpd_irq_handler(dev_priv, <token> <answer> hotplug_trigger); 
<token> (pch_iir & SDE_AUDIO_POWER_MASK) { <answer> if 
int port = ffs((pch_iir <token> SDE_AUDIO_POWER_MASK) >> <answer> & 
drm_dbg(&dev_priv->drm, "PCH audio <token> change on port %d\n", <answer> power 
<token> (pch_iir & SDE_AUX_MASK) <answer> if 
<token> (pch_iir & SDE_GMBUS) <answer> if 
if (pch_iir <token> SDE_AUDIO_HDCP_MASK) <answer> & 
drm_dbg(&dev_priv->drm, "PCH HDCP audio <token> <answer> interrupt\n"); 
if <token> & SDE_AUDIO_TRANS_MASK) <answer> (pch_iir 
drm_dbg(&dev_priv->drm, <token> transcoder audio interrupt\n"); <answer> "PCH 
<token> (pch_iir & SDE_POISON) <answer> if 
drm_err(&dev_priv->drm, "PCH poison <token> <answer> interrupt\n"); 
if (pch_iir & SDE_FDI_MASK) <token> <answer> { 
<token> pipe) <answer> for_each_pipe(dev_priv, 
drm_dbg(&dev_priv->drm, " pipe <token> FDI IIR: 0x%08x\n", <answer> %c 
<token> FDI_RX_IIR(pipe))); <answer> intel_uncore_read(&dev_priv->uncore, 
<token> (pch_iir & (SDE_TRANSB_CRC_DONE | SDE_TRANSA_CRC_DONE)) <answer> if 
drm_dbg(&dev_priv->drm, "PCH <token> CRC done interrupt\n"); <answer> transcoder 
if (pch_iir & <token> | SDE_TRANSA_CRC_ERR)) <answer> (SDE_TRANSB_CRC_ERR 
"PCH transcoder CRC <token> interrupt\n"); <answer> error 
if (pch_iir <token> SDE_TRANSA_FIFO_UNDER) <answer> & 
<token> PIPE_A); <answer> intel_pch_fifo_underrun_irq_handler(dev_priv, 
if <token> & SDE_TRANSB_FIFO_UNDER) <answer> (pch_iir 
<token> PIPE_B); <answer> intel_pch_fifo_underrun_irq_handler(dev_priv, 
static void ivb_err_int_handler(struct drm_i915_private <token> <answer> *dev_priv) 
u32 err_int = intel_uncore_read(&dev_priv->uncore, <token> <answer> GEN7_ERR_INT); 
enum pipe <token> <answer> pipe; 
if <token> & ERR_INT_POISON) <answer> (err_int 
drm_err(&dev_priv->drm, <token> interrupt\n"); <answer> "Poison 
<token> pipe) { <answer> for_each_pipe(dev_priv, 
if (err_int <token> ERR_INT_FIFO_UNDERRUN(pipe)) <answer> & 
<token> pipe); <answer> intel_cpu_fifo_underrun_irq_handler(dev_priv, 
if (err_int & ERR_INT_PIPE_CRC_DONE(pipe)) <token> <answer> { 
<token> (IS_IVYBRIDGE(dev_priv)) <answer> if 
ivb_pipe_crc_irq_handler(dev_priv, <token> <answer> pipe); 
<token> pipe); <answer> hsw_pipe_crc_irq_handler(dev_priv, 
intel_uncore_write(&dev_priv->uncore, GEN7_ERR_INT, <token> <answer> err_int); 
static void <token> drm_i915_private *dev_priv) <answer> cpt_serr_int_handler(struct 
u32 serr_int <token> intel_uncore_read(&dev_priv->uncore, SERR_INT); <answer> = 
<token> pipe pipe; <answer> enum 
if (serr_int <token> SERR_INT_POISON) <answer> & 
drm_err(&dev_priv->drm, "PCH poison <token> <answer> interrupt\n"); 
for_each_pipe(dev_priv, <token> <answer> pipe) 
if <token> & SERR_INT_TRANS_FIFO_UNDERRUN(pipe)) <answer> (serr_int 
intel_pch_fifo_underrun_irq_handler(dev_priv, <token> <answer> pipe); 
<token> SERR_INT, serr_int); <answer> intel_uncore_write(&dev_priv->uncore, 
static <token> cpt_irq_handler(struct drm_i915_private *dev_priv, u32 pch_iir) <answer> void 
enum pipe <token> <answer> pipe; 
u32 hotplug_trigger = <token> & SDE_HOTPLUG_MASK_CPT; <answer> pch_iir 
<token> hotplug_trigger); <answer> ibx_hpd_irq_handler(dev_priv, 
if (pch_iir <token> SDE_AUDIO_POWER_MASK_CPT) { <answer> & 
int port = ffs((pch_iir <token> SDE_AUDIO_POWER_MASK_CPT) >> <answer> & 
<token> "PCH audio power change on port %c\n", <answer> drm_dbg(&dev_priv->drm, 
if (pch_iir & <token> <answer> SDE_AUX_MASK_CPT) 
if (pch_iir & <token> <answer> SDE_GMBUS_CPT) 
<token> (pch_iir & SDE_AUDIO_CP_REQ_CPT) <answer> if 
drm_dbg(&dev_priv->drm, "Audio CP <token> interrupt\n"); <answer> request 
if (pch_iir <token> SDE_AUDIO_CP_CHG_CPT) <answer> & 
drm_dbg(&dev_priv->drm, <token> CP change interrupt\n"); <answer> "Audio 
if (pch_iir & SDE_FDI_MASK_CPT) <token> <answer> { 
<token> pipe) <answer> for_each_pipe(dev_priv, 
drm_dbg(&dev_priv->drm, <token> pipe %c FDI IIR: 0x%08x\n", <answer> " 
<token> FDI_RX_IIR(pipe))); <answer> intel_uncore_read(&dev_priv->uncore, 
if <token> & SDE_ERROR_CPT) <answer> (pch_iir 
void <token> drm_i915_private *dev_priv, u32 de_iir) <answer> ilk_display_irq_handler(struct 
enum <token> pipe; <answer> pipe 
<token> hotplug_trigger = de_iir & DE_DP_A_HOTPLUG; <answer> u32 
<token> (hotplug_trigger) <answer> if 
ilk_hpd_irq_handler(dev_priv, <token> <answer> hotplug_trigger); 
if (de_iir <token> DE_AUX_CHANNEL_A) <answer> & 
if <token> & DE_GSE) <answer> (de_iir 
if (de_iir <token> DE_POISON) <answer> & 
drm_err(&dev_priv->drm, <token> interrupt\n"); <answer> "Poison 
for_each_pipe(dev_priv, pipe) <token> <answer> { 
<token> (de_iir & DE_PIPE_VBLANK(pipe)) <answer> if 
intel_handle_vblank(dev_priv, <token> <answer> pipe); 
if <token> & DE_PLANE_FLIP_DONE(pipe)) <answer> (de_iir 
flip_done_handler(dev_priv, <token> <answer> pipe); 
if (de_iir <token> DE_PIPE_FIFO_UNDERRUN(pipe)) <answer> & 
intel_cpu_fifo_underrun_irq_handler(dev_priv, <token> <answer> pipe); 
if (de_iir <token> DE_PIPE_CRC_DONE(pipe)) <answer> & 
i9xx_pipe_crc_irq_handler(dev_priv, <token> <answer> pipe); 
<token> = intel_uncore_read(&dev_priv->uncore, TRANS_DDI_FUNC_CTL2(TRANSCODER_DSI_0)); <answer> val 
val <token> PORT_SYNC_MODE_ENABLE; <answer> &= 
port = ((te_trigger & DSI1_TE && val) || (te_trigger & <token> ? <answer> DSI0_TE)) 
<token> : PORT_B; <answer> PORT_A 
dsi_trans = (port == PORT_A) <token> TRANSCODER_DSI_0 : TRANSCODER_DSI_1; <answer> ? 
if (*pch_iir & <token> { <answer> SDE_PICAINTERRUPT) 
drm_WARN_ON(&i915->drm, INTEL_PCH_TYPE(i915) < <token> <answer> PCH_MTL); 
pica_ier = intel_de_rmw(i915, PICAINTERRUPT_IER, <token> 0); <answer> ~0, 
*pica_iir = <token> PICAINTERRUPT_IIR); <answer> intel_de_read(i915, 
<token> PICAINTERRUPT_IIR, *pica_iir); <answer> intel_de_write(i915, 
<token> SDEIIR, *pch_iir); <answer> intel_de_write(i915, 
if <token> <answer> (pica_ier) 
intel_de_write(i915, PICAINTERRUPT_IER, <token> <answer> pica_ier); 
<token> gen8_de_irq_handler(struct drm_i915_private *dev_priv, u32 master_ctl) <answer> void 
<token> iir; <answer> u32 
enum pipe <token> <answer> pipe; 
drm_WARN_ON_ONCE(&dev_priv->drm, <token> <answer> !HAS_DISPLAY(dev_priv)); 
if (master_ctl <token> GEN8_DE_MISC_IRQ) { <answer> & 
iir = intel_uncore_read(&dev_priv->uncore, <token> <answer> GEN8_DE_MISC_IIR); 
<token> (iir) { <answer> if 
<token> GEN8_DE_MISC_IIR, iir); <answer> intel_uncore_write(&dev_priv->uncore, 
<token> iir); <answer> gen8_de_misc_irq_handler(dev_priv, 
} else <token> <answer> { 
"The master control interrupt lied <token> MISC)!\n"); <answer> (DE 
if (DISPLAY_VER(dev_priv) <token> 11 && (master_ctl & GEN11_DE_HPD_IRQ)) { <answer> >= 
iir = intel_uncore_read(&dev_priv->uncore, <token> <answer> GEN11_DE_HPD_IIR); 
<token> (iir) { <answer> if 
intel_uncore_write(&dev_priv->uncore, GEN11_DE_HPD_IIR, <token> <answer> iir); 
gen11_hpd_irq_handler(dev_priv, <token> <answer> iir); 
} <token> { <answer> else 
"The master control interrupt lied, (DE <token> <answer> HPD)!\n"); 
if (master_ctl & GEN8_DE_PORT_IRQ) <token> <answer> { 
iir = intel_uncore_read(&dev_priv->uncore, <token> <answer> GEN8_DE_PORT_IIR); 
if <token> { <answer> (iir) 
bool found <token> false; <answer> = 
intel_uncore_write(&dev_priv->uncore, GEN8_DE_PORT_IIR, <token> <answer> iir); 
<token> (iir & gen8_de_port_aux_mask(dev_priv)) { <answer> if 
found = <token> <answer> true; 
<token> (IS_GEMINILAKE(dev_priv) || IS_BROXTON(dev_priv)) { <answer> if 
u32 <token> = iir & BXT_DE_PORT_HOTPLUG_MASK; <answer> hotplug_trigger 
<token> (hotplug_trigger) { <answer> if 
<token> hotplug_trigger); <answer> bxt_hpd_irq_handler(dev_priv, 
found <token> true; <answer> = 
} else <token> (IS_BROADWELL(dev_priv)) { <answer> if 
u32 hotplug_trigger = <token> & BDW_DE_PORT_HOTPLUG_MASK; <answer> iir 
if <token> { <answer> (hotplug_trigger) 
<token> hotplug_trigger); <answer> ilk_hpd_irq_handler(dev_priv, 
found = <token> <answer> true; 
if <token> || IS_BROXTON(dev_priv)) && <answer> ((IS_GEMINILAKE(dev_priv) 
<token> & BXT_DE_PORT_GMBUS)) { <answer> (iir 
found = <token> <answer> true; 
<token> (DISPLAY_VER(dev_priv) >= 11) { <answer> if 
u32 <token> = iir & (DSI0_TE | DSI1_TE); <answer> te_trigger 
if (te_trigger) <token> <answer> { 
<token> te_trigger); <answer> gen11_dsi_te_interrupt_handler(dev_priv, 
found <token> true; <answer> = 
if <token> <answer> (!found) 
"Unexpected DE Port <token> <answer> interrupt\n"); 
} <token> { <answer> else 
"The master control interrupt <token> (DE PORT)!\n"); <answer> lied 
for_each_pipe(dev_priv, pipe) <token> <answer> { 
u32 <token> <answer> fault_errors; 
if (!(master_ctl & <token> <answer> GEN8_DE_PIPE_IRQ(pipe))) 
iir <token> intel_uncore_read(&dev_priv->uncore, GEN8_DE_PIPE_IIR(pipe)); <answer> = 
<token> (!iir) { <answer> if 
"The master control interrupt lied (DE <token> <answer> PIPE)!\n"); 
intel_uncore_write(&dev_priv->uncore, GEN8_DE_PIPE_IIR(pipe), <token> <answer> iir); 
<token> (iir & GEN8_PIPE_VBLANK) <answer> if 
intel_handle_vblank(dev_priv, <token> <answer> pipe); 
if (iir <token> gen8_de_pipe_flip_done_mask(dev_priv)) <answer> & 
<token> pipe); <answer> flip_done_handler(dev_priv, 
if <token> & GEN8_PIPE_CDCLK_CRC_DONE) <answer> (iir 
<token> pipe); <answer> hsw_pipe_crc_irq_handler(dev_priv, 
if (iir <token> gen8_de_pipe_underrun_mask(dev_priv)) <answer> & 
<token> pipe); <answer> intel_cpu_fifo_underrun_irq_handler(dev_priv, 
fault_errors = iir <token> gen8_de_pipe_fault_mask(dev_priv); <answer> & 
if <token> <answer> (fault_errors) 
"Fault errors <token> pipe %c: 0x%08x\n", <answer> on 
if (HAS_PCH_SPLIT(dev_priv) <token> !HAS_PCH_NOP(dev_priv) && <answer> && 
<token> & GEN8_DE_PCH_IRQ) { <answer> master_ctl 
u32 <token> <answer> pica_iir; 
<token> &iir, &pica_iir); <answer> gen8_read_and_ack_pch_irqs(dev_priv, 
<token> (iir) { <answer> if 
if <token> <answer> (pica_iir) 
xelpdp_pica_irq_handler(dev_priv, <token> <answer> pica_iir); 
if (INTEL_PCH_TYPE(dev_priv) <token> PCH_ICP) <answer> >= 
<token> iir); <answer> icp_irq_handler(dev_priv, 
else if (INTEL_PCH_TYPE(dev_priv) >= <token> <answer> PCH_SPT) 
<token> iir); <answer> spt_irq_handler(dev_priv, 
<token> iir); <answer> cpt_irq_handler(dev_priv, 
} <token> { <answer> else 
"The master <token> interrupt lied (SDE)!\n"); <answer> control 
u32 gen11_gu_misc_irq_ack(struct drm_i915_private *i915, <token> u32 master_ctl) <answer> const 
void __iomem <token> const regs = intel_uncore_regs(&i915->uncore); <answer> * 
u32 <token> <answer> iir; 
<token> (!(master_ctl & GEN11_GU_MISC_IRQ)) <answer> if 
return <token> <answer> 0; 
iir = raw_reg_read(regs, <token> <answer> GEN11_GU_MISC_IIR); 
if <token> <answer> (likely(iir)) 
<token> GEN11_GU_MISC_IIR, iir); <answer> raw_reg_write(regs, 
return <token> <answer> iir; 
void gen11_gu_misc_irq_handler(struct drm_i915_private *i915, <token> u32 iir) <answer> const 
<token> (iir & GEN11_GU_MISC_GSE) <answer> if 
void gen11_display_irq_handler(struct drm_i915_private <token> <answer> *i915) 
<token> __iomem * const regs = intel_uncore_regs(&i915->uncore); <answer> void 
const u32 disp_ctl = raw_reg_read(regs, <token> <answer> GEN11_DISPLAY_INT_CTL); 
raw_reg_write(regs, GEN11_DISPLAY_INT_CTL, <token> <answer> 0x0); 
gen8_de_irq_handler(i915, <token> <answer> disp_ctl); 
<token> GEN11_DISPLAY_INT_CTL, <answer> raw_reg_write(regs, 
int i8xx_enable_vblank(struct drm_crtc <token> <answer> *crtc) 
struct drm_i915_private *dev_priv <token> to_i915(crtc->dev); <answer> = 
enum <token> pipe = to_intel_crtc(crtc)->pipe; <answer> pipe 
unsigned long <token> <answer> irqflags; 
<token> irqflags); <answer> spin_lock_irqsave(&dev_priv->irq_lock, 
<token> pipe, PIPE_VBLANK_INTERRUPT_STATUS); <answer> i915_enable_pipestat(dev_priv, 
<token> irqflags); <answer> spin_unlock_irqrestore(&dev_priv->irq_lock, 
<token> 0; <answer> return 
int i915gm_enable_vblank(struct drm_crtc <token> <answer> *crtc) 
struct drm_i915_private <token> = to_i915(crtc->dev); <answer> *dev_priv 
<token> (dev_priv->vblank_enabled++ == 0) <answer> if 
intel_uncore_write(&dev_priv->uncore, SCPD0, <token> <answer> _MASKED_BIT_ENABLE(CSTATE_RENDER_CLOCK_GATE_DISABLE)); 
return <token> <answer> i8xx_enable_vblank(crtc); 
int i965_enable_vblank(struct <token> *crtc) <answer> drm_crtc 
<token> drm_i915_private *dev_priv = to_i915(crtc->dev); <answer> struct 
enum pipe pipe <token> to_intel_crtc(crtc)->pipe; <answer> = 
unsigned long <token> <answer> irqflags; 
spin_lock_irqsave(&dev_priv->irq_lock, <token> <answer> irqflags); 
i915_enable_pipestat(dev_priv, <token> <answer> pipe, 
spin_unlock_irqrestore(&dev_priv->irq_lock, <token> <answer> irqflags); 
return <token> <answer> 0; 
<token> ilk_enable_vblank(struct drm_crtc *crtc) <answer> int 
struct drm_i915_private *dev_priv <token> to_i915(crtc->dev); <answer> = 
enum <token> pipe = to_intel_crtc(crtc)->pipe; <answer> pipe 
<token> long irqflags; <answer> unsigned 
<token> bit = DISPLAY_VER(dev_priv) >= 7 ? <answer> u32 
DE_PIPE_VBLANK_IVB(pipe) <token> DE_PIPE_VBLANK(pipe); <answer> : 
<token> irqflags); <answer> spin_lock_irqsave(&dev_priv->irq_lock, 
<token> bit); <answer> ilk_enable_display_irq(dev_priv, 
spin_unlock_irqrestore(&dev_priv->irq_lock, <token> <answer> irqflags); 
<token> (HAS_PSR(dev_priv)) <answer> if 
return <token> <answer> 0; 
static bool <token> intel_crtc *intel_crtc, <answer> gen11_dsi_configure_te(struct 
<token> enable) <answer> bool 
struct drm_i915_private *dev_priv = <token> <answer> to_i915(intel_crtc->base.dev); 
enum <token> port; <answer> port 
if (!(intel_crtc->mode_flags <token> <answer> & 
(I915_MODE_FLAG_DSI_USE_TE1 <token> I915_MODE_FLAG_DSI_USE_TE0))) <answer> | 
<token> false; <answer> return 
if <token> <answer> (HAS_PSR(dev_priv)) 
<token> 0; <answer> return 
void i8xx_disable_vblank(struct <token> *crtc) <answer> drm_crtc 
struct drm_i915_private *dev_priv <token> to_i915(crtc->dev); <answer> = 
enum pipe <token> = to_intel_crtc(crtc)->pipe; <answer> pipe 
<token> long irqflags; <answer> unsigned 
spin_lock_irqsave(&dev_priv->irq_lock, <token> <answer> irqflags); 
<token> pipe, PIPE_VBLANK_INTERRUPT_STATUS); <answer> i915_disable_pipestat(dev_priv, 
<token> irqflags); <answer> spin_unlock_irqrestore(&dev_priv->irq_lock, 
void i915gm_disable_vblank(struct drm_crtc <token> <answer> *crtc) 
struct drm_i915_private *dev_priv <token> to_i915(crtc->dev); <answer> = 
<token> (--dev_priv->vblank_enabled == 0) <answer> if 
<token> SCPD0, _MASKED_BIT_DISABLE(CSTATE_RENDER_CLOCK_GATE_DISABLE)); <answer> intel_uncore_write(&dev_priv->uncore, 
void i965_disable_vblank(struct drm_crtc <token> <answer> *crtc) 
struct <token> *dev_priv = to_i915(crtc->dev); <answer> drm_i915_private 
enum pipe pipe <token> to_intel_crtc(crtc)->pipe; <answer> = 
<token> long irqflags; <answer> unsigned 
spin_lock_irqsave(&dev_priv->irq_lock, <token> <answer> irqflags); 
<token> pipe, <answer> i915_disable_pipestat(dev_priv, 
<token> irqflags); <answer> spin_unlock_irqrestore(&dev_priv->irq_lock, 
void <token> drm_crtc *crtc) <answer> ilk_disable_vblank(struct 
struct drm_i915_private *dev_priv = <token> <answer> to_i915(crtc->dev); 
enum pipe <token> = to_intel_crtc(crtc)->pipe; <answer> pipe 
<token> long irqflags; <answer> unsigned 
u32 <token> = DISPLAY_VER(dev_priv) >= 7 ? <answer> bit 
DE_PIPE_VBLANK_IVB(pipe) <token> DE_PIPE_VBLANK(pipe); <answer> : 
<token> irqflags); <answer> spin_lock_irqsave(&dev_priv->irq_lock, 
<token> bit); <answer> ilk_disable_display_irq(dev_priv, 
<token> irqflags); <answer> spin_unlock_irqrestore(&dev_priv->irq_lock, 
void bdw_disable_vblank(struct drm_crtc <token> <answer> *_crtc) 
struct <token> *crtc = to_intel_crtc(_crtc); <answer> intel_crtc 
struct <token> *dev_priv = to_i915(crtc->base.dev); <answer> drm_i915_private 
<token> pipe pipe = crtc->pipe; <answer> enum 
unsigned long <token> <answer> irqflags; 
if (gen11_dsi_configure_te(crtc, <token> <answer> false)) 
<token> irqflags); <answer> spin_lock_irqsave(&dev_priv->irq_lock, 
<token> pipe, GEN8_PIPE_VBLANK); <answer> bdw_disable_pipe_irq(dev_priv, 
spin_unlock_irqrestore(&dev_priv->irq_lock, <token> <answer> irqflags); 
<token> vlv_display_irq_reset(struct drm_i915_private *dev_priv) <answer> void 
<token> intel_uncore *uncore = &dev_priv->uncore; <answer> struct 
if <token> <answer> (IS_CHERRYVIEW(dev_priv)) 
intel_uncore_write(uncore, DPINVGTT, <token> <answer> DPINVGTT_STATUS_MASK_CHV); 
<token> DPINVGTT, DPINVGTT_STATUS_MASK_VLV); <answer> intel_uncore_write(uncore, 
<token> 0xffffffff, 0); <answer> i915_hotplug_interrupt_update_locked(dev_priv, 
intel_uncore_rmw(uncore, PORT_HOTPLUG_STAT, 0, <token> <answer> 0); 
<token> VLV_); <answer> GEN3_IRQ_RESET(uncore, 
<token> = ~0u; <answer> dev_priv->irq_mask 
<token> vlv_display_irq_postinstall(struct drm_i915_private *dev_priv) <answer> void 
struct intel_uncore <token> = &dev_priv->uncore; <answer> *uncore 
u32 <token> <answer> pipestat_mask; 
u32 <token> <answer> enable_mask; 
<token> pipe pipe; <answer> enum 
<token> = PIPE_CRC_DONE_INTERRUPT_STATUS; <answer> pipestat_mask 
<token> PIPE_A, PIPE_GMBUS_INTERRUPT_STATUS); <answer> i915_enable_pipestat(dev_priv, 
for_each_pipe(dev_priv, <token> <answer> pipe) 
i915_enable_pipestat(dev_priv, pipe, <token> <answer> pipestat_mask); 
enable_mask = I915_DISPLAY_PORT_INTERRUPT <token> <answer> | 
I915_DISPLAY_PIPE_A_EVENT_INTERRUPT <token> <answer> | 
I915_DISPLAY_PIPE_B_EVENT_INTERRUPT <token> <answer> | 
<token> | <answer> I915_LPE_PIPE_A_INTERRUPT 
<token> (IS_CHERRYVIEW(dev_priv)) <answer> if 
enable_mask <token> I915_DISPLAY_PIPE_C_EVENT_INTERRUPT | <answer> |= 
drm_WARN_ON(&dev_priv->drm, dev_priv->irq_mask <token> ~0u); <answer> != 
dev_priv->irq_mask <token> ~enable_mask; <answer> = 
<token> VLV_, dev_priv->irq_mask, enable_mask); <answer> GEN3_IRQ_INIT(uncore, 
void gen8_display_irq_reset(struct drm_i915_private <token> <answer> *dev_priv) 
struct intel_uncore *uncore = <token> <answer> &dev_priv->uncore; 
<token> pipe pipe; <answer> enum 
if <token> <answer> (!HAS_DISPLAY(dev_priv)) 
intel_uncore_write(uncore, <token> 0xffffffff); <answer> EDP_PSR_IMR, 
<token> EDP_PSR_IIR, 0xffffffff); <answer> intel_uncore_write(uncore, 
for_each_pipe(dev_priv, <token> <answer> pipe) 
if <token> <answer> (intel_display_power_is_enabled(dev_priv, 
<token> DE_PIPE, pipe); <answer> GEN8_IRQ_RESET_NDX(uncore, 
<token> GEN8_DE_PORT_); <answer> GEN3_IRQ_RESET(uncore, 
GEN3_IRQ_RESET(uncore, <token> <answer> GEN8_DE_MISC_); 
void <token> drm_i915_private *dev_priv) <answer> gen11_display_irq_reset(struct 
struct intel_uncore *uncore <token> &dev_priv->uncore; <answer> = 
enum <token> pipe; <answer> pipe 
<token> trans_mask = BIT(TRANSCODER_A) | BIT(TRANSCODER_B) | <answer> u32 
<token> | BIT(TRANSCODER_D); <answer> BIT(TRANSCODER_C) 
if <token> <answer> (!HAS_DISPLAY(dev_priv)) 
intel_uncore_write(uncore, <token> 0); <answer> GEN11_DISPLAY_INT_CTL, 
<token> (DISPLAY_VER(dev_priv) >= 12) { <answer> if 
<token> transcoder trans; <answer> enum 
<token> trans, trans_mask) { <answer> for_each_cpu_transcoder_masked(dev_priv, 
<token> intel_display_power_domain domain; <answer> enum 
<token> = POWER_DOMAIN_TRANSCODER(trans); <answer> domain 
if <token> domain)) <answer> (!intel_display_power_is_enabled(dev_priv, 
<token> TRANS_PSR_IMR(trans), 0xffffffff); <answer> intel_uncore_write(uncore, 
<token> TRANS_PSR_IIR(trans), 0xffffffff); <answer> intel_uncore_write(uncore, 
<token> else { <answer> } 
<token> EDP_PSR_IMR, 0xffffffff); <answer> intel_uncore_write(uncore, 
intel_uncore_write(uncore, <token> 0xffffffff); <answer> EDP_PSR_IIR, 
<token> pipe) <answer> for_each_pipe(dev_priv, 
<token> (intel_display_power_is_enabled(dev_priv, <answer> if 
GEN8_IRQ_RESET_NDX(uncore, <token> pipe); <answer> DE_PIPE, 
GEN3_IRQ_RESET(uncore, <token> <answer> GEN8_DE_PORT_); 
GEN3_IRQ_RESET(uncore, <token> <answer> GEN8_DE_MISC_); 
<token> (DISPLAY_VER(dev_priv) >= 14) <answer> if 
<token> PICAINTERRUPT_); <answer> GEN3_IRQ_RESET(uncore, 
GEN3_IRQ_RESET(uncore, <token> <answer> GEN11_DE_HPD_); 
if (INTEL_PCH_TYPE(dev_priv) <token> PCH_ICP) <answer> >= 
<token> SDE); <answer> GEN3_IRQ_RESET(uncore, 
<token> gen8_irq_power_well_post_enable(struct drm_i915_private *dev_priv, <answer> void 
<token> pipe_mask) <answer> u8 
struct intel_uncore <token> = &dev_priv->uncore; <answer> *uncore 
u32 extra_ier = GEN8_PIPE_VBLANK <token> <answer> | 
gen8_de_pipe_underrun_mask(dev_priv) <token> <answer> | 
enum <token> pipe; <answer> pipe 
if (!intel_irqs_enabled(dev_priv)) <token> <answer> { 
for_each_pipe_masked(dev_priv, pipe, <token> <answer> pipe_mask) 
<token> DE_PIPE, pipe, <answer> GEN8_IRQ_INIT_NDX(uncore, 
~dev_priv->de_irq_mask[pipe] | <token> <answer> extra_ier); 
void gen8_irq_power_well_pre_disable(struct drm_i915_private <token> <answer> *dev_priv, 
<token> pipe_mask) <answer> u8 
struct intel_uncore *uncore <token> &dev_priv->uncore; <answer> = 
<token> pipe pipe; <answer> enum 
if <token> { <answer> (!intel_irqs_enabled(dev_priv)) 
<token> pipe, pipe_mask) <answer> for_each_pipe_masked(dev_priv, 
GEN8_IRQ_RESET_NDX(uncore, <token> pipe); <answer> DE_PIPE, 
static void ibx_irq_postinstall(struct drm_i915_private <token> <answer> *dev_priv) 
struct intel_uncore *uncore = <token> <answer> &dev_priv->uncore; 
u32 <token> <answer> mask; 
<token> (HAS_PCH_NOP(dev_priv)) <answer> if 
if <token> <answer> (HAS_PCH_IBX(dev_priv)) 
mask = <token> | SDE_AUX_MASK | SDE_POISON; <answer> SDE_GMBUS 
else if <token> || HAS_PCH_LPT(dev_priv)) <answer> (HAS_PCH_CPT(dev_priv) 
mask = SDE_GMBUS_CPT <token> SDE_AUX_MASK_CPT; <answer> | 
mask <token> SDE_GMBUS_CPT; <answer> = 
GEN3_IRQ_INIT(uncore, SDE, ~mask, <token> <answer> 0xffffffff); 
void valleyview_enable_display_irqs(struct <token> *dev_priv) <answer> drm_i915_private 
if <token> <answer> (dev_priv->display_irqs_enabled) 
<token> = true; <answer> dev_priv->display_irqs_enabled 
if (intel_irqs_enabled(dev_priv)) <token> <answer> { 
void <token> drm_i915_private *dev_priv) <answer> valleyview_disable_display_irqs(struct 
if <token> <answer> (!dev_priv->display_irqs_enabled) 
dev_priv->display_irqs_enabled <token> false; <answer> = 
<token> (intel_irqs_enabled(dev_priv)) <answer> if 
void ilk_de_irq_postinstall(struct <token> *i915) <answer> drm_i915_private 
struct intel_uncore *uncore <token> &i915->uncore; <answer> = 
<token> display_mask, extra_mask; <answer> u32 
<token> (DISPLAY_VER(i915) >= 7) { <answer> if 
display_mask <token> (DE_MASTER_IRQ_CONTROL | DE_GSE_IVB | <answer> = 
DE_PCH_EVENT_IVB | <token> <answer> DE_AUX_CHANNEL_A_IVB); 
extra_mask = (DE_PIPEC_VBLANK_IVB <token> DE_PIPEB_VBLANK_IVB | <answer> | 
<token> | DE_ERR_INT_IVB | <answer> DE_PIPEA_VBLANK_IVB 
<token> | <answer> DE_PLANE_FLIP_DONE_IVB(PLANE_C) 
DE_PLANE_FLIP_DONE_IVB(PLANE_B) <token> <answer> | 
<token> | <answer> DE_PLANE_FLIP_DONE_IVB(PLANE_A) 
} else <token> <answer> { 
display_mask = <token> | DE_GSE | DE_PCH_EVENT | <answer> (DE_MASTER_IRQ_CONTROL 
DE_AUX_CHANNEL_A | <token> | <answer> DE_PIPEB_CRC_DONE 
DE_PIPEA_CRC_DONE <token> DE_POISON); <answer> | 
extra_mask = (DE_PIPEA_VBLANK | DE_PIPEB_VBLANK <token> <answer> | 
DE_PIPEB_FIFO_UNDERRUN | DE_PIPEA_FIFO_UNDERRUN <token> <answer> | 
DE_PLANE_FLIP_DONE(PLANE_A) <token> <answer> | 
DE_PLANE_FLIP_DONE(PLANE_B) <token> <answer> | 
if <token> { <answer> (IS_HASWELL(i915)) 
<token> EDP_PSR_IIR); <answer> gen3_assert_iir_is_zero(uncore, 
<token> |= DE_EDP_PSR_INT_HSW; <answer> display_mask 
if <token> <answer> (IS_IRONLAKE_M(i915)) 
<token> |= DE_PCU_EVENT; <answer> extra_mask 
i915->irq_mask <token> ~display_mask; <answer> = 
GEN3_IRQ_INIT(uncore, DE, <token> <answer> i915->irq_mask, 
display_mask | <token> <answer> extra_mask); 
static <token> mtp_irq_postinstall(struct drm_i915_private *i915); <answer> void 
static void icp_irq_postinstall(struct drm_i915_private <token> <answer> *i915); 
void gen8_de_irq_postinstall(struct <token> *dev_priv) <answer> drm_i915_private 
struct intel_uncore *uncore <token> &dev_priv->uncore; <answer> = 
<token> de_pipe_masked = gen8_de_pipe_fault_mask(dev_priv) | <answer> u32 
u32 <token> <answer> de_pipe_enables; 
u32 de_port_masked = <token> <answer> gen8_de_port_aux_mask(dev_priv); 
<token> de_port_enables; <answer> u32 
<token> de_misc_masked = GEN8_DE_EDP_PSR; <answer> u32 
u32 trans_mask <token> BIT(TRANSCODER_A) | BIT(TRANSCODER_B) | <answer> = 
BIT(TRANSCODER_C) | <token> <answer> BIT(TRANSCODER_D); 
enum <token> pipe; <answer> pipe 
<token> (!HAS_DISPLAY(dev_priv)) <answer> if 
<token> (DISPLAY_VER(dev_priv) >= 14) <answer> if 
else if (INTEL_PCH_TYPE(dev_priv) <token> PCH_ICP) <answer> >= 
else if <token> <answer> (HAS_PCH_SPLIT(dev_priv)) 
if (DISPLAY_VER(dev_priv) <token> 11) <answer> < 
de_misc_masked |= <token> <answer> GEN8_DE_MISC_GSE; 
<token> (IS_GEMINILAKE(dev_priv) || IS_BROXTON(dev_priv)) <answer> if 
de_port_masked |= <token> <answer> BXT_DE_PORT_GMBUS; 
if (DISPLAY_VER(dev_priv) >= 14) <token> <answer> { 
de_misc_masked <token> XELPDP_PMDEMAND_RSPTOUT_ERR | <answer> |= 
<token> else if (DISPLAY_VER(dev_priv) >= 11) { <answer> } 
<token> port port; <answer> enum 
<token> (intel_bios_is_dsi_present(dev_priv, &port)) <answer> if 
de_port_masked <token> DSI0_TE | DSI1_TE; <answer> |= 
de_pipe_enables = <token> | <answer> de_pipe_masked 
<token> | <answer> GEN8_PIPE_VBLANK 
gen8_de_pipe_underrun_mask(dev_priv) <token> <answer> | 
de_port_enables <token> de_port_masked; <answer> = 
if (IS_GEMINILAKE(dev_priv) || <token> <answer> IS_BROXTON(dev_priv)) 
<token> |= BXT_DE_PORT_HOTPLUG_MASK; <answer> de_port_enables 
<token> if (IS_BROADWELL(dev_priv)) <answer> else 
de_port_enables |= <token> <answer> BDW_DE_PORT_HOTPLUG_MASK; 
if (DISPLAY_VER(dev_priv) >= 12) <token> <answer> { 
enum <token> trans; <answer> transcoder 
<token> trans, trans_mask) { <answer> for_each_cpu_transcoder_masked(dev_priv, 
enum <token> domain; <answer> intel_display_power_domain 
<token> = POWER_DOMAIN_TRANSCODER(trans); <answer> domain 
if <token> domain)) <answer> (!intel_display_power_is_enabled(dev_priv, 
gen3_assert_iir_is_zero(uncore, <token> <answer> TRANS_PSR_IIR(trans)); 
} else <token> <answer> { 
<token> EDP_PSR_IIR); <answer> gen3_assert_iir_is_zero(uncore, 
for_each_pipe(dev_priv, <token> { <answer> pipe) 
<token> = ~de_pipe_masked; <answer> dev_priv->de_irq_mask[pipe] 
if <token> <answer> (intel_display_power_is_enabled(dev_priv, 
GEN8_IRQ_INIT_NDX(uncore, DE_PIPE, <token> <answer> pipe, 
GEN3_IRQ_INIT(uncore, GEN8_DE_PORT_, ~de_port_masked, <token> <answer> de_port_enables); 
GEN3_IRQ_INIT(uncore, <token> ~de_misc_masked, de_misc_masked); <answer> GEN8_DE_MISC_, 
if (IS_DISPLAY_VER(dev_priv, <token> 13)) { <answer> 11, 
u32 de_hpd_masked <token> 0; <answer> = 
u32 de_hpd_enables = <token> | <answer> GEN11_DE_TC_HOTPLUG_MASK 
GEN3_IRQ_INIT(uncore, GEN11_DE_HPD_, <token> <answer> ~de_hpd_masked, 
static <token> mtp_irq_postinstall(struct drm_i915_private *i915) <answer> void 
struct intel_uncore <token> = &i915->uncore; <answer> *uncore 
u32 sde_mask = SDE_GMBUS_ICP <token> SDE_PICAINTERRUPT; <answer> | 
u32 de_hpd_mask <token> XELPDP_AUX_TC_MASK; <answer> = 
u32 de_hpd_enables = <token> | XELPDP_DP_ALT_HOTPLUG_MASK | <answer> de_hpd_mask 
GEN3_IRQ_INIT(uncore, PICAINTERRUPT_, <token> <answer> ~de_hpd_mask, 
GEN3_IRQ_INIT(uncore, <token> ~sde_mask, 0xffffffff); <answer> SDE, 
static void icp_irq_postinstall(struct drm_i915_private <token> <answer> *dev_priv) 
struct <token> *uncore = &dev_priv->uncore; <answer> intel_uncore 
<token> mask = SDE_GMBUS_ICP; <answer> u32 
GEN3_IRQ_INIT(uncore, <token> ~mask, 0xffffffff); <answer> SDE, 
void gen11_de_irq_postinstall(struct drm_i915_private <token> <answer> *dev_priv) 
if <token> <answer> (!HAS_DISPLAY(dev_priv)) 
<token> GEN11_DISPLAY_INT_CTL, <answer> intel_uncore_write(&dev_priv->uncore, 
<token> dg1_de_irq_postinstall(struct drm_i915_private *i915) <answer> void 
if <token> <answer> (!HAS_DISPLAY(i915)) 
intel_uncore_write(&i915->uncore, <token> <answer> GEN11_DISPLAY_INT_CTL, 
void intel_display_irq_init(struct drm_i915_private <token> <answer> *i915) 
i915->drm.vblank_disable_immediate <token> true; <answer> = 
<token> = true; <answer> i915->display_irqs_enabled 
<token> (IS_VALLEYVIEW(i915) || IS_CHERRYVIEW(i915)) <answer> if 
<token> = false; <answer> i915->display_irqs_enabled 
#include <token> <answer> <linux/module.h> 
<token> <linux/i2c.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
<token> <linux/iio/iio.h> <answer> #include 
<token> <linux/iio/sysfs.h> <answer> #include 
<token> <linux/iio/events.h> <answer> #include 
#define <token> 7 <answer> GP2AP002_HYS_HYSD_SHIFT 
<token> GP2AP002_HYS_HYSD_MASK BIT(7) <answer> #define 
<token> GP2AP002_HYS_HYSC_SHIFT 5 <answer> #define 
<token> GP2AP002_HYS_HYSC_MASK GENMASK(6, 5) <answer> #define 
#define GP2AP002_HYS_HYSF_SHIFT <token> <answer> 0 
#define GP2AP002_HYS_HYSF_MASK GENMASK(3, <token> <answer> 0) 
#define GP2AP002_HYS_MASK (GP2AP002_HYS_HYSD_MASK | <token> <answer> \ 
<token> | \ <answer> GP2AP002_HYS_HYSC_MASK 
<token> GP2AP002_CYCLE_CYCL_SHIFT 3 <answer> #define 
#define GP2AP002_CYCLE_CYCL_MASK <token> 3) <answer> GENMASK(5, 
#define <token> 0 <answer> GP2AP002_CYCLE_OSC_EFFECTIVE 
#define <token> BIT(2) <answer> GP2AP002_CYCLE_OSC_INEFFECTIVE 
#define <token> BIT(2) <answer> GP2AP002_CYCLE_OSC_MASK 
#define <token> 3 <answer> GP2AP002_CON_OCON_SHIFT 
#define GP2AP002_CON_OCON_ENABLE <token> << GP2AP002_CON_OCON_SHIFT) <answer> (0x0 
#define GP2AP002_CON_OCON_LOW <token> << GP2AP002_CON_OCON_SHIFT) <answer> (0x2 
#define GP2AP002_CON_OCON_HIGH (0x3 <token> GP2AP002_CON_OCON_SHIFT) <answer> << 
#define GP2AP002_CON_OCON_MASK (0x3 << <token> <answer> GP2AP002_CON_OCON_SHIFT) 
<token> gp2ap002 { <answer> struct 
struct regmap <token> <answer> *map; 
struct <token> *dev; <answer> device 
<token> regulator *vdd; <answer> struct 
<token> regulator *vio; <answer> struct 
struct <token> *alsout; <answer> iio_channel 
u8 <token> <answer> hys_far; 
u8 <token> <answer> hys_close; 
bool <token> <answer> is_gp2ap002s00f; 
int <token> <answer> irq; 
bool <token> <answer> enabled; 
static <token> gp2ap002_prox_irq(int irq, void *d) <answer> irqreturn_t 
struct iio_dev <token> = d; <answer> *indio_dev 
struct gp2ap002 *gp2ap002 = <token> <answer> iio_priv(indio_dev); 
u64 <token> <answer> ev; 
int <token> <answer> val; 
int <token> <answer> ret; 
if <token> <answer> (!gp2ap002->enabled) 
<token> err_retrig; <answer> goto 
ret = regmap_read(gp2ap002->map, <token> &val); <answer> GP2AP002_PROX, 
if <token> { <answer> (ret) 
dev_err(gp2ap002->dev, "error <token> proximity\n"); <answer> reading 
goto <token> <answer> err_retrig; 
if <token> & GP2AP002_PROX_VO_DETECT) { <answer> (val 
<token> 30000); <answer> usleep_range(20000, 
ret <token> regmap_write(gp2ap002->map, GP2AP002_CON, <answer> = 
if <token> <answer> (ret) 
dev_err(gp2ap002->dev, "error setting <token> VOUT control\n"); <answer> up 
<token> IRQ_HANDLED; <answer> return 
static const u16 gp2ap002_illuminance_table[] <token> { <answer> = 
0, 1, 1, 2, 2, 3, 4, 5, 6, 8, 10, 12, <token> 20, 25, 32, 40, 50, 63, 79, <answer> 16, 
100, 126, 158, 200, 251, 316, 398, 501, 631, <token> 1000, 1259, 1585, <answer> 794, 
1995, 2512, 3162, 3981, 5012, 6310, 7943, 10000, 12589, <token> 19953, <answer> 15849, 
25119, 31623, <token> 50119, <answer> 39811, 
static int gp2ap002_get_lux(struct <token> *gp2ap002) <answer> gp2ap002 
int ret, <token> <answer> res; 
u16 <token> <answer> lux; 
ret = <token> &res); <answer> iio_read_channel_processed(gp2ap002->alsout, 
if (ret <token> 0) <answer> < 
return <token> <answer> ret; 
dev_dbg(gp2ap002->dev, "read %d mA from ADC\n", <token> <answer> res); 
return <token> <answer> gp2ap002->enabled; 
static <token> gp2ap002_write_event_config(struct iio_dev *indio_dev, <answer> int 
<token> struct iio_chan_spec *chan, <answer> const 
enum <token> type, <answer> iio_event_type 
enum iio_event_direction <token> <answer> dir, 
int <token> <answer> state) 
struct gp2ap002 <token> = iio_priv(indio_dev); <answer> *gp2ap002 
<token> (state) { <answer> if 
<token> = true; <answer> gp2ap002->enabled 
} <token> { <answer> else 
gp2ap002->enabled <token> false; <answer> = 
<token> 0; <answer> return 
static const struct iio_info gp2ap002_info = <token> <answer> { 
.read_raw <token> gp2ap002_read_raw, <answer> = 
<token> = gp2ap002_read_event_config, <answer> .read_event_config 
<token> = gp2ap002_write_event_config, <answer> .write_event_config 
static <token> struct iio_event_spec gp2ap002_events[] = { <answer> const 
.type = <token> <answer> IIO_EV_TYPE_THRESH, 
.dir = <token> <answer> IIO_EV_DIR_EITHER, 
.mask_separate = <token> <answer> BIT(IIO_EV_INFO_ENABLE), 
static const struct <token> gp2ap002_channels[] = { <answer> iio_chan_spec 
.type = <token> <answer> IIO_PROXIMITY, 
<token> = gp2ap002_events, <answer> .event_spec 
.num_event_specs <token> ARRAY_SIZE(gp2ap002_events), <answer> = 
.type = <token> <answer> IIO_LIGHT, 
.info_mask_separate <token> BIT(IIO_CHAN_INFO_RAW), <answer> = 
.channel <token> GP2AP002_ALS_CHANNEL, <answer> = 
static int gp2ap002_regmap_i2c_read(void *context, unsigned <token> reg, <answer> int 
<token> int *val) <answer> unsigned 
struct <token> *dev = context; <answer> device 
struct i2c_client *i2c = <token> <answer> to_i2c_client(dev); 
int <token> <answer> ret; 
<token> = i2c_smbus_read_word_data(i2c, reg); <answer> ret 
if <token> < 0) <answer> (ret 
return <token> <answer> ret; 
*val = (ret >> 8) <token> 0xFF; <answer> & 
<token> 0; <answer> return 
<token> int gp2ap002_regmap_i2c_write(void *context, unsigned int reg, <answer> static 
unsigned <token> val) <answer> int 
struct device *dev = <token> <answer> context; 
struct i2c_client *i2c = <token> <answer> to_i2c_client(dev); 
return i2c_smbus_write_byte_data(i2c, reg, <token> <answer> val); 
static struct regmap_bus gp2ap002_regmap_bus <token> { <answer> = 
.reg_read = <token> <answer> gp2ap002_regmap_i2c_read, 
.reg_write <token> gp2ap002_regmap_i2c_write, <answer> = 
static <token> gp2ap002_probe(struct i2c_client *client) <answer> int 
<token> gp2ap002 *gp2ap002; <answer> struct 
struct <token> *indio_dev; <answer> iio_dev 
struct device *dev = <token> <answer> &client->dev; 
<token> iio_chan_type ch_type; <answer> enum 
static <token> struct regmap_config config = { <answer> const 
.reg_bits = <token> <answer> 8, 
.val_bits = <token> <answer> 8, 
.max_register <token> GP2AP002_CON, <answer> = 
<token> regmap *regmap; <answer> struct 
int <token> <answer> num_chan; 
<token> char *compat; <answer> const 
<token> val; <answer> u8 
<token> ret; <answer> int 
indio_dev = devm_iio_device_alloc(dev, <token> <answer> sizeof(*gp2ap002)); 
if <token> <answer> (!indio_dev) 
<token> -ENOMEM; <answer> return 
<token> indio_dev); <answer> i2c_set_clientdata(client, 
<token> = iio_priv(indio_dev); <answer> gp2ap002 
<token> = dev; <answer> gp2ap002->dev 
ret = device_property_read_string(dev, <token> &compat); <answer> "compatible", 
<token> (ret) { <answer> if 
<token> "cannot check compatible\n"); <answer> dev_err(dev, 
<token> ret; <answer> return 
gp2ap002->is_gp2ap002s00f = !strcmp(compat, <token> <answer> "sharp,gp2ap002s00f"); 
regmap = devm_regmap_init(dev, &gp2ap002_regmap_bus, dev, <token> <answer> &config); 
if (IS_ERR(regmap)) <token> <answer> { 
dev_err(dev, <token> to register i2c regmap %ld\n", PTR_ERR(regmap)); <answer> "Failed 
<token> PTR_ERR(regmap); <answer> return 
gp2ap002->map = <token> <answer> regmap; 
ret = <token> <answer> gp2ap002_init(gp2ap002); 
if <token> { <answer> (ret) 
dev_err(dev, <token> failed\n"); <answer> "initialization 
goto <token> <answer> out_disable_vio; 
gp2ap002->enabled = <token> <answer> false; 
ret <token> devm_request_threaded_irq(dev, client->irq, NULL, <answer> = 
gp2ap002_prox_irq, <token> <answer> IRQF_ONESHOT, 
"gp2ap002", <token> <answer> indio_dev); 
if (ret) <token> <answer> { 
<token> "unable to request IRQ\n"); <answer> dev_err(dev, 
goto <token> <answer> out_put_pm; 
gp2ap002->irq <token> client->irq; <answer> = 
pm_runtime_set_autosuspend_delay(dev, <token> <answer> 1000); 
indio_dev->info = <token> <answer> &gp2ap002_info; 
<token> = "gp2ap002"; <answer> indio_dev->name 
indio_dev->channels <token> gp2ap002_channels; <answer> = 
return <token> <answer> 0; 
static <token> gp2ap002_runtime_resume(struct device *dev) <answer> int 
struct iio_dev *indio_dev <token> dev_get_drvdata(dev); <answer> = 
struct gp2ap002 *gp2ap002 = <token> <answer> iio_priv(indio_dev); 
<token> ret; <answer> int 
ret = <token> <answer> regulator_enable(gp2ap002->vdd); 
if <token> { <answer> (ret) 
dev_err(dev, "failed to enable <token> regulator in resume path\n"); <answer> VDD 
<token> ret; <answer> return 
ret = <token> <answer> regulator_enable(gp2ap002->vio); 
<token> (ret) { <answer> if 
dev_err(dev, "failed to enable VIO regulator in resume <token> <answer> path\n"); 
<token> ret; <answer> return 
ret = <token> <answer> gp2ap002_init(gp2ap002); 
<token> (ret) { <answer> if 
dev_err(dev, "re-initialization <token> <answer> failed\n"); 
return <token> <answer> ret; 
if <token> >= NUM_WEPKEYS) <answer> (key_index 
return <token> <answer> -EINVAL; 
<token> = prism2_domibset_uint32(wlandev, <answer> result 
<token> (result) <answer> if 
goto <token> <answer> exit; 
<token> = prism2_domibset_uint32(wlandev, <answer> result 
if <token> <answer> (result) 
<token> exit; <answer> goto 
} else <token> <answer> { 
result = <token> <answer> prism2_domibset_uint32(wlandev, 
if <token> <answer> (result) 
goto <token> <answer> exit; 
result = <token> <answer> prism2_domibset_uint32(wlandev, 
<token> (result) <answer> if 
goto <token> <answer> exit; 
msg_join.msgcode = <token> <answer> DIDMSG_LNXREQ_AUTOJOIN; 
<token> sme->ssid, length); <answer> memcpy(msg_join.ssid.data.data, 
msg_join.ssid.data.len <token> length; <answer> = 
result = p80211req_dorequest(wlandev, (u8 <token> <answer> *)&msg_join); 
<token> (result) <answer> if 
<token> = -EFAULT; <answer> err 
<token> err; <answer> return 
static int prism2_disconnect(struct <token> *wiphy, struct net_device *dev, <answer> wiphy 
u16 <token> <answer> reason_code) 
struct wlandevice *wlandev = <token> <answer> dev->ml_priv; 
<token> p80211msg_lnxreq_autojoin msg_join; <answer> struct 
<token> result; <answer> int 
int <token> = 0; <answer> err 
<token> <linux/clk.h> <answer> #include 
#include <token> <answer> <linux/debugfs.h> 
#include <token> <answer> <linux/delay.h> 
<token> <linux/host1x.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_platform.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/pm_runtime.h> <answer> #include 
#include <token> <answer> <linux/regulator/consumer.h> 
<token> <linux/reset.h> <answer> #include 
<token> <video/mipi_display.h> <answer> #include 
<token> <drm/drm_atomic_helper.h> <answer> #include 
#include <token> <answer> <drm/drm_debugfs.h> 
#include <token> <answer> <drm/drm_file.h> 
#include <token> <answer> <drm/drm_mipi_dsi.h> 
#include <token> <answer> <drm/drm_panel.h> 
#include <token> <answer> <drm/drm_simple_kms_helper.h> 
<token> "dc.h" <answer> #include 
#include <token> <answer> "drm.h" 
#include <token> <answer> "dsi.h" 
#include <token> <answer> "mipi-phy.h" 
#include <token> <answer> "trace.h" 
struct tegra_dsi_state <token> <answer> { 
struct <token> base; <answer> drm_connector_state 
struct mipi_dphy_timing <token> <answer> timing; 
<token> long period; <answer> unsigned 
unsigned <token> vrefresh; <answer> int 
unsigned <token> lanes; <answer> int 
unsigned <token> pclk; <answer> long 
unsigned long <token> <answer> bclk; 
enum <token> format; <answer> tegra_dsi_format 
unsigned int <token> <answer> mul; 
unsigned int <token> <answer> div; 
static <token> struct tegra_dsi_state * <answer> inline 
to_dsi_state(struct <token> *state) <answer> drm_connector_state 
return container_of(state, struct <token> base); <answer> tegra_dsi_state, 
<token> tegra_dsi { <answer> struct 
struct host1x_client <token> <answer> client; 
struct tegra_output <token> <answer> output; 
<token> device *dev; <answer> struct 
void __iomem <token> <answer> *regs; 
struct <token> *rst; <answer> reset_control 
<token> clk *clk_parent; <answer> struct 
struct <token> *clk_lp; <answer> clk 
struct clk <token> <answer> *clk; 
struct <token> *debugfs_files; <answer> drm_info_list 
<token> long flags; <answer> unsigned 
<token> mipi_dsi_pixel_format format; <answer> enum 
unsigned <token> lanes; <answer> int 
struct tegra_mipi_device <token> <answer> *mipi; 
struct <token> host; <answer> mipi_dsi_host 
<token> regulator *vdd; <answer> struct 
<token> int video_fifo_depth; <answer> unsigned 
unsigned int <token> <answer> host_fifo_depth; 
static const <token> pkt_seq_video_non_burst_sync_pulses[NUM_PKT_SEQ] = { <answer> u32 
[ <token> = PKT_ID0(MIPI_DSI_V_SYNC_START) | PKT_LEN0(0) | <answer> 0] 
<token> | PKT_LEN1(1) | <answer> PKT_ID1(MIPI_DSI_BLANKING_PACKET) 
PKT_ID2(MIPI_DSI_H_SYNC_END) <token> PKT_LEN2(0) | <answer> | 
[ 1] = <token> <answer> 0, 
[ 2] <token> PKT_ID0(MIPI_DSI_V_SYNC_END) | PKT_LEN0(0) | <answer> = 
PKT_ID1(MIPI_DSI_BLANKING_PACKET) | PKT_LEN1(1) <token> <answer> | 
PKT_ID2(MIPI_DSI_H_SYNC_END) | PKT_LEN2(0) <token> <answer> | 
[ 3] <token> 0, <answer> = 
[ 4] = PKT_ID0(MIPI_DSI_H_SYNC_START) <token> PKT_LEN0(0) | <answer> | 
PKT_ID1(MIPI_DSI_BLANKING_PACKET) | <token> | <answer> PKT_LEN1(1) 
PKT_ID2(MIPI_DSI_H_SYNC_END) | <token> | <answer> PKT_LEN2(0) 
[ 5] = <token> <answer> 0, 
[ <token> = PKT_ID0(MIPI_DSI_H_SYNC_START) | PKT_LEN0(0) | <answer> 6] 
PKT_ID1(MIPI_DSI_BLANKING_PACKET) | PKT_LEN1(1) <token> <answer> | 
<token> | PKT_LEN2(0), <answer> PKT_ID2(MIPI_DSI_H_SYNC_END) 
[ 7] = <token> | PKT_LEN0(2) | <answer> PKT_ID0(MIPI_DSI_BLANKING_PACKET) 
<token> | PKT_LEN1(3) | <answer> PKT_ID1(MIPI_DSI_PACKED_PIXEL_STREAM_24) 
PKT_ID2(MIPI_DSI_BLANKING_PACKET) <token> PKT_LEN2(4), <answer> | 
<token> 8] = PKT_ID0(MIPI_DSI_H_SYNC_START) | PKT_LEN0(0) | <answer> [ 
<token> | PKT_LEN1(1) | <answer> PKT_ID1(MIPI_DSI_BLANKING_PACKET) 
<token> | PKT_LEN2(0) | <answer> PKT_ID2(MIPI_DSI_H_SYNC_END) 
[ 9] = <token> <answer> 0, 
[10] = <token> | PKT_LEN0(0) | <answer> PKT_ID0(MIPI_DSI_H_SYNC_START) 
<token> | PKT_LEN1(1) | <answer> PKT_ID1(MIPI_DSI_BLANKING_PACKET) 
PKT_ID2(MIPI_DSI_H_SYNC_END) <token> PKT_LEN2(0), <answer> | 
[11] = PKT_ID0(MIPI_DSI_BLANKING_PACKET) | <token> | <answer> PKT_LEN0(2) 
PKT_ID1(MIPI_DSI_PACKED_PIXEL_STREAM_24) <token> PKT_LEN1(3) | <answer> | 
PKT_ID2(MIPI_DSI_BLANKING_PACKET) <token> PKT_LEN2(4), <answer> | 
static const u32 <token> = { <answer> pkt_seq_video_non_burst_sync_events[NUM_PKT_SEQ] 
[ 0] = PKT_ID0(MIPI_DSI_V_SYNC_START) <token> PKT_LEN0(0) | <answer> | 
PKT_ID1(MIPI_DSI_END_OF_TRANSMISSION) | <token> | <answer> PKT_LEN1(7) 
<token> 1] = 0, <answer> [ 
[ 2] = PKT_ID0(MIPI_DSI_H_SYNC_START) | <token> | <answer> PKT_LEN0(0) 
PKT_ID1(MIPI_DSI_END_OF_TRANSMISSION) | <token> | <answer> PKT_LEN1(7) 
[ <token> = 0, <answer> 3] 
<token> 4] = PKT_ID0(MIPI_DSI_H_SYNC_START) | PKT_LEN0(0) | <answer> [ 
<token> | PKT_LEN1(7) | <answer> PKT_ID1(MIPI_DSI_END_OF_TRANSMISSION) 
[ 5] <token> 0, <answer> = 
[ 6] = PKT_ID0(MIPI_DSI_H_SYNC_START) <token> PKT_LEN0(0) | <answer> | 
PKT_ID1(MIPI_DSI_BLANKING_PACKET) | <token> | <answer> PKT_LEN1(2) 
PKT_ID2(MIPI_DSI_PACKED_PIXEL_STREAM_24) | <token> <answer> PKT_LEN2(3), 
[ 7] = PKT_ID0(MIPI_DSI_BLANKING_PACKET) <token> PKT_LEN0(4), <answer> | 
[ 8] = PKT_ID0(MIPI_DSI_H_SYNC_START) | PKT_LEN0(0) <token> <answer> | 
PKT_ID1(MIPI_DSI_END_OF_TRANSMISSION) <token> PKT_LEN1(7) | <answer> | 
[ 9] <token> 0, <answer> = 
[10] <token> PKT_ID0(MIPI_DSI_H_SYNC_START) | PKT_LEN0(0) | <answer> = 
PKT_ID1(MIPI_DSI_BLANKING_PACKET) | PKT_LEN1(2) <token> <answer> | 
PKT_ID2(MIPI_DSI_PACKED_PIXEL_STREAM_24) | <token> <answer> PKT_LEN2(3), 
[11] = PKT_ID0(MIPI_DSI_BLANKING_PACKET) | <token> <answer> PKT_LEN0(4), 
static const u32 pkt_seq_command_mode[NUM_PKT_SEQ] <token> { <answer> = 
[ 0] = <token> <answer> 0, 
[ <token> = 0, <answer> 1] 
[ <token> = 0, <answer> 2] 
[ 3] = <token> <answer> 0, 
<token> 4] = 0, <answer> [ 
[ 5] = <token> <answer> 0, 
[ 6] = PKT_ID0(MIPI_DSI_DCS_LONG_WRITE) <token> PKT_LEN0(3) | PKT_LP, <answer> | 
[ 7] = <token> <answer> 0, 
[ 8] <token> 0, <answer> = 
[ 9] = <token> <answer> 0, 
[10] = <token> | PKT_LEN0(5) | PKT_LP, <answer> PKT_ID0(MIPI_DSI_DCS_LONG_WRITE) 
<token> = 0, <answer> [11] 
static void <token> tegra_dsi *dsi, <answer> tegra_dsi_set_phy_timing(struct 
unsigned long <token> <answer> period, 
<token> struct mipi_dphy_timing *timing) <answer> const 
<token> value; <answer> u32 
<token> = DSI_TIMING_FIELD(timing->hsexit, period, 1) << 24 | <answer> value 
DSI_TIMING_FIELD(timing->hstrail, <token> 0) << 16 | <answer> period, 
<token> period, 3) << 8 | <answer> DSI_TIMING_FIELD(timing->hszero, 
<token> period, 1); <answer> DSI_TIMING_FIELD(timing->hsprepare, 
tegra_dsi_writel(dsi, <token> DSI_PHY_TIMING_0); <answer> value, 
value = <token> period, 1) << 24 | <answer> DSI_TIMING_FIELD(timing->clktrail, 
<token> period, 1) << 16 | <answer> DSI_TIMING_FIELD(timing->clkpost, 
DSI_TIMING_FIELD(timing->clkzero, period, 1) << <token> | <answer> 8 
<token> period, 1); <answer> DSI_TIMING_FIELD(timing->lpx, 
<token> value, DSI_PHY_TIMING_1); <answer> tegra_dsi_writel(dsi, 
value = DSI_TIMING_FIELD(timing->clkprepare, <token> 1) << 16 | <answer> period, 
DSI_TIMING_FIELD(timing->clkpre, period, 1) << <token> | <answer> 8 
DSI_TIMING_FIELD(0xff <token> period, period, 0) << 0; <answer> * 
<token> value, DSI_PHY_TIMING_2); <answer> tegra_dsi_writel(dsi, 
value = DSI_TIMING_FIELD(timing->taget, <token> 1) << 16 | <answer> period, 
DSI_TIMING_FIELD(timing->tasure, <token> 1) << 8 | <answer> period, 
<token> period, 1); <answer> DSI_TIMING_FIELD(timing->tago, 
<token> value, DSI_BTA_TIMING); <answer> tegra_dsi_writel(dsi, 
<token> (dsi->slave) <answer> if 
<token> period, timing); <answer> tegra_dsi_set_phy_timing(dsi->slave, 
static int <token> mipi_dsi_pixel_format format, <answer> tegra_dsi_get_muldiv(enum 
unsigned int *mulp, unsigned int <token> <answer> *divp) 
<token> (format) { <answer> switch 
<token> MIPI_DSI_FMT_RGB666_PACKED: <answer> case 
case <token> <answer> MIPI_DSI_FMT_RGB888: 
*mulp <token> 3; <answer> = 
<token> = 1; <answer> *divp 
<token> MIPI_DSI_FMT_RGB565: <answer> case 
*mulp = <token> <answer> 2; 
<token> = 1; <answer> *divp 
<token> MIPI_DSI_FMT_RGB666: <answer> case 
*mulp = <token> <answer> 9; 
*divp = <token> <answer> 4; 
return <token> <answer> -EINVAL; 
<token> 0; <answer> return 
static <token> tegra_dsi_get_format(enum mipi_dsi_pixel_format format, <answer> int 
enum <token> *fmt) <answer> tegra_dsi_format 
switch (format) <token> <answer> { 
<token> MIPI_DSI_FMT_RGB888: <answer> case 
*fmt <token> TEGRA_DSI_FORMAT_24P; <answer> = 
case <token> <answer> MIPI_DSI_FMT_RGB666: 
*fmt <token> TEGRA_DSI_FORMAT_18NP; <answer> = 
case <token> <answer> MIPI_DSI_FMT_RGB666_PACKED: 
*fmt <token> TEGRA_DSI_FORMAT_18P; <answer> = 
case <token> <answer> MIPI_DSI_FMT_RGB565: 
*fmt <token> TEGRA_DSI_FORMAT_16P; <answer> = 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
static void tegra_dsi_ganged_enable(struct tegra_dsi *dsi, <token> int start, <answer> unsigned 
<token> int size) <answer> unsigned 
u32 <token> <answer> value; 
<token> start, DSI_GANGED_MODE_START); <answer> tegra_dsi_writel(dsi, 
tegra_dsi_writel(dsi, <token> << 16 | size, DSI_GANGED_MODE_SIZE); <answer> size 
<token> = DSI_GANGED_MODE_CONTROL_ENABLE; <answer> value 
tegra_dsi_writel(dsi, <token> DSI_GANGED_MODE_CONTROL); <answer> value, 
static void tegra_dsi_enable(struct <token> *dsi) <answer> tegra_dsi 
<token> value; <answer> u32 
<token> = tegra_dsi_readl(dsi, DSI_POWER_CONTROL); <answer> value 
value |= <token> <answer> DSI_POWER_CONTROL_ENABLE; 
tegra_dsi_writel(dsi, <token> DSI_POWER_CONTROL); <answer> value, 
<token> (dsi->slave) <answer> if 
static unsigned <token> tegra_dsi_get_lanes(struct tegra_dsi *dsi) <answer> int 
<token> (dsi->master) <answer> if 
return <token> + dsi->lanes; <answer> dsi->master->lanes 
if <token> <answer> (dsi->slave) 
return dsi->lanes <token> dsi->slave->lanes; <answer> + 
<token> dsi->lanes; <answer> return 
static void tegra_dsi_configure(struct tegra_dsi *dsi, <token> int pipe, <answer> unsigned 
const struct <token> *mode) <answer> drm_display_mode 
unsigned int hact, hsw, hbp, hfp, <token> mul, div; <answer> i, 
struct tegra_dsi_state <token> <answer> *state; 
const u32 <token> <answer> *pkt_seq; 
u32 <token> <answer> value; 
bytes = <token> + (mode->hdisplay / 2) * mul / div; <answer> 1 
} <token> { <answer> else 
<token> 0, mode->hdisplay / 2); <answer> tegra_dsi_ganged_enable(dsi, 
tegra_dsi_ganged_enable(dsi->slave, mode->hdisplay <token> 2, <answer> / 
mode->hdisplay <token> 2); <answer> / 
static <token> tegra_dsi_wait_idle(struct tegra_dsi *dsi, unsigned long timeout) <answer> int 
<token> value; <answer> u32 
timeout = jiffies <token> msecs_to_jiffies(timeout); <answer> + 
while <token> timeout)) { <answer> (time_before(jiffies, 
<token> = tegra_dsi_readl(dsi, DSI_STATUS); <answer> value 
<token> (value & DSI_STATUS_IDLE) <answer> if 
<token> 0; <answer> return 
usleep_range(1000, <token> <answer> 2000); 
<token> -ETIMEDOUT; <answer> return 
static void <token> tegra_dsi *dsi) <answer> tegra_dsi_video_disable(struct 
<token> value; <answer> u32 
value = <token> DSI_CONTROL); <answer> tegra_dsi_readl(dsi, 
<token> &= ~DSI_CONTROL_VIDEO_ENABLE; <answer> value 
tegra_dsi_writel(dsi, <token> DSI_CONTROL); <answer> value, 
<token> (dsi->slave) <answer> if 
static void tegra_dsi_ganged_disable(struct tegra_dsi <token> <answer> *dsi) 
tegra_dsi_writel(dsi, <token> DSI_GANGED_MODE_START); <answer> 0, 
<token> 0, DSI_GANGED_MODE_SIZE); <answer> tegra_dsi_writel(dsi, 
tegra_dsi_writel(dsi, 0, <token> <answer> DSI_GANGED_MODE_CONTROL); 
static int tegra_dsi_pad_enable(struct tegra_dsi <token> <answer> *dsi) 
u32 <token> <answer> value; 
value <token> DSI_PAD_CONTROL_VS1_PULLDN(0) | DSI_PAD_CONTROL_VS1_PDIO(0); <answer> = 
tegra_dsi_writel(dsi, <token> DSI_PAD_CONTROL_0); <answer> value, 
return <token> <answer> 0; 
static int tegra_dsi_pad_calibrate(struct <token> *dsi) <answer> tegra_dsi 
<token> value; <answer> u32 
int <token> <answer> err; 
tegra_dsi_writel(dsi, <token> DSI_PAD_CONTROL_0); <answer> 0, 
<token> 0, DSI_PAD_CONTROL_1); <answer> tegra_dsi_writel(dsi, 
<token> 0, DSI_PAD_CONTROL_2); <answer> tegra_dsi_writel(dsi, 
tegra_dsi_writel(dsi, 0, <token> <answer> DSI_PAD_CONTROL_3); 
tegra_dsi_writel(dsi, 0, <token> <answer> DSI_PAD_CONTROL_4); 
if <token> { <answer> (dc) 
<token> = tegra_dc_readl(dc, DC_DISP_DISP_WIN_OPTIONS); <answer> value 
<token> &= ~DSI_ENABLE; <answer> value 
tegra_dc_writel(dc, <token> DC_DISP_DISP_WIN_OPTIONS); <answer> value, 
err <token> tegra_dsi_wait_idle(dsi, 100); <answer> = 
if (err <token> 0) <answer> < 
dev_dbg(dsi->dev, "failed to idle <token> %d\n", err); <answer> DSI: 
if <token> <answer> (output->panel) 
static <token> tegra_dsi_prepare(struct tegra_dsi *dsi) <answer> int 
<token> err; <answer> int 
err = <token> <answer> host1x_client_resume(&dsi->client); 
if (err <token> 0) { <answer> < 
dev_err(dsi->dev, "failed to resume: <token> err); <answer> %d\n", 
<token> err; <answer> return 
err <token> tegra_mipi_enable(dsi->mipi); <answer> = 
<token> (err < 0) <answer> if 
dev_err(dsi->dev, "failed to enable MIPI <token> %d\n", <answer> calibration: 
<token> = tegra_dsi_pad_calibrate(dsi); <answer> err 
if <token> < 0) <answer> (err 
dev_err(dsi->dev, "MIPI calibration failed: %d\n", <token> <answer> err); 
if <token> <answer> (dsi->slave) 
return <token> <answer> 0; 
static void tegra_dsi_encoder_enable(struct <token> *encoder) <answer> drm_encoder 
struct drm_display_mode *mode <token> &encoder->crtc->state->adjusted_mode; <answer> = 
struct tegra_output <token> = encoder_to_output(encoder); <answer> *output 
<token> tegra_dc *dc = to_tegra_dc(encoder->crtc); <answer> struct 
<token> tegra_dsi *dsi = to_dsi(output); <answer> struct 
struct <token> *state; <answer> tegra_dsi_state 
<token> value; <answer> u32 
<token> err; <answer> int 
value = tegra_dsi_readl(dsi, <token> <answer> DSI_POWER_CONTROL); 
<token> (value & DSI_POWER_CONTROL_ENABLE) <answer> if 
err = <token> <answer> tegra_dsi_prepare(dsi); 
if (err < 0) <token> <answer> { 
dev_err(dsi->dev, "failed to prepare: %d\n", <token> <answer> err); 
<token> = tegra_dsi_get_state(dsi); <answer> state 
tegra_dsi_set_timeout(dsi, <token> state->vrefresh); <answer> state->bclk, 
tegra_dsi_set_phy_timing(dsi, state->period <token> 8, &state->timing); <answer> * 
if <token> <answer> (output->panel) 
tegra_dsi_configure(dsi, dc->pipe, <token> <answer> mode); 
plld = DIV_ROUND_UP(state->bclk * 8, USEC_PER_SEC) <token> USEC_PER_SEC; <answer> * 
<token> = DIV_ROUND_CLOSEST(NSEC_PER_SEC, plld); <answer> state->period 
err = mipi_dphy_timing_get_default(&state->timing, <token> <answer> state->period); 
<token> (err < 0) <answer> if 
<token> err; <answer> return 
err = mipi_dphy_timing_validate(&state->timing, <token> <answer> state->period); 
<token> (err < 0) { <answer> if 
dev_err(dsi->dev, "failed <token> validate D-PHY timing: %d\n", err); <answer> to 
<token> err; <answer> return 
<token> /= 2; <answer> plld 
<token> = ((8 * state->mul) / (state->div * state->lanes)) - 2; <answer> scdiv 
err = <token> crtc_state, dsi->clk_parent, <answer> tegra_dc_state_setup_clock(dc, 
<token> scdiv); <answer> plld, 
if (err < <token> { <answer> 0) 
dev_err(output->dev, "failed to setup <token> state: %d\n", err); <answer> CRTC 
return <token> <answer> err; 
return <token> <answer> err; 
static const struct <token> tegra_dsi_encoder_helper_funcs = { <answer> drm_encoder_helper_funcs 
.disable <token> tegra_dsi_encoder_disable, <answer> = 
.enable <token> tegra_dsi_encoder_enable, <answer> = 
.atomic_check = <token> <answer> tegra_dsi_encoder_atomic_check, 
static int tegra_dsi_init(struct host1x_client <token> <answer> *client) 
struct drm_device *drm = <token> <answer> dev_get_drvdata(client->host); 
struct tegra_dsi *dsi <token> host1x_client_to_dsi(client); <answer> = 
int <token> <answer> err; 
<token> (packet.size > dsi->host_fifo_depth * 4) <answer> if 
value <token> DSI_HOST_CONTROL_FIFO_SEL; <answer> |= 
tegra_dsi_writel(dsi, value, <token> <answer> DSI_HOST_CONTROL); 
<token> ((msg->flags & MIPI_DSI_MSG_REQ_ACK) || <answer> if 
<token> && msg->rx_len > 0)) { <answer> (msg->rx_buf 
value = tegra_dsi_readl(dsi, <token> <answer> DSI_HOST_CONTROL); 
value |= <token> <answer> DSI_HOST_CONTROL_PKT_BTA; 
tegra_dsi_writel(dsi, value, <token> <answer> DSI_HOST_CONTROL); 
value <token> DSI_CONTROL_LANES(0) | DSI_CONTROL_HOST_ENABLE; <answer> = 
tegra_dsi_writel(dsi, value, <token> <answer> DSI_CONTROL); 
case <token> <answer> 0x87: 
dev_err(dsi->dev, "unknown status: %08x\n", <token> <answer> value); 
<token> (count > 1) { <answer> if 
err = <token> msg, count); <answer> tegra_dsi_read_response(dsi, 
<token> (err < 0) <answer> if 
"failed to parse response: <token> <answer> %zd\n", 
<token> { <answer> else 
count = <token> <answer> err; 
} else <token> <answer> { 
count = <token> + packet.payload_length; <answer> 4 
return <token> <answer> count; 
static int <token> tegra_dsi *dsi) <answer> tegra_dsi_ganged_setup(struct 
<token> clk *parent; <answer> struct 
int <token> <answer> err; 
if <token> { <answer> (!dsi->master) 
struct tegra_output *output = <token> <answer> &dsi->output; 
output->panel <token> of_drm_find_panel(device->dev.of_node); <answer> = 
<token> (IS_ERR(output->panel)) <answer> if 
output->panel = <token> <answer> NULL; 
<token> (output->panel && output->connector.dev) <answer> if 
return <token> <answer> 0; 
<token> int tegra_dsi_host_detach(struct mipi_dsi_host *host, <answer> static 
struct mipi_dsi_device <token> <answer> *device) 
struct tegra_dsi *dsi = <token> <answer> host_to_tegra(host); 
<token> tegra_output *output = &dsi->output; <answer> struct 
if (output->panel <token> &device->dev == output->panel->dev) { <answer> && 
output->panel = <token> <answer> NULL; 
<token> (output->connector.dev) <answer> if 
return <token> <answer> 0; 
<token> const struct mipi_dsi_host_ops tegra_dsi_host_ops = { <answer> static 
.attach <token> tegra_dsi_host_attach, <answer> = 
.detach = <token> <answer> tegra_dsi_host_detach, 
.transfer = <token> <answer> tegra_dsi_host_transfer, 
static int <token> tegra_dsi *dsi) <answer> tegra_dsi_ganged_probe(struct 
struct <token> *np; <answer> device_node 
np = of_parse_phandle(dsi->dev->of_node, "nvidia,ganged-mode", <token> <answer> 0); 
if <token> { <answer> (np) 
struct platform_device <token> = of_find_device_by_node(np); <answer> *gangster 
<token> (!gangster) <answer> if 
<token> -EPROBE_DEFER; <answer> return 
dsi->slave = <token> <answer> platform_get_drvdata(gangster); 
if (!dsi->slave) <token> <answer> { 
return <token> <answer> -EPROBE_DEFER; 
dsi->slave->master = <token> <answer> dsi; 
return <token> <answer> 0; 
static int tegra_dsi_probe(struct <token> *pdev) <answer> platform_device 
<token> tegra_dsi *dsi; <answer> struct 
<token> resource *regs; <answer> struct 
<token> err; <answer> int 
dsi = devm_kzalloc(&pdev->dev, sizeof(*dsi), <token> <answer> GFP_KERNEL); 
<token> (!dsi) <answer> if 
<token> -ENOMEM; <answer> return 
dsi->output.dev = dsi->dev <token> &pdev->dev; <answer> = 
<token> = 1920; <answer> dsi->video_fifo_depth 
dsi->host_fifo_depth = <token> <answer> 64; 
err = <token> <answer> tegra_dsi_ganged_probe(dsi); 
if (err <token> 0) <answer> < 
<token> err; <answer> return 
err <token> tegra_output_probe(&dsi->output); <answer> = 
<token> (err < 0) <answer> if 
<token> err; <answer> return 
<token> = DRM_CONNECTOR_POLL_HPD; <answer> dsi->output.connector.polled 
dsi->flags = <token> <answer> MIPI_DSI_MODE_VIDEO; 
dsi->format = <token> <answer> MIPI_DSI_FMT_RGB888; 
dsi->lanes = <token> <answer> 4; 
if <token> { <answer> (!pdev->dev.pm_domain) 
dsi->rst = <token> "dsi"); <answer> devm_reset_control_get(&pdev->dev, 
<token> (IS_ERR(dsi->rst)) { <answer> if 
err <token> PTR_ERR(dsi->rst); <answer> = 
<token> remove; <answer> goto 
<token> = devm_clk_get(&pdev->dev, NULL); <answer> dsi->clk 
if <token> { <answer> (IS_ERR(dsi->clk)) 
err <token> dev_err_probe(&pdev->dev, PTR_ERR(dsi->clk), <answer> = 
"cannot get DSI <token> <answer> clock\n"); 
goto <token> <answer> remove; 
dsi->clk_lp <token> devm_clk_get(&pdev->dev, "lp"); <answer> = 
if <token> { <answer> (IS_ERR(dsi->clk_lp)) 
err = <token> PTR_ERR(dsi->clk_lp), <answer> dev_err_probe(&pdev->dev, 
"cannot <token> low-power clock\n"); <answer> get 
<token> remove; <answer> goto 
dsi->clk_parent = devm_clk_get(&pdev->dev, <token> <answer> "parent"); 
<token> (IS_ERR(dsi->clk_parent)) { <answer> if 
err = <token> PTR_ERR(dsi->clk_parent), <answer> dev_err_probe(&pdev->dev, 
"cannot get <token> clock\n"); <answer> parent 
goto <token> <answer> remove; 
dsi->vdd <token> devm_regulator_get(&pdev->dev, "avdd-dsi-csi"); <answer> = 
if <token> { <answer> (IS_ERR(dsi->vdd)) 
err = <token> PTR_ERR(dsi->vdd), <answer> dev_err_probe(&pdev->dev, 
"cannot get <token> supply\n"); <answer> VDD 
<token> remove; <answer> goto 
err <token> tegra_dsi_setup_clocks(dsi); <answer> = 
if (err < <token> { <answer> 0) 
dev_err(&pdev->dev, "cannot setup <token> <answer> clocks\n"); 
<token> remove; <answer> goto 
regs <token> platform_get_resource(pdev, IORESOURCE_MEM, 0); <answer> = 
dsi->regs = <token> regs); <answer> devm_ioremap_resource(&pdev->dev, 
if <token> { <answer> (IS_ERR(dsi->regs)) 
err <token> PTR_ERR(dsi->regs); <answer> = 
goto <token> <answer> remove; 
dsi->mipi = tegra_mipi_request(&pdev->dev, <token> <answer> pdev->dev.of_node); 
<token> (IS_ERR(dsi->mipi)) { <answer> if 
err <token> PTR_ERR(dsi->mipi); <answer> = 
goto <token> <answer> remove; 
<token> = &tegra_dsi_host_ops; <answer> dsi->host.ops 
<token> = &pdev->dev; <answer> dsi->host.dev 
<token> = mipi_dsi_host_register(&dsi->host); <answer> err 
<token> (err < 0) { <answer> if 
dev_err(&pdev->dev, "failed to register DSI host: %d\n", <token> <answer> err); 
goto <token> <answer> mipi_free; 
<token> dsi); <answer> platform_set_drvdata(pdev, 
<token> = &dsi_client_ops; <answer> dsi->client.ops 
dsi->client.dev = <token> <answer> &pdev->dev; 
err = <token> <answer> host1x_client_register(&dsi->client); 
if (err <token> 0) { <answer> < 
dev_err(&pdev->dev, "failed to register host1x <token> %d\n", <answer> client: 
goto <token> <answer> unregister; 
return <token> <answer> 0; 
return <token> <answer> err; 
static <token> tegra_dsi_remove(struct platform_device *pdev) <answer> void 
<token> tegra_dsi *dsi = platform_get_drvdata(pdev); <answer> struct 
static <token> struct of_device_id tegra_dsi_of_match[] = { <answer> const 
{ .compatible = <token> }, <answer> "nvidia,tegra210-dsi", 
{ .compatible = "nvidia,tegra132-dsi", <token> <answer> }, 
{ .compatible = <token> }, <answer> "nvidia,tegra124-dsi", 
{ .compatible <token> "nvidia,tegra114-dsi", }, <answer> = 
{ <token> <answer> }, 
MODULE_DEVICE_TABLE(of, <token> <answer> tegra_dsi_of_match); 
struct <token> tegra_dsi_driver = { <answer> platform_driver 
<token> = { <answer> .driver 
<token> = "tegra-dsi", <answer> .name 
.of_match_table <token> tegra_dsi_of_match, <answer> = 
<token> = tegra_dsi_probe, <answer> .probe 
<token> = tegra_dsi_remove, <answer> .remove_new 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/of_net.h> <answer> #include 
#include <token> <answer> <linux/of_address.h> 
<token> <linux/if_vlan.h> <answer> #include 
<token> <linux/pm_runtime.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/soc/ti/knav_qmss.h> <answer> #include 
#include <token> <answer> <linux/soc/ti/knav_dma.h> 
<token> "netcp.h" <answer> #include 
#define NETCP_SOP_OFFSET <token> + NET_SKB_PAD) <answer> (NET_IP_ALIGN 
#define NETCP_TX_TIMEOUT <token> * HZ) <answer> (5 
#define NETCP_PACKET_SIZE (ETH_FRAME_LEN <token> ETH_FCS_LEN) <answer> + 
<token> NETCP_MIN_PACKET_SIZE ETH_ZLEN <answer> #define 
<token> NETCP_MAX_MCAST_ADDR 16 <answer> #define 
#define NETCP_EFUSE_REG_INDEX <token> <answer> 0 
#define NETCP_MOD_PROBE_SKIPPED <token> <answer> 1 
#define <token> 2 <answer> NETCP_MOD_PROBE_FAILED 
#define NETCP_DEBUG (NETIF_MSG_HW | NETIF_MSG_WOL | <token> <answer> \ 
NETIF_MSG_DRV | NETIF_MSG_LINK | <token> <answer> \ 
NETIF_MSG_IFUP <token> NETIF_MSG_INTR | \ <answer> | 
NETIF_MSG_PROBE | NETIF_MSG_TIMER <token> \ <answer> | 
<token> | NETIF_MSG_RX_ERR | \ <answer> NETIF_MSG_IFDOWN 
NETIF_MSG_TX_ERR <token> NETIF_MSG_TX_DONE | \ <answer> | 
NETIF_MSG_PKTDATA | NETIF_MSG_TX_QUEUED <token> \ <answer> | 
#define <token> 2 <answer> NETCP_EFUSE_ADDR_SWAP 
#define <token> knav_queue_device_control(q, \ <answer> knav_queue_get_id(q) 
<token> (unsigned long)NULL) <answer> KNAV_QUEUE_GET_ID, 
#define knav_queue_enable_notify(q) knav_queue_device_control(q, <token> <answer> \ 
<token> \ <answer> KNAV_QUEUE_ENABLE_NOTIFY, 
<token> long)NULL) <answer> (unsigned 
#define <token> knav_queue_device_control(q, \ <answer> knav_queue_disable_notify(q) 
KNAV_QUEUE_DISABLE_NOTIFY, <token> <answer> \ 
<token> long)NULL) <answer> (unsigned 
<token> knav_queue_get_count(q) knav_queue_device_control(q, \ <answer> #define 
KNAV_QUEUE_GET_COUNT, (unsigned <token> <answer> long)NULL) 
#define <token> \ <answer> for_each_netcp_module(module) 
<token> &netcp_modules, module_list) <answer> list_for_each_entry(module, 
#define for_each_netcp_device_module(netcp_device, inst_modpriv) <token> <answer> \ 
list_for_each_entry(inst_modpriv, <token> <answer> \ 
<token> inst_list) <answer> &((netcp_device)->modpriv_head), 
#define <token> intf_modpriv) \ <answer> for_each_module(netcp, 
list_for_each_entry(intf_modpriv, <token> intf_list) <answer> &netcp->module_head, 
<token> = (void *)GET_SW_DATA0(ndesc); <answer> buf_ptr 
<token> = (int)GET_SW_DATA1(desc); <answer> buf_len 
dma_unmap_page(netcp->dev, <token> PAGE_SIZE, DMA_FROM_DEVICE); <answer> dma_buf, 
knav_pool_desc_put(netcp->rx_pool, <token> <answer> desc); 
<token> = (void *)GET_SW_DATA0(desc); <answer> buf_ptr 
buf_len <token> (int)GET_SW_DATA1(desc); <answer> = 
<token> (buf_ptr) <answer> if 
<token> <= PAGE_SIZE, buf_ptr); <answer> netcp_frag_free(buf_len 
knav_pool_desc_put(netcp->rx_pool, <token> <answer> desc); 
static <token> netcp_empty_rx_queue(struct netcp_intf *netcp) <answer> void 
struct <token> *rx_stats = &netcp->stats; <answer> netcp_stats 
<token> knav_dma_desc *desc; <answer> struct 
unsigned int <token> <answer> dma_sz; 
dma_addr_t <token> <answer> dma; 
for (; ;) <token> <answer> { 
<token> = knav_queue_pop(netcp->rx_queue, &dma_sz); <answer> dma 
<token> (!dma) <answer> if 
desc <token> knav_pool_desc_unmap(netcp->rx_pool, dma, dma_sz); <answer> = 
if (unlikely(!desc)) <token> <answer> { 
dev_err(netcp->ndev_dev, "%s: failed to <token> Rx desc\n", <answer> unmap 
<token> desc); <answer> netcp_free_rx_desc_chain(netcp, 
static <token> netcp_process_one_rx_packet(struct netcp_intf *netcp) <answer> int 
<token> netcp_stats *rx_stats = &netcp->stats; <answer> struct 
unsigned int <token> buf_len, org_buf_len; <answer> dma_sz, 
<token> knav_dma_desc *desc, *ndesc; <answer> struct 
unsigned int pkt_sz = 0, <token> <answer> accum_sz; 
struct netcp_hook_list <token> <answer> *rx_hook; 
<token> dma_desc, dma_buff; <answer> dma_addr_t 
<token> netcp_packet p_info; <answer> struct 
<token> sk_buff *skb; <answer> struct 
<token> *org_buf_ptr; <answer> void 
u32 <token> <answer> tmp; 
dma_desc <token> knav_queue_pop(netcp->rx_queue, &dma_sz); <answer> = 
<token> (!dma_desc) <answer> if 
<token> -1; <answer> return 
<token> = knav_pool_desc_unmap(netcp->rx_pool, dma_desc, dma_sz); <answer> desc 
<token> (unlikely(!desc)) { <answer> if 
dev_err(netcp->ndev_dev, "failed to <token> Rx desc\n"); <answer> unmap 
<token> 0; <answer> return 
<token> &buf_len, &dma_desc, desc); <answer> get_pkt_info(&dma_buff, 
org_buf_ptr <token> (void *)GET_SW_DATA0(desc); <answer> = 
org_buf_len = <token> <answer> (int)GET_SW_DATA1(desc); 
<token> (unlikely(!org_buf_ptr)) { <answer> if 
dev_err(netcp->ndev_dev, "NULL <token> in desc\n"); <answer> bufptr 
goto <token> <answer> free_desc; 
pkt_sz <token> KNAV_DMA_DESC_PKT_LEN_MASK; <answer> &= 
accum_sz <token> buf_len; <answer> = 
dma_unmap_single(netcp->dev, dma_buff, buf_len, <token> <answer> DMA_FROM_DEVICE); 
page = <token> page *)GET_SW_DATA0(ndesc); <answer> (struct 
if <token> && buf_len && page)) { <answer> (likely(dma_buff 
dma_unmap_page(netcp->dev, dma_buff, <token> <answer> PAGE_SIZE, 
} <token> { <answer> else 
dev_err(netcp->ndev_dev, "Bad Rx desc dma_buff(%pad), len(%d), <token> <answer> page(%p)\n", 
&dma_buff, <token> page); <answer> buf_len, 
<token> free_desc; <answer> goto 
<token> skb_shinfo(skb)->nr_frags, page, <answer> skb_add_rx_frag(skb, 
<token> buf_len, PAGE_SIZE); <answer> offset_in_page(dma_buff), 
accum_sz += <token> <answer> buf_len; 
if (!(netcp->hw_cap & <token> <answer> ETH_SW_CAN_REMOVE_ETH_FCS)) 
<token> skb->len - ETH_FCS_LEN); <answer> __pskb_trim(skb, 
buf_ptr = (void <token> <answer> *)GET_SW_DATA0(desc); 
if (unlikely(!dma)) <token> <answer> { 
dev_err(netcp->ndev_dev, "NULL <token> in desc\n"); <answer> orig_buff 
<token> desc); <answer> knav_pool_desc_put(netcp->rx_pool, 
if (unlikely(!buf_ptr)) <token> <answer> { 
dev_err(netcp->ndev_dev, <token> bufptr in desc\n"); <answer> "NULL 
<token> desc); <answer> knav_pool_desc_put(netcp->rx_pool, 
if (fdq == <token> { <answer> 0) 
<token> dma, buf_len, <answer> dma_unmap_single(netcp->dev, 
<token> <= PAGE_SIZE), buf_ptr); <answer> netcp_frag_free((buf_len 
} <token> { <answer> else 
dma_unmap_page(netcp->dev, dma, <token> <answer> buf_len, 
knav_pool_desc_put(netcp->rx_pool, <token> <answer> desc); 
static void netcp_rxpool_free(struct netcp_intf <token> <answer> *netcp) 
<token> i; <answer> int 
<token> (i = 0; i < KNAV_DMA_FDQ_PER_CHAN && <answer> for 
<token> i++) <answer> !IS_ERR_OR_NULL(netcp->rx_fdq[i]); 
netcp_free_rx_buf(netcp, <token> <answer> i); 
<token> (knav_pool_count(netcp->rx_pool) != netcp->rx_pool_size) <answer> if 
dev_err(netcp->ndev_dev, "Lost <token> (%d) descriptors\n", <answer> Rx 
<token> - knav_pool_count(netcp->rx_pool)); <answer> netcp->rx_pool_size 
<token> = NULL; <answer> netcp->rx_pool 
static int netcp_allocate_rx_buf(struct netcp_intf *netcp, <token> fdq) <answer> int 
struct knav_dma_desc <token> <answer> *hwdesc; 
unsigned int buf_len, <token> <answer> dma_sz; 
u32 <token> pkt_info; <answer> desc_info, 
struct page <token> <answer> *page; 
dma_addr_t <token> <answer> dma; 
void <token> <answer> *bufptr; 
u32 <token> <answer> sw_data[2]; 
sw_data[0] = <token> <answer> (u32)bufptr; 
<token> else { <answer> } 
sw_data[0] = <token> <answer> (u32)page; 
sw_data[1] <token> 0; <answer> = 
<token> = KNAV_DMA_DESC_PS_INFO_IN_DESC; <answer> desc_info 
desc_info |= <token> & KNAV_DMA_DESC_PKT_LEN_MASK; <answer> buf_len 
<token> = KNAV_DMA_DESC_HAS_EPIB; <answer> pkt_info 
<token> |= KNAV_DMA_NUM_PS_WORDS << KNAV_DMA_DESC_PSLEN_SHIFT; <answer> pkt_info 
pkt_info |= <token> & KNAV_DMA_DESC_RETQ_MASK) << <answer> (netcp->rx_queue_id 
set_org_pkt_info(dma, buf_len, <token> <answer> hwdesc); 
<token> hwdesc); <answer> SET_SW_DATA0(sw_data[0], 
<token> hwdesc); <answer> SET_SW_DATA1(sw_data[1], 
set_desc_info(desc_info, pkt_info, <token> <answer> hwdesc); 
skb = <token> sk_buff *)GET_SW_DATA0(desc); <answer> (struct 
netcp_free_tx_desc_chain(netcp, desc, <token> <answer> dma_sz); 
if (!skb) <token> <answer> { 
dev_err(netcp->ndev_dev, "No skb <token> Tx desc\n"); <answer> in 
<token> = (struct netcp_tx_cb *)skb->cb; <answer> tx_cb 
<token> (tx_cb->txtstamp) <answer> if 
<token> skb); <answer> tx_cb->txtstamp(tx_cb->ts_context, 
if (netif_subqueue_stopped(netcp->ndev, skb) <token> <answer> && 
netif_running(netcp->ndev) <token> <answer> && 
<token> > <answer> (knav_pool_count(netcp->tx_pool) 
<token> { <answer> netcp->tx_resume_threshold)) 
u16 <token> = skb_get_queue_mapping(skb); <answer> subqueue 
<token> subqueue); <answer> netif_wake_subqueue(netcp->ndev, 
<token> += skb->len; <answer> tx_stats->tx_bytes 
return <token> <answer> pkts; 
static int netcp_tx_poll(struct <token> *napi, int budget) <answer> napi_struct 
int <token> <answer> packets; 
struct netcp_intf *netcp = <token> struct netcp_intf, <answer> container_of(napi, 
packets = netcp_process_tx_compl_packets(netcp, <token> <answer> budget); 
if (packets <token> budget) { <answer> < 
return <token> <answer> packets; 
<token> void netcp_tx_notify(void *arg) <answer> static 
struct <token> *netcp = arg; <answer> netcp_intf 
static <token> knav_dma_desc* <answer> struct 
netcp_tx_map_skb(struct sk_buff *skb, struct netcp_intf <token> <answer> *netcp) 
struct knav_dma_desc *desc, <token> *pdesc; <answer> *ndesc, 
unsigned <token> pkt_len = skb_headlen(skb); <answer> int 
struct device *dev <token> netcp->dev; <answer> = 
<token> dma_addr; <answer> dma_addr_t 
<token> int dma_sz; <answer> unsigned 
int <token> <answer> i; 
<token> desc); <answer> SET_SW_DATA0((u32)skb, 
<token> (tx_pipe->flags & SWITCH_TO_PORT_IN_TAGINFO) { <answer> if 
<token> = tx_pipe->switch_to_port; <answer> tmp 
set_words(&tmp, 1, <token> <answer> &desc->tag_info); 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/moduleparam.h> <answer> #include 
#include <token> <answer> <linux/usb.h> 
#include <token> <answer> <linux/input.h> 
#include <token> <answer> <linux/usb/input.h> 
#define <token> 0x06cb <answer> USB_VENDOR_ID_SYNAPTICS 
if (pressure <token> 30) <answer> > 
<token> BTN_TOUCH, 1); <answer> input_report_key(input_dev, 
<token> (pressure < 25) <answer> if 
input_report_key(input_dev, <token> 0); <answer> BTN_TOUCH, 
<token> (num_fingers > 0) { <answer> if 
input_report_abs(input_dev, ABS_X, <token> <answer> x); 
input_report_abs(input_dev, <token> <answer> ABS_Y, 
<token> + YMIN_NOMINAL - y); <answer> YMAX_NOMINAL 
<token> ABS_PRESSURE, pressure); <answer> input_report_abs(input_dev, 
input_report_abs(input_dev, ABS_TOOL_WIDTH, <token> <answer> tool_width); 
<token> BTN_TOOL_FINGER, num_fingers == 1); <answer> input_report_key(input_dev, 
input_report_key(input_dev, BTN_TOOL_DOUBLETAP, <token> == 2); <answer> num_fingers 
<token> BTN_TOOL_TRIPLETAP, num_fingers == 3); <answer> input_report_key(input_dev, 
if (synusb->flags & <token> <answer> SYNUSB_AUXDISPLAY) 
input_report_key(input_dev, BTN_MIDDLE, <token> & 0x08); <answer> synusb->data[1] 
static void <token> urb *urb) <answer> synusb_irq(struct 
struct <token> *synusb = urb->context; <answer> synusb 
int <token> <answer> error; 
synusb->flags |= intf_num <token> 1 ? <answer> == 
SYNUSB_STICK <token> SYNUSB_TOUCHPAD; <answer> : 
synusb->urb <token> usb_alloc_urb(0, GFP_KERNEL); <answer> = 
if (!synusb->urb) <token> <answer> { 
<token> = -ENOMEM; <answer> error 
goto <token> <answer> err_free_mem; 
synusb->data = <token> SYNUSB_RECV_SIZE, GFP_KERNEL, <answer> usb_alloc_coherent(udev, 
if (!synusb->data) <token> <answer> { 
error = <token> <answer> -ENOMEM; 
goto <token> <answer> err_free_urb; 
<token> udev, <answer> usb_fill_int_urb(synusb->urb, 
usb_rcvintpipe(udev, <token> <answer> ep->bEndpointAddress), 
synusb->data, <token> <answer> SYNUSB_RECV_SIZE, 
<token> synusb, <answer> synusb_irq, 
synusb->urb->transfer_flags |= <token> <answer> URB_NO_TRANSFER_DMA_MAP; 
if <token> <answer> (udev->manufacturer) 
<token> udev->manufacturer, <answer> strscpy(synusb->name, 
if <token> { <answer> (udev->product) 
if <token> <answer> (udev->manufacturer) 
<token> " ", sizeof(synusb->name)); <answer> strlcat(synusb->name, 
<token> udev->product, sizeof(synusb->name)); <answer> strlcat(synusb->name, 
<token> (!strlen(synusb->name)) <answer> if 
snprintf(synusb->name, <token> <answer> sizeof(synusb->name), 
"USB <token> Device %04x:%04x", <answer> Synaptics 
if (synusb->flags <token> SYNUSB_STICK) <answer> & 
strlcat(synusb->name, <token> (Stick)", sizeof(synusb->name)); <answer> " 
usb_make_path(udev, synusb->phys, <token> <answer> sizeof(synusb->phys)); 
strlcat(synusb->phys, "/input0", <token> <answer> sizeof(synusb->phys)); 
input_dev->name <token> synusb->name; <answer> = 
<token> = synusb->phys; <answer> input_dev->phys 
usb_to_input_id(udev, <token> <answer> &input_dev->id); 
input_dev->dev.parent <token> &synusb->intf->dev; <answer> = 
if (!(synusb->flags & <token> { <answer> SYNUSB_IO_ALWAYS)) 
input_dev->open <token> synusb_open; <answer> = 
input_dev->close = <token> <answer> synusb_close; 
input_set_drvdata(input_dev, <token> <answer> synusb); 
__set_bit(EV_ABS, <token> <answer> input_dev->evbit); 
__set_bit(EV_KEY, <token> <answer> input_dev->evbit); 
if (synusb->flags & <token> { <answer> SYNUSB_STICK) 
__set_bit(EV_REL, <token> <answer> input_dev->evbit); 
<token> input_dev->relbit); <answer> __set_bit(REL_X, 
<token> input_dev->relbit); <answer> __set_bit(REL_Y, 
__set_bit(INPUT_PROP_POINTING_STICK, <token> <answer> input_dev->propbit); 
<token> ABS_PRESSURE, 0, 127, 0, 0); <answer> input_set_abs_params(input_dev, 
} else <token> <answer> { 
input_set_abs_params(input_dev, <token> <answer> ABS_X, 
XMIN_NOMINAL, <token> 0, 0); <answer> XMAX_NOMINAL, 
input_set_abs_params(input_dev, <token> <answer> ABS_Y, 
YMIN_NOMINAL, YMAX_NOMINAL, <token> 0); <answer> 0, 
<token> ABS_PRESSURE, 0, 255, 0, 0); <answer> input_set_abs_params(input_dev, 
input_set_abs_params(input_dev, ABS_TOOL_WIDTH, 0, <token> 0, 0); <answer> 15, 
__set_bit(BTN_TOUCH, <token> <answer> input_dev->keybit); 
<token> input_dev->keybit); <answer> __set_bit(BTN_TOOL_FINGER, 
__set_bit(BTN_TOOL_DOUBLETAP, <token> <answer> input_dev->keybit); 
__set_bit(BTN_TOOL_TRIPLETAP, <token> <answer> input_dev->keybit); 
<token> (synusb->flags & SYNUSB_TOUCHSCREEN) <answer> if 
<token> input_dev->propbit); <answer> __set_bit(INPUT_PROP_DIRECT, 
<token> input_dev->propbit); <answer> __set_bit(INPUT_PROP_POINTER, 
<token> input_dev->keybit); <answer> __set_bit(BTN_LEFT, 
__set_bit(BTN_RIGHT, <token> <answer> input_dev->keybit); 
<token> input_dev->keybit); <answer> __set_bit(BTN_MIDDLE, 
<token> synusb); <answer> usb_set_intfdata(intf, 
if <token> & SYNUSB_IO_ALWAYS) { <answer> (synusb->flags 
error = <token> <answer> synusb_open(input_dev); 
<token> (error) <answer> if 
goto <token> <answer> err_free_dma; 
error = <token> <answer> input_register_device(input_dev); 
<token> (error) { <answer> if 
"Failed to register input device, error <token> <answer> %d\n", 
<token> err_stop_io; <answer> goto 
return <token> <answer> 0; 
if <token> & SYNUSB_IO_ALWAYS) <answer> (synusb->flags 
<token> SYNUSB_RECV_SIZE, synusb->data, <answer> usb_free_coherent(udev, 
<token> NULL); <answer> usb_set_intfdata(intf, 
return <token> <answer> error; 
static void synusb_disconnect(struct usb_interface <token> <answer> *intf) 
struct synusb *synusb = <token> <answer> usb_get_intfdata(intf); 
struct usb_device *udev <token> interface_to_usbdev(intf); <answer> = 
<token> (synusb->flags & SYNUSB_IO_ALWAYS) <answer> if 
usb_free_coherent(udev, SYNUSB_RECV_SIZE, <token> <answer> synusb->data, 
usb_set_intfdata(intf, <token> <answer> NULL); 
<token> int synusb_suspend(struct usb_interface *intf, pm_message_t message) <answer> static 
struct synusb *synusb = <token> <answer> usb_get_intfdata(intf); 
<token> 0; <answer> return 
static <token> synusb_resume(struct usb_interface *intf) <answer> int 
struct synusb *synusb <token> usb_get_intfdata(intf); <answer> = 
int retval = <token> <answer> 0; 
if ((synusb->is_open || (synusb->flags & <token> && <answer> SYNUSB_IO_ALWAYS)) 
usb_submit_urb(synusb->urb, GFP_NOIO) <token> 0) { <answer> < 
retval <token> -EIO; <answer> = 
<token> retval; <answer> return 
<token> int synusb_pre_reset(struct usb_interface *intf) <answer> static 
<token> synusb *synusb = usb_get_intfdata(intf); <answer> struct 
return <token> <answer> 0; 
static int <token> usb_interface *intf) <answer> synusb_post_reset(struct 
struct synusb *synusb <token> usb_get_intfdata(intf); <answer> = 
<token> retval = 0; <answer> int 
if ((synusb->is_open || (synusb->flags <token> SYNUSB_IO_ALWAYS)) && <answer> & 
usb_submit_urb(synusb->urb, <token> < 0) { <answer> GFP_NOIO) 
retval <token> -EIO; <answer> = 
return <token> <answer> retval; 
static <token> synusb_reset_resume(struct usb_interface *intf) <answer> int 
<token> synusb_resume(intf); <answer> return 
static <token> struct usb_device_id synusb_idtable[] = { <answer> const 
{ USB_DEVICE_SYNAPTICS(TP, <token> }, <answer> SYNUSB_TOUCHPAD) 
{ USB_DEVICE_SYNAPTICS(INT_TP, <token> }, <answer> SYNUSB_TOUCHPAD) 
{ <token> <answer> USB_DEVICE_SYNAPTICS(CPAD, 
SYNUSB_TOUCHPAD | SYNUSB_AUXDISPLAY | <token> }, <answer> SYNUSB_IO_ALWAYS) 
{ USB_DEVICE_SYNAPTICS(TS, SYNUSB_TOUCHSCREEN) <token> <answer> }, 
<token> USB_DEVICE_SYNAPTICS(STICK, SYNUSB_STICK) }, <answer> { 
<token> USB_DEVICE_SYNAPTICS(WP, SYNUSB_TOUCHPAD) }, <answer> { 
{ USB_DEVICE_SYNAPTICS(COMP_TP, SYNUSB_COMBO) <token> <answer> }, 
{ <token> SYNUSB_TOUCHPAD) }, <answer> USB_DEVICE_SYNAPTICS(WTP, 
{ USB_DEVICE_SYNAPTICS(DPAD, <token> }, <answer> SYNUSB_TOUCHPAD) 
<token> } <answer> { 
<token> synusb_idtable); <answer> MODULE_DEVICE_TABLE(usb, 
<token> struct usb_driver synusb_driver = { <answer> static 
<token> = "synaptics_usb", <answer> .name 
.probe = <token> <answer> synusb_probe, 
<token> = synusb_disconnect, <answer> .disconnect 
.id_table <token> synusb_idtable, <answer> = 
.suspend = <token> <answer> synusb_suspend, 
.resume <token> synusb_resume, <answer> = 
.pre_reset <token> synusb_pre_reset, <answer> = 
.post_reset <token> synusb_post_reset, <answer> = 
.reset_resume = <token> <answer> synusb_reset_resume, 
.supports_autosuspend = <token> <answer> 1, 
MODULE_AUTHOR("Rob <token> <rob@inpharmatica.co.uk>, " <answer> Miller 
"Ron <token> <ron@debian.org>, " <answer> Lee 
"Jan <token> <cpad@jan-steinhoff.de>"); <answer> Steinhoff 
MODULE_DESCRIPTION("Synaptics USB <token> driver"); <answer> device 
#include <token> <answer> <linux/module.h> 
<token> <linux/mod_devicetable.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/spi/spi.h> 
#include <token> <answer> <linux/property.h> 
#include <token> <answer> "adxl355.h" 
static const struct regmap_config adxl355_spi_regmap_config = <token> <answer> { 
.reg_bits = <token> <answer> 7, 
.pad_bits <token> 1, <answer> = 
.val_bits <token> 8, <answer> = 
<token> = BIT(0), <answer> .read_flag_mask 
<token> = 0x2F, <answer> .max_register 
<token> = &adxl355_readable_regs_tbl, <answer> .rd_table 
<token> = &adxl355_writeable_regs_tbl, <answer> .wr_table 
static int adxl355_spi_probe(struct spi_device <token> <answer> *spi) 
const <token> adxl355_chip_info *chip_data; <answer> struct 
struct regmap <token> <answer> *regmap; 
chip_data = <token> <answer> device_get_match_data(&spi->dev); 
<token> (!chip_data) { <answer> if 
chip_data = <token> *)spi_get_device_id(spi)->driver_data; <answer> (void 
<token> (!chip_data) <answer> if 
return <token> <answer> -EINVAL; 
regmap = <token> &adxl355_spi_regmap_config); <answer> devm_regmap_init_spi(spi, 
if <token> { <answer> (IS_ERR(regmap)) 
dev_err(&spi->dev, <token> initializing spi regmap: %ld\n", <answer> "Error 
return <token> <answer> PTR_ERR(regmap); 
return <token> regmap, chip_data); <answer> adxl355_core_probe(&spi->dev, 
static const struct spi_device_id adxl355_spi_id[] = <token> <answer> { 
{ "adxl355", <token> }, <answer> (kernel_ulong_t)&adxl35x_chip_info[ADXL355] 
<token> "adxl359", (kernel_ulong_t)&adxl35x_chip_info[ADXL359] }, <answer> { 
{ <token> <answer> } 
<token> adxl355_spi_id); <answer> MODULE_DEVICE_TABLE(spi, 
<token> const struct of_device_id adxl355_of_match[] = { <answer> static 
<token> .compatible = "adi,adxl355", .data = &adxl35x_chip_info[ADXL355] }, <answer> { 
{ .compatible <token> "adi,adxl359", .data = &adxl35x_chip_info[ADXL359] }, <answer> = 
{ <token> <answer> } 
<token> adxl355_of_match); <answer> MODULE_DEVICE_TABLE(of, 
static struct <token> adxl355_spi_driver = { <answer> spi_driver 
<token> = { <answer> .driver 
.name = <token> <answer> "adxl355_spi", 
.of_match_table <token> adxl355_of_match, <answer> = 
.probe <token> adxl355_spi_probe, <answer> = 
.id_table <token> adxl355_spi_id, <answer> = 
MODULE_AUTHOR("Puranjay Mohan <token> <answer> <puranjay12@gmail.com>"); 
MODULE_DESCRIPTION("ADXL355 <token> Digital Accelerometer SPI driver"); <answer> 3-Axis 
<token> v2"); <answer> MODULE_LICENSE("GPL 
#include <token> <answer> "mana_ib.h" 
<token> ib_wq *mana_ib_create_wq(struct ib_pd *pd, <answer> struct 
struct <token> *init_attr, <answer> ib_wq_init_attr 
struct <token> *udata) <answer> ib_udata 
struct mana_ib_dev *mdev <token> <answer> = 
container_of(pd->device, struct mana_ib_dev, <token> <answer> ib_dev); 
struct mana_ib_create_wq <token> = {}; <answer> ucmd 
struct <token> *wq; <answer> mana_ib_wq 
struct <token> *umem; <answer> ib_umem 
<token> err; <answer> int 
if (udata->inlen <token> sizeof(ucmd)) <answer> < 
<token> ERR_PTR(-EINVAL); <answer> return 
err = ib_copy_from_udata(&ucmd, <token> min(sizeof(ucmd), udata->inlen)); <answer> udata, 
<token> (err) { <answer> if 
"Failed to copy from udata <token> create wq, %d\n", err); <answer> for 
<token> ERR_PTR(err); <answer> return 
wq = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*wq), 
if <token> <answer> (!wq) 
return <token> <answer> ERR_PTR(-ENOMEM); 
<token> "ucmd wq_buf_addr 0x%llx\n", ucmd.wq_buf_addr); <answer> ibdev_dbg(&mdev->ib_dev, 
<token> = ib_umem_get(pd->device, ucmd.wq_buf_addr, ucmd.wq_buf_size, <answer> umem 
<token> (IS_ERR(umem)) { <answer> if 
err <token> PTR_ERR(umem); <answer> = 
"Failed to get umem for create <token> err %d\n", err); <answer> wq, 
goto <token> <answer> err_free_wq; 
wq->umem <token> umem; <answer> = 
wq->wqe = <token> <answer> init_attr->max_wr; 
<token> = ucmd.wq_buf_size; <answer> wq->wq_buf_size 
wq->rx_object <token> INVALID_MANA_HANDLE; <answer> = 
err = mana_ib_create_zero_offset_dma_region(mdev, wq->umem, <token> <answer> &wq->gdma_region); 
if (err) <token> <answer> { 
"Failed to create dma region for create <token> %d\n", <answer> wq, 
goto <token> <answer> err_release_umem; 
<token> ret %d gdma_region 0x%llx\n", <answer> "create_dma_region 
err, <token> <answer> wq->gdma_region); 
<token> 0; <answer> return 
int <token> ib_rwq_ind_table *ib_rwq_ind_tbl) <answer> mana_ib_destroy_rwq_ind_table(struct 
return <token> <answer> 0; 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/string.h> 
<token> <linux/nls.h> <answer> #include 
<token> <linux/errno.h> <answer> #include 
<token> const wchar_t charset2uni[256] = { <answer> static 
#include <token> <answer> "ptrace.h" 
<token> "child.h" <answer> #include 
<token> __NR_pkey_alloc <answer> #ifndef 
#define __NR_pkey_alloc <token> <answer> 384 
<token> __NR_pkey_free <answer> #ifndef 
#define __NR_pkey_free <token> <answer> 385 
<token> NT_PPC_PKEY <answer> #ifndef 
<token> NT_PPC_PKEY 0x110 <answer> #define 
#ifndef <token> <answer> PKEY_DISABLE_EXECUTE 
#define PKEY_DISABLE_EXECUTE <token> <answer> 0x4 
#define AMR_BITS_PER_PKEY <token> <answer> 2 
<token> PKEY_REG_BITS (sizeof(u64) * 8) <answer> #define 
#define pkeyshift(pkey) (PKEY_REG_BITS <token> ((pkey + 1) * AMR_BITS_PER_PKEY)) <answer> - 
static const char user_read[] = "[User Read <token> <answer> (Running)]"; 
<token> const char user_write[] = "[User Write (Running)]"; <answer> static 
static const char ptrace_read_running[] = "[Ptrace <token> (Running)]"; <answer> Read 
static const char ptrace_write_running[] = "[Ptrace Write <token> <answer> (Running)]"; 
unsigned <token> invalid_iamr; <answer> long 
unsigned <token> invalid_uamor; <answer> long 
static int sys_pkey_alloc(unsigned <token> flags, unsigned long init_access_rights) <answer> long 
<token> syscall(__NR_pkey_alloc, flags, init_access_rights); <answer> return 
static int child(struct shared_info <token> <answer> *info) 
<token> long reg; <answer> unsigned 
bool disable_execute <token> true; <answer> = 
int pkey1, pkey2, <token> <answer> pkey3; 
int <token> <answer> ret; 
info->invalid_amr = info->amr2 | (~0x0UL <token> ~info->expected_uamor); <answer> & 
<token> (disable_execute) <answer> if 
info->expected_iamr |= 1ul << <token> <answer> pkeyshift(pkey1); 
info->expected_iamr <token> ~(1ul << pkeyshift(pkey1)); <answer> &= 
info->expected_iamr <token> ~(1ul << pkeyshift(pkey2)); <answer> &= 
info->expected_iamr &= ~(1ul << <token> <answer> pkeyshift(pkey3)); 
info->invalid_iamr = <token> | (1ul << pkeyshift(pkey1) | 1ul << pkeyshift(pkey2)); <answer> info->expected_iamr 
info->invalid_uamor <token> info->expected_uamor & ~(0x3ul << pkeyshift(pkey1)); <answer> = 
printf("%-30s AMR: %016lx pkey1: <token> pkey2: %d pkey3: %d\n", <answer> %d 
<token> info->amr1, pkey1, pkey2, pkey3); <answer> user_write, 
<token> = prod_parent(&info->child_sync); <answer> ret 
CHILD_FAIL_IF(ret, <token> <answer> &info->child_sync); 
ret = <token> <answer> wait_parent(&info->child_sync); 
<token> (ret) <answer> if 
<token> ret; <answer> return 
reg <token> mfspr(SPRN_AMR); <answer> = 
printf("%-30s AMR: %016lx\n", <token> reg); <answer> user_read, 
CHILD_FAIL_IF(reg != info->amr2, <token> <answer> &info->child_sync); 
ret = <token> <answer> prod_parent(&info->child_sync); 
<token> &info->child_sync); <answer> CHILD_FAIL_IF(ret, 
ret = <token> <answer> wait_parent(&info->child_sync); 
if <token> <answer> (ret) 
<token> ret; <answer> return 
reg = <token> <answer> mfspr(SPRN_AMR); 
printf("%-30s AMR: %016lx\n", <token> reg); <answer> user_read, 
CHILD_FAIL_IF(reg != <token> &info->child_sync); <answer> info->amr2, 
ret = ptrace_read_regs(pid, NT_PPC_PKEY, <token> 3); <answer> regs, 
PARENT_SKIP_IF_UNSUPPORTED(ret, &info->child_sync, <token> not supported"); <answer> "PKEYs 
<token> &info->child_sync); <answer> PARENT_FAIL_IF(ret, 
info->amr1 = <token> = regs[0]; <answer> info->amr2 
<token> = regs[1]; <answer> info->expected_iamr 
info->expected_uamor <token> regs[2]; <answer> = 
<token> <linux/bug.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/types.h> 
<token> <linux/string.h> <answer> #include 
#include <token> <answer> <asm/sgialib.h> 
<token> <asm/bootinfo.h> <answer> #include 
struct smatch <token> <answer> { 
char <token> <answer> *arcname; 
<token> *liname; <answer> char 
int <token> <answer> flags; 
<token> struct smatch mach_table[] = { <answer> static 
<token> = "SGI-IP22", <answer> .arcname 
.liname = "SGI <token> <answer> Indy", 
.flags <token> PROM_FLAG_ARCS, <answer> = 
<token> { <answer> }, 
.arcname <token> "SGI-IP28", <answer> = 
.liname = <token> IP28", <answer> "SGI 
.flags <token> PROM_FLAG_ARCS, <answer> = 
}, <token> <answer> { 
.arcname = <token> <answer> "SGI-IP30", 
.liname = <token> Octane", <answer> "SGI 
<token> = PROM_FLAG_ARCS, <answer> .flags 
}, <token> <answer> { 
<token> = "SGI-IP32", <answer> .arcname 
<token> = "SGI O2", <answer> .liname 
.flags <token> PROM_FLAG_ARCS, <answer> = 
}, <token> <answer> { 
<token> = "Microsoft-Jazz", <answer> .arcname 
.liname <token> "Jazz MIPS_Magnum_4000", <answer> = 
.flags <token> 0, <answer> = 
<token> { <answer> }, 
.arcname <token> "PICA-61", <answer> = 
<token> = "Jazz Acer_PICA_61", <answer> .liname 
.flags = <token> <answer> 0, 
}, <token> <answer> { 
<token> = "RM200PCI", <answer> .arcname 
<token> = "SNI RM200_PCI", <answer> .liname 
.flags = <token> <answer> PROM_FLAG_DONT_FREE_TEMP, 
}, <token> <answer> { 
.arcname = <token> <answer> "RM200PCI-R5K", 
.liname = <token> RM200_PCI-R5K", <answer> "SNI 
.flags = <token> <answer> PROM_FLAG_DONT_FREE_TEMP, 
int <token> <answer> prom_flags; 
static <token> smatch * __init string_to_mach(const char *s) <answer> struct 
int <token> <answer> i; 
for (i = <token> i < ARRAY_SIZE(mach_table); i++) { <answer> 0; 
if (!strcmp(s, <token> <answer> mach_table[i].arcname)) 
return <token> <answer> &mach_table[i]; 
panic("Yeee, could <token> determine architecture type <%s>", s); <answer> not 
char <token> <answer> *system_type; 
const <token> *get_system_type(void) <answer> char 
<token> system_type; <answer> return 
static <token> * __init ArcGetChild(pcomponent *Current) <answer> pcomponent 
return (pcomponent *) ARC_CALL1(child_component, <token> <answer> Current); 
void <token> prom_identify_arch(void) <answer> __init 
<token> *p; <answer> pcomponent 
<token> smatch *mach; <answer> struct 
<token> char *iname; <answer> const 
p = <token> <answer> ArcGetChild(PROM_NULL_COMPONENT); 
<token> (p == NULL) { <answer> if 
<token> = "Unknown"; <answer> iname 
<token> else <answer> } 
iname = <token> *) (long) p->iname; <answer> (char 
printk("ARCH: <token> iname); <answer> %s\n", 
mach = <token> <answer> string_to_mach(iname); 
system_type = <token> <answer> mach->liname; 
prom_flags <token> mach->flags; <answer> = 
#include <token> <answer> <linux/bcd.h> 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/mfd/palmas.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/rtc.h> 
<token> <linux/types.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/pm.h> 
<token> palmas_rtc { <answer> struct 
<token> rtc_device *rtc; <answer> struct 
<token> device *dev; <answer> struct 
<token> int irq; <answer> unsigned 
<token> <linux/module.h> <answer> #include 
<token> <linux/proc_fs.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/types.h> 
<token> <linux/smp.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
<token> <linux/sysctl.h> <answer> #include 
<token> <linux/highmem.h> <answer> #include 
<token> <linux/timer.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/jiffies.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
#include <token> <answer> <linux/list.h> 
#include <token> <answer> <linux/ctype.h> 
#include <token> <answer> <linux/edac.h> 
#include <token> <answer> <linux/bitops.h> 
#include <token> <answer> <linux/uaccess.h> 
<token> <asm/page.h> <answer> #include 
#include <token> <answer> "edac_mc.h" 
#include <token> <answer> "edac_module.h" 
#include <token> <answer> <ras/ras_event.h> 
<token> CONFIG_EDAC_ATOMIC_SCRUB <answer> #ifdef 
#include <token> <answer> <asm/edac.h> 
<token> edac_atomic_scrub(va, size) do { } while (0) <answer> #define 
int <token> = EDAC_OPSTATE_INVAL; <answer> edac_op_state 
static const <token> *edac_mc_owner; <answer> char 
<token> struct mem_ctl_info *error_desc_to_mci(struct edac_raw_error_desc *e) <answer> static 
<token> container_of(e, struct mem_ctl_info, error_desc); <answer> return 
unsigned <token> edac_dimm_info_location(struct dimm_info *dimm, char *buf, <answer> int 
unsigned int <token> <answer> len) 
struct mem_ctl_info *mci <token> dimm->mci; <answer> = 
int i, n, <token> = 0; <answer> count 
<token> *p = buf; <answer> char 
for <token> = 0; i < mci->n_layers; i++) { <answer> (i 
n = scnprintf(p, len, <token> %d ", <answer> "%s 
p += <token> <answer> n; 
<token> -= n; <answer> len 
<token> += n; <answer> count 
<token> count; <answer> return 
#ifdef <token> <answer> CONFIG_EDAC_DEBUG 
static <token> edac_mc_dump_channel(struct rank_info *chan) <answer> void 
edac_dbg(4, <token> channel->chan_idx = %d\n", chan->chan_idx); <answer> " 
edac_dbg(4, " channel = %p\n", <token> <answer> chan); 
<token> " channel->csrow = %p\n", chan->csrow); <answer> edac_dbg(4, 
edac_dbg(4, " channel->dimm <token> %p\n", chan->dimm); <answer> = 
static void <token> dimm_info *dimm) <answer> edac_mc_dump_dimm(struct 
char <token> <answer> location[80]; 
if <token> <answer> (!dimm->nr_pages) 
edac_dimm_info_location(dimm, location, <token> <answer> sizeof(location)); 
edac_dbg(4, "%s%i: %smapped as virtual <token> %d, chan %d\n", <answer> row 
dimm->mci->csbased <token> "rank" : "dimm", <answer> ? 
dimm->idx, location, <token> dimm->cschannel); <answer> dimm->csrow, 
edac_dbg(4, " dimm = <token> dimm); <answer> %p\n", 
<token> " dimm->label = '%s'\n", dimm->label); <answer> edac_dbg(4, 
edac_dbg(4, " <token> = 0x%x\n", dimm->nr_pages); <answer> dimm->nr_pages 
edac_dbg(4, " dimm->grain = <token> dimm->grain); <answer> %d\n", 
<token> void edac_mc_dump_csrow(struct csrow_info *csrow) <answer> static 
edac_dbg(4, "csrow->csrow_idx = %d\n", <token> <answer> csrow->csrow_idx); 
edac_dbg(4, " <token> = %p\n", csrow); <answer> csrow 
edac_dbg(4, " csrow->first_page = 0x%lx\n", <token> <answer> csrow->first_page); 
edac_dbg(4, " <token> = 0x%lx\n", csrow->last_page); <answer> csrow->last_page 
edac_dbg(4, " csrow->page_mask = 0x%lx\n", <token> <answer> csrow->page_mask); 
edac_dbg(4, <token> csrow->nr_channels = %d\n", csrow->nr_channels); <answer> " 
edac_dbg(4, " csrow->channels <token> %p\n", csrow->channels); <answer> = 
<token> " csrow->mci = %p\n", csrow->mci); <answer> edac_dbg(4, 
<token> void edac_mc_dump_mci(struct mem_ctl_info *mci) <answer> static 
edac_dbg(3, <token> = %p\n", mci); <answer> "\tmci 
edac_dbg(3, <token> = %lx\n", mci->mtype_cap); <answer> "\tmci->mtype_cap 
edac_dbg(3, "\tmci->edac_ctl_cap = <token> mci->edac_ctl_cap); <answer> %lx\n", 
edac_dbg(3, "\tmci->edac_cap = <token> mci->edac_cap); <answer> %lx\n", 
edac_dbg(4, "\tmci->edac_check <token> %p\n", mci->edac_check); <answer> = 
edac_dbg(3, "\tmci->nr_csrows = %d, <token> = %p\n", <answer> csrows 
<token> mci->csrows); <answer> mci->nr_csrows, 
edac_dbg(3, <token> = %d, dimms = %p\n", <answer> "\tmci->nr_dimms 
mci->tot_dimms, <token> <answer> mci->dimms); 
edac_dbg(3, "\tdev <token> %p\n", mci->pdev); <answer> = 
edac_dbg(3, "\tmod_name:ctl_name <token> %s:%s\n", <answer> = 
<token> mci->ctl_name); <answer> mci->mod_name, 
edac_dbg(3, "\tpvt_info = <token> mci->pvt_info); <answer> %p\n\n", 
mci->csrows = <token> sizeof(*mci->csrows), GFP_KERNEL); <answer> kcalloc(tot_csrows, 
if <token> <answer> (!mci->csrows) 
<token> -ENOMEM; <answer> return 
for (row = 0; row < tot_csrows; row++) <token> <answer> { 
struct <token> *csr; <answer> csrow_info 
csr = <token> GFP_KERNEL); <answer> kzalloc(sizeof(**mci->csrows), 
if <token> <answer> (!csr) 
<token> -ENOMEM; <answer> return 
<token> = csr; <answer> mci->csrows[row] 
csr->csrow_idx <token> row; <answer> = 
csr->mci = <token> <answer> mci; 
csr->nr_channels <token> tot_channels; <answer> = 
<token> = kcalloc(tot_channels, sizeof(*csr->channels), <answer> csr->channels 
<token> (!csr->channels) <answer> if 
return <token> <answer> -ENOMEM; 
for (chn = 0; chn < <token> chn++) { <answer> tot_channels; 
struct <token> *chan; <answer> rank_info 
chan = kzalloc(sizeof(**csr->channels), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!chan) 
<token> -ENOMEM; <answer> return 
csr->channels[chn] <token> chan; <answer> = 
chan->chan_idx <token> chn; <answer> = 
<token> = csr; <answer> chan->csrow 
return <token> <answer> 0; 
static int edac_mc_alloc_dimms(struct <token> *mci) <answer> mem_ctl_info 
unsigned int <token> <answer> pos[EDAC_MAX_LAYERS]; 
unsigned int <token> chn, idx; <answer> row, 
<token> layer; <answer> int 
<token> *p; <answer> void 
mci->dimms = <token> sizeof(*mci->dimms), GFP_KERNEL); <answer> kcalloc(mci->tot_dimms, 
if <token> <answer> (!mci->dimms) 
return <token> <answer> -ENOMEM; 
memset(&pos, <token> sizeof(pos)); <answer> 0, 
row = <token> <answer> 0; 
chn <token> 0; <answer> = 
for (idx = 0; idx < <token> idx++) { <answer> mci->tot_dimms; 
struct dimm_info <token> <answer> *dimm; 
struct <token> *chan; <answer> rank_info 
int n, <token> <answer> len; 
<token> = mci->csrows[row]->channels[chn]; <answer> chan 
dimm = kzalloc(sizeof(**mci->dimms), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!dimm) 
return <token> <answer> -ENOMEM; 
mci->dimms[idx] <token> dimm; <answer> = 
<token> = mci; <answer> dimm->mci 
dimm->idx = <token> <answer> idx; 
<token> = sizeof(dimm->label); <answer> len 
p <token> dimm->label; <answer> = 
n = scnprintf(p, len, "mc#%u", <token> <answer> mci->mc_idx); 
p <token> n; <answer> += 
<token> -= n; <answer> len 
for (layer = 0; layer < mci->n_layers; layer++) <token> <answer> { 
n = scnprintf(p, len, <token> <answer> "%s#%u", 
p <token> n; <answer> += 
<token> -= n; <answer> len 
<token> = pos[layer]; <answer> dimm->location[layer] 
for (idx = 0; idx <token> n_layers; idx++) { <answer> < 
tot_dimms <token> layers[idx].size; <answer> *= 
if <token> <answer> (layers[idx].is_virt_csrow) 
tot_csrows *= <token> <answer> layers[idx].size; 
tot_channels <token> layers[idx].size; <answer> *= 
<token> (layers[idx].type == EDAC_MC_LAYER_CHIP_SELECT) <answer> if 
per_rank <token> true; <answer> = 
<token> = kzalloc(sizeof(struct mem_ctl_info), GFP_KERNEL); <answer> mci 
<token> (!mci) <answer> if 
<token> NULL; <answer> return 
mci->layers = kcalloc(n_layers, <token> edac_mc_layer), GFP_KERNEL); <answer> sizeof(struct 
if <token> <answer> (!mci->layers) 
goto <token> <answer> error; 
<token> = kzalloc(sz_pvt, GFP_KERNEL); <answer> mci->pvt_info 
if <token> <answer> (!mci->pvt_info) 
<token> error; <answer> goto 
mci->dev.release <token> mci_release; <answer> = 
struct <token> *find_mci_by_dev(struct device *dev) <answer> mem_ctl_info 
<token> mem_ctl_info *ret; <answer> struct 
ret = <token> <answer> __find_mci_by_dev(dev); 
<token> ret; <answer> return 
static <token> edac_mc_workq_function(struct work_struct *work_req) <answer> void 
<token> delayed_work *d_work = to_delayed_work(work_req); <answer> struct 
struct mem_ctl_info *mci <token> to_edac_mem_ctl_work(d_work); <answer> = 
<token> (mci->op_state != OP_RUNNING_POLL) { <answer> if 
if (edac_op_state <token> EDAC_OPSTATE_POLL) <answer> == 
void edac_mc_reset_delay_period(unsigned <token> value) <answer> long 
struct <token> *mci; <answer> mem_ctl_info 
struct list_head <token> <answer> *item; 
<token> &mc_devices) { <answer> list_for_each(item, 
mci = list_entry(item, <token> mem_ctl_info, link); <answer> struct 
if (mci->op_state <token> OP_RUNNING_POLL) <answer> == 
edac_mod_work(&mci->work, <token> <answer> value); 
static int add_mc_to_global_list(struct mem_ctl_info <token> <answer> *mci) 
<token> list_head *item, *insert_before; <answer> struct 
<token> mem_ctl_info *p; <answer> struct 
insert_before <token> &mc_devices; <answer> = 
<token> = __find_mci_by_dev(mci->pdev); <answer> p 
if (unlikely(p <token> NULL)) <answer> != 
goto <token> <answer> fail0; 
list_for_each(item, <token> { <answer> &mc_devices) 
p = list_entry(item, struct <token> link); <answer> mem_ctl_info, 
if (p->mc_idx >= <token> { <answer> mci->mc_idx) 
if <token> == mci->mc_idx)) <answer> (unlikely(p->mc_idx 
goto <token> <answer> fail1; 
insert_before <token> item; <answer> = 
<token> insert_before); <answer> list_add_tail_rcu(&mci->link, 
<token> 0; <answer> return 
<token> EDAC_MC, <answer> edac_printk(KERN_WARNING, 
"%s (%s) %s %s already assigned %d\n", <token> <answer> dev_name(p->pdev), 
edac_dev_name(mci), p->mod_name, p->ctl_name, <token> <answer> p->mc_idx); 
<token> 1; <answer> return 
<token> EDAC_MC, <answer> edac_printk(KERN_WARNING, 
"bug in low-level driver: attempt to <token> <answer> assign\n" 
" duplicate mc_idx %d in %s()\n", p->mc_idx, <token> <answer> __func__); 
<token> 1; <answer> return 
static int del_mc_from_global_list(struct <token> *mci) <answer> mem_ctl_info 
return <token> <answer> list_empty(&mc_devices); 
struct <token> *edac_mc_find(int idx) <answer> mem_ctl_info 
<token> mem_ctl_info *mci; <answer> struct 
struct list_head <token> <answer> *item; 
<token> &mc_devices) { <answer> list_for_each(item, 
mci = <token> struct mem_ctl_info, link); <answer> list_entry(item, 
if (mci->mc_idx == <token> <answer> idx) 
goto <token> <answer> unlock; 
mci <token> NULL; <answer> = 
return <token> <answer> mci; 
const <token> *edac_get_owner(void) <answer> char 
return <token> <answer> edac_mc_owner; 
<token> = mci->ctl_page_to_phys ? <answer> remapped_page 
mci->ctl_page_to_phys(mci, <token> : <answer> e->page_frame_number) 
edac_mc_scrub_block(remapped_page, <token> e->grain); <answer> e->offset_in_page, 
<token> void edac_ue_error(struct edac_raw_error_desc *e) <answer> static 
struct mem_ctl_info <token> = error_desc_to_mci(e); <answer> *mci 
if (edac_mc_get_log_ue()) <token> <answer> { 
edac_mc_printk(mci, <token> <answer> KERN_WARNING, 
"%d UE %s%son %s (%s page:0x%lx <token> grain:%ld%s%s)\n", <answer> offset:0x%lx 
<token> e->msg, <answer> e->error_count, 
*e->msg ? <token> " : "", <answer> " 
e->label, e->location, e->page_frame_number, <token> <answer> e->offset_in_page, 
*e->other_detail ? " <token> " : "", <answer> - 
if (edac_mc_get_panic_on_ue()) <token> <answer> { 
panic("UE %s%son %s (%s page:0x%lx offset:0x%lx <token> <answer> grain:%ld%s%s)\n", 
*e->msg <token> " " : "", <answer> ? 
e->label, <token> e->page_frame_number, e->offset_in_page, <answer> e->location, 
*e->other_detail ? <token> - " : "", <answer> " 
<token> void edac_inc_csrow(struct edac_raw_error_desc *e, int row, int chan) <answer> static 
<token> mem_ctl_info *mci = error_desc_to_mci(e); <answer> struct 
<token> hw_event_mc_err_type type = e->type; <answer> enum 
<token> count = e->error_count; <answer> u16 
if (row <token> 0) <answer> < 
edac_dbg(4, "csrow/channel to <token> (%d,%d)\n", row, chan); <answer> increment: 
if (type == HW_EVENT_ERR_CORRECTED) <token> <answer> { 
<token> += count; <answer> mci->csrows[row]->ce_count 
if (chan >= <token> <answer> 0) 
<token> += count; <answer> mci->csrows[row]->channels[chan]->ce_count 
} <token> { <answer> else 
mci->csrows[row]->ue_count <token> count; <answer> += 
void <token> edac_raw_error_desc *e) <answer> edac_raw_mc_handle_error(struct 
struct mem_ctl_info <token> = error_desc_to_mci(e); <answer> *mci 
<token> grain_bits; <answer> u8 
for (i = 0; i < <token> i++) { <answer> mci->n_layers; 
<token> (pos[i] >= (int)mci->layers[i].size) { <answer> if 
<token> KERN_ERR, <answer> edac_mc_printk(mci, 
"INTERNAL ERROR: %s value <token> out of range (%d >= %d)\n", <answer> is 
<token> mci->layers[i].size); <answer> pos[i], 
pos[i] = <token> <answer> -1; 
if (pos[i] <token> 0) <answer> >= 
any_memory <token> false; <answer> = 
<token> = e->label; <answer> p 
*p = <token> <answer> '\0'; 
<token> = p + sizeof(e->label); <answer> end 
prefix <token> ""; <answer> = 
mci_for_each_dimm(mci, <token> { <answer> dimm) 
if (top_layer >= 0 && <token> != dimm->location[0]) <answer> top_layer 
if (mid_layer >= 0 && mid_layer != <token> <answer> dimm->location[1]) 
<token> (low_layer >= 0 && low_layer != dimm->location[2]) <answer> if 
<token> (!dimm->nr_pages) <answer> if 
<token> (n_labels > EDAC_MAX_LABELS) { <answer> if 
<token> = e->label; <answer> p 
<token> = '\0'; <answer> *p 
} <token> { <answer> else 
p += scnprintf(p, end <token> p, "%s%s", prefix, dimm->label); <answer> - 
<token> = OTHER_LABEL; <answer> prefix 
edac_dbg(4, "%s <token> map: (%d,%d)\n", <answer> csrows 
mci->csbased ? "rank" : <token> <answer> "dimm", 
<token> dimm->cschannel); <answer> dimm->csrow, 
<token> (row == -1) <answer> if 
row = <token> <answer> dimm->csrow; 
<token> if (row >= 0 && row != dimm->csrow) <answer> else 
row = <token> <answer> -2; 
if (chan == <token> <answer> -1) 
chan <token> dimm->cschannel; <answer> = 
else if (chan >= 0 && <token> != dimm->cschannel) <answer> chan 
chan = <token> <answer> -2; 
<token> (any_memory) <answer> if 
<token> "any memory", sizeof(e->label)); <answer> strscpy(e->label, 
else <token> (!*e->label) <answer> if 
strscpy(e->label, "unknown <token> sizeof(e->label)); <answer> memory", 
edac_inc_csrow(e, <token> chan); <answer> row, 
<token> "atl1c.h" <answer> #include 
char <token> = "atl1c"; <answer> atl1c_driver_name[] 
static const struct pci_device_id <token> = { <answer> atl1c_pci_tbl[] 
{PCI_DEVICE(PCI_VENDOR_ID_ATTANSIC, <token> <answer> PCI_DEVICE_ID_ATTANSIC_L1C)}, 
{PCI_DEVICE(PCI_VENDOR_ID_ATTANSIC, <token> <answer> PCI_DEVICE_ID_ATTANSIC_L2C)}, 
{PCI_DEVICE(PCI_VENDOR_ID_ATTANSIC, <token> <answer> PCI_DEVICE_ID_ATHEROS_L2C_B)}, 
<token> PCI_DEVICE_ID_ATHEROS_L2C_B2)}, <answer> {PCI_DEVICE(PCI_VENDOR_ID_ATTANSIC, 
<token> PCI_DEVICE_ID_ATHEROS_L1D)}, <answer> {PCI_DEVICE(PCI_VENDOR_ID_ATTANSIC, 
<token> PCI_DEVICE_ID_ATHEROS_L1D_2_0)}, <answer> {PCI_DEVICE(PCI_VENDOR_ID_ATTANSIC, 
<token> void atl1c_reset_pcie(struct atl1c_hw *hw, u32 flag) <answer> static 
<token> data; <answer> u32 
u32 <token> <answer> pci_cmd; 
struct pci_dev *pdev <token> hw->adapter->pdev; <answer> = 
int <token> <answer> pos; 
AT_READ_REG(hw, PCI_COMMAND, <token> <answer> &pci_cmd); 
pci_cmd <token> ~PCI_COMMAND_INTX_DISABLE; <answer> &= 
pci_cmd |= (PCI_COMMAND_MEMORY | PCI_COMMAND_MASTER <token> <answer> | 
AT_WRITE_REG(hw, <token> pci_cmd); <answer> PCI_COMMAND, 
pci_enable_wake(pdev, PCI_D3hot, <token> <answer> 0); 
pci_enable_wake(pdev, PCI_D3cold, <token> <answer> 0); 
pos = pci_find_ext_capability(pdev, <token> <answer> PCI_EXT_CAP_ID_ERR); 
if <token> { <answer> (pos) 
pci_read_config_dword(pdev, pos <token> PCI_ERR_UNCOR_SEVER, &data); <answer> + 
<token> &= ~(PCI_ERR_UNC_DLP | PCI_ERR_UNC_FCP); <answer> data 
pci_write_config_dword(pdev, pos + <token> data); <answer> PCI_ERR_UNCOR_SEVER, 
<token> inline void atl1c_irq_enable(struct atl1c_adapter *adapter) <answer> static 
if (likely(atomic_dec_and_test(&adapter->irq_sem))) <token> <answer> { 
AT_WRITE_REG(&adapter->hw, REG_ISR, <token> <answer> 0x7FFFFFFF); 
AT_WRITE_REG(&adapter->hw, <token> adapter->hw.intr_mask); <answer> REG_IMR, 
static inline void atl1c_irq_disable(struct atl1c_adapter <token> <answer> *adapter) 
<token> REG_IMR, 0); <answer> AT_WRITE_REG(&adapter->hw, 
AT_WRITE_REG(&adapter->hw, <token> ISR_DIS_INT); <answer> REG_ISR, 
static <token> atl1c_wait_until_idle(struct atl1c_hw *hw, u32 modu_ctrl) <answer> u32 
<token> timeout; <answer> int 
u32 <token> <answer> data; 
for <token> = 0; timeout < AT_HW_MAX_IDLE_DELAY; timeout++) { <answer> (timeout 
<token> REG_IDLE_STATUS, &data); <answer> AT_READ_REG(hw, 
if <token> & modu_ctrl) == 0) <answer> ((data 
<token> 0; <answer> return 
return <token> <answer> data; 
static void atl1c_phy_config(struct <token> *t) <answer> timer_list 
struct <token> *adapter = from_timer(adapter, t, <answer> atl1c_adapter 
struct <token> *hw = &adapter->hw; <answer> atl1c_hw 
unsigned <token> flags; <answer> long 
<token> flags); <answer> spin_lock_irqsave(&adapter->mdio_lock, 
spin_unlock_irqrestore(&adapter->mdio_lock, <token> <answer> flags); 
<token> atl1c_reinit_locked(struct atl1c_adapter *adapter) <answer> void 
clear_bit(__AT_RESETTING, <token> <answer> &adapter->flags); 
<token> void atl1c_check_link_status(struct atl1c_adapter *adapter) <answer> static 
<token> atl1c_hw *hw = &adapter->hw; <answer> struct 
struct net_device *netdev = <token> <answer> adapter->netdev; 
struct pci_dev <token> = adapter->pdev; <answer> *pdev 
<token> err; <answer> int 
unsigned <token> flags; <answer> long 
u16 speed, <token> <answer> duplex; 
bool <token> <answer> link; 
spin_lock_irqsave(&adapter->mdio_lock, <token> <answer> flags); 
link = <token> <answer> atl1c_get_link_status(hw); 
<token> flags); <answer> spin_unlock_irqrestore(&adapter->mdio_lock, 
<token> (!link) { <answer> if 
static void atl1c_tx_timeout(struct net_device *netdev, <token> int txqueue) <answer> unsigned 
struct <token> *adapter = netdev_priv(netdev); <answer> atl1c_adapter 
static void <token> net_device *netdev) <answer> atl1c_set_multi(struct 
struct atl1c_adapter *adapter <token> netdev_priv(netdev); <answer> = 
struct atl1c_hw <token> = &adapter->hw; <answer> *hw 
struct <token> *ha; <answer> netdev_hw_addr 
u32 <token> <answer> mac_ctrl_data; 
<token> hash_value; <answer> u32 
static <token> atl1c_set_mac_addr(struct net_device *netdev, void *p) <answer> int 
struct atl1c_adapter <token> = netdev_priv(netdev); <answer> *adapter 
struct <token> *addr = p; <answer> sockaddr 
if <token> <answer> (!is_valid_ether_addr(addr->sa_data)) 
<token> -EADDRNOTAVAIL; <answer> return 
<token> (netif_running(netdev)) <answer> if 
return <token> <answer> -EBUSY; 
eth_hw_addr_set(netdev, <token> <answer> addr->sa_data); 
memcpy(adapter->hw.mac_addr, <token> netdev->addr_len); <answer> addr->sa_data, 
<token> adapter->hw.mac_addr); <answer> atl1c_hw_set_mac_addr(&adapter->hw, 
<token> 0; <answer> return 
static <token> atl1c_set_rxbufsize(struct atl1c_adapter *adapter, <answer> void 
<token> net_device *dev) <answer> struct 
int mtu = <token> <answer> dev->mtu; 
<token> = mtu > AT_RX_BUF_SIZE ? <answer> adapter->rx_buffer_len 
<token> + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN, 8) : AT_RX_BUF_SIZE; <answer> roundup(mtu 
static netdev_features_t <token> net_device *netdev, <answer> atl1c_fix_features(struct 
<token> features) <answer> netdev_features_t 
struct <token> *adapter = netdev_priv(netdev); <answer> atl1c_adapter 
<token> atl1c_hw *hw = &adapter->hw; <answer> struct 
if <token> & NETIF_F_HW_VLAN_CTAG_RX) <answer> (features 
<token> |= NETIF_F_HW_VLAN_CTAG_TX; <answer> features 
<token> &= ~NETIF_F_HW_VLAN_CTAG_TX; <answer> features 
if (hw->nic_type != athr_mt) <token> <answer> { 
if (netdev->mtu <token> MAX_TSO_FRAME_SIZE) <answer> > 
features <token> ~(NETIF_F_TSO | NETIF_F_TSO6); <answer> &= 
return <token> <answer> features; 
static int atl1c_set_features(struct net_device <token> <answer> *netdev, 
<token> features) <answer> netdev_features_t 
netdev_features_t changed = netdev->features <token> features; <answer> ^ 
if (changed & <token> <answer> NETIF_F_HW_VLAN_CTAG_RX) 
atl1c_vlan_mode(netdev, <token> <answer> features); 
<token> 0; <answer> return 
static <token> atl1c_set_max_mtu(struct net_device *netdev) <answer> void 
struct atl1c_adapter *adapter <token> netdev_priv(netdev); <answer> = 
struct atl1c_hw *hw <token> &adapter->hw; <answer> = 
switch (hw->nic_type) <token> <answer> { 
static int atl1c_change_mtu(struct <token> *netdev, int new_mtu) <answer> net_device 
struct atl1c_adapter *adapter = <token> <answer> netdev_priv(netdev); 
static int atl1c_mdio_read(struct net_device *netdev, int <token> int reg_num) <answer> phy_id, 
struct atl1c_adapter *adapter = <token> <answer> netdev_priv(netdev); 
u16 <token> <answer> result; 
atl1c_read_phy_reg(&adapter->hw, <token> &result); <answer> reg_num, 
return <token> <answer> result; 
static void atl1c_mdio_write(struct <token> *netdev, int phy_id, <answer> net_device 
int <token> int val) <answer> reg_num, 
struct <token> *adapter = netdev_priv(netdev); <answer> atl1c_adapter 
atl1c_write_phy_reg(&adapter->hw, <token> val); <answer> reg_num, 
static int <token> net_device *netdev, <answer> atl1c_mii_ioctl(struct 
<token> ifreq *ifr, int cmd) <answer> struct 
<token> atl1c_adapter *adapter = netdev_priv(netdev); <answer> struct 
struct <token> *pdev = adapter->pdev; <answer> pci_dev 
struct mii_ioctl_data *data <token> if_mii(ifr); <answer> = 
unsigned long <token> <answer> flags; 
<token> retval = 0; <answer> int 
<token> (!netif_running(netdev)) <answer> if 
return <token> <answer> -EINVAL; 
<token> flags); <answer> spin_lock_irqsave(&adapter->mdio_lock, 
switch (cmd) <token> <answer> { 
<token> SIOCGMIIPHY: <answer> case 
data->phy_id <token> 0; <answer> = 
<token> SIOCGMIIREG: <answer> case 
<token> (atl1c_read_phy_reg(&adapter->hw, data->reg_num & 0x1F, <answer> if 
&data->val_out)) <token> <answer> { 
retval = <token> <answer> -EIO; 
<token> out; <answer> goto 
<token> SIOCSMIIREG: <answer> case 
if (data->reg_num & ~(0x1F)) <token> <answer> { 
retval <token> -EFAULT; <answer> = 
goto <token> <answer> out; 
dev_dbg(&pdev->dev, "<atl1c_mii_ioctl> write %x <token> <answer> %x", 
data->reg_num, <token> <answer> data->val_in); 
if <token> <answer> (atl1c_write_phy_reg(&adapter->hw, 
data->reg_num, data->val_in)) <token> <answer> { 
retval <token> -EIO; <answer> = 
goto <token> <answer> out; 
<token> = -EOPNOTSUPP; <answer> retval 
<token> flags); <answer> spin_unlock_irqrestore(&adapter->mdio_lock, 
return <token> <answer> retval; 
static int atl1c_ioctl(struct net_device *netdev, struct ifreq <token> int cmd) <answer> *ifr, 
switch <token> { <answer> (cmd) 
case <token> <answer> SIOCGMIIPHY: 
case <token> <answer> SIOCGMIIREG: 
<token> SIOCSMIIREG: <answer> case 
<token> atl1c_mii_ioctl(netdev, ifr, cmd); <answer> return 
<token> -EOPNOTSUPP; <answer> return 
static int atl1c_alloc_queues(struct <token> *adapter) <answer> atl1c_adapter 
return <token> <answer> 0; 
static enum atl1c_nic_type <token> pci_dev *pdev, <answer> atl1c_get_mac_type(struct 
u8 <token> *hw_addr) <answer> __iomem 
<token> (pdev->device) { <answer> switch 
<token> PCI_DEVICE_ID_ATTANSIC_L2C: <answer> case 
<token> athr_l2c; <answer> return 
<token> PCI_DEVICE_ID_ATTANSIC_L1C: <answer> case 
<token> athr_l1c; <answer> return 
case <token> <answer> PCI_DEVICE_ID_ATHEROS_L2C_B: 
return <token> <answer> athr_l2c_b; 
case <token> <answer> PCI_DEVICE_ID_ATHEROS_L2C_B2: 
return <token> <answer> athr_l2c_b2; 
case <token> <answer> PCI_DEVICE_ID_ATHEROS_L1D: 
return <token> <answer> athr_l1d; 
<token> PCI_DEVICE_ID_ATHEROS_L1D_2_0: <answer> case 
if (readl(hw_addr + REG_MT_MAGIC) <token> MT_MAGIC) <answer> == 
<token> athr_mt; <answer> return 
<token> athr_l1d_2; <answer> return 
return <token> <answer> athr_l1c; 
static int <token> atl1c_hw *hw) <answer> atl1c_setup_mac_funcs(struct 
<token> link_ctrl_data; <answer> u32 
AT_READ_REG(hw, REG_LINK_CTRL, <token> <answer> &link_ctrl_data); 
<token> = ATL1C_INTR_MODRT_ENABLE | <answer> hw->ctrl_flags 
hw->ctrl_flags |= ATL1C_ASPM_L0S_SUPPORT <token> <answer> | 
hw->ctrl_flags |= <token> <answer> ATL1C_ASPM_CTRL_MON; 
if (hw->nic_type <token> athr_l1c || <answer> == 
hw->nic_type == <token> || <answer> athr_l1d 
hw->nic_type <token> athr_l1d_2) <answer> == 
hw->link_cap_flags <token> ATL1C_LINK_CAP_1000M; <answer> |= 
return <token> <answer> 0; 
<token> atl1c_platform_patch { <answer> struct 
u16 <token> <answer> pci_did; 
<token> pci_revid; <answer> u8 
u16 <token> <answer> subsystem_vid; 
u16 <token> <answer> subsystem_did; 
<token> patch_flag; <answer> u32 
#define ATL1C_LINK_PATCH <token> <answer> 0x1 
static const struct atl1c_platform_patch plats[] = <token> <answer> { 
{0x2060, 0xC1, 0x1019, <token> 0x1}, <answer> 0x8152, 
{0x2060, 0xC1, 0x1019, 0x2060, <token> <answer> 0x1}, 
<token> 0xC1, 0x1019, 0xE000, 0x1}, <answer> {0x2060, 
{0x2062, 0xC0, 0x1019, 0x8152, <token> <answer> 0x1}, 
{0x2062, 0xC0, <token> 0x2062, 0x1}, <answer> 0x1019, 
<token> 0xC0, 0x1458, 0xE000, 0x1}, <answer> {0x2062, 
<token> 0xC1, 0x1019, 0x8152, 0x1}, <answer> {0x2062, 
{0x2062, <token> 0x1019, 0x2062, 0x1}, <answer> 0xC1, 
<token> 0xC1, 0x1458, 0xE000, 0x1}, <answer> {0x2062, 
{0x2062, 0xC1, <token> 0x2802, 0x1}, <answer> 0x1565, 
{0x2062, 0xC1, <token> 0x2801, 0x1}, <answer> 0x1565, 
{0x1073, 0xC0, <token> 0x8151, 0x1}, <answer> 0x1019, 
{0x1073, <token> 0x1019, 0x1073, 0x1}, <answer> 0xC0, 
{0x1073, <token> 0x1458, 0xE000, 0x1}, <answer> 0xC0, 
<token> 0xC0, 0x1458, 0xE000, 0x1}, <answer> {0x1083, 
{0x1083, 0xC0, 0x1019, 0x8151, <token> <answer> 0x1}, 
<token> 0xC0, 0x1019, 0x1083, 0x1}, <answer> {0x1083, 
{0x1083, <token> 0x1462, 0x7680, 0x1}, <answer> 0xC0, 
{0x1083, <token> 0x1565, 0x2803, 0x1}, <answer> 0xC0, 
static void atl1c_patch_assign(struct <token> *hw) <answer> atl1c_hw 
struct pci_dev <token> = hw->adapter->pdev; <answer> *pdev 
u32 <token> <answer> misc_ctrl; 
int i <token> 0; <answer> = 
hw->msi_lnkpatch <token> false; <answer> = 
while (plats[i].pci_did != 0) <token> <answer> { 
if (plats[i].pci_did <token> hw->device_id && <answer> == 
plats[i].pci_revid <token> hw->revision_id && <answer> == 
plats[i].subsystem_vid <token> hw->subsystem_vendor_id && <answer> == 
plats[i].subsystem_did == hw->subsystem_id) <token> <answer> { 
if <token> & ATL1C_LINK_PATCH) <answer> (plats[i].patch_flag 
hw->msi_lnkpatch <token> true; <answer> = 
if (hw->device_id <token> PCI_DEVICE_ID_ATHEROS_L2C_B2 && <answer> == 
hw->revision_id == <token> { <answer> L2CB_V21) 
static int atl1c_sw_init(struct atl1c_adapter <token> <answer> *adapter) 
struct atl1c_hw *hw <token> &adapter->hw; <answer> = 
struct <token> *pdev = adapter->pdev; <answer> pci_dev 
<token> revision; <answer> u32 
int <token> <answer> i; 
adapter->wol = <token> <answer> 0; 
<token> false); <answer> device_set_wakeup_enable(&pdev->dev, 
<token> = SPEED_0; <answer> adapter->link_speed 
<token> = FULL_DUPLEX; <answer> adapter->link_duplex 
adapter->tpd_ring[0].count = <token> <answer> 1024; 
adapter->rfd_ring[0].count = <token> <answer> 512; 
hw->vendor_id = <token> <answer> pdev->vendor; 
<token> = pdev->device; <answer> hw->device_id 
<token> = pdev->subsystem_vendor; <answer> hw->subsystem_vendor_id 
hw->subsystem_id <token> pdev->subsystem_device; <answer> = 
pci_read_config_dword(pdev, PCI_CLASS_REVISION, <token> <answer> &revision); 
hw->revision_id <token> revision & 0xFF; <answer> = 
static <token> atl1c_clean_tx_ring(struct atl1c_adapter *adapter, <answer> void 
<token> queue) <answer> u32 
<token> atl1c_tpd_ring *tpd_ring = &adapter->tpd_ring[queue]; <answer> struct 
struct <token> *buffer_info; <answer> atl1c_buffer 
struct pci_dev <token> = adapter->pdev; <answer> *pdev 
u16 <token> ring_count; <answer> index, 
ring_count = <token> <answer> tpd_ring->count; 
for <token> = 0; index < ring_count; index++) { <answer> (index 
<token> = &tpd_ring->buffer_info[index]; <answer> buffer_info 
atl1c_clean_buffer(pdev, buffer_info, <token> <answer> 0); 
netdev_tx_reset_queue(netdev_get_tx_queue(adapter->netdev, <token> <answer> queue)); 
<token> void atl1c_clean_rx_ring(struct atl1c_adapter *adapter, u32 queue) <answer> static 
struct <token> *rfd_ring = &adapter->rfd_ring[queue]; <answer> atl1c_rfd_ring 
struct atl1c_rrd_ring <token> = &adapter->rrd_ring[queue]; <answer> *rrd_ring 
<token> atl1c_buffer *buffer_info; <answer> struct 
struct pci_dev *pdev = <token> <answer> adapter->pdev; 
<token> j; <answer> int 
for <token> = 0; j < rfd_ring->count; j++) { <answer> (j 
buffer_info = <token> <answer> &rfd_ring->buffer_info[j]; 
<token> buffer_info, 0); <answer> atl1c_clean_buffer(pdev, 
static void <token> atl1c_adapter *adapter) <answer> atl1c_init_ring_ptrs(struct 
struct atl1c_tpd_ring <token> = adapter->tpd_ring; <answer> *tpd_ring 
struct atl1c_rfd_ring <token> = adapter->rfd_ring; <answer> *rfd_ring 
<token> atl1c_rrd_ring *rrd_ring = adapter->rrd_ring; <answer> struct 
<token> atl1c_buffer *buffer_info; <answer> struct 
int <token> j; <answer> i, 
for (i <token> 0; i < adapter->tx_queue_count; i++) { <answer> = 
tpd_ring[i].next_to_use = <token> <answer> 0; 
atomic_set(&tpd_ring[i].next_to_clean, <token> <answer> 0); 
buffer_info <token> tpd_ring[i].buffer_info; <answer> = 
for (j <token> 0; j < tpd_ring->count; j++) <answer> = 
<token> (i = 0; i < adapter->rx_queue_count; i++) { <answer> for 
rfd_ring[i].next_to_use = <token> <answer> 0; 
rfd_ring[i].next_to_clean = <token> <answer> 0; 
<token> = 0; <answer> rrd_ring[i].next_to_use 
<token> = 0; <answer> rrd_ring[i].next_to_clean 
for (j = 0; j < <token> j++) { <answer> rfd_ring[i].count; 
<token> = &rfd_ring[i].buffer_info[j]; <answer> buffer_info 
ATL1C_SET_BUFFER_STATE(buffer_info, <token> <answer> ATL1C_BUFFER_FREE); 
<token> void atl1c_free_ring_resources(struct atl1c_adapter *adapter) <answer> static 
<token> pci_dev *pdev = adapter->pdev; <answer> struct 
<token> adapter->ring_header.size, <answer> dma_free_coherent(&pdev->dev, 
adapter->ring_header.desc, <token> <answer> adapter->ring_header.dma); 
<token> = NULL; <answer> adapter->ring_header.desc 
if (adapter->tpd_ring[0].buffer_info) <token> <answer> { 
adapter->tpd_ring[0].buffer_info <token> NULL; <answer> = 
static int <token> atl1c_adapter *adapter) <answer> atl1c_setup_ring_resources(struct 
struct pci_dev <token> = adapter->pdev; <answer> *pdev 
<token> atl1c_tpd_ring *tpd_ring = adapter->tpd_ring; <answer> struct 
struct atl1c_rfd_ring *rfd_ring <token> adapter->rfd_ring; <answer> = 
struct atl1c_rrd_ring <token> = adapter->rrd_ring; <answer> *rrd_ring 
<token> atl1c_ring_header *ring_header = &adapter->ring_header; <answer> struct 
int tqc = <token> <answer> adapter->tx_queue_count; 
<token> rqc = adapter->rx_queue_count; <answer> int 
<token> size; <answer> int 
<token> i; <answer> int 
<token> count = 0; <answer> int 
<token> offset = 0; <answer> u32 
if (tqc == <token> <answer> 1) 
tqc <token> 2; <answer> = 
for (i = 1; i <token> tqc; i++) <answer> < 
tpd_ring[i].count = <token> <answer> tpd_ring[0].count; 
size <token> sizeof(struct atl1c_buffer) * (tpd_ring->count * tqc + <answer> = 
rfd_ring->count <token> rqc); <answer> * 
tpd_ring->buffer_info <token> kzalloc(size, GFP_KERNEL); <answer> = 
if <token> <answer> (unlikely(!tpd_ring->buffer_info)) 
goto <token> <answer> err_nomem; 
for (i = <token> i < tqc; i++) { <answer> 0; 
<token> = adapter; <answer> tpd_ring[i].adapter 
<token> = i; <answer> tpd_ring[i].num 
tpd_ring[i].buffer_info <token> (tpd_ring->buffer_info + count); <answer> = 
count += <token> <answer> tpd_ring[i].count; 
for (i = 0; i < <token> i++) { <answer> rqc; 
rrd_ring[i].adapter <token> adapter; <answer> = 
rrd_ring[i].num = <token> <answer> i; 
rrd_ring[i].count = <token> <answer> rfd_ring[0].count; 
rfd_ring[i].count <token> rfd_ring[0].count; <answer> = 
<token> = (tpd_ring->buffer_info + count); <answer> rfd_ring[i].buffer_info 
count <token> rfd_ring->count; <answer> += 
ring_header->size <token> <answer> = 
sizeof(struct atl1c_tpd_desc) * tpd_ring->count * <token> + <answer> tqc 
sizeof(struct atl1c_rx_free_desc) * rfd_ring->count * rqc <token> <answer> + 
sizeof(struct atl1c_recv_ret_status) * rfd_ring->count <token> rqc + <answer> * 
<token> * 4; <answer> 8 
<token> = dma_alloc_coherent(&pdev->dev, ring_header->size, <answer> ring_header->desc 
<token> GFP_KERNEL); <answer> &ring_header->dma, 
if (unlikely(!ring_header->desc)) <token> <answer> { 
dev_err(&pdev->dev, "could not <token> memory for DMA buffer\n"); <answer> get 
goto <token> <answer> err_nomem; 
if <token> < DEVICE_CTRL_MAXRRS_MIN) { <answer> (hw->dmar_block 
pcie_set_readrq(adapter->pdev, <token> << DEVICE_CTRL_MAXRRS_MIN); <answer> 128 
<token> = DEVICE_CTRL_MAXRRS_MIN; <answer> hw->dmar_block 
<token> = <answer> txq_ctrl_data 
hw->nic_type == athr_l2c_b || hw->nic_type == athr_l2c_b2 <token> <answer> ? 
L2CB_TXQ_CFGV : <token> <answer> L1C_TXQ_CFGV; 
<token> REG_TXQ_CTRL, txq_ctrl_data); <answer> AT_WRITE_REG(hw, 
static <token> atl1c_configure_rx(struct atl1c_adapter *adapter) <answer> void 
struct <token> *hw = &adapter->hw; <answer> atl1c_hw 
<token> rxq_ctrl_data; <answer> u32 
<token> = (hw->rfd_burst & RXQ_RFD_BURST_NUM_MASK) << <answer> rxq_ctrl_data 
if <token> & ATL1C_RX_IPV6_CHKSUM) <answer> (hw->ctrl_flags 
<token> |= IPV6_CHKSUM_CTRL_EN; <answer> rxq_ctrl_data 
static <token> atl1c_stop_mac(struct atl1c_hw *hw) <answer> int 
<token> data; <answer> u32 
AT_READ_REG(hw, REG_RXQ_CTRL, <token> <answer> &data); 
data &= <token> <answer> ~RXQ_CTRL_EN; 
AT_WRITE_REG(hw, <token> data); <answer> REG_RXQ_CTRL, 
AT_READ_REG(hw, REG_TXQ_CTRL, <token> <answer> &data); 
data &= <token> <answer> ~TXQ_CTRL_EN; 
AT_WRITE_REG(hw, REG_TXQ_CTRL, <token> <answer> data); 
<token> IDLE_STATUS_RXQ_BUSY | IDLE_STATUS_TXQ_BUSY); <answer> atl1c_wait_until_idle(hw, 
<token> REG_MAC_CTRL, &data); <answer> AT_READ_REG(hw, 
data <token> ~(MAC_CTRL_TX_EN | MAC_CTRL_RX_EN); <answer> &= 
<token> REG_MAC_CTRL, data); <answer> AT_WRITE_REG(hw, 
return <token> <answer> (int)atl1c_wait_until_idle(hw, 
IDLE_STATUS_TXMAC_BUSY <token> IDLE_STATUS_RXMAC_BUSY); <answer> | 
static void <token> atl1c_adapter *adapter) <answer> atl1c_start_mac(struct 
struct atl1c_hw *hw <token> &adapter->hw; <answer> = 
u32 mac, <token> rxq; <answer> txq, 
hw->mac_duplex = adapter->link_duplex <token> FULL_DUPLEX; <answer> == 
<token> = adapter->link_speed == SPEED_1000 ? <answer> hw->mac_speed 
atl1c_mac_speed_1000 : <token> <answer> atl1c_mac_speed_10_100; 
AT_READ_REG(hw, <token> &txq); <answer> REG_TXQ_CTRL, 
<token> REG_RXQ_CTRL, &rxq); <answer> AT_READ_REG(hw, 
AT_READ_REG(hw, <token> &mac); <answer> REG_MAC_CTRL, 
txq <token> TXQ_CTRL_EN; <answer> |= 
<token> |= RXQ_CTRL_EN; <answer> rxq 
mac |= <token> | MAC_CTRL_TX_FLOW | <answer> MAC_CTRL_TX_EN 
<token> | MAC_CTRL_RX_FLOW | <answer> MAC_CTRL_RX_EN 
MAC_CTRL_ADD_CRC | MAC_CTRL_PAD <token> <answer> | 
<token> | MAC_CTRL_SINGLE_PAUSE_EN | <answer> MAC_CTRL_BC_EN 
<token> (hw->mac_duplex) <answer> if 
<token> |= MAC_CTRL_DUPLX; <answer> mac 
<token> &= ~MAC_CTRL_DUPLX; <answer> mac 
mac = FIELD_SETX(mac, <token> hw->mac_speed); <answer> MAC_CTRL_SPEED, 
<token> = FIELD_SETX(mac, MAC_CTRL_PRMLEN, hw->preamble_len); <answer> mac 
<token> REG_TXQ_CTRL, txq); <answer> AT_WRITE_REG(hw, 
<token> REG_RXQ_CTRL, rxq); <answer> AT_WRITE_REG(hw, 
AT_WRITE_REG(hw, REG_MAC_CTRL, <token> <answer> mac); 
<token> int atl1c_reset_mac(struct atl1c_hw *hw) <answer> static 
struct atl1c_adapter *adapter = <token> <answer> hw->adapter; 
struct pci_dev *pdev = <token> <answer> adapter->pdev; 
u32 ctrl_data = <token> <answer> 0; 
AT_READ_REG(hw, REG_MASTER_CTRL, <token> <answer> &ctrl_data); 
ctrl_data <token> MASTER_CTRL_OOB_DIS; <answer> |= 
AT_WRITE_REG(hw, REG_MASTER_CTRL, ctrl_data <token> MASTER_CTRL_SOFT_RST); <answer> | 
static void atl1c_set_aspm(struct atl1c_hw *hw, u16 <token> <answer> link_speed) 
u32 <token> <answer> pm_ctrl_data; 
u32 <token> <answer> link_l1_timer; 
AT_READ_REG(hw, REG_PM_CTRL, <token> <answer> &pm_ctrl_data); 
<token> &= ~(PM_CTRL_ASPM_L1_EN | <answer> pm_ctrl_data 
<token> | <answer> PM_CTRL_ASPM_L0S_EN 
<token> int atl1c_configure_mac(struct atl1c_adapter *adapter) <answer> static 
struct <token> *hw = &adapter->hw; <answer> atl1c_hw 
u32 <token> = 0; <answer> master_ctrl_data 
<token> intr_modrt_data; <answer> u32 
u32 <token> <answer> data; 
AT_READ_REG(hw, REG_MASTER_CTRL, <token> <answer> &master_ctrl_data); 
<token> &= ~(MASTER_CTRL_TX_ITIMER_EN | <answer> master_ctrl_data 
MASTER_CTRL_RX_ITIMER_EN <token> <answer> | 
<token> = CLK_GATING_EN_ALL; <answer> data 
if (hw->ctrl_flags & ATL1C_CLK_GATING_EN) <token> <answer> { 
if (hw->nic_type <token> athr_l2c_b) <answer> == 
<token> &= ~CLK_GATING_RXMAC_EN; <answer> data 
<token> else <answer> } 
data <token> 0; <answer> = 
AT_WRITE_REG(hw, REG_CLK_GATING_CTRL, <token> <answer> data); 
AT_WRITE_REG(hw, <token> <answer> REG_INT_RETRIG_TIMER, 
hw->ict & <token> <answer> INT_RETRIG_TIMER_MASK); 
if (hw->ctrl_flags & <token> { <answer> ATL1C_INTR_MODRT_ENABLE) 
intr_modrt_data = (hw->tx_imt & <token> << <answer> IRQ_MODRT_TIMER_MASK) 
intr_modrt_data |= (hw->rx_imt & IRQ_MODRT_TIMER_MASK) <token> <answer> << 
AT_WRITE_REG(hw, REG_IRQ_MODRT_TIMER_INIT, <token> <answer> intr_modrt_data); 
master_ctrl_data <token> <answer> |= 
<token> | MASTER_CTRL_RX_ITIMER_EN; <answer> MASTER_CTRL_TX_ITIMER_EN 
if (hw->ctrl_flags <token> ATL1C_INTR_CLEAR_ON_READ) <answer> & 
master_ctrl_data |= <token> <answer> MASTER_CTRL_INT_RDCLR; 
master_ctrl_data <token> MASTER_CTRL_SA_TIMER_EN; <answer> |= 
AT_WRITE_REG(hw, REG_MASTER_CTRL, <token> <answer> master_ctrl_data); 
<token> REG_SMB_STAT_TIMER, <answer> AT_WRITE_REG(hw, 
<token> & SMB_STAT_TIMER_MASK); <answer> hw->smb_timer 
static struct net_device_stats *atl1c_get_stats(struct <token> *netdev) <answer> net_device 
<token> atl1c_adapter *adapter = netdev_priv(netdev); <answer> struct 
struct atl1c_hw_stats <token> = &adapter->hw_stats; <answer> *hw_stats 
struct net_device_stats *net_stats <token> &netdev->stats; <answer> = 
<token> = hw_stats->rx_byte_cnt; <answer> net_stats->rx_bytes 
<token> = hw_stats->tx_byte_cnt; <answer> net_stats->tx_bytes 
net_stats->multicast <token> hw_stats->rx_mcast; <answer> = 
<token> = hw_stats->tx_1_col + <answer> net_stats->collisions 
hw_stats->tx_2_col <token> <answer> + 
hw_stats->tx_late_col <token> <answer> + 
net_stats->rx_errors = <token> + <answer> hw_stats->rx_frag 
<token> + <answer> hw_stats->rx_fcs_err 
hw_stats->rx_len_err <token> <answer> + 
<token> + <answer> hw_stats->rx_sz_ov 
<token> + <answer> hw_stats->rx_rrd_ov 
<token> + <answer> hw_stats->rx_align_err 
net_stats->rx_fifo_errors <token> hw_stats->rx_rxf_ov; <answer> = 
<token> = hw_stats->rx_len_err; <answer> net_stats->rx_length_errors 
net_stats->rx_crc_errors = <token> <answer> hw_stats->rx_fcs_err; 
net_stats->rx_frame_errors = <token> <answer> hw_stats->rx_align_err; 
net_stats->rx_dropped = <token> <answer> hw_stats->rx_rrd_ov; 
net_stats->tx_errors <token> hw_stats->tx_late_col + <answer> = 
<token> + <answer> hw_stats->tx_abort_col 
hw_stats->tx_underrun <token> <answer> + 
<token> = hw_stats->tx_underrun; <answer> net_stats->tx_fifo_errors 
net_stats->tx_aborted_errors = <token> <answer> hw_stats->tx_abort_col; 
<token> = hw_stats->tx_late_col; <answer> net_stats->tx_window_errors 
net_stats->rx_packets <token> hw_stats->rx_ok + net_stats->rx_errors; <answer> = 
<token> = hw_stats->tx_ok + net_stats->tx_errors; <answer> net_stats->tx_packets 
return <token> <answer> net_stats; 
static inline <token> atl1c_clear_phy_int(struct atl1c_adapter *adapter) <answer> void 
u16 <token> <answer> phy_data; 
<token> MII_ISR, &phy_data); <answer> atl1c_read_phy_reg(&adapter->hw, 
static int atl1c_clean_tx(struct napi_struct *napi, <token> budget) <answer> int 
<token> atl1c_tpd_ring *tpd_ring = <answer> struct 
container_of(napi, struct atl1c_tpd_ring, <token> <answer> napi); 
struct <token> *adapter = tpd_ring->adapter; <answer> atl1c_adapter 
<token> netdev_queue *txq = <answer> struct 
<token> tpd_ring->num); <answer> netdev_get_tx_queue(napi->dev, 
struct <token> *buffer_info; <answer> atl1c_buffer 
struct <token> *pdev = adapter->pdev; <answer> pci_dev 
u16 next_to_clean = <token> <answer> atomic_read(&tpd_ring->next_to_clean); 
u16 <token> <answer> hw_next_to_clean; 
unsigned int total_bytes = 0, total_packets <token> 0; <answer> = 
unsigned <token> flags; <answer> long 
AT_READ_REGW(&adapter->hw, <token> <answer> atl1c_qregs[tpd_ring->num].tpd_cons, 
while <token> != hw_next_to_clean) { <answer> (next_to_clean 
buffer_info = <token> <answer> &tpd_ring->buffer_info[next_to_clean]; 
if <token> { <answer> (buffer_info->skb) 
total_bytes += <token> <answer> buffer_info->skb->len; 
atl1c_clean_buffer(pdev, <token> budget); <answer> buffer_info, 
if (++next_to_clean <token> tpd_ring->count) <answer> == 
<token> = 0; <answer> next_to_clean 
<token> next_to_clean); <answer> atomic_set(&tpd_ring->next_to_clean, 
netdev_tx_completed_queue(txq, <token> total_bytes); <answer> total_packets, 
if <token> && netif_carrier_ok(adapter->netdev)) <answer> (netif_tx_queue_stopped(txq) 
if (total_packets < budget) <token> <answer> { 
napi_complete_done(napi, <token> <answer> total_packets); 
<token> flags); <answer> spin_lock_irqsave(&adapter->hw.intr_mask_lock, 
<token> |= atl1c_qregs[tpd_ring->num].tx_isr; <answer> adapter->hw.intr_mask 
<token> REG_IMR, adapter->hw.intr_mask); <answer> AT_WRITE_REG(&adapter->hw, 
<token> flags); <answer> spin_unlock_irqrestore(&adapter->hw.intr_mask_lock, 
return <token> <answer> total_packets; 
<token> budget; <answer> return 
<token> void atl1c_intr_rx_tx(struct atl1c_adapter *adapter, u32 status) <answer> static 
struct atl1c_hw *hw <token> &adapter->hw; <answer> = 
u32 <token> <answer> intr_mask; 
<token> i; <answer> int 
intr_mask = <token> <answer> hw->intr_mask; 
for (i = 0; <token> < adapter->rx_queue_count; ++i) { <answer> i 
<token> (!(status & atl1c_qregs[i].rx_isr)) <answer> if 
if <token> { <answer> (napi_schedule_prep(&adapter->rrd_ring[i].napi)) 
intr_mask &= <token> <answer> ~atl1c_qregs[i].rx_isr; 
<token> (i = 0; i < adapter->tx_queue_count; ++i) { <answer> for 
if (!(status <token> atl1c_qregs[i].tx_isr)) <answer> & 
<token> (napi_schedule_prep(&adapter->tpd_ring[i].napi)) { <answer> if 
<token> &= ~atl1c_qregs[i].tx_isr; <answer> intr_mask 
if (hw->intr_mask != intr_mask) <token> <answer> { 
hw->intr_mask = <token> <answer> intr_mask; 
AT_WRITE_REG(hw, REG_IMR, <token> <answer> hw->intr_mask); 
static irqreturn_t <token> irq, void *data) <answer> atl1c_intr(int 
struct net_device *netdev = <token> <answer> data; 
<token> atl1c_adapter *adapter = netdev_priv(netdev); <answer> struct 
struct pci_dev *pdev <token> adapter->pdev; <answer> = 
struct atl1c_hw *hw = <token> <answer> &adapter->hw; 
int max_ints = <token> <answer> AT_MAX_INT_WORK; 
int <token> = IRQ_NONE; <answer> handled 
<token> status; <answer> u32 
<token> reg_data; <answer> u32 
do <token> <answer> { 
AT_READ_REG(hw, <token> &reg_data); <answer> REG_ISR, 
<token> = reg_data & hw->intr_mask; <answer> status 
if (status <token> 0 || (status & ISR_DIS_INT) != 0) { <answer> == 
if (max_ints != <token> <answer> AT_MAX_INT_WORK) 
handled <token> IRQ_HANDLED; <answer> = 
<token> int atl1c_alloc_rx_buffer(struct atl1c_adapter *adapter, u32 queue, <answer> static 
<token> napi_mode) <answer> bool 
struct atl1c_rfd_ring *rfd_ring = <token> <answer> &adapter->rfd_ring[queue]; 
struct atl1c_rrd_ring *rrd_ring <token> &adapter->rrd_ring[queue]; <answer> = 
<token> pci_dev *pdev = adapter->pdev; <answer> struct 
struct <token> *buffer_info, *next_info; <answer> atl1c_buffer 
struct sk_buff <token> <answer> *skb; 
void *vir_addr = <token> <answer> NULL; 
u16 num_alloc <token> 0; <answer> = 
u16 <token> next_next; <answer> rfd_next_to_use, 
struct atl1c_rx_free_desc <token> <answer> *rfd_desc; 
<token> mapping; <answer> dma_addr_t 
next_next <token> rfd_next_to_use = rfd_ring->next_to_use; <answer> = 
<token> (++next_next == rfd_ring->count) <answer> if 
<token> = 0; <answer> next_next 
buffer_info = <token> <answer> &rfd_ring->buffer_info[rfd_next_to_use]; 
next_info <token> &rfd_ring->buffer_info[next_next]; <answer> = 
while <token> & ATL1C_BUFFER_FREE) { <answer> (next_info->flags 
rfd_desc = <token> rfd_next_to_use); <answer> ATL1C_RFD_DESC(rfd_ring, 
<token> (likely(napi_mode)) <answer> if 
skb = napi_alloc_skb(&rrd_ring->napi, adapter->rx_buffer_len <token> 64); <answer> + 
skb = netdev_alloc_skb(adapter->netdev, <token> + 64); <answer> adapter->rx_buffer_len 
<token> (unlikely(!skb)) { <answer> if 
<token> (netif_msg_rx_err(adapter)) <answer> if 
dev_warn(&pdev->dev, "alloc rx buffer <token> <answer> failed\n"); 
if (((unsigned <token> & 0xfff) == 0xfc0) <answer> long)skb->data 
skb_reserve(skb, <token> <answer> 64); 
vir_addr <token> skb->data; <answer> = 
<token> ATL1C_BUFFER_BUSY); <answer> ATL1C_SET_BUFFER_STATE(buffer_info, 
buffer_info->skb <token> skb; <answer> = 
buffer_info->length = <token> <answer> adapter->rx_buffer_len; 
mapping = dma_map_single(&pdev->dev, <token> <answer> vir_addr, 
buffer_info->length, <token> <answer> DMA_FROM_DEVICE); 
if (unlikely(dma_mapping_error(&pdev->dev, mapping))) <token> <answer> { 
<token> = NULL; <answer> buffer_info->skb 
<token> = 0; <answer> buffer_info->length 
ATL1C_SET_BUFFER_STATE(buffer_info, <token> <answer> ATL1C_BUFFER_FREE); 
netif_warn(adapter, rx_err, <token> "RX dma_map_single failed"); <answer> adapter->netdev, 
buffer_info->dma = <token> <answer> mapping; 
<token> ATL1C_PCIMAP_SINGLE, <answer> ATL1C_SET_PCIMAP_TYPE(buffer_info, 
rfd_desc->buffer_addr <token> cpu_to_le64(buffer_info->dma); <answer> = 
<token> = next_next; <answer> rfd_next_to_use 
<token> (++next_next == rfd_ring->count) <answer> if 
<token> = 0; <answer> next_next 
buffer_info = <token> <answer> &rfd_ring->buffer_info[rfd_next_to_use]; 
<token> = &rfd_ring->buffer_info[next_next]; <answer> next_info 
<token> (num_alloc) { <answer> if 
static int atl1c_clean_rx(struct <token> *napi, int budget) <answer> napi_struct 
struct atl1c_rrd_ring *rrd_ring <token> <answer> = 
container_of(napi, struct <token> napi); <answer> atl1c_rrd_ring, 
struct <token> *adapter = rrd_ring->adapter; <answer> atl1c_adapter 
u16 <token> rfd_index; <answer> rfd_num, 
u16 <token> <answer> length; 
struct pci_dev *pdev = <token> <answer> adapter->pdev; 
struct net_device *netdev <token> adapter->netdev; <answer> = 
<token> atl1c_rfd_ring *rfd_ring = &adapter->rfd_ring[rrd_ring->num]; <answer> struct 
struct sk_buff <token> <answer> *skb; 
struct atl1c_recv_ret_status <token> <answer> *rrs; 
struct atl1c_buffer <token> <answer> *buffer_info; 
<token> work_done = 0; <answer> int 
unsigned <token> flags; <answer> long 
static void atl1c_netpoll(struct <token> *netdev) <answer> net_device 
struct atl1c_adapter <token> = netdev_priv(netdev); <answer> *adapter 
atl1c_intr(adapter->pdev->irq, <token> <answer> netdev); 
static <token> u16 atl1c_tpd_avail(struct atl1c_adapter *adapter, u32 queue) <answer> inline 
<token> atl1c_tpd_ring *tpd_ring = &adapter->tpd_ring[queue]; <answer> struct 
u16 next_to_use <token> 0; <answer> = 
u16 <token> = 0; <answer> next_to_clean 
<token> = atomic_read(&tpd_ring->next_to_clean); <answer> next_to_clean 
<token> = tpd_ring->next_to_use; <answer> next_to_use 
return (u16)(next_to_clean <token> next_to_use) ? <answer> > 
(next_to_clean - next_to_use - <token> : <answer> 1) 
(tpd_ring->count + <token> - next_to_use - 1); <answer> next_to_clean 
static struct <token> *atl1c_get_tpd(struct atl1c_adapter *adapter, <answer> atl1c_tpd_desc 
<token> queue) <answer> u32 
struct atl1c_tpd_ring *tpd_ring = <token> <answer> &adapter->tpd_ring[queue]; 
<token> atl1c_tpd_desc *tpd_desc; <answer> struct 
u16 next_to_use <token> 0; <answer> = 
<token> = tpd_ring->next_to_use; <answer> next_to_use 
<token> (++tpd_ring->next_to_use == tpd_ring->count) <answer> if 
tpd_ring->next_to_use <token> 0; <answer> = 
tpd_desc = ATL1C_TPD_DESC(tpd_ring, <token> <answer> next_to_use); 
memset(tpd_desc, 0, sizeof(struct <token> <answer> atl1c_tpd_desc)); 
<token> tpd_desc; <answer> return 
static <token> atl1c_buffer * <answer> struct 
atl1c_get_tx_buffer(struct atl1c_adapter *adapter, <token> atl1c_tpd_desc *tpd) <answer> struct 
struct atl1c_tpd_ring *tpd_ring = <token> <answer> adapter->tpd_ring; 
return <token> - <answer> &tpd_ring->buffer_info[tpd 
(struct atl1c_tpd_desc <token> <answer> *)tpd_ring->desc]; 
if <token> == 0) <answer> (mapped_len 
use_tpd = <token> <answer> tpd; 
else <token> <answer> { 
use_tpd = atl1c_get_tpd(adapter, <token> <answer> queue); 
memcpy(use_tpd, <token> sizeof(struct atl1c_tpd_desc)); <answer> tpd, 
buffer_info <token> atl1c_get_tx_buffer(adapter, use_tpd); <answer> = 
buffer_info->length <token> buf_len - mapped_len; <answer> = 
buffer_info->dma <token> <answer> = 
<token> + mapped_len, <answer> skb->data 
buffer_info->length, <token> <answer> DMA_TO_DEVICE); 
<token> (unlikely(dma_mapping_error(&adapter->pdev->dev, buffer_info->dma))) <answer> if 
goto <token> <answer> err_dma; 
ATL1C_SET_BUFFER_STATE(buffer_info, <token> <answer> ATL1C_BUFFER_BUSY); 
<token> ATL1C_PCIMAP_SINGLE, <answer> ATL1C_SET_PCIMAP_TYPE(buffer_info, 
use_tpd->buffer_addr <token> cpu_to_le64(buffer_info->dma); <answer> = 
<token> = cpu_to_le16(buffer_info->length); <answer> use_tpd->buffer_len 
for (f = 0; f < nr_frags; <token> { <answer> f++) 
<token> *frag = &skb_shinfo(skb)->frags[f]; <answer> skb_frag_t 
use_tpd = atl1c_get_tpd(adapter, <token> <answer> queue); 
memcpy(use_tpd, <token> sizeof(struct atl1c_tpd_desc)); <answer> tpd, 
buffer_info <token> atl1c_get_tx_buffer(adapter, use_tpd); <answer> = 
buffer_info->length = <token> <answer> skb_frag_size(frag); 
buffer_info->dma <token> skb_frag_dma_map(&adapter->pdev->dev, <answer> = 
frag, <token> <answer> 0, 
if (dma_mapping_error(&adapter->pdev->dev, <token> <answer> buffer_info->dma)) 
goto <token> <answer> err_dma; 
<token> ATL1C_BUFFER_BUSY); <answer> ATL1C_SET_BUFFER_STATE(buffer_info, 
ATL1C_SET_PCIMAP_TYPE(buffer_info, <token> <answer> ATL1C_PCIMAP_PAGE, 
<token> = cpu_to_le64(buffer_info->dma); <answer> use_tpd->buffer_addr 
use_tpd->buffer_len <token> cpu_to_le16(buffer_info->length); <answer> = 
<token> = skb; <answer> buffer_info->skb 
<token> 0; <answer> return 
<token> = 0; <answer> buffer_info->dma 
buffer_info->length = <token> <answer> 0; 
<token> -1; <answer> return 
static void atl1c_tx_queue(struct atl1c_adapter <token> u32 queue) <answer> *adapter, 
struct <token> *tpd_ring = &adapter->tpd_ring[queue]; <answer> atl1c_tpd_ring 
<token> atl1c_qregs[queue].tpd_prod, <answer> AT_WRITE_REGW(&adapter->hw, 
static <token> atl1c_xmit_frame(struct sk_buff *skb, <answer> netdev_tx_t 
struct net_device <token> <answer> *netdev) 
<token> atl1c_adapter *adapter = netdev_priv(netdev); <answer> struct 
u32 <token> = skb_get_queue_mapping(skb); <answer> queue 
struct netdev_queue *txq = <token> queue); <answer> netdev_get_tx_queue(netdev, 
struct atl1c_tpd_desc <token> <answer> *tpd; 
u16 <token> <answer> tpd_req; 
if (test_bit(__AT_DOWN, <token> { <answer> &adapter->flags)) 
<token> NETDEV_TX_OK; <answer> return 
<token> = atl1c_cal_tpd_req(skb); <answer> tpd_req 
if (atl1c_tpd_avail(adapter, queue) < <token> { <answer> tpd_req) 
set_bit(__AT_DOWN, <token> <answer> &adapter->flags); 
for <token> = 0; i < adapter->tx_queue_count; ++i) <answer> (i 
for (i = 0; i < <token> ++i) <answer> adapter->rx_queue_count; 
static int <token> net_device *netdev) <answer> atl1c_open(struct 
struct atl1c_adapter *adapter = <token> <answer> netdev_priv(netdev); 
<token> err; <answer> int 
static <token> atl1c_close(struct net_device *netdev) <answer> int 
struct atl1c_adapter <token> = netdev_priv(netdev); <answer> *adapter 
WARN_ON(test_bit(__AT_RESETTING, <token> <answer> &adapter->flags)); 
set_bit(__AT_DOWN, <token> <answer> &adapter->flags); 
<token> 0; <answer> return 
static int atl1c_suspend(struct <token> *dev) <answer> device 
struct net_device *netdev = <token> <answer> dev_get_drvdata(dev); 
struct atl1c_adapter <token> = netdev_priv(netdev); <answer> *adapter 
struct <token> *hw = &adapter->hw; <answer> atl1c_hw 
u32 <token> = adapter->wol; <answer> wufc 
if <token> { <answer> (netif_running(netdev)) 
<token> &adapter->flags)); <answer> WARN_ON(test_bit(__AT_RESETTING, 
<token> (wufc) <answer> if 
if (atl1c_phy_to_ps_link(hw) <token> 0) <answer> != 
dev_dbg(dev, "phy power saving <token> <answer> failed"); 
atl1c_power_saving(hw, <token> <answer> wufc); 
return <token> <answer> 0; 
#ifdef <token> <answer> CONFIG_PM_SLEEP 
static <token> atl1c_resume(struct device *dev) <answer> int 
struct <token> *netdev = dev_get_drvdata(dev); <answer> net_device 
<token> atl1c_adapter *adapter = netdev_priv(netdev); <answer> struct 
AT_WRITE_REG(&adapter->hw, <token> 0); <answer> REG_WOL_CTRL, 
atl1c_reset_pcie(&adapter->hw, <token> <answer> ATL1C_PCIE_L0S_L1_DISABLE); 
<token> (netif_running(netdev)) <answer> if 
return <token> <answer> 0; 
<token> void atl1c_shutdown(struct pci_dev *pdev) <answer> static 
struct net_device *netdev <token> pci_get_drvdata(pdev); <answer> = 
struct atl1c_adapter *adapter <token> netdev_priv(netdev); <answer> = 
<token> adapter->wol); <answer> pci_wake_from_d3(pdev, 
<token> PCI_D3hot); <answer> pci_set_power_state(pdev, 
static const struct net_device_ops atl1c_netdev_ops = <token> <answer> { 
.ndo_open = <token> <answer> atl1c_open, 
<token> = atl1c_close, <answer> .ndo_stop 
<token> = eth_validate_addr, <answer> .ndo_validate_addr 
.ndo_start_xmit <token> atl1c_xmit_frame, <answer> = 
.ndo_set_mac_address = <token> <answer> atl1c_set_mac_addr, 
.ndo_set_rx_mode <token> atl1c_set_multi, <answer> = 
.ndo_change_mtu <token> atl1c_change_mtu, <answer> = 
.ndo_fix_features <token> atl1c_fix_features, <answer> = 
<token> = atl1c_set_features, <answer> .ndo_set_features 
.ndo_eth_ioctl = <token> <answer> atl1c_ioctl, 
.ndo_tx_timeout <token> atl1c_tx_timeout, <answer> = 
<token> = atl1c_get_stats, <answer> .ndo_get_stats 
#ifdef <token> <answer> CONFIG_NET_POLL_CONTROLLER 
<token> = atl1c_netpoll, <answer> .ndo_poll_controller 
static int atl1c_init_netdev(struct net_device *netdev, struct <token> *pdev) <answer> pci_dev 
SET_NETDEV_DEV(netdev, <token> <answer> &pdev->dev); 
pci_set_drvdata(pdev, <token> <answer> netdev); 
netdev->netdev_ops = <token> <answer> &atl1c_netdev_ops; 
netdev->watchdog_timeo <token> AT_TX_WATCHDOG; <answer> = 
netdev->min_mtu <token> ETH_ZLEN - (ETH_HLEN + VLAN_HLEN); <answer> = 
static int atl1c_probe(struct pci_dev *pdev, <token> struct pci_device_id *ent) <answer> const 
struct <token> *netdev; <answer> net_device 
struct <token> *adapter; <answer> atl1c_adapter 
<token> int cards_found; <answer> static 
<token> __iomem *hw_addr; <answer> u8 
enum atl1c_nic_type <token> <answer> nic_type; 
<token> queue_count = 1; <answer> u32 
int err = <token> <answer> 0; 
<token> i; <answer> int 
<token> = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32)); <answer> err 
<token> (err) { <answer> if 
dev_err(&pdev->dev, "No <token> DMA configuration,aborting\n"); <answer> usable 
goto <token> <answer> err_dma; 
err = pci_request_regions(pdev, <token> <answer> atl1c_driver_name); 
<token> (err) { <answer> if 
dev_err(&pdev->dev, "cannot obtain PCI <token> <answer> resources\n"); 
<token> err_pci_reg; <answer> goto 
hw_addr <token> pci_ioremap_bar(pdev, 0); <answer> = 
if (!hw_addr) <token> <answer> { 
<token> = -EIO; <answer> err 
<token> "cannot map device registers\n"); <answer> dev_err(&pdev->dev, 
<token> err_ioremap; <answer> goto 
nic_type <token> atl1c_get_mac_type(pdev, hw_addr); <answer> = 
if <token> == athr_mt) <answer> (nic_type 
<token> = 4; <answer> queue_count 
netdev = <token> atl1c_adapter), queue_count); <answer> alloc_etherdev_mq(sizeof(struct 
if (netdev <token> NULL) { <answer> == 
err <token> -ENOMEM; <answer> = 
goto <token> <answer> err_alloc_etherdev; 
err = <token> pdev); <answer> atl1c_init_netdev(netdev, 
if <token> { <answer> (err) 
dev_err(&pdev->dev, "init <token> failed\n"); <answer> netdevice 
<token> err_init_netdev; <answer> goto 
adapter <token> netdev_priv(netdev); <answer> = 
adapter->bd_number = <token> <answer> cards_found; 
adapter->netdev = <token> <answer> netdev; 
adapter->pdev = <token> <answer> pdev; 
<token> = adapter; <answer> adapter->hw.adapter 
<token> = nic_type; <answer> adapter->hw.nic_type 
adapter->msg_enable <token> netif_msg_init(-1, atl1c_default_msg); <answer> = 
adapter->hw.hw_addr <token> hw_addr; <answer> = 
adapter->tx_queue_count = <token> <answer> queue_count; 
adapter->rx_queue_count = <token> <answer> queue_count; 
err <token> atl1c_phy_init(&adapter->hw); <answer> = 
if (err) <token> <answer> { 
<token> = -EIO; <answer> err 
goto <token> <answer> err_reset; 
<token> (atl1c_read_mac_addr(&adapter->hw)) { <answer> if 
static void atl1c_remove(struct <token> *pdev) <answer> pci_dev 
<token> net_device *netdev = pci_get_drvdata(pdev); <answer> struct 
struct atl1c_adapter *adapter = <token> <answer> netdev_priv(netdev); 
static pci_ers_result_t atl1c_io_error_detected(struct <token> *pdev, <answer> pci_dev 
<token> state) <answer> pci_channel_state_t 
struct net_device <token> = pci_get_drvdata(pdev); <answer> *netdev 
<token> atl1c_adapter *adapter = netdev_priv(netdev); <answer> struct 
if (state <token> pci_channel_io_perm_failure) <answer> == 
<token> PCI_ERS_RESULT_DISCONNECT; <answer> return 
<token> (netif_running(netdev)) <answer> if 
static pci_ers_result_t <token> pci_dev *pdev) <answer> atl1c_io_slot_reset(struct 
<token> net_device *netdev = pci_get_drvdata(pdev); <answer> struct 
struct atl1c_adapter *adapter = <token> <answer> netdev_priv(netdev); 
if (pci_enable_device(pdev)) <token> <answer> { 
if <token> <answer> (netif_msg_hw(adapter)) 
"Cannot <token> PCI device after reset\n"); <answer> re-enable 
<token> PCI_ERS_RESULT_DISCONNECT; <answer> return 
<token> PCI_D3hot, 0); <answer> pci_enable_wake(pdev, 
pci_enable_wake(pdev, <token> 0); <answer> PCI_D3cold, 
<token> PCI_ERS_RESULT_RECOVERED; <answer> return 
static void atl1c_io_resume(struct pci_dev <token> <answer> *pdev) 
struct net_device *netdev <token> pci_get_drvdata(pdev); <answer> = 
<token> atl1c_adapter *adapter = netdev_priv(netdev); <answer> struct 
if (netif_running(netdev)) <token> <answer> { 
if <token> { <answer> (atl1c_up(adapter)) 
<token> (netif_msg_hw(adapter)) <answer> if 
"Cannot bring device back up after <token> <answer> reset\n"); 
static const struct pci_error_handlers atl1c_err_handler = <token> <answer> { 
<token> = atl1c_io_error_detected, <answer> .error_detected 
<token> = atl1c_io_slot_reset, <answer> .slot_reset 
.resume <token> atl1c_io_resume, <answer> = 
static SIMPLE_DEV_PM_OPS(atl1c_pm_ops, atl1c_suspend, <token> <answer> atl1c_resume); 
static struct pci_driver <token> = { <answer> atl1c_driver 
.name = <token> <answer> atl1c_driver_name, 
.id_table <token> atl1c_pci_tbl, <answer> = 
.probe = <token> <answer> atl1c_probe, 
<token> = atl1c_remove, <answer> .remove 
.shutdown <token> atl1c_shutdown, <answer> = 
<token> = &atl1c_err_handler, <answer> .err_handler 
.driver.pm = <token> <answer> &atl1c_pm_ops, 
<token> <linux/mm.h> <answer> #include 
<token> <linux/rbtree.h> <answer> #include 
#include <token> <answer> <trace/events/btrfs.h> 
#include <token> <answer> "ctree.h" 
<token> "disk-io.h" <answer> #include 
#include <token> <answer> "backref.h" 
<token> "ulist.h" <answer> #include 
<token> "transaction.h" <answer> #include 
#include <token> <answer> "delayed-ref.h" 
#include <token> <answer> "locking.h" 
#include <token> <answer> "misc.h" 
#include <token> <answer> "tree-mod-log.h" 
<token> "fs.h" <answer> #include 
#include <token> <answer> "accessors.h" 
#include <token> <answer> "extent-tree.h" 
#include <token> <answer> "relocation.h" 
<token> "tree-checker.h" <answer> #include 
nritems = <token> <answer> btrfs_header_nritems(eb); 
for (slot = 0; <token> < nritems; ++slot) { <answer> slot 
btrfs_item_key_to_cpu(eb, <token> slot); <answer> &key, 
if (key.type <token> BTRFS_EXTENT_DATA_KEY) <answer> != 
fi = btrfs_item_ptr(eb, <token> struct btrfs_file_extent_item); <answer> slot, 
extent_type = btrfs_file_extent_type(eb, <token> <answer> fi); 
if <token> == BTRFS_FILE_EXTENT_INLINE) <answer> (extent_type 
<token> share_check { <answer> struct 
struct <token> *ctx; <answer> btrfs_backref_share_check_ctx 
struct btrfs_root <token> <answer> *root; 
u64 <token> <answer> inum; 
<token> data_bytenr; <answer> u64 
u64 <token> <answer> data_extent_gen; 
<token> share_count; <answer> int 
<token> self_ref_count; <answer> int 
bool <token> <answer> have_delayed_delete_refs; 
<token> inline int extent_is_shared(struct share_check *sc) <answer> static 
return (sc && sc->share_count > 1) <token> BACKREF_FOUND_SHARED : 0; <answer> ? 
static <token> kmem_cache *btrfs_prelim_ref_cache; <answer> struct 
int __init <token> <answer> btrfs_prelim_ref_init(void) 
<token> = kmem_cache_create("btrfs_prelim_ref", <answer> btrfs_prelim_ref_cache 
sizeof(struct prelim_ref), 0, 0, <token> <answer> NULL); 
<token> (!btrfs_prelim_ref_cache) <answer> if 
return <token> <answer> -ENOMEM; 
<token> 0; <answer> return 
void <token> btrfs_prelim_ref_exit(void) <answer> __cold 
static void free_pref(struct prelim_ref <token> <answer> *ref) 
<token> ref); <answer> kmem_cache_free(btrfs_prelim_ref_cache, 
static <token> prelim_ref_compare(struct prelim_ref *ref1, <answer> int 
struct prelim_ref <token> <answer> *ref2) 
if (ref1->level <token> ref2->level) <answer> < 
return <token> <answer> -1; 
if (ref1->level > <token> <answer> ref2->level) 
<token> 1; <answer> return 
if (ref1->root_id <token> ref2->root_id) <answer> < 
return <token> <answer> -1; 
if <token> > ref2->root_id) <answer> (ref1->root_id 
<token> 1; <answer> return 
if <token> < ref2->key_for_search.type) <answer> (ref1->key_for_search.type 
<token> -1; <answer> return 
if <token> > ref2->key_for_search.type) <answer> (ref1->key_for_search.type 
<token> 1; <answer> return 
if (ref1->key_for_search.objectid < <token> <answer> ref2->key_for_search.objectid) 
<token> -1; <answer> return 
if (ref1->key_for_search.objectid > <token> <answer> ref2->key_for_search.objectid) 
<token> 1; <answer> return 
if (ref1->key_for_search.offset <token> ref2->key_for_search.offset) <answer> < 
return <token> <answer> -1; 
if <token> > ref2->key_for_search.offset) <answer> (ref1->key_for_search.offset 
return <token> <answer> 1; 
if <token> < ref2->parent) <answer> (ref1->parent 
return <token> <answer> -1; 
if (ref1->parent <token> ref2->parent) <answer> > 
return <token> <answer> 1; 
<token> 0; <answer> return 
static <token> update_share_count(struct share_check *sc, int oldcount, <answer> void 
int newcount, struct <token> *newref) <answer> prelim_ref 
if ((!sc) || (oldcount == 0 && <token> < 1)) <answer> newcount 
if <token> > 0 && newcount < 1) <answer> (oldcount 
else if (oldcount < 1 && newcount <token> 0) <answer> > 
if (newref->root_id == <token> && <answer> sc->root->root_key.objectid 
newref->wanted_disk_byte == <token> && <answer> sc->data_bytenr 
newref->key_for_search.objectid == <token> <answer> sc->inum) 
sc->self_ref_count <token> newref->count; <answer> += 
static void <token> struct btrfs_fs_info *fs_info, <answer> prelim_ref_insert(const 
struct preftree <token> <answer> *preftree, 
struct prelim_ref <token> <answer> *newref, 
<token> share_check *sc) <answer> struct 
struct rb_root_cached <token> <answer> *root; 
struct <token> **p; <answer> rb_node 
struct rb_node <token> = NULL; <answer> *parent 
struct <token> *ref; <answer> prelim_ref 
int <token> <answer> result; 
<token> leftmost = true; <answer> bool 
<token> = &preftree->root; <answer> root 
p = <token> <answer> &root->rb_root.rb_node; 
while <token> { <answer> (*p) 
parent = <token> <answer> *p; 
<token> = rb_entry(parent, struct prelim_ref, rbnode); <answer> ref 
result <token> prelim_ref_compare(ref, newref); <answer> = 
<token> (result < 0) { <answer> if 
p <token> &(*p)->rb_left; <answer> = 
} else if (result > <token> { <answer> 0) 
p <token> &(*p)->rb_right; <answer> = 
leftmost <token> false; <answer> = 
<token> else { <answer> } 
update_share_count(sc, <token> <answer> ref->count, 
ref->count + newref->count, <token> <answer> newref); 
ref->count += <token> <answer> newref->count; 
update_share_count(sc, 0, newref->count, <token> <answer> newref); 
<token> newref, NULL, preftree->count); <answer> trace_btrfs_prelim_ref_insert(fs_info, 
<token> parent, p); <answer> rb_link_node(&newref->rbnode, 
rb_insert_color_cached(&newref->rbnode, <token> leftmost); <answer> root, 
static void prelim_release(struct preftree <token> <answer> *preftree) 
struct <token> *ref, *next_ref; <answer> prelim_ref 
rbtree_postorder_for_each_entry_safe(ref, <token> <answer> next_ref, 
&preftree->root.rb_root, rbnode) <token> <answer> { 
preftree->root <token> RB_ROOT_CACHED; <answer> = 
<token> = 0; <answer> preftree->count 
static int add_prelim_ref(const struct <token> *fs_info, <answer> btrfs_fs_info 
<token> preftree *preftree, u64 root_id, <answer> struct 
const struct btrfs_key *key, int level, u64 <token> <answer> parent, 
<token> wanted_disk_byte, int count, <answer> u64 
<token> share_check *sc, gfp_t gfp_mask) <answer> struct 
<token> prelim_ref *ref; <answer> struct 
<token> (root_id == BTRFS_DATA_RELOC_TREE_OBJECTID) <answer> if 
return <token> <answer> 0; 
<token> = kmem_cache_alloc(btrfs_prelim_ref_cache, gfp_mask); <answer> ref 
<token> (!ref) <answer> if 
<token> -ENOMEM; <answer> return 
ref->root_id <token> root_id; <answer> = 
<token> (key) <answer> if 
ref->key_for_search <token> *key; <answer> = 
memset(&ref->key_for_search, <token> sizeof(ref->key_for_search)); <answer> 0, 
ref->inode_list = <token> <answer> NULL; 
<token> = level; <answer> ref->level 
<token> = count; <answer> ref->count 
<token> = parent; <answer> ref->parent 
<token> = wanted_disk_byte; <answer> ref->wanted_disk_byte 
prelim_ref_insert(fs_info, <token> ref, sc); <answer> preftree, 
return <token> <answer> extent_is_shared(sc); 
eb <token> path->nodes[0]; <answer> = 
if (path->slots[0] >= <token> || <answer> btrfs_header_nritems(eb) 
is_shared_data_backref(preftrees, eb->start) <token> <answer> || 
ref->root_id != btrfs_header_owner(eb)) <token> <answer> { 
if (ctx->time_seq <token> BTRFS_SEQ_LAST) <answer> == 
ret = <token> path); <answer> btrfs_next_leaf(root, 
ret <token> btrfs_next_old_leaf(root, path, ctx->time_seq); <answer> = 
while (!ret && count < ref->count) <token> <answer> { 
<token> = path->nodes[0]; <answer> eb 
slot <token> path->slots[0]; <answer> = 
<token> &key, slot); <answer> btrfs_item_key_to_cpu(eb, 
<token> (key.objectid != key_for_search->objectid || <answer> if 
key.type <token> BTRFS_EXTENT_DATA_KEY) <answer> != 
if (slot <token> 0 && <answer> == 
<token> eb->start) || <answer> (is_shared_data_backref(preftrees, 
ref->root_id <token> btrfs_header_owner(eb))) { <answer> != 
if (ctx->time_seq <token> BTRFS_SEQ_LAST) <answer> == 
ret = btrfs_next_leaf(root, <token> <answer> path); 
ret = <token> path, ctx->time_seq); <answer> btrfs_next_old_leaf(root, 
<token> = btrfs_item_ptr(eb, slot, struct btrfs_file_extent_item); <answer> fi 
<token> = btrfs_file_extent_type(eb, fi); <answer> type 
if (type <token> BTRFS_FILE_EXTENT_INLINE) <answer> == 
<token> next; <answer> goto 
<token> = btrfs_file_extent_disk_bytenr(eb, fi); <answer> disk_byte 
<token> = btrfs_file_extent_offset(eb, fi); <answer> data_offset 
if <token> == wanted_disk_byte) { <answer> (disk_byte 
<token> = NULL; <answer> eie 
<token> = NULL; <answer> old 
if (ref->key_for_search.offset <token> key.offset - data_offset) <answer> == 
<token> next; <answer> goto 
<token> (!ctx->skip_inode_ref_list) { <answer> if 
ret = check_extent_in_eb(ctx, <token> eb, fi, &eie); <answer> &key, 
<token> (ret == BTRFS_ITERATE_EXTENT_INODES_STOP || <answer> if 
ret < <token> <answer> 0) 
if (ret <token> 0) <answer> > 
<token> next; <answer> goto 
<token> = ulist_add_merge_ptr(parents, eb->start, <answer> ret 
eie, (void **)&old, <token> <answer> GFP_NOFS); 
if <token> < 0) <answer> (ret 
if (!ret && !ctx->skip_inode_ref_list) <token> <answer> { 
<token> (old->next) <answer> while 
old <token> old->next; <answer> = 
old->next <token> eie; <answer> = 
eie = <token> <answer> NULL; 
if <token> == BTRFS_SEQ_LAST) <answer> (ctx->time_seq 
ret = btrfs_next_item(root, <token> <answer> path); 
<token> = btrfs_next_old_item(root, path, ctx->time_seq); <answer> ret 
if <token> == BTRFS_ITERATE_EXTENT_INODES_STOP || ret < 0) <answer> (ret 
else <token> (ret > 0) <answer> if 
<token> = 0; <answer> ret 
return <token> <answer> ret; 
static int resolve_indirect_ref(struct btrfs_backref_walk_ctx <token> <answer> *ctx, 
struct btrfs_path <token> <answer> *path, 
struct <token> *preftrees, <answer> preftrees 
struct prelim_ref *ref, struct <token> *parents) <answer> ulist 
<token> btrfs_root *root; <answer> struct 
<token> extent_buffer *eb; <answer> struct 
int <token> = 0; <answer> ret 
<token> root_level; <answer> int 
int level = <token> <answer> ref->level; 
struct btrfs_key search_key = <token> <answer> ref->key_for_search; 
if <token> <answer> (path->search_commit_root) 
root = <token> path, ref->root_id); <answer> btrfs_get_fs_root_commit_root(ctx->fs_info, 
root <token> btrfs_get_fs_root(ctx->fs_info, ref->root_id, false); <answer> = 
if (IS_ERR(root)) <token> <answer> { 
ret <token> PTR_ERR(root); <answer> = 
goto <token> <answer> out_free; 
if <token> && <answer> (!path->search_commit_root 
test_bit(BTRFS_ROOT_DELETING, <token> { <answer> &root->state)) 
ret <token> -ENOENT; <answer> = 
goto <token> <answer> out; 
<token> (btrfs_is_testing(ctx->fs_info)) { <answer> if 
ret = <token> <answer> -ENOENT; 
<token> out; <answer> goto 
<token> (path->search_commit_root) <answer> if 
root_level <token> btrfs_header_level(root->commit_root); <answer> = 
else <token> (ctx->time_seq == BTRFS_SEQ_LAST) <answer> if 
root_level <token> btrfs_header_level(root->node); <answer> = 
root_level <token> btrfs_old_root_level(root, ctx->time_seq); <answer> = 
if (root_level <token> 1 == level) <answer> + 
<token> out; <answer> goto 
if (search_key.type <token> BTRFS_EXTENT_DATA_KEY && <answer> == 
search_key.offset <token> LLONG_MAX) <answer> >= 
search_key.offset <token> 0; <answer> = 
path->lowest_level = <token> <answer> level; 
if (ctx->time_seq <token> BTRFS_SEQ_LAST) <answer> == 
ret <token> btrfs_search_slot(NULL, root, &search_key, path, 0, 0); <answer> = 
<token> = btrfs_search_old_slot(root, &search_key, path, ctx->time_seq); <answer> ret 
<token> slot in root %llu (level %d, ref count %d) returned %d for key (%llu %u %llu)", <answer> "search 
ref->root_id, <token> ref->count, ret, <answer> level, 
ref->key_for_search.objectid, <token> <answer> ref->key_for_search.type, 
if <token> < 0) <answer> (ret 
<token> out; <answer> goto 
eb = <token> <answer> path->nodes[level]; 
<token> (!eb) { <answer> while 
<token> (WARN_ON(!level)) { <answer> if 
ret = <token> <answer> 1; 
<token> out; <answer> goto 
<token> = path->nodes[level]; <answer> eb 
ret = add_all_parents(ctx, root, path, parents, preftrees, <token> level); <answer> ref, 
path->lowest_level = <token> <answer> 0; 
<token> ret; <answer> return 
<token> struct extent_inode_elem * <answer> static 
unode_aux_to_inode_list(struct ulist_node <token> <answer> *node) 
<token> (!node) <answer> if 
<token> NULL; <answer> return 
<token> (struct extent_inode_elem *)(uintptr_t)node->aux; <answer> return 
static <token> free_leaf_list(struct ulist *ulist) <answer> void 
struct <token> *node; <answer> ulist_node 
struct <token> uiter; <answer> ulist_iterator 
<token> ((node = ulist_next(ulist, &uiter))) <answer> while 
<token> int resolve_indirect_refs(struct btrfs_backref_walk_ctx *ctx, <answer> static 
<token> btrfs_path *path, <answer> struct 
<token> preftrees *preftrees, <answer> struct 
<token> share_check *sc) <answer> struct 
<token> err; <answer> int 
int ret <token> 0; <answer> = 
struct <token> *parents; <answer> ulist 
struct ulist_node <token> <answer> *node; 
struct ulist_iterator <token> <answer> uiter; 
struct rb_node <token> <answer> *rnode; 
parents = <token> <answer> ulist_alloc(GFP_NOFS); 
if <token> <answer> (!parents) 
return <token> <answer> -ENOMEM; 
<token> ((rnode = rb_first_cached(&preftrees->indirect.root))) { <answer> while 
<token> prelim_ref *ref; <answer> struct 
ref = rb_entry(rnode, struct <token> rbnode); <answer> prelim_ref, 
if <token> <answer> (WARN(ref->parent, 
"BUG: <token> ref found in indirect tree")) { <answer> direct 
ret = <token> <answer> -EINVAL; 
<token> out; <answer> goto 
<token> &preftrees->indirect.root); <answer> rb_erase_cached(&ref->rbnode, 
<token> (ref->count == 0) { <answer> if 
<token> (sc && ref->root_id != sc->root->root_key.objectid) { <answer> if 
ret = <token> <answer> BACKREF_FOUND_SHARED; 
goto <token> <answer> out; 
err <token> resolve_indirect_ref(ctx, path, preftrees, ref, parents); <answer> = 
if (err == <token> { <answer> -ENOENT) 
prelim_ref_insert(ctx->fs_info, <token> ref, <answer> &preftrees->direct, 
} else <token> (err) { <answer> if 
ret <token> err; <answer> = 
<token> out; <answer> goto 
<token> &preftrees->direct, ref, NULL); <answer> prelim_ref_insert(ctx->fs_info, 
<token> ret; <answer> return 
static <token> add_missing_keys(struct btrfs_fs_info *fs_info, <answer> int 
struct preftrees <token> bool lock) <answer> *preftrees, 
struct prelim_ref <token> <answer> *ref; 
<token> extent_buffer *eb; <answer> struct 
struct <token> *tree = &preftrees->indirect_missing_keys; <answer> preftree 
<token> rb_node *node; <answer> struct 
while ((node = <token> { <answer> rb_first_cached(&tree->root))) 
<token> btrfs_tree_parent_check check = { 0 }; <answer> struct 
ref = rb_entry(node, struct <token> rbnode); <answer> prelim_ref, 
rb_erase_cached(node, <token> <answer> &tree->root); 
static int add_delayed_refs(const struct <token> *fs_info, <answer> btrfs_fs_info 
<token> btrfs_delayed_ref_head *head, u64 seq, <answer> struct 
struct preftrees *preftrees, <token> share_check *sc) <answer> struct 
struct btrfs_delayed_ref_node <token> <answer> *node; 
struct <token> key; <answer> btrfs_key 
struct <token> *n; <answer> rb_node 
<token> count; <answer> int 
int ret = <token> <answer> 0; 
for (n = <token> n; n = rb_next(n)) { <answer> rb_first_cached(&head->ref_tree); 
node = rb_entry(n, struct <token> <answer> btrfs_delayed_ref_node, 
if (node->seq > <token> <answer> seq) 
switch <token> { <answer> (node->action) 
<token> BTRFS_ADD_DELAYED_EXTENT: <answer> case 
case <token> <answer> BTRFS_UPDATE_DELAYED_HEAD: 
case <token> <answer> BTRFS_ADD_DELAYED_REF: 
<token> = node->ref_mod; <answer> count 
<token> BTRFS_DROP_DELAYED_REF: <answer> case 
count <token> node->ref_mod * -1; <answer> = 
switch <token> { <answer> (node->type) 
case BTRFS_TREE_BLOCK_REF_KEY: <token> <answer> { 
if <token> && count < 0) <answer> (sc 
sc->have_delayed_delete_refs <token> true; <answer> = 
<token> = add_indirect_ref(fs_info, preftrees, ref->root, <answer> ret 
&key, 0, node->bytenr, <token> sc, <answer> count, 
case <token> { <answer> BTRFS_SHARED_DATA_REF_KEY: 
if (ret && (ret <token> BACKREF_FOUND_SHARED)) <answer> != 
<token> (!ret) <answer> if 
ret <token> extent_is_shared(sc); <answer> = 
return <token> <answer> ret; 
static int <token> btrfs_backref_walk_ctx *ctx, <answer> add_inline_refs(struct 
struct <token> *path, <answer> btrfs_path 
int *info_level, struct <token> *preftrees, <answer> preftrees 
<token> share_check *sc) <answer> struct 
int ret <token> 0; <answer> = 
<token> slot; <answer> int 
<token> extent_buffer *leaf; <answer> struct 
struct btrfs_key <token> <answer> key; 
<token> btrfs_key found_key; <answer> struct 
unsigned <token> ptr; <answer> long 
<token> long end; <answer> unsigned 
<token> btrfs_extent_item *ei; <answer> struct 
<token> flags; <answer> u64 
u64 <token> <answer> item_size; 
leaf <token> path->nodes[0]; <answer> = 
slot = <token> <answer> path->slots[0]; 
item_size = btrfs_item_size(leaf, <token> <answer> slot); 
ei = <token> slot, struct btrfs_extent_item); <answer> btrfs_item_ptr(leaf, 
<token> (ctx->check_extent_item) { <answer> if 
ret = ctx->check_extent_item(ctx->bytenr, <token> leaf, ctx->user_ctx); <answer> ei, 
if <token> <answer> (ret) 
return <token> <answer> ret; 
flags <token> btrfs_extent_flags(leaf, ei); <answer> = 
<token> &found_key, slot); <answer> btrfs_item_key_to_cpu(leaf, 
ptr = <token> long)(ei + 1); <answer> (unsigned 
end = (unsigned long)ei + <token> <answer> item_size; 
if (found_key.type == <token> && <answer> BTRFS_EXTENT_ITEM_KEY 
<token> & BTRFS_EXTENT_FLAG_TREE_BLOCK) { <answer> flags 
struct btrfs_tree_block_info <token> <answer> *info; 
info = <token> btrfs_tree_block_info *)ptr; <answer> (struct 
*info_level <token> btrfs_tree_block_level(leaf, info); <answer> = 
ptr += <token> btrfs_tree_block_info); <answer> sizeof(struct 
BUG_ON(ptr <token> end); <answer> > 
} else if (found_key.type <token> BTRFS_METADATA_ITEM_KEY) { <answer> == 
<token> = found_key.offset; <answer> *info_level 
} <token> { <answer> else 
<token> & BTRFS_EXTENT_FLAG_DATA)); <answer> BUG_ON(!(flags 
while <token> < end) { <answer> (ptr 
<token> btrfs_extent_inline_ref *iref; <answer> struct 
<token> offset; <answer> u64 
int <token> <answer> type; 
iref = (struct <token> *)ptr; <answer> btrfs_extent_inline_ref 
<token> = btrfs_get_extent_inline_ref_type(leaf, iref, <answer> type 
if <token> == BTRFS_REF_TYPE_INVALID) <answer> (type 
<token> -EUCLEAN; <answer> return 
offset = btrfs_extent_inline_ref_offset(leaf, <token> <answer> iref); 
<token> (type) { <answer> switch 
case <token> <answer> BTRFS_SHARED_BLOCK_REF_KEY: 
ret = <token> preftrees, <answer> add_direct_ref(ctx->fs_info, 
*info_level + <token> offset, <answer> 1, 
ctx->bytenr, 1, <token> GFP_NOFS); <answer> NULL, 
case <token> { <answer> BTRFS_SHARED_DATA_REF_KEY: 
<token> btrfs_shared_data_ref *sdref; <answer> struct 
int <token> <answer> count; 
sdref = (struct btrfs_shared_data_ref *)(iref <token> 1); <answer> + 
count = <token> sdref); <answer> btrfs_shared_data_ref_count(leaf, 
ret <token> add_direct_ref(ctx->fs_info, preftrees, 0, offset, <answer> = 
ctx->bytenr, count, <token> GFP_NOFS); <answer> sc, 
case <token> <answer> BTRFS_TREE_BLOCK_REF_KEY: 
<token> = add_indirect_ref(ctx->fs_info, preftrees, offset, <answer> ret 
<token> *info_level + 1, <answer> NULL, 
ctx->bytenr, <token> NULL, GFP_NOFS); <answer> 1, 
case <token> { <answer> BTRFS_EXTENT_DATA_REF_KEY: 
struct btrfs_extent_data_ref <token> <answer> *dref; 
int <token> <answer> count; 
<token> root; <answer> u64 
dref <token> (struct btrfs_extent_data_ref *)(&iref->offset); <answer> = 
<token> = btrfs_extent_data_ref_count(leaf, dref); <answer> count 
key.objectid = <token> <answer> btrfs_extent_data_ref_objectid(leaf, 
key.type <token> BTRFS_EXTENT_DATA_KEY; <answer> = 
key.offset = btrfs_extent_data_ref_offset(leaf, <token> <answer> dref); 
<token> (sc && key.objectid != sc->inum && <answer> if 
!sc->have_delayed_delete_refs) <token> <answer> { 
ret = <token> <answer> BACKREF_FOUND_SHARED; 
root = <token> dref); <answer> btrfs_extent_data_ref_root(leaf, 
<token> (!ctx->skip_data_ref || <answer> if 
!ctx->skip_data_ref(root, key.objectid, <token> <answer> key.offset, 
ret <token> add_indirect_ref(ctx->fs_info, preftrees, <answer> = 
root, &key, <token> ctx->bytenr, <answer> 0, 
count, sc, <token> <answer> GFP_NOFS); 
case <token> <answer> BTRFS_EXTENT_OWNER_REF_KEY: 
<token> SIMPLE_QUOTA)); <answer> ASSERT(btrfs_fs_incompat(ctx->fs_info, 
if <token> <answer> (ret) 
return <token> <answer> ret; 
ptr += <token> <answer> btrfs_extent_inline_ref_size(type); 
<token> 0; <answer> return 
static int add_keyed_refs(struct btrfs_backref_walk_ctx <token> <answer> *ctx, 
<token> btrfs_root *extent_root, <answer> struct 
struct btrfs_path <token> <answer> *path, 
int info_level, <token> preftrees *preftrees, <answer> struct 
struct <token> *sc) <answer> share_check 
struct btrfs_fs_info *fs_info <token> extent_root->fs_info; <answer> = 
int <token> <answer> ret; 
int <token> <answer> slot; 
<token> extent_buffer *leaf; <answer> struct 
struct <token> key; <answer> btrfs_key 
<token> (1) { <answer> while 
ret = btrfs_next_item(extent_root, <token> <answer> path); 
if (ret < <token> <answer> 0) 
<token> (ret) { <answer> if 
<token> = 0; <answer> ret 
slot = <token> <answer> path->slots[0]; 
<token> = path->nodes[0]; <answer> leaf 
<token> &key, slot); <answer> btrfs_item_key_to_cpu(leaf, 
if (key.objectid <token> ctx->bytenr) <answer> != 
<token> (key.type < BTRFS_TREE_BLOCK_REF_KEY) <answer> if 
if <token> > BTRFS_SHARED_DATA_REF_KEY) <answer> (key.type 
<token> (key.type) { <answer> switch 
case <token> <answer> BTRFS_SHARED_BLOCK_REF_KEY: 
static bool lookup_backref_shared_cache(struct <token> *ctx, <answer> btrfs_backref_share_check_ctx 
<token> btrfs_root *root, <answer> struct 
u64 bytenr, <token> level, bool *is_shared) <answer> int 
const struct btrfs_fs_info <token> = root->fs_info; <answer> *fs_info 
struct btrfs_backref_shared_cache_entry <token> <answer> *entry; 
<token> (!current->journal_info) <answer> if 
if <token> <answer> (!ctx->use_path_cache) 
return <token> <answer> false; 
<token> (WARN_ON_ONCE(level >= BTRFS_MAX_LEVEL)) <answer> if 
return <token> <answer> false; 
<token> >= 0); <answer> ASSERT(level 
entry <token> &ctx->path_cache_entries[level]; <answer> = 
if <token> && <answer> (!entry->is_shared 
entry->gen <token> btrfs_root_last_snapshot(&root->root_item)) <answer> != 
<token> false; <answer> return 
if <token> && <answer> (entry->is_shared 
entry->gen <token> btrfs_get_last_root_drop_gen(fs_info)) <answer> != 
<token> false; <answer> return 
*is_shared <token> entry->is_shared; <answer> = 
if <token> { <answer> (*is_shared) 
for (int i = 0; i <token> level; i++) { <answer> < 
<token> = true; <answer> ctx->path_cache_entries[i].is_shared 
ctx->path_cache_entries[i].gen <token> entry->gen; <answer> = 
return <token> <answer> true; 
static void store_backref_shared_cache(struct btrfs_backref_share_check_ctx <token> <answer> *ctx, 
struct btrfs_root <token> <answer> *root, 
u64 bytenr, int level, <token> is_shared) <answer> bool 
const <token> btrfs_fs_info *fs_info = root->fs_info; <answer> struct 
<token> btrfs_backref_shared_cache_entry *entry; <answer> struct 
<token> gen; <answer> u64 
if <token> <answer> (!current->journal_info) 
if <token> <answer> (!ctx->use_path_cache) 
if (WARN_ON_ONCE(level <token> BTRFS_MAX_LEVEL)) <answer> >= 
ASSERT(level >= <token> <answer> 0); 
<token> (is_shared) <answer> if 
gen <token> btrfs_get_last_root_drop_gen(fs_info); <answer> = 
gen <token> btrfs_root_last_snapshot(&root->root_item); <answer> = 
entry = <token> <answer> &ctx->path_cache_entries[level]; 
entry->bytenr <token> bytenr; <answer> = 
entry->is_shared = <token> <answer> is_shared; 
<token> = gen; <answer> entry->gen 
if <token> { <answer> (is_shared) 
for (int i = 0; i <token> level; i++) { <answer> < 
entry <token> &ctx->path_cache_entries[i]; <answer> = 
entry->is_shared = <token> <answer> is_shared; 
entry->gen = <token> <answer> gen; 
static <token> find_parent_nodes(struct btrfs_backref_walk_ctx *ctx, <answer> int 
struct share_check <token> <answer> *sc) 
struct <token> *root = btrfs_extent_root(ctx->fs_info, ctx->bytenr); <answer> btrfs_root 
struct <token> key; <answer> btrfs_key 
<token> btrfs_path *path; <answer> struct 
struct btrfs_delayed_ref_root *delayed_refs = <token> <answer> NULL; 
struct btrfs_delayed_ref_head <token> <answer> *head; 
int info_level <token> 0; <answer> = 
int <token> <answer> ret; 
struct <token> *ref; <answer> prelim_ref 
struct rb_node <token> <answer> *node; 
struct extent_inode_elem *eie <token> NULL; <answer> = 
<token> preftrees preftrees = { <answer> struct 
<token> = PREFTREE_INIT, <answer> .direct 
<token> = PREFTREE_INIT, <answer> .indirect 
.indirect_missing_keys <token> PREFTREE_INIT <answer> = 
ret <token> -EUCLEAN; <answer> = 
goto <token> <answer> out; 
if <token> && likely(ctx->trans->type != __TRANS_DUMMY) && <answer> (ctx->trans 
<token> != BTRFS_SEQ_LAST) { <answer> ctx->time_seq 
delayed_refs <token> &ctx->trans->transaction->delayed_refs; <answer> = 
<token> = btrfs_find_delayed_ref_head(delayed_refs, ctx->bytenr); <answer> head 
if (head) <token> <answer> { 
<token> (!mutex_trylock(&head->mutex)) { <answer> if 
<token> again; <answer> goto 
ret = <token> head, ctx->time_seq, <answer> add_delayed_refs(ctx->fs_info, 
<token> sc); <answer> &preftrees, 
if <token> <answer> (ret) 
goto <token> <answer> out; 
<token> else { <answer> } 
if (path->slots[0]) <token> <answer> { 
struct extent_buffer <token> <answer> *leaf; 
int <token> <answer> slot; 
leaf <token> path->nodes[0]; <answer> = 
<token> = path->slots[0]; <answer> slot 
<token> &key, slot); <answer> btrfs_item_key_to_cpu(leaf, 
if <token> == ctx->bytenr && <answer> (key.objectid 
(key.type <token> BTRFS_EXTENT_ITEM_KEY || <answer> == 
key.type == BTRFS_METADATA_ITEM_KEY)) <token> <answer> { 
ret = add_inline_refs(ctx, <token> &info_level, <answer> path, 
<token> sc); <answer> &preftrees, 
if <token> <answer> (ret) 
goto <token> <answer> out; 
ret = <token> root, path, info_level, <answer> add_keyed_refs(ctx, 
&preftrees, <token> <answer> sc); 
if <token> <answer> (ret) 
goto <token> <answer> out; 
ASSERT(extent_is_shared(sc) == <token> <answer> 0); 
<token> (sc && ctx->bytenr == sc->data_bytenr) { <answer> if 
if <token> > <answer> (sc->data_extent_gen 
btrfs_root_last_snapshot(&sc->root->root_item)) <token> <answer> { 
ret <token> BACKREF_FOUND_NOT_SHARED; <answer> = 
<token> out; <answer> goto 
if (sc->ctx->curr_leaf_bytenr <token> sc->ctx->prev_leaf_bytenr && <answer> == 
sc->self_ref_count == 1) <token> <answer> { 
bool <token> <answer> cached; 
bool <token> <answer> is_shared; 
cached = <token> sc->root, <answer> lookup_backref_shared_cache(sc->ctx, 
0, <token> <answer> &is_shared); 
<token> (cached) { <answer> if 
if <token> <answer> (is_shared) 
ret <token> BACKREF_FOUND_SHARED; <answer> = 
ret = <token> <answer> BACKREF_FOUND_NOT_SHARED; 
<token> out; <answer> goto 
ret = add_missing_keys(ctx->fs_info, &preftrees, <token> == 0); <answer> path->skip_locking 
<token> (ret) <answer> if 
<token> out; <answer> goto 
<token> = resolve_indirect_refs(ctx, path, &preftrees, sc); <answer> ret 
if <token> <answer> (ret) 
goto <token> <answer> out; 
node <token> rb_first_cached(&preftrees.direct.root); <answer> = 
while (node) <token> <answer> { 
ref = rb_entry(node, <token> prelim_ref, rbnode); <answer> struct 
node <token> rb_next(&ref->rbnode); <answer> = 
if (ctx->roots && ref->count <token> ref->root_id && ref->parent == 0) { <answer> && 
eie <token> NULL; <answer> = 
ret <token> ulist_add_merge_ptr(ctx->refs, ref->parent, <answer> = 
(void **)&eie, <token> <answer> GFP_NOFS); 
if (ret < <token> <answer> 0) 
goto <token> <answer> out; 
if <token> && !ctx->skip_inode_ref_list) { <answer> (!ret 
if (!eie) <token> <answer> { 
<token> = -EUCLEAN; <answer> ret 
goto <token> <answer> out; 
while <token> <answer> (eie->next) 
<token> = eie->next; <answer> eie 
eie->next = <token> <answer> ref->inode_list; 
<token> = NULL; <answer> eie 
<token> = NULL; <answer> ref->inode_list 
<token> (ret == BTRFS_ITERATE_EXTENT_INODES_STOP || ret < 0) <answer> if 
<token> ret; <answer> return 
int btrfs_find_all_leafs(struct btrfs_backref_walk_ctx <token> <answer> *ctx) 
int <token> <answer> ret; 
<token> == NULL); <answer> ASSERT(ctx->refs 
<token> = ulist_alloc(GFP_NOFS); <answer> ctx->refs 
<token> (!ctx->refs) <answer> if 
<token> -ENOMEM; <answer> return 
ret <token> find_parent_nodes(ctx, NULL); <answer> = 
if (ret <token> BTRFS_ITERATE_EXTENT_INODES_STOP || <answer> == 
(ret < 0 && ret != <token> { <answer> -ENOENT)) 
ctx->refs <token> NULL; <answer> = 
return <token> <answer> ret; 
<token> 0; <answer> return 
static <token> btrfs_find_all_roots_safe(struct btrfs_backref_walk_ctx *ctx) <answer> int 
const u64 orig_bytenr = <token> <answer> ctx->bytenr; 
const bool orig_skip_inode_ref_list <token> ctx->skip_inode_ref_list; <answer> = 
<token> roots_ulist_allocated = false; <answer> bool 
struct <token> uiter; <answer> ulist_iterator 
<token> ret = 0; <answer> int 
<token> == NULL); <answer> ASSERT(ctx->refs 
ctx->refs <token> ulist_alloc(GFP_NOFS); <answer> = 
if <token> <answer> (!ctx->refs) 
<token> -ENOMEM; <answer> return 
if (!ctx->roots) <token> <answer> { 
ctx->roots <token> ulist_alloc(GFP_NOFS); <answer> = 
if (!ctx->roots) <token> <answer> { 
ctx->refs = <token> <answer> NULL; 
return <token> <answer> -ENOMEM; 
<token> = true; <answer> roots_ulist_allocated 
ctx->skip_inode_ref_list = <token> <answer> true; 
while <token> { <answer> (1) 
struct <token> *node; <answer> ulist_node 
<token> = find_parent_nodes(ctx, NULL); <answer> ret 
<token> (ret < 0 && ret != -ENOENT) { <answer> if 
if <token> { <answer> (roots_ulist_allocated) 
ctx->roots = <token> <answer> NULL; 
ret <token> 0; <answer> = 
node = ulist_next(ctx->refs, <token> <answer> &uiter); 
if <token> <answer> (!node) 
ctx->bytenr <token> node->val; <answer> = 
ctx->refs = <token> <answer> NULL; 
<token> = orig_bytenr; <answer> ctx->bytenr 
<token> = orig_skip_inode_ref_list; <answer> ctx->skip_inode_ref_list 
<token> ret; <answer> return 
<token> btrfs_find_all_roots(struct btrfs_backref_walk_ctx *ctx, <answer> int 
<token> skip_commit_root_sem) <answer> bool 
int <token> <answer> ret; 
if (!ctx->trans <token> !skip_commit_root_sem) <answer> && 
<token> = btrfs_find_all_roots_safe(ctx); <answer> ret 
<token> (!ctx->trans && !skip_commit_root_sem) <answer> if 
<token> ret; <answer> return 
struct btrfs_backref_share_check_ctx <token> <answer> *btrfs_alloc_backref_share_check_ctx(void) 
<token> btrfs_backref_share_check_ctx *ctx; <answer> struct 
<token> = kzalloc(sizeof(*ctx), GFP_KERNEL); <answer> ctx 
if <token> <answer> (!ctx) 
return <token> <answer> NULL; 
return <token> <answer> ctx; 
void <token> btrfs_backref_share_check_ctx *ctx) <answer> btrfs_free_backref_share_ctx(struct 
<token> (!ctx) <answer> if 
int <token> btrfs_inode *inode, u64 bytenr, <answer> btrfs_is_data_extent_shared(struct 
u64 <token> <answer> extent_gen, 
<token> btrfs_backref_share_check_ctx *ctx) <answer> struct 
struct btrfs_backref_walk_ctx walk_ctx = { 0 <token> <answer> }; 
struct btrfs_root *root <token> inode->root; <answer> = 
struct btrfs_fs_info *fs_info <token> root->fs_info; <answer> = 
struct <token> *trans; <answer> btrfs_trans_handle 
<token> ulist_iterator uiter; <answer> struct 
struct <token> *node; <answer> ulist_node 
struct btrfs_seq_list elem <token> BTRFS_SEQ_LIST_INIT(elem); <answer> = 
<token> ret = 0; <answer> int 
struct <token> shared = { <answer> share_check 
<token> = ctx, <answer> .ctx 
<token> = root, <answer> .root 
.inum = <token> <answer> btrfs_ino(inode), 
<token> = bytenr, <answer> .data_bytenr 
.data_extent_gen <token> extent_gen, <answer> = 
.share_count = <token> <answer> 0, 
<token> = 0, <answer> .self_ref_count 
.have_delayed_delete_refs <token> false, <answer> = 
<token> level; <answer> int 
<token> leaf_cached; <answer> bool 
<token> leaf_is_shared; <answer> bool 
for (int i = 0; <token> < BTRFS_BACKREF_CTX_PREV_EXTENTS_SIZE; i++) { <answer> i 
if <token> == bytenr) <answer> (ctx->prev_extents_cache[i].bytenr 
return <token> <answer> ctx->prev_extents_cache[i].is_shared; 
trans = <token> <answer> btrfs_join_transaction_nostart(root); 
<token> (IS_ERR(trans)) { <answer> if 
if (PTR_ERR(trans) != -ENOENT && <token> != -EROFS) { <answer> PTR_ERR(trans) 
ret <token> PTR_ERR(trans); <answer> = 
goto <token> <answer> out; 
trans = <token> <answer> NULL; 
} else <token> <answer> { 
btrfs_get_tree_mod_seq(fs_info, <token> <answer> &elem); 
walk_ctx.time_seq = <token> <answer> elem.seq; 
ctx->use_path_cache <token> true; <answer> = 
leaf_cached = <token> root, <answer> lookup_backref_shared_cache(ctx, 
ctx->curr_leaf_bytenr, <token> <answer> 0, 
<token> (leaf_cached && leaf_is_shared) { <answer> if 
ret <token> 1; <answer> = 
goto <token> <answer> out_trans; 
walk_ctx.skip_inode_ref_list <token> true; <answer> = 
<token> = trans; <answer> walk_ctx.trans 
walk_ctx.fs_info <token> fs_info; <answer> = 
walk_ctx.refs <token> &ctx->refs; <answer> = 
if ((ctx->refs.nnodes - <token> > 1) <answer> prev_ref_count) 
ctx->use_path_cache <token> false; <answer> = 
if (level <token> 0) <answer> >= 
store_backref_shared_cache(ctx, <token> bytenr, <answer> root, 
level, <token> <answer> false); 
<token> = ulist_next(&ctx->refs, &uiter); <answer> node 
if <token> <answer> (!node) 
bytenr <token> node->val; <answer> = 
<token> (ctx->use_path_cache) { <answer> if 
bool <token> <answer> is_shared; 
<token> cached; <answer> bool 
cached = lookup_backref_shared_cache(ctx, <token> bytenr, <answer> root, 
<token> &is_shared); <answer> level, 
if <token> { <answer> (cached) 
ret = (is_shared ? 1 : <token> <answer> 0); 
shared.share_count = <token> <answer> 0; 
shared.have_delayed_delete_refs = <token> <answer> false; 
if <token> { <answer> (!ctx->use_path_cache) 
int <token> = 0; <answer> i 
if (ret <token> 0 && level >= 0) { <answer> >= 
bytenr <token> ctx->path_cache_entries[level].bytenr; <answer> = 
ctx->use_path_cache = <token> <answer> true; 
store_backref_shared_cache(ctx, root, bytenr, <token> ret); <answer> level, 
i = <token> + 1; <answer> level 
<token> ( ; i < BTRFS_MAX_LEVEL; i++) <answer> for 
ctx->path_cache_entries[i].bytenr = <token> <answer> 0; 
if (ret >= 0 <token> shared.self_ref_count > 1) { <answer> && 
int slot = <token> <answer> ctx->prev_extents_cache_slot; 
ctx->prev_extents_cache[slot].bytenr <token> shared.data_bytenr; <answer> = 
ctx->prev_extents_cache[slot].is_shared <token> (ret == 1); <answer> = 
slot = (slot + 1) % <token> <answer> BTRFS_BACKREF_CTX_PREV_EXTENTS_SIZE; 
ctx->prev_extents_cache_slot = <token> <answer> slot; 
<token> (trans) { <answer> if 
<token> &elem); <answer> btrfs_put_tree_mod_seq(fs_info, 
} else <token> <answer> { 
ctx->prev_leaf_bytenr <token> ctx->curr_leaf_bytenr; <answer> = 
<token> ret; <answer> return 
<token> btrfs_find_one_extref(struct btrfs_root *root, u64 inode_objectid, <answer> int 
<token> start_off, struct btrfs_path *path, <answer> u64 
struct <token> **ret_extref, <answer> btrfs_inode_extref 
u64 <token> <answer> *found_off) 
<token> ret, slot; <answer> int 
<token> btrfs_key key; <answer> struct 
struct <token> found_key; <answer> btrfs_key 
struct <token> *extref; <answer> btrfs_inode_extref 
const struct <token> *leaf; <answer> extent_buffer 
unsigned long <token> <answer> ptr; 
key.objectid <token> inode_objectid; <answer> = 
key.type <token> BTRFS_INODE_EXTREF_KEY; <answer> = 
<token> = start_off; <answer> key.offset 
ret = btrfs_search_slot(NULL, root, &key, path, <token> 0); <answer> 0, 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
while (1) <token> <answer> { 
leaf <token> path->nodes[0]; <answer> = 
slot <token> path->slots[0]; <answer> = 
if (slot >= btrfs_header_nritems(leaf)) <token> <answer> { 
ret = <token> path); <answer> btrfs_next_leaf(root, 
if (ret) <token> <answer> { 
if (ret >= <token> <answer> 1) 
ret = <token> <answer> -ENOENT; 
btrfs_item_key_to_cpu(leaf, <token> slot); <answer> &found_key, 
ret = <token> <answer> -ENOENT; 
if (found_key.objectid <token> inode_objectid) <answer> != 
<token> (found_key.type != BTRFS_INODE_EXTREF_KEY) <answer> if 
ret = <token> <answer> 0; 
ptr <token> btrfs_item_ptr_offset(leaf, path->slots[0]); <answer> = 
extref = <token> btrfs_inode_extref *)ptr; <answer> (struct 
*ret_extref = <token> <answer> extref; 
if <token> <answer> (found_off) 
<token> = found_key.offset; <answer> *found_off 
return <token> <answer> ret; 
char <token> btrfs_root *fs_root, struct btrfs_path *path, <answer> *btrfs_ref_to_path(struct 
u32 name_len, <token> long name_off, <answer> unsigned 
struct extent_buffer *eb_in, <token> parent, <answer> u64 
char *dest, u32 <token> <answer> size) 
int <token> <answer> slot; 
u64 <token> <answer> next_inum; 
<token> ret; <answer> int 
s64 bytes_left = ((s64)size) - <token> <answer> 1; 
<token> extent_buffer *eb = eb_in; <answer> struct 
struct <token> found_key; <answer> btrfs_key 
struct btrfs_inode_ref <token> <answer> *iref; 
if (bytes_left <token> 0) <answer> >= 
<token> = '\0'; <answer> dest[bytes_left] 
<token> (1) { <answer> while 
bytes_left -= <token> <answer> name_len; 
if (bytes_left <token> 0) <answer> >= 
read_extent_buffer(eb, dest + <token> <answer> bytes_left, 
name_off, <token> <answer> name_len); 
if (eb <token> eb_in) { <answer> != 
if <token> <answer> (!path->skip_locking) 
ret = btrfs_find_item(fs_root, <token> parent, 0, <answer> path, 
BTRFS_INODE_REF_KEY, <token> <answer> &found_key); 
if (ret <token> 0) <answer> > 
ret <token> -ENOENT; <answer> = 
if <token> <answer> (ret) 
next_inum <token> found_key.offset; <answer> = 
int extent_from_logical(struct btrfs_fs_info <token> u64 logical, <answer> *fs_info, 
struct <token> *path, struct btrfs_key *found_key, <answer> btrfs_path 
<token> *flags_ret) <answer> u64 
<token> btrfs_root *extent_root = btrfs_extent_root(fs_info, logical); <answer> struct 
<token> ret; <answer> int 
<token> flags; <answer> u64 
u64 <token> = 0; <answer> size 
u32 <token> <answer> item_size; 
const struct extent_buffer <token> <answer> *eb; 
struct <token> *ei; <answer> btrfs_extent_item 
struct btrfs_key <token> <answer> key; 
if (btrfs_fs_incompat(fs_info, <token> <answer> SKINNY_METADATA)) 
<token> = BTRFS_METADATA_ITEM_KEY; <answer> key.type 
<token> = BTRFS_EXTENT_ITEM_KEY; <answer> key.type 
key.objectid <token> logical; <answer> = 
key.offset = <token> <answer> (u64)-1; 
ret <token> btrfs_search_slot(NULL, extent_root, &key, path, 0, 0); <answer> = 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
<token> (ret == 0) { <answer> if 
return <token> <answer> -EUCLEAN; 
ret <token> btrfs_previous_extent_item(extent_root, path, 0); <answer> = 
<token> (ret) { <answer> if 
if (ret > <token> <answer> 0) 
ret <token> -ENOENT; <answer> = 
return <token> <answer> ret; 
btrfs_item_key_to_cpu(path->nodes[0], found_key, <token> <answer> path->slots[0]); 
<token> (found_key->type == BTRFS_METADATA_ITEM_KEY) <answer> if 
size <token> fs_info->nodesize; <answer> = 
else <token> (found_key->type == BTRFS_EXTENT_ITEM_KEY) <answer> if 
size <token> found_key->offset; <answer> = 
if <token> > logical || <answer> (found_key->objectid 
found_key->objectid + size <= <token> { <answer> logical) 
<token> %llu is not within any extent", logical); <answer> "logical 
return <token> <answer> -ENOENT; 
eb <token> path->nodes[0]; <answer> = 
<token> = btrfs_item_size(eb, path->slots[0]); <answer> item_size 
ei = btrfs_item_ptr(eb, path->slots[0], <token> btrfs_extent_item); <answer> struct 
flags <token> btrfs_extent_flags(eb, ei); <answer> = 
"logical %llu is at position %llu within the <token> (%llu EXTENT_ITEM %llu) flags %#llx size %u", <answer> extent 
logical, logical - <token> found_key->objectid, <answer> found_key->objectid, 
found_key->offset, <token> item_size); <answer> flags, 
if <token> { <answer> (flags_ret) 
if (flags & <token> <answer> BTRFS_EXTENT_FLAG_TREE_BLOCK) 
<token> = BTRFS_EXTENT_FLAG_TREE_BLOCK; <answer> *flags_ret 
else if <token> & BTRFS_EXTENT_FLAG_DATA) <answer> (flags 
*flags_ret <token> BTRFS_EXTENT_FLAG_DATA; <answer> = 
<token> 0; <answer> return 
<token> -EIO; <answer> return 
<token> int get_extent_inline_ref(unsigned long *ptr, <answer> static 
const struct <token> *eb, <answer> extent_buffer 
const struct btrfs_key <token> <answer> *key, 
const <token> btrfs_extent_item *ei, <answer> struct 
<token> item_size, <answer> u32 
struct btrfs_extent_inline_ref <token> <answer> **out_eiref, 
int <token> <answer> *out_type) 
<token> long end; <answer> unsigned 
u64 <token> <answer> flags; 
struct <token> *info; <answer> btrfs_tree_block_info 
if (!*ptr) <token> <answer> { 
int tree_backref_for_extent(unsigned <token> *ptr, struct extent_buffer *eb, <answer> long 
struct btrfs_key *key, struct btrfs_extent_item <token> <answer> *ei, 
u32 <token> u64 *out_root, u8 *out_level) <answer> item_size, 
<token> ret; <answer> int 
<token> type; <answer> int 
struct <token> *eiref; <answer> btrfs_extent_inline_ref 
if <token> == (unsigned long)-1) <answer> (*ptr 
return <token> <answer> 1; 
while (1) <token> <answer> { 
ret <token> get_extent_inline_ref(ptr, eb, key, ei, item_size, <answer> = 
<token> &type); <answer> &eiref, 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
if (type == BTRFS_TREE_BLOCK_REF_KEY <token> <answer> || 
type == <token> <answer> BTRFS_SHARED_BLOCK_REF_KEY) 
if (ret <token> 1) <answer> == 
return <token> <answer> 1; 
int iterate_extent_inodes(struct btrfs_backref_walk_ctx <token> <answer> *ctx, 
<token> search_commit_root, <answer> bool 
<token> *iterate, void *user_ctx) <answer> iterate_extent_inodes_t 
<token> ret; <answer> int 
struct <token> *refs; <answer> ulist 
struct <token> *ref_node; <answer> ulist_node 
struct btrfs_seq_list seq_elem <token> BTRFS_SEQ_LIST_INIT(seq_elem); <answer> = 
struct <token> ref_uiter; <answer> ulist_iterator 
btrfs_debug(ctx->fs_info, "resolving all inodes for extent <token> <answer> %llu", 
ASSERT(ctx->trans <token> NULL); <answer> == 
ASSERT(ctx->roots == <token> <answer> NULL); 
<token> (!search_commit_root) { <answer> if 
struct btrfs_trans_handle <token> <answer> *trans; 
trans = <token> <answer> btrfs_attach_transaction(ctx->fs_info->tree_root); 
if <token> { <answer> (IS_ERR(trans)) 
if (PTR_ERR(trans) <token> -ENOENT && <answer> != 
PTR_ERR(trans) <token> -EROFS) <answer> != 
return <token> <answer> PTR_ERR(trans); 
<token> = NULL; <answer> trans 
<token> = trans; <answer> ctx->trans 
if (ctx->trans) <token> <answer> { 
<token> &seq_elem); <answer> btrfs_get_tree_mod_seq(ctx->fs_info, 
ctx->time_seq = <token> <answer> seq_elem.seq; 
<token> else { <answer> } 
ret = <token> <answer> btrfs_find_all_leafs(ctx); 
if <token> <answer> (ret) 
goto <token> <answer> out; 
refs = <token> <answer> ctx->refs; 
<token> = NULL; <answer> ctx->refs 
<token> (!ret && (ref_node = ulist_next(refs, &ref_uiter))) { <answer> while 
const u64 <token> = ref_node->val; <answer> leaf_bytenr 
struct <token> *root_node; <answer> ulist_node 
struct ulist_iterator <token> <answer> root_uiter; 
struct <token> *inode_list; <answer> extent_inode_elem 
inode_list = <token> extent_inode_elem *)(uintptr_t)ref_node->aux; <answer> (struct 
<token> (ctx->cache_lookup) { <answer> if 
<token> u64 *root_ids; <answer> const 
<token> root_count; <answer> int 
<token> cached; <answer> bool 
cached = ctx->cache_lookup(leaf_bytenr, <token> <answer> ctx->user_ctx, 
&root_ids, <token> <answer> &root_count); 
if (cached) <token> <answer> { 
for <token> i = 0; i < root_count; i++) { <answer> (int 
<token> = iterate_leaf_refs(ctx->fs_info, <answer> ret 
if <token> <answer> (ret) 
<token> (!ctx->roots) { <answer> if 
ctx->roots <token> ulist_alloc(GFP_NOFS); <answer> = 
if <token> { <answer> (!ctx->roots) 
ret <token> -ENOMEM; <answer> = 
ctx->bytenr <token> leaf_bytenr; <answer> = 
ret = <token> <answer> btrfs_find_all_roots_safe(ctx); 
<token> (ret) <answer> if 
<token> (ctx->cache_store) <answer> if 
ctx->cache_store(leaf_bytenr, ctx->roots, <token> <answer> ctx->user_ctx); 
while (!ret && (root_node <token> ulist_next(ctx->roots, &root_uiter))) { <answer> = 
"root %llu <token> leaf %llu, data list %#llx", <answer> references 
root_node->val, <token> <answer> ref_node->val, 
ret = iterate_leaf_refs(ctx->fs_info, <token> <answer> inode_list, 
root_node->val, <token> <answer> ctx->bytenr, 
iterate, <token> <answer> user_ctx); 
<token> (ctx->trans) { <answer> if 
<token> &seq_elem); <answer> btrfs_put_tree_mod_seq(ctx->fs_info, 
ctx->trans = <token> <answer> NULL; 
} else <token> <answer> { 
ctx->roots = <token> <answer> NULL; 
if (ret == <token> <answer> BTRFS_ITERATE_EXTENT_INODES_STOP) 
ret <token> 0; <answer> = 
return <token> <answer> ret; 
static int <token> inum, u64 offset, u64 num_bytes, u64 root, void *ctx) <answer> build_ino_list(u64 
<token> btrfs_data_container *inodes = ctx; <answer> struct 
const <token> c = 3 * sizeof(u64); <answer> size_t 
if (inodes->bytes_left >= <token> { <answer> c) 
<token> -= c; <answer> inodes->bytes_left 
inodes->val[inodes->elem_cnt] = <token> <answer> inum; 
inodes->val[inodes->elem_cnt + <token> = offset; <answer> 1] 
inodes->val[inodes->elem_cnt + <token> = root; <answer> 2] 
inodes->elem_cnt <token> 3; <answer> += 
} <token> { <answer> else 
<token> += c - inodes->bytes_left; <answer> inodes->bytes_missing 
inodes->bytes_left <token> 0; <answer> = 
inodes->elem_missed += <token> <answer> 3; 
<token> 0; <answer> return 
int iterate_inodes_from_logical(u64 logical, struct <token> *fs_info, <answer> btrfs_fs_info 
struct btrfs_path <token> <answer> *path, 
void *ctx, <token> ignore_offset) <answer> bool 
struct <token> walk_ctx = { 0 }; <answer> btrfs_backref_walk_ctx 
int <token> <answer> ret; 
u64 <token> = 0; <answer> flags 
<token> btrfs_key found_key; <answer> struct 
<token> search_commit_root = path->search_commit_root; <answer> int 
ret = extent_from_logical(fs_info, logical, <token> &found_key, &flags); <answer> path, 
if <token> < 0) <answer> (ret 
<token> ret; <answer> return 
if (flags <token> BTRFS_EXTENT_FLAG_TREE_BLOCK) <answer> & 
return <token> <answer> -EINVAL; 
walk_ctx.bytenr <token> found_key.objectid; <answer> = 
if <token> <answer> (ignore_offset) 
walk_ctx.ignore_extent_item_pos = <token> <answer> true; 
walk_ctx.extent_item_pos = logical - <token> <answer> found_key.objectid; 
<token> = fs_info; <answer> walk_ctx.fs_info 
return iterate_extent_inodes(&walk_ctx, <token> <answer> search_commit_root, 
<token> ctx); <answer> build_ino_list, 
static int inode_to_path(u64 inum, u32 <token> unsigned long name_off, <answer> name_len, 
struct extent_buffer *eb, struct inode_fs_paths <token> <answer> *ipath); 
static <token> iterate_inode_refs(u64 inum, struct inode_fs_paths *ipath) <answer> int 
<token> ret = 0; <answer> int 
int <token> <answer> slot; 
u32 <token> <answer> cur; 
u32 <token> <answer> len; 
<token> name_len; <answer> u32 
u64 parent = <token> <answer> 0; 
int found = <token> <answer> 0; 
struct <token> *fs_root = ipath->fs_root; <answer> btrfs_root 
<token> btrfs_path *path = ipath->btrfs_path; <answer> struct 
struct <token> *eb; <answer> extent_buffer 
struct btrfs_inode_ref <token> <answer> *iref; 
<token> btrfs_key found_key; <answer> struct 
<token> (!ret) { <answer> while 
ret = btrfs_find_item(fs_root, <token> inum, <answer> path, 
parent ? parent <token> 1 : 0, BTRFS_INODE_REF_KEY, <answer> + 
if (ret <token> 0) <answer> < 
<token> (ret) { <answer> if 
ret = found ? <token> : -ENOENT; <answer> 0 
parent <token> found_key.offset; <answer> = 
slot <token> path->slots[0]; <answer> = 
eb <token> btrfs_clone_extent_buffer(path->nodes[0]); <answer> = 
<token> (!eb) { <answer> if 
ret = <token> <answer> -ENOMEM; 
iref = btrfs_item_ptr(eb, slot, <token> btrfs_inode_ref); <answer> struct 
for (cur = <token> cur < btrfs_item_size(eb, slot); cur += len) { <answer> 0; 
name_len = btrfs_inode_ref_name_len(eb, <token> <answer> iref); 
static int inode_to_path(u64 inum, u32 name_len, <token> long name_off, <answer> unsigned 
struct extent_buffer <token> struct inode_fs_paths *ipath) <answer> *eb, 
char <token> <answer> *fspath; 
<token> *fspath_min; <answer> char 
<token> i = ipath->fspath->elem_cnt; <answer> int 
const int s_ptr <token> sizeof(char *); <answer> = 
<token> bytes_left; <answer> u32 
bytes_left = <token> > s_ptr ? <answer> ipath->fspath->bytes_left 
ipath->fspath->bytes_left - s_ptr : <token> <answer> 0; 
fspath_min = (char *)ipath->fspath->val + (i <token> 1) * s_ptr; <answer> + 
<token> = btrfs_ref_to_path(ipath->fs_root, ipath->btrfs_path, name_len, <answer> fspath 
name_off, eb, inum, <token> bytes_left); <answer> fspath_min, 
<token> (IS_ERR(fspath)) <answer> if 
return <token> <answer> PTR_ERR(fspath); 
<token> (fspath > fspath_min) { <answer> if 
<token> = (u64)(unsigned long)fspath; <answer> ipath->fspath->val[i] 
ipath->fspath->bytes_left = fspath - <token> <answer> fspath_min; 
} else <token> <answer> { 
<token> += fspath_min - fspath; <answer> ipath->fspath->bytes_missing 
ipath->fspath->bytes_left <token> 0; <answer> = 
<token> 0; <answer> return 
int paths_from_inode(u64 inum, <token> inode_fs_paths *ipath) <answer> struct 
int <token> <answer> ret; 
int found_refs = <token> <answer> 0; 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/dmi.h> <answer> #include 
<token> <linux/firmware.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/delay.h> <answer> #include 
<token> <linux/irq.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/platform_data/x86/soc.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/acpi.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <asm/unaligned.h> 
<token> "goodix.h" <answer> #include 
<token> GOODIX_GPIO_INT_NAME "irq" <answer> #define 
<token> GOODIX_GPIO_RST_NAME "reset" <answer> #define 
#define <token> 4096 <answer> GOODIX_MAX_HEIGHT 
<token> GOODIX_MAX_WIDTH 4096 <answer> #define 
#define <token> 1 <answer> GOODIX_INT_TRIGGER 
#define <token> 8 <answer> GOODIX_CONTACT_SIZE 
<token> GOODIX_MAX_CONTACT_SIZE 9 <answer> #define 
<token> GOODIX_MAX_CONTACTS 10 <answer> #define 
#define GOODIX_CONFIG_MIN_LENGTH <token> <answer> 186 
#define <token> 186 <answer> GOODIX_CONFIG_911_LENGTH 
<token> GOODIX_CONFIG_967_LENGTH 228 <answer> #define 
#define GOODIX_CONFIG_GT9X_LENGTH <token> <answer> 240 
<token> GOODIX_BUFFER_STATUS_READY BIT(7) <answer> #define 
#define <token> BIT(4) <answer> GOODIX_HAVE_KEY 
#define GOODIX_BUFFER_STATUS_TIMEOUT <token> <answer> 20 
#define <token> 1 <answer> RESOLUTION_LOC 
#define MAX_CONTACTS_LOC <token> <answer> 5 
#define <token> 6 <answer> TRIGGER_LOC 
<token> const struct dmi_system_id inverted_x_screen[] = { <answer> static 
#if defined(CONFIG_DMI) && <token> <answer> defined(CONFIG_X86) 
.ident <token> "Cube I15-TC", <answer> = 
.matches <token> { <answer> = 
DMI_MATCH(DMI_SYS_VENDOR, <token> <answer> "Cube"), 
<token> "I15-TC") <answer> DMI_MATCH(DMI_PRODUCT_NAME, 
int goodix_i2c_read(struct i2c_client *client, u16 reg, u8 *buf, int <token> <answer> len) 
struct i2c_msg <token> <answer> msgs[2]; 
<token> wbuf = cpu_to_be16(reg); <answer> __be16 
<token> ret; <answer> int 
msgs[0].flags = <token> <answer> 0; 
msgs[0].addr <token> client->addr; <answer> = 
msgs[0].len = <token> <answer> 2; 
msgs[0].buf <token> (u8 *)&wbuf; <answer> = 
<token> = I2C_M_RD; <answer> msgs[1].flags 
msgs[1].addr <token> client->addr; <answer> = 
<token> = len; <answer> msgs[1].len 
msgs[1].buf <token> buf; <answer> = 
ret <token> i2c_transfer(client->adapter, msgs, 2); <answer> = 
if (ret >= <token> <answer> 0) 
ret = (ret == ARRAY_SIZE(msgs) ? <token> : -EIO); <answer> 0 
<token> (ret) <answer> if 
dev_err(&client->dev, "Error reading %d bytes from <token> %d\n", <answer> 0x%04x: 
<token> reg, ret); <answer> len, 
return <token> <answer> ret; 
int goodix_i2c_write(struct i2c_client *client, u16 reg, const <token> *buf, int len) <answer> u8 
<token> *addr_buf; <answer> u8 
<token> i2c_msg msg; <answer> struct 
<token> ret; <answer> int 
addr_buf = kmalloc(len <token> 2, GFP_KERNEL); <answer> + 
<token> (!addr_buf) <answer> if 
return <token> <answer> -ENOMEM; 
addr_buf[0] = reg <token> 8; <answer> >> 
addr_buf[1] = reg <token> 0xFF; <answer> & 
memcpy(&addr_buf[2], buf, <token> <answer> len); 
msg.flags = <token> <answer> 0; 
msg.addr = <token> <answer> client->addr; 
<token> = addr_buf; <answer> msg.buf 
msg.len = <token> + 2; <answer> len 
ret = <token> &msg, 1); <answer> i2c_transfer(client->adapter, 
if <token> >= 0) <answer> (ret 
ret = (ret == 1 ? 0 <token> -EIO); <answer> : 
<token> (ret) <answer> if 
dev_err(&client->dev, "Error writing %d bytes to 0x%04x: <token> <answer> %d\n", 
len, <token> ret); <answer> reg, 
return <token> <answer> ret; 
int <token> i2c_client *client, u16 reg, u8 value) <answer> goodix_i2c_write_u8(struct 
return goodix_i2c_write(client, <token> &value, sizeof(value)); <answer> reg, 
static const struct <token> *goodix_get_chip_data(const char *id) <answer> goodix_chip_data 
unsigned int <token> <answer> i; 
for (i = 0; goodix_chip_ids[i].id; i++) <token> <answer> { 
if (!strcmp(goodix_chip_ids[i].id, <token> <answer> id)) 
<token> goodix_chip_ids[i].data; <answer> return 
return <token> <answer> &gt9x_chip_data; 
static int goodix_ts_read_input_report(struct goodix_ts_data <token> u8 *data) <answer> *ts, 
<token> long max_timeout; <answer> unsigned 
<token> touch_num; <answer> int 
int <token> <answer> error; 
u16 addr = <token> <answer> GOODIX_READ_COOR_ADDR; 
const int header_contact_keycode_size = 1 + ts->contact_size <token> 1; <answer> + 
max_timeout = jiffies + <token> <answer> msecs_to_jiffies(GOODIX_BUFFER_STATUS_TIMEOUT); 
<token> { <answer> do 
error = <token> addr, data, <answer> goodix_i2c_read(ts->client, 
if <token> <answer> (error) 
<token> error; <answer> return 
if <token> & GOODIX_BUFFER_STATUS_READY) { <answer> (data[0] 
touch_num = data[0] & <token> <answer> 0x0f; 
<token> (touch_num > ts->max_touch_num) <answer> if 
<token> -EPROTO; <answer> return 
if <token> > 1) { <answer> (touch_num 
addr += <token> <answer> header_contact_keycode_size; 
data <token> header_contact_keycode_size; <answer> += 
error = <token> <answer> goodix_i2c_read(ts->client, 
addr, <token> <answer> data, 
ts->contact_size <token> <answer> * 
(touch_num <token> 1)); <answer> - 
<token> (error) <answer> if 
return <token> <answer> error; 
return <token> <answer> touch_num; 
if (data[0] == 0 && ts->firmware_name) <token> <answer> { 
if <token> <answer> (goodix_handle_fw_request(ts)) 
return <token> <answer> 0; 
return <token> <answer> -ENOMSG; 
static int goodix_create_pen_input(struct <token> *ts) <answer> goodix_ts_data 
struct device *dev <token> &ts->client->dev; <answer> = 
struct <token> *input; <answer> input_dev 
<token> = devm_input_allocate_device(dev); <answer> input 
<token> (!input) <answer> if 
<token> -ENOMEM; <answer> return 
input_copy_abs(input, ABS_X, ts->input_dev, <token> <answer> ABS_MT_POSITION_X); 
input_copy_abs(input, ABS_Y, ts->input_dev, <token> <answer> ABS_MT_POSITION_Y); 
input_abs_set_res(input, <token> 10); <answer> ABS_X, 
input_abs_set_res(input, ABS_Y, <token> <answer> 10); 
<token> ABS_PRESSURE, 0, 255, 0, 0); <answer> input_set_abs_params(input, 
<token> EV_KEY, BTN_TOUCH); <answer> input_set_capability(input, 
<token> EV_KEY, BTN_TOOL_PEN); <answer> input_set_capability(input, 
input_set_capability(input, EV_KEY, <token> <answer> BTN_STYLUS); 
input_set_capability(input, EV_KEY, <token> <answer> BTN_STYLUS2); 
<token> input->propbit); <answer> __set_bit(INPUT_PROP_DIRECT, 
input->name = "Goodix Active <token> <answer> Pen"; 
input->phys = <token> <answer> "input/pen"; 
<token> = BUS_I2C; <answer> input->id.bustype 
input->id.vendor <token> 0x0416; <answer> = 
if <token> 10, &input->id.product)) <answer> (kstrtou16(ts->id, 
<token> = 0x1001; <answer> input->id.product 
input->id.version = <token> <answer> ts->version; 
<token> = input; <answer> ts->input_pen 
<token> 0; <answer> return 
static void goodix_ts_report_pen_down(struct <token> *ts, u8 *data) <answer> goodix_ts_data 
int input_x, <token> input_w, error; <answer> input_y, 
u8 <token> <answer> key_value; 
if (!ts->pen_input_registered) <token> <answer> { 
error = <token> <answer> input_register_device(ts->input_pen); 
ts->pen_input_registered = (error == 0) ? <token> : error; <answer> 1 
if <token> < 0) <answer> (ts->pen_input_registered 
if (ts->contact_size == <token> { <answer> 9) 
input_x = <token> <answer> get_unaligned_le16(&data[4]); 
input_y <token> get_unaligned_le16(&data[6]); <answer> = 
<token> = get_unaligned_le16(&data[8]); <answer> input_w 
} <token> { <answer> else 
input_x <token> get_unaligned_le16(&data[2]); <answer> = 
input_y <token> get_unaligned_le16(&data[4]); <answer> = 
<token> = get_unaligned_le16(&data[6]); <answer> input_w 
touchscreen_report_pos(ts->input_pen, &ts->prop, input_x, input_y, <token> <answer> false); 
input_report_abs(ts->input_pen, ABS_PRESSURE, <token> <answer> input_w); 
<token> BTN_TOUCH, 1); <answer> input_report_key(ts->input_pen, 
<token> BTN_TOOL_PEN, 1); <answer> input_report_key(ts->input_pen, 
if (data[0] <token> GOODIX_HAVE_KEY) { <answer> & 
key_value = data[1 <token> ts->contact_size]; <answer> + 
input_report_key(ts->input_pen, BTN_STYLUS, <token> & 0x10); <answer> key_value 
<token> BTN_STYLUS2, key_value & 0x20); <answer> input_report_key(ts->input_pen, 
} else <token> <answer> { 
input_report_key(ts->input_pen, BTN_STYLUS, <token> <answer> 0); 
input_report_key(ts->input_pen, BTN_STYLUS2, <token> <answer> 0); 
<token> void goodix_ts_report_pen_up(struct goodix_ts_data *ts) <answer> static 
<token> (!ts->input_pen) <answer> if 
input_report_key(ts->input_pen, BTN_TOUCH, <token> <answer> 0); 
input_report_key(ts->input_pen, BTN_TOOL_PEN, <token> <answer> 0); 
input_report_key(ts->input_pen, <token> 0); <answer> BTN_STYLUS, 
input_report_key(ts->input_pen, <token> 0); <answer> BTN_STYLUS2, 
<token> void goodix_ts_report_touch_8b(struct goodix_ts_data *ts, u8 *coor_data) <answer> static 
int id = coor_data[0] <token> 0x0F; <answer> & 
int <token> = get_unaligned_le16(&coor_data[1]); <answer> input_x 
int input_y = <token> <answer> get_unaligned_le16(&coor_data[3]); 
int input_w = <token> <answer> get_unaligned_le16(&coor_data[5]); 
input_mt_slot(ts->input_dev, <token> <answer> id); 
input_mt_report_slot_state(ts->input_dev, MT_TOOL_FINGER, <token> <answer> true); 
touchscreen_report_pos(ts->input_dev, <token> <answer> &ts->prop, 
<token> input_y, true); <answer> input_x, 
input_report_abs(ts->input_dev, ABS_MT_TOUCH_MAJOR, <token> <answer> input_w); 
<token> ABS_MT_WIDTH_MAJOR, input_w); <answer> input_report_abs(ts->input_dev, 
static void goodix_ts_report_touch_9b(struct goodix_ts_data <token> u8 *coor_data) <answer> *ts, 
<token> id = coor_data[1] & 0x0F; <answer> int 
int <token> = get_unaligned_le16(&coor_data[3]); <answer> input_x 
int <token> = get_unaligned_le16(&coor_data[5]); <answer> input_y 
int input_w = <token> <answer> get_unaligned_le16(&coor_data[7]); 
<token> id); <answer> input_mt_slot(ts->input_dev, 
input_mt_report_slot_state(ts->input_dev, MT_TOOL_FINGER, <token> <answer> true); 
touchscreen_report_pos(ts->input_dev, <token> <answer> &ts->prop, 
<token> input_y, true); <answer> input_x, 
input_report_abs(ts->input_dev, ABS_MT_TOUCH_MAJOR, <token> <answer> input_w); 
<token> ABS_MT_WIDTH_MAJOR, input_w); <answer> input_report_abs(ts->input_dev, 
<token> void goodix_ts_release_keys(struct goodix_ts_data *ts) <answer> static 
<token> i; <answer> int 
for (i = 0; i < <token> i++) <answer> GOODIX_MAX_KEYS; 
<token> ts->keymap[i], 0); <answer> input_report_key(ts->input_dev, 
static void goodix_ts_report_key(struct goodix_ts_data <token> u8 *data) <answer> *ts, 
<token> touch_num; <answer> int 
u8 <token> <answer> key_value; 
int <token> <answer> i; 
if <token> & GOODIX_HAVE_KEY) { <answer> (data[0] 
<token> = data[0] & 0x0f; <answer> touch_num 
key_value = <token> + ts->contact_size * touch_num]; <answer> data[1 
for (i = 0; i < <token> i++) <answer> GOODIX_MAX_KEYS; 
if <token> & BIT(i)) <answer> (key_value 
<token> 1); <answer> ts->keymap[i], 
} <token> { <answer> else 
static void goodix_process_events(struct goodix_ts_data <token> <answer> *ts) 
u8 point_data[2 <token> GOODIX_MAX_CONTACT_SIZE * GOODIX_MAX_CONTACTS]; <answer> + 
<token> touch_num; <answer> int 
<token> i; <answer> int 
touch_num = <token> point_data); <answer> goodix_ts_read_input_report(ts, 
<token> (touch_num < 0) <answer> if 
<token> irqreturn_t goodix_ts_irq_handler(int irq, void *dev_id) <answer> static 
struct goodix_ts_data <token> = dev_id; <answer> *ts 
goodix_i2c_write_u8(ts->client, GOODIX_READ_COOR_ADDR, <token> <answer> 0); 
return <token> <answer> IRQ_HANDLED; 
static void <token> goodix_ts_data *ts) <answer> goodix_free_irq(struct 
devm_free_irq(&ts->client->dev, ts->client->irq, <token> <answer> ts); 
static int goodix_request_irq(struct <token> *ts) <answer> goodix_ts_data 
return <token> ts->client->irq, <answer> devm_request_threaded_irq(&ts->client->dev, 
NULL, <token> <answer> goodix_ts_irq_handler, 
ts->irq_flags, ts->client->name, <token> <answer> ts); 
static int goodix_check_cfg_8(struct <token> *ts, const u8 *cfg, int len) <answer> goodix_ts_data 
int i, raw_cfg_len <token> len - 2; <answer> = 
u8 check_sum = <token> <answer> 0; 
for <token> = 0; i < raw_cfg_len; i++) <answer> (i 
check_sum <token> cfg[i]; <answer> += 
check_sum = (~check_sum) + <token> <answer> 1; 
if <token> != cfg[raw_cfg_len]) { <answer> (check_sum 
"The checksum <token> the config fw is not correct"); <answer> of 
return <token> <answer> -EINVAL; 
if (cfg[raw_cfg_len + 1] <token> 1) { <answer> != 
"Config <token> must have Config_Fresh register set"); <answer> fw 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
static void <token> goodix_ts_data *ts) <answer> goodix_calc_cfg_checksum_8(struct 
int <token> raw_cfg_len = ts->chip->config_len - 2; <answer> i, 
u8 check_sum = <token> <answer> 0; 
for (i <token> 0; i < raw_cfg_len; i++) <answer> = 
check_sum += <token> <answer> ts->config[i]; 
check_sum = (~check_sum) <token> 1; <answer> + 
<token> = check_sum; <answer> ts->config[raw_cfg_len] 
static int goodix_check_cfg(struct <token> *ts, const u8 *cfg, int len) <answer> goodix_ts_data 
if <token> < GOODIX_CONFIG_MIN_LENGTH || <answer> (len 
len > <token> { <answer> GOODIX_CONFIG_MAX_LENGTH) 
"The length of the config fw is <token> correct"); <answer> not 
return <token> <answer> -EINVAL; 
return ts->chip->check_config(ts, <token> len); <answer> cfg, 
int <token> goodix_ts_data *ts, const u8 *cfg, int len) <answer> goodix_send_cfg(struct 
<token> error; <answer> int 
error = <token> cfg, len); <answer> goodix_check_cfg(ts, 
<token> (error) <answer> if 
<token> error; <answer> return 
error = goodix_i2c_write(ts->client, ts->chip->config_addr, cfg, <token> <answer> len); 
<token> (error) <answer> if 
<token> error; <answer> return 
dev_dbg(&ts->client->dev, <token> sent successfully."); <answer> "Config 
return gpiod_direction_output_raw(ts->gpiod_int, <token> <answer> value); 
case <token> <answer> IRQ_PIN_ACCESS_ACPI_METHOD: 
return goodix_pin_acpi_output_method(ts, <token> <answer> value); 
int goodix_reset_no_int_sync(struct <token> *ts) <answer> goodix_ts_data 
<token> error; <answer> int 
if (ts->irq_pin_access_method == <token> { <answer> IRQ_PIN_ACCESS_GPIO) 
error = <token> <answer> gpiod_direction_input(ts->gpiod_rst); 
<token> (error) <answer> if 
goto <token> <answer> error; 
<token> 0; <answer> return 
dev_err(&ts->client->dev, "Controller <token> failed.\n"); <answer> reset 
return <token> <answer> error; 
static int <token> goodix_ts_data *ts) <answer> goodix_reset(struct 
int <token> <answer> error; 
error <token> goodix_reset_no_int_sync(ts); <answer> = 
<token> (error) <answer> if 
<token> error; <answer> return 
return <token> <answer> goodix_int_sync(ts); 
#ifdef <token> <answer> ACPI_GPIO_SUPPORT 
static <token> struct acpi_gpio_params first_gpio = { 0, 0, false }; <answer> const 
static const struct acpi_gpio_params second_gpio <token> { 1, 0, false }; <answer> = 
static const <token> acpi_gpio_mapping acpi_goodix_int_first_gpios[] = { <answer> struct 
{ GOODIX_GPIO_INT_NAME "-gpios", &first_gpio, <token> }, <answer> 1 
{ <token> "-gpios", &second_gpio, 1 }, <answer> GOODIX_GPIO_RST_NAME 
{ <token> <answer> }, 
static const struct acpi_gpio_mapping acpi_goodix_int_last_gpios[] <token> { <answer> = 
{ GOODIX_GPIO_RST_NAME "-gpios", &first_gpio, 1 <token> <answer> }, 
{ GOODIX_GPIO_INT_NAME "-gpios", &second_gpio, 1 <token> <answer> }, 
{ <token> <answer> }, 
static const struct acpi_gpio_mapping acpi_goodix_reset_only_gpios[] = <token> <answer> { 
{ GOODIX_GPIO_RST_NAME <token> &first_gpio, 1 }, <answer> "-gpios", 
<token> }, <answer> { 
<token> int goodix_resource(struct acpi_resource *ares, void *data) <answer> static 
<token> goodix_ts_data *ts = data; <answer> struct 
struct <token> *dev = &ts->client->dev; <answer> device 
struct acpi_resource_gpio <token> <answer> *gpio; 
if <token> &gpio)) { <answer> (acpi_gpio_get_irq_resource(ares, 
if (ts->gpio_int_idx <token> -1) { <answer> == 
ts->gpio_int_idx = <token> <answer> ts->gpio_count; 
<token> else { <answer> } 
dev_err(dev, "More then one GpioInt <token> ignoring ACPI GPIO resources\n"); <answer> resource, 
ts->gpio_int_idx <token> -2; <answer> = 
} else if (acpi_gpio_get_io_resource(ares, <token> <answer> &gpio)) 
<token> 0; <answer> return 
static int goodix_add_acpi_gpio_mappings(struct <token> *ts) <answer> goodix_ts_data 
const <token> acpi_gpio_mapping *gpio_mapping = NULL; <answer> struct 
struct <token> *dev = &ts->client->dev; <answer> device 
int <token> ret; <answer> irq, 
<token> = 0; <answer> ts->gpio_count 
<token> = -1; <answer> ts->gpio_int_idx 
<token> = acpi_dev_get_resources(ACPI_COMPANION(dev), &resources, <answer> ret 
<token> ts); <answer> goodix_resource, 
<token> (ret < 0) { <answer> if 
dev_err(dev, "Error getting <token> resources: %d\n", ret); <answer> ACPI 
return <token> <answer> ret; 
<token> (soc_intel_is_cht() && ts->gpio_count == 2 && ts->gpio_int_idx != -1) { <answer> if 
irq = acpi_dev_gpio_irq_get(ACPI_COMPANION(dev), <token> <answer> 0); 
if (irq > 0 && irq != <token> { <answer> ts->client->irq) 
dev_warn(dev, "Overriding IRQ %d -> %d\n", ts->client->irq, <token> <answer> irq); 
<token> = irq; <answer> ts->client->irq 
ts->irq_pin_access_method = <token> <answer> IRQ_PIN_ACCESS_NONE; 
gpio_mapping = <token> <answer> acpi_goodix_int_first_gpios; 
} else <token> <answer> { 
dev_warn(dev, "Unexpected ACPI resources: gpio_count %d, <token> %d\n", <answer> gpio_int_idx 
ts->gpio_count, <token> <answer> ts->gpio_int_idx); 
return <token> <answer> -EINVAL; 
ts->gpiod_rst_flags = <token> <answer> GPIOD_ASIS; 
<token> devm_acpi_dev_add_driver_gpios(dev, gpio_mapping); <answer> return 
static int <token> goodix_ts_data *ts) <answer> goodix_add_acpi_gpio_mappings(struct 
return <token> <answer> -EINVAL; 
static int goodix_get_gpio_config(struct goodix_ts_data <token> <answer> *ts) 
struct device <token> <answer> *dev; 
struct <token> *gpiod; <answer> gpio_desc 
bool added_acpi_mappings = <token> <answer> false; 
<token> (!ts->client) <answer> if 
return <token> <answer> -EINVAL; 
dev = <token> <answer> &ts->client->dev; 
ts->gpiod_rst_flags <token> GPIOD_IN; <answer> = 
<token> = devm_regulator_get(dev, "AVDD28"); <answer> ts->avdd28 
<token> (IS_ERR(ts->avdd28)) <answer> if 
return dev_err_probe(dev, PTR_ERR(ts->avdd28), "Failed to get AVDD28 <token> <answer> regulator\n"); 
ts->vddio = devm_regulator_get(dev, <token> <answer> "VDDIO"); 
<token> (IS_ERR(ts->vddio)) <answer> if 
return dev_err_probe(dev, PTR_ERR(ts->vddio), "Failed to get <token> regulator\n"); <answer> VDDIO 
if <token> || !ts->gpiod_rst) <answer> (!ts->gpiod_int 
<token> = IRQ_PIN_ACCESS_NONE; <answer> ts->irq_pin_access_method 
<token> IRQ_PIN_ACCESS_ACPI_METHOD: <answer> case 
<token> (!ts->gpiod_rst) <answer> if 
ts->irq_pin_access_method = <token> <answer> IRQ_PIN_ACCESS_NONE; 
if <token> && ts->gpiod_rst) { <answer> (ts->gpiod_int 
ts->reset_controller_at_probe = <token> <answer> true; 
ts->load_cfg_from_disk = <token> <answer> true; 
ts->irq_pin_access_method <token> IRQ_PIN_ACCESS_GPIO; <answer> = 
return <token> <answer> 0; 
static void <token> goodix_ts_data *ts) <answer> goodix_read_config(struct 
int <token> y_max; <answer> x_max, 
<token> error; <answer> int 
<token> (!ts->firmware_name) { <answer> if 
error = goodix_i2c_read(ts->client, <token> <answer> ts->chip->config_addr, 
ts->config, <token> <answer> ts->chip->config_len); 
if (error) <token> <answer> { 
ts->int_trigger_type = <token> <answer> GOODIX_INT_TRIGGER; 
ts->max_touch_num <token> GOODIX_MAX_CONTACTS; <answer> = 
ts->int_trigger_type = <token> & 0x03; <answer> ts->config[TRIGGER_LOC] 
ts->max_touch_num = ts->config[MAX_CONTACTS_LOC] <token> 0x0f; <answer> & 
<token> = get_unaligned_le16(&ts->config[RESOLUTION_LOC]); <answer> x_max 
<token> = get_unaligned_le16(&ts->config[RESOLUTION_LOC + 2]); <answer> y_max 
if <token> && y_max) { <answer> (x_max 
input_abs_set_max(ts->input_dev, ABS_MT_POSITION_X, x_max - <token> <answer> 1); 
input_abs_set_max(ts->input_dev, <token> y_max - 1); <answer> ABS_MT_POSITION_Y, 
static <token> goodix_read_version(struct goodix_ts_data *ts) <answer> int 
int <token> <answer> error; 
<token> buf[6]; <answer> u8 
char id_str[GOODIX_ID_MAX_LEN + <token> <answer> 1]; 
<token> = goodix_i2c_read(ts->client, GOODIX_REG_ID, buf, sizeof(buf)); <answer> error 
<token> (error) <answer> if 
return <token> <answer> error; 
memcpy(id_str, <token> GOODIX_ID_MAX_LEN); <answer> buf, 
id_str[GOODIX_ID_MAX_LEN] <token> 0; <answer> = 
<token> id_str, GOODIX_ID_MAX_LEN + 1); <answer> strscpy(ts->id, 
<token> = get_unaligned_le16(&buf[4]); <answer> ts->version 
dev_info(&ts->client->dev, "ID %s, version: %04x\n", <token> <answer> ts->id, 
<token> 0; <answer> return 
static <token> goodix_i2c_test(struct i2c_client *client) <answer> int 
int retry = <token> <answer> 0; 
<token> error; <answer> int 
u8 <token> <answer> test; 
while (retry++ < <token> { <answer> 2) 
error <token> goodix_i2c_read(client, GOODIX_REG_ID, &test, 1); <answer> = 
if <token> <answer> (!error) 
return <token> <answer> 0; 
<token> error; <answer> return 
<token> int goodix_configure_dev(struct goodix_ts_data *ts) <answer> static 
<token> error; <answer> int 
int <token> <answer> i; 
<token> = GOODIX_INT_TRIGGER; <answer> ts->int_trigger_type 
ts->max_touch_num = <token> <answer> GOODIX_MAX_CONTACTS; 
ts->input_dev <token> devm_input_allocate_device(&ts->client->dev); <answer> = 
<token> (!ts->input_dev) { <answer> if 
dev_err(&ts->client->dev, "Failed to allocate <token> device."); <answer> input 
<token> -ENOMEM; <answer> return 
<token> = "Goodix Capacitive TouchScreen"; <answer> ts->input_dev->name 
ts->input_dev->phys <token> "input/ts"; <answer> = 
<token> = BUS_I2C; <answer> ts->input_dev->id.bustype 
ts->input_dev->id.vendor <token> 0x0416; <answer> = 
<token> (kstrtou16(ts->id, 10, &ts->input_dev->id.product)) <answer> if 
ts->input_dev->id.product <token> 0x1001; <answer> = 
ts->input_dev->id.version <token> ts->version; <answer> = 
<token> = ts->keymap; <answer> ts->input_dev->keycode 
<token> = sizeof(ts->keymap[0]); <answer> ts->input_dev->keycodesize 
ts->input_dev->keycodemax = <token> <answer> GOODIX_MAX_KEYS; 
<token> = goodix_create_pen_input(ts); <answer> error 
if <token> <answer> (error) 
<token> error; <answer> return 
ts->irq_flags = goodix_irq_flags[ts->int_trigger_type] <token> IRQF_ONESHOT; <answer> | 
error = <token> <answer> goodix_request_irq(ts); 
if (error) <token> <answer> { 
dev_err(&ts->client->dev, "request IRQ <token> %d\n", error); <answer> failed: 
return <token> <answer> error; 
return <token> <answer> 0; 
static void <token> struct firmware *cfg, void *ctx) <answer> goodix_config_cb(const 
<token> goodix_ts_data *ts = ctx; <answer> struct 
int <token> <answer> error; 
if (ts->firmware_name) <token> <answer> { 
if <token> <answer> (!cfg) 
<token> err_release_cfg; <answer> goto 
error = <token> cfg->data, cfg->size); <answer> goodix_check_cfg(ts, 
<token> (error) <answer> if 
<token> err_release_cfg; <answer> goto 
memcpy(ts->config, <token> cfg->size); <answer> cfg->data, 
} <token> if (cfg) { <answer> else 
return <token> <answer> 0; 
static int <token> device *dev) <answer> goodix_resume(struct 
struct i2c_client <token> = to_i2c_client(dev); <answer> *client 
struct goodix_ts_data *ts = <token> <answer> i2c_get_clientdata(client); 
<token> config_ver; <answer> u8 
<token> error; <answer> int 
if <token> == IRQ_PIN_ACCESS_NONE) { <answer> (ts->irq_pin_access_method 
<token> 0; <answer> return 
error <token> goodix_irq_direction_output(ts, 1); <answer> = 
if <token> <answer> (error) 
return <token> <answer> error; 
<token> 5000); <answer> usleep_range(2000, 
error <token> goodix_int_sync(ts); <answer> = 
if <token> <answer> (error) 
<token> error; <answer> return 
error = <token> ts->chip->config_addr, <answer> goodix_i2c_read(ts->client, 
<token> 1); <answer> &config_ver, 
if (!error && config_ver <token> ts->config[0]) <answer> != 
<token> "Config version mismatch %d != %d, resetting controller\n", <answer> dev_info(dev, 
config_ver, <token> <answer> ts->config[0]); 
<token> (error != 0 || config_ver != ts->config[0]) { <answer> if 
error = <token> <answer> goodix_reset(ts); 
<token> (error) <answer> if 
return <token> <answer> error; 
error = goodix_send_cfg(ts, ts->config, <token> <answer> ts->chip->config_len); 
<token> (error) <answer> if 
return <token> <answer> error; 
error = <token> <answer> goodix_request_irq(ts); 
<token> (error) <answer> if 
return <token> <answer> error; 
return <token> <answer> 0; 
<token> DEFINE_SIMPLE_DEV_PM_OPS(goodix_pm_ops, goodix_suspend, goodix_resume); <answer> static 
static <token> struct i2c_device_id goodix_ts_id[] = { <answer> const 
<token> "GDIX1001:00", 0 }, <answer> { 
<token> } <answer> { 
MODULE_DEVICE_TABLE(i2c, <token> <answer> goodix_ts_id); 
<token> CONFIG_ACPI <answer> #ifdef 
static const struct <token> goodix_acpi_match[] = { <answer> acpi_device_id 
<token> "GDIX1001", 0 }, <answer> { 
<token> "GDIX1002", 0 }, <answer> { 
{ <token> 0 }, <answer> "GDX9110", 
<token> } <answer> { 
MODULE_DEVICE_TABLE(acpi, <token> <answer> goodix_acpi_match); 
<token> CONFIG_OF <answer> #ifdef 
static const <token> of_device_id goodix_of_match[] = { <answer> struct 
{ .compatible = <token> }, <answer> "goodix,gt1151" 
<token> .compatible = "goodix,gt1158" }, <answer> { 
{ <token> = "goodix,gt5663" }, <answer> .compatible 
{ .compatible = "goodix,gt5688" <token> <answer> }, 
{ .compatible = <token> }, <answer> "goodix,gt911" 
<token> .compatible = "goodix,gt9110" }, <answer> { 
{ <token> = "goodix,gt912" }, <answer> .compatible 
<token> .compatible = "goodix,gt9147" }, <answer> { 
{ .compatible = <token> }, <answer> "goodix,gt917s" 
<token> .compatible = "goodix,gt927" }, <answer> { 
{ <token> = "goodix,gt9271" }, <answer> .compatible 
{ <token> = "goodix,gt928" }, <answer> .compatible 
<token> .compatible = "goodix,gt9286" }, <answer> { 
{ <token> = "goodix,gt967" }, <answer> .compatible 
{ <token> <answer> } 
MODULE_DEVICE_TABLE(of, <token> <answer> goodix_of_match); 
static <token> i2c_driver goodix_ts_driver = { <answer> struct 
.probe <token> goodix_ts_probe, <answer> = 
.remove = <token> <answer> goodix_ts_remove, 
.id_table <token> goodix_ts_id, <answer> = 
.driver = <token> <answer> { 
.name <token> "Goodix-TS", <answer> = 
.acpi_match_table = <token> <answer> ACPI_PTR(goodix_acpi_match), 
<token> = of_match_ptr(goodix_of_match), <answer> .of_match_table 
.pm = <token> <answer> pm_sleep_ptr(&goodix_pm_ops), 
MODULE_AUTHOR("Benjamin Tissoires <token> <answer> <benjamin.tissoires@gmail.com>"); 
<token> Nocera <hadess@hadess.net>"); <answer> MODULE_AUTHOR("Bastien 
MODULE_DESCRIPTION("Goodix <token> driver"); <answer> touchscreen 
<token> v2"); <answer> MODULE_LICENSE("GPL 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/pci.h> 
<token> <linux/irq.h> <answer> #include 
#include <token> <answer> <linux/leds.h> 
<token> <linux/gpio.h> <answer> #include 
#include <token> <answer> <asm/mach-types.h> 
#include <token> <answer> <asm/mach/arch.h> 
<token> <asm/mach/pci.h> <answer> #include 
<token> <plat/orion-gpio.h> <answer> #include 
#include <token> <answer> "common.h" 
<token> "orion5x.h" <answer> #include 
#define <token> 6 <answer> D2NET_GPIO_RED_LED 
#define D2NET_GPIO_BLUE_LED_BLINK_CTRL <token> <answer> 16 
<token> D2NET_GPIO_BLUE_LED_OFF 23 <answer> #define 
static struct gpio_led d2net_leds[] <token> { <answer> = 
.name <token> "d2net:blue:sata", <answer> = 
.default_trigger = <token> <answer> "default-on", 
.gpio <token> D2NET_GPIO_BLUE_LED_OFF, <answer> = 
<token> = 1, <answer> .active_low 
<token> = "d2net:red:fail", <answer> .name 
<token> = D2NET_GPIO_RED_LED, <answer> .gpio 
static <token> gpio_led_platform_data d2net_led_data = { <answer> struct 
.num_leds <token> ARRAY_SIZE(d2net_leds), <answer> = 
.leds = <token> <answer> d2net_leds, 
static struct platform_device d2net_gpio_leds <token> { <answer> = 
.name <token> "leds-gpio", <answer> = 
<token> = -1, <answer> .id 
<token> = { <answer> .dev 
.platform_data = <token> <answer> &d2net_led_data, 
static <token> __init d2net_gpio_leds_init(void) <answer> void 
int <token> <answer> err; 
void <token> d2net_init(void) <answer> __init 
pr_notice("d2net: Flash <token> are not yet supported.\n"); <answer> write 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/fs.h> <answer> #include 
<token> <linux/minix_fs.h> <answer> #include 
#include <token> <answer> <linux/ext2_fs.h> 
#include <token> <answer> <linux/romfs_fs.h> 
#include <token> <answer> <uapi/linux/cramfs_fs.h> 
<token> <linux/initrd.h> <answer> #include 
#include <token> <answer> <linux/string.h> 
<token> <linux/slab.h> <answer> #include 
<token> "do_mounts.h" <answer> #include 
<token> "../fs/squashfs/squashfs_fs.h" <answer> #include 
<token> <linux/decompress/generic.h> <answer> #include 
static struct file <token> *out_file; <answer> *in_file, 
<token> loff_t in_pos, out_pos; <answer> static 
<token> int __init prompt_ramdisk(char *str) <answer> static 
pr_warn("ignoring the deprecated prompt_ramdisk= <token> <answer> option\n"); 
return <token> <answer> 1; 
__setup("prompt_ramdisk=", <token> <answer> prompt_ramdisk); 
static int <token> <answer> __init 
identify_ramdisk_image(struct file <token> loff_t pos, <answer> *file, 
decompress_fn <token> <answer> *decompressor) 
const int size <token> 512; <answer> = 
<token> minix_super_block *minixsb; <answer> struct 
struct <token> *romfsb; <answer> romfs_super_block 
<token> cramfs_super *cramfsb; <answer> struct 
struct <token> *squashfsb; <answer> squashfs_super_block 
int nblocks = <token> <answer> -1; 
unsigned char <token> <answer> *buf; 
<token> char *compress_name; <answer> const 
unsigned long <token> <answer> n; 
int start_block = <token> <answer> rd_image_start; 
buf = kmalloc(size, <token> <answer> GFP_KERNEL); 
<token> (!buf) <answer> if 
return <token> <answer> -ENOMEM; 
minixsb = (struct minix_super_block *) <token> <answer> buf; 
romfsb = (struct <token> *) buf; <answer> romfs_super_block 
<token> = (struct cramfs_super *) buf; <answer> cramfsb 
squashfsb = (struct <token> *) buf; <answer> squashfs_super_block 
<token> 0xe5, size); <answer> memset(buf, 
pos = start_block <token> BLOCK_SIZE; <answer> * 
<token> buf, size, &pos); <answer> kernel_read(file, 
*decompressor <token> decompress_method(buf, size, &compress_name); <answer> = 
if (compress_name) <token> <answer> { 
printk(KERN_NOTICE "RAMDISK: <token> image found at block %d\n", <answer> %s 
<token> start_block); <answer> compress_name, 
if <token> <answer> (!*decompressor) 
"RAMDISK: %s decompressor not <token> <answer> configured!\n", 
<token> = 0; <answer> nblocks 
goto <token> <answer> done; 
pos = start_block * BLOCK_SIZE <token> 0x200; <answer> + 
kernel_read(file, buf, size, <token> <answer> &pos); 
if (cramfsb->magic == <token> { <answer> CRAMFS_MAGIC) 
<token> cramfs filesystem found at block %d\n", <answer> "RAMDISK: 
nblocks = (cramfsb->size + BLOCK_SIZE <token> 1) >> BLOCK_SIZE_BITS; <answer> - 
goto <token> <answer> done; 
pos = <token> + 1) * BLOCK_SIZE; <answer> (start_block 
kernel_read(file, buf, size, <token> <answer> &pos); 
rd_blocks <token> nr_blocks(out_file); <answer> = 
if <token> > rd_blocks) { <answer> (nblocks 
printk("RAMDISK: <token> too big! (%dKiB/%ldKiB)\n", <answer> image 
nblocks, <token> <answer> rd_blocks); 
goto <token> <answer> done; 
if (strcmp(from, <token> == 0) <answer> "/initrd.image") 
devblocks = <token> <answer> nblocks; 
<token> = nr_blocks(in_file); <answer> devblocks 
if <token> == 0) { <answer> (devblocks 
printk(KERN_ERR "RAMDISK: could not <token> device size\n"); <answer> determine 
goto <token> <answer> done; 
<token> = kmalloc(BLOCK_SIZE, GFP_KERNEL); <answer> buf 
<token> (!buf) { <answer> if 
printk(KERN_ERR <token> could not allocate buffer\n"); <answer> "RAMDISK: 
<token> done; <answer> goto 
printk(KERN_NOTICE "RAMDISK: Loading %dKiB [%ld disk%s] into <token> disk... ", <answer> ram 
nblocks, ((nblocks-1)/devblocks)+1, nblocks>devblocks <token> "s" : ""); <answer> ? 
for (i = 0; i < nblocks; <token> { <answer> i++) 
if (i <token> (i % devblocks == 0)) { <answer> && 
pr_cont("done disk <token> <answer> #1.\n"); 
<token> = 0; <answer> rotate 
kernel_read(in_file, buf, BLOCK_SIZE, <token> <answer> &in_pos); 
kernel_write(out_file, buf, BLOCK_SIZE, <token> <answer> &out_pos); 
#if <token> <answer> !defined(CONFIG_S390) 
if <token> % 16)) { <answer> (!(i 
pr_cont("%c\b", rotator[rotate <token> 0x3]); <answer> & 
<token> = 1; <answer> res 
<token> res; <answer> return 
int <token> rd_load_disk(int n) <answer> __init 
<token> ROOT_DEV); <answer> create_dev("/dev/root", 
create_dev("/dev/ram", MKDEV(RAMDISK_MAJOR, <token> <answer> n)); 
<token> rd_load_image("/dev/root"); <answer> return 
<token> int exit_code; <answer> static 
<token> int decompress_error; <answer> static 
<token> long __init compr_fill(void *buf, unsigned long len) <answer> static 
long r = kernel_read(in_file, buf, <token> &in_pos); <answer> len, 
if (r < <token> <answer> 0) 
printk(KERN_ERR <token> error while reading compressed data"); <answer> "RAMDISK: 
else if (r <token> 0) <answer> == 
printk(KERN_ERR "RAMDISK: <token> while reading compressed data"); <answer> EOF 
<token> r; <answer> return 
<token> long __init compr_flush(void *window, unsigned long outcnt) <answer> static 
long written = kernel_write(out_file, window, <token> &out_pos); <answer> outcnt, 
if (written != <token> { <answer> outcnt) 
if (decompress_error <token> 0) <answer> == 
"RAMDISK: <token> write (%ld != %ld)\n", <answer> incomplete 
<token> outcnt); <answer> written, 
<token> = 1; <answer> decompress_error 
return <token> <answer> -1; 
return <token> <answer> outcnt; 
<token> void __init error(char *x) <answer> static 
printk(KERN_ERR <token> x); <answer> "%s\n", 
exit_code = <token> <answer> 1; 
decompress_error = <token> <answer> 1; 
static <token> __init crd_load(decompress_fn deco) <answer> int 
<token> result; <answer> int 
if <token> { <answer> (!deco) 
pr_emerg("Invalid ramdisk decompression <token> " <answer> routine. 
"Select <token> config option.\n"); <answer> appropriate 
panic("Could not decompress initial ramdisk <token> <answer> image."); 
result = deco(NULL, 0, compr_fill, compr_flush, NULL, NULL, <token> <answer> error); 
<token> (decompress_error) <answer> if 
result = <token> <answer> 1; 
return <token> <answer> result; 
<token> <linux/bitfield.h> <answer> #include 
#include <token> <answer> <linux/device.h> 
#include <token> <answer> <linux/errno.h> 
<token> <linux/i3c/master.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
<token> "hci.h" <answer> #include 
#include <token> <answer> "ext_caps.h" 
#include <token> <answer> "xfer_mode_rate.h" 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/slab.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/proc_fs.h> 
<token> <linux/skbuff.h> <answer> #include 
#include <token> <answer> <linux/netfilter.h> 
#include <token> <answer> <linux/netfilter_ipv4.h> 
#include <token> <answer> <linux/netfilter_ipv6.h> 
#include <token> <answer> <linux/netfilter_bridge.h> 
#include <token> <answer> <linux/seq_file.h> 
#include <token> <answer> <linux/rcupdate.h> 
#include <token> <answer> <net/protocol.h> 
#include <token> <answer> <net/netfilter/nf_queue.h> 
#include <token> <answer> <net/dst.h> 
#include <token> <answer> "nf_internals.h" 
static const <token> nf_queue_handler __rcu *nf_queue_handler; <answer> struct 
void nf_register_queue_handler(const struct <token> *qh) <answer> nf_queue_handler 
<token> <media/rc-map.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> "trace/beauty/beauty.h" 
static size_t renameat2__scnprintf_flags(unsigned long flags, char *bf, size_t size, bool <token> <answer> show_prefix) 
#include <token> <answer> "trace/beauty/generated/rename_flags_array.c" 
<token> DEFINE_STRARRAY(rename_flags, "RENAME_"); <answer> static 
return <token> bf, size, show_prefix, flags); <answer> strarray__scnprintf_flags(&strarray__rename_flags, 
size_t syscall_arg__scnprintf_renameat2_flags(char *bf, size_t size, <token> syscall_arg *arg) <answer> struct 
<token> long flags = arg->val; <answer> unsigned 
return renameat2__scnprintf_flags(flags, <token> size, arg->show_string_prefix); <answer> bf, 
#include <token> <answer> <linux/bitops.h> 
#include <token> <answer> <linux/gpio/driver.h> 
#include <token> <answer> <linux/ioport.h> 
#include <token> <answer> <linux/mfd/lpc_ich.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> DRV_NAME "gpio_ich" <answer> #define 
<token> GPIO_REG { <answer> enum 
GPIO_USE_SEL <token> 0, <answer> = 
static const u8 ichx_regs[4][3] <token> { <answer> = 
bool <token> <answer> use_outlvl_cache; 
static <token> { <answer> struct 
spinlock_t <token> <answer> lock; 
struct <token> *dev; <answer> device 
<token> gpio_chip chip; <answer> struct 
return ichx_write_bit(GPIO_IO_SEL, nr, 1, <token> <answer> 1); 
static int ichx_gpio_direction_output(struct gpio_chip *gpio, unsigned int <token> <answer> nr, 
<token> val) <answer> int 
return ichx_write_bit(GPIO_IO_SEL, nr, 0, <token> <answer> 1); 
static int ichx_gpio_get(struct <token> *chip, unsigned int nr) <answer> gpio_chip 
<token> ichx_read_bit(GPIO_LVL, nr); <answer> return 
static int ich6_gpio_get(struct <token> *chip, unsigned int nr) <answer> gpio_chip 
<token> long flags; <answer> unsigned 
<token> data; <answer> u32 
if (nr <token> 16) { <answer> < 
if <token> <answer> (!ichx_priv.pm_base) 
return <token> <answer> -ENXIO; 
spin_lock_irqsave(&ichx_priv.lock, <token> <answer> flags); 
if <token> / 32] & BIT(nr & 0x1f)) <answer> (ichx_priv.desc->use_sel_ignore[nr 
return <token> <answer> 0; 
return ichx_read_bit(GPIO_USE_SEL, nr) ? <token> : -ENODEV; <answer> 0 
static int ich6_gpio_request(struct gpio_chip <token> unsigned int nr) <answer> *chip, 
if <token> == 16 || nr == 17) <answer> (nr 
nr -= <token> <answer> 16; 
return <token> nr); <answer> ichx_gpio_request(chip, 
static <token> ichx_gpio_set(struct gpio_chip *chip, unsigned int nr, int val) <answer> void 
<token> nr, val, 0); <answer> ichx_write_bit(GPIO_LVL, 
static void ichx_gpiolib_setup(struct <token> *chip) <answer> gpio_chip 
chip->owner <token> THIS_MODULE; <answer> = 
<token> = DRV_NAME; <answer> chip->label 
<token> = ichx_priv.dev; <answer> chip->parent 
.use_sel_ignore <token> {0x00130000, 0x00010000, 0x0}, <answer> = 
.ngpio = <token> <answer> 60, 
.regs <token> avoton_regs, <answer> = 
.reglen = <token> <answer> avoton_reglen, 
.use_outlvl_cache = <token> <answer> true, 
static int <token> device *dev, <answer> ichx_gpio_request_regions(struct 
struct resource *res_base, const char *name, <token> use_gpio) <answer> u8 
int <token> <answer> i; 
if (!res_base <token> !res_base->start || !res_base->end) <answer> || 
<token> -ENODEV; <answer> return 
for <token> = 0; i < ARRAY_SIZE(ichx_priv.desc->regs[0]); i++) { <answer> (i 
<token> (!(use_gpio & BIT(i))) <answer> if 
if <token> <answer> (!devm_request_region(dev, 
res_base->start + <token> <answer> ichx_priv.desc->regs[0][i], 
ichx_priv.desc->reglen[i], <token> <answer> name)) 
return <token> <answer> -EBUSY; 
return <token> <answer> 0; 
<token> int ichx_gpio_probe(struct platform_device *pdev) <answer> static 
struct device *dev <token> &pdev->dev; <answer> = 
struct lpc_ich_info *ich_info = <token> <answer> dev_get_platdata(dev); 
struct resource *res_base, <token> <answer> *res_pm; 
int <token> <answer> err; 
if <token> <answer> (!ich_info) 
return <token> <answer> -ENODEV; 
switch (ich_info->gpio_version) <token> <answer> { 
<token> ICH_I3100_GPIO: <answer> case 
ichx_priv.desc <token> &i3100_desc; <answer> = 
<token> ICH_V5_GPIO: <answer> case 
ichx_priv.desc = <token> <answer> &intel5_desc; 
<token> ICH_V6_GPIO: <answer> case 
ichx_priv.desc = <token> <answer> &ich6_desc; 
case <token> <answer> ICH_V7_GPIO: 
<token> = &ich7_desc; <answer> ichx_priv.desc 
case <token> <answer> ICH_V9_GPIO: 
<token> = &ich9_desc; <answer> ichx_priv.desc 
<token> ICH_V10CORP_GPIO: <answer> case 
ichx_priv.desc = <token> <answer> &ich10_corp_desc; 
case <token> <answer> ICH_V10CONS_GPIO: 
<token> = &ich10_cons_desc; <answer> ichx_priv.desc 
<token> AVOTON_GPIO: <answer> case 
ichx_priv.desc <token> &avoton_desc; <answer> = 
return <token> <answer> -ENODEV; 
ichx_priv.dev <token> dev; <answer> = 
res_base = platform_get_resource(pdev, <token> ICH_RES_GPIO); <answer> IORESOURCE_IO, 
err = ichx_gpio_request_regions(dev, <token> pdev->name, <answer> res_base, 
<token> (err) <answer> if 
return <token> <answer> err; 
ichx_priv.gpio_base = <token> <answer> res_base; 
<token> = ich_info->use_gpio; <answer> ichx_priv.use_gpio 
<token> (!ichx_priv.desc->uses_gpe0) <answer> if 
goto <token> <answer> init; 
res_pm = platform_get_resource(pdev, IORESOURCE_IO, <token> <answer> ICH_RES_GPE0); 
if (!res_pm) <token> <answer> { 
dev_warn(dev, "ACPI <token> is unavailable, GPI 0 - 15 unavailable\n"); <answer> BAR 
goto <token> <answer> init; 
if (!devm_request_region(dev, res_pm->start, <token> <answer> resource_size(res_pm), 
pdev->name)) <token> <answer> { 
dev_warn(dev, "ACPI BAR is busy, GPI 0 <token> 15 unavailable\n"); <answer> - 
<token> init; <answer> goto 
<token> = res_pm; <answer> ichx_priv.pm_base 
err = <token> &ichx_priv.chip, NULL); <answer> devm_gpiochip_add_data(dev, 
if <token> { <answer> (err) 
<token> "Failed to register GPIOs\n"); <answer> dev_err(dev, 
return <token> <answer> err; 
dev_info(dev, "GPIO <token> %d to %d\n", ichx_priv.chip.base, <answer> from 
ichx_priv.chip.base + ichx_priv.chip.ngpio - <token> <answer> 1); 
<token> 0; <answer> return 
<token> struct platform_driver ichx_gpio_driver = { <answer> static 
.driver = <token> <answer> { 
<token> = DRV_NAME, <answer> .name 
<token> = ichx_gpio_probe, <answer> .probe 
MODULE_AUTHOR("Peter <token> <ptyser@xes-inc.com>"); <answer> Tyser 
MODULE_DESCRIPTION("GPIO interface for Intel <token> series"); <answer> ICH 
<token> void irdma_request_reset(struct irdma_pci_f *rf) <answer> static 
struct ice_pf *pf = <token> <answer> rf->cdev; 
<token> "Requesting a reset\n"); <answer> ibdev_warn(&rf->iwdev->ibdev, 
<token> IIDC_PFR); <answer> ice_rdma_request_reset(pf, 
static int irdma_lan_register_qset(struct irdma_sc_vsi <token> <answer> *vsi, 
<token> irdma_ws_node *tc_node) <answer> struct 
struct irdma_device *iwdev = <token> <answer> vsi->back_vsi; 
struct ice_pf <token> = iwdev->rf->cdev; <answer> *pf 
struct iidc_rdma_qset_params <token> = {}; <answer> qset 
int <token> <answer> ret; 
qset.qs_handle = <token> <answer> tc_node->qs_handle; 
qset.tc <token> tc_node->traffic_class; <answer> = 
qset.vport_id = <token> <answer> vsi->vsi_idx; 
ret = <token> &qset); <answer> ice_add_rdma_qset(pf, 
if (ret) <token> <answer> { 
ibdev_dbg(&iwdev->ibdev, "WS: LAN alloc_res <token> rdma qset failed.\n"); <answer> for 
return <token> <answer> ret; 
<token> = qset.teid; <answer> tc_node->l2_sched_node_id 
vsi->qos[tc_node->user_pri].l2_sched_node_id <token> qset.teid; <answer> = 
<token> 0; <answer> return 
static void irdma_lan_unregister_qset(struct irdma_sc_vsi <token> <answer> *vsi, 
<token> irdma_ws_node *tc_node) <answer> struct 
struct <token> *iwdev = vsi->back_vsi; <answer> irdma_device 
struct ice_pf *pf = <token> <answer> iwdev->rf->cdev; 
struct iidc_rdma_qset_params qset = <token> <answer> {}; 
qset.qs_handle = <token> <answer> tc_node->qs_handle; 
qset.tc <token> tc_node->traffic_class; <answer> = 
<token> = vsi->vsi_idx; <answer> qset.vport_id 
<token> = tc_node->l2_sched_node_id; <answer> qset.teid 
if (ice_del_rdma_qset(pf, <token> <answer> &qset)) 
ibdev_dbg(&iwdev->ibdev, "WS: LAN free_res for rdma <token> failed.\n"); <answer> qset 
static void irdma_remove(struct <token> *aux_dev) <answer> auxiliary_device 
struct iidc_auxiliary_dev *iidc_adev = <token> <answer> container_of(aux_dev, 
struct <token> <answer> iidc_auxiliary_dev, 
struct ice_pf <token> = iidc_adev->pf; <answer> *pf 
struct irdma_device <token> = auxiliary_get_drvdata(aux_dev); <answer> *iwdev 
ice_rdma_update_vsi_filter(pf, iwdev->vsi_num, <token> <answer> false); 
pr_debug("INIT: Gen2 <token> device remove success\n", PCI_FUNC(pf->pdev->devfn)); <answer> PF[%d] 
static void <token> irdma_device *iwdev, struct ice_pf *pf, <answer> irdma_fill_device_info(struct 
struct ice_vsi <token> <answer> *vsi) 
struct irdma_pci_f *rf = <token> <answer> iwdev->rf; 
rf->cdev <token> pf; <answer> = 
rf->gen_ops.register_qset = <token> <answer> irdma_lan_register_qset; 
rf->gen_ops.unregister_qset = <token> <answer> irdma_lan_unregister_qset; 
rf->hw.hw_addr = <token> <answer> pf->hw.hw_addr; 
<token> = pf->pdev; <answer> rf->pcidev 
rf->msix_count = <token> <answer> pf->num_rdma_msix; 
<token> = pf->hw.pf_id; <answer> rf->pf_id 
rf->msix_entries <token> &pf->msix_entries[pf->rdma_base_vector]; <answer> = 
<token> = vsi->vsi_num; <answer> rf->default_vsi.vsi_idx 
rf->protocol_used = pf->rdma_mode & <token> ? <answer> IIDC_RDMA_PROTOCOL_ROCEV2 
<token> : IRDMA_IWARP_PROTOCOL_ONLY; <answer> IRDMA_ROCE_PROTOCOL_ONLY 
rf->rdma_ver = <token> <answer> IRDMA_GEN_2; 
rf->rsrc_profile <token> IRDMA_HMC_PROFILE_DEFAULT; <answer> = 
rf->rst_to <token> IRDMA_RST_TIMEOUT_HZ; <answer> = 
rf->gen_ops.request_reset = <token> <answer> irdma_request_reset; 
rf->limits_sel <token> 7; <answer> = 
rf->iwdev = <token> <answer> iwdev; 
iwdev->netdev = <token> <answer> vsi->netdev; 
iwdev->vsi_num <token> vsi->vsi_num; <answer> = 
<token> = INITIAL_STATE; <answer> iwdev->init_state 
iwdev->roce_cwnd = <token> <answer> IRDMA_ROCE_CWND_DEFAULT; 
iwdev->roce_ackcreds = <token> <answer> IRDMA_ROCE_ACKCREDS_DEFAULT; 
<token> = IRDMA_CM_DEFAULT_RCV_WND_SCALED; <answer> iwdev->rcv_wnd 
iwdev->rcv_wscale <token> IRDMA_CM_DEFAULT_RCV_WND_SCALE; <answer> = 
if (rf->protocol_used == <token> <answer> IRDMA_ROCE_PROTOCOL_ONLY) 
<token> = true; <answer> iwdev->roce_mode 
static <token> irdma_probe(struct auxiliary_device *aux_dev, const struct auxiliary_device_id *id) <answer> int 
struct <token> *iidc_adev = container_of(aux_dev, <answer> iidc_auxiliary_dev 
struct <token> <answer> iidc_auxiliary_dev, 
struct <token> *pf = iidc_adev->pf; <answer> ice_pf 
struct <token> *vsi = ice_get_main_vsi(pf); <answer> ice_vsi 
struct iidc_qos_params qos_info <token> {}; <answer> = 
<token> irdma_device *iwdev; <answer> struct 
<token> irdma_pci_f *rf; <answer> struct 
<token> irdma_l2params l2params = {}; <answer> struct 
int <token> <answer> err; 
if <token> <answer> (!vsi) 
<token> -EIO; <answer> return 
iwdev = <token> ibdev); <answer> ib_alloc_device(irdma_device, 
if <token> <answer> (!iwdev) 
<token> -ENOMEM; <answer> return 
iwdev->rf = kzalloc(sizeof(*rf), <token> <answer> GFP_KERNEL); 
if <token> { <answer> (!iwdev->rf) 
<token> -ENOMEM; <answer> return 
irdma_fill_device_info(iwdev, pf, <token> <answer> vsi); 
<token> = iwdev->rf; <answer> rf 
err = <token> <answer> irdma_ctrl_init_hw(rf); 
<token> (err) <answer> if 
goto <token> <answer> err_ctrl_init; 
l2params.mtu <token> iwdev->netdev->mtu; <answer> = 
ice_get_qos_params(pf, <token> <answer> &qos_info); 
irdma_fill_qos_info(&l2params, <token> <answer> &qos_info); 
if <token> != IRDMA_IWARP_PROTOCOL_ONLY) <answer> (iwdev->rf->protocol_used 
iwdev->dcb_vlan_mode <token> l2params.num_tc > 1 && !l2params.dscp_mode; <answer> = 
err <token> irdma_rt_init_hw(iwdev, &l2params); <answer> = 
if <token> <answer> (err) 
<token> err_rt_init; <answer> goto 
err <token> irdma_ib_register_device(iwdev); <answer> = 
<token> (err) <answer> if 
goto <token> <answer> err_ibreg; 
ice_rdma_update_vsi_filter(pf, iwdev->vsi_num, <token> <answer> true); 
ibdev_dbg(&iwdev->ibdev, "INIT: Gen2 PF[%d] device probe <token> PCI_FUNC(rf->pcidev->devfn)); <answer> success\n", 
auxiliary_set_drvdata(aux_dev, <token> <answer> iwdev); 
return <token> <answer> 0; 
<token> err; <answer> return 
<token> const struct auxiliary_device_id irdma_auxiliary_id_table[] = { <answer> static 
{.name = "ice.iwarp", <token> <answer> }, 
{.name = "ice.roce", <token> <answer> }, 
<token> irdma_auxiliary_id_table); <answer> MODULE_DEVICE_TABLE(auxiliary, 
<token> struct iidc_auxiliary_drv irdma_auxiliary_drv = { <answer> static 
.adrv = <token> <answer> { 
.id_table = <token> <answer> irdma_auxiliary_id_table, 
.probe <token> irdma_probe, <answer> = 
.remove = <token> <answer> irdma_remove, 
.event_handler <token> irdma_iidc_event_handler, <answer> = 
static int <token> irdma_init_module(void) <answer> __init 
int <token> <answer> ret; 
ret <token> auxiliary_driver_register(&i40iw_auxiliary_drv); <answer> = 
if (ret) <token> <answer> { 
pr_err("Failed <token> auxiliary_driver_register() ret=%d\n", <answer> i40iw(gen_1) 
return <token> <answer> ret; 
ret = <token> <answer> auxiliary_driver_register(&irdma_auxiliary_drv.adrv); 
<token> (ret) { <answer> if 
pr_err("Failed irdma auxiliary_driver_register() <token> <answer> ret=%d\n", 
return <token> <answer> ret; 
return <token> <answer> 0; 
<token> void __exit irdma_exit_module(void) <answer> static 
#define pr_fmt(fmt) KBUILD_MODNAME ": <token> fmt <answer> " 
<token> <linux/firmware.h> <answer> #include 
#include <token> <answer> <linux/greybus.h> 
#include <token> <answer> "firmware.h" 
<token> "spilib.h" <answer> #include 
struct gb_fw_core <token> <answer> { 
struct <token> *download_connection; <answer> gb_connection 
struct <token> *mgmt_connection; <answer> gb_connection 
struct <token> *spi_connection; <answer> gb_connection 
<token> gb_connection *cap_connection; <answer> struct 
<token> struct spilib_ops *spilib_ops; <answer> static 
struct gb_connection *to_fw_mgmt_connection(struct device <token> <answer> *dev) 
struct gb_fw_core *fw_core <token> dev_get_drvdata(dev); <answer> = 
<token> fw_core->mgmt_connection; <answer> return 
static int <token> gb_connection *connection) <answer> gb_fw_spi_connection_init(struct 
int <token> <answer> ret; 
if <token> <answer> (!connection) 
return <token> <answer> 0; 
ret <token> gb_connection_enable(connection); <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
ret = <token> &connection->bundle->dev, <answer> gb_spilib_master_init(connection, 
if (ret) <token> <answer> { 
return <token> <answer> ret; 
<token> 0; <answer> return 
static void <token> gb_connection *connection) <answer> gb_fw_spi_connection_exit(struct 
<token> (!connection) <answer> if 
<token> int gb_fw_core_probe(struct gb_bundle *bundle, <answer> static 
const struct greybus_bundle_id <token> <answer> *id) 
struct <token> *cport_desc; <answer> greybus_descriptor_cport 
struct <token> *connection; <answer> gb_connection 
struct gb_fw_core <token> <answer> *fw_core; 
int <token> i; <answer> ret, 
<token> cport_id; <answer> u16 
<token> protocol_id; <answer> u8 
fw_core = kzalloc(sizeof(*fw_core), <token> <answer> GFP_KERNEL); 
<token> (!fw_core) <answer> if 
return <token> <answer> -ENOMEM; 
<token> <linux/module.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <uapi/linux/mdio.h> 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> "../vfio_platform_private.h" 
#define <token> 0x3000 <answer> DMA_MR 
#define <token> 0x0110 <answer> MAC_VR 
#define <token> 0x3008 <answer> DMA_ISR 
#define MAC_ISR <token> <answer> 0x00b0 
#define PCS_MMD_SELECT <token> <answer> 0xff 
<token> MDIO_AN_INT 0x8002 <answer> #define 
#define MDIO_AN_INTMASK <token> <answer> 0x8001 
static <token> int xmdio_read(void __iomem *ioaddr, unsigned int mmd, <answer> unsigned 
unsigned int <token> <answer> reg) 
<token> int mmd_address, value; <answer> unsigned 
mmd_address <token> (mmd << 16) | ((reg) & 0xffff); <answer> = 
<token> >> 8, ioaddr + (PCS_MMD_SELECT << 2)); <answer> iowrite32(mmd_address 
value = ioread32(ioaddr + ((mmd_address & 0xff) << <token> <answer> 2)); 
<token> value; <answer> return 
<token> void xmdio_write(void __iomem *ioaddr, unsigned int mmd, <answer> static 
unsigned int <token> unsigned int value) <answer> reg, 
<token> int mmd_address; <answer> unsigned 
mmd_address = (mmd << <token> | ((reg) & 0xffff); <answer> 16) 
iowrite32(mmd_address >> 8, ioaddr + <token> << 2)); <answer> (PCS_MMD_SELECT 
iowrite32(value, ioaddr + ((mmd_address & <token> << 2)); <answer> 0xff) 
static int <token> vfio_platform_device *vdev) <answer> vfio_platform_amdxgbe_reset(struct 
struct <token> *xgmac_regs = &vdev->regions[0]; <answer> vfio_platform_region 
<token> vfio_platform_region *xpcs_regs = &vdev->regions[1]; <answer> struct 
u32 dma_mr_value, <token> value; <answer> pcs_value, 
<token> int count; <answer> unsigned 
if <token> { <answer> (!xgmac_regs->ioaddr) 
xgmac_regs->ioaddr <token> <answer> = 
ioremap(xgmac_regs->addr, <token> <answer> xgmac_regs->size); 
<token> (!xgmac_regs->ioaddr) <answer> if 
return <token> <answer> -ENOMEM; 
if <token> { <answer> (!xpcs_regs->ioaddr) 
<token> = <answer> xpcs_regs->ioaddr 
ioremap(xpcs_regs->addr, <token> <answer> xpcs_regs->size); 
if <token> <answer> (!xpcs_regs->ioaddr) 
<token> -ENOMEM; <answer> return 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/gpio/driver.h> 
<token> <linux/irq.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <mach/fpga.h> 
<token> NR_FPGA_GPIOS 8 <answer> #define 
static const char *usrgpir_gpio_names[NR_FPGA_GPIOS] <token> { <answer> = 
"in0", "in1", "in2", "in3", "in4", <token> "in6", "in7", <answer> "in5", 
static int usrgpir_gpio_direction_input(struct <token> *chip, unsigned gpio) <answer> gpio_chip 
#include <token> <answer> <linux/suspend.h> 
<token> <linux/clk.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/err.h> 
<token> <linux/export.h> <answer> #include 
<token> <linux/genalloc.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_address.h> 
#include <token> <answer> <linux/of_platform.h> 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <asm/cacheflush.h> 
<token> <asm/fncpy.h> <answer> #include 
<token> <asm/system_misc.h> <answer> #include 
#include <token> <answer> <asm/tlbflush.h> 
<token> "common.h" <answer> #include 
#include <token> <answer> "cpuidle.h" 
#include <token> <answer> "hardware.h" 
#define MXC_CCM_CLPCR <token> <answer> 0x54 
#define MXC_CCM_CLPCR_LPM_OFFSET <token> <answer> 0 
#define <token> 0x3 <answer> MXC_CCM_CLPCR_LPM_MASK 
#define MXC_CCM_CLPCR_STBY_COUNT_OFFSET <token> <answer> 9 
<token> MXC_CCM_CLPCR_VSTBY (0x1 << 8) <answer> #define 
<token> MXC_CCM_CLPCR_SBYOS (0x1 << 6) <answer> #define 
#define MXC_CORTEXA8_PLAT_LPC <token> <answer> 0xc 
#define MXC_CORTEXA8_PLAT_LPC_DSM <token> << 0) <answer> (1 
#define MXC_CORTEXA8_PLAT_LPC_DBG_DSM (1 << <token> <answer> 1) 
#define <token> 0x280 <answer> MXC_SRPG_NEON_SRPGCR 
<token> MXC_SRPG_ARM_SRPGCR 0x2a0 <answer> #define 
#define MXC_SRPG_EMPGC0_SRPGCR <token> <answer> 0x2c0 
#define MXC_SRPG_EMPGC1_SRPGCR <token> <answer> 0x2d0 
#define MXC_SRPGCR_PCR <token> <answer> 1 
<token> IMX5_DEFAULT_CPU_IDLE_STATE WAIT_UNCLOCKED_POWER_OFF <answer> #define 
struct <token> { <answer> imx5_suspend_io_state 
u32 <token> <answer> offset; 
<token> clear; <answer> u32 
u32 <token> <answer> set; 
u32 <token> <answer> saved_value; 
struct <token> { <answer> imx5_pm_data 
phys_addr_t <token> <answer> ccm_addr; 
phys_addr_t <token> <answer> cortex_addr; 
phys_addr_t <token> <answer> gpc_addr; 
<token> m4if_addr; <answer> phys_addr_t 
phys_addr_t <token> <answer> iomuxc_addr; 
<token> (*suspend_asm)(void __iomem *ocram_vbase); <answer> void 
<token> u32 *suspend_asm_sz; <answer> const 
<token> struct imx5_suspend_io_state *suspend_io_config; <answer> const 
<token> suspend_io_count; <answer> int 
static const struct <token> imx53_suspend_io_config[] = { <answer> imx5_suspend_io_state 
#define MX53_DSE_HIGHZ_MASK (0x7 <token> 19) <answer> << 
struct imx5_cpu_suspend_info <token> <answer> { 
<token> __iomem *m4if_base; <answer> void 
void __iomem <token> <answer> *iomuxc_base; 
<token> io_count; <answer> u32 
<token> imx5_suspend_io_state io_state[MX5_MAX_SUSPEND_IOSTATE]; <answer> struct 
} <token> <answer> __aligned(8); 
static void __iomem <token> <answer> *ccm_base; 
static void <token> *cortex_base; <answer> __iomem 
<token> void __iomem *gpc_base; <answer> static 
<token> void __iomem *suspend_ocram_base; <answer> static 
static void (*imx5_suspend_in_ocram_fn)(void __iomem <token> <answer> *ocram_vbase); 
<token> void mx5_cpu_lp_set(enum mxc_cpu_pwr_mode mode) <answer> static 
u32 plat_lpc, <token> ccm_clpcr; <answer> arm_srpgcr, 
u32 <token> empgc1; <answer> empgc0, 
int stop_mode = <token> <answer> 0; 
<token> <linux/module.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/serio.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
<token> "nvec.h" <answer> #include 
#define PACKET_SIZE <token> <answer> 6 
<token> ENABLE_MOUSE 0xf4 <answer> #define 
#define DISABLE_MOUSE <token> <answer> 0xf5 
#define PSMOUSE_RST <token> <answer> 0xff 
<token> NVEC_PS2_DEBUG <answer> #ifdef 
#define NVEC_PHD(str, buf, <token> \ <answer> len) 
<token> str, DUMP_PREFIX_NONE, \ <answer> print_hex_dump(KERN_DEBUG, 
16, 1, <token> len, false) <answer> buf, 
#define <token> buf, len) do { } while (0) <answer> NVEC_PHD(str, 
enum ps2_subcmds <token> <answer> { 
SEND_COMMAND = <token> <answer> 1, 
struct nvec_ps2 <token> <answer> { 
<token> serio *ser_dev; <answer> struct 
<token> notifier_block notifier; <answer> struct 
struct <token> *nvec; <answer> nvec_chip 
static struct nvec_ps2 <token> <answer> ps2_dev; 
static int ps2_startstreaming(struct <token> *ser_dev) <answer> serio 
<token> char buf[] = { NVEC_PS2, AUTO_RECEIVE_N, PACKET_SIZE }; <answer> unsigned 
return <token> buf, sizeof(buf)); <answer> nvec_write_async(ps2_dev.nvec, 
static void ps2_stopstreaming(struct <token> *ser_dev) <answer> serio 
<token> char buf[] = { NVEC_PS2, CANCEL_AUTO_RECEIVE }; <answer> unsigned 
nvec_write_async(ps2_dev.nvec, buf, <token> <answer> sizeof(buf)); 
<token> int ps2_sendcommand(struct serio *ser_dev, unsigned char cmd) <answer> static 
unsigned char buf[] = { NVEC_PS2, SEND_COMMAND, ENABLE_MOUSE, <token> }; <answer> 1 
buf[2] <token> cmd & 0xff; <answer> = 
dev_dbg(&ser_dev->dev, <token> ps2 cmd %02x\n", cmd); <answer> "Sending 
<token> nvec_write_async(ps2_dev.nvec, buf, sizeof(buf)); <answer> return 
static int nvec_ps2_notifier(struct <token> *nb, <answer> notifier_block 
unsigned long event_type, <token> *data) <answer> void 
<token> i; <answer> int 
<token> char *msg = data; <answer> unsigned 
switch (event_type) <token> <answer> { 
case <token> <answer> NVEC_PS2_EVT: 
for (i = 0; i <token> msg[1]; i++) <answer> < 
serio_interrupt(ps2_dev.ser_dev, <token> + i], 0); <answer> msg[2 
NVEC_PHD("ps/2 <token> event: ", &msg[2], msg[1]); <answer> mouse 
return <token> <answer> NOTIFY_STOP; 
case <token> <answer> NVEC_PS2: 
if (msg[2] <token> 1) { <answer> == 
for (i = 0; i < (msg[1] - 2); <token> <answer> i++) 
serio_interrupt(ps2_dev.ser_dev, msg[i + <token> 0); <answer> 4], 
NVEC_PHD("ps/2 mouse reply: ", <token> msg[1] - 2); <answer> &msg[4], 
<token> <keys/asymmetric-type.h> <answer> #include 
<token> <linux/user_namespace.h> <answer> #include 
<token> <linux/ima.h> <answer> #include 
<token> "ima.h" <answer> #include 
void ima_post_key_create_or_update(struct key *keyring, struct <token> *key, <answer> key 
<token> void *payload, size_t payload_len, <answer> const 
unsigned long flags, bool <token> <answer> create) 
bool <token> = false; <answer> queued 
process_buffer_measurement(&nop_mnt_idmap, <token> payload, payload_len, <answer> NULL, 
keyring->description, KEY_CHECK, <token> <answer> 0, 
<token> false, NULL, 0); <answer> keyring->description, 
#define <token> KBUILD_MODNAME ": " fmt <answer> pr_fmt(fmt) 
<token> <linux/net.h> <answer> #include 
#include <token> <answer> <linux/nls.h> 
<token> <linux/connector.h> <answer> #include 
<token> <linux/workqueue.h> <answer> #include 
#include <token> <answer> <linux/hyperv.h> 
#include <token> <answer> <asm/hyperv-tlfs.h> 
#include <token> <answer> "hyperv_vmbus.h" 
#include <token> <answer> "hv_utils_transport.h" 
#define <token> 1 <answer> WS2008_SRV_MAJOR 
<token> WS2008_SRV_MINOR 0 <answer> #define 
#define WS2008_SRV_VERSION <token> << 16 | WS2008_SRV_MINOR) <answer> (WS2008_SRV_MAJOR 
#define WIN7_SRV_MAJOR <token> <answer> 3 
#define <token> 0 <answer> WIN7_SRV_MINOR 
<token> WIN7_SRV_VERSION (WIN7_SRV_MAJOR << 16 | WIN7_SRV_MINOR) <answer> #define 
<token> WIN8_SRV_MAJOR 4 <answer> #define 
<token> WIN8_SRV_MINOR 0 <answer> #define 
#define WIN8_SRV_VERSION (WIN8_SRV_MAJOR <token> 16 | WIN8_SRV_MINOR) <answer> << 
#define KVP_VER_COUNT <token> <answer> 3 
static <token> int kvp_versions[] = { <answer> const 
<token> FW_VER_COUNT 2 <answer> #define 
<token> const int fw_versions[] = { <answer> static 
<token> struct { <answer> static 
static <token> dm_reg_value; <answer> int 
static <token> kvp_send_key(struct work_struct *dummy); <answer> void 
static <token> kvp_respond_to_host(struct hv_kvp_msg *msg, int error); <answer> void 
<token> void kvp_timeout_func(struct work_struct *dummy); <answer> static 
<token> void kvp_host_handshake_func(struct work_struct *dummy); <answer> static 
static <token> kvp_register(int); <answer> void 
<token> DECLARE_DELAYED_WORK(kvp_timeout_work, kvp_timeout_func); <answer> static 
static <token> kvp_host_handshake_func); <answer> DECLARE_DELAYED_WORK(kvp_host_handshake_work, 
static DECLARE_WORK(kvp_sendkey_work, <token> <answer> kvp_send_key); 
static const char kvp_devname[] = <token> <answer> "vmbus/hv_kvp"; 
<token> u8 *recv_buffer; <answer> static 
static <token> hvutil_transport *hvt; <answer> struct 
#define <token> "3.1" <answer> HV_DRV_VERSION 
static <token> kvp_poll_wrapper(void *channel) <answer> void 
pr_debug("KVP: userspace <token> registered\n"); <answer> daemon 
<token> kvp_poll_wrapper); <answer> hv_poll_channel(kvp_transaction.recv_channel, 
static <token> <answer> void 
kvp_register(int <token> <answer> reg_value) 
<token> hv_kvp_msg *kvp_msg; <answer> struct 
<token> *version; <answer> char 
kvp_msg <token> kzalloc(sizeof(*kvp_msg), GFP_KERNEL); <answer> = 
if (kvp_msg) <token> <answer> { 
<token> = kvp_msg->body.kvp_register.version; <answer> version 
kvp_msg->kvp_hdr.operation <token> reg_value; <answer> = 
strcpy(version, <token> <answer> HV_DRV_VERSION); 
hvutil_transport_send(hvt, kvp_msg, <token> <answer> sizeof(*kvp_msg), 
static <token> kvp_timeout_func(struct work_struct *dummy) <answer> void 
kvp_respond_to_host(NULL, <token> <answer> HV_E_FAIL); 
hv_poll_channel(kvp_transaction.recv_channel, <token> <answer> kvp_poll_wrapper); 
static void <token> work_struct *dummy) <answer> kvp_host_handshake_func(struct 
static int kvp_handle_handshake(struct <token> *msg) <answer> hv_kvp_msg 
<token> (msg->kvp_hdr.operation) { <answer> switch 
case <token> <answer> KVP_OP_REGISTER: 
<token> = KVP_OP_REGISTER; <answer> dm_reg_value 
pr_info("KVP: IP injection functionality <token> available\n"); <answer> not 
pr_info("KVP: <token> the KVP daemon\n"); <answer> Upgrade 
<token> KVP_OP_REGISTER1: <answer> case 
dm_reg_value = <token> <answer> KVP_OP_REGISTER1; 
<token> incompatible daemon\n"); <answer> pr_info("KVP: 
<token> KVP version: %d, Daemon version: %d\n", <answer> pr_info("KVP: 
KVP_OP_REGISTER1, <token> <answer> msg->kvp_hdr.operation); 
<token> -EINVAL; <answer> return 
pr_debug("KVP: userspace <token> ver. %d connected\n", <answer> daemon 
return <token> <answer> 0; 
static int kvp_on_msg(void *msg, <token> len) <answer> int 
struct hv_kvp_msg *message = (struct hv_kvp_msg <token> <answer> *)msg; 
struct hv_kvp_msg_enumerate <token> <answer> *data; 
int <token> = 0; <answer> error 
if <token> < sizeof(*message)) <answer> (len 
<token> -EINVAL; <answer> return 
<token> (kvp_transaction.state < HVUTIL_READY) { <answer> if 
<token> kvp_handle_handshake(message); <answer> return 
<token> = &message->body.kvp_enum_data; <answer> data 
switch (dm_reg_value) <token> <answer> { 
<token> KVP_OP_REGISTER: <answer> case 
if (data->data.key[0] == <token> <answer> 0) 
error = <token> <answer> HV_S_CONT; 
<token> KVP_OP_REGISTER1: <answer> case 
error = <token> <answer> message->error; 
<token> (cancel_delayed_work_sync(&kvp_timeout_work)) { <answer> if 
kvp_respond_to_host(message, <token> <answer> error); 
<token> kvp_poll_wrapper); <answer> hv_poll_channel(kvp_transaction.recv_channel, 
<token> 0; <answer> return 
static <token> process_ob_ipinfo(void *in_msg, void *out_msg, int op) <answer> int 
<token> hv_kvp_msg *in = in_msg; <answer> struct 
struct hv_kvp_ip_msg *out <token> out_msg; <answer> = 
<token> len; <answer> int 
switch <token> { <answer> (op) 
<token> KVP_OP_GET_IP_INFO: <answer> case 
len = <token> *)in->body.kvp_ip_val.ip_addr, <answer> utf8s_to_utf16s((char 
<token> *)in->body.kvp_ip_val.ip_addr), <answer> strlen((char 
<token> *)out->kvp_ip_val.ip_addr, <answer> (wchar_t 
<token> (len < 0) <answer> if 
<token> len; <answer> return 
len <token> utf8s_to_utf16s((char *)in->body.kvp_ip_val.sub_net, <answer> = 
strlen((char <token> <answer> *)in->body.kvp_ip_val.sub_net), 
(wchar_t <token> <answer> *)out->kvp_ip_val.sub_net, 
if <token> < 0) <answer> (len 
return <token> <answer> len; 
<token> = utf8s_to_utf16s((char *)in->body.kvp_ip_val.gate_way, <answer> len 
<token> *)in->body.kvp_ip_val.gate_way), <answer> strlen((char 
(wchar_t <token> <answer> *)out->kvp_ip_val.gate_way, 
<token> (len < 0) <answer> if 
return <token> <answer> len; 
<token> = utf8s_to_utf16s((char *)in->body.kvp_ip_val.dns_addr, <answer> len 
<token> *)in->body.kvp_ip_val.dns_addr), <answer> strlen((char 
<token> *)out->kvp_ip_val.dns_addr, <answer> (wchar_t 
if (len <token> 0) <answer> < 
<token> len; <answer> return 
len = <token> *)in->body.kvp_ip_val.adapter_id, <answer> utf8s_to_utf16s((char 
<token> *)in->body.kvp_ip_val.adapter_id), <answer> strlen((char 
(wchar_t <token> <answer> *)out->kvp_ip_val.adapter_id, 
if (len <token> 0) <answer> < 
<token> len; <answer> return 
<token> = <answer> out->kvp_ip_val.dhcp_enabled 
<token> = <answer> out->kvp_ip_val.addr_family 
<token> 0; <answer> return 
static void process_ib_ipinfo(void *in_msg, <token> *out_msg, int op) <answer> void 
struct <token> *in = in_msg; <answer> hv_kvp_ip_msg 
struct hv_kvp_msg <token> = out_msg; <answer> *out 
switch (op) <token> <answer> { 
<token> KVP_OP_SET_IP_INFO: <answer> case 
<token> *)in->kvp_ip_val.ip_addr, <answer> utf16s_to_utf8s((wchar_t 
<token> *)out->body.kvp_ip_val.ip_addr, <answer> (__u8 
utf16s_to_utf8s((wchar_t <token> <answer> *)in->kvp_ip_val.sub_net, 
(__u8 <token> <answer> *)out->body.kvp_ip_val.sub_net, 
utf16s_to_utf8s((wchar_t <token> <answer> *)in->kvp_ip_val.gate_way, 
(__u8 <token> <answer> *)out->body.kvp_ip_val.gate_way, 
<token> *)in->kvp_ip_val.dns_addr, <answer> utf16s_to_utf8s((wchar_t 
<token> *)out->body.kvp_ip_val.dns_addr, <answer> (__u8 
<token> = in->kvp_ip_val.dhcp_enabled; <answer> out->body.kvp_ip_val.dhcp_enabled 
<token> KVP_OP_GET_IP_INFO: <answer> case 
<token> *)in->kvp_ip_val.adapter_id, <answer> utf16s_to_utf8s((wchar_t 
(__u8 <token> <answer> *)out->body.kvp_ip_val.adapter_id, 
out->body.kvp_ip_val.addr_family <token> in->kvp_ip_val.addr_family; <answer> = 
<token> void <answer> static 
<token> work_struct *dummy) <answer> kvp_send_key(struct 
struct hv_kvp_msg <token> <answer> *message; 
struct hv_kvp_msg <token> <answer> *in_msg; 
__u8 <token> = kvp_transaction.kvp_msg->kvp_hdr.operation; <answer> operation 
__u8 pool <token> kvp_transaction.kvp_msg->kvp_hdr.pool; <answer> = 
__u32 <token> <answer> val32; 
<token> val64; <answer> __u64 
<token> rc; <answer> int 
<token> (message->kvp_hdr.operation) { <answer> switch 
case <token> <answer> KVP_OP_SET_IP_INFO: 
process_ib_ipinfo(in_msg, message, <token> <answer> KVP_OP_SET_IP_INFO); 
<token> KVP_OP_GET_IP_INFO: <answer> case 
<token> message, KVP_OP_GET_IP_INFO); <answer> process_ib_ipinfo(in_msg, 
<token> KVP_OP_SET: <answer> case 
switch <token> { <answer> (in_msg->body.kvp_set.data.value_type) 
case <token> <answer> REG_SZ: 
message->body.kvp_set.data.value_size <token> <answer> = 
<token> *)in_msg->body.kvp_set.data.value, <answer> (wchar_t 
HV_KVP_EXCHANGE_MAX_VALUE_SIZE <token> 1) + 1; <answer> - 
case <token> <answer> REG_U32: 
val32 = <token> <answer> in_msg->body.kvp_set.data.value_u32; 
<token> = <answer> message->body.kvp_set.data.value_size 
<token> val32) + 1; <answer> "%u", 
case <token> <answer> REG_U64: 
val64 = <token> <answer> in_msg->body.kvp_set.data.value_u64; 
message->body.kvp_set.data.value_size <token> <answer> = 
"%llu", <token> + 1; <answer> val64) 
<token> = <answer> message->body.kvp_set.data.key_size 
<token> *)in_msg->body.kvp_set.data.key, <answer> (wchar_t 
<token> - 1) + 1; <answer> HV_KVP_EXCHANGE_MAX_KEY_SIZE 
<token> KVP_OP_GET: <answer> case 
message->body.kvp_get.data.key_size <token> <answer> = 
(wchar_t <token> <answer> *)in_msg->body.kvp_get.data.key, 
HV_KVP_EXCHANGE_MAX_KEY_SIZE - 1) + <token> <answer> 1; 
case <token> <answer> KVP_OP_DELETE: 
<token> = <answer> message->body.kvp_delete.key_size 
(wchar_t <token> <answer> *)in_msg->body.kvp_delete.key, 
HV_KVP_EXCHANGE_MAX_KEY_SIZE - 1) + <token> <answer> 1; 
<token> KVP_OP_ENUMERATE: <answer> case 
message->body.kvp_enum_data.index <token> <answer> = 
kvp_transaction.state = <token> <answer> HVUTIL_USERSPACE_REQ; 
rc <token> hvutil_transport_send(hvt, message, sizeof(*message), NULL); <answer> = 
if <token> { <answer> (rc) 
pr_debug("KVP: failed <token> communicate to the daemon: %d\n", rc); <answer> to 
<token> (cancel_delayed_work_sync(&kvp_timeout_work)) { <answer> if 
kvp_respond_to_host(message, <token> <answer> HV_E_FAIL); 
kvp_transaction.state = <token> <answer> HVUTIL_READY; 
static <token> <answer> void 
kvp_respond_to_host(struct <token> *msg_to_host, int error) <answer> hv_kvp_msg 
struct <token> *kvp_msg; <answer> hv_kvp_msg 
struct hv_kvp_exchg_msg_value <token> <answer> *kvp_data; 
<token> *key_name; <answer> char 
<token> *value; <answer> char 
<token> icmsg_hdr *icmsghdrp; <answer> struct 
int keylen = <token> <answer> 0; 
int <token> = 0; <answer> valuelen 
u32 <token> <answer> buf_len; 
struct <token> *channel; <answer> vmbus_channel 
<token> req_id; <answer> u64 
<token> ret; <answer> int 
buf_len <token> kvp_transaction.recv_len; <answer> = 
channel = <token> <answer> kvp_transaction.recv_channel; 
req_id <token> kvp_transaction.recv_req_id; <answer> = 
icmsghdrp = <token> icmsg_hdr *) <answer> (struct 
<token> vmbuspipe_hdr)]; <answer> &recv_buffer[sizeof(struct 
if (channel->onchannel_callback <token> NULL) <answer> == 
icmsghdrp->status <token> error; <answer> = 
if (error) <token> <answer> { 
goto <token> <answer> response_done; 
<token> = (struct hv_kvp_msg *) <answer> kvp_msg 
&recv_buffer[sizeof(struct vmbuspipe_hdr) <token> <answer> + 
sizeof(struct <token> <answer> icmsg_hdr)]; 
<token> (kvp_transaction.kvp_msg->kvp_hdr.operation) { <answer> switch 
<token> KVP_OP_GET_IP_INFO: <answer> case 
ret <token> process_ob_ipinfo(msg_to_host, <answer> = 
<token> hv_kvp_ip_msg *)kvp_msg, <answer> (struct 
if <token> < 0) <answer> (ret 
icmsghdrp->status = <token> <answer> HV_E_FAIL; 
<token> response_done; <answer> goto 
case <token> <answer> KVP_OP_SET_IP_INFO: 
goto <token> <answer> response_done; 
case <token> <answer> KVP_OP_GET: 
kvp_data = <token> <answer> &kvp_msg->body.kvp_get.data; 
<token> copy_value; <answer> goto 
case <token> <answer> KVP_OP_SET: 
<token> KVP_OP_DELETE: <answer> case 
<token> response_done; <answer> goto 
kvp_data <token> &kvp_msg->body.kvp_enum_data.data; <answer> = 
<token> = msg_to_host->body.kvp_enum_data.data.key; <answer> key_name 
<token> = utf8s_to_utf16s(key_name, strlen(key_name), UTF16_HOST_ENDIAN, <answer> keylen 
(wchar_t <token> kvp_data->key, <answer> *) 
(HV_KVP_EXCHANGE_MAX_KEY_SIZE <token> 2) - 2); <answer> / 
if ((keylen < 0) || (valuelen <token> 0)) <answer> < 
<token> = HV_E_FAIL; <answer> icmsghdrp->status 
<token> hv_kvp_onchannelcallback(void *context) <answer> void 
struct vmbus_channel <token> = context; <answer> *channel 
<token> recvlen; <answer> u32 
u64 <token> <answer> requestid; 
<token> hv_kvp_msg *kvp_msg; <answer> struct 
struct icmsg_hdr <token> <answer> *icmsghdrp; 
<token> kvp_srv_version; <answer> int 
static <token> {NEGO_NOT_STARTED, <answer> enum 
NEGO_FINISHED} <token> = NEGO_NOT_STARTED; <answer> host_negotiatied 
if <token> < HVUTIL_READY) { <answer> (kvp_transaction.state 
<token> (host_negotiatied == NEGO_NOT_STARTED) { <answer> if 
host_negotiatied = <token> <answer> NEGO_IN_PROGRESS; 
<token> * HZ); <answer> HV_UTIL_NEGO_TIMEOUT 
if <token> > HVUTIL_READY) <answer> (kvp_transaction.state 
if (vmbus_recvpacket(channel, <token> HV_HYP_PAGE_SIZE * 4, &recvlen, &requestid)) { <answer> recv_buffer, 
pr_err_ratelimited("KVP request received. <token> not read into recv buf\n"); <answer> Could 
if <token> <answer> (!recvlen) 
kvp_msg = (struct <token> *)&recv_buffer[ICMSG_HDR]; <answer> hv_kvp_msg 
kvp_transaction.recv_len <token> recvlen; <answer> = 
<token> = requestid; <answer> kvp_transaction.recv_req_id 
<token> = kvp_msg; <answer> kvp_transaction.kvp_msg 
if (kvp_transaction.state < HVUTIL_READY) <token> <answer> { 
HV_UTIL_TIMEOUT <token> HZ); <answer> * 
<token> else { <answer> } 
pr_err_ratelimited("KVP request received. Invalid msg <token> %d\n", <answer> type: 
<token> = ICMSGHDRFLAG_TRANSACTION <answer> icmsghdrp->icflags 
| <token> <answer> ICMSGHDRFLAG_RESPONSE; 
<token> recv_buffer, <answer> vmbus_sendpacket(channel, 
recvlen, <token> <answer> requestid, 
<token> 0); <answer> VM_PKT_DATA_INBAND, 
host_negotiatied = <token> <answer> NEGO_FINISHED; 
<token> kvp_poll_wrapper); <answer> hv_poll_channel(kvp_transaction.recv_channel, 
<token> void kvp_on_reset(void) <answer> static 
<token> (cancel_delayed_work_sync(&kvp_timeout_work)) <answer> if 
kvp_respond_to_host(NULL, <token> <answer> HV_E_FAIL); 
kvp_transaction.state <token> HVUTIL_DEVICE_INIT; <answer> = 
hv_kvp_init(struct <token> *srv) <answer> hv_util_service 
recv_buffer = <token> <answer> srv->recv_buffer; 
<token> = srv->channel; <answer> kvp_transaction.recv_channel 
kvp_transaction.recv_channel->max_pkt_size = <token> * 4; <answer> HV_HYP_PAGE_SIZE 
<token> = HVUTIL_DEVICE_INIT; <answer> kvp_transaction.state 
hvt = hvutil_transport_init(kvp_devname, <token> CN_KVP_VAL, <answer> CN_KVP_IDX, 
kvp_on_msg, <token> <answer> kvp_on_reset); 
<token> (!hvt) <answer> if 
<token> -EFAULT; <answer> return 
<token> 0; <answer> return 
static <token> hv_kvp_cancel_work(void) <answer> void 
<token> hv_kvp_pre_suspend(void) <answer> int 
struct vmbus_channel <token> = kvp_transaction.recv_channel; <answer> *channel 
kvp_transaction.state = <token> <answer> HVUTIL_READY; 
return <token> <answer> 0; 
<token> hv_kvp_pre_resume(void) <answer> int 
struct vmbus_channel *channel = <token> <answer> kvp_transaction.recv_channel; 
return <token> <answer> 0; 
<token> hv_kvp_deinit(void) <answer> void 
kvp_transaction.state = <token> <answer> HVUTIL_DEVICE_DYING; 
#include <token> <answer> <linux/pm_runtime.h> 
#include <token> <answer> <linux/iio/common/inv_sensors_timestamp.h> 
#include <token> <answer> "inv_mpu_iio.h" 
<token> unsigned int inv_scan_query_mpu6050(struct iio_dev *indio_dev) <answer> static 
struct inv_mpu6050_state *st <token> iio_priv(indio_dev); <answer> = 
<token> int mask; <answer> unsigned 
<token> (!indio_dev->active_scan_mask) { <answer> if 
<token> = true; <answer> st->chip_config.temp_fifo_enable 
return <token> <answer> INV_MPU6050_SENSOR_TEMP; 
<token> = <answer> st->chip_config.gyro_fifo_enable 
indio_dev->active_scan_mask) <token> <answer> || 
<token> || <answer> indio_dev->active_scan_mask) 
<token> = <answer> st->chip_config.accl_fifo_enable 
<token> || <answer> indio_dev->active_scan_mask) 
<token> || <answer> indio_dev->active_scan_mask) 
st->chip_config.temp_fifo_enable <token> <answer> = 
test_bit(INV_MPU6050_SCAN_TEMP, <token> <answer> indio_dev->active_scan_mask); 
mask <token> 0; <answer> = 
if <token> <answer> (st->chip_config.gyro_fifo_enable) 
mask |= <token> <answer> INV_MPU6050_SENSOR_GYRO; 
<token> (st->chip_config.accl_fifo_enable) <answer> if 
mask |= <token> <answer> INV_MPU6050_SENSOR_ACCL; 
<token> (st->chip_config.temp_fifo_enable) <answer> if 
mask <token> INV_MPU6050_SENSOR_TEMP; <answer> |= 
return <token> <answer> mask; 
static unsigned int inv_scan_query_mpu9x50(struct <token> *indio_dev) <answer> iio_dev 
struct inv_mpu6050_state <token> = iio_priv(indio_dev); <answer> *st 
unsigned int <token> <answer> mask; 
mask <token> inv_scan_query_mpu6050(indio_dev); <answer> = 
static int inv_mpu6050_set_enable(struct iio_dev *indio_dev, bool <token> <answer> enable) 
<token> inv_mpu6050_state *st = iio_priv(indio_dev); <answer> struct 
struct <token> *pdev = regmap_get_device(st->map); <answer> device 
unsigned int <token> <answer> scan; 
<token> result; <answer> int 
<token> (enable) { <answer> if 
scan <token> inv_scan_query(indio_dev); <answer> = 
result = <token> <answer> pm_runtime_resume_and_get(pdev); 
if <token> <answer> (result) 
<token> result; <answer> return 
result = <token> false, ~scan); <answer> inv_mpu6050_switch_engine(st, 
<token> (result) <answer> if 
goto <token> <answer> error_power_off; 
result = <token> true, scan); <answer> inv_mpu6050_switch_engine(st, 
<token> (result) <answer> if 
<token> error_power_off; <answer> goto 
<token> = inv_compute_skip_samples(st); <answer> st->skip_samples 
result = inv_mpu6050_prepare_fifo(st, <token> <answer> true); 
<token> (result) <answer> if 
goto <token> <answer> error_power_off; 
} <token> { <answer> else 
st->chip_config.gyro_fifo_enable = <token> <answer> 0; 
st->chip_config.accl_fifo_enable <token> 0; <answer> = 
<token> = 0; <answer> st->chip_config.temp_fifo_enable 
st->chip_config.magn_fifo_enable <token> 0; <answer> = 
result <token> inv_mpu6050_prepare_fifo(st, false); <answer> = 
<token> (result) <answer> if 
goto <token> <answer> error_power_off; 
<token> 0; <answer> return 
return <token> <answer> result; 
static <token> inv_mpu_data_rdy_trigger_set_state(struct iio_trigger *trig, <answer> int 
<token> state) <answer> bool 
<token> iio_dev *indio_dev = iio_trigger_get_drvdata(trig); <answer> struct 
<token> inv_mpu6050_state *st = iio_priv(indio_dev); <answer> struct 
int <token> <answer> result; 
<token> = inv_mpu6050_set_enable(indio_dev, state); <answer> result 
return <token> <answer> result; 
static const struct <token> inv_mpu_trigger_ops = { <answer> iio_trigger_ops 
.set_trigger_state <token> &inv_mpu_data_rdy_trigger_set_state, <answer> = 
int inv_mpu6050_probe_trigger(struct <token> *indio_dev, int irq_type) <answer> iio_dev 
int <token> <answer> ret; 
struct inv_mpu6050_state *st = <token> <answer> iio_priv(indio_dev); 
st->trig = <token> <answer> devm_iio_trigger_alloc(&indio_dev->dev, 
<token> (!st->trig) <answer> if 
return <token> <answer> -ENOMEM; 
ret = devm_request_irq(&indio_dev->dev, <token> <answer> st->irq, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> = regmap_get_device(st->map); <answer> st->trig->dev.parent 
st->trig->ops <token> &inv_mpu_trigger_ops; <answer> = 
<token> indio_dev); <answer> iio_trigger_set_drvdata(st->trig, 
<token> = devm_iio_trigger_register(&indio_dev->dev, st->trig); <answer> ret 
<token> (ret) <answer> if 
return <token> <answer> ret; 
indio_dev->trig = <token> <answer> iio_trigger_get(st->trig); 
return <token> <answer> 0; 
<token> DEBUG <answer> #undef 
<token> <linux/pagemap.h> <answer> #include 
#include <token> <answer> <linux/namei.h> 
#include <token> <answer> <linux/backing-dev.h> 
<token> <linux/capability.h> <answer> #include 
#include <token> <answer> <linux/sched.h> 
<token> <linux/lockdep.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/configfs.h> 
#include <token> <answer> "configfs_internal.h" 
#ifdef <token> <answer> CONFIG_LOCKDEP 
<token> struct lock_class_key default_group_class[MAX_LOCK_DEPTH]; <answer> static 
static const struct <token> configfs_inode_operations ={ <answer> inode_operations 
.setattr = <token> <answer> configfs_setattr, 
int configfs_setattr(struct mnt_idmap *idmap, struct dentry <token> <answer> *dentry, 
struct iattr <token> <answer> *iattr) 
<token> inode * inode = d_inode(dentry); <answer> struct 
struct configfs_dirent * sd = <token> <answer> dentry->d_fsdata; 
<token> iattr * sd_iattr; <answer> struct 
<token> int ia_valid = iattr->ia_valid; <answer> unsigned 
<token> error; <answer> int 
<token> (!sd) <answer> if 
return <token> <answer> -EINVAL; 
sd_iattr <token> sd->s_iattr; <answer> = 
if <token> { <answer> (!sd_iattr) 
<token> sd->s_iattr); <answer> set_inode_attr(inode, 
} <token> <answer> else 
set_default_inode_attr(inode, <token> <answer> mode); 
return <token> <answer> inode; 
#ifdef <token> <answer> CONFIG_LOCKDEP 
<token> void configfs_set_inode_lock_class(struct configfs_dirent *sd, <answer> static 
struct <token> *inode) <answer> inode 
<token> depth = sd->s_depth; <answer> int 
if (depth <token> 0) { <answer> > 
if (depth <= <token> { <answer> ARRAY_SIZE(default_group_class)) 
&default_group_class[depth <token> 1]); <answer> - 
} <token> { <answer> else 
<token> many levels of inodes for the locking correctness validator.\n"); <answer> pr_info("Too 
pr_info("Spurious warnings may <token> <answer> appear.\n"); 
const unsigned char * configfs_get_name(struct <token> *sd) <answer> configfs_dirent 
struct configfs_attribute <token> <answer> *attr; 
BUG_ON(!sd <token> !sd->s_element); <answer> || 
<token> configfs_drop_dentry(struct configfs_dirent * sd, struct dentry * parent) <answer> void 
struct <token> * dentry = sd->s_dentry; <answer> dentry 
<token> (dentry) { <answer> if 
if <token> { <answer> (simple_positive(dentry)) 
<token> dentry); <answer> simple_unlink(d_inode(parent), 
} <token> <answer> else 
void configfs_hash_and_remove(struct <token> * dir, const char * name) <answer> dentry 
struct <token> * sd; <answer> configfs_dirent 
struct <token> * parent_sd = dir->d_fsdata; <answer> configfs_dirent 
<token> (d_really_is_negative(dir)) <answer> if 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/firmware.h> 
<token> <linux/i2c.h> <answer> #include 
<token> <linux/input.h> <answer> #include 
<token> <linux/input/mt.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#define <token> "bu21023_ts" <answer> BU21023_NAME 
<token> BU21023_FIRMWARE_NAME "bu21023.bin" <answer> #define 
#define <token> 2 <answer> MAX_CONTACTS 
#define <token> 4 <answer> AXIS_ADJUST 
<token> AXIS_OFFSET 8 <answer> #define 
#define <token> 32U <answer> FIRMWARE_BLOCK_SIZE 
#define <token> 4 <answer> FIRMWARE_RETRY_MAX 
#define VADOUT_YP_H <token> <answer> 0x00 
<token> VADOUT_YP_L 0x01 <answer> #define 
#define <token> 0x02 <answer> VADOUT_XP_H 
#define VADOUT_XP_L <token> <answer> 0x03 
<token> VADOUT_YN_H 0x04 <answer> #define 
<token> VADOUT_YN_L 0x05 <answer> #define 
#define VADOUT_XN_H <token> <answer> 0x06 
#define <token> 0x07 <answer> VADOUT_XN_L 
#define PRM1_X_H <token> <answer> 0x08 
#define <token> 0x09 <answer> PRM1_X_L 
#define <token> 0x0a <answer> PRM1_Y_H 
<token> PRM1_Y_L 0x0b <answer> #define 
<token> PRM2_X_H 0x0c <answer> #define 
<token> PRM2_X_L 0x0d <answer> #define 
#define <token> 0x0e <answer> PRM2_Y_H 
#define PRM2_Y_L <token> <answer> 0x0f 
#define <token> 0x10 <answer> MLT_PRM_MONI_X 
#define MLT_PRM_MONI_Y <token> <answer> 0x11 
<token> DEBUG_MONI_1 0x12 <answer> #define 
<token> DEBUG_MONI_2 0x13 <answer> #define 
<token> VADOUT_ZX_H 0x14 <answer> #define 
#define VADOUT_ZX_L <token> <answer> 0x15 
#define VADOUT_ZY_H <token> <answer> 0x16 
<token> VADOUT_ZY_L 0x17 <answer> #define 
<token> Z_PARAM_H 0x18 <answer> #define 
#define Z_PARAM_L <token> <answer> 0x19 
<token> VADOUT_L_MASK 0x01 <answer> #define 
#define PRM_L_MASK <token> <answer> 0x01 
#define <token> 0x20 <answer> POS_X1_H 
<token> POS_X1_L 0x21 <answer> #define 
#define <token> 0x22 <answer> POS_Y1_H 
#define <token> 0x23 <answer> POS_Y1_L 
#define <token> 0x24 <answer> POS_X2_H 
#define POS_X2_L <token> <answer> 0x25 
<token> POS_Y2_H 0x26 <answer> #define 
#define POS_Y2_L <token> <answer> 0x27 
#define POS_L_MASK <token> <answer> 0x01 
#define <token> 0x28 <answer> TOUCH 
#define TOUCH_DETECT <token> <answer> 0x01 
#define TOUCH_GESTURE <token> <answer> 0x29 
#define SINGLE_TOUCH <token> <answer> 0x01 
#define DUAL_TOUCH <token> <answer> 0x03 
#define <token> 0x03 <answer> TOUCH_MASK 
#define CALIBRATION_REQUEST <token> <answer> 0x04 
#define CALIBRATION_STATUS <token> <answer> 0x08 
<token> CALIBRATION_MASK 0x0c <answer> #define 
<token> GESTURE_SPREAD 0x10 <answer> #define 
#define GESTURE_PINCH <token> <answer> 0x20 
<token> GESTURE_ROTATE_R 0x40 <answer> #define 
<token> GESTURE_ROTATE_L 0x80 <answer> #define 
#define <token> 0x2a <answer> INT_STATUS 
#define <token> 0x3d <answer> INT_MASK 
#define INT_CLEAR <token> <answer> 0x3e 
#define COORD_UPDATE <token> <answer> 0x01 
#define CALIBRATION_DONE <token> <answer> 0x02 
#define <token> 0x04 <answer> SLEEP_IN 
#define <token> 0x08 <answer> SLEEP_OUT 
#define PROGRAM_LOAD_DONE <token> <answer> 0x10 
<token> ERROR 0x80 <answer> #define 
<token> INT_ALL 0x9f <answer> #define 
#define ERR_STATUS <token> <answer> 0x2b 
#define ERR_MASK <token> <answer> 0x3f 
#define ADC_TIMEOUT <token> <answer> 0x01 
#define CPU_TIMEOUT <token> <answer> 0x02 
#define CALIBRATION_ERR <token> <answer> 0x04 
<token> PROGRAM_LOAD_ERR 0x10 <answer> #define 
#define COMMON_SETUP1 <token> <answer> 0x30 
#define PROGRAM_LOAD_HOST <token> <answer> 0x02 
<token> PROGRAM_LOAD_EEPROM 0x03 <answer> #define 
#define CENSOR_4PORT <token> <answer> 0x04 
static int rohm_i2c_burst_read(struct i2c_client *client, u8 start, void <token> <answer> *buf, 
size_t <token> <answer> len) 
struct i2c_adapter <token> = client->adapter; <answer> *adap 
struct <token> msg[2]; <answer> i2c_msg 
int <token> ret = 0; <answer> i, 
msg[0].addr <token> client->addr; <answer> = 
msg[0].flags = <token> <answer> 0; 
<token> = 1; <answer> msg[0].len 
msg[0].buf = <token> <answer> &start; 
<token> = client->addr; <answer> msg[1].addr 
msg[1].flags <token> I2C_M_RD; <answer> = 
msg[1].len = <token> <answer> len; 
msg[1].buf <token> buf; <answer> = 
<token> I2C_LOCK_SEGMENT); <answer> i2c_lock_bus(adap, 
for <token> = 0; i < 2; i++) { <answer> (i 
if (__i2c_transfer(adap, &msg[i], <token> < 0) { <answer> 1) 
ret <token> -EIO; <answer> = 
i2c_unlock_bus(adap, <token> <answer> I2C_LOCK_SEGMENT); 
<token> ret; <answer> return 
static int rohm_ts_manual_calibration(struct rohm_ts_data <token> <answer> *ts) 
struct i2c_client *client = <token> <answer> ts->client; 
struct <token> *dev = &client->dev; <answer> device 
error = <token> FORCE_CALIBRATION, <answer> i2c_smbus_write_byte_data(client, 
<token> (error) <answer> if 
<token> out; <answer> goto 
error = <token> FORCE_CALIBRATION, <answer> i2c_smbus_write_byte_data(client, 
<token> (error) <answer> if 
goto <token> <answer> out; 
<token> = false; <answer> calibration_done 
<token> (i = 0; i < 10; i++) { <answer> for 
val <token> i2c_smbus_read_byte_data(client, TOUCH_GESTURE); <answer> = 
<token> (!(val & CALIBRATION_MASK)) { <answer> if 
calibration_done <token> true; <answer> = 
} else if (val <token> 0) { <answer> < 
error <token> val; <answer> = 
<token> out; <answer> goto 
if (calibration_done) <token> <answer> { 
val <token> i2c_smbus_read_byte_data(client, INT_STATUS); <answer> = 
<token> (val == CALIBRATION_DONE) { <answer> if 
<token> = true; <answer> success 
} else if (val <token> 0) { <answer> < 
<token> = val; <answer> error 
<token> out; <answer> goto 
<token> else { <answer> } 
dev_warn(dev, <token> timeout\n"); <answer> "calibration 
<token> (!success) { <answer> if 
error = <token> CALIBRATION_REG1, <answer> i2c_smbus_write_byte_data(client, 
if <token> <answer> (error) 
<token> out; <answer> goto 
error = <token> CALIBRATION_REG2, <answer> i2c_smbus_write_byte_data(client, 
if <token> <answer> (error) 
<token> out; <answer> goto 
error <token> i2c_smbus_write_byte_data(client, CALIBRATION_REG3, <answer> = 
<token> (error) <answer> if 
goto <token> <answer> out; 
error = i2c_smbus_write_byte_data(client, <token> STEP_X_DEFAULT); <answer> STEP_X, 
if <token> <answer> (error) 
return <token> <answer> error; 
error = i2c_smbus_write_byte_data(client, STEP_Y, <token> <answer> STEP_Y_DEFAULT); 
<token> (error) <answer> if 
<token> error; <answer> return 
error = i2c_smbus_write_byte_data(client, OFFSET_X, <token> <answer> OFFSET_X_DEFAULT); 
if <token> <answer> (error) 
<token> error; <answer> return 
error = i2c_smbus_write_byte_data(client, <token> OFFSET_Y_DEFAULT); <answer> OFFSET_Y, 
if <token> <answer> (error) 
<token> error; <answer> return 
error = i2c_smbus_write_byte_data(client, <token> <answer> THRESHOLD_TOUCH, 
<token> (error) <answer> if 
<token> error; <answer> return 
error = i2c_smbus_write_byte_data(client, <token> EVR_XY_DEFAULT); <answer> EVR_XY, 
<token> (error) <answer> if 
<token> error; <answer> return 
error <token> i2c_smbus_write_byte_data(client, EVR_X, EVR_X_DEFAULT); <answer> = 
<token> (error) <answer> if 
<token> error; <answer> return 
<token> = i2c_smbus_write_byte_data(client, EVR_Y, EVR_Y_DEFAULT); <answer> error 
<token> (error) <answer> if 
<token> error; <answer> return 
error = <token> CALIBRATION_REG1, <answer> i2c_smbus_write_byte_data(client, 
if <token> <answer> (error) 
<token> error; <answer> return 
error <token> i2c_smbus_write_byte_data(client, CALIBRATION_REG2, <answer> = 
if <token> <answer> (error) 
return <token> <answer> error; 
error <token> i2c_smbus_write_byte_data(client, CALIBRATION_REG3, <answer> = 
if <token> <answer> (error) 
return <token> <answer> error; 
error <token> i2c_smbus_write_byte_data(client, FORCE_CALIBRATION, <answer> = 
<token> (error) <answer> if 
<token> error; <answer> return 
<token> = i2c_smbus_write_byte_data(client, FORCE_CALIBRATION, <answer> error 
<token> (error) <answer> if 
<token> error; <answer> return 
<token> "resource.h" <answer> #include 
<token> "clk_mgr.h" <answer> #include 
<token> "dcn31/dcn31_resource.h" <answer> #include 
<token> "dcn315/dcn315_resource.h" <answer> #include 
<token> "dcn316/dcn316_resource.h" <answer> #include 
#include <token> <answer> "dml/dcn20/dcn20_fpu.h" 
#include <token> <answer> "dcn31_fpu.h" 
<token> _vcs_dpi_ip_params_st dcn3_1_ip = { <answer> struct 
.gpuvm_enable = <token> <answer> 1, 
.gpuvm_max_page_table_levels = <token> <answer> 1, 
<token> = 1, <answer> .hostvm_enable 
<token> = 2, <answer> .hostvm_max_page_table_levels 
<token> = 64, <answer> .rob_buffer_size_kbytes 
.det_buffer_size_kbytes = <token> <answer> DCN3_1_DEFAULT_DET_SIZE, 
<token> = 1792, <answer> .config_return_buffer_size_in_kbytes 
.compressed_buffer_segment_size_in_kbytes <token> 64, <answer> = 
.meta_fifo_size_in_kentries = <token> <answer> 32, 
.zero_size_buffer_entries <token> 512, <answer> = 
<token> = 256, <answer> .compbuf_reserved_space_64b 
.compbuf_reserved_space_zs = <token> <answer> 64, 
.dpp_output_buffer_pixels <token> 2560, <answer> = 
.opp_output_buffer_lines <token> 1, <answer> = 
.pixel_chunk_size_kbytes = <token> <answer> 8, 
.meta_chunk_size_kbytes = <token> <answer> 2, 
.min_meta_chunk_size_bytes = <token> <answer> 256, 
.writeback_chunk_size_kbytes = <token> <answer> 8, 
<token> = false, <answer> .ptoi_supported 
<token> = 3, <answer> .num_dsc 
<token> = 10, <answer> .maximum_dsc_bits_per_component 
.dsc422_native_support = <token> <answer> false, 
.is_line_buffer_bpp_fixed <token> true, <answer> = 
.line_buffer_fixed_bpp = <token> <answer> 48, 
.line_buffer_size_bits <token> 789504, <answer> = 
.max_line_buffer_lines <token> 12, <answer> = 
.writeback_interface_buffer_size_kbytes = <token> <answer> 90, 
<token> = 4, <answer> .max_num_dpp 
<token> = 4, <answer> .max_num_otg 
<token> = 1, <answer> .max_num_hdmi_frl_outputs 
.max_num_wb <token> 1, <answer> = 
.max_dchub_pscl_bw_pix_per_clk = <token> <answer> 4, 
.max_pscl_lb_bw_pix_per_clk = <token> <answer> 2, 
.max_lb_vscl_bw_pix_per_clk = <token> <answer> 4, 
<token> = 4, <answer> .max_vscl_hscl_bw_pix_per_clk 
.max_hscl_ratio <token> 6, <answer> = 
.max_vscl_ratio = <token> <answer> 6, 
.max_hscl_taps <token> 8, <answer> = 
<token> = 8, <answer> .max_vscl_taps 
.dpte_buffer_size_in_pte_reqs_luma = <token> <answer> 64, 
.dpte_buffer_size_in_pte_reqs_chroma <token> 34, <answer> = 
.dispclk_ramp_margin_percent <token> 1, <answer> = 
.max_inter_dcn_tile_repeaters = <token> <answer> 8, 
<token> = 16, <answer> .cursor_buffer_size 
.cursor_chunk_size <token> 2, <answer> = 
.writeback_line_buffer_buffer_size = <token> <answer> 0, 
.writeback_min_hscl_ratio = <token> <answer> 1, 
.writeback_min_vscl_ratio <token> 1, <answer> = 
.writeback_max_hscl_ratio <token> 1, <answer> = 
.writeback_max_vscl_ratio = <token> <answer> 1, 
<token> = 1, <answer> .writeback_max_hscl_taps 
.writeback_max_vscl_taps = <token> <answer> 1, 
.dppclk_delay_subtotal <token> 46, <answer> = 
<token> = 50, <answer> .dppclk_delay_scl 
.dppclk_delay_scl_lb_only = <token> <answer> 16, 
.dppclk_delay_cnvc_formatter = <token> <answer> 27, 
.dppclk_delay_cnvc_cursor <token> 6, <answer> = 
.dispclk_delay_subtotal <token> 119, <answer> = 
<token> = false, <answer> .dynamic_metadata_vm_enabled 
.odm_combine_4to1_supported = <token> <answer> false, 
<token> = true, <answer> .dcc_supported 
static struct _vcs_dpi_soc_bounding_box_st <token> = { <answer> dcn3_1_soc 
if (pipe_cnt == <token> { <answer> 0) 
<token> = dcfclk; <answer> context->bw_ctx.bw.dcn.clk.dcfclk_khz 
pipes[0].clks_cfg.voltage <token> vlevel; <answer> = 
<token> = dcfclk; <answer> pipes[0].clks_cfg.dcfclk_mhz 
<token> = context->bw_ctx.dml.soc.clock_limits[vlevel].socclk_mhz; <answer> pipes[0].clks_cfg.socclk_mhz 
dc->res_pool->funcs->update_soc_for_wm_a(dc, <token> <answer> context); 
context->bw_ctx.bw.dcn.watermarks.a.urgent_ns = get_wm_urgent(&context->bw_ctx.dml, pipes, pipe_cnt) <token> 1000; <answer> * 
<token> = get_wm_stutter_enter_exit(&context->bw_ctx.dml, pipes, pipe_cnt) * 1000; <answer> context->bw_ctx.bw.dcn.watermarks.a.cstate_pstate.cstate_enter_plus_exit_ns 
context->bw_ctx.bw.dcn.watermarks.a.cstate_pstate.cstate_exit_ns = get_wm_stutter_exit(&context->bw_ctx.dml, pipes, pipe_cnt) * <token> <answer> 1000; 
context->bw_ctx.bw.dcn.watermarks.a.cstate_pstate.pstate_change_ns = get_wm_dram_clock_change(&context->bw_ctx.dml, pipes, <token> * 1000; <answer> pipe_cnt) 
context->bw_ctx.bw.dcn.watermarks.a.cstate_pstate.cstate_enter_plus_exit_z8_ns = get_wm_z8_stutter_enter_exit(&context->bw_ctx.dml, pipes, pipe_cnt) <token> 1000; <answer> * 
context->bw_ctx.bw.dcn.watermarks.a.cstate_pstate.cstate_exit_z8_ns = get_wm_z8_stutter_exit(&context->bw_ctx.dml, pipes, <token> * 1000; <answer> pipe_cnt) 
context->bw_ctx.bw.dcn.watermarks.a.pte_meta_urgent_ns = get_wm_memory_trip(&context->bw_ctx.dml, pipes, <token> * 1000; <answer> pipe_cnt) 
context->bw_ctx.bw.dcn.watermarks.a.frac_urg_bw_nom <token> get_fraction_of_urgent_bandwidth(&context->bw_ctx.dml, pipes, pipe_cnt) * 1000; <answer> = 
context->bw_ctx.bw.dcn.watermarks.a.frac_urg_bw_flip = get_fraction_of_urgent_bandwidth_imm_flip(&context->bw_ctx.dml, pipes, pipe_cnt) <token> 1000; <answer> * 
context->bw_ctx.bw.dcn.watermarks.a.urgent_latency_ns = <token> pipes, pipe_cnt) * 1000; <answer> get_urgent_latency(&context->bw_ctx.dml, 
context->bw_ctx.bw.dcn.watermarks.b <token> context->bw_ctx.bw.dcn.watermarks.a; <answer> = 
<token> = context->bw_ctx.bw.dcn.watermarks.a; <answer> context->bw_ctx.bw.dcn.watermarks.c 
context->bw_ctx.bw.dcn.watermarks.d <token> context->bw_ctx.bw.dcn.watermarks.a; <answer> = 
for (i = 0, pipe_idx = <token> i < dc->res_pool->pipe_count; i++) { <answer> 0; 
<token> (!context->res_ctx.pipe_ctx[i].stream) <answer> if 
<token> (context->res_ctx.pipe_ctx[i].plane_state) <answer> if 
<token> = get_dispclk_calculated(&context->bw_ctx.dml, pipes, pipe_cnt); <answer> pipes[pipe_idx].clks_cfg.dispclk_mhz 
<token> = get_dppclk_calculated(&context->bw_ctx.dml, pipes, pipe_cnt, pipe_idx); <answer> pipes[pipe_idx].clks_cfg.dppclk_mhz 
if <token> || dc->debug.max_disp_clk) { <answer> (dc->config.forced_clocks 
pipes[pipe_idx].clks_cfg.dispclk_mhz = <token> <answer> context->bw_ctx.dml.soc.clock_limits[0].dispclk_mhz; 
<token> = context->bw_ctx.dml.soc.clock_limits[0].dppclk_mhz; <answer> pipes[pipe_idx].clks_cfg.dppclk_mhz 
if (dc->debug.min_disp_clk_khz > pipes[pipe_idx].clks_cfg.dispclk_mhz * <token> <answer> 1000) 
pipes[pipe_idx].clks_cfg.dispclk_mhz = <token> / 1000.0; <answer> dc->debug.min_disp_clk_khz 
if (dc->debug.min_dpp_clk_khz <token> pipes[pipe_idx].clks_cfg.dppclk_mhz * 1000) <answer> > 
pipes[pipe_idx].clks_cfg.dppclk_mhz = <token> / 1000.0; <answer> dc->debug.min_dpp_clk_khz 
<token> context, pipes, pipe_cnt, vlevel); <answer> dcn20_calculate_dlg_params(dc, 
dcn3_15_soc.dispclk_dppclk_vco_speed_mhz = <token> * 2; <answer> max_dispclk_mhz 
if ((int)(dcn3_15_soc.dram_clock_change_latency_us * <token> <answer> 1000) 
!= <token> <answer> dc->debug.dram_clock_change_latency_ns 
<token> dc->debug.dram_clock_change_latency_ns) { <answer> && 
dcn3_15_soc.dram_clock_change_latency_us = <token> / 1000; <answer> dc->debug.dram_clock_change_latency_ns 
<token> &dcn3_15_soc, &dcn3_15_ip, DML_PROJECT_DCN315); <answer> dml_init_instance(&dc->dml, 
void dcn316_update_bw_bounding_box(struct <token> *dc, struct clk_bw_params *bw_params) <answer> dc 
struct <token> *s = dc->scratch.update_bw_bounding_box.clock_limits; <answer> _vcs_dpi_voltage_scaling_st 
struct clk_limit_table <token> = &bw_params->clk_table; <answer> *clk_table 
unsigned int <token> closest_clk_lvl; <answer> i, 
int max_dispclk_mhz = 0, max_dppclk_mhz <token> 0; <answer> = 
<token> j; <answer> int 
<token> dcn3_16_soc.clock_limits, sizeof(dcn3_16_soc.clock_limits)); <answer> memcpy(s, 
dcn3_16_ip.max_num_otg = <token> <answer> dc->res_pool->res_cap->num_timing_generator; 
<token> = dc->res_pool->pipe_count; <answer> dcn3_16_ip.max_num_dpp 
dcn3_16_soc.num_chans <token> bw_params->num_channels; <answer> = 
return (int)(soc->dram_clock_change_latency_us <token> pix_clk_100hz * bpp <answer> * 
/ 10240000 + seg_size_kb - 1) <token> seg_size_kb; <answer> / 
#define <token> "%s: " fmt, __func__ <answer> pr_fmt(fmt) 
<token> <linux/delay.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_platform.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/ssbi.h> 
static int ssbi_wait_mask(struct ssbi *ssbi, u32 <token> u32 clr_mask) <answer> set_mask, 
u32 timeout = <token> <answer> SSBI_TIMEOUT_US; 
<token> val; <answer> u32 
while (timeout--) <token> <answer> { 
<token> = ssbi_readl(ssbi, SSBI2_STATUS); <answer> val 
if <token> & set_mask) == set_mask) && ((val & clr_mask) == 0)) <answer> (((val 
<token> 0; <answer> return 
<token> -ETIMEDOUT; <answer> return 
static <token> <answer> int 
ssbi_read_bytes(struct ssbi <token> u16 addr, u8 *buf, int len) <answer> *ssbi, 
<token> cmd = SSBI_CMD_RDWRN | ((addr & 0xff) << 16); <answer> u32 
int ret = <token> <answer> 0; 
<token> (ssbi->controller_type == MSM_SBI_CTRL_SSBI2) { <answer> if 
u32 mode2 <token> ssbi_readl(ssbi, SSBI2_MODE2); <answer> = 
mode2 = SET_SSBI_MODE2_REG_ADDR_15_8(mode2, <token> <answer> addr); 
ssbi_writel(ssbi, mode2, <token> <answer> SSBI2_MODE2); 
while (len) <token> <answer> { 
ret = ssbi_wait_mask(ssbi, <token> 0); <answer> SSBI_STATUS_READY, 
if <token> <answer> (ret) 
goto <token> <answer> err; 
<token> cmd, SSBI2_CMD); <answer> ssbi_writel(ssbi, 
<token> = ssbi_wait_mask(ssbi, SSBI_STATUS_RD_READY, 0); <answer> ret 
if <token> <answer> (ret) 
goto <token> <answer> err; 
*buf++ = <token> SSBI2_RD) & 0xff; <answer> ssbi_readl(ssbi, 
<token> ret; <answer> return 
<token> int <answer> static 
ssbi_write_bytes(struct ssbi *ssbi, u16 <token> const u8 *buf, int len) <answer> addr, 
int ret <token> 0; <answer> = 
if (ssbi->controller_type == MSM_SBI_CTRL_SSBI2) <token> <answer> { 
<token> mode2 = ssbi_readl(ssbi, SSBI2_MODE2); <answer> u32 
mode2 = <token> addr); <answer> SET_SSBI_MODE2_REG_ADDR_15_8(mode2, 
ssbi_writel(ssbi, <token> SSBI2_MODE2); <answer> mode2, 
while <token> { <answer> (len) 
ret = ssbi_wait_mask(ssbi, <token> 0); <answer> SSBI_STATUS_READY, 
<token> (ret) <answer> if 
<token> err; <answer> goto 
<token> ((addr & 0xff) << 16) | *buf, SSBI2_CMD); <answer> ssbi_writel(ssbi, 
<token> = ssbi_wait_mask(ssbi, 0, SSBI_STATUS_MCHN_BUSY); <answer> ret 
if <token> <answer> (ret) 
<token> err; <answer> goto 
return <token> <answer> ret; 
static <token> int <answer> inline 
ssbi_pa_transfer(struct ssbi *ssbi, u32 cmd, <token> *data) <answer> u8 
u32 <token> = SSBI_TIMEOUT_US; <answer> timeout 
<token> rd_status = 0; <answer> u32 
<token> cmd, SSBI_PA_CMD); <answer> ssbi_writel(ssbi, 
<token> (timeout--) { <answer> while 
<token> = ssbi_readl(ssbi, SSBI_PA_RD_STATUS); <answer> rd_status 
if (rd_status <token> SSBI_PA_RD_STATUS_TRANS_DENIED) <answer> & 
<token> -EPERM; <answer> return 
if (rd_status & SSBI_PA_RD_STATUS_TRANS_DONE) <token> <answer> { 
<token> (data) <answer> if 
*data <token> rd_status & 0xff; <answer> = 
<token> 0; <answer> return 
<token> -ETIMEDOUT; <answer> return 
static <token> <answer> int 
ssbi_pa_read_bytes(struct ssbi *ssbi, u16 <token> u8 *buf, int len) <answer> addr, 
u32 <token> <answer> cmd; 
<token> ret = 0; <answer> int 
<token> = SSBI_PA_CMD_RDWRN | (addr & SSBI_PA_CMD_ADDR_MASK) << 8; <answer> cmd 
while <token> { <answer> (len) 
ret = ssbi_pa_transfer(ssbi, <token> buf); <answer> cmd, 
<token> (ret) <answer> if 
goto <token> <answer> err; 
return <token> <answer> ret; 
<token> int <answer> static 
