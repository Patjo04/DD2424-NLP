#include <token> <answer> <linux/crypto.h> 
#include <token> <answer> "ubifs.h" 
void ubifs_compress(const struct ubifs_info *c, const <token> *in_buf, <answer> void 
<token> in_len, void *out_buf, int *out_len, int *compr_type) <answer> int 
int <token> <answer> err; 
struct ubifs_compressor <token> = ubifs_compressors[*compr_type]; <answer> *compr 
if <token> == UBIFS_COMPR_NONE) <answer> (*compr_type 
goto <token> <answer> no_compr; 
if (in_len - *out_len <token> UBIFS_MIN_COMPRESS_DIFF) <answer> < 
goto <token> <answer> no_compr; 
memcpy(out_buf, in_buf, <token> <answer> in_len); 
*out_len = <token> <answer> in_len; 
<token> = UBIFS_COMPR_NONE; <answer> *compr_type 
int ubifs_decompress(const struct <token> *c, const void *in_buf, <answer> ubifs_info 
int in_len, void <token> int *out_len, int compr_type) <answer> *out_buf, 
<token> err; <answer> int 
<token> ubifs_compressor *compr; <answer> struct 
if (unlikely(compr_type < 0 || <token> >= UBIFS_COMPR_TYPES_CNT)) { <answer> compr_type 
ubifs_err(c, "invalid <token> type %d", compr_type); <answer> compression 
<token> -EINVAL; <answer> return 
<token> = ubifs_compressors[compr_type]; <answer> compr 
if <token> { <answer> (unlikely(!compr->capi_name)) 
ubifs_err(c, "%s compression <token> not compiled in", compr->name); <answer> is 
<token> -EINVAL; <answer> return 
if (compr_type == UBIFS_COMPR_NONE) <token> <answer> { 
<token> in_buf, in_len); <answer> memcpy(out_buf, 
*out_len <token> in_len; <answer> = 
<token> 0; <answer> return 
<token> (compr->decomp_mutex) <answer> if 
<token> = crypto_comp_decompress(compr->cc, in_buf, in_len, out_buf, <answer> err 
<token> int *)out_len); <answer> (unsigned 
<token> (compr->decomp_mutex) <answer> if 
<token> (err) <answer> if 
ubifs_err(c, "cannot <token> %d bytes, compressor %s, error %d", <answer> decompress 
in_len, compr->name, <token> <answer> err); 
return <token> <answer> err; 
static int __init <token> ubifs_compressor *compr) <answer> compr_init(struct 
if <token> { <answer> (compr->capi_name) 
compr->cc <token> crypto_alloc_comp(compr->capi_name, 0, 0); <answer> = 
<token> (IS_ERR(compr->cc)) { <answer> if 
pr_err("UBIFS error (pid %d): cannot initialize <token> %s, error %ld", <answer> compressor 
current->pid, <token> PTR_ERR(compr->cc)); <answer> compr->name, 
return <token> <answer> PTR_ERR(compr->cc); 
ubifs_compressors[compr->compr_type] = <token> <answer> compr; 
return <token> <answer> 0; 
static void <token> ubifs_compressor *compr) <answer> compr_exit(struct 
<token> (compr->capi_name) <answer> if 
<token> __init ubifs_compressors_init(void) <answer> int 
int <token> <answer> err; 
err <token> compr_init(&lzo_compr); <answer> = 
<token> (err) <answer> if 
<token> err; <answer> return 
err <token> compr_init(&zstd_compr); <answer> = 
<token> (err) <answer> if 
goto <token> <answer> out_lzo; 
err = <token> <answer> compr_init(&zlib_compr); 
<token> (err) <answer> if 
goto <token> <answer> out_zstd; 
<token> = &none_compr; <answer> ubifs_compressors[UBIFS_COMPR_NONE] 
return <token> <answer> 0; 
<token> err; <answer> return 
<token> ubifs_compressors_exit(void) <answer> void 
<token> <linux/clk-provider.h> <answer> #include 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <linux/clk/davinci.h> 
#include <token> <answer> <linux/delay.h> 
<token> <linux/err.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/mfd/syscon.h> 
#include <token> <answer> <linux/notifier.h> 
#include <token> <answer> <linux/of.h> 
<token> <linux/platform_data/clk-davinci-pll.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/property.h> 
<token> <linux/regmap.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/types.h> <answer> #include 
<token> "pll.h" <answer> #include 
#define <token> 20 <answer> MAX_NAME_SIZE 
#define OSCIN_CLK_NAME <token> <answer> "oscin" 
#define <token> 0x000 <answer> REVID 
#define <token> 0x100 <answer> PLLCTL 
#define OCSEL <token> <answer> 0x104 
#define PLLSECCTL <token> <answer> 0x108 
<token> PLLM 0x110 <answer> #define 
#define <token> 0x114 <answer> PREDIV 
#define PLLDIV1 <token> <answer> 0x118 
#define PLLDIV2 <token> <answer> 0x11c 
#define PLLDIV3 <token> <answer> 0x120 
<token> OSCDIV 0x124 <answer> #define 
#define POSTDIV <token> <answer> 0x128 
<token> BPDIV 0x12c <answer> #define 
<token> PLLCMD 0x138 <answer> #define 
<token> PLLSTAT 0x13c <answer> #define 
#define <token> 0x140 <answer> ALNCTL 
<token> DCHANGE 0x144 <answer> #define 
#define CKEN <token> <answer> 0x148 
#define CKSTAT <token> <answer> 0x14c 
#define SYSTAT <token> <answer> 0x150 
#define <token> 0x160 <answer> PLLDIV4 
#define PLLDIV5 <token> <answer> 0x164 
<token> PLLDIV6 0x168 <answer> #define 
#define PLLDIV7 <token> <answer> 0x16c 
#define <token> 0x170 <answer> PLLDIV8 
#define PLLDIV9 <token> <answer> 0x174 
#define PLLCTL_PLLEN <token> <answer> BIT(0) 
#define PLLCTL_PLLPWRDN <token> <answer> BIT(1) 
#define PLLCTL_PLLRST <token> <answer> BIT(3) 
<token> PLLCTL_PLLDIS BIT(4) <answer> #define 
<token> PLLCTL_PLLENSRC BIT(5) <answer> #define 
<token> PLLCTL_CLKMODE BIT(8) <answer> #define 
<token> PLL_BYPASS_TIME 1 <answer> #define 
#define <token> 20 <answer> PLL_LOCK_TIME 
struct davinci_pll_clk <token> <answer> { 
<token> clk_hw hw; <answer> struct 
<token> __iomem *base; <answer> void 
<token> pllm_min; <answer> u32 
<token> pllm_max; <answer> u32 
<token> pllm_mask; <answer> u32 
<token> to_davinci_pll_clk(_hw) \ <answer> #define 
container_of((_hw), struct davinci_pll_clk, <token> <answer> hw) 
static unsigned long davinci_pll_recalc_rate(struct clk_hw <token> <answer> *hw, 
unsigned <token> parent_rate) <answer> long 
struct <token> *pll = to_davinci_pll_clk(hw); <answer> davinci_pll_clk 
unsigned long rate <token> parent_rate; <answer> = 
u32 <token> <answer> mult; 
mult = readl(pll->base + PLLM) <token> pll->pllm_mask; <answer> & 
rate *= mult <token> 1; <answer> + 
return <token> <answer> rate; 
static int <token> clk_hw *hw, <answer> davinci_pll_determine_rate(struct 
struct clk_rate_request <token> <answer> *req) 
struct davinci_pll_clk *pll <token> to_davinci_pll_clk(hw); <answer> = 
<token> clk_hw *parent = req->best_parent_hw; <answer> struct 
unsigned long parent_rate = <token> <answer> req->best_parent_rate; 
unsigned <token> rate = req->rate; <answer> long 
unsigned long best_rate, <token> <answer> r; 
<token> mult; <answer> u32 
static <token> clk *davinci_pll_div_register(struct device *dev, <answer> struct 
const char <token> <answer> *name, 
const char <token> <answer> *parent_name, 
<token> __iomem *reg, <answer> void 
bool <token> u32 flags) <answer> fixed, 
<token> char * const *parent_names = parent_name ? &parent_name : NULL; <answer> const 
int num_parents <token> parent_name ? 1 : 0; <answer> = 
const struct clk_ops *divider_ops = <token> <answer> &clk_divider_ops; 
<token> clk_gate *gate; <answer> struct 
struct clk_divider <token> <answer> *divider; 
struct <token> *clk; <answer> clk 
<token> ret; <answer> int 
gate = kzalloc(sizeof(*gate), <token> <answer> GFP_KERNEL); 
<token> (!gate) <answer> if 
return <token> <answer> ERR_PTR(-ENOMEM); 
<token> = reg; <answer> gate->reg 
gate->bit_idx = <token> <answer> DIV_ENABLE_SHIFT; 
divider = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*divider), 
if <token> { <answer> (!divider) 
ret <token> -ENOMEM; <answer> = 
<token> err_free_gate; <answer> goto 
divider->reg = <token> <answer> reg; 
<token> = DIV_RATIO_SHIFT; <answer> divider->shift 
<token> = DIV_RATIO_WIDTH; <answer> divider->width 
if (fixed) <token> <answer> { 
divider->flags <token> CLK_DIVIDER_READ_ONLY; <answer> |= 
divider_ops <token> &clk_divider_ro_ops; <answer> = 
clk = clk_register_composite(dev, name, <token> num_parents, <answer> parent_names, 
NULL, NULL, &divider->hw, <token> <answer> divider_ops, 
<token> &clk_gate_ops, flags); <answer> &gate->hw, 
if (IS_ERR(clk)) <token> <answer> { 
ret = <token> <answer> PTR_ERR(clk); 
goto <token> <answer> err_free_divider; 
return <token> <answer> clk; 
<token> ERR_PTR(ret); <answer> return 
struct <token> { <answer> davinci_pllen_clk 
<token> clk_hw hw; <answer> struct 
void __iomem <token> <answer> *base; 
<token> to_davinci_pllen_clk(_hw) \ <answer> #define 
container_of((_hw), struct davinci_pllen_clk, <token> <answer> hw) 
static const struct clk_ops <token> = { <answer> davinci_pllen_ops 
static int <token> notifier_block *nb, <answer> davinci_pllen_rate_change(struct 
<token> long flags, void *data) <answer> unsigned 
struct clk_notifier_data <token> = data; <answer> *cnd 
struct clk_hw *hw = <token> <answer> __clk_get_hw(cnd->clk); 
<token> davinci_pllen_clk *pll = to_davinci_pllen_clk(hw); <answer> struct 
u32 <token> <answer> ctrl; 
<token> = readl(pll->base + PLLCTL); <answer> ctrl 
if <token> == PRE_RATE_CHANGE) { <answer> (flags 
struct clk *davinci_pll_clk_register(struct <token> *dev, <answer> device 
const <token> davinci_pll_clk_info *info, <answer> struct 
<token> char *parent_name, <answer> const 
<token> __iomem *base, <answer> void 
<token> regmap *cfgchip) <answer> struct 
char <token> <answer> prediv_name[MAX_NAME_SIZE]; 
<token> pllout_name[MAX_NAME_SIZE]; <answer> char 
<token> postdiv_name[MAX_NAME_SIZE]; <answer> char 
<token> pllen_name[MAX_NAME_SIZE]; <answer> char 
<token> clk_init_data init; <answer> struct 
struct davinci_pll_clk <token> <answer> *pllout; 
struct <token> *pllen; <answer> davinci_pllen_clk 
struct clk <token> = NULL; <answer> *oscin_clk 
struct clk *prediv_clk = <token> <answer> NULL; 
struct <token> *pllout_clk; <answer> clk 
<token> clk *postdiv_clk = NULL; <answer> struct 
struct <token> *pllen_clk; <answer> clk 
<token> ret; <answer> int 
if (info->flags & PLL_HAS_CLKMODE) <token> <answer> { 
oscin_clk = clk_register_fixed_factor(dev, <token> <answer> OSCIN_CLK_NAME, 
parent_name, <token> 1, 1); <answer> 0, 
if <token> <answer> (IS_ERR(oscin_clk)) 
<token> oscin_clk; <answer> return 
parent_name = <token> <answer> OSCIN_CLK_NAME; 
if (info->flags <token> PLL_HAS_PREDIV) { <answer> & 
bool fixed = <token> & PLL_PREDIV_FIXED_DIV; <answer> info->flags 
u32 flags <token> 0; <answer> = 
<token> MAX_NAME_SIZE, "%s_prediv", info->name); <answer> snprintf(prediv_name, 
if (info->flags <token> PLL_PREDIV_ALWAYS_ENABLED) <answer> & 
flags <token> CLK_IS_CRITICAL; <answer> |= 
struct clk <token> device *dev, <answer> *davinci_pll_auxclk_register(struct 
const char <token> <answer> *name, 
void __iomem <token> <answer> *base) 
return clk_register_gate(dev, name, OSCIN_CLK_NAME, <token> base + CKEN, <answer> 0, 
CKEN_AUXEN_SHIFT, 0, <token> <answer> NULL); 
<token> clk *davinci_pll_sysclkbp_clk_register(struct device *dev, <answer> struct 
const <token> *name, <answer> char 
void __iomem <token> <answer> *base) 
return clk_register_divider(dev, name, OSCIN_CLK_NAME, 0, <token> + BPDIV, <answer> base 
<token> DIV_RATIO_WIDTH, <answer> DIV_RATIO_SHIFT, 
CLK_DIVIDER_READ_ONLY, <token> <answer> NULL); 
<token> clk * <answer> struct 
<token> device *dev, <answer> davinci_pll_obsclk_register(struct 
const struct <token> *info, <answer> davinci_pll_obsclk_info 
void __iomem <token> <answer> *base) 
struct <token> *mux; <answer> clk_mux 
struct clk_gate <token> <answer> *gate; 
struct clk_divider <token> <answer> *divider; 
struct clk <token> <answer> *clk; 
u32 <token> <answer> oscdiv; 
<token> ret; <answer> int 
mux = kzalloc(sizeof(*mux), <token> <answer> GFP_KERNEL); 
<token> (!mux) <answer> if 
return <token> <answer> ERR_PTR(-ENOMEM); 
<token> = base + OCSEL; <answer> mux->reg 
mux->table <token> info->table; <answer> = 
mux->mask <token> info->ocsrc_mask; <answer> = 
gate = kzalloc(sizeof(*gate), <token> <answer> GFP_KERNEL); 
if <token> { <answer> (!gate) 
ret = <token> <answer> -ENOMEM; 
<token> err_free_mux; <answer> goto 
gate->reg = <token> + CKEN; <answer> base 
gate->bit_idx <token> CKEN_OBSCLK_SHIFT; <answer> = 
divider <token> kzalloc(sizeof(*divider), GFP_KERNEL); <answer> = 
if <token> { <answer> (!divider) 
<token> = -ENOMEM; <answer> ret 
goto <token> <answer> err_free_gate; 
<token> = base + OSCDIV; <answer> divider->reg 
<token> = DIV_RATIO_SHIFT; <answer> divider->shift 
<token> = DIV_RATIO_WIDTH; <answer> divider->width 
struct <token> * <answer> clk 
davinci_pll_sysclk_register(struct <token> *dev, <answer> device 
const <token> davinci_pll_sysclk_info *info, <answer> struct 
void __iomem <token> <answer> *base) 
const struct clk_ops *divider_ops = <token> <answer> &clk_divider_ops; 
<token> clk_gate *gate; <answer> struct 
struct <token> *divider; <answer> clk_divider 
<token> clk *clk; <answer> struct 
u32 <token> <answer> reg; 
u32 <token> = 0; <answer> flags 
int <token> <answer> ret; 
if <token> <answer> (!pdata) 
<token> = devm_kzalloc(dev, sizeof(*pdata), GFP_KERNEL); <answer> pdata 
<token> (!pdata) <answer> if 
return <token> <answer> NULL; 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/export.h> 
#include <token> <answer> <linux/types.h> 
#include <token> <answer> <linux/scatterlist.h> 
<token> <linux/mmc/host.h> <answer> #include 
<token> <linux/mmc/card.h> <answer> #include 
#include <token> <answer> <linux/mmc/mmc.h> 
#include <token> <answer> "core.h" 
<token> "card.h" <answer> #include 
<token> "host.h" <answer> #include 
<token> "mmc_ops.h" <answer> #include 
<token> (status) <answer> if 
<token> = cmd.resp[0]; <answer> *status 
<token> 0; <answer> return 
int mmc_send_status(struct mmc_card *card, u32 <token> <answer> *status) 
<token> __mmc_send_status(card, status, MMC_CMD_RETRIES); <answer> return 
static int _mmc_select_card(struct <token> *host, struct mmc_card *card) <answer> mmc_host 
struct <token> cmd = {}; <answer> mmc_command 
<token> = MMC_SELECT_CARD; <answer> cmd.opcode 
if <token> { <answer> (card) 
cmd.arg = card->rca <token> 16; <answer> << 
cmd.flags <token> MMC_RSP_R1 | MMC_CMD_AC; <answer> = 
} else <token> <answer> { 
cmd.arg = <token> <answer> 0; 
<token> = MMC_RSP_NONE | MMC_CMD_AC; <answer> cmd.flags 
<token> mmc_wait_for_cmd(host, &cmd, MMC_CMD_RETRIES); <answer> return 
int <token> mmc_card *card) <answer> mmc_select_card(struct 
<token> _mmc_select_card(card->host, card); <answer> return 
int mmc_deselect_cards(struct mmc_host <token> <answer> *host) 
return _mmc_select_card(host, <token> <answer> NULL); 
<token> mmc_set_dsr(struct mmc_host *host) <answer> int 
<token> mmc_command cmd = {}; <answer> struct 
cmd.opcode = <token> <answer> MMC_SET_DSR; 
cmd.arg = (host->dsr <token> 16) | 0xffff; <answer> << 
<token> = MMC_RSP_NONE | MMC_CMD_AC; <answer> cmd.flags 
return mmc_wait_for_cmd(host, <token> MMC_CMD_RETRIES); <answer> &cmd, 
int mmc_go_idle(struct <token> *host) <answer> mmc_host 
int <token> <answer> err; 
struct mmc_command cmd <token> {}; <answer> = 
if <token> { <answer> (!mmc_host_is_spi(host)) 
mmc_set_chip_select(host, <token> <answer> MMC_CS_HIGH); 
<token> = MMC_GO_IDLE_STATE; <answer> cmd.opcode 
cmd.arg <token> 0; <answer> = 
cmd.flags = MMC_RSP_SPI_R1 | MMC_RSP_NONE <token> MMC_CMD_BC; <answer> | 
err = mmc_wait_for_cmd(host, <token> 0); <answer> &cmd, 
<token> (!mmc_host_is_spi(host)) { <answer> if 
<token> MMC_CS_DONTCARE); <answer> mmc_set_chip_select(host, 
host->use_spi_crc <token> 0; <answer> = 
<token> err; <answer> return 
static int __mmc_send_op_cond_cb(void <token> bool *busy) <answer> *cb_data, 
struct mmc_op_cond_busy_data *data <token> cb_data; <answer> = 
struct <token> *host = data->host; <answer> mmc_host 
<token> mmc_command *cmd = data->cmd; <answer> struct 
u32 <token> = data->ocr; <answer> ocr 
int err = <token> <answer> 0; 
<token> = mmc_wait_for_cmd(host, cmd, 0); <answer> err 
<token> (err) <answer> if 
return <token> <answer> err; 
if (mmc_host_is_spi(host)) <token> <answer> { 
if (!(cmd->resp[0] & <token> { <answer> R1_SPI_IDLE)) 
<token> = false; <answer> *busy 
return <token> <answer> 0; 
} <token> { <answer> else 
if (cmd->resp[0] <token> MMC_CARD_BUSY) { <answer> & 
*busy <token> false; <answer> = 
return <token> <answer> 0; 
*busy = <token> <answer> true; 
if (!ocr && <token> <answer> !mmc_host_is_spi(host)) 
cmd->arg <token> cmd->resp[0] | BIT(30); <answer> = 
return <token> <answer> 0; 
int <token> mmc_host *host, u32 ocr, u32 *rocr) <answer> mmc_send_op_cond(struct 
struct mmc_command cmd = <token> <answer> {}; 
int err <token> 0; <answer> = 
struct mmc_op_cond_busy_data <token> = { <answer> cb_data 
.host = <token> <answer> host, 
.ocr <token> ocr, <answer> = 
<token> = &cmd <answer> .cmd 
cmd.opcode <token> MMC_SEND_OP_COND; <answer> = 
cmd.arg = mmc_host_is_spi(host) ? 0 : <token> <answer> ocr; 
cmd.flags = <token> | MMC_RSP_R3 | MMC_CMD_BCR; <answer> MMC_RSP_SPI_R1 
err = __mmc_poll_for_busy(host, <token> <answer> MMC_OP_COND_PERIOD_US, 
<token> &cb_data); <answer> &__mmc_send_op_cond_cb, 
if <token> <answer> (err) 
return <token> <answer> err; 
if (rocr && <token> <answer> !mmc_host_is_spi(host)) 
*rocr = <token> <answer> cmd.resp[0]; 
<token> err; <answer> return 
int mmc_set_relative_addr(struct <token> *card) <answer> mmc_card 
<token> mmc_command cmd = {}; <answer> struct 
cmd.opcode <token> MMC_SET_RELATIVE_ADDR; <answer> = 
cmd.arg <token> card->rca << 16; <answer> = 
cmd.flags <token> MMC_RSP_R1 | MMC_CMD_AC; <answer> = 
return mmc_wait_for_cmd(card->host, &cmd, <token> <answer> MMC_CMD_RETRIES); 
static <token> <answer> int 
mmc_send_cxd_native(struct mmc_host *host, <token> arg, u32 *cxd, int opcode) <answer> u32 
<token> err; <answer> int 
struct mmc_command cmd <token> {}; <answer> = 
cmd.opcode = <token> <answer> opcode; 
cmd.arg <token> arg; <answer> = 
cmd.flags = <token> | MMC_CMD_AC; <answer> MMC_RSP_R2 
err = <token> &cmd, MMC_CMD_RETRIES); <answer> mmc_wait_for_cmd(host, 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> cmd.resp, sizeof(u32) * 4); <answer> memcpy(cxd, 
return <token> <answer> 0; 
int mmc_send_adtc_data(struct mmc_card *card, struct mmc_host *host, u32 <token> <answer> opcode, 
u32 args, <token> *buf, unsigned len) <answer> void 
struct mmc_request mrq <token> {}; <answer> = 
struct <token> cmd = {}; <answer> mmc_command 
struct <token> data = {}; <answer> mmc_data 
struct scatterlist <token> <answer> sg; 
<token> = &cmd; <answer> mrq.cmd 
<token> = &data; <answer> mrq.data 
cmd.opcode = <token> <answer> opcode; 
<token> = args; <answer> cmd.arg 
cmd.flags = MMC_RSP_SPI_R1 <token> MMC_RSP_R1 | MMC_CMD_ADTC; <answer> | 
data.blksz = <token> <answer> len; 
<token> = 1; <answer> data.blocks 
data.flags <token> MMC_DATA_READ; <answer> = 
<token> = &sg; <answer> data.sg 
<token> = 1; <answer> data.sg_len 
sg_init_one(&sg, buf, <token> <answer> len); 
if (opcode == MMC_SEND_CSD || opcode == MMC_SEND_CID) <token> <answer> { 
data.timeout_ns <token> 0; <answer> = 
data.timeout_clks <token> 64; <answer> = 
} <token> <answer> else 
mmc_set_data_timeout(&data, <token> <answer> card); 
<token> &mrq); <answer> mmc_wait_for_req(host, 
if <token> <answer> (cmd.error) 
<token> cmd.error; <answer> return 
if <token> <answer> (data.error) 
<token> data.error; <answer> return 
<token> 0; <answer> return 
static int mmc_spi_send_cxd(struct mmc_host *host, u32 *cxd, <token> opcode) <answer> u32 
int ret, <token> <answer> i; 
__be32 <token> <answer> *cxd_tmp; 
<token> = kzalloc(16, GFP_KERNEL); <answer> cxd_tmp 
if <token> <answer> (!cxd_tmp) 
<token> -ENOMEM; <answer> return 
<token> = mmc_send_adtc_data(NULL, host, opcode, 0, cxd_tmp, 16); <answer> ret 
<token> (ret) <answer> if 
goto <token> <answer> err; 
for (i = 0; i < 4; <token> <answer> i++) 
<token> = be32_to_cpu(cxd_tmp[i]); <answer> cxd[i] 
return <token> <answer> ret; 
int mmc_send_csd(struct mmc_card <token> u32 *csd) <answer> *card, 
if <token> <answer> (mmc_host_is_spi(card->host)) 
return <token> csd, MMC_SEND_CSD); <answer> mmc_spi_send_cxd(card->host, 
return <token> card->rca << 16, csd, <answer> mmc_send_cxd_native(card->host, 
<token> mmc_send_cid(struct mmc_host *host, u32 *cid) <answer> int 
<token> (mmc_host_is_spi(host)) <answer> if 
return mmc_spi_send_cxd(host, <token> MMC_SEND_CID); <answer> cid, 
return mmc_send_cxd_native(host, <token> cid, MMC_ALL_SEND_CID); <answer> 0, 
int mmc_get_ext_csd(struct <token> *card, u8 **new_ext_csd) <answer> mmc_card 
<token> err; <answer> int 
<token> *ext_csd; <answer> u8 
if <token> || !new_ext_csd) <answer> (!card 
<token> -EINVAL; <answer> return 
<token> (!mmc_can_ext_csd(card)) <answer> if 
<token> -EOPNOTSUPP; <answer> return 
ext_csd = kzalloc(512, <token> <answer> GFP_KERNEL); 
if <token> <answer> (!ext_csd) 
<token> -ENOMEM; <answer> return 
err = mmc_send_adtc_data(card, card->host, <token> 0, ext_csd, <answer> MMC_SEND_EXT_CSD, 
<token> (err) <answer> if 
<token> = ext_csd; <answer> *new_ext_csd 
<token> err; <answer> return 
<token> mmc_spi_read_ocr(struct mmc_host *host, int highcap, u32 *ocrp) <answer> int 
struct <token> cmd = {}; <answer> mmc_command 
<token> err; <answer> int 
<token> = MMC_SPI_READ_OCR; <answer> cmd.opcode 
cmd.arg = highcap <token> (1 << 30) : 0; <answer> ? 
cmd.flags = <token> <answer> MMC_RSP_SPI_R3; 
err <token> mmc_wait_for_cmd(host, &cmd, 0); <answer> = 
*ocrp <token> cmd.resp[1]; <answer> = 
<token> err; <answer> return 
int mmc_spi_set_crc(struct mmc_host *host, int <token> <answer> use_crc) 
struct mmc_command <token> = {}; <answer> cmd 
int <token> <answer> err; 
cmd.opcode <token> MMC_SPI_CRC_ON_OFF; <answer> = 
cmd.flags = <token> <answer> MMC_RSP_SPI_R1; 
<token> = use_crc; <answer> cmd.arg 
err = <token> &cmd, 0); <answer> mmc_wait_for_cmd(host, 
<token> (!err) <answer> if 
<token> = use_crc; <answer> host->use_spi_crc 
return <token> <answer> err; 
static int mmc_switch_status_error(struct mmc_host <token> u32 status) <answer> *host, 
if (mmc_host_is_spi(host)) <token> <answer> { 
if (status <token> R1_SPI_ILLEGAL_COMMAND) <answer> & 
<token> -EBADMSG; <answer> return 
<token> else { <answer> } 
<token> (R1_STATUS(status)) <answer> if 
pr_warn("%s: unexpected status %#x <token> switch\n", <answer> after 
mmc_hostname(host), <token> <answer> status); 
if (status <token> R1_SWITCH_ERROR) <answer> & 
<token> -EBADMSG; <answer> return 
<token> 0; <answer> return 
expired = <token> timeout); <answer> time_after(jiffies, 
<token> = (*busy_cb)(cb_data, &busy); <answer> err 
<token> (err) <answer> if 
return <token> <answer> err; 
if (!(host->caps & MMC_CAP_NEED_RSP_BUSY) && <token> && <answer> host->max_busy_timeout 
<token> > host->max_busy_timeout)) { <answer> (timeout_ms 
cmd->flags = MMC_CMD_AC | MMC_RSP_SPI_R1 <token> MMC_RSP_R1; <answer> | 
<token> false; <answer> return 
cmd->flags <token> MMC_CMD_AC | MMC_RSP_SPI_R1B | MMC_RSP_R1B; <answer> = 
<token> = timeout_ms; <answer> cmd->busy_timeout 
return <token> <answer> true; 
int __mmc_switch(struct mmc_card *card, <token> set, u8 index, u8 value, <answer> u8 
unsigned int <token> unsigned char timing, <answer> timeout_ms, 
bool send_status, bool <token> unsigned int retries) <answer> retry_crc_err, 
struct mmc_host *host <token> card->host; <answer> = 
<token> err; <answer> int 
struct mmc_command <token> = {}; <answer> cmd 
bool <token> <answer> use_r1b_resp; 
unsigned char old_timing = <token> <answer> host->ios.timing; 
<token> (!timeout_ms) { <answer> if 
pr_warn("%s: unspecified timeout for CMD6 - <token> generic\n", <answer> use 
timeout_ms = <token> <answer> card->ext_csd.generic_cmd6_time; 
cmd.opcode = <token> <answer> MMC_SWITCH; 
cmd.arg <token> (MMC_SWITCH_MODE_WRITE_BYTE << 24) | <answer> = 
(index << 16) <token> <answer> | 
(value << <token> | <answer> 8) 
use_r1b_resp = mmc_prepare_busy_cmd(host, &cmd, <token> <answer> timeout_ms); 
err = <token> &cmd, retries); <answer> mmc_wait_for_cmd(host, 
<token> (err) <answer> if 
goto <token> <answer> out; 
if <token> && !host->ops->card_busy) { <answer> (!send_status 
goto <token> <answer> out_tim; 
data.timeout_ns <token> 150 * NSEC_PER_MSEC; <answer> = 
data.sg <token> &sg; <answer> = 
data.sg_len <token> 1; <answer> = 
<token> data_buf, size); <answer> sg_init_one(&sg, 
<token> &mrq); <answer> mmc_wait_for_req(host, 
<token> (cmd_error) <answer> if 
*cmd_error = <token> <answer> cmd.error; 
if (cmd.error) <token> <answer> { 
err = <token> <answer> cmd.error; 
goto <token> <answer> out; 
if (data.error) <token> <answer> { 
err <token> data.error; <answer> = 
<token> out; <answer> goto 
if <token> tuning_block_pattern, size)) <answer> (memcmp(data_buf, 
<token> = -EIO; <answer> err 
<token> err; <answer> return 
<token> mmc_send_abort_tuning(struct mmc_host *host, u32 opcode) <answer> int 
struct <token> cmd = {}; <answer> mmc_command 
if (opcode != <token> <answer> MMC_SEND_TUNING_BLOCK_HS200) 
<token> 0; <answer> return 
cmd.opcode <token> MMC_STOP_TRANSMISSION; <answer> = 
<token> = MMC_RSP_SPI_R1 | MMC_RSP_R1 | MMC_CMD_AC; <answer> cmd.flags 
cmd.busy_timeout <token> 150; <answer> = 
return mmc_wait_for_cmd(host, &cmd, <token> <answer> 0); 
<token> int <answer> static 
mmc_send_bus_test(struct mmc_card *card, struct <token> *host, u8 opcode, <answer> mmc_host 
u8 <token> <answer> len) 
struct mmc_request <token> = {}; <answer> mrq 
<token> mmc_command cmd = {}; <answer> struct 
struct mmc_data data = <token> <answer> {}; 
<token> scatterlist sg; <answer> struct 
u8 <token> <answer> *data_buf; 
u8 <token> <answer> *test_buf; 
int i, <token> <answer> err; 
static u8 testdata_8bit[8] <token> { 0x55, 0xaa, 0, 0, 0, 0, 0, 0 }; <answer> = 
static u8 testdata_4bit[4] = { 0x5a, 0, 0, <token> }; <answer> 0 
data_buf = kmalloc(len, <token> <answer> GFP_KERNEL); 
if <token> <answer> (!data_buf) 
<token> -ENOMEM; <answer> return 
if (len <token> 8) <answer> == 
test_buf <token> testdata_8bit; <answer> = 
else if (len <token> 4) <answer> == 
test_buf = <token> <answer> testdata_4bit; 
else <token> <answer> { 
<token> Invalid bus_width %d\n", <answer> pr_err("%s: 
<token> len); <answer> mmc_hostname(host), 
<token> -EINVAL; <answer> return 
<token> (opcode == MMC_BUS_TEST_W) <answer> if 
memcpy(data_buf, test_buf, <token> <answer> len); 
mrq.cmd = <token> <answer> &cmd; 
mrq.data <token> &data; <answer> = 
cmd.opcode = <token> <answer> opcode; 
cmd.arg <token> 0; <answer> = 
cmd.flags = MMC_RSP_SPI_R1 | <token> | MMC_CMD_ADTC; <answer> MMC_RSP_R1 
<token> = len; <answer> data.blksz 
data.blocks <token> 1; <answer> = 
if <token> == MMC_BUS_TEST_R) <answer> (opcode 
<token> = MMC_DATA_READ; <answer> data.flags 
data.flags = <token> <answer> MMC_DATA_WRITE; 
data.sg = <token> <answer> &sg; 
<token> = 1; <answer> data.sg_len 
<token> card); <answer> mmc_set_data_timeout(&data, 
sg_init_one(&sg, <token> len); <answer> data_buf, 
<token> &mrq); <answer> mmc_wait_for_req(host, 
<token> = 0; <answer> err 
if (opcode == <token> { <answer> MMC_BUS_TEST_R) 
for (i = 0; <token> < len / 4; i++) <answer> i 
if ((test_buf[i] ^ data_buf[i]) != <token> { <answer> 0xff) 
<token> = -EIO; <answer> err 
<token> (cmd.error) <answer> if 
<token> cmd.error; <answer> return 
if <token> <answer> (data.error) 
return <token> <answer> data.error; 
return <token> <answer> err; 
int mmc_bus_test(struct <token> *card, u8 bus_width) <answer> mmc_card 
<token> width; <answer> int 
if (bus_width <token> MMC_BUS_WIDTH_8) <answer> == 
width <token> 8; <answer> = 
else if <token> == MMC_BUS_WIDTH_4) <answer> (bus_width 
width <token> 4; <answer> = 
else <token> (bus_width == MMC_BUS_WIDTH_1) <answer> if 
mmc_send_bus_test(card, card->host, MMC_BUS_TEST_W, <token> <answer> width); 
return <token> card->host, MMC_BUS_TEST_R, width); <answer> mmc_send_bus_test(card, 
static int mmc_send_hpi_cmd(struct <token> *card) <answer> mmc_card 
unsigned int busy_timeout_ms = <token> <answer> card->ext_csd.out_of_int_time; 
struct <token> *host = card->host; <answer> mmc_host 
bool use_r1b_resp <token> false; <answer> = 
struct mmc_command <token> = {}; <answer> cmd 
int <token> <answer> err; 
cmd.opcode <token> card->ext_csd.hpi_cmd; <answer> = 
cmd.arg <token> card->rca << 16 | 1; <answer> = 
<token> = MMC_RSP_R1 | MMC_CMD_AC; <answer> cmd.flags 
<token> (cmd.opcode == MMC_STOP_TRANSMISSION) <answer> if 
use_r1b_resp = mmc_prepare_busy_cmd(host, <token> <answer> &cmd, 
err = mmc_wait_for_cmd(host, <token> 0); <answer> &cmd, 
if <token> { <answer> (err) 
pr_warn("%s: HPI <token> %d. Command response %#x\n", <answer> error 
mmc_hostname(host), <token> cmd.resp[0]); <answer> err, 
<token> err; <answer> return 
static int <token> mmc_card *card) <answer> mmc_interrupt_hpi(struct 
int <token> <answer> err; 
<token> status; <answer> u32 
if (!card->ext_csd.hpi_en) <token> <answer> { 
<token> HPI enable bit unset\n", mmc_hostname(card->host)); <answer> pr_info("%s: 
<token> 1; <answer> return 
<token> = mmc_send_status(card, &status); <answer> err 
if (err) <token> <answer> { 
pr_err("%s: Get card status fail\n", <token> <answer> mmc_hostname(card->host)); 
goto <token> <answer> out; 
<token> (R1_CURRENT_STATE(status)) { <answer> switch 
case <token> <answer> R1_STATE_IDLE: 
<token> R1_STATE_READY: <answer> case 
case <token> <answer> R1_STATE_STBY: 
<token> R1_STATE_TRAN: <answer> case 
<token> out; <answer> goto 
<token> R1_STATE_PRG: <answer> case 
void <token> mmc_card *card) <answer> mmc_run_bkops(struct 
int <token> <answer> err; 
<token> (!card->ext_csd.man_bkops_en) <answer> if 
err = <token> <answer> mmc_read_bkops_status(card); 
if <token> { <answer> (err) 
pr_err("%s: Failed to read bkops <token> %d\n", <answer> status: 
<token> err); <answer> mmc_hostname(card->host), 
<token> (!card->ext_csd.raw_bkops_status || <answer> if 
<token> < EXT_CSD_BKOPS_LEVEL_2) <answer> card->ext_csd.raw_bkops_status 
err = mmc_switch(card, <token> <answer> EXT_CSD_CMD_SET_NORMAL, 
EXT_CSD_BKOPS_START, <token> MMC_BKOPS_TIMEOUT_MS); <answer> 1, 
if (err == <token> && !mmc_interrupt_hpi(card)) <answer> -ETIMEDOUT 
pr_warn("%s: BKOPS aborted\n", <token> <answer> mmc_hostname(card->host)); 
else if <token> <answer> (err) 
<token> Error %d running bkops\n", <answer> pr_warn("%s: 
mmc_hostname(card->host), <token> <answer> err); 
static int mmc_cmdq_switch(struct mmc_card *card, <token> enable) <answer> bool 
u8 val = enable <token> EXT_CSD_CMDQ_MODE_ENABLED : 0; <answer> ? 
<token> err; <answer> int 
<token> (!card->ext_csd.cmdq_support) <answer> if 
return <token> <answer> -EOPNOTSUPP; 
err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL, <token> <answer> EXT_CSD_CMDQ_MODE_EN, 
<token> card->ext_csd.generic_cmd6_time); <answer> val, 
<token> (!err) <answer> if 
<token> = enable; <answer> card->ext_csd.cmdq_en 
return <token> <answer> err; 
int mmc_cmdq_enable(struct mmc_card <token> <answer> *card) 
<token> mmc_cmdq_switch(card, true); <answer> return 
int mmc_cmdq_disable(struct <token> *card) <answer> mmc_card 
return <token> false); <answer> mmc_cmdq_switch(card, 
int mmc_sanitize(struct <token> *card, unsigned int timeout_ms) <answer> mmc_card 
<token> mmc_host *host = card->host; <answer> struct 
<token> err; <answer> int 
<token> (!mmc_can_sanitize(card)) { <answer> if 
pr_warn("%s: Sanitize not supported\n", <token> <answer> mmc_hostname(host)); 
return <token> <answer> -EOPNOTSUPP; 
if <token> <answer> (!timeout_ms) 
timeout_ms = <token> <answer> MMC_SANITIZE_TIMEOUT_MS; 
pr_debug("%s: Sanitize <token> progress...\n", mmc_hostname(host)); <answer> in 
<token> = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL, EXT_CSD_SANITIZE_START, <answer> err 
1, timeout_ms, <token> true, false, 0); <answer> 0, 
<token> (err) <answer> if 
pr_err("%s: Sanitize failed err=%d\n", mmc_hostname(host), <token> <answer> err); 
if (err <token> -ETIMEDOUT && !mmc_interrupt_hpi(card)) <answer> == 
<token> Sanitize aborted\n", mmc_hostname(host)); <answer> pr_warn("%s: 
pr_debug("%s: <token> completed\n", mmc_hostname(host)); <answer> Sanitize 
return <token> <answer> err; 
<token> "mt76x2u.h" <answer> #include 
#include <token> <answer> "eeprom.h" 
<token> void mt76x2u_mac_fixup_xtal(struct mt76x02_dev *dev) <answer> static 
s8 offset = <token> <answer> 0; 
<token> eep_val; <answer> u16 
<token> = mt76x02_eeprom_get(dev, MT_EE_XTAL_TRIM_2); <answer> eep_val 
offset = eep_val <token> 0x7f; <answer> & 
if <token> & 0xff) == 0xff) <answer> ((eep_val 
offset <token> 0; <answer> = 
else if (eep_val <token> 0x80) <answer> & 
<token> = 0 - offset; <answer> offset 
eep_val <token> 8; <answer> >>= 
if (eep_val == 0x00 || eep_val <token> 0xff) { <answer> == 
eep_val = mt76x02_eeprom_get(dev, <token> <answer> MT_EE_XTAL_TRIM_1); 
eep_val <token> 0xff; <answer> &= 
if (eep_val == 0x00 || eep_val <token> 0xff) <answer> == 
eep_val = <token> <answer> 0x14; 
eep_val &= <token> <answer> 0x7f; 
mt76_rmw_field(dev, MT_VEND_ADDR(CFG, <token> <answer> MT_XO_CTRL5), 
MT_XO_CTRL5_C2_VAL, <token> + offset); <answer> eep_val 
mt76_set(dev, MT_VEND_ADDR(CFG, <token> MT_XO_CTRL6_C2_CTRL); <answer> MT_XO_CTRL6), 
<token> 0x504, 0x06000000); <answer> mt76_wr(dev, 
mt76_wr(dev, <token> 0x08800000); <answer> 0x50c, 
mt76_wr(dev, 0x504, <token> <answer> 0x0); 
<token> <linux/export.h> <answer> #include 
<token> <linux/security.h> <answer> #include 
#include <token> <answer> "internal.h" 
int <token> key_ref_t key_ref, const struct cred *cred, <answer> key_task_permission(const 
enum key_need_perm <token> <answer> need_perm) 
<token> key *key; <answer> struct 
key_perm_t <token> mask; <answer> kperm, 
int <token> <answer> ret; 
<token> (need_perm) { <answer> switch 
return <token> <answer> -EACCES; 
<token> KEY_NEED_UNLINK: <answer> case 
case <token> <answer> KEY_SYSADMIN_OVERRIDE: 
<token> KEY_AUTHTOKEN_OVERRIDE: <answer> case 
<token> KEY_DEFER_PERM_CHECK: <answer> case 
goto <token> <answer> lsm; 
case KEY_NEED_VIEW: mask <token> KEY_OTH_VIEW; break; <answer> = 
case KEY_NEED_READ: mask = KEY_OTH_READ; <token> <answer> break; 
case KEY_NEED_WRITE: mask = <token> break; <answer> KEY_OTH_WRITE; 
<token> KEY_NEED_SEARCH: mask = KEY_OTH_SEARCH; break; <answer> case 
case <token> mask = KEY_OTH_LINK; break; <answer> KEY_NEED_LINK: 
case <token> mask = KEY_OTH_SETATTR; break; <answer> KEY_NEED_SETATTR: 
key = <token> <answer> key_ref_to_ptr(key_ref); 
if (gid_valid(key->gid) && key->perm & <token> { <answer> KEY_GRP_ALL) 
if (gid_eq(key->gid, cred->fsgid)) <token> <answer> { 
kperm = <token> >> 8; <answer> key->perm 
goto <token> <answer> use_these_perms; 
ret <token> groups_search(cred->group_info, key->gid); <answer> = 
if (ret) <token> <answer> { 
kperm = key->perm >> <token> <answer> 8; 
<token> use_these_perms; <answer> goto 
if <token> <answer> (is_key_possessed(key_ref)) 
kperm |= key->perm <token> 24; <answer> >> 
if ((kperm & <token> != mask) <answer> mask) 
return <token> <answer> -EACCES; 
int key_validate(const struct <token> *key) <answer> key 
unsigned long <token> = READ_ONCE(key->flags); <answer> flags 
time64_t expiry = <token> <answer> READ_ONCE(key->expiry); 
<token> (flags & (1 << KEY_FLAG_INVALIDATED)) <answer> if 
return <token> <answer> -ENOKEY; 
<token> int nv3Busy <answer> static 
<token> *chip <answer> RIVA_HW_INST 
return ((NV_RD32(&chip->Rop->FifoFree, 0) < <token> || <answer> chip->FifoEmptyCount) 
NV_RD32(&chip->PGRAPH[0x000006B0/4], 0) <token> 0x01); <answer> & 
static int <token> <answer> nv4Busy 
<token> *chip <answer> RIVA_HW_INST 
return ((NV_RD32(&chip->Rop->FifoFree, 0) < <token> || <answer> chip->FifoEmptyCount) 
<token> 0) & 0x01); <answer> NV_RD32(&chip->PGRAPH[0x00000700/4], 
static int <token> <answer> nv10Busy 
<token> *chip <answer> RIVA_HW_INST 
return ((NV_RD32(&chip->Rop->FifoFree, 0) <token> chip->FifoEmptyCount) || <answer> < 
NV_RD32(&chip->PGRAPH[0x00000700/4], 0) <token> 0x01); <answer> & 
<token> void vgaLockUnlock <answer> static 
<token> *chip, <answer> RIVA_HW_INST 
int <token> <answer> Lock 
<token> cr11; <answer> U008 
VGA_WR08(chip->PCIO, 0x3D4, <token> <answer> 0x11); 
cr11 = VGA_RD08(chip->PCIO, <token> <answer> 0x3D5); 
if(Lock) <token> |= 0x80; <answer> cr11 
<token> cr11 &= ~0x80; <answer> else 
VGA_WR08(chip->PCIO, 0x3D5, <token> <answer> cr11); 
static void <token> <answer> nv3LockUnlock 
<token> *chip, <answer> RIVA_HW_INST 
int <token> <answer> Lock 
VGA_WR08(chip->PVIO, <token> 0x06); <answer> 0x3C4, 
VGA_WR08(chip->PVIO, 0x3C5, Lock <token> 0x99 : 0x57); <answer> ? 
vgaLockUnlock(chip, <token> <answer> Lock); 
static void <token> <answer> nv4LockUnlock 
<token> *chip, <answer> RIVA_HW_INST 
int <token> <answer> Lock 
VGA_WR08(chip->PCIO, <token> 0x1F); <answer> 0x3D4, 
VGA_WR08(chip->PCIO, <token> Lock ? 0x99 : 0x57); <answer> 0x3D5, 
<token> Lock); <answer> vgaLockUnlock(chip, 
static <token> ShowHideCursor <answer> int 
<token> *chip, <answer> RIVA_HW_INST 
int <token> <answer> ShowHide 
<token> cursor; <answer> int 
cursor = <token> <answer> chip->CurrentState->cursor1; 
chip->CurrentState->cursor1 = (chip->CurrentState->cursor1 & <token> | <answer> 0xFE) 
<token> & 0x01); <answer> (ShowHide 
VGA_WR08(chip->PCIO, <token> 0x31); <answer> 0x3D4, 
<token> 0x3D5, chip->CurrentState->cursor1); <answer> VGA_WR08(chip->PCIO, 
return <token> & 0x01); <answer> (cursor 
#define <token> 100 <answer> DEFAULT_GR_LWM 
#define DEFAULT_VID_LWM <token> <answer> 100 
#define <token> 256 <answer> DEFAULT_GR_BURST_SIZE 
<token> DEFAULT_VID_BURST_SIZE 128 <answer> #define 
#define <token> 0 <answer> VIDEO 
#define <token> 1 <answer> GRAPHICS 
#define <token> 2 <answer> MPORT 
#define ENGINE <token> <answer> 3 
#define GFIFO_SIZE <token> <answer> 320 
<token> GFIFO_SIZE_128 256 <answer> #define 
<token> MFIFO_SIZE 120 <answer> #define 
<token> VFIFO_SIZE 256 <answer> #define 
<token> struct { <answer> typedef 
int <token> <answer> gdrain_rate; 
<token> vdrain_rate; <answer> int 
<token> mdrain_rate; <answer> int 
int <token> <answer> gburst_size; 
<token> vburst_size; <answer> int 
<token> vid_en; <answer> char 
<token> gr_en; <answer> char 
int wcmocc, wcgocc, wcvocc, wcvlwm, <token> <answer> wcglwm; 
int <token> <answer> by_gfacc; 
<token> vid_only_once; <answer> char 
char <token> <answer> gr_only_once; 
char <token> <answer> first_vacc; 
char <token> <answer> first_gacc; 
<token> first_macc; <answer> char 
int <token> <answer> vocc; 
int <token> <answer> gocc; 
int <token> <answer> mocc; 
char <token> <answer> cur; 
<token> engine_en; <answer> char 
char <token> <answer> converged; 
int <token> <answer> priority; 
<token> nv3_arb_info; <answer> } 
typedef <token> { <answer> struct 
int <token> <answer> graphics_lwm; 
<token> video_lwm; <answer> int 
int <token> <answer> graphics_burst_size; 
int <token> <answer> video_burst_size; 
<token> graphics_hi_priority; <answer> int 
int <token> <answer> media_hi_priority; 
<token> rtl_values; <answer> int 
<token> valid; <answer> int 
<token> nv3_fifo_info; <answer> } 
typedef <token> { <answer> struct 
char <token> <answer> pix_bpp; 
<token> enable_video; <answer> char 
<token> gr_during_vid; <answer> char 
char <token> <answer> enable_mp; 
<token> memory_width; <answer> int 
int <token> <answer> video_scale; 
<token> pclk_khz; <answer> int 
<token> mclk_khz; <answer> int 
int <token> <answer> mem_page_miss; 
int <token> <answer> mem_latency; 
char <token> <answer> mem_aligned; 
} <token> <answer> nv3_sim_state; 
typedef <token> { <answer> struct 
int <token> <answer> graphics_lwm; 
int <token> <answer> video_lwm; 
int <token> <answer> graphics_burst_size; 
<token> video_burst_size; <answer> int 
<token> valid; <answer> int 
<token> nv4_fifo_info; <answer> } 
typedef struct <token> <answer> { 
int <token> <answer> pclk_khz; 
<token> mclk_khz; <answer> int 
int <token> <answer> nvclk_khz; 
<token> mem_page_miss; <answer> char 
char <token> <answer> mem_latency; 
int <token> <answer> memory_width; 
<token> enable_video; <answer> char 
<token> gr_during_vid; <answer> char 
<token> pix_bpp; <answer> char 
<token> mem_aligned; <answer> char 
char <token> <answer> enable_mp; 
<token> nv4_sim_state; <answer> } 
<token> struct { <answer> typedef 
<token> graphics_lwm; <answer> int 
int <token> <answer> video_lwm; 
<token> graphics_burst_size; <answer> int 
int <token> <answer> video_burst_size; 
<token> valid; <answer> int 
} <token> <answer> nv10_fifo_info; 
typedef struct <token> <answer> { 
int <token> <answer> pclk_khz; 
<token> mclk_khz; <answer> int 
<token> nvclk_khz; <answer> int 
char <token> <answer> mem_page_miss; 
<token> mem_latency; <answer> char 
<token> memory_type; <answer> u32 
int <token> <answer> memory_width; 
char <token> <answer> enable_video; 
char <token> <answer> gr_during_vid; 
char <token> <answer> pix_bpp; 
char <token> <answer> mem_aligned; 
char <token> <answer> enable_mp; 
} <token> <answer> nv10_sim_state; 
static int nv3_iterate(nv3_fifo_info *res_info, nv3_sim_state * state, <token> *ainfo) <answer> nv3_arb_info 
int <token> = 0; <answer> iter 
int <token> <answer> tmp; 
<token> vfsize, mfsize, gfsize; <answer> int 
int mburst_size = <token> <answer> 32; 
<token> mmisses, gmisses, vmisses; <answer> int 
<token> misses; <answer> int 
<token> vlwm, glwm; <answer> int 
int <token> next, cur; <answer> last, 
int max_gfsize <token> <answer> ; 
long <token> <answer> ns; 
vlwm = <token> <answer> 0; 
glwm = <token> <answer> 0; 
vfsize = <token> <answer> 0; 
gfsize <token> 0; <answer> = 
<token> = ainfo->cur; <answer> cur 
mmisses = <token> <answer> 2; 
gmisses = <token> <answer> 2; 
vmisses = <token> <answer> 2; 
if (ainfo->gburst_size == 128) max_gfsize <token> GFIFO_SIZE_128; <answer> = 
else max_gfsize = <token> <answer> GFIFO_SIZE; 
<token> = GFIFO_SIZE; <answer> max_gfsize 
<token> (1) <answer> while 
if <token> <answer> (ainfo->vid_en) 
<token> (ainfo->wcvocc > ainfo->vocc) ainfo->wcvocc = ainfo->vocc; <answer> if 
if (ainfo->wcvlwm > vlwm) ainfo->wcvlwm = <token> ; <answer> vlwm 
ns <token> 1000000 * ainfo->vburst_size/(state->memory_width/8)/state->mclk_khz; <answer> = 
<token> = ns * ainfo->vdrain_rate / 1000000; <answer> vfsize 
vfsize = <token> - ainfo->vburst_size + vfsize; <answer> ainfo->wcvlwm 
<token> (state->enable_mp) <answer> if 
if (ainfo->wcmocc <token> ainfo->mocc) ainfo->wcmocc = ainfo->mocc; <answer> > 
if <token> <answer> (ainfo->gr_en) 
<token> (ainfo->wcglwm > glwm) ainfo->wcglwm = glwm ; <answer> if 
if (ainfo->wcgocc > <token> ainfo->wcgocc = ainfo->gocc; <answer> ainfo->gocc) 
ns = 1000000 * <token> <answer> (ainfo->gburst_size/(state->memory_width/8))/state->mclk_khz; 
gfsize = (ns * <token> ainfo->gdrain_rate)/1000000; <answer> (long) 
<token> = ainfo->wcglwm - ainfo->gburst_size + gfsize; <answer> gfsize 
<token> = 0; <answer> mfsize 
if <token> && ainfo->vid_en) <answer> (!state->gr_during_vid 
if (ainfo->vid_en <token> (ainfo->vocc < 0) && !ainfo->vid_only_once) <answer> && 
next = <token> <answer> VIDEO; 
<token> if (ainfo->mocc < 0) <answer> else 
next <token> MPORT; <answer> = 
else <token> (ainfo->gocc< ainfo->by_gfacc) <answer> if 
next = <token> <answer> GRAPHICS; 
<token> return (0); <answer> else 
else switch <token> <answer> (ainfo->priority) 
case <token> <answer> VIDEO: 
if <token> && ainfo->vocc<0 && !ainfo->vid_only_once) <answer> (ainfo->vid_en 
next = <token> <answer> VIDEO; 
else if (ainfo->gr_en && <token> && !ainfo->gr_only_once) <answer> ainfo->gocc<0 
<token> = GRAPHICS; <answer> next 
<token> if (ainfo->mocc<0) <answer> else 
<token> = MPORT; <answer> next 
else <token> (0); <answer> return 
case <token> <answer> GRAPHICS: 
if <token> && ainfo->gocc<0 && !ainfo->gr_only_once) <answer> (ainfo->gr_en 
<token> = GRAPHICS; <answer> next 
else if (ainfo->vid_en && <token> && !ainfo->vid_only_once) <answer> ainfo->vocc<0 
next = <token> <answer> VIDEO; 
<token> if (ainfo->mocc<0) <answer> else 
next <token> MPORT; <answer> = 
<token> return (0); <answer> else 
<token> (ainfo->mocc<0) <answer> if 
next = <token> <answer> MPORT; 
else if (ainfo->gr_en && ainfo->gocc<0 && <token> <answer> !ainfo->gr_only_once) 
<token> = GRAPHICS; <answer> next 
else if (ainfo->vid_en && ainfo->vocc<0 && <token> <answer> !ainfo->vid_only_once) 
next = <token> <answer> VIDEO; 
else return <token> <answer> (0); 
<token> = cur; <answer> last 
<token> = next; <answer> cur 
switch <token> <answer> (cur) 
<token> VIDEO: <answer> case 
if (last==cur) misses <token> 0; <answer> = 
<token> if (ainfo->first_vacc) misses = vmisses; <answer> else 
<token> misses = 1; <answer> else 
ainfo->first_vacc <token> 0; <answer> = 
if <token> <answer> (last!=cur) 
ns = 1000000 * (vmisses*state->mem_page_miss <token> state->mem_latency)/state->mclk_khz; <answer> + 
vlwm <token> ns * ainfo->vdrain_rate/ 1000000; <answer> = 
vlwm = ainfo->vocc <token> vlwm; <answer> - 
ns <token> 1000000*(misses*state->mem_page_miss + ainfo->vburst_size)/(state->memory_width/8)/state->mclk_khz; <answer> = 
ainfo->vocc <token> ainfo->vocc + ainfo->vburst_size - ns*ainfo->vdrain_rate/1000000; <answer> = 
ainfo->gocc = ainfo->gocc - <token> <answer> ns*ainfo->gdrain_rate/1000000; 
ainfo->mocc = ainfo->mocc <token> ns*ainfo->mdrain_rate/1000000; <answer> - 
case <token> <answer> GRAPHICS: 
<token> (last==cur) misses = 0; <answer> if 
<token> if (ainfo->first_gacc) misses = gmisses; <answer> else 
else misses <token> 1; <answer> = 
ainfo->first_gacc = <token> <answer> 0; 
<token> (last!=cur) <answer> if 
ns = 1000000*(gmisses*state->mem_page_miss <token> state->mem_latency)/state->mclk_khz ; <answer> + 
glwm <token> ns * ainfo->gdrain_rate/1000000; <answer> = 
glwm <token> ainfo->gocc - glwm; <answer> = 
<token> = 1000000*(misses*state->mem_page_miss + ainfo->gburst_size/(state->memory_width/8))/state->mclk_khz; <answer> ns 
ainfo->vocc = ainfo->vocc <token> 0 - ns*ainfo->vdrain_rate/1000000; <answer> + 
ainfo->gocc = ainfo->gocc + ainfo->gburst_size - <token> <answer> ns*ainfo->gdrain_rate/1000000; 
ainfo->mocc = <token> + 0 - ns*ainfo->mdrain_rate/1000000; <answer> ainfo->mocc 
if (last==cur) misses <token> 0; <answer> = 
<token> if (ainfo->first_macc) misses = mmisses; <answer> else 
else misses = <token> <answer> 1; 
<token> = 0; <answer> ainfo->first_macc 
ns = <token> + mburst_size/(state->memory_width/8))/state->mclk_khz; <answer> 1000000*(misses*state->mem_page_miss 
<token> = ainfo->vocc + 0 - ns*ainfo->vdrain_rate/1000000; <answer> ainfo->vocc 
<token> = ainfo->gocc + 0 - ns*ainfo->gdrain_rate/1000000; <answer> ainfo->gocc 
ainfo->mocc <token> ainfo->mocc + mburst_size - ns*ainfo->mdrain_rate/1000000; <answer> = 
if <token> <answer> (iter>100) 
<token> = 0; <answer> ainfo->converged 
return <token> <answer> (1); 
ns <token> 1000000*ainfo->gburst_size/(state->memory_width/8)/state->mclk_khz; <answer> = 
<token> = ns * ainfo->gdrain_rate/1000000; <answer> tmp 
<token> (abs(ainfo->gburst_size) + ((abs(ainfo->wcglwm) + 16 ) & ~0x7) - tmp > max_gfsize) <answer> if 
<token> = 0; <answer> ainfo->converged 
<token> (1); <answer> return 
<token> = 1000000*ainfo->vburst_size/(state->memory_width/8)/state->mclk_khz; <answer> ns 
tmp <token> ns * ainfo->vdrain_rate/1000000; <answer> = 
if (abs(ainfo->vburst_size) + (abs(ainfo->wcvlwm + 32) <token> ~0xf) - tmp> VFIFO_SIZE) <answer> & 
ainfo->converged <token> 0; <answer> = 
<token> (1); <answer> return 
<token> (abs(ainfo->gocc) > max_gfsize) <answer> if 
<token> = 0; <answer> ainfo->converged 
<token> (1); <answer> return 
<token> (abs(ainfo->vocc) > VFIFO_SIZE) <answer> if 
ainfo->converged = <token> <answer> 0; 
return <token> <answer> (1); 
if (abs(ainfo->mocc) <token> MFIFO_SIZE) <answer> > 
ainfo->converged = <token> <answer> 0; 
<token> (1); <answer> return 
if <token> > VFIFO_SIZE) <answer> (abs(vfsize) 
ainfo->converged = <token> <answer> 0; 
return <token> <answer> (1); 
if (abs(gfsize) <token> max_gfsize) <answer> > 
ainfo->converged = <token> <answer> 0; 
<token> (1); <answer> return 
<token> (abs(mfsize) > MFIFO_SIZE) <answer> if 
<token> = 0; <answer> ainfo->converged 
<token> (1); <answer> return 
static char nv3_arb(nv3_fifo_info * res_info, nv3_sim_state * <token> nv3_arb_info *ainfo) <answer> state, 
long <token> vns, mns, gns; <answer> ens, 
int mmisses, <token> vmisses, eburst_size, mburst_size; <answer> gmisses, 
<token> refresh_cycle; <answer> int 
refresh_cycle = 2*(state->mclk_khz/state->pclk_khz) <token> 5; <answer> + 
<token> = 2; <answer> mmisses 
<token> (state->mem_aligned) gmisses = 2; <answer> if 
else gmisses = <token> <answer> 3; 
vmisses <token> 2; <answer> = 
<token> = state->memory_width * 1; <answer> eburst_size 
<token> = 32; <answer> mburst_size 
<token> = 1000000 * (gmisses*state->mem_page_miss + state->mem_latency)/state->mclk_khz; <answer> gns 
ainfo->by_gfacc = <token> <answer> gns*ainfo->gdrain_rate/1000000; 
ainfo->wcmocc = <token> <answer> 0; 
ainfo->wcgocc <token> 0; <answer> = 
<token> = 0; <answer> ainfo->wcvocc 
ainfo->wcvlwm <token> 0; <answer> = 
ainfo->wcglwm = <token> <answer> 0; 
ainfo->engine_en = <token> <answer> 1; 
ainfo->converged = <token> <answer> 1; 
if <token> <answer> (ainfo->engine_en) 
<token> = 1000000*(state->mem_page_miss + eburst_size/(state->memory_width/8) +refresh_cycle)/state->mclk_khz; <answer> ens 
ainfo->mocc = <token> ? 0-ens*ainfo->mdrain_rate/1000000 : 0; <answer> state->enable_mp 
ainfo->vocc = ainfo->vid_en ? 0-ens*ainfo->vdrain_rate/1000000 <token> 0; <answer> : 
ainfo->gocc = ainfo->gr_en ? 0-ens*ainfo->gdrain_rate/1000000 : <token> <answer> 0; 
ainfo->cur = <token> <answer> ENGINE; 
<token> = 1; <answer> ainfo->first_vacc 
ainfo->first_gacc = <token> <answer> 1; 
ainfo->first_macc = <token> <answer> 1; 
nv3_iterate(res_info, <token> <answer> state,ainfo); 
if <token> <answer> (state->enable_mp) 
mns = 1000000 * (mmisses*state->mem_page_miss + <token> + refresh_cycle)/state->mclk_khz; <answer> mburst_size/(state->memory_width/8) 
ainfo->mocc = state->enable_mp ? 0 <token> mburst_size - mns*ainfo->mdrain_rate/1000000; <answer> : 
ainfo->vocc = ainfo->vid_en <token> 0 : 0- mns*ainfo->vdrain_rate/1000000; <answer> ? 
ainfo->gocc = ainfo->gr_en ? 0: <token> mns*ainfo->gdrain_rate/1000000; <answer> 0- 
<token> = MPORT; <answer> ainfo->cur 
<token> = 1; <answer> ainfo->first_vacc 
ainfo->first_gacc = <token> <answer> 1; 
ainfo->first_macc <token> 0; <answer> = 
nv3_iterate(res_info, <token> <answer> state,ainfo); 
<token> (ainfo->gr_en) <answer> if 
ainfo->first_vacc <token> 1; <answer> = 
<token> = 0; <answer> ainfo->first_gacc 
ainfo->first_macc <token> 1; <answer> = 
<token> = 1000000*(gmisses*state->mem_page_miss + ainfo->gburst_size/(state->memory_width/8) + refresh_cycle)/state->mclk_khz; <answer> gns 
ainfo->gocc = ainfo->gburst_size - <token> <answer> gns*ainfo->gdrain_rate/1000000; 
ainfo->vocc = ainfo->vid_en? <token> : 0; <answer> 0-gns*ainfo->vdrain_rate/1000000 
ainfo->mocc = state->enable_mp <token> 0-gns*ainfo->mdrain_rate/1000000: 0; <answer> ? 
<token> = GRAPHICS; <answer> ainfo->cur 
nv3_iterate(res_info, <token> <answer> state,ainfo); 
<token> (ainfo->vid_en) <answer> if 
<token> = 0; <answer> ainfo->first_vacc 
<token> = 1; <answer> ainfo->first_gacc 
ainfo->first_macc = <token> <answer> 1; 
<token> = 1000000*(vmisses*state->mem_page_miss + ainfo->vburst_size/(state->memory_width/8) + refresh_cycle)/state->mclk_khz; <answer> vns 
ainfo->vocc <token> ainfo->vburst_size - vns*ainfo->vdrain_rate/1000000; <answer> = 
ainfo->gocc = ainfo->gr_en? <token> : 0; <answer> (0-vns*ainfo->gdrain_rate/1000000) 
ainfo->mocc = state->enable_mp? <token> :0 ; <answer> 0-vns*ainfo->mdrain_rate/1000000 
<token> = VIDEO; <answer> ainfo->cur 
<token> state, ainfo); <answer> nv3_iterate(res_info, 
<token> (ainfo->converged) <answer> if 
res_info->graphics_lwm = (int)abs(ainfo->wcglwm) <token> 16; <answer> + 
res_info->video_lwm <token> (int)abs(ainfo->wcvlwm) + 32; <answer> = 
<token> = ainfo->gburst_size; <answer> res_info->graphics_burst_size 
res_info->video_burst_size <token> ainfo->vburst_size; <answer> = 
res_info->graphics_hi_priority = <token> == GRAPHICS); <answer> (ainfo->priority 
res_info->media_hi_priority = (ainfo->priority <token> MPORT); <answer> == 
if (res_info->video_lwm <token> 160) <answer> > 
res_info->graphics_lwm = <token> <answer> 256; 
res_info->video_lwm <token> 128; <answer> = 
res_info->graphics_burst_size <token> 64; <answer> = 
res_info->video_burst_size <token> 64; <answer> = 
<token> = 0; <answer> res_info->graphics_hi_priority 
res_info->media_hi_priority <token> 0; <answer> = 
ainfo->converged <token> 0; <answer> = 
return <token> <answer> (0); 
if (res_info->video_lwm > <token> <answer> 128) 
res_info->video_lwm = <token> <answer> 128; 
<token> (1); <answer> return 
res_info->graphics_lwm <token> 256; <answer> = 
<token> = 128; <answer> res_info->video_lwm 
<token> = 64; <answer> res_info->graphics_burst_size 
<token> = 64; <answer> res_info->video_burst_size 
res_info->graphics_hi_priority = <token> <answer> 0; 
res_info->media_hi_priority <token> 0; <answer> = 
<token> (0); <answer> return 
static char nv3_get_param(nv3_fifo_info *res_info, nv3_sim_state <token> state, nv3_arb_info *ainfo) <answer> * 
int <token> g,v, p; <answer> done, 
done <token> 0; <answer> = 
for (p=0; <token> < 2; p++) <answer> p 
for <token> ; g > 32; g= g>> 1) <answer> (g=128 
for <token> v >=32; v = v>> 1) <answer> (v=128; 
<token> = p; <answer> ainfo->priority 
<token> = g; <answer> ainfo->gburst_size 
ainfo->vburst_size = <token> <answer> v; 
done = <token> state,ainfo); <answer> nv3_arb(res_info, 
if (done <token> (g==128)) <answer> && 
if ((res_info->graphics_lwm <token> g) > 256) <answer> + 
<token> = 0; <answer> done 
if <token> <answer> (done) 
<token> Done; <answer> goto 
return <token> <answer> done; 
static void <token> <answer> nv3CalcArbitration 
<token> * res_info, <answer> nv3_fifo_info 
<token> * state <answer> nv3_sim_state 
nv3_fifo_info <token> <answer> save_info; 
nv3_arb_info <token> <answer> ainfo; 
char res_gr, <token> <answer> res_vid; 
ainfo.gr_en = <token> <answer> 1; 
ainfo.vid_en = <token> <answer> state->enable_video; 
ainfo.vid_only_once = <token> <answer> 0; 
ainfo.gr_only_once <token> 0; <answer> = 
ainfo.gdrain_rate = (int) state->pclk_khz * <token> <answer> (state->pix_bpp/8); 
ainfo.vdrain_rate = (int) state->pclk_khz <token> 2; <answer> * 
if <token> != 0) <answer> (state->video_scale 
ainfo.vdrain_rate = <token> <answer> ainfo.vdrain_rate/state->video_scale; 
ainfo.mdrain_rate <token> 33000; <answer> = 
res_info->rtl_values = <token> <answer> 0; 
<token> (!state->gr_during_vid && state->enable_video) <answer> if 
ainfo.gr_only_once <token> 1; <answer> = 
ainfo.gr_en = <token> <answer> 1; 
ainfo.gdrain_rate <token> 0; <answer> = 
res_vid = nv3_get_param(res_info, <token> &ainfo); <answer> state, 
res_vid <token> ainfo.converged; <answer> = 
<token> = res_info->video_lwm; <answer> save_info.video_lwm 
save_info.video_burst_size = <token> <answer> res_info->video_burst_size; 
ainfo.vid_en = <token> <answer> 1; 
ainfo.vid_only_once <token> 1; <answer> = 
ainfo.gr_en <token> 1; <answer> = 
<token> = (int) state->pclk_khz * (state->pix_bpp/8); <answer> ainfo.gdrain_rate 
ainfo.vdrain_rate <token> 0; <answer> = 
<token> = nv3_get_param(res_info, state, &ainfo); <answer> res_gr 
res_gr <token> ainfo.converged; <answer> = 
<token> = save_info.video_lwm; <answer> res_info->video_lwm 
res_info->video_burst_size = <token> <answer> save_info.video_burst_size; 
res_info->valid = <token> & res_vid; <answer> res_gr 
if <token> ainfo.gdrain_rate = 0; <answer> (!ainfo.gr_en) 
if <token> ainfo.vdrain_rate = 0; <answer> (!ainfo.vid_en) 
<token> = nv3_get_param(res_info, state, &ainfo); <answer> res_gr 
<token> = ainfo.converged; <answer> res_info->valid 
static <token> nv3UpdateArbitrationSettings <answer> void 
<token> VClk, <answer> unsigned 
<token> pixelDepth, <answer> unsigned 
unsigned <token> <answer> *burst, 
<token> *lwm, <answer> unsigned 
<token> *chip <answer> RIVA_HW_INST 
nv3_fifo_info <token> <answer> fifo_data; 
nv3_sim_state <token> <answer> sim_data; 
unsigned int M, N, <token> pll, MClk; <answer> P, 
pll <token> NV_RD32(&chip->PRAMDAC0[0x00000504/4], 0); <answer> = 
M = (pll >> 0) & 0xFF; N = (pll >> 8) <token> 0xFF; P = (pll >> 16) & 0x0F; <answer> & 
MClk = (N * chip->CrystalFreqKHz / <token> >> P; <answer> M) 
sim_data.pix_bpp = <token> <answer> (char)pixelDepth; 
sim_data.enable_video <token> 0; <answer> = 
sim_data.enable_mp = <token> <answer> 0; 
<token> = 1; <answer> sim_data.video_scale 
sim_data.memory_width = <token> 0) & 0x10) ? <answer> (NV_RD32(&chip->PEXTDEV[0x00000000/4], 
128 : <token> <answer> 64; 
sim_data.memory_width = <token> <answer> 128; 
sim_data.mem_latency = <token> <answer> 9; 
<token> = 1; <answer> sim_data.mem_aligned 
sim_data.mem_page_miss <token> 11; <answer> = 
sim_data.gr_during_vid <token> 0; <answer> = 
<token> = VClk; <answer> sim_data.pclk_khz 
<token> = MClk; <answer> sim_data.mclk_khz 
nv3CalcArbitration(&fifo_data, <token> <answer> &sim_data); 
if <token> <answer> (fifo_data.valid) 
<token> b = fifo_data.graphics_burst_size >> 4; <answer> int 
*burst = <token> <answer> 0; 
while (b <token> 1) <answer> >>= 
<token> = fifo_data.graphics_lwm >> 3; <answer> *lwm 
*lwm <token> 0x24; <answer> = 
*burst <token> 0x2; <answer> = 
static void <token> <answer> nv4CalcArbitration 
nv4_fifo_info <token> <answer> *fifo, 
nv4_sim_state <token> <answer> *arb 
int data, <token> cas,width, video_enable, bpp; <answer> pagemiss, 
int <token> mclks, pclks, vpagemiss, crtpagemiss, vbs; <answer> nvclks, 
int <token> mclk_extra, mclk_loop, cbs, m1, p1; <answer> found, 
<token> mclk_freq, pclk_freq, nvclk_freq, mp_enable; <answer> int 
int <token> us_n, us_p, video_drain_rate, crtc_drain_rate; <answer> us_m, 
int vpm_us, <token> vlwm, video_fill_us, cpm_us, us_crt,clwm; <answer> us_video, 
fifo->valid <token> 1; <answer> = 
<token> = arb->pclk_khz; <answer> pclk_freq 
<token> = arb->mclk_khz; <answer> mclk_freq 
nvclk_freq = <token> <answer> arb->nvclk_khz; 
pagemiss = <token> <answer> arb->mem_page_miss; 
cas = <token> <answer> arb->mem_latency; 
width = arb->memory_width >> <token> <answer> 6; 
<token> = arb->enable_video; <answer> video_enable 
<token> = arb->pix_bpp; <answer> bpp 
<token> = arb->enable_mp; <answer> mp_enable 
<token> = 0; <answer> clwm 
vlwm <token> 0; <answer> = 
<token> = 128; <answer> cbs 
<token> = 2; <answer> pclks 
<token> = 2; <answer> nvclks 
nvclks <token> 2; <answer> += 
nvclks += <token> <answer> 1; 
mclks <token> 5; <answer> = 
<token> += 3; <answer> mclks 
mclks += <token> <answer> 1; 
<token> += cas; <answer> mclks 
mclks += <token> <answer> 1; 
mclks += <token> <answer> 1; 
mclks <token> 1; <answer> += 
mclks <token> 1; <answer> += 
mclk_extra = <token> <answer> 3; 
nvclks += <token> <answer> 2; 
nvclks += <token> <answer> 1; 
nvclks <token> 1; <answer> += 
nvclks <token> 1; <answer> += 
<token> (mp_enable) <answer> if 
<token> += 0; <answer> nvclks 
<token> += 0; <answer> pclks 
found = <token> <answer> 0; 
vbs = <token> <answer> 0; 
<token> (found != 1) <answer> while 
<token> = 1; <answer> fifo->valid 
<token> = 1; <answer> found 
mclk_loop <token> mclks+mclk_extra; <answer> = 
<token> = mclk_loop *1000*1000 / mclk_freq; <answer> us_m 
us_n = nvclks*1000*1000 / <token> <answer> nvclk_freq; 
us_p = <token> / pclk_freq; <answer> nvclks*1000*1000 
<token> (video_enable) <answer> if 
video_drain_rate = pclk_freq <token> 2; <answer> * 
crtc_drain_rate = pclk_freq <token> bpp/8; <answer> * 
vpagemiss <token> 2; <answer> = 
<token> += 1; <answer> vpagemiss 
crtpagemiss = <token> <answer> 2; 
<token> = (vpagemiss * pagemiss)*1000*1000/mclk_freq; <answer> vpm_us 
<token> (nvclk_freq * 2 > mclk_freq * width) <answer> if 
video_fill_us = cbs*1000*1000 / 16 / nvclk_freq <token> <answer> ; 
video_fill_us = cbs*1000*1000 / (8 * width) / <token> <answer> mclk_freq; 
us_video = vpm_us + <token> + us_n + us_p + video_fill_us; <answer> us_m 
vlwm = <token> * video_drain_rate/(1000*1000); <answer> us_video 
vbs <token> 128; <answer> = 
if (vlwm > 128) <token> = 64; <answer> vbs 
if (vlwm > (256-64)) vbs <token> 32; <answer> = 
if (nvclk_freq * <token> > mclk_freq * width) <answer> 2 
video_fill_us = vbs <token> 16 / nvclk_freq ; <answer> *1000*1000/ 
video_fill_us <token> vbs*1000*1000 / (8 * width) / mclk_freq; <answer> = 
cpm_us = crtpagemiss * pagemiss <token> mclk_freq; <answer> *1000*1000/ 
<token> = <answer> us_crt 
+us_m + <token> +us_p <answer> us_n 
<token> = us_crt * crtc_drain_rate/(1000*1000); <answer> clwm 
crtc_drain_rate <token> pclk_freq * bpp/8; <answer> = 
crtpagemiss = <token> <answer> 2; 
crtpagemiss <token> 1; <answer> += 
<token> = crtpagemiss * pagemiss *1000*1000/ mclk_freq; <answer> cpm_us 
us_crt = cpm_us + us_m <token> us_n + us_p ; <answer> + 
<token> = us_crt * crtc_drain_rate/(1000*1000); <answer> clwm 
m1 = clwm + cbs <token> 512; <answer> - 
p1 <token> m1 * pclk_freq / mclk_freq; <answer> = 
p1 = p1 * <token> / 8; <answer> bpp 
if ((p1 < m1) && <token> > 0)) <answer> (m1 
<token> = 0; <answer> fifo->valid 
<token> = 0; <answer> found 
<token> (mclk_extra ==0) found = 1; <answer> if 
else <token> (video_enable) <answer> if 
if ((clwm > 511) || (vlwm <token> 255)) <answer> > 
fifo->valid <token> 0; <answer> = 
found = <token> <answer> 0; 
if <token> ==0) found = 1; <answer> (mclk_extra 
<token> (clwm > 519) <answer> if 
<token> = 0; <answer> fifo->valid 
<token> = 0; <answer> found 
if (mclk_extra ==0) <token> = 1; <answer> found 
if <token> < 384) clwm = 384; <answer> (clwm 
if (vlwm < 128) <token> = 128; <answer> vlwm 
data = <token> <answer> (int)(clwm); 
<token> = data; <answer> fifo->graphics_lwm 
<token> = 128; <answer> fifo->graphics_burst_size 
data = <token> <answer> (int)((vlwm+15)); 
<token> = data; <answer> fifo->video_lwm 
fifo->video_burst_size <token> vbs; <answer> = 
<token> void nv4UpdateArbitrationSettings <answer> static 
<token> VClk, <answer> unsigned 
<token> pixelDepth, <answer> unsigned 
unsigned <token> <answer> *burst, 
unsigned <token> <answer> *lwm, 
RIVA_HW_INST <token> <answer> *chip 
nv4_fifo_info <token> <answer> fifo_data; 
nv4_sim_state <token> <answer> sim_data; 
unsigned int M, N, P, pll, MClk, NVClk, <token> <answer> cfg1; 
pll = NV_RD32(&chip->PRAMDAC0[0x00000504/4], <token> <answer> 0); 
M <token> (pll >> 0) & 0xFF; N = (pll >> 8) & 0xFF; P = (pll >> 16) & 0x0F; <answer> = 
MClk = <token> * chip->CrystalFreqKHz / M) >> P; <answer> (N 
pll = NV_RD32(&chip->PRAMDAC0[0x00000500/4], <token> <answer> 0); 
M = (pll >> 0) & 0xFF; N = (pll <token> 8) & 0xFF; P = (pll >> 16) & 0x0F; <answer> >> 
NVClk = (N * chip->CrystalFreqKHz <token> M) >> P; <answer> / 
cfg1 = NV_RD32(&chip->PFB[0x00000204/4], <token> <answer> 0); 
<token> = (char)pixelDepth; <answer> sim_data.pix_bpp 
<token> = 0; <answer> sim_data.enable_video 
<token> = 0; <answer> sim_data.enable_mp 
sim_data.memory_width = (NV_RD32(&chip->PEXTDEV[0x00000000/4], 0) & 0x10) <token> <answer> ? 
<token> : 64; <answer> 128 
sim_data.mem_latency = (char)cfg1 & <token> <answer> 0x0F; 
sim_data.mem_aligned = <token> <answer> 1; 
<token> = (char)(((cfg1 >> 4) &0x0F) + ((cfg1 >> 31) & 0x01)); <answer> sim_data.mem_page_miss 
sim_data.gr_during_vid = <token> <answer> 0; 
sim_data.pclk_khz <token> VClk; <answer> = 
sim_data.mclk_khz <token> MClk; <answer> = 
sim_data.nvclk_khz <token> NVClk; <answer> = 
<token> &sim_data); <answer> nv4CalcArbitration(&fifo_data, 
<token> (fifo_data.valid) <answer> if 
<token> b = fifo_data.graphics_burst_size >> 4; <answer> int 
*burst <token> 0; <answer> = 
while (b >>= <token> <answer> 1) 
<token> = fifo_data.graphics_lwm >> 3; <answer> *lwm 
<token> void nv10CalcArbitration <answer> static 
<token> *fifo, <answer> nv10_fifo_info 
<token> *arb <answer> nv10_sim_state 
int <token> pagemiss, width, video_enable, bpp; <answer> data, 
int nvclks, mclks, <token> vpagemiss, crtpagemiss; <answer> pclks, 
<token> nvclk_fill; <answer> int 
int <token> mclk_extra, mclk_loop, cbs, m1; <answer> found, 
<token> mclk_freq, pclk_freq, nvclk_freq, mp_enable; <answer> int 
int us_m, us_m_min, us_n, us_p, <token> <answer> crtc_drain_rate; 
<token> vus_m; <answer> int 
<token> vpm_us, us_video, cpm_us, us_crt,clwm; <answer> int 
<token> clwm_rnd_down; <answer> int 
<token> m2us, us_pipe_min, p1clk, p2; <answer> int 
<token> min_mclk_extra; <answer> int 
<token> us_min_mclk_extra; <answer> int 
fifo->valid <token> 1; <answer> = 
clwm_rnd_down <token> ((int)clwm/8)*8; <answer> = 
if <token> < clwm) <answer> (clwm_rnd_down 
<token> += 8; <answer> clwm 
<token> int CalcVClock <answer> static 
int <token> <answer> clockIn, 
int <token> <answer> *clockOut, 
int <token> <answer> *mOut, 
<token> *nOut, <answer> int 
int <token> <answer> *pOut, 
<token> *chip <answer> RIVA_HW_INST 
unsigned lowM, <token> highP; <answer> highM, 
<token> DeltaNew, DeltaOld; <answer> unsigned 
<token> VClk, Freq; <answer> unsigned 
<token> M, N, P; <answer> unsigned 
<token> = 0xFFFFFFFF; <answer> DeltaOld 
<token> = (unsigned)clockIn; <answer> VClk 
if <token> == 13500) <answer> (chip->CrystalFreqKHz 
lowM = <token> <answer> 7; 
highM = <token> - (chip->Architecture == NV_ARCH_03); <answer> 13 
lowM <token> 8; <answer> = 
highM = 14 <token> (chip->Architecture == NV_ARCH_03); <answer> - 
highP = 4 <token> (chip->Architecture == NV_ARCH_03); <answer> - 
for (P = 0; <token> <= highP; P ++) <answer> P 
<token> = VClk << P; <answer> Freq 
<token> ((Freq >= 128000) && (Freq <= chip->MaxVClockFreqKHz)) <answer> if 
for (M = lowM; M <= <token> M++) <answer> highM; 
N = <token> << P) * M / chip->CrystalFreqKHz; <answer> (VClk 
if(N <= <token> { <answer> 255) 
Freq = (chip->CrystalFreqKHz * N / M) <token> P; <answer> >> 
if <token> > VClk) <answer> (Freq 
DeltaNew = <token> - VClk; <answer> Freq 
DeltaNew = VClk - <token> <answer> Freq; 
<token> (DeltaNew < DeltaOld) <answer> if 
<token> = M; <answer> *mOut 
*nOut = <token> <answer> N; 
<token> = P; <answer> *pOut 
*clockOut = <token> <answer> Freq; 
DeltaOld = <token> <answer> DeltaNew; 
<token> CalcStateExt <answer> int 
RIVA_HW_INST <token> <answer> *chip, 
<token> *state, <answer> RIVA_HW_STATE 
struct <token> *pdev, <answer> pci_dev 
int <token> <answer> bpp, 
int <token> <answer> width, 
int <token> <answer> hDisplaySize, 
int <token> <answer> height, 
<token> dotClock <answer> int 
<token> pixelDepth; <answer> int 
int VClk, m, <token> p; <answer> n, 
pixelDepth = (bpp <token> 1)/8; <answer> + 
if <token> &VClk, &m, &n, &p, chip)) <answer> (!CalcVClock(dotClock, 
return <token> <answer> -EINVAL; 
switch <token> <answer> (chip->Architecture) 
<token> NV_ARCH_03: <answer> case 
pixelDepth * <token> <answer> 8, 
state->cursor0 = <token> <answer> 0x00; 
state->cursor1 <token> 0x78; <answer> = 
state->cursor2 = <token> <answer> 0x00000000; 
<token> = 0x10010100; <answer> state->pllsel 
state->config = <token> + 31)/32) <answer> ((width 
| (((pixelDepth > 2) ? 3 : pixelDepth) << <token> <answer> 8) 
<token> 0x1000; <answer> | 
<token> = 0x00100100; <answer> state->general 
state->repaint1 = hDisplaySize <token> 1280 ? 0x06 : 0x02; <answer> < 
<token> NV_ARCH_04: <answer> case 
<token> * 8, <answer> pixelDepth 
state->cursor0 = <token> <answer> 0x00; 
<token> = 0xFC; <answer> state->cursor1 
state->cursor2 = <token> <answer> 0x00000000; 
state->pllsel <token> 0x10000700; <answer> = 
state->config = <token> <answer> 0x00001114; 
state->general = bpp == 16 ? 0x00101100 : <token> <answer> 0x00100100; 
state->repaint1 = hDisplaySize < 1280 ? <token> : 0x00; <answer> 0x04 
case <token> <answer> NV_ARCH_10: 
case <token> <answer> NV_ARCH_20: 
case <token> <answer> NV_ARCH_30: 
<token> == NV_CHIP_IGEFORCE2) || <answer> if((chip->Chipset 
(chip->Chipset <token> NV_CHIP_0x01F0)) <answer> == 
pixelDepth <token> 8, <answer> * 
<token> pdev); <answer> chip, 
<token> else { <answer> } 
<token> * 8, <answer> pixelDepth 
state->cursor0 <token> 0x80 | (chip->CursorStart >> 17); <answer> = 
state->cursor1 = (chip->CursorStart <token> 11) << 2; <answer> >> 
state->cursor2 = chip->CursorStart <token> 24; <answer> >> 
state->pllsel = <token> <answer> 0x10000700; 
state->config <token> NV_RD32(&chip->PFB[0x00000200/4], 0); <answer> = 
<token> = bpp == 16 ? 0x00101100 : 0x00100100; <answer> state->general 
state->repaint1 <token> hDisplaySize < 1280 ? 0x04 : 0x00; <answer> = 
#define <token> \ <answer> LOAD_FIXED_STATE(tbl,dev) 
for (i = 0; i < <token> i++) \ <answer> sizeof(tbl##Table##dev)/8; 
NV_WR32(&chip->dev[tbl##Table##dev[i][0]], <token> tbl##Table##dev[i][1]) <answer> 0, 
#define LOAD_FIXED_STATE_8BPP(tbl,dev) <token> <answer> \ 
<token> (i = 0; i < sizeof(tbl##Table##dev##_8BPP)/8; i++) \ <answer> for 
<token> 0, tbl##Table##dev##_8BPP[i][1]) <answer> NV_WR32(&chip->dev[tbl##Table##dev##_8BPP[i][0]], 
#define LOAD_FIXED_STATE_15BPP(tbl,dev) <token> <answer> \ 
for <token> = 0; i < sizeof(tbl##Table##dev##_15BPP)/8; i++) \ <answer> (i 
NV_WR32(&chip->dev[tbl##Table##dev##_15BPP[i][0]], <token> tbl##Table##dev##_15BPP[i][1]) <answer> 0, 
#define LOAD_FIXED_STATE_16BPP(tbl,dev) <token> <answer> \ 
<token> (i = 0; i < sizeof(tbl##Table##dev##_16BPP)/8; i++) \ <answer> for 
NV_WR32(&chip->dev[tbl##Table##dev##_16BPP[i][0]], <token> tbl##Table##dev##_16BPP[i][1]) <answer> 0, 
#define LOAD_FIXED_STATE_32BPP(tbl,dev) <token> <answer> \ 
for <token> = 0; i < sizeof(tbl##Table##dev##_32BPP)/8; i++) \ <answer> (i 
NV_WR32(&chip->dev[tbl##Table##dev##_32BPP[i][0]], <token> tbl##Table##dev##_32BPP[i][1]) <answer> 0, 
<token> void UpdateFifoState <answer> static 
RIVA_HW_INST <token> <answer> *chip 
<token> i; <answer> int 
switch <token> <answer> (chip->Architecture) 
<token> NV_ARCH_04: <answer> case 
chip->Tri03 <token> NULL; <answer> = 
chip->Tri05 = <token> __iomem *)&(chip->FIFO[0x0000E000/4]); <answer> (RivaTexturedTriangle05 
<token> NV_ARCH_10: <answer> case 
case <token> <answer> NV_ARCH_20: 
case <token> <answer> NV_ARCH_30: 
<token> = NULL; <answer> chip->Tri03 
chip->Tri05 = <token> __iomem *)&(chip->FIFO[0x0000E000/4]); <answer> (RivaTexturedTriangle05 
static <token> LoadStateExt <answer> void 
RIVA_HW_INST <token> <answer> *chip, 
RIVA_HW_STATE <token> <answer> *state 
<token> i; <answer> int 
<token> (chip->Architecture) <answer> switch 
<token> NV_ARCH_03: <answer> case 
NV_WR32(chip->PFB, 0x00000200, <token> <answer> state->config); 
switch <token> <answer> (state->bpp) 
<token> 15: <answer> case 
<token> 16: <answer> case 
<token> = (RivaTexturedTriangle03 __iomem *)&(chip->FIFO[0x0000E000/4]); <answer> chip->Tri03 
<token> 24: <answer> case 
<token> 32: <answer> case 
<token> = NULL; <answer> chip->Tri03 
<token> 8: <answer> case 
chip->Tri03 <token> NULL; <answer> = 
for (i = <token> i < 0x00800; i++) <answer> 0x00000; 
NV_WR32(&chip->PRAMIN[0x00000502 + i], 0, <token> << 12) | 0x03); <answer> (i 
<token> 0x00000630, state->offset0); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, <token> state->offset1); <answer> 0x00000634, 
<token> 0x00000638, state->offset2); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, <token> state->offset3); <answer> 0x0000063C, 
NV_WR32(chip->PGRAPH, <token> state->pitch0); <answer> 0x00000650, 
<token> 0x00000654, state->pitch1); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, 0x00000658, <token> <answer> state->pitch2); 
NV_WR32(chip->PGRAPH, <token> state->pitch3); <answer> 0x0000065C, 
<token> NV_ARCH_04: <answer> case 
NV_WR32(chip->PFB, <token> state->config); <answer> 0x00000200, 
<token> (state->bpp) <answer> switch 
<token> 15: <answer> case 
chip->Tri03 = (RivaTexturedTriangle03 __iomem <token> <answer> *)&(chip->FIFO[0x0000E000/4]); 
case <token> <answer> 16: 
chip->Tri03 = (RivaTexturedTriangle03 <token> *)&(chip->FIFO[0x0000E000/4]); <answer> __iomem 
case <token> <answer> 24: 
<token> 32: <answer> case 
chip->Tri03 <token> NULL; <answer> = 
case <token> <answer> 8: 
chip->Tri03 <token> NULL; <answer> = 
NV_WR32(chip->PGRAPH, 0x00000640, <token> <answer> state->offset0); 
<token> 0x00000644, state->offset1); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, <token> state->offset2); <answer> 0x00000648, 
<token> 0x0000064C, state->offset3); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, <token> state->pitch0); <answer> 0x00000670, 
<token> 0x00000674, state->pitch1); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, <token> state->pitch2); <answer> 0x00000678, 
NV_WR32(chip->PGRAPH, 0x0000067C, <token> <answer> state->pitch3); 
<token> NV_ARCH_10: <answer> case 
<token> NV_ARCH_20: <answer> case 
case <token> <answer> NV_ARCH_30: 
<token> { <answer> if(chip->twoHeads) 
VGA_WR08(chip->PCIO, 0x03D4, <token> <answer> 0x44); 
<token> 0x03D5, state->crtcOwner); <answer> VGA_WR08(chip->PCIO, 
<token> 0); <answer> chip->LockUnlock(chip, 
switch <token> <answer> (state->bpp) 
<token> 15: <answer> case 
chip->Tri03 <token> (RivaTexturedTriangle03 __iomem *)&(chip->FIFO[0x0000E000/4]); <answer> = 
case <token> <answer> 16: 
chip->Tri03 <token> (RivaTexturedTriangle03 __iomem *)&(chip->FIFO[0x0000E000/4]); <answer> = 
case <token> <answer> 24: 
case <token> <answer> 32: 
<token> = NULL; <answer> chip->Tri03 
case <token> <answer> 8: 
<token> = NULL; <answer> chip->Tri03 
if(chip->Architecture == NV_ARCH_10) <token> <answer> { 
<token> 0x00000640, state->offset0); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, <token> state->offset1); <answer> 0x00000644, 
<token> 0x00000648, state->offset2); <answer> NV_WR32(chip->PGRAPH, 
<token> 0x0000064C, state->offset3); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, 0x00000670, <token> <answer> state->pitch0); 
NV_WR32(chip->PGRAPH, 0x00000674, <token> <answer> state->pitch1); 
<token> 0x00000678, state->pitch2); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, <token> state->pitch3); <answer> 0x0000067C, 
NV_WR32(chip->PGRAPH, <token> state->pitch3); <answer> 0x00000680, 
} <token> { <answer> else 
<token> 0x00000820, state->offset0); <answer> NV_WR32(chip->PGRAPH, 
<token> 0x00000824, state->offset1); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, <token> state->offset2); <answer> 0x00000828, 
<token> 0x0000082C, state->offset3); <answer> NV_WR32(chip->PGRAPH, 
<token> 0x00000850, state->pitch0); <answer> NV_WR32(chip->PGRAPH, 
<token> 0x00000854, state->pitch1); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, 0x00000858, <token> <answer> state->pitch2); 
<token> 0x0000085C, state->pitch3); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, 0x00000860, <token> <answer> state->pitch3); 
NV_WR32(chip->PGRAPH, <token> state->pitch3); <answer> 0x00000864, 
NV_WR32(chip->PGRAPH, 0x000009A4, <token> 0x00000200)); <answer> NV_RD32(chip->PFB, 
<token> 0x000009A8, NV_RD32(chip->PFB, 0x00000204)); <answer> NV_WR32(chip->PGRAPH, 
if(chip->twoHeads) <token> <answer> { 
<token> 0x00000860, state->head); <answer> NV_WR32(chip->PCRTC0, 
NV_WR32(chip->PCRTC0, <token> state->head2); <answer> 0x00002860, 
NV_WR32(chip->PRAMDAC, 0x00000404, NV_RD32(chip->PRAMDAC, 0x00000404) | (1 << <token> <answer> 25)); 
NV_WR32(chip->PMC, <token> 1); <answer> 0x00008704, 
<token> 0x00008140, 0); <answer> NV_WR32(chip->PMC, 
<token> 0x00008920, 0); <answer> NV_WR32(chip->PMC, 
NV_WR32(chip->PMC, <token> 0); <answer> 0x00008924, 
NV_WR32(chip->PMC, 0x00008908, <token> <answer> 0x01ffffff); 
NV_WR32(chip->PMC, <token> 0x01ffffff); <answer> 0x0000890C, 
NV_WR32(chip->PMC, 0x00001588, <token> <answer> 0); 
NV_WR32(chip->PFB, <token> 0); <answer> 0x00000240, 
<token> 0x00000250, 0); <answer> NV_WR32(chip->PFB, 
NV_WR32(chip->PFB, <token> 0); <answer> 0x00000260, 
NV_WR32(chip->PFB, 0x00000270, <token> <answer> 0); 
<token> 0x00000280, 0); <answer> NV_WR32(chip->PFB, 
NV_WR32(chip->PFB, <token> 0); <answer> 0x00000290, 
NV_WR32(chip->PFB, <token> 0); <answer> 0x000002A0, 
NV_WR32(chip->PFB, <token> 0); <answer> 0x000002B0, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x00000240)); <answer> 0x00000B00, 
NV_WR32(chip->PGRAPH, 0x00000B04, <token> 0x00000244)); <answer> NV_RD32(chip->PFB, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x00000248)); <answer> 0x00000B08, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x0000024C)); <answer> 0x00000B0C, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x00000250)); <answer> 0x00000B10, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x00000254)); <answer> 0x00000B14, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x00000258)); <answer> 0x00000B18, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x0000025C)); <answer> 0x00000B1C, 
NV_WR32(chip->PGRAPH, 0x00000B20, <token> 0x00000260)); <answer> NV_RD32(chip->PFB, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x00000264)); <answer> 0x00000B24, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x00000268)); <answer> 0x00000B28, 
NV_WR32(chip->PGRAPH, 0x00000B2C, <token> 0x0000026C)); <answer> NV_RD32(chip->PFB, 
NV_WR32(chip->PGRAPH, 0x00000B30, <token> 0x00000270)); <answer> NV_RD32(chip->PFB, 
NV_WR32(chip->PGRAPH, 0x00000B34, NV_RD32(chip->PFB, <token> <answer> 0x00000274)); 
NV_WR32(chip->PGRAPH, 0x00000B38, <token> 0x00000278)); <answer> NV_RD32(chip->PFB, 
NV_WR32(chip->PGRAPH, 0x00000B3C, NV_RD32(chip->PFB, <token> <answer> 0x0000027C)); 
NV_WR32(chip->PGRAPH, 0x00000B40, <token> 0x00000280)); <answer> NV_RD32(chip->PFB, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x00000284)); <answer> 0x00000B44, 
NV_WR32(chip->PGRAPH, 0x00000B48, NV_RD32(chip->PFB, <token> <answer> 0x00000288)); 
NV_WR32(chip->PGRAPH, 0x00000B4C, NV_RD32(chip->PFB, <token> <answer> 0x0000028C)); 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x00000290)); <answer> 0x00000B50, 
NV_WR32(chip->PGRAPH, 0x00000B54, NV_RD32(chip->PFB, <token> <answer> 0x00000294)); 
NV_WR32(chip->PGRAPH, 0x00000B58, <token> 0x00000298)); <answer> NV_RD32(chip->PFB, 
NV_WR32(chip->PGRAPH, 0x00000B5C, NV_RD32(chip->PFB, <token> <answer> 0x0000029C)); 
NV_WR32(chip->PGRAPH, 0x00000B60, NV_RD32(chip->PFB, <token> <answer> 0x000002A0)); 
<token> 0x00000B64, NV_RD32(chip->PFB, 0x000002A4)); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x000002A8)); <answer> 0x00000B68, 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x000002AC)); <answer> 0x00000B6C, 
NV_WR32(chip->PGRAPH, 0x00000B70, NV_RD32(chip->PFB, <token> <answer> 0x000002B0)); 
NV_WR32(chip->PGRAPH, 0x00000B74, NV_RD32(chip->PFB, <token> <answer> 0x000002B4)); 
NV_WR32(chip->PGRAPH, <token> NV_RD32(chip->PFB, 0x000002B8)); <answer> 0x00000B78, 
NV_WR32(chip->PGRAPH, 0x00000B7C, <token> 0x000002BC)); <answer> NV_RD32(chip->PFB, 
<token> 0x00000F40, 0x10000000); <answer> NV_WR32(chip->PGRAPH, 
<token> 0x00000F44, 0x00000000); <answer> NV_WR32(chip->PGRAPH, 
<token> 0x00000F50, 0x00000040); <answer> NV_WR32(chip->PGRAPH, 
<token> 0x00000F54, 0x00000008); <answer> NV_WR32(chip->PGRAPH, 
<token> 0x00000F50, 0x00000200); <answer> NV_WR32(chip->PGRAPH, 
for (i = 0; i <token> (3*16); i++) <answer> < 
NV_WR32(chip->PGRAPH, <token> 0x00000000); <answer> 0x00000F54, 
NV_WR32(chip->PGRAPH, 0x00000F50, <token> <answer> 0x00000040); 
NV_WR32(chip->PGRAPH, <token> 0x00000000); <answer> 0x00000F54, 
NV_WR32(chip->PGRAPH, 0x00000F50, <token> <answer> 0x00000800); 
<token> (i = 0; i < (16*16); i++) <answer> for 
<token> 0x00000F54, 0x00000000); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, <token> 0x30000000); <answer> 0x00000F40, 
<token> 0x00000F44, 0x00000004); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PGRAPH, <token> 0x00006400); <answer> 0x00000F50, 
<token> (i = 0; i < (59*4); i++) <answer> for 
NV_WR32(chip->PGRAPH, 0x00000F54, <token> <answer> 0x00000000); 
<token> 0x00000F50, 0x00006800); <answer> NV_WR32(chip->PGRAPH, 
for (i <token> 0; i < (47*4); i++) <answer> = 
NV_WR32(chip->PGRAPH, 0x00000F54, <token> <answer> 0x00000000); 
NV_WR32(chip->PGRAPH, <token> 0x00006C00); <answer> 0x00000F50, 
for (i = 0; <token> < (3*4); i++) <answer> i 
NV_WR32(chip->PGRAPH, 0x00000F54, <token> <answer> 0x00000000); 
NV_WR32(chip->PGRAPH, <token> 0x00007000); <answer> 0x00000F50, 
for (i <token> 0; i < (19*4); i++) <answer> = 
NV_WR32(chip->PGRAPH, <token> 0x00000000); <answer> 0x00000F54, 
NV_WR32(chip->PGRAPH, <token> 0x00007400); <answer> 0x00000F50, 
for (i <token> 0; i < (12*4); i++) <answer> = 
NV_WR32(chip->PGRAPH, 0x00000F54, <token> <answer> 0x00000000); 
NV_WR32(chip->PGRAPH, <token> 0x00007800); <answer> 0x00000F50, 
for (i = 0; i <token> (12*4); i++) <answer> < 
NV_WR32(chip->PGRAPH, <token> 0x00000000); <answer> 0x00000F54, 
NV_WR32(chip->PGRAPH, 0x00000F50, <token> <answer> 0x00004400); 
for (i = 0; i <token> (8*4); i++) <answer> < 
NV_WR32(chip->PGRAPH, 0x00000F54, <token> <answer> 0x00000000); 
NV_WR32(chip->PGRAPH, <token> 0x00000000); <answer> 0x00000F50, 
for <token> = 0; i < 16; i++) <answer> (i 
NV_WR32(chip->PGRAPH, <token> 0x00000000); <answer> 0x00000F54, 
NV_WR32(chip->PGRAPH, 0x00000F50, <token> <answer> 0x00000040); 
for (i = 0; i < <token> i++) <answer> 4; 
<token> 0x00000F54, 0x00000000); <answer> NV_WR32(chip->PGRAPH, 
NV_WR32(chip->PCRTC, 0x00000810, <token> <answer> state->cursorConfig); 
if(chip->flatPanel) <token> <answer> { 
if((chip->Chipset <token> 0x0ff0) == 0x0110) { <answer> & 
<token> 0x0528, state->dither); <answer> NV_WR32(chip->PRAMDAC, 
<token> else <answer> } 
if((chip->Chipset & 0x0ff0) <token> 0x0170) { <answer> >= 
NV_WR32(chip->PRAMDAC, 0x083C, <token> <answer> state->dither); 
<token> 0x03D4, 0x53); <answer> VGA_WR08(chip->PCIO, 
VGA_WR08(chip->PCIO, <token> 0); <answer> 0x03D5, 
VGA_WR08(chip->PCIO, 0x03D4, <token> <answer> 0x54); 
<token> 0x03D5, 0); <answer> VGA_WR08(chip->PCIO, 
<token> 0x03D4, 0x21); <answer> VGA_WR08(chip->PCIO, 
VGA_WR08(chip->PCIO, 0x03D5, <token> <answer> 0xfa); 
<token> 0x03D4, 0x41); <answer> VGA_WR08(chip->PCIO, 
<token> 0x03D5, state->extra); <answer> VGA_WR08(chip->PCIO, 
VGA_WR08(chip->PCIO, 0x03D4, <token> <answer> 0x19); 
VGA_WR08(chip->PCIO, 0x03D5, <token> <answer> state->repaint0); 
VGA_WR08(chip->PCIO, 0x03D4, <token> <answer> 0x1A); 
VGA_WR08(chip->PCIO, <token> state->repaint1); <answer> 0x03D5, 
<token> 0x03D4, 0x25); <answer> VGA_WR08(chip->PCIO, 
VGA_WR08(chip->PCIO, 0x03D5, <token> <answer> state->screen); 
VGA_WR08(chip->PCIO, <token> 0x28); <answer> 0x03D4, 
<token> 0x03D5, state->pixel); <answer> VGA_WR08(chip->PCIO, 
VGA_WR08(chip->PCIO, 0x03D4, <token> <answer> 0x2D); 
VGA_WR08(chip->PCIO, <token> state->horiz); <answer> 0x03D5, 
VGA_WR08(chip->PCIO, 0x03D4, <token> <answer> 0x1B); 
VGA_WR08(chip->PCIO, <token> state->arbitration0); <answer> 0x03D5, 
VGA_WR08(chip->PCIO, <token> 0x20); <answer> 0x03D4, 
VGA_WR08(chip->PCIO, <token> state->arbitration1); <answer> 0x03D5, 
VGA_WR08(chip->PCIO, <token> 0x30); <answer> 0x03D4, 
VGA_WR08(chip->PCIO, 0x03D5, <token> <answer> state->cursor0); 
VGA_WR08(chip->PCIO, 0x03D4, <token> <answer> 0x31); 
VGA_WR08(chip->PCIO, 0x03D5, <token> <answer> state->cursor1); 
VGA_WR08(chip->PCIO, 0x03D4, <token> <answer> 0x2F); 
VGA_WR08(chip->PCIO, <token> state->cursor2); <answer> 0x03D5, 
<token> 0x03D4, 0x39); <answer> VGA_WR08(chip->PCIO, 
VGA_WR08(chip->PCIO, <token> state->interlace); <answer> 0x03D5, 
if(!chip->flatPanel) <token> <answer> { 
NV_WR32(chip->PRAMDAC0, 0x00000508, <token> <answer> state->vpll); 
<token> 0x0000050C, state->pllsel); <answer> NV_WR32(chip->PRAMDAC0, 
NV_WR32(chip->PRAMDAC0, 0x00000520, <token> <answer> state->vpll2); 
} else <token> <answer> { 
NV_WR32(chip->PRAMDAC, 0x00000848 <token> state->scale); <answer> , 
NV_WR32(chip->PRAMDAC, <token> , state->general); <answer> 0x00000600 
NV_WR32(chip->PCRTC, 0x00000140, <token> <answer> 0); 
<token> 0x00000100, chip->VBlankBit); <answer> NV_WR32(chip->PCRTC, 
NV_WR32(chip->PMC, 0x00000140, chip->EnableIRQ & <token> <answer> 0x01); 
chip->CurrentState <token> state; <answer> = 
chip->FifoFreeCount = <token> <answer> 0; 
VGA_WR08(chip->PCIO, 0x03D4, <token> <answer> 0x19); 
<token> = VGA_RD08(chip->PCIO, 0x03D5); <answer> state->repaint0 
<token> 0x03D4, 0x1A); <answer> VGA_WR08(chip->PCIO, 
<token> = VGA_RD08(chip->PCIO, 0x03D5); <answer> state->repaint1 
VGA_WR08(chip->PCIO, <token> 0x25); <answer> 0x03D4, 
<token> = VGA_RD08(chip->PCIO, 0x03D5); <answer> state->screen 
VGA_WR08(chip->PCIO, <token> 0x28); <answer> 0x03D4, 
state->pixel <token> VGA_RD08(chip->PCIO, 0x03D5); <answer> = 
VGA_WR08(chip->PCIO, 0x03D4, <token> <answer> 0x2D); 
state->horiz = <token> 0x03D5); <answer> VGA_RD08(chip->PCIO, 
<token> 0x03D4, 0x1B); <answer> VGA_WR08(chip->PCIO, 
state->arbitration0 = <token> 0x03D5); <answer> VGA_RD08(chip->PCIO, 
<token> 0x03D4, 0x20); <answer> VGA_WR08(chip->PCIO, 
state->arbitration1 <token> VGA_RD08(chip->PCIO, 0x03D5); <answer> = 
<token> 0x03D4, 0x30); <answer> VGA_WR08(chip->PCIO, 
state->cursor0 = VGA_RD08(chip->PCIO, <token> <answer> 0x03D5); 
VGA_WR08(chip->PCIO, <token> 0x31); <answer> 0x03D4, 
state->cursor1 = <token> 0x03D5); <answer> VGA_RD08(chip->PCIO, 
<token> 0x03D4, 0x2F); <answer> VGA_WR08(chip->PCIO, 
state->cursor2 = VGA_RD08(chip->PCIO, <token> <answer> 0x03D5); 
VGA_WR08(chip->PCIO, <token> 0x39); <answer> 0x03D4, 
state->interlace <token> VGA_RD08(chip->PCIO, 0x03D5); <answer> = 
<token> = NV_RD32(chip->PRAMDAC0, 0x00000508); <answer> state->vpll 
state->vpll2 = NV_RD32(chip->PRAMDAC0, <token> <answer> 0x00000520); 
state->pllsel = <token> 0x0000050C); <answer> NV_RD32(chip->PRAMDAC0, 
state->general = <token> 0x00000600); <answer> NV_RD32(chip->PRAMDAC, 
state->scale <token> NV_RD32(chip->PRAMDAC, 0x00000848); <answer> = 
state->config <token> NV_RD32(chip->PFB, 0x00000200); <answer> = 
<token> (chip->Architecture) <answer> switch 
<token> NV_ARCH_03: <answer> case 
state->offset0 <token> NV_RD32(chip->PGRAPH, 0x00000630); <answer> = 
state->offset1 = <token> 0x00000634); <answer> NV_RD32(chip->PGRAPH, 
<token> = NV_RD32(chip->PGRAPH, 0x00000638); <answer> state->offset2 
<token> = NV_RD32(chip->PGRAPH, 0x0000063C); <answer> state->offset3 
state->pitch0 = <token> 0x00000650); <answer> NV_RD32(chip->PGRAPH, 
state->pitch1 = <token> 0x00000654); <answer> NV_RD32(chip->PGRAPH, 
state->pitch2 <token> NV_RD32(chip->PGRAPH, 0x00000658); <answer> = 
state->pitch3 <token> NV_RD32(chip->PGRAPH, 0x0000065C); <answer> = 
case <token> <answer> NV_ARCH_04: 
state->offset0 <token> NV_RD32(chip->PGRAPH, 0x00000640); <answer> = 
state->offset1 <token> NV_RD32(chip->PGRAPH, 0x00000644); <answer> = 
state->offset2 <token> NV_RD32(chip->PGRAPH, 0x00000648); <answer> = 
state->offset3 = <token> 0x0000064C); <answer> NV_RD32(chip->PGRAPH, 
<token> = NV_RD32(chip->PGRAPH, 0x00000670); <answer> state->pitch0 
state->pitch1 <token> NV_RD32(chip->PGRAPH, 0x00000674); <answer> = 
state->pitch2 = NV_RD32(chip->PGRAPH, <token> <answer> 0x00000678); 
state->pitch3 = <token> 0x0000067C); <answer> NV_RD32(chip->PGRAPH, 
<token> NV_ARCH_10: <answer> case 
case <token> <answer> NV_ARCH_20: 
case <token> <answer> NV_ARCH_30: 
state->offset0 = <token> 0x00000640); <answer> NV_RD32(chip->PGRAPH, 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/input.h> <answer> #include 
<token> <linux/suspend.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/of_platform.h> 
#include <token> <answer> <linux/pm_wakeirq.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <asm/bootinfo.h> 
<token> <asm/suspend.h> <answer> #include 
#define LOONGSON2_PM1_CNT_REG <token> <answer> 0x14 
#define <token> 0x0c <answer> LOONGSON2_PM1_STS_REG 
#define <token> 0x10 <answer> LOONGSON2_PM1_ENA_REG 
#define <token> 0x28 <answer> LOONGSON2_GPE0_STS_REG 
#define <token> 0x2c <answer> LOONGSON2_GPE0_ENA_REG 
#define <token> BIT(8) <answer> LOONGSON2_PM1_PWRBTN_STS 
#define LOONGSON2_PM1_PCIEXP_WAKE_STS <token> <answer> BIT(14) 
#define LOONGSON2_PM1_WAKE_STS <token> <answer> BIT(15) 
#define <token> BIT(0) <answer> LOONGSON2_PM1_CNT_INT_EN 
#define LOONGSON2_PM1_PWRBTN_EN <token> <answer> LOONGSON2_PM1_PWRBTN_STS 
static <token> loongson2_pm { <answer> struct 
void __iomem <token> <answer> *base; 
<token> input_dev *dev; <answer> struct 
<token> suspended; <answer> bool 
} <token> <answer> loongson2_pm; 
#define loongson2_pm_readw(reg) <token> + reg) <answer> readw(loongson2_pm.base 
#define loongson2_pm_readl(reg) <token> + reg) <answer> readl(loongson2_pm.base 
#define loongson2_pm_writew(val, reg) writew(val, <token> + reg) <answer> loongson2_pm.base 
#define loongson2_pm_writel(val, reg) writel(val, loongson2_pm.base + <token> <answer> reg) 
static <token> loongson2_pm_status_clear(void) <answer> void 
<token> value; <answer> u16 
<token> = loongson2_pm_readw(LOONGSON2_PM1_STS_REG); <answer> value 
<token> |= (LOONGSON2_PM1_PWRBTN_STS | LOONGSON2_PM1_PCIEXP_WAKE_STS | <answer> value 
<token> LOONGSON2_PM1_STS_REG); <answer> loongson2_pm_writew(value, 
<token> LOONGSON2_GPE0_STS_REG); <answer> loongson2_pm_writel(loongson2_pm_readl(LOONGSON2_GPE0_STS_REG), 
static <token> loongson2_pm_irq_enable(void) <answer> void 
<token> value; <answer> u16 
value <token> loongson2_pm_readw(LOONGSON2_PM1_CNT_REG); <answer> = 
<token> |= LOONGSON2_PM1_CNT_INT_EN; <answer> value 
<token> LOONGSON2_PM1_CNT_REG); <answer> loongson2_pm_writew(value, 
value = <token> <answer> loongson2_pm_readw(LOONGSON2_PM1_ENA_REG); 
value |= <token> <answer> LOONGSON2_PM1_PWRBTN_EN; 
loongson2_pm_writew(value, <token> <answer> LOONGSON2_PM1_ENA_REG); 
static int loongson2_suspend_enter(suspend_state_t <token> <answer> state) 
<token> 0; <answer> return 
<token> int loongson2_suspend_begin(suspend_state_t state) <answer> static 
<token> 0; <answer> return 
<token> int loongson2_suspend_valid_state(suspend_state_t state) <answer> static 
return (state == <token> <answer> PM_SUSPEND_MEM); 
static const struct platform_suspend_ops loongson2_suspend_ops = <token> <answer> { 
<token> = loongson2_suspend_valid_state, <answer> .valid 
.begin <token> loongson2_suspend_begin, <answer> = 
.enter <token> loongson2_suspend_enter, <answer> = 
static int loongson2_power_button_init(struct device *dev, <token> irq) <answer> int 
<token> ret; <answer> int 
struct input_dev <token> <answer> *button; 
button = <token> <answer> input_allocate_device(); 
if <token> <answer> (!dev) 
<token> -ENOMEM; <answer> return 
button->name = <token> Button"; <answer> "Power 
button->phys <token> "pm/button/input0"; <answer> = 
button->id.bustype <token> BUS_HOST; <answer> = 
button->dev.parent = <token> <answer> NULL; 
input_set_capability(button, EV_KEY, <token> <answer> KEY_POWER); 
<token> = input_register_device(button); <answer> ret 
<token> (ret) <answer> if 
goto <token> <answer> free_dev; 
<token> irq); <answer> dev_pm_set_wake_irq(&button->dev, 
<token> true); <answer> device_set_wakeup_capable(&button->dev, 
<token> true); <answer> device_set_wakeup_enable(&button->dev, 
loongson2_pm.dev <token> button; <answer> = 
dev_info(dev, "Power Button: Init <token> <answer> successful!\n"); 
<token> 0; <answer> return 
<token> ret; <answer> return 
static irqreturn_t loongson2_pm_irq_handler(int irq, <token> *dev_id) <answer> void 
u16 status <token> loongson2_pm_readw(LOONGSON2_PM1_STS_REG); <answer> = 
if (!loongson2_pm.suspended <token> (status & LOONGSON2_PM1_PWRBTN_STS)) { <answer> && 
<token> Button pressed...\n"); <answer> pr_info("Power 
input_report_key(loongson2_pm.dev, <token> 1); <answer> KEY_POWER, 
input_report_key(loongson2_pm.dev, KEY_POWER, <token> <answer> 0); 
return <token> <answer> IRQ_HANDLED; 
static int __maybe_unused <token> device *dev) <answer> loongson2_pm_suspend(struct 
loongson2_pm.suspended <token> true; <answer> = 
return <token> <answer> 0; 
static int <token> loongson2_pm_resume(struct device *dev) <answer> __maybe_unused 
loongson2_pm.suspended = <token> <answer> false; 
return <token> <answer> 0; 
<token> SIMPLE_DEV_PM_OPS(loongson2_pm_ops, loongson2_pm_suspend, loongson2_pm_resume); <answer> static 
static int loongson2_pm_probe(struct platform_device <token> <answer> *pdev) 
int <token> retval; <answer> irq, 
u64 <token> <answer> suspend_addr; 
struct device *dev <token> &pdev->dev; <answer> = 
<token> = devm_platform_ioremap_resource(pdev, 0); <answer> loongson2_pm.base 
if <token> <answer> (IS_ERR(loongson2_pm.base)) 
<token> PTR_ERR(loongson2_pm.base); <answer> return 
<token> = platform_get_irq(pdev, 0); <answer> irq 
if (irq <token> 0) <answer> < 
<token> irq; <answer> return 
if (!device_property_read_u64(dev, <token> &suspend_addr)) <answer> "loongson,suspend-address", 
loongson_sysconf.suspend_addr <token> (u64)phys_to_virt(suspend_addr); <answer> = 
dev_err(dev, "No <token> could not support S3!\n"); <answer> loongson,suspend-address, 
if <token> irq)) <answer> (loongson2_power_button_init(dev, 
<token> -EINVAL; <answer> return 
retval = devm_request_irq(&pdev->dev, <token> loongson2_pm_irq_handler, <answer> irq, 
IRQF_SHARED, "pm_irq", <token> <answer> &loongson2_pm); 
<token> (retval) <answer> if 
<token> retval; <answer> return 
<token> (loongson_sysconf.suspend_addr) <answer> if 
<token> <linux/acpi.h> <answer> #include 
<token> <linux/cacheinfo.h> <answer> #include 
#include <token> <answer> <linux/ctype.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/io-64-nonatomic-lo-hi.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/mutex.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
<token> <linux/perf_event.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> "arm_cspmu.h" 
#define <token> "arm_cspmu" <answer> PMUNAME 
#define DRVNAME <token> <answer> "arm-cs-arch-pmu" 
#define ARM_CSPMU_CPUMASK_ATTR(_name, <token> \ <answer> _config) 
ARM_CSPMU_EXT_ATTR(_name, arm_cspmu_cpumask_show, <token> <answer> \ 
<token> long)_config) <answer> (unsigned 
#define PMEVCNTR_LO <token> <answer> 0x0 
<token> PMEVCNTR_HI 0x4 <answer> #define 
#define PMEVTYPER <token> <answer> 0x400 
<token> PMCCFILTR 0x47C <answer> #define 
<token> PMEVFILTR 0xA00 <answer> #define 
#define <token> 0xC00 <answer> PMCNTENSET 
#define PMCNTENCLR <token> <answer> 0xC20 
#define <token> 0xC40 <answer> PMINTENSET 
#define <token> 0xC60 <answer> PMINTENCLR 
#define <token> 0xC80 <answer> PMOVSCLR 
<token> PMOVSSET 0xCC0 <answer> #define 
#define <token> 0xE00 <answer> PMCFGR 
#define <token> 0xE04 <answer> PMCR 
#define <token> 0xE08 <answer> PMIIDR 
#define HILOHI_MAX_POLL <token> <answer> 1000 
<token> unsigned long arm_cspmu_cpuhp_state; <answer> static 
static <token> <answer> DEFINE_MUTEX(arm_cspmu_lock); 
<token> void arm_cspmu_set_ev_filter(struct arm_cspmu *cspmu, <answer> static 
<token> hw_perf_event *hwc, u32 filter); <answer> struct 
static struct acpi_apmt_node <token> device *dev) <answer> *arm_cspmu_apmt_node(struct 
struct acpi_apmt_node **ptr <token> dev_get_platdata(dev); <answer> = 
return ptr ? *ptr : <token> <answer> NULL; 
<token> u64 read_reg64_hilohi(const void __iomem *addr, u32 max_poll_count) <answer> static 
u32 val_lo, <token> <answer> val_hi; 
u64 <token> <answer> val; 
idx <token> find_first_zero_bit(hw_events->used_ctrs, <answer> = 
<token> (idx >= cspmu->cycle_counter_logical_idx) { <answer> if 
idx = <token> <answer> find_next_zero_bit( 
<token> + 1); <answer> cspmu->cycle_counter_logical_idx 
} <token> { <answer> else 
<token> = find_first_zero_bit(hw_events->used_ctrs, <answer> idx 
if (idx >= <token> <answer> cspmu->num_logical_ctrs) 
<token> -EAGAIN; <answer> return 
<token> (cspmu->impl.ops.validate_event) { <answer> if 
ret = <token> event); <answer> cspmu->impl.ops.validate_event(cspmu, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> hw_events->used_ctrs); <answer> set_bit(idx, 
return <token> <answer> idx; 
static bool arm_cspmu_validate_event(struct pmu <token> <answer> *pmu, 
<token> arm_cspmu_hw_events *hw_events, <answer> struct 
struct <token> *event) <answer> perf_event 
if <token> <answer> (is_software_event(event)) 
<token> true; <answer> return 
static bool arm_cspmu_validate_group(struct perf_event <token> <answer> *event) 
struct perf_event <token> *leader = event->group_leader; <answer> *sibling, 
struct <token> fake_hw_events; <answer> arm_cspmu_hw_events 
if (event->group_leader <token> event) <answer> == 
return <token> <answer> true; 
memset(&fake_hw_events, <token> sizeof(fake_hw_events)); <answer> 0, 
<token> (!arm_cspmu_validate_event(event->pmu, &fake_hw_events, leader)) <answer> if 
<token> false; <answer> return 
<token> leader) { <answer> for_each_sibling_event(sibling, 
if (!arm_cspmu_validate_event(event->pmu, <token> <answer> &fake_hw_events, 
<token> false; <answer> return 
<token> arm_cspmu_validate_event(event->pmu, &fake_hw_events, event); <answer> return 
static <token> arm_cspmu_event_init(struct perf_event *event) <answer> int 
struct arm_cspmu <token> <answer> *cspmu; 
struct hw_perf_event *hwc = <token> <answer> &event->hw; 
cspmu <token> to_arm_cspmu(event->pmu); <answer> = 
if (event->attr.type <token> event->pmu->type) <answer> != 
return <token> <answer> -ENOENT; 
<token> (is_sampling_event(event)) { <answer> if 
<token> support sampling events\n"); <answer> "Can't 
<token> -EOPNOTSUPP; <answer> return 
if (event->cpu < 0 || event->attach_state & PERF_ATTACH_TASK) <token> <answer> { 
"Can't support <token> counters\n"); <answer> per-task 
return <token> <answer> -EINVAL; 
if (!cpumask_test_cpu(event->cpu, <token> { <answer> &cspmu->associated_cpus)) 
"Requested cpu is not associated with <token> PMU\n"); <answer> the 
<token> -EINVAL; <answer> return 
hwc->idx <token> -1; <answer> = 
<token> = -1; <answer> hwc->extra_reg.idx 
hwc->config <token> cspmu->impl.ops.event_type(event); <answer> = 
<token> 0; <answer> return 
<token> inline u32 counter_offset(u32 reg_sz, u32 ctr_idx) <answer> static 
return (PMEVCNTR_LO + (reg_sz <token> ctr_idx)); <answer> * 
static void arm_cspmu_write_counter(struct <token> *event, u64 val) <answer> perf_event 
<token> offset; <answer> u32 
struct arm_cspmu <token> = to_arm_cspmu(event->pmu); <answer> *cspmu 
if (use_64b_counter_reg(cspmu)) <token> <answer> { 
offset <token> counter_offset(sizeof(u64), event->hw.idx); <answer> = 
<token> (cspmu->has_atomic_dword) <answer> if 
<token> cspmu->base1 + offset); <answer> writeq(val, 
<token> cspmu->base1 + offset); <answer> lo_hi_writeq(val, 
} else <token> <answer> { 
offset = counter_offset(sizeof(u32), <token> <answer> event->hw.idx); 
<token> cspmu->base1 + offset); <answer> writel(lower_32_bits(val), 
static u64 arm_cspmu_read_counter(struct perf_event <token> <answer> *event) 
<token> offset; <answer> u32 
<token> void __iomem *counter_addr; <answer> const 
struct <token> *cspmu = to_arm_cspmu(event->pmu); <answer> arm_cspmu 
<token> (use_64b_counter_reg(cspmu)) { <answer> if 
offset <token> counter_offset(sizeof(u64), event->hw.idx); <answer> = 
counter_addr = <token> + offset; <answer> cspmu->base1 
return cspmu->has_atomic_dword <token> <answer> ? 
<token> : <answer> readq(counter_addr) 
read_reg64_hilohi(counter_addr, <token> <answer> HILOHI_MAX_POLL); 
offset = counter_offset(sizeof(u32), <token> <answer> event->hw.idx); 
return <token> + offset); <answer> readl(cspmu->base1 
static void <token> perf_event *event) <answer> arm_cspmu_set_event_period(struct 
struct arm_cspmu *cspmu <token> to_arm_cspmu(event->pmu); <answer> = 
u64 <token> = counter_mask(cspmu) >> 1ULL; <answer> val 
<token> val); <answer> local64_set(&event->hw.prev_count, 
arm_cspmu_write_counter(event, <token> <answer> val); 
static <token> arm_cspmu_enable_counter(struct arm_cspmu *cspmu, int idx) <answer> void 
<token> reg_id, reg_bit, inten_off, cnten_off; <answer> u32 
reg_id <token> COUNTER_TO_SET_CLR_ID(idx); <answer> = 
<token> = COUNTER_TO_SET_CLR_BIT(idx); <answer> reg_bit 
inten_off = <token> + (4 * reg_id); <answer> PMINTENSET 
cnten_off = PMCNTENSET + <token> * reg_id); <answer> (4 
writel(BIT(reg_bit), cspmu->base0 <token> inten_off); <answer> + 
writel(BIT(reg_bit), cspmu->base0 + <token> <answer> cnten_off); 
static void arm_cspmu_disable_counter(struct arm_cspmu *cspmu, int <token> <answer> idx) 
u32 reg_id, <token> inten_off, cnten_off; <answer> reg_bit, 
reg_id <token> COUNTER_TO_SET_CLR_ID(idx); <answer> = 
reg_bit = <token> <answer> COUNTER_TO_SET_CLR_BIT(idx); 
<token> = PMINTENCLR + (4 * reg_id); <answer> inten_off 
<token> = PMCNTENCLR + (4 * reg_id); <answer> cnten_off 
writel(BIT(reg_bit), cspmu->base0 <token> cnten_off); <answer> + 
<token> cspmu->base0 + inten_off); <answer> writel(BIT(reg_bit), 
static <token> arm_cspmu_event_update(struct perf_event *event) <answer> void 
struct arm_cspmu <token> = to_arm_cspmu(event->pmu); <answer> *cspmu 
<token> hw_perf_event *hwc = &event->hw; <answer> struct 
<token> delta, prev, now; <answer> u64 
do <token> <answer> { 
prev <token> local64_read(&hwc->prev_count); <answer> = 
<token> = arm_cspmu_read_counter(event); <answer> now 
} while (local64_cmpxchg(&hwc->prev_count, prev, now) != <token> <answer> prev); 
delta = (now <token> prev) & counter_mask(cspmu); <answer> - 
local64_add(delta, <token> <answer> &event->count); 
static <token> void arm_cspmu_set_event(struct arm_cspmu *cspmu, <answer> inline 
struct <token> *hwc) <answer> hw_perf_event 
u32 offset = PMEVTYPER <token> (4 * hwc->idx); <answer> + 
writel(hwc->config, <token> + offset); <answer> cspmu->base0 
<token> void arm_cspmu_set_ev_filter(struct arm_cspmu *cspmu, <answer> static 
struct <token> *hwc, <answer> hw_perf_event 
u32 <token> <answer> filter) 
u32 offset = PMEVFILTR + (4 * <token> <answer> hwc->idx); 
writel(filter, cspmu->base0 + <token> <answer> offset); 
static inline void <token> arm_cspmu *cspmu, u32 filter) <answer> arm_cspmu_set_cc_filter(struct 
u32 offset = <token> <answer> PMCCFILTR; 
writel(filter, cspmu->base0 <token> offset); <answer> + 
static void arm_cspmu_start(struct perf_event <token> int pmu_flags) <answer> *event, 
<token> arm_cspmu *cspmu = to_arm_cspmu(event->pmu); <answer> struct 
struct hw_perf_event <token> = &event->hw; <answer> *hwc 
<token> filter; <answer> u32 
<token> = <answer> cspmu->cycle_counter_logical_idx 
(cspmu->num_logical_ctrs <= ARM_CSPMU_CYCLE_CNTR_IDX) <token> <answer> ? 
cspmu->num_logical_ctrs - <token> : <answer> 1 
cspmu->num_set_clr_reg <token> <answer> = 
<token> = <answer> cspmu->hw_events.events 
<token> cspmu->num_logical_ctrs, <answer> devm_kcalloc(dev, 
sizeof(*cspmu->hw_events.events), <token> <answer> GFP_KERNEL); 
<token> (!cspmu->hw_events.events) <answer> if 
return <token> <answer> -ENOMEM; 
return <token> <answer> 0; 
static inline <token> arm_cspmu_get_reset_overflow(struct arm_cspmu *cspmu, <answer> int 
<token> *pmovs) <answer> u32 
<token> i; <answer> int 
u32 pmovclr_offset <token> PMOVSCLR; <answer> = 
u32 has_overflowed <token> 0; <answer> = 
for (i = 0; i < <token> ++i) { <answer> cspmu->num_set_clr_reg; 
<token> = readl(cspmu->base1 + pmovclr_offset); <answer> pmovs[i] 
has_overflowed <token> pmovs[i]; <answer> |= 
writel(pmovs[i], cspmu->base1 + <token> <answer> pmovclr_offset); 
<token> += sizeof(u32); <answer> pmovclr_offset 
return <token> != 0; <answer> has_overflowed 
static irqreturn_t <token> irq_num, void *dev) <answer> arm_cspmu_handle_irq(int 
<token> idx, has_overflowed; <answer> int 
struct <token> *event; <answer> perf_event 
struct arm_cspmu *cspmu <token> dev; <answer> = 
DECLARE_BITMAP(pmovs, <token> <answer> ARM_CSPMU_MAX_HW_CNTRS); 
bool <token> = false; <answer> handled 
has_overflowed = arm_cspmu_get_reset_overflow(cspmu, <token> *)pmovs); <answer> (u32 
if <token> <answer> (!has_overflowed) 
<token> done; <answer> goto 
<token> cspmu->hw_events.used_ctrs, <answer> for_each_set_bit(idx, 
<token> { <answer> cspmu->num_logical_ctrs) 
event = <token> <answer> cspmu->hw_events.events[idx]; 
<token> (!event) <answer> if 
if (!test_bit(event->hw.idx, <token> <answer> pmovs)) 
<token> = true; <answer> handled 
return <token> <answer> IRQ_RETVAL(handled); 
static int arm_cspmu_request_irq(struct arm_cspmu <token> <answer> *cspmu) 
int irq, <token> <answer> ret; 
struct <token> *dev; <answer> device 
struct <token> *pdev; <answer> platform_device 
dev = <token> <answer> cspmu->dev; 
pdev <token> to_platform_device(dev); <answer> = 
#include <token> <answer> <linux/module.h> 
<token> <linux/types.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/init.h> 
<token> <asm/io.h> <answer> #include 
#include <token> <answer> <linux/mtd/mtd.h> 
#include <token> <answer> <linux/mtd/map.h> 
<token> <linux/mtd/concat.h> <answer> #include 
#define <token> <answer> REPROGRAM_PAR 
#ifdef <token> <answer> REPROGRAM_PAR 
<token> SC520_MMCR_BASE 0xFFFEF000 <answer> #define 
#define <token> 0x1000 <answer> SC520_MMCR_EXTENT 
#define SC520_PAR(x) ((0x88/sizeof(unsigned long)) + <token> <answer> (x)) 
#define <token> (0x4<<29) <answer> SC520_PAR_BOOTCS 
#define SC520_PAR_ROMCS0 <token> <answer> (0x5<<29) 
#define <token> (0x6<<29) <answer> SC520_PAR_ROMCS1 
#define SC520_PAR_TRGDEV <token> <answer> (0x7<<29) 
<token> SC520_PAR_PG_SIZ4 (0<<25) <answer> #define 
#define SC520_PAR_PG_SIZ64 <token> <answer> (1<<25) 
#define SC520_PAR_ENTRY(trgdev, address, <token> \ <answer> size) 
((trgdev) | SC520_PAR_NOCACHE | SC520_PAR_PG_SIZ64 <token> \ <answer> | 
(address) >> 16 | <token> >> 16) - 1) << 14) <answer> (((size) 
<token> sc520_par_table <answer> struct 
unsigned long <token> <answer> trgdev; 
unsigned long <token> <answer> new_par; 
unsigned long <token> <answer> default_address; 
static const struct sc520_par_table <token> = <answer> par_table[NUM_FLASH_BANKS] 
#define pr_fmt(fmt) KBUILD_MODNAME ": " <token> <answer> fmt 
#include <token> <answer> <linux/module.h> 
<token> <linux/vmalloc.h> <answer> #include 
<token> <linux/mm.h> <answer> #include 
#include <token> <answer> <linux/uio.h> 
<token> <linux/bvec.h> <answer> #include 
#include <token> <answer> <kunit/test.h> 
<token> testing"); <answer> MODULE_DESCRIPTION("iov_iter 
MODULE_AUTHOR("David Howells <token> <answer> <dhowells@redhat.com>"); 
struct <token> { <answer> kvec_test_range 
<token> from, to; <answer> int 
static const struct <token> kvec_test_ranges[] = { <answer> kvec_test_range 
{ <token> 0x00002 }, <answer> 0x00002, 
{ <token> 0x03000 }, <answer> 0x00027, 
<token> 0x05193, 0x18794 }, <answer> { 
<token> 0x20000, 0x20000 }, <answer> { 
{ 0x20000, <token> }, <answer> 0x24000 
{ 0x24000, 0x27001 <token> <answer> }, 
<token> 0x29000, 0xffffb }, <answer> { 
{ <token> 0xffffe }, <answer> 0xffffd, 
{ -1 <token> <answer> } 
<token> inline u8 pattern(unsigned long x) <answer> static 
<token> x & 0xff; <answer> return 
<token> void iov_kunit_unmap(void *data) <answer> static 
static <token> *__init iov_kunit_create_buffer(struct kunit *test, <answer> void 
<token> page ***ppages, <answer> struct 
<token> npages) <answer> size_t 
<token> page **pages; <answer> struct 
unsigned long <token> <answer> got; 
<token> *buffer; <answer> void 
pages = kunit_kcalloc(test, npages, sizeof(struct page *), <token> <answer> GFP_KERNEL); 
<token> pages); <answer> KUNIT_ASSERT_NOT_ERR_OR_NULL(test, 
*ppages = <token> <answer> pages; 
got = alloc_pages_bulk_array(GFP_KERNEL, npages, <token> <answer> pages); 
if (got != npages) <token> <answer> { 
<token> got); <answer> release_pages(pages, 
KUNIT_ASSERT_EQ(test, got, <token> <answer> npages); 
buffer = <token> npages, VM_MAP | VM_MAP_PUT_PAGES, PAGE_KERNEL); <answer> vmap(pages, 
KUNIT_ASSERT_NOT_ERR_OR_NULL(test, <token> <answer> buffer); 
<token> iov_kunit_unmap, buffer); <answer> kunit_add_action_or_reset(test, 
<token> buffer; <answer> return 
static void <token> iov_kunit_load_kvec(struct kunit *test, <answer> __init 
struct <token> *iter, int dir, <answer> iov_iter 
struct kvec *kvec, unsigned int <token> <answer> kvmax, 
void <token> size_t bufsize, <answer> *buffer, 
const struct <token> *pr) <answer> kvec_test_range 
size_t size <token> 0; <answer> = 
<token> i; <answer> int 
<token> (i = 0; i < kvmax; i++, pr++) { <answer> for 
if <token> < 0) <answer> (pr->from 
KUNIT_ASSERT_GE(test, pr->to, <token> <answer> pr->from); 
<token> pr->to, bufsize); <answer> KUNIT_ASSERT_LE(test, 
kvec[i].iov_base = buffer + <token> <answer> pr->from; 
kvec[i].iov_len = <token> - pr->from; <answer> pr->to 
size += <token> - pr->from; <answer> pr->to 
<token> size, bufsize); <answer> KUNIT_ASSERT_LE(test, 
<token> dir, kvec, i, size); <answer> iov_iter_kvec(iter, 
static void <token> iov_kunit_copy_to_kvec(struct kunit *test) <answer> __init 
const struct kvec_test_range <token> <answer> *pr; 
<token> iov_iter iter; <answer> struct 
struct page **spages, <token> <answer> **bpages; 
struct kvec <token> <answer> kvec[8]; 
<token> *scratch, *buffer; <answer> u8 
<token> bufsize, npages, size, copied; <answer> size_t 
<token> i, patt; <answer> int 
bufsize = <token> <answer> 0x100000; 
npages = bufsize <token> PAGE_SIZE; <answer> / 
scratch = iov_kunit_create_buffer(test, <token> npages); <answer> &spages, 
for (i <token> 0; i < bufsize; i++) <answer> = 
<token> = pattern(i); <answer> scratch[i] 
<token> = iov_kunit_create_buffer(test, &bpages, npages); <answer> buffer 
memset(buffer, 0, <token> <answer> bufsize); 
iov_kunit_load_kvec(test, <token> READ, kvec, ARRAY_SIZE(kvec), <answer> &iter, 
buffer, <token> kvec_test_ranges); <answer> bufsize, 
size = <token> <answer> iter.count; 
copied = copy_to_iter(scratch, size, <token> <answer> &iter); 
KUNIT_EXPECT_EQ(test, <token> size); <answer> copied, 
KUNIT_EXPECT_EQ(test, <token> 0); <answer> iter.count, 
KUNIT_EXPECT_EQ(test, <token> 0); <answer> iter.nr_segs, 
static void __init <token> kunit *test) <answer> iov_kunit_copy_from_kvec(struct 
<token> struct kvec_test_range *pr; <answer> const 
struct iov_iter <token> <answer> iter; 
struct page <token> **bpages; <answer> **spages, 
<token> kvec kvec[8]; <answer> struct 
u8 <token> *buffer; <answer> *scratch, 
size_t bufsize, npages, <token> copied; <answer> size, 
int i, <token> <answer> j; 
bufsize <token> 0x100000; <answer> = 
npages = <token> / PAGE_SIZE; <answer> bufsize 
buffer = iov_kunit_create_buffer(test, &bpages, <token> <answer> npages); 
for (i = 0; i <token> bufsize; i++) <answer> < 
buffer[i] <token> pattern(i); <answer> = 
scratch <token> iov_kunit_create_buffer(test, &spages, npages); <answer> = 
memset(scratch, 0, <token> <answer> bufsize); 
iov_kunit_load_kvec(test, &iter, <token> kvec, ARRAY_SIZE(kvec), <answer> WRITE, 
<token> bufsize, kvec_test_ranges); <answer> buffer, 
size <token> min(iter.count, bufsize); <answer> = 
copied = copy_from_iter(scratch, <token> &iter); <answer> size, 
KUNIT_EXPECT_EQ(test, <token> size); <answer> copied, 
<token> iter.count, 0); <answer> KUNIT_EXPECT_EQ(test, 
KUNIT_EXPECT_EQ(test, <token> 0); <answer> iter.nr_segs, 
static void __init iov_kunit_copy_to_bvec(struct kunit <token> <answer> *test) 
const struct <token> *pr; <answer> bvec_test_range 
struct iov_iter <token> <answer> iter; 
<token> bio_vec bvec[8]; <answer> struct 
struct page **spages, <token> <answer> **bpages; 
u8 *scratch, <token> <answer> *buffer; 
size_t bufsize, npages, size, <token> <answer> copied; 
int i, b, <token> <answer> patt; 
bufsize <token> 0x100000; <answer> = 
npages <token> bufsize / PAGE_SIZE; <answer> = 
scratch = iov_kunit_create_buffer(test, <token> npages); <answer> &spages, 
<token> (i = 0; i < bufsize; i++) <answer> for 
<token> = pattern(i); <answer> scratch[i] 
buffer <token> iov_kunit_create_buffer(test, &bpages, npages); <answer> = 
memset(buffer, 0, <token> <answer> bufsize); 
iov_kunit_load_bvec(test, <token> READ, bvec, ARRAY_SIZE(bvec), <answer> &iter, 
bpages, <token> bufsize, bvec_test_ranges); <answer> npages, 
size <token> iter.count; <answer> = 
copied = copy_to_iter(scratch, <token> &iter); <answer> size, 
KUNIT_EXPECT_EQ(test, copied, <token> <answer> size); 
KUNIT_EXPECT_EQ(test, iter.count, <token> <answer> 0); 
KUNIT_EXPECT_EQ(test, <token> 0); <answer> iter.nr_segs, 
static void __init iov_kunit_copy_from_bvec(struct kunit <token> <answer> *test) 
const struct bvec_test_range <token> <answer> *pr; 
struct <token> iter; <answer> iov_iter 
struct <token> bvec[8]; <answer> bio_vec 
struct page <token> **bpages; <answer> **spages, 
u8 *scratch, <token> <answer> *buffer; 
size_t bufsize, <token> size, copied; <answer> npages, 
int <token> j; <answer> i, 
bufsize = <token> <answer> 0x100000; 
npages = bufsize / <token> <answer> PAGE_SIZE; 
buffer = iov_kunit_create_buffer(test, &bpages, <token> <answer> npages); 
for (i = 0; i < bufsize; <token> <answer> i++) 
buffer[i] <token> pattern(i); <answer> = 
scratch <token> iov_kunit_create_buffer(test, &spages, npages); <answer> = 
memset(scratch, <token> bufsize); <answer> 0, 
<token> &iter, WRITE, bvec, ARRAY_SIZE(bvec), <answer> iov_kunit_load_bvec(test, 
bpages, <token> bufsize, bvec_test_ranges); <answer> npages, 
size = <token> <answer> iter.count; 
copied = copy_from_iter(scratch, size, <token> <answer> &iter); 
<token> copied, size); <answer> KUNIT_EXPECT_EQ(test, 
KUNIT_EXPECT_EQ(test, iter.count, <token> <answer> 0); 
KUNIT_EXPECT_EQ(test, <token> 0); <answer> iter.nr_segs, 
<token> void __init iov_kunit_copy_to_xarray(struct kunit *test) <answer> static 
const struct kvec_test_range <token> <answer> *pr; 
struct <token> iter; <answer> iov_iter 
struct xarray <token> <answer> *xarray; 
struct page <token> **bpages; <answer> **spages, 
u8 *scratch, <token> <answer> *buffer; 
size_t bufsize, npages, size, <token> <answer> copied; 
int i, <token> <answer> patt; 
bufsize = <token> <answer> 0x100000; 
npages = <token> / PAGE_SIZE; <answer> bufsize 
xarray = <token> <answer> iov_kunit_create_xarray(test); 
scratch = iov_kunit_create_buffer(test, <token> npages); <answer> &spages, 
for (i = 0; i < bufsize; <token> <answer> i++) 
scratch[i] <token> pattern(i); <answer> = 
<token> = iov_kunit_create_buffer(test, &bpages, npages); <answer> buffer 
memset(buffer, <token> bufsize); <answer> 0, 
iov_kunit_load_xarray(test, &iter, READ, xarray, <token> npages); <answer> bpages, 
i <token> 0; <answer> = 
for (pr = <token> pr->from >= 0; pr++) { <answer> kvec_test_ranges; 
size = <token> - pr->from; <answer> pr->to 
<token> pr->to, bufsize); <answer> KUNIT_ASSERT_LE(test, 
iov_iter_xarray(&iter, READ, xarray, pr->from, <token> <answer> size); 
<token> = copy_to_iter(scratch + i, size, &iter); <answer> copied 
KUNIT_EXPECT_EQ(test, copied, <token> <answer> size); 
KUNIT_EXPECT_EQ(test, iter.count, <token> <answer> 0); 
KUNIT_EXPECT_EQ(test, iter.iov_offset, <token> <answer> size); 
i += <token> <answer> size; 
static void <token> iov_kunit_copy_from_xarray(struct kunit *test) <answer> __init 
const struct kvec_test_range <token> <answer> *pr; 
struct <token> iter; <answer> iov_iter 
struct <token> *xarray; <answer> xarray 
struct page <token> **bpages; <answer> **spages, 
u8 <token> *buffer; <answer> *scratch, 
size_t bufsize, npages, size, <token> <answer> copied; 
int i, <token> <answer> j; 
<token> = 0x100000; <answer> bufsize 
npages = <token> / PAGE_SIZE; <answer> bufsize 
<token> = iov_kunit_create_xarray(test); <answer> xarray 
buffer = <token> &bpages, npages); <answer> iov_kunit_create_buffer(test, 
<token> (i = 0; i < bufsize; i++) <answer> for 
buffer[i] = <token> <answer> pattern(i); 
scratch <token> iov_kunit_create_buffer(test, &spages, npages); <answer> = 
memset(scratch, <token> bufsize); <answer> 0, 
iov_kunit_load_xarray(test, &iter, READ, xarray, <token> npages); <answer> bpages, 
i <token> 0; <answer> = 
for (pr = kvec_test_ranges; pr->from <token> 0; pr++) { <answer> >= 
size = pr->to <token> pr->from; <answer> - 
<token> pr->to, bufsize); <answer> KUNIT_ASSERT_LE(test, 
<token> WRITE, xarray, pr->from, size); <answer> iov_iter_xarray(&iter, 
copied = copy_from_iter(scratch + i, <token> &iter); <answer> size, 
KUNIT_EXPECT_EQ(test, <token> size); <answer> copied, 
<token> iter.count, 0); <answer> KUNIT_EXPECT_EQ(test, 
KUNIT_EXPECT_EQ(test, <token> size); <answer> iter.iov_offset, 
<token> += size; <answer> i 
static <token> __init iov_kunit_extract_pages_kvec(struct kunit *test) <answer> void 
<token> struct kvec_test_range *pr; <answer> const 
struct <token> iter; <answer> iov_iter 
struct page <token> *pagelist[8], **pages = pagelist; <answer> **bpages, 
struct kvec <token> <answer> kvec[8]; 
u8 <token> <answer> *buffer; 
ssize_t <token> <answer> len; 
size_t bufsize, size = <token> npages; <answer> 0, 
int i, <token> <answer> from; 
bufsize <token> 0x100000; <answer> = 
npages <token> bufsize / PAGE_SIZE; <answer> = 
buffer <token> iov_kunit_create_buffer(test, &bpages, npages); <answer> = 
iov_kunit_load_kvec(test, &iter, READ, kvec, <token> <answer> ARRAY_SIZE(kvec), 
buffer, bufsize, <token> <answer> kvec_test_ranges); 
<token> = iter.count; <answer> size 
pr <token> kvec_test_ranges; <answer> = 
<token> = pr->from; <answer> from 
<token> { <answer> do 
size_t offset0 = <token> <answer> LONG_MAX; 
for (i = 0; i < <token> i++) <answer> ARRAY_SIZE(pagelist); 
pagelist[i] <token> (void *)(unsigned long)0xaa55aa55aa55aa55ULL; <answer> = 
len = iov_iter_extract_pages(&iter, &pages, <token> * 1024, <answer> 100 
ARRAY_SIZE(pagelist), <token> &offset0); <answer> 0, 
KUNIT_EXPECT_GE(test, <token> 0); <answer> len, 
if (len <token> 0) <answer> < 
KUNIT_EXPECT_GE(test, (ssize_t)offset0, <token> <answer> 0); 
KUNIT_EXPECT_LT(test, offset0, <token> <answer> PAGE_SIZE); 
KUNIT_EXPECT_LE(test, <token> size); <answer> len, 
KUNIT_EXPECT_EQ(test, <token> size - len); <answer> iter.count, 
size -= <token> <answer> len; 
<token> (len == 0) <answer> if 
for (i = 0; i < <token> i++) { <answer> ARRAY_SIZE(pagelist); 
<token> page *p; <answer> struct 
ssize_t part = min_t(ssize_t, len, PAGE_SIZE - <token> <answer> offset0); 
int <token> <answer> ix; 
<token> part, 0); <answer> KUNIT_ASSERT_GE(test, 
while (from <token> pr->to) { <answer> == 
from <token> pr->from; <answer> = 
if (from < <token> <answer> 0) 
<token> stop; <answer> goto 
ix <token> from / PAGE_SIZE; <answer> = 
<token> ix, npages); <answer> KUNIT_ASSERT_LT(test, 
p = <token> <answer> bpages[ix]; 
KUNIT_EXPECT_PTR_EQ(test, pagelist[i], <token> <answer> p); 
KUNIT_EXPECT_EQ(test, offset0, from % <token> <answer> PAGE_SIZE); 
from <token> part; <answer> += 
<token> -= part; <answer> len 
KUNIT_ASSERT_GE(test, <token> 0); <answer> len, 
if <token> == 0) <answer> (len 
<token> = 0; <answer> offset0 
if (test->status <token> KUNIT_FAILURE) <answer> == 
} while <token> > 0); <answer> (iov_iter_count(&iter) 
KUNIT_EXPECT_EQ(test, <token> 0); <answer> size, 
<token> iter.count, 0); <answer> KUNIT_EXPECT_EQ(test, 
static void __init <token> kunit *test) <answer> iov_kunit_extract_pages_bvec(struct 
const struct <token> *pr; <answer> bvec_test_range 
struct <token> iter; <answer> iov_iter 
struct page **bpages, *pagelist[8], **pages <token> pagelist; <answer> = 
<token> bio_vec bvec[8]; <answer> struct 
ssize_t <token> <answer> len; 
size_t bufsize, size = 0, <token> <answer> npages; 
int <token> from; <answer> i, 
bufsize = <token> <answer> 0x100000; 
npages = bufsize / <token> <answer> PAGE_SIZE; 
iov_kunit_create_buffer(test, &bpages, <token> <answer> npages); 
iov_kunit_load_bvec(test, &iter, READ, bvec, <token> <answer> ARRAY_SIZE(bvec), 
<token> npages, bufsize, bvec_test_ranges); <answer> bpages, 
size <token> iter.count; <answer> = 
pr <token> bvec_test_ranges; <answer> = 
from = <token> <answer> pr->from; 
do <token> <answer> { 
size_t offset0 <token> LONG_MAX; <answer> = 
for (i <token> 0; i < ARRAY_SIZE(pagelist); i++) <answer> = 
<token> = (void *)(unsigned long)0xaa55aa55aa55aa55ULL; <answer> pagelist[i] 
len = iov_iter_extract_pages(&iter, &pages, 100 <token> 1024, <answer> * 
ARRAY_SIZE(pagelist), 0, <token> <answer> &offset0); 
KUNIT_EXPECT_GE(test, len, <token> <answer> 0); 
if (len <token> 0) <answer> < 
<token> (ssize_t)offset0, 0); <answer> KUNIT_EXPECT_GE(test, 
KUNIT_EXPECT_LT(test, <token> PAGE_SIZE); <answer> offset0, 
<token> len, size); <answer> KUNIT_EXPECT_LE(test, 
<token> iter.count, size - len); <answer> KUNIT_EXPECT_EQ(test, 
<token> -= len; <answer> size 
if <token> == 0) <answer> (len 
for (i <token> 0; i < ARRAY_SIZE(pagelist); i++) { <answer> = 
struct <token> *p; <answer> page 
ssize_t part = <token> len, PAGE_SIZE - offset0); <answer> min_t(ssize_t, 
<token> ix; <answer> int 
<token> part, 0); <answer> KUNIT_ASSERT_GE(test, 
while (from == <token> { <answer> pr->to) 
from <token> pr->from; <answer> = 
if (from < <token> <answer> 0) 
<token> stop; <answer> goto 
ix = pr->page + from <token> PAGE_SIZE; <answer> / 
<token> ix, npages); <answer> KUNIT_ASSERT_LT(test, 
p = <token> <answer> bpages[ix]; 
<token> pagelist[i], p); <answer> KUNIT_EXPECT_PTR_EQ(test, 
<token> offset0, from % PAGE_SIZE); <answer> KUNIT_EXPECT_EQ(test, 
from += <token> <answer> part; 
<token> -= part; <answer> len 
KUNIT_ASSERT_GE(test, len, <token> <answer> 0); 
if (len <token> 0) <answer> == 
<token> = 0; <answer> offset0 
<token> (test->status == KUNIT_FAILURE) <answer> if 
<token> while (iov_iter_count(&iter) > 0); <answer> } 
KUNIT_EXPECT_EQ(test, <token> 0); <answer> size, 
<token> iter.count, 0); <answer> KUNIT_EXPECT_EQ(test, 
static void __init <token> kunit *test) <answer> iov_kunit_extract_pages_xarray(struct 
const <token> kvec_test_range *pr; <answer> struct 
struct iov_iter <token> <answer> iter; 
struct <token> *xarray; <answer> xarray 
struct page **bpages, *pagelist[8], <token> = pagelist; <answer> **pages 
<token> len; <answer> ssize_t 
size_t bufsize, <token> = 0, npages; <answer> size 
<token> i, from; <answer> int 
bufsize = <token> <answer> 0x100000; 
<token> = bufsize / PAGE_SIZE; <answer> npages 
<token> = iov_kunit_create_xarray(test); <answer> xarray 
iov_kunit_create_buffer(test, &bpages, <token> <answer> npages); 
iov_kunit_load_xarray(test, &iter, <token> xarray, bpages, npages); <answer> READ, 
for (pr = kvec_test_ranges; pr->from >= 0; <token> { <answer> pr++) 
from = <token> <answer> pr->from; 
size <token> pr->to - from; <answer> = 
KUNIT_ASSERT_LE(test, <token> bufsize); <answer> pr->to, 
iov_iter_xarray(&iter, WRITE, xarray, <token> size); <answer> from, 
<token> { <answer> do 
size_t <token> = LONG_MAX; <answer> offset0 
for <token> = 0; i < ARRAY_SIZE(pagelist); i++) <answer> (i 
pagelist[i] = (void *)(unsigned <token> <answer> long)0xaa55aa55aa55aa55ULL; 
len = iov_iter_extract_pages(&iter, &pages, <token> * 1024, <answer> 100 
ARRAY_SIZE(pagelist), <token> &offset0); <answer> 0, 
<token> len, 0); <answer> KUNIT_EXPECT_GE(test, 
if <token> < 0) <answer> (len 
KUNIT_EXPECT_LE(test, <token> size); <answer> len, 
<token> iter.count, size - len); <answer> KUNIT_EXPECT_EQ(test, 
if <token> == 0) <answer> (len 
size -= <token> <answer> len; 
KUNIT_EXPECT_GE(test, (ssize_t)offset0, <token> <answer> 0); 
KUNIT_EXPECT_LT(test, offset0, <token> <answer> PAGE_SIZE); 
for <token> = 0; i < ARRAY_SIZE(pagelist); i++) { <answer> (i 
<token> page *p; <answer> struct 
ssize_t part = min_t(ssize_t, len, <token> - offset0); <answer> PAGE_SIZE 
<token> ix; <answer> int 
KUNIT_ASSERT_GE(test, part, <token> <answer> 0); 
ix = <token> / PAGE_SIZE; <answer> from 
KUNIT_ASSERT_LT(test, <token> npages); <answer> ix, 
p <token> bpages[ix]; <answer> = 
KUNIT_EXPECT_PTR_EQ(test, <token> p); <answer> pagelist[i], 
KUNIT_EXPECT_EQ(test, offset0, <token> % PAGE_SIZE); <answer> from 
<token> += part; <answer> from 
len -= <token> <answer> part; 
KUNIT_ASSERT_GE(test, len, <token> <answer> 0); 
if <token> == 0) <answer> (len 
offset0 <token> 0; <answer> = 
if (test->status == <token> <answer> KUNIT_FAILURE) 
<token> stop; <answer> goto 
} while (iov_iter_count(&iter) > <token> <answer> 0); 
KUNIT_EXPECT_EQ(test, <token> 0); <answer> size, 
<token> iter.count, 0); <answer> KUNIT_EXPECT_EQ(test, 
KUNIT_EXPECT_EQ(test, iter.iov_offset, pr->to - <token> <answer> pr->from); 
static <token> kunit_case __refdata iov_kunit_cases[] = { <answer> struct 
static <token> kunit_suite iov_kunit_suite = { <answer> struct 
<token> = "iov_iter", <answer> .name 
.test_cases <token> iov_kunit_cases, <answer> = 
#include <token> <answer> <inttypes.h> 
<token> <stdio.h> <answer> #include 
<token> <stdlib.h> <answer> #include 
#include <token> <answer> <stdbool.h> 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/types.h> 
#include <token> <answer> <linux/perf_event.h> 
<token> "util/evsel_fprintf.h" <answer> #include 
#include <token> <answer> "trace-event.h" 
<token> bit_names { <answer> struct 
int <token> <answer> bit; 
const <token> *name; <answer> char 
static void __p_bits(char <token> size_t size, u64 value, struct bit_names *bits) <answer> *buf, 
bool <token> = true; <answer> first_bit 
int <token> = 0; <answer> i 
do <token> <answer> { 
if (value <token> bits[i].bit) { <answer> & 
buf += scnprintf(buf, size, "%s%s", first_bit ? "" : <token> bits[i].name); <answer> "|", 
<token> = false; <answer> first_bit 
} while <token> != NULL); <answer> (bits[++i].name 
static void __p_sample_type(char *buf, size_t <token> u64 value) <answer> size, 
#define bit_name(n) { PERF_SAMPLE_##n, <token> } <answer> #n 
struct bit_names bits[] <token> { <answer> = 
bit_name(IP), bit_name(TID), bit_name(TIME), <token> <answer> bit_name(ADDR), 
bit_name(READ), bit_name(CALLCHAIN), bit_name(ID), <token> <answer> bit_name(CPU), 
bit_name(PERIOD), bit_name(STREAM_ID), <token> <answer> bit_name(RAW), 
bit_name(BRANCH_STACK), <token> bit_name(STACK_USER), <answer> bit_name(REGS_USER), 
<token> bit_name(REGS_INTR), bit_name(DATA_SRC), <answer> bit_name(IDENTIFIER), 
bit_name(WEIGHT), <token> bit_name(AUX), <answer> bit_name(PHYS_ADDR), 
bit_name(CGROUP), <token> bit_name(CODE_PAGE_SIZE), <answer> bit_name(DATA_PAGE_SIZE), 
{ .name = <token> } <answer> NULL, 
#undef <token> <answer> bit_name 
__p_bits(buf, size, value, <token> <answer> bits); 
static void <token> *buf, size_t size, u64 value) <answer> __p_branch_sample_type(char 
#define bit_name(n) <token> PERF_SAMPLE_BRANCH_##n, #n } <answer> { 
struct <token> bits[] = { <answer> bit_names 
<token> bit_name(KERNEL), bit_name(HV), bit_name(ANY), <answer> bit_name(USER), 
bit_name(ANY_CALL), bit_name(ANY_RETURN), <token> <answer> bit_name(IND_CALL), 
bit_name(ABORT_TX), <token> bit_name(NO_TX), <answer> bit_name(IN_TX), 
bit_name(COND), bit_name(CALL_STACK), <token> <answer> bit_name(IND_JUMP), 
<token> bit_name(NO_FLAGS), bit_name(NO_CYCLES), <answer> bit_name(CALL), 
<token> bit_name(HW_INDEX), bit_name(PRIV_SAVE), <answer> bit_name(TYPE_SAVE), 
<token> .name = NULL, } <answer> { 
#undef <token> <answer> bit_name 
__p_bits(buf, size, value, <token> <answer> bits); 
static void __p_read_format(char *buf, size_t size, <token> value) <answer> u64 
#define bit_name(n) { PERF_FORMAT_##n, #n <token> <answer> } 
<token> bit_names bits[] = { <answer> struct 
bit_name(TOTAL_TIME_ENABLED), <token> <answer> bit_name(TOTAL_TIME_RUNNING), 
bit_name(ID), bit_name(GROUP), <token> <answer> bit_name(LOST), 
{ .name = NULL, <token> <answer> } 
#undef <token> <answer> bit_name 
__p_bits(buf, <token> value, bits); <answer> size, 
#define ENUM_ID_TO_STR_CASE(x) case <token> return (#x); <answer> x: 
static <token> char *stringify_perf_type_id(u64 value) <answer> const 
switch <token> { <answer> (value) 
<token> NULL; <answer> return 
static const char <token> value) <answer> *stringify_perf_hw_id(u64 
switch <token> { <answer> (value) 
return <token> <answer> NULL; 
static const <token> *stringify_perf_hw_cache_id(u64 value) <answer> char 
switch (value) <token> <answer> { 
<token> NULL; <answer> return 
static const <token> *stringify_perf_hw_cache_op_id(u64 value) <answer> char 
switch <token> { <answer> (value) 
<token> NULL; <answer> return 
static <token> char *stringify_perf_hw_cache_op_result_id(u64 value) <answer> const 
switch (value) <token> <answer> { 
<token> NULL; <answer> return 
static const char *stringify_perf_sw_id(u64 <token> <answer> value) 
<token> (value) { <answer> switch 
<token> NULL; <answer> return 
#undef <token> <answer> ENUM_ID_TO_STR_CASE 
<token> PRINT_ID(_s, _f) \ <answer> #define 
<token> { \ <answer> do 
const char <token> = _s; \ <answer> *__s 
if (__s <token> NULL) \ <answer> == 
<token> size, _f, value); \ <answer> snprintf(buf, 
else <token> <answer> \ 
snprintf(buf, size, _f" (%s)", value, <token> \ <answer> __s); 
} while <token> <answer> (0) 
#define print_id_unsigned(_s) PRINT_ID(_s, <token> <answer> "%"PRIu64) 
<token> print_id_hex(_s) PRINT_ID(_s, "%#"PRIx64) <answer> #define 
static void __p_type_id(char *buf, size_t size, <token> value) <answer> u64 
static void __p_config_hw_id(char *buf, size_t size, <token> value) <answer> u64 
static void __p_config_sw_id(char *buf, <token> size, u64 value) <answer> size_t 
static <token> __p_config_hw_cache_id(char *buf, size_t size, u64 value) <answer> void 
const char *hw_cache_str = stringify_perf_hw_cache_id(value <token> 0xff); <answer> & 
const char <token> = <answer> *hw_cache_op_str 
stringify_perf_hw_cache_op_id((value & 0xff00) <token> 8); <answer> >> 
const char *hw_cache_op_result_str <token> <answer> = 
stringify_perf_hw_cache_op_result_id((value <token> 0xff0000) >> 16); <answer> & 
if (hw_cache_str == NULL || <token> == NULL || <answer> hw_cache_op_str 
hw_cache_op_result_str == NULL) <token> <answer> { 
snprintf(buf, size, <token> value); <answer> "%#"PRIx64, 
<token> else { <answer> } 
<token> size, "%#"PRIx64" (%s | %s | %s)", value, <answer> snprintf(buf, 
hw_cache_op_result_str, hw_cache_op_str, <token> <answer> hw_cache_str); 
#ifdef <token> <answer> HAVE_LIBTRACEEVENT 
static <token> __p_config_tracepoint_id(char *buf, size_t size, u64 value) <answer> void 
char *str <token> tracepoint_id_to_name(value); <answer> = 
static <token> __p_config_id(char *buf, size_t size, u32 type, u64 value) <answer> void 
<token> (type) { <answer> switch 
case <token> <answer> PERF_TYPE_HARDWARE: 
return <token> size, value); <answer> __p_config_hw_id(buf, 
<token> PERF_TYPE_SOFTWARE: <answer> case 
return __p_config_sw_id(buf, size, <token> <answer> value); 
case <token> <answer> PERF_TYPE_HW_CACHE: 
<token> __p_config_hw_cache_id(buf, size, value); <answer> return 
case <token> <answer> PERF_TYPE_TRACEPOINT: 
#ifdef <token> <answer> HAVE_LIBTRACEEVENT 
return __p_config_tracepoint_id(buf, size, <token> <answer> value); 
case <token> <answer> PERF_TYPE_RAW: 
<token> PERF_TYPE_BREAKPOINT: <answer> case 
<token> size, "%#"PRIx64, value); <answer> snprintf(buf, 
<token> BUF_SIZE 1024 <answer> #define 
#define p_hex(val) <token> BUF_SIZE, "%#"PRIx64, (uint64_t)(val)) <answer> snprintf(buf, 
#define p_unsigned(val) snprintf(buf, BUF_SIZE, <token> (uint64_t)(val)) <answer> "%"PRIu64, 
#define p_signed(val) snprintf(buf, <token> "%"PRId64, (int64_t)(val)) <answer> BUF_SIZE, 
#define p_sample_type(val) __p_sample_type(buf, <token> val) <answer> BUF_SIZE, 
#define p_branch_sample_type(val) <token> BUF_SIZE, val) <answer> __p_branch_sample_type(buf, 
#define p_read_format(val) __p_read_format(buf, <token> val) <answer> BUF_SIZE, 
#define p_type_id(val) __p_type_id(buf, BUF_SIZE, <token> <answer> val) 
#define <token> __p_config_id(buf, BUF_SIZE, attr->type, val) <answer> p_config_id(val) 
#define PRINT_ATTRn(_n, _f, <token> _a) \ <answer> _p, 
do { <token> <answer> \ 
if (_a || attr->_f) <token> \ <answer> { 
_p(attr->_f); <token> <answer> \ 
ret += <token> _n, buf, priv);\ <answer> attr__fprintf(fp, 
} <token> <answer> \ 
} <token> (0) <answer> while 
#define PRINT_ATTRf(_f, _p) PRINT_ATTRn(#_f, _f, <token> false) <answer> _p, 
int perf_event_attr__fprintf(FILE *fp, struct perf_event_attr <token> <answer> *attr, 
attr__fprintf_f attr__fprintf, <token> *priv) <answer> void 
char <token> <answer> buf[BUF_SIZE]; 
<token> ret = 0; <answer> int 
PRINT_ATTRn("type", type, p_type_id, <token> <answer> true); 
<token> p_unsigned); <answer> PRINT_ATTRf(size, 
PRINT_ATTRn("config", <token> p_config_id, true); <answer> config, 
PRINT_ATTRn("{ sample_period, sample_freq <token> sample_period, p_unsigned, false); <answer> }", 
<token> p_sample_type); <answer> PRINT_ATTRf(sample_type, 
PRINT_ATTRf(read_format, <token> <answer> p_read_format); 
PRINT_ATTRf(disabled, <token> <answer> p_unsigned); 
<token> p_unsigned); <answer> PRINT_ATTRf(inherit, 
<token> p_unsigned); <answer> PRINT_ATTRf(pinned, 
<token> p_unsigned); <answer> PRINT_ATTRf(exclusive, 
<token> p_unsigned); <answer> PRINT_ATTRf(exclude_user, 
PRINT_ATTRf(exclude_kernel, <token> <answer> p_unsigned); 
<token> p_unsigned); <answer> PRINT_ATTRf(exclude_hv, 
PRINT_ATTRf(exclude_idle, <token> <answer> p_unsigned); 
<token> p_unsigned); <answer> PRINT_ATTRf(mmap, 
<token> p_unsigned); <answer> PRINT_ATTRf(comm, 
PRINT_ATTRf(freq, <token> <answer> p_unsigned); 
PRINT_ATTRf(inherit_stat, <token> <answer> p_unsigned); 
PRINT_ATTRf(enable_on_exec, <token> <answer> p_unsigned); 
<token> p_unsigned); <answer> PRINT_ATTRf(task, 
<token> p_unsigned); <answer> PRINT_ATTRf(watermark, 
<token> p_unsigned); <answer> PRINT_ATTRf(precise_ip, 
<token> p_unsigned); <answer> PRINT_ATTRf(mmap_data, 
<token> p_unsigned); <answer> PRINT_ATTRf(sample_id_all, 
<token> p_unsigned); <answer> PRINT_ATTRf(exclude_host, 
<token> p_unsigned); <answer> PRINT_ATTRf(exclude_guest, 
PRINT_ATTRf(exclude_callchain_kernel, <token> <answer> p_unsigned); 
<token> p_unsigned); <answer> PRINT_ATTRf(exclude_callchain_user, 
<token> p_unsigned); <answer> PRINT_ATTRf(mmap2, 
<token> p_unsigned); <answer> PRINT_ATTRf(comm_exec, 
<token> p_unsigned); <answer> PRINT_ATTRf(use_clockid, 
PRINT_ATTRf(context_switch, <token> <answer> p_unsigned); 
PRINT_ATTRf(write_backward, <token> <answer> p_unsigned); 
<token> p_unsigned); <answer> PRINT_ATTRf(namespaces, 
<token> p_unsigned); <answer> PRINT_ATTRf(ksymbol, 
PRINT_ATTRf(bpf_event, <token> <answer> p_unsigned); 
<token> p_unsigned); <answer> PRINT_ATTRf(aux_output, 
PRINT_ATTRf(cgroup, <token> <answer> p_unsigned); 
<token> p_unsigned); <answer> PRINT_ATTRf(text_poke, 
PRINT_ATTRf(build_id, <token> <answer> p_unsigned); 
<token> p_unsigned); <answer> PRINT_ATTRf(inherit_thread, 
PRINT_ATTRf(remove_on_exec, <token> <answer> p_unsigned); 
PRINT_ATTRf(sigtrap, <token> <answer> p_unsigned); 
PRINT_ATTRn("{ wakeup_events, wakeup_watermark }", wakeup_events, p_unsigned, <token> <answer> false); 
PRINT_ATTRf(bp_type, <token> <answer> p_unsigned); 
PRINT_ATTRn("{ <token> config1 }", bp_addr, p_hex, false); <answer> bp_addr, 
<token> bp_len, config2 }", bp_len, p_hex, false); <answer> PRINT_ATTRn("{ 
<token> p_branch_sample_type); <answer> PRINT_ATTRf(branch_sample_type, 
PRINT_ATTRf(sample_regs_user, <token> <answer> p_hex); 
PRINT_ATTRf(sample_stack_user, <token> <answer> p_unsigned); 
<token> p_signed); <answer> PRINT_ATTRf(clockid, 
<token> p_hex); <answer> PRINT_ATTRf(sample_regs_intr, 
PRINT_ATTRf(aux_watermark, <token> <answer> p_unsigned); 
PRINT_ATTRf(sample_max_stack, <token> <answer> p_unsigned); 
PRINT_ATTRf(aux_sample_size, <token> <answer> p_unsigned); 
PRINT_ATTRf(sig_data, <token> <answer> p_unsigned); 
<token> ret; <answer> return 
#include <token> <answer> <linux/bits.h> 
<token> <linux/gpio/driver.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/pinctrl/pinmux.h> 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> "../pinctrl-utils.h" 
#include <token> <answer> "pinctrl-bcm63xx.h" 
<token> BCM6328_NUM_GPIOS 32 <answer> #define 
<token> BCM6328_MODE_REG 0x18 <answer> #define 
<token> BCM6328_MUX_HI_REG 0x1c <answer> #define 
<token> BCM6328_MUX_LO_REG 0x20 <answer> #define 
#define BCM6328_MUX_OTHER_REG <token> <answer> 0x24 
#define BCM6328_MUX_MASK <token> 0) <answer> GENMASK(1, 
<token> bcm6328_function { <answer> struct 
const <token> *name; <answer> char 
const char * <token> *groups; <answer> const 
<token> unsigned num_groups; <answer> const 
unsigned <token> <answer> mode_val:1; 
<token> mux_val:2; <answer> unsigned 
static <token> unsigned int bcm6328_mux[] = { <answer> const 
<token> const struct pinctrl_pin_desc bcm6328_pins[] = { <answer> static 
<token> "gpio0"), <answer> PINCTRL_PIN(0, 
<token> "gpio1"), <answer> PINCTRL_PIN(1, 
<token> "gpio2"), <answer> PINCTRL_PIN(2, 
PINCTRL_PIN(3, <token> <answer> "gpio3"), 
<token> "gpio4"), <answer> PINCTRL_PIN(4, 
PINCTRL_PIN(5, <token> <answer> "gpio5"), 
PINCTRL_PIN(6, <token> <answer> "gpio6"), 
PINCTRL_PIN(7, <token> <answer> "gpio7"), 
PINCTRL_PIN(8, <token> <answer> "gpio8"), 
PINCTRL_PIN(9, <token> <answer> "gpio9"), 
<token> "gpio10"), <answer> PINCTRL_PIN(10, 
<token> "gpio11"), <answer> PINCTRL_PIN(11, 
PINCTRL_PIN(12, <token> <answer> "gpio12"), 
<token> "gpio13"), <answer> PINCTRL_PIN(13, 
PINCTRL_PIN(14, <token> <answer> "gpio14"), 
<token> "gpio15"), <answer> PINCTRL_PIN(15, 
<token> "gpio16"), <answer> PINCTRL_PIN(16, 
<token> "gpio17"), <answer> PINCTRL_PIN(17, 
PINCTRL_PIN(18, <token> <answer> "gpio18"), 
PINCTRL_PIN(19, <token> <answer> "gpio19"), 
<token> "gpio20"), <answer> PINCTRL_PIN(20, 
PINCTRL_PIN(21, <token> <answer> "gpio21"), 
<token> "gpio22"), <answer> PINCTRL_PIN(22, 
PINCTRL_PIN(23, <token> <answer> "gpio23"), 
<token> "gpio24"), <answer> PINCTRL_PIN(24, 
<token> "gpio25"), <answer> PINCTRL_PIN(25, 
PINCTRL_PIN(26, <token> <answer> "gpio26"), 
PINCTRL_PIN(27, <token> <answer> "gpio27"), 
<token> "gpio28"), <answer> PINCTRL_PIN(28, 
PINCTRL_PIN(29, <token> <answer> "gpio29"), 
<token> "gpio30"), <answer> PINCTRL_PIN(30, 
PINCTRL_PIN(31, <token> <answer> "gpio31"), 
<token> "hsspi_cs1"), <answer> PINCTRL_PIN(36, 
PINCTRL_PIN(38, <token> <answer> "usb_p2"), 
static <token> gpio0_pins[] = { 0 }; <answer> unsigned 
<token> unsigned gpio1_pins[] = { 1 }; <answer> static 
static <token> gpio2_pins[] = { 2 }; <answer> unsigned 
static unsigned gpio3_pins[] = { <token> }; <answer> 3 
<token> unsigned gpio4_pins[] = { 4 }; <answer> static 
<token> unsigned gpio5_pins[] = { 5 }; <answer> static 
static <token> gpio6_pins[] = { 6 }; <answer> unsigned 
static unsigned <token> = { 7 }; <answer> gpio7_pins[] 
static unsigned gpio8_pins[] = <token> 8 }; <answer> { 
static unsigned gpio9_pins[] = { 9 <token> <answer> }; 
<token> unsigned gpio10_pins[] = { 10 }; <answer> static 
static unsigned gpio11_pins[] = <token> 11 }; <answer> { 
static unsigned gpio12_pins[] = { 12 <token> <answer> }; 
static unsigned <token> = { 13 }; <answer> gpio13_pins[] 
static <token> gpio14_pins[] = { 14 }; <answer> unsigned 
static unsigned gpio15_pins[] = { <token> }; <answer> 15 
<token> unsigned gpio16_pins[] = { 16 }; <answer> static 
<token> unsigned gpio17_pins[] = { 17 }; <answer> static 
static <token> gpio18_pins[] = { 18 }; <answer> unsigned 
<token> unsigned gpio19_pins[] = { 19 }; <answer> static 
static unsigned gpio20_pins[] = <token> 20 }; <answer> { 
static unsigned gpio21_pins[] = { 21 <token> <answer> }; 
static unsigned gpio22_pins[] = { 22 <token> <answer> }; 
<token> unsigned gpio23_pins[] = { 23 }; <answer> static 
<token> unsigned gpio24_pins[] = { 24 }; <answer> static 
static unsigned gpio25_pins[] = { 25 <token> <answer> }; 
static unsigned gpio26_pins[] = <token> 26 }; <answer> { 
static unsigned gpio27_pins[] = { <token> }; <answer> 27 
static unsigned gpio28_pins[] <token> { 28 }; <answer> = 
static unsigned gpio29_pins[] = { <token> }; <answer> 29 
static unsigned <token> = { 30 }; <answer> gpio30_pins[] 
static <token> gpio31_pins[] = { 31 }; <answer> unsigned 
static <token> hsspi_cs1_pins[] = { 36 }; <answer> unsigned 
static unsigned <token> = { 38 }; <answer> usb_port1_pins[] 
static struct pingroup bcm6328_groups[] <token> { <answer> = 
#define pr_fmt(fmt) KBUILD_MODNAME <token> " fmt <answer> ": 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/uaccess.h> 
#include <token> <answer> <linux/bitops.h> 
<token> <linux/string.h> <answer> #include 
<token> <linux/tty.h> <answer> #include 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <linux/netdevice.h> 
#include <token> <answer> <linux/skbuff.h> 
#include <token> <answer> <linux/rtnetlink.h> 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/workqueue.h> <answer> #include 
#include <token> <answer> <linux/can.h> 
<token> <linux/can/dev.h> <answer> #include 
<token> <linux/can/skb.h> <answer> #include 
#include <token> <answer> "slcan.h" 
MODULE_DESCRIPTION("serial line CAN <token> <answer> interface"); 
MODULE_AUTHOR("Oliver <token> <socketcan@hartkopp.net>"); <answer> Hartkopp 
<token> Binacchi <dario.binacchi@amarulasolutions.com>"); <answer> MODULE_AUTHOR("Dario 
static void <token> slcan *sl) <answer> slcan_bump_state(struct 
struct net_device *dev = <token> <answer> sl->dev; 
<token> sk_buff *skb; <answer> struct 
<token> can_frame *cf; <answer> struct 
char <token> = sl->rbuff; <answer> *cmd 
<token> rxerr, txerr; <answer> u32 
enum can_state state, rx_state, <token> <answer> tx_state; 
switch <token> { <answer> (cmd[1]) 
<token> 'a': <answer> case 
state = <token> <answer> CAN_STATE_ERROR_ACTIVE; 
<token> 'w': <answer> case 
state <token> CAN_STATE_ERROR_WARNING; <answer> = 
<token> 'p': <answer> case 
<token> = CAN_STATE_ERROR_PASSIVE; <answer> state 
case <token> <answer> 'b': 
state <token> CAN_STATE_BUS_OFF; <answer> = 
<token> (state == sl->can.state || sl->rcount < SLCAN_STATE_FRAME_LEN) <answer> if 
cmd <token> SLCAN_STATE_BE_RXCNT_LEN + SLCAN_CMD_LEN + 1; <answer> += 
cmd[SLCAN_STATE_BE_TXCNT_LEN] <token> 0; <answer> = 
if (kstrtou32(cmd, 10, <token> <answer> &txerr)) 
<token> = 0; <answer> *cmd 
cmd -= <token> <answer> SLCAN_STATE_BE_RXCNT_LEN; 
if (kstrtou32(cmd, <token> &rxerr)) <answer> 10, 
skb = <token> &cf); <answer> alloc_can_err_skb(dev, 
tx_state = txerr >= rxerr ? state : <token> <answer> 0; 
rx_state <token> txerr <= rxerr ? state : 0; <answer> = 
can_change_state(dev, <token> tx_state, rx_state); <answer> cf, 
<token> (state == CAN_STATE_BUS_OFF) { <answer> if 
} else if (skb) <token> <answer> { 
<token> |= CAN_ERR_CNT; <answer> cf->can_id 
<token> = txerr; <answer> cf->data[6] 
cf->data[7] <token> rxerr; <answer> = 
<token> (skb) <answer> if 
static <token> slcan_bump_err(struct slcan *sl) <answer> void 
struct net_device *dev = <token> <answer> sl->dev; 
struct sk_buff <token> <answer> *skb; 
struct can_frame <token> <answer> *cf; 
char <token> = sl->rbuff; <answer> *cmd 
bool rx_errors <token> false, tx_errors = false, rx_over_errors = false; <answer> = 
int <token> len; <answer> i, 
<token> &sl->tty->flags); <answer> set_bit(TTY_DO_WRITE_WAKEUP, 
actual = <token> sl->xbuff, pos - sl->xbuff); <answer> sl->tty->ops->write(sl->tty, 
sl->xleft = (pos - <token> - actual; <answer> sl->xbuff) 
sl->xhead = sl->xbuff <token> actual; <answer> + 
clear_bit(TTY_DO_WRITE_WAKEUP, <token> <answer> &sl->tty->flags); 
actual = <token> sl->xhead, sl->xleft); <answer> sl->tty->ops->write(sl->tty, 
<token> -= actual; <answer> sl->xleft 
sl->xhead += <token> <answer> actual; 
static void slcan_write_wakeup(struct <token> *tty) <answer> tty_struct 
struct slcan *sl <token> tty->disc_data; <answer> = 
static int slcan_transmit_cmd(struct slcan <token> const unsigned char *cmd) <answer> *sl, 
int ret, <token> n; <answer> actual, 
if <token> { <answer> (!sl->tty) 
<token> -ENODEV; <answer> return 
n = scnprintf(sl->xbuff, <token> "%s", cmd); <answer> sizeof(sl->xbuff), 
set_bit(TTY_DO_WRITE_WAKEUP, <token> <answer> &sl->tty->flags); 
actual = sl->tty->ops->write(sl->tty, sl->xbuff, <token> <answer> n); 
sl->xleft <token> n - actual; <answer> = 
<token> = sl->xbuff + actual; <answer> sl->xhead 
set_bit(SLF_XCMD, <token> <answer> &sl->flags); 
ret = <token> <answer> wait_event_interruptible_timeout(sl->xcmd_wait, 
<token> &sl->flags), <answer> !test_bit(SLF_XCMD, 
<token> &sl->flags); <answer> clear_bit(SLF_XCMD, 
if <token> == -ERESTARTSYS) <answer> (ret 
return <token> <answer> ret; 
if (ret == <token> <answer> 0) 
<token> -ETIMEDOUT; <answer> return 
<token> 0; <answer> return 
if (sl->can.bittiming.bitrate == <token> <answer> CAN_BITRATE_UNSET) 
<token> = CAN_BITRATE_UNKNOWN; <answer> sl->can.bittiming.bitrate 
err <token> open_candev(dev); <answer> = 
if (err) <token> <answer> { 
netdev_err(dev, "failed to open <token> device\n"); <answer> can 
return <token> <answer> err; 
if (sl->can.bittiming.bitrate != <token> { <answer> CAN_BITRATE_UNKNOWN) 
for (s = 0; s < <token> s++) { <answer> ARRAY_SIZE(slcan_bitrate_const); 
if (sl->can.bittiming.bitrate <token> slcan_bitrate_const[s]) <answer> == 
snprintf(cmd, sizeof(cmd), "C\rS%d\r", <token> <answer> s); 
<token> = slcan_transmit_cmd(sl, cmd); <answer> err 
if (err) <token> <answer> { 
"failed to send bitrate <token> 'C\\rS%d\\r'\n", <answer> command 
goto <token> <answer> cmd_transmit_failed; 
if (test_bit(CF_ERR_RST, &sl->cmd_flags)) <token> <answer> { 
<token> = slcan_transmit_cmd(sl, "F\r"); <answer> err 
if (err) <token> <answer> { 
<token> to send error command 'F\\r'\n"); <answer> "failed 
<token> cmd_transmit_failed; <answer> goto 
if (sl->can.ctrlmode <token> CAN_CTRLMODE_LISTENONLY) { <answer> & 
err <token> slcan_transmit_cmd(sl, "L\r"); <answer> = 
<token> (err) { <answer> if 
"failed to send listen-only <token> 'L\\r'\n"); <answer> command 
<token> cmd_transmit_failed; <answer> goto 
<token> else { <answer> } 
err <token> slcan_transmit_cmd(sl, "O\r"); <answer> = 
<token> (err) { <answer> if 
"failed to send <token> command 'O\\r'\n"); <answer> open 
<token> cmd_transmit_failed; <answer> goto 
sl->can.state <token> CAN_STATE_ERROR_ACTIVE; <answer> = 
return <token> <answer> 0; 
<token> err; <answer> return 
<token> const struct net_device_ops slcan_netdev_ops = { <answer> static 
<token> = slcan_netdev_open, <answer> .ndo_open 
<token> = slcan_netdev_close, <answer> .ndo_stop 
.ndo_start_xmit <token> slcan_netdev_xmit, <answer> = 
.ndo_change_mtu = <token> <answer> can_change_mtu, 
<token> void slcan_receive_buf(struct tty_struct *tty, const u8 *cp, <answer> static 
<token> u8 *fp, size_t count) <answer> const 
struct <token> *sl = tty->disc_data; <answer> slcan 
<token> (!netif_running(sl->dev)) <answer> if 
static int slcan_open(struct <token> *tty) <answer> tty_struct 
<token> net_device *dev; <answer> struct 
<token> slcan *sl; <answer> struct 
<token> err; <answer> int 
<token> (!capable(CAP_NET_ADMIN)) <answer> if 
<token> -EPERM; <answer> return 
if <token> <answer> (!tty->ops->write) 
return <token> <answer> -EOPNOTSUPP; 
<token> = alloc_candev(sizeof(*sl), 1); <answer> dev 
if <token> <answer> (!dev) 
<token> -ENFILE; <answer> return 
sl = <token> <answer> netdev_priv(dev); 
static void slcan_close(struct <token> *tty) <answer> tty_struct 
<token> slcan *sl = tty->disc_data; <answer> struct 
<token> "amdgpu.h" <answer> #include 
#include <token> <answer> "atom.h" 
#include <token> <answer> <linux/device.h> 
#include <token> <answer> <linux/pci.h> 
<token> <linux/slab.h> <answer> #include 
<token> <linux/acpi.h> <answer> #include 
#define AMD_VBIOS_SIGNATURE <token> 761295520" <answer> " 
#define <token> 0x30 <answer> AMD_VBIOS_SIGNATURE_OFFSET 
#define AMD_VBIOS_SIGNATURE_SIZE <token> <answer> sizeof(AMD_VBIOS_SIGNATURE) 
#define AMD_VBIOS_SIGNATURE_END (AMD_VBIOS_SIGNATURE_OFFSET <token> AMD_VBIOS_SIGNATURE_SIZE) <answer> + 
#define AMD_IS_VALID_VBIOS(p) ((p)[0] == 0x55 && (p)[1] == <token> <answer> 0xAA) 
#define AMD_VBIOS_LENGTH(p) ((p)[2] << <token> <answer> 9) 
static bool <token> *bios, size_t size) <answer> check_atom_bios(uint8_t 
uint16_t <token> bios_header_start; <answer> tmp, 
if (!bios || <token> < 0x49) { <answer> size 
DRM_INFO("vbios mem is null or mem <token> is wrong\n"); <answer> size 
return <token> <answer> false; 
if <token> { <answer> (!AMD_IS_VALID_VBIOS(bios)) 
DRM_INFO("BIOS <token> incorrect %x %x\n", bios[0], bios[1]); <answer> signature 
<token> false; <answer> return 
bios_header_start = <token> | (bios[0x49] << 8); <answer> bios[0x48] 
<token> (!bios_header_start) { <answer> if 
<token> locate bios header\n"); <answer> DRM_INFO("Can't 
return <token> <answer> false; 
tmp = bios_header_start <token> 4; <answer> + 
if <token> < tmp) { <answer> (size 
<token> header is broken\n"); <answer> DRM_INFO("BIOS 
<token> false; <answer> return 
if (!memcmp(bios + tmp, <token> 4) || <answer> "ATOM", 
!memcmp(bios + <token> "MOTA", 4)) { <answer> tmp, 
DRM_DEBUG("ATOMBIOS <token> <answer> detected\n"); 
<token> true; <answer> return 
return <token> <answer> false; 
static bool igp_read_bios_from_vram(struct <token> *adev) <answer> amdgpu_device 
uint8_t <token> *bios; <answer> __iomem 
resource_size_t <token> <answer> vram_base; 
static int amdgpu_atrm_call(acpi_handle <token> uint8_t *bios, <answer> atrm_handle, 
<token> offset, int len) <answer> int 
<token> status; <answer> acpi_status 
union <token> atrm_arg_elements[2], *obj; <answer> acpi_object 
<token> acpi_object_list atrm_arg; <answer> struct 
struct acpi_buffer buffer = { <token> NULL}; <answer> ACPI_ALLOCATE_BUFFER, 
atrm_arg.count <token> 2; <answer> = 
atrm_arg.pointer <token> &atrm_arg_elements[0]; <answer> = 
atrm_arg_elements[0].type = <token> <answer> ACPI_TYPE_INTEGER; 
<token> = offset; <answer> atrm_arg_elements[0].integer.value 
<token> = ACPI_TYPE_INTEGER; <answer> atrm_arg_elements[1].type 
atrm_arg_elements[1].integer.value = <token> <answer> len; 
status = acpi_evaluate_object(atrm_handle, NULL, &atrm_arg, <token> <answer> &buffer); 
if <token> { <answer> (ACPI_FAILURE(status)) 
DRM_ERROR("failed to evaluate <token> got %s\n", acpi_format_exception(status)); <answer> ATRM 
<token> -ENODEV; <answer> return 
obj <token> (union acpi_object *)buffer.pointer; <answer> = 
memcpy(bios+offset, <token> obj->buffer.length); <answer> obj->buffer.pointer, 
len = <token> <answer> obj->buffer.length; 
return <token> <answer> len; 
static bool amdgpu_atrm_get_bios(struct <token> *adev) <answer> amdgpu_device 
<token> ret; <answer> int 
int size = <token> * 1024; <answer> 256 
<token> i; <answer> int 
struct pci_dev *pdev <token> NULL; <answer> = 
<token> dhandle, atrm_handle; <answer> acpi_handle 
<token> status; <answer> acpi_status 
<token> found = false; <answer> bool 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/pci.h> 
#include <token> <answer> <linux/fs.h> 
<token> <linux/firmware.h> <answer> #include 
#include <token> <answer> <sound/core.h> 
#include <token> <answer> <sound/soc.h> 
<token> <asm/platform_sst_audio.h> <answer> #include 
#include <token> <answer> "../sst-mfld-platform.h" 
<token> "sst.h" <answer> #include 
<token> int sst_platform_get_resources(struct intel_sst_drv *ctx) <answer> static 
int ddr_base, ret <token> 0; <answer> = 
struct pci_dev <token> = ctx->pci; <answer> *pci 
ret = <token> SST_DRV_NAME); <answer> pci_request_regions(pci, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
<token> int intel_sst_probe(struct pci_dev *pci, <answer> static 
const struct pci_device_id <token> <answer> *pci_id) 
<token> ret = 0; <answer> int 
<token> intel_sst_drv *sst_drv_ctx; <answer> struct 
struct sst_platform_info *sst_pdata <token> pci->dev.platform_data; <answer> = 
dev_dbg(&pci->dev, <token> for DID %x\n", pci->device); <answer> "Probe 
ret <token> sst_alloc_drv_context(&sst_drv_ctx, &pci->dev, pci->device); <answer> = 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
sst_drv_ctx->pdata <token> sst_pdata; <answer> = 
<token> = pci->irq; <answer> sst_drv_ctx->irq_num 
<token> sizeof(sst_drv_ctx->firmware_name), <answer> snprintf(sst_drv_ctx->firmware_name, 
"%s%04x%s", <token> <answer> "fw_sst_", 
<token> ".bin"); <answer> sst_drv_ctx->dev_id, 
<token> = sst_context_init(sst_drv_ctx); <answer> ret 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
static <token> intel_sst_remove(struct pci_dev *pci) <answer> void 
struct intel_sst_drv <token> = pci_get_drvdata(pci); <answer> *sst_drv_ctx 
<token> NULL); <answer> pci_set_drvdata(pci, 
#include <token> <answer> "a8293.h" 
#define A8293_FLAG_ODT <token> <answer> 0x10 
struct a8293_dev <token> <answer> { 
struct i2c_client <token> <answer> *client; 
u8 <token> <answer> reg[2]; 
int <token> <answer> volt_slew_nanos_per_mv; 
static int a8293_set_voltage_slew(struct a8293_dev <token> <answer> *dev, 
struct <token> *client, <answer> i2c_client 
enum fe_sec_voltage <token> <answer> fe_sec_voltage, 
<token> min_nanos_per_mv) <answer> int 
<token> ret; <answer> int 
<token> reg0, reg1; <answer> u8 
<token> new_volt_idx; <answer> int 
<token> int idx_to_mv[] = { <answer> const 
0, 12709, 13042, <token> 14042, 15042, 18042, 18709, 19042 <answer> 13375, 
<token> u8 idx_to_reg[] = { <answer> const 
0x00, 0x20, <token> 0x22, 0x24, 0x27, 0x28, 0x2A, 0x2B <answer> 0x21, 
int <token> <answer> this_volt_idx; 
<token> status; <answer> u8 
int <token> <answer> prev_volt_idx; 
dev_dbg(&client->dev, "set_voltage_slew <token> <answer> fe_sec_voltage=%d\n", 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/netdevice.h> 
#include <token> <answer> <linux/etherdevice.h> 
#include <token> <answer> <linux/ethtool.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/moduleparam.h> <answer> #include 
<token> <linux/rtnetlink.h> <answer> #include 
#include <token> <answer> <linux/net_tstamp.h> 
#include <token> <answer> <net/rtnetlink.h> 
#include <token> <answer> <linux/u64_stats_sync.h> 
<token> DRV_NAME "dummy" <answer> #define 
static int numdummies <token> 1; <answer> = 
<token> <linux/hdmi.h> <answer> #include 
#include <token> <answer> <drm/drm_edid.h> 
<token> <drm/radeon_drm.h> <answer> #include 
#include <token> <answer> "evergreen_hdmi.h" 
<token> "radeon.h" <answer> #include 
<token> "radeon_asic.h" <answer> #include 
<token> "radeon_audio.h" <answer> #include 
#include <token> <answer> "evergreend.h" 
#include <token> <answer> "atom.h" 
void evergreen_set_avi_packet(struct <token> *rdev, u32 offset, <answer> radeon_device 
unsigned <token> *buffer, size_t size) <answer> char 
uint8_t *frame = buffer <token> 3; <answer> + 
WREG32(AFMT_AVI_INFO0 + <token> <answer> offset, 
frame[0x0] | (frame[0x1] << 8) | (frame[0x2] << 16) | (frame[0x3] <token> 24)); <answer> << 
WREG32(AFMT_AVI_INFO1 + <token> <answer> offset, 
frame[0x4] | (frame[0x5] << 8) | (frame[0x6] <token> 16) | (frame[0x7] << 24)); <answer> << 
WREG32(AFMT_AVI_INFO2 <token> offset, <answer> + 
frame[0x8] | (frame[0x9] << <token> | (frame[0xA] << 16) | (frame[0xB] << 24)); <answer> 8) 
<token> + offset, <answer> WREG32(AFMT_AVI_INFO3 
frame[0xC] | (frame[0xD] << <token> | (buffer[1] << 24)); <answer> 8) 
WREG32_P(HDMI_INFOFRAME_CONTROL1 <token> offset, <answer> + 
WREG32(DCCG_AUDIO_DTO0_PHASE, <token> <answer> dto_phase); 
<token> clock); <answer> WREG32(DCCG_AUDIO_DTO0_MODULE, 
void <token> radeon_device *rdev, <answer> dce4_dp_audio_set_dto(struct 
<token> radeon_crtc *crtc, unsigned int clock) <answer> struct 
<token> value; <answer> u32 
value = RREG32(DCCG_AUDIO_DTO1_CNTL) & <token> <answer> ~DCCG_AUDIO_DTO_WALLCLOCK_RATIO_MASK; 
value <token> DCCG_AUDIO_DTO1_USE_512FBR_DTO; <answer> |= 
WREG32(DCCG_AUDIO_DTO1_CNTL, <token> <answer> value); 
<token> (ASIC_IS_DCE41(rdev)) { <answer> if 
unsigned <token> div = (RREG32(DCE41_DENTIST_DISPCLK_CNTL) & <answer> int 
<token> >> <answer> DENTIST_DPREFCLK_WDIVIDER_MASK) 
div = <token> <answer> radeon_audio_decode_dfs_div(div); 
if <token> <answer> (div) 
clock = 100 * clock <token> div; <answer> / 
<token> 24000); <answer> WREG32(DCCG_AUDIO_DTO1_PHASE, 
WREG32(DCCG_AUDIO_DTO1_MODULE, <token> <answer> clock); 
void dce4_set_vbi_packet(struct drm_encoder *encoder, u32 <token> <answer> offset) 
struct drm_device *dev <token> encoder->dev; <answer> = 
struct radeon_device *rdev <token> dev->dev_private; <answer> = 
WREG32(HDMI_VBI_PACKET_CONTROL + <token> <answer> offset, 
<token> <linux/utsname.h> <answer> #include 
#include <token> <answer> <net/cfg80211.h> 
<token> "core.h" <answer> #include 
<token> "rdev-ops.h" <answer> #include 
void cfg80211_get_drvinfo(struct net_device *dev, struct <token> *info) <answer> ethtool_drvinfo 
struct wireless_dev *wdev <token> dev->ieee80211_ptr; <answer> = 
struct device *pdev <token> wiphy_dev(wdev->wiphy); <answer> = 
<token> (pdev->driver) <answer> if 
<token> pdev->driver->name, <answer> strscpy(info->driver, 
strscpy(info->driver, <token> sizeof(info->driver)); <answer> "N/A", 
strscpy(info->version, init_utsname()->release, <token> <answer> sizeof(info->version)); 
if <token> <answer> (wdev->wiphy->fw_version[0]) 
strscpy(info->fw_version, <token> <answer> wdev->wiphy->fw_version, 
strscpy(info->fw_version, <token> sizeof(info->fw_version)); <answer> "N/A", 
<token> dev_name(wiphy_dev(wdev->wiphy)), <answer> strscpy(info->bus_info, 
<token> <linux/bits.h> <answer> #include 
#include <token> <answer> <linux/bitfield.h> 
<token> <linux/device.h> <answer> #include 
<token> <linux/gfp.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/kthread.h> 
<token> <linux/list.h> <answer> #include 
<token> <linux/mutex.h> <answer> #include 
<token> <linux/netdevice.h> <answer> #include 
#include <token> <answer> <linux/skbuff.h> 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/wait.h> <answer> #include 
#include <token> <answer> <linux/wwan.h> 
<token> "t7xx_hif_cldma.h" <answer> #include 
#include <token> <answer> "t7xx_modem_ops.h" 
#include <token> <answer> "t7xx_port.h" 
#include <token> <answer> "t7xx_port_proxy.h" 
<token> "t7xx_state_monitor.h" <answer> #include 
#define Q_IDX_CTRL <token> <answer> 0 
<token> Q_IDX_MBIM 2 <answer> #define 
#define <token> 5 <answer> Q_IDX_AT_CMD 
<token> INVALID_SEQ_NUM GENMASK(15, 0) <answer> #define 
<token> for_each_proxy_port(i, p, proxy) \ <answer> #define 
for <token> = 0, (p) = &(proxy)->ports[i]; \ <answer> (i 
<token> < (proxy)->port_count; \ <answer> i 
<token> (p) = &(proxy)->ports[i]) <answer> i++, 
<token> T7XX_MAX_POSSIBLE_PORTS_NUM \ <answer> #define 
<token> ARRAY_SIZE(t7xx_early_port_conf))) <answer> (max(ARRAY_SIZE(t7xx_port_conf), 
static const struct t7xx_port_conf t7xx_port_conf[] = <token> <answer> { 
<token> = PORT_CH_UART2_TX, <answer> .tx_ch 
.rx_ch = <token> <answer> PORT_CH_UART2_RX, 
<token> = Q_IDX_AT_CMD, <answer> .txq_index 
<token> = Q_IDX_AT_CMD, <answer> .rxq_index 
.txq_exp_index = <token> <answer> 0xff, 
<token> = 0xff, <answer> .rxq_exp_index 
.path_id <token> CLDMA_ID_MD, <answer> = 
.ops = <token> <answer> &wwan_sub_port_ops, 
.name = <token> <answer> "AT", 
.port_type = <token> <answer> WWAN_PORT_AT, 
}, <token> <answer> { 
.tx_ch <token> PORT_CH_MBIM_TX, <answer> = 
.rx_ch = <token> <answer> PORT_CH_MBIM_RX, 
.txq_index = <token> <answer> Q_IDX_MBIM, 
.rxq_index <token> Q_IDX_MBIM, <answer> = 
.path_id = <token> <answer> CLDMA_ID_MD, 
.ops = <token> <answer> &wwan_sub_port_ops, 
.name = <token> <answer> "MBIM", 
.port_type = <token> <answer> WWAN_PORT_MBIM, 
}, <token> <answer> { 
<token> CONFIG_WWAN_DEBUGFS <answer> #ifdef 
.tx_ch <token> PORT_CH_MD_LOG_TX, <answer> = 
<token> = PORT_CH_MD_LOG_RX, <answer> .rx_ch 
.txq_index <token> 7, <answer> = 
<token> = 7, <answer> .rxq_index 
<token> = 7, <answer> .txq_exp_index 
<token> = 7, <answer> .rxq_exp_index 
.path_id <token> CLDMA_ID_MD, <answer> = 
<token> = &t7xx_trace_port_ops, <answer> .ops 
<token> = "mdlog", <answer> .name 
}, <token> <answer> { 
<token> = PORT_CH_CONTROL_TX, <answer> .tx_ch 
<token> = PORT_CH_CONTROL_RX, <answer> .rx_ch 
<token> = Q_IDX_CTRL, <answer> .txq_index 
<token> = Q_IDX_CTRL, <answer> .rxq_index 
<token> = CLDMA_ID_MD, <answer> .path_id 
<token> = &ctl_port_ops, <answer> .ops 
<token> = "t7xx_ctrl", <answer> .name 
<token> { <answer> }, 
<token> = PORT_CH_AP_CONTROL_TX, <answer> .tx_ch 
.rx_ch <token> PORT_CH_AP_CONTROL_RX, <answer> = 
<token> = Q_IDX_CTRL, <answer> .txq_index 
<token> = Q_IDX_CTRL, <answer> .rxq_index 
.path_id = <token> <answer> CLDMA_ID_AP, 
<token> = &ctl_port_ops, <answer> .ops 
.name <token> "t7xx_ap_ctrl", <answer> = 
<token> const struct t7xx_port_conf t7xx_early_port_conf[] = { <answer> static 
.tx_ch <token> PORT_CH_UNIMPORTANT, <answer> = 
<token> = PORT_CH_UNIMPORTANT, <answer> .rx_ch 
.txq_index = <token> <answer> CLDMA_Q_IDX_DUMP, 
.rxq_index = <token> <answer> CLDMA_Q_IDX_DUMP, 
.txq_exp_index <token> CLDMA_Q_IDX_DUMP, <answer> = 
<token> = CLDMA_Q_IDX_DUMP, <answer> .rxq_exp_index 
<token> = CLDMA_ID_AP, <answer> .path_id 
.ops <token> &wwan_sub_port_ops, <answer> = 
.name = <token> <answer> "fastboot", 
<token> = WWAN_PORT_FASTBOOT, <answer> .port_type 
static struct t7xx_port <token> port_proxy *port_prox, enum port_ch ch) <answer> *t7xx_proxy_get_port_by_ch(struct 
const struct <token> *port_conf; <answer> t7xx_port_conf 
struct t7xx_port <token> <answer> *port; 
int <token> <answer> i; 
for_each_proxy_port(i, port, port_prox) <token> <answer> { 
port_conf <token> port->port_conf; <answer> = 
if (port_conf->rx_ch == ch <token> port_conf->tx_ch == ch) <answer> || 
<token> port; <answer> return 
return <token> <answer> NULL; 
static u16 t7xx_port_next_rx_seq_num(struct t7xx_port *port, struct ccci_header <token> <answer> *ccci_h) 
u32 status = <token> <answer> le32_to_cpu(ccci_h->status); 
u16 <token> next_seq_num; <answer> seq_num, 
bool <token> <answer> assert_bit; 
seq_num = FIELD_GET(CCCI_H_SEQ_FLD, <token> <answer> status); 
next_seq_num = <token> + 1) & FIELD_MAX(CCCI_H_SEQ_FLD); <answer> (seq_num 
assert_bit = status & <token> <answer> CCCI_H_AST_BIT; 
<token> (!assert_bit || port->seq_nums[MTK_RX] == INVALID_SEQ_NUM) <answer> if 
return <token> <answer> next_seq_num; 
<token> (seq_num != port->seq_nums[MTK_RX]) <answer> if 
"seq num out-of-order %u != %u (header <token> len %X)\n", <answer> %X, 
seq_num, <token> <answer> port->seq_nums[MTK_RX], 
<token> next_seq_num; <answer> return 
<token> t7xx_port_proxy_reset(struct port_proxy *port_prox) <answer> void 
<token> t7xx_port *port; <answer> struct 
<token> i; <answer> int 
for_each_proxy_port(i, <token> port_prox) { <answer> port, 
port->seq_nums[MTK_RX] <token> INVALID_SEQ_NUM; <answer> = 
port->seq_nums[MTK_TX] <token> 0; <answer> = 
static int <token> t7xx_port *port) <answer> t7xx_port_get_queue_no(struct 
const struct t7xx_port_conf <token> = port->port_conf; <answer> *port_conf 
<token> t7xx_fsm_ctl *ctl = port->t7xx_dev->md->fsm_ctl; <answer> struct 
return t7xx_fsm_get_md_state(ctl) <token> MD_STATE_EXCEPTION ? <answer> == 
port_conf->txq_exp_index <token> port_conf->txq_index; <answer> : 
static void t7xx_port_struct_init(struct <token> *port) <answer> t7xx_port 
<token> = INVALID_SEQ_NUM; <answer> port->seq_nums[MTK_RX] 
<token> = 0; <answer> port->seq_nums[MTK_TX] 
atomic_set(&port->usage_cnt, <token> <answer> 0); 
struct <token> *t7xx_port_alloc_skb(int payload) <answer> sk_buff 
struct sk_buff *skb = __dev_alloc_skb(payload + sizeof(struct ccci_header), <token> <answer> GFP_KERNEL); 
<token> (skb) <answer> if 
skb_reserve(skb, <token> ccci_header)); <answer> sizeof(struct 
<token> skb; <answer> return 
struct sk_buff *t7xx_ctrl_alloc_skb(int <token> <answer> payload) 
struct sk_buff *skb = t7xx_port_alloc_skb(payload + <token> ctrl_msg_header)); <answer> sizeof(struct 
<token> (skb) <answer> if 
skb_reserve(skb, sizeof(struct <token> <answer> ctrl_msg_header)); 
return <token> <answer> skb; 
int <token> t7xx_port *port, struct sk_buff *skb) <answer> t7xx_port_enqueue_skb(struct 
unsigned long <token> <answer> flags; 
spin_lock_irqsave(&port->rx_wq.lock, <token> <answer> flags); 
if (port->rx_skb_list.qlen >= port->rx_length_th) <token> <answer> { 
spin_unlock_irqrestore(&port->rx_wq.lock, <token> <answer> flags); 
<token> -ENOBUFS; <answer> return 
__skb_queue_tail(&port->rx_skb_list, <token> <answer> skb); 
spin_unlock_irqrestore(&port->rx_wq.lock, <token> <answer> flags); 
return <token> <answer> 0; 
int t7xx_get_port_mtu(struct <token> *port) <answer> t7xx_port 
enum cldma_id <token> = port->port_conf->path_id; <answer> path_id 
int tx_qno <token> t7xx_port_get_queue_no(port); <answer> = 
struct cldma_ctrl <token> <answer> *md_ctrl; 
md_ctrl <token> port->t7xx_dev->md->md_ctrl[path_id]; <answer> = 
return <token> <answer> md_ctrl->tx_ring[tx_qno].pkt_size; 
int t7xx_port_send_raw_skb(struct t7xx_port *port, <token> sk_buff *skb) <answer> struct 
enum cldma_id path_id <token> port->port_conf->path_id; <answer> = 
struct <token> *md_ctrl; <answer> cldma_ctrl 
int <token> tx_qno; <answer> ret, 
md_ctrl = <token> <answer> port->t7xx_dev->md->md_ctrl[path_id]; 
tx_qno <token> t7xx_port_get_queue_no(port); <answer> = 
ret = t7xx_cldma_send_skb(md_ctrl, tx_qno, <token> <answer> skb); 
<token> (ret) <answer> if 
dev_err(port->dev, "Failed to send skb: %d\n", <token> <answer> ret); 
<token> ret; <answer> return 
static <token> t7xx_port_send_ccci_skb(struct t7xx_port *port, struct sk_buff *skb, <answer> int 
unsigned int <token> unsigned int ex_msg) <answer> pkt_header, 
const struct <token> *port_conf = port->port_conf; <answer> t7xx_port_conf 
<token> ccci_header *ccci_h; <answer> struct 
u32 <token> <answer> status; 
<token> ret; <answer> int 
<token> = skb_push(skb, sizeof(*ccci_h)); <answer> ccci_h 
status <token> FIELD_PREP(CCCI_H_CHN_FLD, port_conf->tx_ch) | <answer> = 
FIELD_PREP(CCCI_H_SEQ_FLD, port->seq_nums[MTK_TX]) <token> CCCI_H_AST_BIT; <answer> | 
ccci_h->status = <token> <answer> cpu_to_le32(status); 
ccci_h->packet_header <token> cpu_to_le32(pkt_header); <answer> = 
<token> = cpu_to_le32(skb->len); <answer> ccci_h->packet_len 
ccci_h->ex_msg = <token> <answer> cpu_to_le32(ex_msg); 
ret = t7xx_port_send_raw_skb(port, <token> <answer> skb); 
<token> (ret) <answer> if 
<token> ret; <answer> return 
return <token> <answer> 0; 
int t7xx_port_send_ctl_skb(struct t7xx_port *port, struct sk_buff *skb, <token> int msg, <answer> unsigned 
<token> int ex_msg) <answer> unsigned 
struct ctrl_msg_header <token> <answer> *ctrl_msg_h; 
unsigned int <token> = skb->len; <answer> msg_len 
<token> pkt_header = 0; <answer> u32 
ctrl_msg_h = skb_push(skb, <token> <answer> sizeof(*ctrl_msg_h)); 
<token> = cpu_to_le32(msg); <answer> ctrl_msg_h->ctrl_msg_id 
ctrl_msg_h->ex_msg <token> cpu_to_le32(ex_msg); <answer> = 
<token> = cpu_to_le32(msg_len); <answer> ctrl_msg_h->data_length 
<token> (!msg_len) <answer> if 
pkt_header = <token> <answer> CCCI_HEADER_NO_DATA; 
return t7xx_port_send_ccci_skb(port, skb, <token> ex_msg); <answer> pkt_header, 
int t7xx_port_send_skb(struct t7xx_port *port, struct sk_buff *skb, unsigned <token> pkt_header, <answer> int 
<token> int ex_msg) <answer> unsigned 
struct t7xx_fsm_ctl *ctl <token> port->t7xx_dev->md->fsm_ctl; <answer> = 
unsigned int <token> <answer> fsm_state; 
fsm_state <token> t7xx_fsm_get_ctl_state(ctl); <answer> = 
if (fsm_state <token> FSM_STATE_PRE_START) { <answer> != 
const struct t7xx_port_conf *port_conf = <token> <answer> port->port_conf; 
enum md_state <token> = t7xx_fsm_get_md_state(ctl); <answer> md_state 
<token> (md_state) { <answer> switch 
case <token> <answer> MD_STATE_EXCEPTION: 
if (port_conf->tx_ch != <token> <answer> PORT_CH_MD_LOG_TX) 
<token> -EBUSY; <answer> return 
case <token> <answer> MD_STATE_WAITING_FOR_HS1: 
<token> MD_STATE_WAITING_FOR_HS2: <answer> case 
<token> MD_STATE_STOPPED: <answer> case 
<token> MD_STATE_WAITING_TO_STOP: <answer> case 
<token> MD_STATE_INVALID: <answer> case 
return <token> <answer> -ENODEV; 
return t7xx_port_send_ccci_skb(port, skb, pkt_header, <token> <answer> ex_msg); 
static void <token> port_proxy *port_prox) <answer> t7xx_proxy_setup_ch_mapping(struct 
struct t7xx_port <token> <answer> *port; 
int i, <token> <answer> j; 
for (i = 0; i < ARRAY_SIZE(port_prox->rx_ch_ports); <token> <answer> i++) 
for (j = <token> j < ARRAY_SIZE(port_prox->queue_ports); j++) { <answer> 0; 
for <token> = 0; i < ARRAY_SIZE(port_prox->queue_ports[j]); i++) <answer> (i 
for_each_proxy_port(i, port, port_prox) <token> <answer> { 
const struct <token> *port_conf = port->port_conf; <answer> t7xx_port_conf 
enum cldma_id <token> = port_conf->path_id; <answer> path_id 
u8 <token> <answer> ch_id; 
ch_id = <token> port_conf->rx_ch); <answer> FIELD_GET(PORT_CH_ID_MASK, 
<token> &port_prox->rx_ch_ports[ch_id]); <answer> list_add_tail(&port->entry, 
int t7xx_port_proxy_recv_skb_from_dedicated_queue(struct <token> *queue, struct sk_buff *skb) <answer> cldma_queue 
struct <token> *t7xx_dev = queue->md_ctrl->t7xx_dev; <answer> t7xx_pci_dev 
struct port_proxy *port_prox <token> t7xx_dev->md->port_prox; <answer> = 
const <token> t7xx_port_conf *port_conf; <answer> struct 
<token> t7xx_port *port; <answer> struct 
<token> ret; <answer> int 
port <token> &port_prox->ports[0]; <answer> = 
if (WARN_ON_ONCE(port->port_conf->rxq_index <token> queue->index)) { <answer> != 
return <token> <answer> -EINVAL; 
port_conf <token> port->port_conf; <answer> = 
<token> = port_conf->ops->recv_skb(port, skb); <answer> ret 
if (ret < <token> && ret != -ENOBUFS) { <answer> 0 
dev_err(port->dev, "drop on RX ch %d, %d\n", port_conf->rx_ch, <token> <answer> ret); 
<token> ret; <answer> return 
static struct t7xx_port *t7xx_port_proxy_find_port(struct t7xx_pci_dev <token> <answer> *t7xx_dev, 
struct cldma_queue *queue, u16 <token> <answer> channel) 
struct <token> *port_prox = t7xx_dev->md->port_prox; <answer> port_proxy 
<token> list_head *port_list; <answer> struct 
struct <token> *port; <answer> t7xx_port 
u8 <token> <answer> ch_id; 
ch_id = FIELD_GET(PORT_CH_ID_MASK, <token> <answer> channel); 
port_list <token> &port_prox->rx_ch_ports[ch_id]; <answer> = 
list_for_each_entry(port, port_list, entry) <token> <answer> { 
const struct <token> *port_conf = port->port_conf; <answer> t7xx_port_conf 
if <token> == port_conf->path_id && <answer> (queue->md_ctrl->hif_id 
channel <token> port_conf->rx_ch) <answer> == 
<token> port; <answer> return 
<token> NULL; <answer> return 
int t7xx_port_proxy_recv_skb(struct cldma_queue *queue, <token> sk_buff *skb) <answer> struct 
struct ccci_header *ccci_h <token> (struct ccci_header *)skb->data; <answer> = 
struct t7xx_pci_dev <token> = queue->md_ctrl->t7xx_dev; <answer> *t7xx_dev 
struct t7xx_fsm_ctl <token> = t7xx_dev->md->fsm_ctl; <answer> *ctl 
struct <token> *dev = queue->md_ctrl->dev; <answer> device 
<token> struct t7xx_port_conf *port_conf; <answer> const 
<token> t7xx_port *port; <answer> struct 
u16 seq_num, <token> <answer> channel; 
int <token> <answer> ret; 
channel = FIELD_GET(CCCI_H_CHN_FLD, <token> <answer> le32_to_cpu(ccci_h->status)); 
if <token> == MD_STATE_INVALID) { <answer> (t7xx_fsm_get_md_state(ctl) 
dev_err_ratelimited(dev, "Packet drop on <token> 0x%x, modem not ready\n", channel); <answer> channel 
<token> drop_skb; <answer> goto 
port = <token> queue, channel); <answer> t7xx_port_proxy_find_port(t7xx_dev, 
<token> (!port) { <answer> if 
dev_err_ratelimited(dev, "Packet drop on <token> 0x%x, port not found\n", channel); <answer> channel 
<token> drop_skb; <answer> goto 
seq_num = <token> ccci_h); <answer> t7xx_port_next_rx_seq_num(port, 
<token> = port->port_conf; <answer> port_conf 
skb_pull(skb, <token> <answer> sizeof(*ccci_h)); 
ret <token> port_conf->ops->recv_skb(port, skb); <answer> = 
<token> t7xx_port_proxy_md_status_notify(struct port_proxy *port_prox, unsigned int state) <answer> void 
struct <token> *port; <answer> t7xx_port 
int <token> <answer> i; 
for_each_proxy_port(i, port, <token> { <answer> port_prox) 
<token> struct t7xx_port_conf *port_conf = port->port_conf; <answer> const 
if <token> <answer> (port_conf->ops->md_state_notify) 
<token> state); <answer> port_conf->ops->md_state_notify(port, 
static void t7xx_proxy_init_all_ports(struct t7xx_modem <token> <answer> *md) 
<token> port_proxy *port_prox = md->port_prox; <answer> struct 
struct t7xx_port <token> <answer> *port; 
int <token> <answer> i; 
<token> port, port_prox) { <answer> for_each_proxy_port(i, 
const struct t7xx_port_conf *port_conf = <token> <answer> port->port_conf; 
if (port_conf->tx_ch == <token> <answer> PORT_CH_CONTROL_TX) 
<token> = port; <answer> md->core_md.ctl_port 
if (port_conf->tx_ch <token> PORT_CH_AP_CONTROL_TX) <answer> == 
md->core_ap.ctl_port = <token> <answer> port; 
port->t7xx_dev = <token> <answer> md->t7xx_dev; 
port->dev = <token> <answer> &md->t7xx_dev->pdev->dev; 
<token> = false; <answer> port->chan_enable 
if <token> && port_conf->ops->init) <answer> (port_conf->ops 
void t7xx_port_proxy_set_cfg(struct t7xx_modem *md, enum port_cfg_id <token> <answer> cfg_id) 
<token> port_proxy *port_prox = md->port_prox; <answer> struct 
const struct t7xx_port_conf <token> <answer> *port_conf; 
<token> port_count; <answer> u32 
int <token> <answer> i; 
if (cfg_id == <token> { <answer> PORT_CFG_ID_EARLY) 
port_conf <token> t7xx_early_port_conf; <answer> = 
port_count <token> ARRAY_SIZE(t7xx_early_port_conf); <answer> = 
<token> else { <answer> } 
port_conf <token> t7xx_port_conf; <answer> = 
port_count <token> ARRAY_SIZE(t7xx_port_conf); <answer> = 
for (i = 0; i < <token> i++) <answer> port_count; 
port_prox->ports[i].port_conf <token> &port_conf[i]; <answer> = 
<token> = cfg_id; <answer> port_prox->cfg_id 
port_prox->port_count <token> port_count; <answer> = 
static int t7xx_proxy_alloc(struct t7xx_modem <token> <answer> *md) 
<token> device *dev = &md->t7xx_dev->pdev->dev; <answer> struct 
struct <token> *port_prox; <answer> port_proxy 
<token> = devm_kzalloc(dev, <answer> port_prox 
<token> (!port_prox) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = port_prox; <answer> md->port_prox 
<token> = dev; <answer> port_prox->dev 
<token> PORT_CFG_ID_EARLY); <answer> t7xx_port_proxy_set_cfg(md, 
return <token> <answer> 0; 
int <token> t7xx_modem *md) <answer> t7xx_port_proxy_init(struct 
<token> ret; <answer> int 
ret = <token> <answer> t7xx_proxy_alloc(md); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
return <token> <answer> 0; 
void t7xx_port_proxy_uninit(struct port_proxy <token> <answer> *port_prox) 
struct <token> *port; <answer> t7xx_port 
int <token> <answer> i; 
for_each_proxy_port(i, <token> port_prox) { <answer> port, 
const struct t7xx_port_conf *port_conf = <token> <answer> port->port_conf; 
<token> (port_conf->ops && port_conf->ops->uninit) <answer> if 
int t7xx_port_proxy_chl_enable_disable(struct port_proxy *port_prox, unsigned <token> ch_id, <answer> int 
bool <token> <answer> en_flag) 
<token> t7xx_port *port = t7xx_proxy_get_port_by_ch(port_prox, ch_id); <answer> struct 
const <token> t7xx_port_conf *port_conf; <answer> struct 
<token> (!port) <answer> if 
return <token> <answer> -EINVAL; 
port_conf <token> port->port_conf; <answer> = 
if <token> { <answer> (en_flag) 
<token> (port_conf->ops->enable_chl) <answer> if 
<token> else { <answer> } 
<token> (port_conf->ops->disable_chl) <answer> if 
<token> 0; <answer> return 
#include <token> <answer> <linux/debugfs.h> 
<token> <linux/device.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/of.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/seq_file.h> 
#include <token> <answer> <linux/soc/qcom/smem.h> 
<token> <clocksource/arm_arch_timer.h> <answer> #include 
#define RPM_DYNAMIC_ADDR <token> <answer> 0x14 
#define <token> 0xFFFF <answer> RPM_DYNAMIC_ADDR_MASK 
#define STAT_TYPE_OFFSET <token> <answer> 0x0 
#define <token> 0x4 <answer> COUNT_OFFSET 
#define <token> 0x8 <answer> LAST_ENTERED_AT_OFFSET 
#define LAST_EXITED_AT_OFFSET <token> <answer> 0x10 
#define <token> 0x18 <answer> ACCUMULATED_OFFSET 
<token> CLIENT_VOTES_OFFSET 0x20 <answer> #define 
struct subsystem_data <token> <answer> { 
<token> char *name; <answer> const 
<token> smem_item; <answer> u32 
<token> pid; <answer> u32 
static const struct subsystem_data subsystems[] <token> { <answer> = 
<token> "modem", 605, 1 }, <answer> { 
<token> "wpss", 605, 13 }, <answer> { 
{ "adsp", <token> 2 }, <answer> 606, 
{ <token> 607, 5 }, <answer> "cdsp", 
<token> "slpi", 608, 3 }, <answer> { 
{ "gpu", 609, 0 <token> <answer> }, 
{ <token> 610, 0 }, <answer> "display", 
<token> "adsp_island", 613, 2 }, <answer> { 
{ "slpi_island", 613, <token> }, <answer> 3 
<token> stats_config { <answer> struct 
<token> stats_offset; <answer> size_t 
<token> num_records; <answer> size_t 
<token> appended_stats_avail; <answer> bool 
bool <token> <answer> dynamic_offset; 
bool <token> <answer> subsystem_stats_in_smem; 
struct stats_data <token> <answer> { 
bool <token> <answer> appended_stats_avail; 
void <token> *base; <answer> __iomem 
<token> sleep_stats { <answer> struct 
<token> stat_type; <answer> u32 
<token> count; <answer> u32 
<token> last_entered_at; <answer> u64 
u64 <token> <answer> last_exited_at; 
u64 <token> <answer> accumulated; 
<token> appended_stats { <answer> struct 
<token> client_votes; <answer> u32 
u32 <token> <answer> reserved[3]; 
static void qcom_print_stats(struct seq_file *s, const struct <token> *stat) <answer> sleep_stats 
u64 accumulated <token> stat->accumulated; <answer> = 
if (stat->last_entered_at <token> stat->last_exited_at) <answer> > 
accumulated += <token> - stat->last_entered_at; <answer> arch_timer_read_counter() 
<token> "Count: %u\n", stat->count); <answer> seq_printf(s, 
seq_printf(s, <token> Entered At: %llu\n", stat->last_entered_at); <answer> "Last 
seq_printf(s, "Last <token> At: %llu\n", stat->last_exited_at); <answer> Exited 
<token> "Accumulated Duration: %llu\n", accumulated); <answer> seq_printf(s, 
static int qcom_subsystem_sleep_stats_show(struct seq_file <token> void *unused) <answer> *s, 
struct subsystem_data <token> = s->private; <answer> *subsystem 
struct sleep_stats <token> <answer> *stat; 
<token> (config->dynamic_offset) { <answer> if 
stats_offset <token> readl(reg + RPM_DYNAMIC_ADDR); <answer> = 
<token> &= RPM_DYNAMIC_ADDR_MASK; <answer> stats_offset 
for (i = 0; i < config->num_records; i++) <token> <answer> { 
d[i].base = reg + offset + <token> <answer> stats_offset; 
type = <token> <answer> readl(d[i].base); 
for (j = 0; j < sizeof(u32); <token> { <answer> j++) 
stat_type[j] <token> type & 0xff; <answer> = 
type <token> type >> 8; <answer> = 
<token> 0400, root, &d[i], <answer> debugfs_create_file(stat_type, 
offset <token> sizeof(struct sleep_stats); <answer> += 
<token> (d[i].appended_stats_avail) <answer> if 
offset += sizeof(struct <token> <answer> appended_stats); 
static void qcom_create_subsystem_stat_files(struct dentry <token> <answer> *root, 
const struct <token> *config) <answer> stats_config 
int <token> <answer> i; 
<token> (!config->subsystem_stats_in_smem) <answer> if 
<token> (i = 0; i < ARRAY_SIZE(subsystems); i++) <answer> for 
debugfs_create_file(subsystems[i].name, 0400, <token> (void *)&subsystems[i], <answer> root, 
static int <token> platform_device *pdev) <answer> qcom_stats_probe(struct 
<token> __iomem *reg; <answer> void 
struct <token> *root; <answer> dentry 
const struct stats_config <token> <answer> *config; 
<token> stats_data *d; <answer> struct 
<token> i; <answer> int 
config <token> device_get_match_data(&pdev->dev); <answer> = 
if <token> <answer> (!config) 
return <token> <answer> -ENODEV; 
<token> = devm_platform_get_and_ioremap_resource(pdev, 0, NULL); <answer> reg 
<token> (IS_ERR(reg)) <answer> if 
return <token> <answer> -ENOMEM; 
d <token> devm_kcalloc(&pdev->dev, config->num_records, <answer> = 
<token> GFP_KERNEL); <answer> sizeof(*d), 
<token> (!d) <answer> if 
<token> -ENOMEM; <answer> return 
<token> (i = 0; i < config->num_records; i++) <answer> for 
<token> = config->appended_stats_avail; <answer> d[i].appended_stats_avail 
<token> = debugfs_create_dir("qcom_stats", NULL); <answer> root 
<token> config); <answer> qcom_create_subsystem_stat_files(root, 
qcom_create_soc_sleep_stat_files(root, reg, d, <token> <answer> config); 
<token> root); <answer> platform_set_drvdata(pdev, 
<token> 0; <answer> return 
static void qcom_stats_remove(struct <token> *pdev) <answer> platform_device 
struct dentry *root = <token> <answer> platform_get_drvdata(pdev); 
static const struct stats_config <token> = { <answer> rpm_data 
.stats_offset = <token> <answer> 0, 
<token> = 2, <answer> .num_records 
.appended_stats_avail <token> true, <answer> = 
<token> = true, <answer> .dynamic_offset 
.subsystem_stats_in_smem <token> false, <answer> = 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/mfd/syscon.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/soc/amlogic/meson-canvas.h> 
#include <token> <answer> <linux/of_address.h> 
<token> <linux/of_platform.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#define <token> 256 <answer> NUM_CANVAS 
<token> = dev_get_drvdata(&canvas_pdev->dev); <answer> canvas 
if <token> { <answer> (!canvas) 
<token> ERR_PTR(-EINVAL); <answer> return 
<token> canvas; <answer> return 
int meson_canvas_config(struct meson_canvas *canvas, u8 <token> <answer> canvas_index, 
u32 addr, u32 stride, u32 <token> <answer> height, 
unsigned <token> wrap, <answer> int 
<token> int blkmode, <answer> unsigned 
unsigned <token> endian) <answer> int 
unsigned <token> flags; <answer> long 
<token> (endian && !canvas->supports_endianness) { <answer> if 
<token> is not supported on this SoC\n"); <answer> "Endianness 
return <token> <answer> -EINVAL; 
<token> flags); <answer> spin_lock_irqsave(&canvas->lock, 
<token> (!canvas->used[canvas_index]) { <answer> if 
"Trying to setup non <token> canvas %u\n", <answer> allocated 
spin_unlock_irqrestore(&canvas->lock, <token> <answer> flags); 
return <token> <answer> -EINVAL; 
canvas_write(canvas, <token> <answer> DMC_CAV_LUT_DATAL, 
((addr <token> 7) >> 3) | <answer> + 
(((stride + 7) >> 3) << <token> <answer> CANVAS_WIDTH_LBIT)); 
<token> DMC_CAV_LUT_DATAH, <answer> canvas_write(canvas, 
<token> + 7) >> 3) >> CANVAS_WIDTH_LWID) << <answer> ((((stride 
CANVAS_WIDTH_HBIT) <token> <answer> | 
(height << CANVAS_HEIGHT_BIT) <token> <answer> | 
(wrap << <token> | <answer> CANVAS_WRAP_BIT) 
(blkmode << CANVAS_BLKMODE_BIT) <token> <answer> | 
(endian <token> CANVAS_ENDIAN_BIT)); <answer> << 
canvas_write(canvas, <token> <answer> DMC_CAV_LUT_ADDR, 
CANVAS_LUT_WR_EN | <token> <answer> canvas_index); 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/pci.h> 
#include <token> <answer> "amdgpu.h" 
#include <token> <answer> "amdgpu_pm.h" 
#include <token> <answer> "amdgpu_dpm.h" 
<token> "amdgpu_atombios.h" <answer> #include 
#include <token> <answer> "amdgpu_dpm_internal.h" 
<token> "amd_pcie.h" <answer> #include 
#include <token> <answer> "sid.h" 
#include <token> <answer> "r600_dpm.h" 
#include <token> <answer> "si_dpm.h" 
#include <token> <answer> "atom.h" 
#include <token> <answer> "../include/pptable.h" 
#include <token> <answer> <linux/math64.h> 
<token> <linux/seq_file.h> <answer> #include 
#include <token> <answer> <linux/firmware.h> 
<token> <legacy_dpm.h> <answer> #include 
#define <token> 0x0a <answer> MC_CG_ARB_FREQ_F0 
#define <token> 0x0b <answer> MC_CG_ARB_FREQ_F1 
#define <token> 0x0c <answer> MC_CG_ARB_FREQ_F2 
#define MC_CG_ARB_FREQ_F3 <token> <answer> 0x0d 
#define SMC_RAM_END <token> <answer> 0x20000 
#define SCLK_MIN_DEEPSLEEP_FREQ <token> <answer> 1350 
si_notify_smc_display_change(adev, adev->pm.dpm.new_active_crtc_count > <token> <answer> 0); 
static void si_enable_spread_spectrum(struct amdgpu_device *adev, <token> enable) <answer> bool 
struct <token> *pi = rv770_get_pi(adev); <answer> rv7xx_power_info 
if (enable) <token> <answer> { 
<token> (pi->sclk_ss) <answer> if 
WREG32_P(GENERAL_PWRMGT, DYN_SPREAD_SPECTRUM_EN, <token> <answer> ~DYN_SPREAD_SPECTRUM_EN); 
<token> else { <answer> } 
WREG32_P(CG_SPLL_SPREAD_SPECTRUM, <token> ~SSEN); <answer> 0, 
WREG32_P(GENERAL_PWRMGT, 0, <token> <answer> ~DYN_SPREAD_SPECTRUM_EN); 
static <token> si_setup_bsp(struct amdgpu_device *adev) <answer> void 
struct rv7xx_power_info <token> = rv770_get_pi(adev); <answer> *pi 
u32 xclk <token> amdgpu_asic_get_xclk(adev); <answer> = 
pi->dsp = BSP(pi->bsp) | <token> <answer> BSU(pi->bsu); 
<token> = BSP(pi->pbsp) | BSU(pi->pbsu); <answer> pi->psp 
<token> pi->dsp); <answer> WREG32(CG_BSP, 
<token> void si_program_git(struct amdgpu_device *adev) <answer> static 
WREG32_P(CG_GIT, <token> ~CG_GICST_MASK); <answer> CG_GICST(R600_GICST_DFLT), 
static <token> si_program_tp(struct amdgpu_device *adev) <answer> void 
<token> i; <answer> int 
enum <token> td = R600_TD_DFLT; <answer> r600_td 
for (i = 0; <token> < R600_PM_NUMBER_OF_TC; i++) <answer> i 
WREG32(CG_FFCT_0 <token> i, (UTC_0(r600_utc[i]) | DTC_0(r600_dtc[i]))); <answer> + 
if <token> == R600_TD_AUTO) <answer> (td 
WREG32_P(SCLK_PWRMGT_CNTL, 0, <token> <answer> ~FIR_FORCE_TREND_SEL); 
<token> FIR_FORCE_TREND_SEL, ~FIR_FORCE_TREND_SEL); <answer> WREG32_P(SCLK_PWRMGT_CNTL, 
if (td == <token> <answer> R600_TD_UP) 
WREG32_P(SCLK_PWRMGT_CNTL, <token> ~FIR_TREND_MODE); <answer> 0, 
if (td == <token> <answer> R600_TD_DOWN) 
WREG32_P(SCLK_PWRMGT_CNTL, <token> ~FIR_TREND_MODE); <answer> FIR_TREND_MODE, 
static void si_program_tpp(struct amdgpu_device <token> <answer> *adev) 
<token> R600_TPC_DFLT); <answer> WREG32(CG_TPC, 
<token> void si_program_sstp(struct amdgpu_device *adev) <answer> static 
WREG32(CG_SSP, <token> | SST(R600_SST_DFLT))); <answer> (SSTU(R600_SSTU_DFLT) 
static void <token> amdgpu_device *adev) <answer> si_enable_display_gap(struct 
u32 tmp <token> RREG32(CG_DISPLAY_GAP_CNTL); <answer> = 
tmp &= <token> | DISP2_GAP_MASK); <answer> ~(DISP1_GAP_MASK 
<token> |= (DISP1_GAP(R600_PM_DISPLAY_GAP_IGNORE) | <answer> tmp 
<token> &= ~(DISP1_GAP_MCHG_MASK | DISP2_GAP_MCHG_MASK); <answer> tmp 
tmp |= <token> | <answer> (DISP1_GAP_MCHG(R600_PM_DISPLAY_GAP_VBLANK) 
WREG32(CG_DISPLAY_GAP_CNTL, <token> <answer> tmp); 
static void si_program_vc(struct <token> *adev) <answer> amdgpu_device 
struct rv7xx_power_info *pi <token> rv770_get_pi(adev); <answer> = 
<token> pi->vrc); <answer> WREG32(CG_FTV, 
static void <token> amdgpu_device *adev) <answer> si_clear_vc(struct 
WREG32(CG_FTV, <token> <answer> 0); 
static u8 si_get_ddr3_mclk_frequency_ratio(u32 <token> <answer> memory_clock) 
u8 <token> <answer> mc_para_index; 
if (memory_clock < <token> <answer> 10000) 
mc_para_index = <token> <answer> 0; 
<token> if (memory_clock >= 80000) <answer> else 
mc_para_index = <token> <answer> 0x0f; 
mc_para_index = <token> - 10000) / 5000 + 1); <answer> (u8)((memory_clock 
return <token> <answer> mc_para_index; 
<token> u8 si_get_mclk_frequency_ratio(u32 memory_clock, bool strobe_mode) <answer> static 
u8 <token> <answer> mc_para_index; 
if <token> { <answer> (strobe_mode) 
<token> (memory_clock < 12500) <answer> if 
mc_para_index <token> 0x00; <answer> = 
else if <token> > 47500) <answer> (memory_clock 
mc_para_index <token> 0x0f; <answer> = 
mc_para_index = (u8)((memory_clock - <token> / 2500); <answer> 10000) 
} <token> { <answer> else 
<token> (memory_clock < 65000) <answer> if 
mc_para_index = <token> <answer> 0x00; 
else <token> (memory_clock > 135000) <answer> if 
<token> = 0x0f; <answer> mc_para_index 
<token> = (u8)((memory_clock - 60000) / 5000); <answer> mc_para_index 
return <token> <answer> mc_para_index; 
static u8 si_get_strobe_mode_settings(struct amdgpu_device *adev, <token> mclk) <answer> u32 
struct <token> *pi = rv770_get_pi(adev); <answer> rv7xx_power_info 
bool <token> = false; <answer> strobe_mode 
u8 <token> = 0; <answer> result 
if (mclk <= <token> <answer> pi->mclk_strobe_mode_threshold) 
strobe_mode = <token> <answer> true; 
if <token> == AMDGPU_VRAM_TYPE_GDDR5) <answer> (adev->gmc.vram_type 
result = si_get_mclk_frequency_ratio(mclk, <token> <answer> strobe_mode); 
result <token> si_get_ddr3_mclk_frequency_ratio(mclk); <answer> = 
<token> (strobe_mode) <answer> if 
<token> |= SISLANDS_SMC_STROBE_ENABLE; <answer> result 
<token> result; <answer> return 
static int si_upload_firmware(struct amdgpu_device <token> <answer> *adev) 
<token> si_power_info *si_pi = si_get_pi(adev); <answer> struct 
<token> false); <answer> amdgpu_si_smc_clock(adev, 
return amdgpu_si_load_smc_ucode(adev, <token> <answer> si_pi->sram_end); 
static <token> si_validate_phase_shedding_tables(struct amdgpu_device *adev, <answer> bool 
const <token> atom_voltage_table *table, <answer> struct 
const <token> amdgpu_phase_shedding_limits_table *limits) <answer> struct 
<token> data, num_bits, num_levels; <answer> u32 
if <token> == NULL) || (limits == NULL)) <answer> ((table 
return <token> <answer> false; 
data <token> table->mask_low; <answer> = 
<token> = hweight32(data); <answer> num_bits 
if (num_bits <token> 0) <answer> == 
return <token> <answer> false; 
<token> = (1 << num_bits); <answer> num_levels 
if <token> != num_levels) <answer> (table->count 
return <token> <answer> false; 
if (limits->count <token> (num_levels - 1)) <answer> != 
<token> false; <answer> return 
return <token> <answer> true; 
static void <token> amdgpu_device *adev, <answer> si_trim_voltage_table_to_fit_state_table(struct 
<token> max_voltage_steps, <answer> u32 
struct <token> *voltage_table) <answer> atom_voltage_table 
<token> int i, diff; <answer> unsigned 
if <token> <= max_voltage_steps) <answer> (voltage_table->count 
diff = voltage_table->count <token> max_voltage_steps; <answer> - 
for (i= 0; i < <token> i++) <answer> max_voltage_steps; 
voltage_table->entries[i] = <token> + diff]; <answer> voltage_table->entries[i 
<token> = max_voltage_steps; <answer> voltage_table->count 
static int si_get_svi2_voltage_table(struct <token> *adev, <answer> amdgpu_device 
struct amdgpu_clock_voltage_dependency_table <token> <answer> *voltage_dependency_table, 
struct <token> *voltage_table) <answer> atom_voltage_table 
<token> i; <answer> u32 
if (voltage_dependency_table <token> NULL) <answer> == 
return <token> <answer> -EINVAL; 
voltage_table->mask_low = <token> <answer> 0; 
voltage_table->phase_delay = <token> <answer> 0; 
voltage_table->count <token> voltage_dependency_table->count; <answer> = 
for (i <token> 0; i < voltage_table->count; i++) { <answer> = 
voltage_table->entries[i].value = <token> <answer> voltage_dependency_table->entries[i].v; 
<token> = 0; <answer> voltage_table->entries[i].smio_low 
return <token> <answer> 0; 
static int si_construct_voltage_tables(struct <token> *adev) <answer> amdgpu_device 
struct <token> *pi = rv770_get_pi(adev); <answer> rv7xx_power_info 
struct <token> *eg_pi = evergreen_get_pi(adev); <answer> evergreen_power_info 
struct si_power_info *si_pi = <token> <answer> si_get_pi(adev); 
int <token> <answer> ret; 
<token> (pi->voltage_control) { <answer> if 
ret = <token> VOLTAGE_TYPE_VDDC, <answer> amdgpu_atombios_get_voltage_table(adev, 
<token> &eg_pi->vddc_voltage_table); <answer> VOLTAGE_OBJ_GPIO_LUT, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if (eg_pi->vddc_voltage_table.count > <token> <answer> SISLANDS_MAX_NO_VREG_STEPS) 
} else <token> (si_pi->voltage_control_svi2) { <answer> if 
ret <token> si_get_svi2_voltage_table(adev, <answer> = 
<token> (ret) <answer> if 
return <token> <answer> ret; 
} <token> { <answer> else 
return <token> <answer> -EINVAL; 
if <token> { <answer> (eg_pi->vddci_control) 
<token> = amdgpu_atombios_get_voltage_table(adev, VOLTAGE_TYPE_VDDCI, <answer> ret 
VOLTAGE_OBJ_GPIO_LUT, <token> <answer> &eg_pi->vddci_voltage_table); 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if (eg_pi->vddci_voltage_table.count > <token> <answer> SISLANDS_MAX_NO_VREG_STEPS) 
<token> (si_pi->vddci_control_svi2) { <answer> if 
ret = <token> <answer> si_get_svi2_voltage_table(adev, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
if (pi->mvdd_control) <token> <answer> { 
<token> = amdgpu_atombios_get_voltage_table(adev, VOLTAGE_TYPE_MVDDC, <answer> ret 
<token> &si_pi->mvdd_voltage_table); <answer> VOLTAGE_OBJ_GPIO_LUT, 
<token> (ret) { <answer> if 
<token> = false; <answer> pi->mvdd_control 
return <token> <answer> ret; 
if (si_pi->mvdd_voltage_table.count == 0) <token> <answer> { 
<token> = false; <answer> pi->mvdd_control 
<token> -EINVAL; <answer> return 
if <token> > SISLANDS_MAX_NO_VREG_STEPS) <answer> (si_pi->mvdd_voltage_table.count 
if (si_pi->vddc_phase_shed_control) <token> <answer> { 
ret = amdgpu_atombios_get_voltage_table(adev, <token> <answer> VOLTAGE_TYPE_VDDC, 
VOLTAGE_OBJ_PHASE_LUT, <token> <answer> &si_pi->vddc_phase_shed_table); 
if <token> <answer> (ret) 
si_pi->vddc_phase_shed_control = <token> <answer> false; 
if <token> == 0) || <answer> ((si_pi->vddc_phase_shed_table.count 
(si_pi->vddc_phase_shed_table.count <token> SISLANDS_MAX_NO_VREG_STEPS)) <answer> > 
si_pi->vddc_phase_shed_control = <token> <answer> false; 
<token> 0; <answer> return 
static <token> si_populate_smc_voltage_table(struct amdgpu_device *adev, <answer> void 
<token> struct atom_voltage_table *voltage_table, <answer> const 
<token> *table) <answer> SISLANDS_SMC_STATETABLE 
unsigned int <token> <answer> i; 
for (i = <token> i < voltage_table->count; i++) <answer> 0; 
<token> |= cpu_to_be32(voltage_table->entries[i].smio_low); <answer> table->lowSMIO[i] 
<token> int si_populate_smc_voltage_tables(struct amdgpu_device *adev, <answer> static 
<token> *table) <answer> SISLANDS_SMC_STATETABLE 
struct rv7xx_power_info <token> = rv770_get_pi(adev); <answer> *pi 
struct evergreen_power_info *eg_pi = <token> <answer> evergreen_get_pi(adev); 
struct <token> *si_pi = si_get_pi(adev); <answer> si_power_info 
u8 <token> <answer> i; 
if <token> { <answer> (si_pi->voltage_control_svi2) 
<token> SI_SMC_SOFT_REGISTER_svi_rework_gpio_id_svc, <answer> si_write_smc_soft_register(adev, 
<token> SI_SMC_SOFT_REGISTER_svi_rework_gpio_id_svd, <answer> si_write_smc_soft_register(adev, 
si_write_smc_soft_register(adev, <token> <answer> SI_SMC_SOFT_REGISTER_svi_rework_plat_type, 
} else <token> <answer> { 
<token> (eg_pi->vddc_voltage_table.count) { <answer> if 
si_populate_smc_voltage_table(adev, <token> table); <answer> &eg_pi->vddc_voltage_table, 
table->voltageMaskTable.lowMask[SISLANDS_SMC_VOLTAGEMASK_VDDC] <token> <answer> = 
for (i = 0; i < <token> i++) { <answer> eg_pi->vddc_voltage_table.count; 
if (pi->max_vddc_in_table <= eg_pi->vddc_voltage_table.entries[i].value) <token> <answer> { 
table->maxVDDCIndexInPPTable = <token> <answer> i; 
if <token> { <answer> (eg_pi->vddci_voltage_table.count) 
<token> &eg_pi->vddci_voltage_table, table); <answer> si_populate_smc_voltage_table(adev, 
<token> = <answer> table->voltageMaskTable.lowMask[SISLANDS_SMC_VOLTAGEMASK_VDDCI] 
if (si_pi->mvdd_voltage_table.count) <token> <answer> { 
si_populate_smc_voltage_table(adev, <token> table); <answer> &si_pi->mvdd_voltage_table, 
<token> = <answer> table->voltageMaskTable.lowMask[SISLANDS_SMC_VOLTAGEMASK_MVDD] 
if <token> { <answer> (si_pi->vddc_phase_shed_control) 
<token> (si_validate_phase_shedding_tables(adev, &si_pi->vddc_phase_shed_table, <answer> if 
<token> { <answer> &adev->pm.dpm.dyn_state.phase_shedding_limits_table)) 
si_populate_smc_voltage_table(adev, <token> table); <answer> &si_pi->vddc_phase_shed_table, 
table->phaseMaskTable.lowMask[SISLANDS_SMC_VOLTAGEMASK_VDDC_PHASE_SHEDDING] <token> <answer> = 
si_write_smc_soft_register(adev, <token> <answer> SI_SMC_SOFT_REGISTER_phase_shedding_delay, 
} else <token> <answer> { 
<token> = false; <answer> si_pi->vddc_phase_shed_control 
return <token> <answer> 0; 
static int si_populate_voltage_value(struct <token> *adev, <answer> amdgpu_device 
<token> struct atom_voltage_table *table, <answer> const 
u16 value, SISLANDS_SMC_VOLTAGE_VALUE <token> <answer> *voltage) 
<token> int i; <answer> unsigned 
for (i = 0; i < table->count; <token> { <answer> i++) 
if (value <= <token> { <answer> table->entries[i].value) 
<token> = (u8)i; <answer> voltage->index 
<token> = cpu_to_be16(table->entries[i].value); <answer> voltage->value 
if (i <token> table->count) <answer> >= 
return <token> <answer> -EINVAL; 
<token> 0; <answer> return 
<token> int si_populate_mvdd_value(struct amdgpu_device *adev, u32 mclk, <answer> static 
SISLANDS_SMC_VOLTAGE_VALUE <token> <answer> *voltage) 
struct rv7xx_power_info <token> = rv770_get_pi(adev); <answer> *pi 
struct si_power_info *si_pi <token> si_get_pi(adev); <answer> = 
if <token> { <answer> (pi->mvdd_control) 
if (mclk <= <token> <answer> pi->mvdd_split_frequency) 
voltage->index = <token> <answer> 0; 
voltage->index <token> (u8)(si_pi->mvdd_voltage_table.count) - 1; <answer> = 
voltage->value <token> cpu_to_be16(si_pi->mvdd_voltage_table.entries[voltage->index].value); <answer> = 
<token> 0; <answer> return 
static int <token> amdgpu_device *adev, <answer> si_get_std_voltage_value(struct 
SISLANDS_SMC_VOLTAGE_VALUE <token> <answer> *voltage, 
u16 <token> <answer> *std_voltage) 
<token> v_index; <answer> u16 
bool <token> = false; <answer> voltage_found 
<token> = be16_to_cpu(voltage->value); <answer> *std_voltage 
<token> (adev->pm.dpm.dyn_state.cac_leakage_table.entries) { <answer> if 
if <token> & ATOM_PP_PLATFORM_CAP_NEW_CAC_VOLTAGE) { <answer> (adev->pm.dpm.platform_caps 
if (adev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries == <token> <answer> NULL) 
<token> -EINVAL; <answer> return 
for (v_index = 0; (u32)v_index < <token> v_index++) { <answer> adev->pm.dpm.dyn_state.vddc_dependency_on_sclk.count; 
if <token> == <answer> (be16_to_cpu(voltage->value) 
<token> { <answer> (u16)adev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[v_index].v) 
voltage_found <token> true; <answer> = 
if <token> < adev->pm.dpm.dyn_state.cac_leakage_table.count) <answer> ((u32)v_index 
<token> = <answer> *std_voltage 
*std_voltage <token> <answer> = 
if <token> { <answer> (!voltage_found) 
<token> (v_index = 0; (u32)v_index < adev->pm.dpm.dyn_state.vddc_dependency_on_sclk.count; v_index++) { <answer> for 
<token> (be16_to_cpu(voltage->value) <= <answer> if 
<token> { <answer> (u16)adev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[v_index].v) 
voltage_found <token> true; <answer> = 
if <token> < adev->pm.dpm.dyn_state.cac_leakage_table.count) <answer> ((u32)v_index 
*std_voltage <token> <answer> = 
*std_voltage <token> <answer> = 
} else <token> <answer> { 
<token> ((u32)voltage->index < adev->pm.dpm.dyn_state.cac_leakage_table.count) <answer> if 
*std_voltage <token> adev->pm.dpm.dyn_state.cac_leakage_table.entries[voltage->index].vddc; <answer> = 
return <token> <answer> 0; 
static int si_populate_std_voltage_value(struct <token> *adev, <answer> amdgpu_device 
u16 value, u8 <token> <answer> index, 
SISLANDS_SMC_VOLTAGE_VALUE <token> <answer> *voltage) 
voltage->index <token> index; <answer> = 
<token> = cpu_to_be16(value); <answer> voltage->value 
<token> 0; <answer> return 
static int si_populate_phase_shedding_value(struct amdgpu_device <token> <answer> *adev, 
const struct <token> *limits, <answer> amdgpu_phase_shedding_limits_table 
u16 voltage, <token> sclk, u32 mclk, <answer> u32 
SISLANDS_SMC_VOLTAGE_VALUE <token> <answer> *smc_voltage) 
unsigned <token> i; <answer> int 
for <token> = 0; i < limits->count; i++) { <answer> (i 
if ((voltage <= limits->entries[i].voltage) <token> <answer> && 
(sclk <= <token> && <answer> limits->entries[i].sclk) 
<token> <= limits->entries[i].mclk)) <answer> (mclk 
smc_voltage->phase_settings <token> (u8)i; <answer> = 
return <token> <answer> 0; 
static int si_init_arb_table_index(struct amdgpu_device <token> <answer> *adev) 
struct si_power_info <token> = si_get_pi(adev); <answer> *si_pi 
<token> tmp; <answer> u32 
<token> ret; <answer> int 
ret = amdgpu_si_read_smc_sram_dword(adev, <token> <answer> si_pi->arb_table_start, 
&tmp, <token> <answer> si_pi->sram_end); 
<token> (ret) <answer> if 
return <token> <answer> ret; 
tmp &= <token> <answer> 0x00FFFFFF; 
tmp <token> MC_CG_ARB_FREQ_F1 << 24; <answer> |= 
return <token> si_pi->arb_table_start, <answer> amdgpu_si_write_smc_sram_dword(adev, 
tmp, <token> <answer> si_pi->sram_end); 
static int si_initial_switch_from_arb_f0_to_f1(struct amdgpu_device <token> <answer> *adev) 
return ni_copy_and_switch_arb_sets(adev, MC_CG_ARB_FREQ_F0, <token> <answer> MC_CG_ARB_FREQ_F1); 
static int <token> amdgpu_device *adev) <answer> si_reset_to_default(struct 
return (amdgpu_si_send_msg_to_smc(adev, <token> == PPSMC_Result_OK) ? <answer> PPSMC_MSG_ResetToDefaults) 
0 <token> -EINVAL; <answer> : 
<token> int si_force_switch_to_arb_f0(struct amdgpu_device *adev) <answer> static 
struct si_power_info *si_pi = <token> <answer> si_get_pi(adev); 
u32 <token> <answer> tmp; 
int <token> <answer> ret; 
ret = amdgpu_si_read_smc_sram_dword(adev, <token> <answer> si_pi->arb_table_start, 
<token> si_pi->sram_end); <answer> &tmp, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
tmp = (tmp >> 24) & <token> <answer> 0xff; 
if <token> == MC_CG_ARB_FREQ_F0) <answer> (tmp 
return <token> <answer> 0; 
<token> ni_copy_and_switch_arb_sets(adev, tmp, MC_CG_ARB_FREQ_F0); <answer> return 
<token> u32 si_calculate_memory_refresh_rate(struct amdgpu_device *adev, <answer> static 
<token> engine_clock) <answer> u32 
<token> dram_rows; <answer> u32 
u32 <token> <answer> dram_refresh_rate; 
<token> mc_arb_rfsh_rate; <answer> u32 
u32 tmp = (RREG32(MC_ARB_RAMCFG) & <token> >> NOOFROWS_SHIFT; <answer> NOOFROWS_MASK) 
<token> (tmp >= 4) <answer> if 
dram_rows <token> 16384; <answer> = 
<token> = 1 << (tmp + 10); <answer> dram_rows 
dram_refresh_rate = 1 << ((RREG32(MC_SEQ_MISC0) & 0x3) <token> 3); <answer> + 
mc_arb_rfsh_rate = ((engine_clock * 10) * dram_refresh_rate / dram_rows - 32) <token> 64; <answer> / 
<token> mc_arb_rfsh_rate; <answer> return 
static <token> si_populate_memory_timing_parameters(struct amdgpu_device *adev, <answer> int 
<token> rv7xx_pl *pl, <answer> struct 
SMC_SIslands_MCArbDramTimingRegisterSet <token> <answer> *arb_regs) 
u32 <token> <answer> dram_timing; 
<token> dram_timing2; <answer> u32 
<token> burst_time; <answer> u32 
arb_regs->mc_arb_rfsh_rate <token> <answer> = 
(u8)si_calculate_memory_refresh_rate(adev, <token> <answer> pl->sclk); 
<token> = RREG32(MC_ARB_DRAM_TIMING); <answer> dram_timing 
dram_timing2 = <token> <answer> RREG32(MC_ARB_DRAM_TIMING2); 
burst_time = <token> & STATE0_MASK; <answer> RREG32(MC_ARB_BURST_TIME) 
arb_regs->mc_arb_dram_timing <token> cpu_to_be32(dram_timing); <answer> = 
arb_regs->mc_arb_dram_timing2 = <token> <answer> cpu_to_be32(dram_timing2); 
arb_regs->mc_arb_burst_time <token> (u8)burst_time; <answer> = 
<token> 0; <answer> return 
<token> int si_do_program_memory_timing_parameters(struct amdgpu_device *adev, <answer> static 
<token> amdgpu_ps *amdgpu_state, <answer> struct 
unsigned <token> first_arb_set) <answer> int 
struct si_power_info <token> = si_get_pi(adev); <answer> *si_pi 
struct si_ps *state <token> si_get_ps(amdgpu_state); <answer> = 
SMC_SIslands_MCArbDramTimingRegisterSet arb_regs = { 0 <token> <answer> }; 
int i, <token> = 0; <answer> ret 
for (i <token> 0; i < state->performance_level_count; i++) { <answer> = 
ret = si_populate_memory_timing_parameters(adev, &state->performance_levels[i], <token> <answer> &arb_regs); 
if <token> <answer> (ret) 
ret <token> amdgpu_si_copy_bytes_to_smc(adev, <answer> = 
<token> + <answer> si_pi->arb_table_start 
offsetof(SMC_SIslands_MCArbDramTimingRegisters, <token> + <answer> data) 
sizeof(SMC_SIslands_MCArbDramTimingRegisterSet) * (first_arb_set <token> i), <answer> + 
(u8 <token> <answer> *)&arb_regs, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
static int <token> amdgpu_device *adev, <answer> si_program_memory_timing_parameters(struct 
struct amdgpu_ps <token> <answer> *amdgpu_new_state) 
return si_do_program_memory_timing_parameters(adev, <token> <answer> amdgpu_new_state, 
static int <token> amdgpu_device *adev, <answer> si_populate_initial_mvdd_value(struct 
struct SISLANDS_SMC_VOLTAGE_VALUE <token> <answer> *voltage) 
struct <token> *pi = rv770_get_pi(adev); <answer> rv7xx_power_info 
struct si_power_info <token> = si_get_pi(adev); <answer> *si_pi 
<token> (pi->mvdd_control) <answer> if 
return si_populate_voltage_value(adev, <token> <answer> &si_pi->mvdd_voltage_table, 
<token> voltage); <answer> si_pi->mvdd_bootup_value, 
return <token> <answer> 0; 
static int si_populate_smc_initial_state(struct amdgpu_device <token> <answer> *adev, 
<token> amdgpu_ps *amdgpu_initial_state, <answer> struct 
SISLANDS_SMC_STATETABLE <token> <answer> *table) 
struct si_ps *initial_state <token> si_get_ps(amdgpu_initial_state); <answer> = 
struct rv7xx_power_info *pi <token> rv770_get_pi(adev); <answer> = 
<token> evergreen_power_info *eg_pi = evergreen_get_pi(adev); <answer> struct 
struct si_power_info *si_pi <token> si_get_pi(adev); <answer> = 
u32 <token> <answer> reg; 
int <token> <answer> ret; 
table->initialState.level.mclk.vDLL_CNTL <token> <answer> = 
table->initialState.level.mclk.vMCLK_PWRMGT_CNTL <token> <answer> = 
table->initialState.level.mclk.vMPLL_AD_FUNC_CNTL <token> <answer> = 
table->initialState.level.mclk.vMPLL_DQ_FUNC_CNTL <token> <answer> = 
<token> = <answer> table->initialState.level.mclk.vMPLL_FUNC_CNTL 
table->initialState.level.mclk.vMPLL_FUNC_CNTL_1 <token> <answer> = 
<token> = <answer> table->initialState.level.mclk.vMPLL_FUNC_CNTL_2 
table->initialState.level.mclk.vMPLL_SS <token> <answer> = 
table->initialState.level.mclk.vMPLL_SS2 <token> <answer> = 
<token> = <answer> table->initialState.level.mclk.mclk_value 
<token> = <answer> table->initialState.level.sclk.vCG_SPLL_FUNC_CNTL 
table->initialState.level.sclk.vCG_SPLL_FUNC_CNTL_2 <token> <answer> = 
table->initialState.level.sclk.vCG_SPLL_FUNC_CNTL_3 <token> <answer> = 
table->initialState.level.sclk.vCG_SPLL_FUNC_CNTL_4 <token> <answer> = 
table->initialState.level.sclk.vCG_SPLL_SPREAD_SPECTRUM <token> <answer> = 
<token> = <answer> table->initialState.level.sclk.vCG_SPLL_SPREAD_SPECTRUM_2 
<token> = <answer> table->initialState.level.sclk.sclk_value 
<token> = <answer> table->initialState.level.arbRefreshState 
<token> = 0; <answer> table->initialState.level.ACIndex 
ret = si_populate_voltage_value(adev, <token> <answer> &eg_pi->vddc_voltage_table, 
if <token> { <answer> (!ret) 
<token> std_vddc; <answer> u16 
ret = <token> <answer> si_get_std_voltage_value(adev, 
if <token> <answer> (!ret) 
si_populate_std_voltage_value(adev, <token> <answer> std_vddc, 
if <token> <answer> (eg_pi->vddci_control) 
if <token> <answer> (si_pi->vddc_phase_shed_control) 
<token> &table->initialState.level.mvdd); <answer> si_populate_initial_mvdd_value(adev, 
reg <token> CG_R(0xffff) | CG_L(0); <answer> = 
<token> = cpu_to_be32(reg); <answer> table->initialState.level.aT 
table->initialState.level.bSP <token> cpu_to_be32(pi->dsp); <answer> = 
table->initialState.level.gen2PCIE = <token> <answer> (u8)si_pi->boot_pcie_gen; 
if <token> == AMDGPU_VRAM_TYPE_GDDR5) { <answer> (adev->gmc.vram_type 
table->initialState.level.strobeMode <token> <answer> = 
if <token> > pi->mclk_edc_enable_threshold) <answer> (initial_state->performance_levels[0].mclk 
table->initialState.level.mcFlags = SISLANDS_SMC_MC_EDC_RD_FLAG | <token> <answer> SISLANDS_SMC_MC_EDC_WR_FLAG; 
table->initialState.level.mcFlags = <token> <answer> 0; 
table->initialState.levelCount = <token> <answer> 1; 
<token> |= PPSMC_SWSTATE_FLAG_DC; <answer> table->initialState.flags 
<token> = 0; <answer> table->initialState.level.dpm2.MaxPS 
table->initialState.level.dpm2.NearTDPDec <token> 0; <answer> = 
table->initialState.level.dpm2.AboveSafeInc <token> 0; <answer> = 
table->initialState.level.dpm2.BelowSafeInc <token> 0; <answer> = 
table->initialState.level.dpm2.PwrEfficiencyRatio = <token> <answer> 0; 
<token> = MIN_POWER_MASK | MAX_POWER_MASK; <answer> reg 
<token> = cpu_to_be32(reg); <answer> table->initialState.level.SQPowerThrottle 
reg = MAX_POWER_DELTA_MASK | <token> | LTI_RATIO_MASK; <answer> STI_SIZE_MASK 
<token> = cpu_to_be32(reg); <answer> table->initialState.level.SQPowerThrottle_2 
return <token> <answer> 0; 
static enum si_pcie_gen <token> amdgpu_device *adev, <answer> si_gen_pcie_gen_support(struct 
<token> sys_mask, <answer> u32 
enum si_pcie_gen <token> <answer> asic_gen, 
<token> si_pcie_gen default_gen) <answer> enum 
switch (asic_gen) <token> <answer> { 
<token> SI_PCIE_GEN1: <answer> case 
<token> SI_PCIE_GEN1; <answer> return 
case <token> <answer> SI_PCIE_GEN2: 
return <token> <answer> SI_PCIE_GEN2; 
<token> SI_PCIE_GEN3: <answer> case 
<token> SI_PCIE_GEN3; <answer> return 
if ((sys_mask <token> CAIL_PCIE_LINK_SPEED_SUPPORT_GEN3) && <answer> & 
(default_gen == <token> <answer> SI_PCIE_GEN3)) 
<token> SI_PCIE_GEN3; <answer> return 
else <token> ((sys_mask & CAIL_PCIE_LINK_SPEED_SUPPORT_GEN2) && <answer> if 
<token> == SI_PCIE_GEN2)) <answer> (default_gen 
return <token> <answer> SI_PCIE_GEN2; 
<token> SI_PCIE_GEN1; <answer> return 
return <token> <answer> SI_PCIE_GEN1; 
static <token> si_populate_smc_acpi_state(struct amdgpu_device *adev, <answer> int 
SISLANDS_SMC_STATETABLE <token> <answer> *table) 
struct rv7xx_power_info *pi <token> rv770_get_pi(adev); <answer> = 
struct evergreen_power_info *eg_pi = <token> <answer> evergreen_get_pi(adev); 
<token> si_power_info *si_pi = si_get_pi(adev); <answer> struct 
u32 spll_func_cntl <token> si_pi->clock_registers.cg_spll_func_cntl; <answer> = 
u32 <token> = si_pi->clock_registers.cg_spll_func_cntl_2; <answer> spll_func_cntl_2 
<token> spll_func_cntl_3 = si_pi->clock_registers.cg_spll_func_cntl_3; <answer> u32 
u32 spll_func_cntl_4 <token> si_pi->clock_registers.cg_spll_func_cntl_4; <answer> = 
u32 dll_cntl <token> si_pi->clock_registers.dll_cntl; <answer> = 
<token> mclk_pwrmgt_cntl = si_pi->clock_registers.mclk_pwrmgt_cntl; <answer> u32 
u32 mpll_ad_func_cntl <token> si_pi->clock_registers.mpll_ad_func_cntl; <answer> = 
u32 <token> = si_pi->clock_registers.mpll_dq_func_cntl; <answer> mpll_dq_func_cntl 
u32 <token> = si_pi->clock_registers.mpll_func_cntl; <answer> mpll_func_cntl 
u32 mpll_func_cntl_1 = <token> <answer> si_pi->clock_registers.mpll_func_cntl_1; 
<token> mpll_func_cntl_2 = si_pi->clock_registers.mpll_func_cntl_2; <answer> u32 
u32 <token> <answer> reg; 
<token> ret; <answer> int 
table->ACPIState = <token> <answer> table->initialState; 
table->ACPIState.flags &= <token> <answer> ~PPSMC_SWSTATE_FLAG_DC; 
if (pi->acpi_vddc) <token> <answer> { 
ret = <token> &eg_pi->vddc_voltage_table, <answer> si_populate_voltage_value(adev, 
pi->acpi_vddc, <token> <answer> &table->ACPIState.level.vddc); 
if <token> { <answer> (!ret) 
<token> std_vddc; <answer> u16 
<token> = si_get_std_voltage_value(adev, <answer> ret 
<token> &std_vddc); <answer> &table->ACPIState.level.vddc, 
if <token> <answer> (!ret) 
<token> std_vddc, <answer> si_populate_std_voltage_value(adev, 
table->ACPIState.level.gen2PCIE = <token> <answer> si_pi->acpi_pcie_gen; 
<token> (si_pi->vddc_phase_shed_control) { <answer> if 
} <token> { <answer> else 
ret = si_populate_voltage_value(adev, <token> <answer> &eg_pi->vddc_voltage_table, 
pi->min_vddc_in_table, <token> <answer> &table->ACPIState.level.vddc); 
if (!ret) <token> <answer> { 
u16 <token> <answer> std_vddc; 
ret <token> si_get_std_voltage_value(adev, <answer> = 
<token> &std_vddc); <answer> &table->ACPIState.level.vddc, 
if <token> <answer> (!ret) 
si_populate_std_voltage_value(adev, <token> <answer> std_vddc, 
<token> = <answer> table->ACPIState.level.gen2PCIE 
if <token> <answer> (si_pi->vddc_phase_shed_control) 
if <token> { <answer> (pi->acpi_vddc) 
<token> (eg_pi->acpi_vddci) <answer> if 
si_populate_voltage_value(adev, <token> <answer> &eg_pi->vddci_voltage_table, 
<token> |= MRDCK0_RESET | MRDCK1_RESET; <answer> mclk_pwrmgt_cntl 
mclk_pwrmgt_cntl &= <token> | MRDCK1_PDNB); <answer> ~(MRDCK0_PDNB 
dll_cntl &= ~(MRDCK0_BYPASS <token> MRDCK1_BYPASS); <answer> | 
spll_func_cntl_2 &= <token> <answer> ~SCLK_MUX_SEL_MASK; 
spll_func_cntl_2 |= <token> <answer> SCLK_MUX_SEL(4); 
table->ACPIState.level.mclk.vDLL_CNTL <token> <answer> = 
table->ACPIState.level.mclk.vMCLK_PWRMGT_CNTL <token> <answer> = 
table->ACPIState.level.mclk.vMPLL_AD_FUNC_CNTL <token> <answer> = 
<token> = <answer> table->ACPIState.level.mclk.vMPLL_DQ_FUNC_CNTL 
<token> = <answer> table->ACPIState.level.mclk.vMPLL_FUNC_CNTL 
<token> = <answer> table->ACPIState.level.mclk.vMPLL_FUNC_CNTL_1 
<token> = <answer> table->ACPIState.level.mclk.vMPLL_FUNC_CNTL_2 
<token> = <answer> table->ACPIState.level.mclk.vMPLL_SS 
table->ACPIState.level.mclk.vMPLL_SS2 <token> <answer> = 
table->ACPIState.level.sclk.vCG_SPLL_FUNC_CNTL <token> <answer> = 
<token> = <answer> table->ACPIState.level.sclk.vCG_SPLL_FUNC_CNTL_2 
<token> = <answer> table->ACPIState.level.sclk.vCG_SPLL_FUNC_CNTL_3 
table->ACPIState.level.sclk.vCG_SPLL_FUNC_CNTL_4 <token> <answer> = 
<token> = 0; <answer> table->ACPIState.level.mclk.mclk_value 
<token> = 0; <answer> table->ACPIState.level.sclk.sclk_value 
si_populate_mvdd_value(adev, 0, <token> <answer> &table->ACPIState.level.mvdd); 
if <token> <answer> (eg_pi->dynamic_ac_timing) 
table->ACPIState.level.ACIndex = <token> <answer> 0; 
<token> = 0; <answer> table->ACPIState.level.dpm2.MaxPS 
<token> = 0; <answer> table->ACPIState.level.dpm2.NearTDPDec 
<token> = 0; <answer> table->ACPIState.level.dpm2.AboveSafeInc 
<token> = 0; <answer> table->ACPIState.level.dpm2.BelowSafeInc 
<token> = 0; <answer> table->ACPIState.level.dpm2.PwrEfficiencyRatio 
<token> = MIN_POWER_MASK | MAX_POWER_MASK; <answer> reg 
<token> = cpu_to_be32(reg); <answer> table->ACPIState.level.SQPowerThrottle 
reg = MAX_POWER_DELTA_MASK | STI_SIZE_MASK <token> LTI_RATIO_MASK; <answer> | 
table->ACPIState.level.SQPowerThrottle_2 = <token> <answer> cpu_to_be32(reg); 
return <token> <answer> 0; 
<token> int si_populate_ulv_state(struct amdgpu_device *adev, <answer> static 
struct SISLANDS_SMC_SWSTATE_SINGLE <token> <answer> *state) 
struct evergreen_power_info *eg_pi <token> evergreen_get_pi(adev); <answer> = 
struct si_power_info *si_pi = <token> <answer> si_get_pi(adev); 
struct si_ulv_param *ulv <token> &si_pi->ulv; <answer> = 
<token> else { <answer> } 
<token> int si_dpm_set_power_state(void *handle) <answer> static 
struct amdgpu_device *adev = <token> amdgpu_device *)handle; <answer> (struct 
struct <token> *eg_pi = evergreen_get_pi(adev); <answer> evergreen_power_info 
struct amdgpu_ps *new_ps = <token> <answer> &eg_pi->requested_rps; 
struct amdgpu_ps *old_ps = <token> <answer> &eg_pi->current_rps; 
int <token> <answer> ret; 
ret <token> si_disable_ulv(adev); <answer> = 
<token> (ret) { <answer> if 
<token> failed\n"); <answer> DRM_ERROR("si_disable_ulv 
return <token> <answer> ret; 
ret = <token> <answer> si_restrict_performance_levels_before_switch(adev); 
if (ret) <token> <answer> { 
DRM_ERROR("si_restrict_performance_levels_before_switch <token> <answer> failed\n"); 
return <token> <answer> ret; 
<token> (eg_pi->pcie_performance_request) <answer> if 
si_request_link_speed_change_before_state_change(adev, <token> old_ps); <answer> new_ps, 
ni_set_uvd_clock_before_set_eng_clock(adev, <token> old_ps); <answer> new_ps, 
ret = si_enable_power_containment(adev, <token> false); <answer> new_ps, 
if <token> { <answer> (ret) 
DRM_ERROR("si_enable_power_containment <token> <answer> failed\n"); 
<token> ret; <answer> return 
ret = si_enable_smc_cac(adev, new_ps, <token> <answer> false); 
<token> (ret) { <answer> if 
<token> failed\n"); <answer> DRM_ERROR("si_enable_smc_cac 
return <token> <answer> ret; 
ret = <token> <answer> si_halt_smc(adev); 
<token> (ret) { <answer> if 
DRM_ERROR("si_halt_smc <token> <answer> failed\n"); 
return <token> <answer> ret; 
ret = <token> new_ps); <answer> si_upload_sw_state(adev, 
<token> (ret) { <answer> if 
<token> failed\n"); <answer> DRM_ERROR("si_upload_sw_state 
return <token> <answer> ret; 
ret <token> si_upload_smc_data(adev); <answer> = 
if (ret) <token> <answer> { 
DRM_ERROR("si_upload_smc_data <token> <answer> failed\n"); 
return <token> <answer> ret; 
ret = <token> <answer> si_upload_ulv_state(adev); 
if (ret) <token> <answer> { 
DRM_ERROR("si_upload_ulv_state <token> <answer> failed\n"); 
<token> ret; <answer> return 
if <token> { <answer> (eg_pi->dynamic_ac_timing) 
<token> = si_upload_mc_reg_table(adev, new_ps); <answer> ret 
if (ret) <token> <answer> { 
<token> failed\n"); <answer> DRM_ERROR("si_upload_mc_reg_table 
return <token> <answer> ret; 
ret = si_program_memory_timing_parameters(adev, <token> <answer> new_ps); 
<token> (ret) { <answer> if 
<token> failed\n"); <answer> DRM_ERROR("si_program_memory_timing_parameters 
return <token> <answer> ret; 
<token> new_ps, old_ps); <answer> si_set_pcie_lane_width_in_smc(adev, 
<token> = si_resume_smc(adev); <answer> ret 
if (ret) <token> <answer> { 
<token> failed\n"); <answer> DRM_ERROR("si_resume_smc 
return <token> <answer> ret; 
ret <token> si_set_sw_state(adev); <answer> = 
<token> (ret) { <answer> if 
DRM_ERROR("si_set_sw_state <token> <answer> failed\n"); 
<token> ret; <answer> return 
ni_set_uvd_clock_after_set_eng_clock(adev, <token> old_ps); <answer> new_ps, 
<token> new_ps, old_ps); <answer> si_set_vce_clock(adev, 
<token> (eg_pi->pcie_performance_request) <answer> if 
si_notify_link_speed_change_after_state_change(adev, <token> old_ps); <answer> new_ps, 
<token> = si_set_power_state_conditionally_enable_ulv(adev, new_ps); <answer> ret 
if (ret) <token> <answer> { 
<token> failed\n"); <answer> DRM_ERROR("si_set_power_state_conditionally_enable_ulv 
<token> ret; <answer> return 
ret = si_enable_smc_cac(adev, <token> true); <answer> new_ps, 
if (ret) <token> <answer> { 
<token> failed\n"); <answer> DRM_ERROR("si_enable_smc_cac 
return <token> <answer> ret; 
<token> = si_enable_power_containment(adev, new_ps, true); <answer> ret 
<token> (ret) { <answer> if 
DRM_ERROR("si_enable_power_containment <token> <answer> failed\n"); 
return <token> <answer> ret; 
ret <token> si_power_control_set_level(adev); <answer> = 
<token> (ret) { <answer> if 
DRM_ERROR("si_power_control_set_level <token> <answer> failed\n"); 
<token> ret; <answer> return 
return <token> <answer> 0; 
static <token> si_dpm_post_set_power_state(void *handle) <answer> void 
struct amdgpu_device *adev = (struct <token> *)handle; <answer> amdgpu_device 
struct <token> *eg_pi = evergreen_get_pi(adev); <answer> evergreen_power_info 
struct <token> *new_ps = &eg_pi->requested_rps; <answer> amdgpu_ps 
<token> new_ps); <answer> ni_update_current_ps(adev, 
<token> 0 <answer> #if 
<token> si_dpm_reset_asic(struct amdgpu_device *adev) <answer> void 
static void si_dpm_display_configuration_changed(void <token> <answer> *handle) 
struct amdgpu_device *adev = (struct <token> *)handle; <answer> amdgpu_device 
static void <token> amdgpu_device *adev, <answer> si_parse_pplib_non_clock_info(struct 
struct <token> *rps, <answer> amdgpu_ps 
<token> _ATOM_PPLIB_NONCLOCK_INFO *non_clock_info, <answer> struct 
u8 <token> <answer> table_rev) 
rps->caps = <token> <answer> le32_to_cpu(non_clock_info->ulCapsAndSettings); 
rps->class <token> le16_to_cpu(non_clock_info->usClassification); <answer> = 
rps->class2 = <token> <answer> le16_to_cpu(non_clock_info->usClassification2); 
if <token> < table_rev) { <answer> (ATOM_PPLIB_NONCLOCKINFO_VER1 
rps->vclk = <token> <answer> le32_to_cpu(non_clock_info->ulVCLK); 
rps->dclk <token> le32_to_cpu(non_clock_info->ulDCLK); <answer> = 
} else if <token> rps->class2)) { <answer> (r600_is_uvd_state(rps->class, 
<token> = RV770_DEFAULT_VCLK_FREQ; <answer> rps->vclk 
rps->dclk <token> RV770_DEFAULT_DCLK_FREQ; <answer> = 
} <token> { <answer> else 
rps->vclk <token> 0; <answer> = 
<token> = 0; <answer> rps->dclk 
if (rps->class & <token> <answer> ATOM_PPLIB_CLASSIFICATION_BOOT) 
adev->pm.dpm.boot_ps = <token> <answer> rps; 
if (rps->class & <token> <answer> ATOM_PPLIB_CLASSIFICATION_UVDSTATE) 
<token> = rps; <answer> adev->pm.dpm.uvd_ps 
static void si_parse_pplib_clock_info(struct <token> *adev, <answer> amdgpu_device 
struct amdgpu_ps *rps, int <token> <answer> index, 
union pplib_clock_info <token> <answer> *clock_info) 
struct rv7xx_power_info *pi <token> rv770_get_pi(adev); <answer> = 
<token> evergreen_power_info *eg_pi = evergreen_get_pi(adev); <answer> struct 
struct si_power_info *si_pi = <token> <answer> si_get_pi(adev); 
struct si_ps *ps <token> si_get_ps(rps); <answer> = 
u16 <token> <answer> leakage_voltage; 
struct rv7xx_pl *pl = <token> <answer> &ps->performance_levels[index]; 
int <token> <answer> ret; 
ps->performance_level_count = index <token> 1; <answer> + 
<token> = le16_to_cpu(clock_info->si.usEngineClockLow); <answer> pl->sclk 
pl->sclk |= <token> << 16; <answer> clock_info->si.ucEngineClockHigh 
pl->mclk <token> le16_to_cpu(clock_info->si.usMemoryClockLow); <answer> = 
pl->mclk |= clock_info->si.ucMemoryClockHigh <token> 16; <answer> << 
pl->vddc <token> le16_to_cpu(clock_info->si.usVDDC); <answer> = 
pl->vddci = <token> <answer> le16_to_cpu(clock_info->si.usVDDCI); 
<token> = le32_to_cpu(clock_info->si.ulFlags); <answer> pl->flags 
pl->pcie_gen = <token> <answer> si_gen_pcie_gen_support(adev, 
<token> int si_dpm_init_microcode(struct amdgpu_device *adev) <answer> static 
const char <token> <answer> *chip_name; 
char <token> <answer> fw_name[30]; 
<token> err; <answer> int 
switch (adev->asic_type) <token> <answer> { 
<token> CHIP_TAHITI: <answer> case 
chip_name <token> "tahiti"; <answer> = 
<token> CHIP_PITCAIRN: <answer> case 
<token> ((adev->pdev->revision == 0x81) && <answer> if 
((adev->pdev->device == <token> || <answer> 0x6810) 
<token> == 0x6811))) <answer> (adev->pdev->device 
chip_name <token> "pitcairn_k"; <answer> = 
chip_name = <token> <answer> "pitcairn"; 
<token> CHIP_VERDE: <answer> case 
if <token> == 0x6820) && <answer> (((adev->pdev->device 
((adev->pdev->revision == 0x81) <token> <answer> || 
(adev->pdev->revision <token> 0x83))) || <answer> == 
((adev->pdev->device == <token> && <answer> 0x6821) 
<token> == 0x83) || <answer> ((adev->pdev->revision 
(adev->pdev->revision == <token> || <answer> 0x87))) 
<token> == 0x87) && <answer> ((adev->pdev->revision 
<token> == 0x6823) || <answer> ((adev->pdev->device 
<token> == 0x682b)))) <answer> (adev->pdev->device 
chip_name <token> "verde_k"; <answer> = 
chip_name = <token> <answer> "verde"; 
<token> CHIP_OLAND: <answer> case 
if <token> == 0x81) && <answer> (((adev->pdev->revision 
((adev->pdev->device <token> 0x6600) || <answer> == 
(adev->pdev->device == <token> || <answer> 0x6604) 
<token> == 0x6605) || <answer> (adev->pdev->device 
(adev->pdev->device == 0x6610))) <token> <answer> || 
((adev->pdev->revision == 0x83) <token> <answer> && 
(adev->pdev->device == <token> <answer> 0x6610))) 
<token> = "oland_k"; <answer> chip_name 
<token> = "oland"; <answer> chip_name 
case <token> <answer> CHIP_HAINAN: 
if (((adev->pdev->revision == 0x81) <token> <answer> && 
(adev->pdev->device == 0x6660)) <token> <answer> || 
((adev->pdev->revision == <token> && <answer> 0x83) 
((adev->pdev->device == 0x6660) <token> <answer> || 
(adev->pdev->device == <token> || <answer> 0x6663) 
(adev->pdev->device == 0x6665) <token> <answer> || 
<token> == 0x6667)))) <answer> (adev->pdev->device 
chip_name = <token> <answer> "hainan_k"; 
else if ((adev->pdev->revision == 0xc3) <token> <answer> && 
(adev->pdev->device <token> 0x6665)) <answer> == 
<token> = "banks_k_2"; <answer> chip_name 
chip_name <token> "hainan"; <answer> = 
<token> BUG(); <answer> default: 
<token> sizeof(fw_name), "amdgpu/%s_smc.bin", chip_name); <answer> snprintf(fw_name, 
err = <token> &adev->pm.fw, fw_name); <answer> amdgpu_ucode_request(adev, 
if (err) <token> <answer> { 
DRM_ERROR("si_smc: Failed to load firmware. err = <token> <answer> %d\"%s\"\n", 
<token> fw_name); <answer> err, 
return <token> <answer> err; 
static int <token> *handle) <answer> si_dpm_sw_init(void 
<token> ret; <answer> int 
struct amdgpu_device <token> = (struct amdgpu_device *)handle; <answer> *adev 
ret = <token> AMDGPU_IRQ_CLIENTID_LEGACY, 230, &adev->pm.dpm.thermal.irq); <answer> amdgpu_irq_add_id(adev, 
if <token> <answer> (ret) 
return <token> <answer> ret; 
ret = amdgpu_irq_add_id(adev, AMDGPU_IRQ_CLIENTID_LEGACY, 231, <token> <answer> &adev->pm.dpm.thermal.irq); 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> <linux/module.h> <answer> #include 
<token> <linux/usb.h> <answer> #include 
#include <token> <answer> "debug.h" 
<token> "core.h" <answer> #include 
<token> urb_context); <answer> ath6kl_usb_free_urb_to_pipe(pipe, 
"ath6kl usb: alloc resources <token> hpipe:0x%X urbs:%d\n", <answer> lpipe:%d 
<token> pipe->usb_pipe_handle, <answer> pipe->logical_pipe_num, 
<token> status; <answer> return 
static void ath6kl_usb_free_pipe_resources(struct ath6kl_usb_pipe <token> <answer> *pipe) 
struct <token> *urb_context; <answer> ath6kl_urb_context 
<token> (pipe->ar_usb == NULL) { <answer> if 
static void ath6kl_usb_start_recv_pipes(struct <token> *ar_usb) <answer> ath6kl_usb 
<token> = 1; <answer> ar_usb->pipes[ATH6KL_USB_PIPE_RX_DATA].urb_cnt_thresh 
<token> = -ECANCELED; <answer> status 
"%s recv pipe: %d <token> failed:%d\n", <answer> (ep:0x%2.2X), 
<token> pipe->logical_pipe_num, <answer> __func__, 
pipe->ep_address, <token> <answer> urb->status); 
<token> cleanup_recv_urb; <answer> goto 
if (urb->actual_length <token> 0) <answer> == 
<token> cleanup_recv_urb; <answer> goto 
<token> = urb_context->skb; <answer> skb 
"%s pipe:%d no <token> left. URB Cnt : %d\n", <answer> urbs 
__func__, <token> pipe->urb_cnt); <answer> PipeID, 
status = <token> <answer> -ENOMEM; 
goto <token> <answer> fail_hif_send; 
urb_context->skb = <token> <answer> skb; 
data = <token> <answer> skb->data; 
len <token> skb->len; <answer> = 
urb <token> usb_alloc_urb(0, GFP_ATOMIC); <answer> = 
if (urb == NULL) <token> <answer> { 
status <token> -ENOMEM; <answer> = 
<token> fail_hif_send; <answer> goto 
ath6kl_usb_usb_transmit_complete, <token> <answer> urb_context); 
<token> ((len % pipe->max_packet_size) == 0) { <answer> if 
<token> = ATH6KL_USB_PIPE_RX_DATA; <answer> *dl_pipe 
case <token> <answer> WMI_DATA_VI_SVC: 
<token> (test_bit(ATH6KL_FW_CAPABILITY_MAP_LP_ENDPOINT, <answer> if 
*ul_pipe <token> ATH6KL_USB_PIPE_TX_DATA_LP; <answer> = 
*ul_pipe <token> ATH6KL_USB_PIPE_TX_DATA_MP; <answer> = 
*dl_pipe = <token> <answer> ATH6KL_USB_PIPE_RX_DATA; 
case <token> <answer> WMI_DATA_VO_SVC: 
if <token> <answer> (test_bit(ATH6KL_FW_CAPABILITY_MAP_LP_ENDPOINT, 
*ul_pipe = <token> <answer> ATH6KL_USB_PIPE_TX_DATA_LP; 
*ul_pipe = <token> <answer> ATH6KL_USB_PIPE_TX_DATA_MP; 
*dl_pipe <token> ATH6KL_USB_PIPE_RX_DATA; <answer> = 
status <token> -EPERM; <answer> = 
return <token> <answer> status; 
static <token> ath6kl_usb_get_free_queue_number(struct ath6kl *ar, u8 pipe_id) <answer> u16 
struct ath6kl_usb *device <token> ath6kl_usb_priv(ar); <answer> = 
<token> device->pipes[pipe_id].urb_cnt; <answer> return 
<token> void hif_detach_htc(struct ath6kl *ar) <answer> static 
<token> ath6kl_usb *device = ath6kl_usb_priv(ar); <answer> struct 
static int ath6kl_usb_submit_ctrl_out(struct ath6kl_usb <token> <answer> *ar_usb, 
u8 req, u16 value, <token> index, void *data, <answer> u16 
<token> size) <answer> u32 
<token> *buf = NULL; <answer> u8 
<token> ret; <answer> int 
if <token> > 0) { <answer> (size 
<token> = kmemdup(data, size, GFP_KERNEL); <answer> buf 
if (buf == <token> <answer> NULL) 
<token> -ENOMEM; <answer> return 
<token> int ath6kl_usb_suspend(struct ath6kl *ar, struct cfg80211_wowlan *wow) <answer> static 
<token> 0; <answer> return 
static int ath6kl_usb_resume(struct ath6kl <token> <answer> *ar) 
return <token> <answer> 0; 
static const struct ath6kl_hif_ops <token> = { <answer> ath6kl_usb_ops 
<token> = ath6kl_usb_diag_read32, <answer> .diag_read32 
.diag_write32 <token> ath6kl_usb_diag_write32, <answer> = 
.bmi_read = <token> <answer> ath6kl_usb_bmi_read, 
<token> = ath6kl_usb_bmi_write, <answer> .bmi_write 
<token> = ath6kl_usb_power_on, <answer> .power_on 
.power_off <token> ath6kl_usb_power_off, <answer> = 
.stop = <token> <answer> ath6kl_usb_stop, 
<token> = ath6kl_usb_send, <answer> .pipe_send 
<token> = ath6kl_usb_get_default_pipe, <answer> .pipe_get_default 
<token> = ath6kl_usb_map_service_pipe, <answer> .pipe_map_service 
<token> = ath6kl_usb_get_free_queue_number, <answer> .pipe_get_free_queue_number 
.cleanup_scatter <token> ath6kl_usb_cleanup_scatter, <answer> = 
.suspend <token> ath6kl_usb_suspend, <answer> = 
.resume <token> ath6kl_usb_resume, <answer> = 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <drm/drm_drv.h> 
#include <token> <answer> "vc4_drv.h" 
#include <token> <answer> "vc4_regs.h" 
#include <token> <answer> "vc4_trace.h" 
#define V3D_DRIVER_IRQS (V3D_INT_OUTOMEM | <token> <answer> \ 
V3D_INT_FLDONE | <token> <answer> \ 
<token> void <answer> static 
<token> work_struct *work) <answer> vc4_overflow_mem_work(struct 
struct vc4_dev <token> = <answer> *vc4 
container_of(work, <token> vc4_dev, overflow_mem_work); <answer> struct 
struct vc4_bo <token> <answer> *bo; 
int <token> <answer> bin_bo_slot; 
struct vc4_exec_info <token> <answer> *exec; 
unsigned long <token> <answer> irqflags; 
if <token> <answer> (!vc4->bin_bo) 
<token> complete; <answer> goto 
<token> = vc4->bin_bo; <answer> bo 
<token> = vc4_v3d_get_bin_slot(vc4); <answer> bin_bo_slot 
if (bin_bo_slot < 0) <token> <answer> { 
DRM_ERROR("Couldn't allocate binner overflow <token> <answer> mem\n"); 
<token> complete; <answer> goto 
<token> irqflags); <answer> spin_lock_irqsave(&vc4->job_lock, 
if (vc4->bin_alloc_overflow) <token> <answer> { 
exec = <token> <answer> vc4_first_bin_job(vc4); 
if <token> <answer> (!exec) 
<token> = vc4_last_render_job(vc4); <answer> exec 
<token> (exec) { <answer> if 
exec->bin_slots |= <token> <answer> vc4->bin_alloc_overflow; 
} else <token> <answer> { 
vc4->bin_alloc_used <token> ~vc4->bin_alloc_overflow; <answer> &= 
vc4->bin_alloc_overflow <token> BIT(bin_bo_slot); <answer> = 
V3D_WRITE(V3D_BPOA, bo->base.dma_addr + bin_bo_slot * <token> <answer> vc4->bin_alloc_size); 
<token> bo->base.base.size); <answer> V3D_WRITE(V3D_BPOS, 
V3D_WRITE(V3D_INTCTL, <token> <answer> V3D_INT_OUTOMEM); 
<token> V3D_INT_OUTOMEM); <answer> V3D_WRITE(V3D_INTENA, 
spin_unlock_irqrestore(&vc4->job_lock, <token> <answer> irqflags); 
static <token> <answer> void 
<token> drm_device *dev) <answer> vc4_irq_finish_bin_job(struct 
struct vc4_dev *vc4 <token> to_vc4_dev(dev); <answer> = 
struct <token> *next, *exec = vc4_first_bin_job(vc4); <answer> vc4_exec_info 
if <token> <answer> (!exec) 
<token> exec->seqno); <answer> trace_vc4_bcl_end_irq(dev, 
<token> exec); <answer> vc4_move_job_to_render(dev, 
next = <token> <answer> vc4_first_bin_job(vc4); 
if (next <token> next->perfmon == exec->perfmon) <answer> && 
<token> void <answer> static 
<token> drm_device *dev) <answer> vc4_cancel_bin_job(struct 
struct vc4_dev *vc4 <token> to_vc4_dev(dev); <answer> = 
struct vc4_exec_info *exec = <token> <answer> vc4_first_bin_job(vc4); 
if <token> <answer> (!exec) 
if (exec->perfmon && !nextrender <token> <answer> && 
(!nextbin || nextbin->perfmon <token> exec->perfmon)) <answer> != 
vc4_perfmon_stop(vc4, exec->perfmon, <token> <answer> true); 
if <token> <answer> (nextrender) 
else <token> (nextbin && nextbin->perfmon != exec->perfmon) <answer> if 
if <token> { <answer> (exec->fence) 
exec->fence <token> NULL; <answer> = 
<token> irqreturn_t <answer> static 
vc4_irq(int <token> void *arg) <answer> irq, 
struct drm_device *dev = <token> <answer> arg; 
struct vc4_dev <token> = to_vc4_dev(dev); <answer> *vc4 
<token> intctl; <answer> uint32_t 
irqreturn_t status <token> IRQ_NONE; <answer> = 
<token> = V3D_READ(V3D_INTCTL); <answer> intctl 
V3D_WRITE(V3D_INTCTL, <token> <answer> intctl); 
if (intctl <token> V3D_INT_OUTOMEM) { <answer> & 
<token> V3D_DRIVER_IRQS); <answer> V3D_WRITE(V3D_INTCTL, 
<token> drm_device *dev) <answer> vc4_irq_enable(struct 
struct vc4_dev <token> = to_vc4_dev(dev); <answer> *vc4 
<token> (WARN_ON_ONCE(vc4->is_vc5)) <answer> if 
<token> (!vc4->v3d) <answer> if 
V3D_WRITE(V3D_INTENA, V3D_INT_FLDONE <token> V3D_INT_FRDONE); <answer> | 
vc4_irq_disable(struct <token> *dev) <answer> drm_device 
struct vc4_dev *vc4 = <token> <answer> to_vc4_dev(dev); 
if <token> <answer> (WARN_ON_ONCE(vc4->is_vc5)) 
if <token> <answer> (!vc4->v3d) 
V3D_WRITE(V3D_INTENA, <token> <answer> V3D_DRIVER_IRQS); 
<token> irqflags); <answer> spin_lock_irqsave(&vc4->job_lock, 
spin_unlock_irqrestore(&vc4->job_lock, <token> <answer> irqflags); 
<token> <linux/pci.h> <answer> #include 
<token> "amdgpu.h" <answer> #include 
#include <token> <answer> "amdgpu_ih.h" 
<token> "vid.h" <answer> #include 
<token> "oss/oss_3_0_d.h" <answer> #include 
#include <token> <answer> "oss/oss_3_0_sh_mask.h" 
<token> "bif/bif_5_1_d.h" <answer> #include 
#include <token> <answer> "bif/bif_5_1_sh_mask.h" 
static void <token> amdgpu_device *adev); <answer> tonga_ih_set_interrupt_funcs(struct 
<token> void tonga_ih_enable_interrupts(struct amdgpu_device *adev) <answer> static 
u32 ih_rb_cntl = <token> <answer> RREG32(mmIH_RB_CNTL); 
ih_rb_cntl = REG_SET_FIELD(ih_rb_cntl, IH_RB_CNTL, <token> 1); <answer> RB_ENABLE, 
ih_rb_cntl = <token> IH_RB_CNTL, ENABLE_INTR, 1); <answer> REG_SET_FIELD(ih_rb_cntl, 
<token> ih_rb_cntl); <answer> WREG32(mmIH_RB_CNTL, 
<token> = true; <answer> adev->irq.ih.enabled 
static void tonga_ih_disable_interrupts(struct amdgpu_device <token> <answer> *adev) 
u32 ih_rb_cntl <token> RREG32(mmIH_RB_CNTL); <answer> = 
ih_rb_cntl = REG_SET_FIELD(ih_rb_cntl, <token> RB_ENABLE, 0); <answer> IH_RB_CNTL, 
ih_rb_cntl = REG_SET_FIELD(ih_rb_cntl, <token> ENABLE_INTR, 0); <answer> IH_RB_CNTL, 
WREG32(mmIH_RB_CNTL, <token> <answer> ih_rb_cntl); 
static int <token> amdgpu_device *adev) <answer> tonga_ih_irq_init(struct 
u32 <token> ih_rb_cntl, ih_doorbell_rtpr; <answer> interrupt_cntl, 
struct amdgpu_ih_ring *ih = <token> <answer> &adev->irq.ih; 
<token> rb_bufsz; <answer> int 
interrupt_cntl <token> REG_SET_FIELD(interrupt_cntl, INTERRUPT_CNTL, IH_DUMMY_RD_OVERRIDE, 0); <answer> = 
<token> void tonga_ih_irq_disable(struct amdgpu_device *adev) <answer> static 
<token> u32 tonga_ih_get_wptr(struct amdgpu_device *adev, <answer> static 
<token> amdgpu_ih_ring *ih) <answer> struct 
u32 <token> tmp; <answer> wptr, 
wptr = <token> <answer> le32_to_cpu(*ih->wptr_cpu); 
if <token> IH_RB_WPTR, RB_OVERFLOW)) <answer> (!REG_GET_FIELD(wptr, 
goto <token> <answer> out; 
dev_warn(adev->dev, "IH <token> buffer overflow (0x%08X, 0x%08X, 0x%08X)\n", <answer> ring 
wptr, ih->rptr, (wptr + 16) & <token> <answer> ih->ptr_mask); 
ih->rptr = <token> + 16) & ih->ptr_mask; <answer> (wptr 
tmp <token> RREG32(mmIH_RB_CNTL); <answer> = 
tmp = <token> IH_RB_CNTL, WPTR_OVERFLOW_CLEAR, 1); <answer> REG_SET_FIELD(tmp, 
WREG32(mmIH_RB_CNTL, <token> <answer> tmp); 
tmp = REG_SET_FIELD(tmp, IH_RB_CNTL, WPTR_OVERFLOW_CLEAR, <token> <answer> 0); 
WREG32(mmIH_RB_CNTL, <token> <answer> tmp); 
return (wptr <token> ih->ptr_mask); <answer> & 
<token> void tonga_ih_decode_iv(struct amdgpu_device *adev, <answer> static 
struct amdgpu_ih_ring <token> <answer> *ih, 
<token> amdgpu_iv_entry *entry) <answer> struct 
static <token> tonga_ih_set_rptr(struct amdgpu_device *adev, <answer> void 
struct <token> *ih) <answer> amdgpu_ih_ring 
<token> (ih->use_doorbell) { <answer> if 
int idxd_device_init_reset(struct <token> *idxd) <answer> idxd_device 
<token> device *dev = &idxd->pdev->dev; <answer> struct 
<token> idxd_command_reg cmd; <answer> union 
if <token> { <answer> (idxd_device_is_halted(idxd)) 
dev_warn(&idxd->pdev->dev, "Device is <token> <answer> HALTED!\n"); 
<token> -ENXIO; <answer> return 
<token> 0, sizeof(cmd)); <answer> memset(&cmd, 
<token> = IDXD_CMD_RESET_DEVICE; <answer> cmd.cmd 
dev_dbg(dev, "%s: sending reset for init.\n", <token> <answer> __func__); 
iowrite32(cmd.bits, idxd->reg_base <token> IDXD_CMD_OFFSET); <answer> + 
while (ioread32(idxd->reg_base <token> IDXD_CMDSTS_OFFSET) & <answer> + 
return <token> <answer> 0; 
static void idxd_cmd_exec(struct idxd_device *idxd, int cmd_code, u32 <token> <answer> operand, 
<token> *status) <answer> u32 
union <token> cmd; <answer> idxd_command_reg 
<token> stat; <answer> u32 
unsigned long <token> <answer> flags; 
if <token> { <answer> (idxd_device_is_halted(idxd)) 
dev_warn(&idxd->pdev->dev, <token> is HALTED!\n"); <answer> "Device 
<token> (status) <answer> if 
*status <token> IDXD_CMDSTS_HW_ERR; <answer> = 
memset(&cmd, <token> sizeof(cmd)); <answer> 0, 
cmd.cmd = <token> <answer> cmd_code; 
<token> = operand; <answer> cmd.operand 
<token> = 1; <answer> cmd.int_req 
<token> flags); <answer> spin_lock_irqsave(&idxd->cmd_lock, 
!test_bit(IDXD_FLAG_CMD_RUNNING, <token> <answer> &idxd->flags), 
dev_dbg(&idxd->pdev->dev, "%s: sending cmd: <token> op: %#x\n", <answer> %#x 
<token> cmd_code, operand); <answer> __func__, 
idxd->cmd_status = <token> <answer> 0; 
__set_bit(IDXD_FLAG_CMD_RUNNING, <token> <answer> &idxd->flags); 
<token> = &done; <answer> idxd->cmd_done 
iowrite32(cmd.bits, idxd->reg_base <token> IDXD_CMD_OFFSET); <answer> + 
spin_unlock_irqrestore(&idxd->cmd_lock, <token> <answer> flags); 
<token> = ioread32(idxd->reg_base + IDXD_CMDSTS_OFFSET); <answer> stat 
if <token> <answer> (status) 
*status = <token> <answer> stat; 
<token> = stat & GENMASK(7, 0); <answer> idxd->cmd_status 
__clear_bit(IDXD_FLAG_CMD_RUNNING, <token> <answer> &idxd->flags); 
group->rdbufs_allowed <token> idxd->max_rdbufs; <answer> = 
<token> = 0; <answer> group->rdbufs_reserved 
if (idxd->hw.version <= <token> && !tc_override) { <answer> DEVICE_VERSION_2 
group->tc_a <token> 1; <answer> = 
group->tc_b <token> 1; <answer> = 
<token> else { <answer> } 
group->tc_a = <token> <answer> -1; 
group->tc_b <token> -1; <answer> = 
group->desc_progress_limit = <token> <answer> 0; 
group->batch_progress_limit <token> 0; <answer> = 
<token> void idxd_device_wqs_clear_state(struct idxd_device *idxd) <answer> static 
int <token> <answer> i; 
for (i = 0; i < idxd->max_wqs; i++) <token> <answer> { 
struct idxd_wq <token> = idxd->wqs[i]; <answer> *wq 
void <token> idxd_device *idxd) <answer> idxd_device_clear_state(struct 
<token> else { <answer> } 
<token> = IDXD_DEV_DISABLED; <answer> idxd->state 
static int <token> idxd_device *idxd) <answer> idxd_device_evl_setup(struct 
union <token> gencfg; <answer> gencfg_reg 
union <token> evlcfg; <answer> evlcfg_reg 
union genctrl_reg <token> <answer> genctrl; 
struct <token> *dev = &idxd->pdev->dev; <answer> device 
<token> *addr; <answer> void 
dma_addr_t <token> <answer> dma_addr; 
<token> size; <answer> int 
struct idxd_evl *evl = <token> <answer> idxd->evl; 
unsigned <token> *bmap; <answer> long 
<token> rc; <answer> int 
<token> (!evl) <answer> if 
<token> 0; <answer> return 
<token> = evl_size(idxd); <answer> size 
bmap <token> bitmap_zalloc(size, GFP_KERNEL); <answer> = 
if <token> { <answer> (!bmap) 
rc = <token> <answer> -ENOMEM; 
goto <token> <answer> err_bmap; 
addr = dma_alloc_coherent(dev, <token> &dma_addr, GFP_KERNEL); <answer> size, 
if (!addr) <token> <answer> { 
rc = <token> <answer> -ENOMEM; 
<token> err_alloc; <answer> goto 
<token> = addr; <answer> evl->log 
<token> = dma_addr; <answer> evl->dma 
<token> = size; <answer> evl->log_size 
evl->bmap = <token> <answer> bmap; 
memset(&evlcfg, 0, <token> <answer> sizeof(evlcfg)); 
evlcfg.bits[0] = dma_addr <token> GENMASK(63, 12); <answer> & 
evlcfg.size <token> evl->size; <answer> = 
iowrite64(evlcfg.bits[0], idxd->reg_base + <token> <answer> IDXD_EVLCFG_OFFSET); 
iowrite64(evlcfg.bits[1], idxd->reg_base + IDXD_EVLCFG_OFFSET + <token> <answer> 8); 
genctrl.bits <token> ioread32(idxd->reg_base + IDXD_GENCTRL_OFFSET); <answer> = 
genctrl.evl_int_en <token> 1; <answer> = 
<token> idxd->reg_base + IDXD_GENCTRL_OFFSET); <answer> iowrite32(genctrl.bits, 
gencfg.bits = <token> + IDXD_GENCFG_OFFSET); <answer> ioread32(idxd->reg_base 
gencfg.evl_en = <token> <answer> 1; 
iowrite32(gencfg.bits, idxd->reg_base <token> IDXD_GENCFG_OFFSET); <answer> + 
<token> 0; <answer> return 
return <token> <answer> rc; 
static <token> idxd_device_evl_free(struct idxd_device *idxd) <answer> void 
void <token> <answer> *evl_log; 
unsigned <token> evl_log_size; <answer> int 
<token> evl_dma; <answer> dma_addr_t 
union gencfg_reg <token> <answer> gencfg; 
<token> genctrl_reg genctrl; <answer> union 
struct <token> *dev = &idxd->pdev->dev; <answer> device 
struct idxd_evl *evl <token> idxd->evl; <answer> = 
gencfg.bits = ioread32(idxd->reg_base + <token> <answer> IDXD_GENCFG_OFFSET); 
if <token> <answer> (!gencfg.evl_en) 
gencfg.evl_en <token> 0; <answer> = 
iowrite32(gencfg.bits, <token> + IDXD_GENCFG_OFFSET); <answer> idxd->reg_base 
genctrl.bits = ioread32(idxd->reg_base + <token> <answer> IDXD_GENCTRL_OFFSET); 
<token> = 0; <answer> genctrl.evl_int_en 
iowrite32(genctrl.bits, idxd->reg_base <token> IDXD_GENCTRL_OFFSET); <answer> + 
iowrite64(0, <token> + IDXD_EVLCFG_OFFSET); <answer> idxd->reg_base 
<token> idxd->reg_base + IDXD_EVLCFG_OFFSET + 8); <answer> iowrite64(0, 
<token> = evl->log; <answer> evl_log 
<token> = evl->log_size; <answer> evl_log_size 
evl_dma <token> evl->dma; <answer> = 
evl->log = <token> <answer> NULL; 
evl->size = <token> <answer> IDXD_EVL_SIZE_MIN; 
<token> evl_log_size, evl_log, evl_dma); <answer> dma_free_coherent(dev, 
static void idxd_group_config_write(struct idxd_group <token> <answer> *group) 
struct idxd_device <token> = group->idxd; <answer> *idxd 
struct device *dev = <token> <answer> &idxd->pdev->dev; 
<token> i; <answer> int 
<token> grpcfg_offset; <answer> u32 
dev_dbg(dev, "Writing group <token> cfg registers\n", group->id); <answer> %d 
for (i <token> 0; i < WQCFG_STRIDES(idxd); i++) { <answer> = 
wq_offset <token> WQCFG_OFFSET(idxd, wq->id, i); <answer> = 
wq->wqcfg->bits[i] <token> ioread32(idxd->reg_base + wq_offset); <answer> |= 
if <token> == 0 && wq->type != IDXD_WQT_NONE) <answer> (wq->size 
wq->size <token> WQ_DEFAULT_QUEUE_DEPTH; <answer> = 
if (wq_dedicated(wq) && wq->wqcfg->pasid_en <token> <answer> && 
<token> && <answer> !idxd_device_pasid_priv_enabled(idxd) 
<token> == IDXD_WQT_KERNEL) { <answer> wq->type 
idxd->cmd_status <token> IDXD_SCMD_WQ_NO_PRIV; <answer> = 
<token> -EOPNOTSUPP; <answer> return 
wq->wqcfg->priority <token> wq->priority; <answer> = 
if <token> && <answer> (idxd->hw.gen_cap.block_on_fault 
<token> &wq->flags) && <answer> test_bit(WQ_FLAG_BLOCK_ON_FAULT, 
<token> &wq->flags)) <answer> !test_bit(WQ_FLAG_PRS_DISABLE, 
wq->wqcfg->bof = <token> <answer> 1; 
<token> (idxd->hw.wq_cap.wq_ats_support) <answer> if 
wq->wqcfg->wq_ats_disable <token> test_bit(WQ_FLAG_ATS_DISABLE, &wq->flags); <answer> = 
<token> (idxd->hw.wq_cap.wq_prs_support) <answer> if 
wq->wqcfg->wq_prs_disable = <token> &wq->flags); <answer> test_bit(WQ_FLAG_PRS_DISABLE, 
for (i = <token> i < GRPWQCFG_STRIDES; i++) { <answer> 0; 
<token> idxd_wq *wq; <answer> struct 
<token> = GRPWQCFG_OFFSET(idxd, group->id, i); <answer> grpcfg_offset 
group->grpcfg.wqs[i] <token> ioread64(idxd->reg_base + grpcfg_offset); <answer> = 
<token> "GRPCFG wq[%d:%d: %#x]: %#llx\n", <answer> dev_dbg(dev, 
group->id, i, <token> group->grpcfg.wqs[i]); <answer> grpcfg_offset, 
if (i * 64 <token> idxd->max_wqs) <answer> >= 
tx <token> &desc->txd; <answer> = 
<token> = NULL; <answer> tx->callback 
tx->callback_result = <token> <answer> NULL; 
idxd_dma_complete_txd(desc, ctype, <token> NULL, NULL); <answer> true, 
static <token> idxd_device_set_perm_entry(struct idxd_device *idxd, <answer> void 
<token> idxd_irq_entry *ie) <answer> struct 
union msix_perm <token> <answer> mperm; 
if (ie->pasid == <token> <answer> IOMMU_PASID_INVALID) 
mperm.bits = <token> <answer> 0; 
mperm.pasid <token> ie->pasid; <answer> = 
<token> = 1; <answer> mperm.pasid_en 
<token> idxd->reg_base + idxd->msix_perm_offset + ie->id * 8); <answer> iowrite32(mperm.bits, 
static void <token> idxd_device *idxd, <answer> idxd_device_clear_perm_entry(struct 
<token> idxd_irq_entry *ie) <answer> struct 
iowrite32(0, <token> + idxd->msix_perm_offset + ie->id * 8); <answer> idxd->reg_base 
void idxd_wq_free_irq(struct <token> *wq) <answer> idxd_wq 
struct idxd_device *idxd = <token> <answer> wq->idxd; 
struct idxd_irq_entry <token> = &wq->ie; <answer> *ie 
if <token> != IDXD_WQT_KERNEL) <answer> (wq->type 
free_irq(ie->vector, <token> <answer> ie); 
if <token> <answer> (idxd->request_int_handles) 
idxd_device_release_int_handle(idxd, <token> IDXD_IRQ_MSIX); <answer> ie->int_handle, 
<token> ie); <answer> idxd_device_clear_perm_entry(idxd, 
ie->vector <token> -1; <answer> = 
ie->int_handle <token> INVALID_INT_HANDLE; <answer> = 
ie->pasid <token> IOMMU_PASID_INVALID; <answer> = 
<token> idxd_wq_request_irq(struct idxd_wq *wq) <answer> int 
struct <token> *idxd = wq->idxd; <answer> idxd_device 
struct pci_dev *pdev = <token> <answer> idxd->pdev; 
struct device <token> = &pdev->dev; <answer> *dev 
struct idxd_irq_entry <token> <answer> *ie; 
int <token> <answer> rc; 
if <token> != IDXD_WQT_KERNEL) <answer> (wq->type 
return <token> <answer> 0; 
ie = <token> <answer> &wq->ie; 
ie->vector = <token> ie->id); <answer> pci_irq_vector(pdev, 
ie->pasid = device_pasid_enabled(idxd) ? idxd->pasid : <token> <answer> IOMMU_PASID_INVALID; 
<token> ie); <answer> idxd_device_set_perm_entry(idxd, 
rc = request_threaded_irq(ie->vector, NULL, idxd_wq_thread, <token> "idxd-portal", ie); <answer> 0, 
if <token> < 0) { <answer> (rc 
dev_err(dev, "Failed to request irq %d.\n", <token> <answer> ie->vector); 
<token> err_irq; <answer> goto 
<token> (idxd->request_int_handles) { <answer> if 
rc = idxd_device_request_int_handle(idxd, <token> &ie->int_handle, <answer> ie->id, 
if <token> < 0) <answer> (rc 
<token> err_int_handle; <answer> goto 
<token> else { <answer> } 
ie->int_handle <token> ie->id; <answer> = 
<token> 0; <answer> return 
<token> = INVALID_INT_HANDLE; <answer> ie->int_handle 
free_irq(ie->vector, <token> <answer> ie); 
<token> ie); <answer> idxd_device_clear_perm_entry(idxd, 
<token> = IOMMU_PASID_INVALID; <answer> ie->pasid 
return <token> <answer> rc; 
int idxd_drv_enable_wq(struct idxd_wq <token> <answer> *wq) 
struct <token> *idxd = wq->idxd; <answer> idxd_device 
struct device <token> = &idxd->pdev->dev; <answer> *dev 
int rc <token> -ENXIO; <answer> = 
if (idxd->state != <token> { <answer> IDXD_DEV_ENABLED) 
idxd->cmd_status <token> IDXD_SCMD_DEV_NOT_ENABLED; <answer> = 
goto <token> <answer> err; 
if (wq->state != <token> { <answer> IDXD_WQ_DISABLED) 
dev_dbg(dev, "wq %d already enabled.\n", <token> <answer> wq->id); 
idxd->cmd_status = <token> <answer> IDXD_SCMD_WQ_ENABLED; 
rc = <token> <answer> -EBUSY; 
goto <token> <answer> err; 
<token> (!wq->group) { <answer> if 
dev_dbg(dev, "wq %d <token> attached to group.\n", wq->id); <answer> not 
idxd->cmd_status <token> IDXD_SCMD_WQ_NO_GRP; <answer> = 
goto <token> <answer> err; 
if (strlen(wq->name) <token> 0) { <answer> == 
idxd->cmd_status <token> IDXD_SCMD_WQ_NO_NAME; <answer> = 
dev_dbg(dev, <token> %d name not set.\n", wq->id); <answer> "wq 
<token> err; <answer> goto 
<token> (wq->threshold == 0) { <answer> if 
idxd->cmd_status = <token> <answer> IDXD_SCMD_WQ_NO_THRESH; 
dev_dbg(dev, "Shared wq <token> threshold 0.\n"); <answer> and 
<token> err; <answer> goto 
if <token> &idxd->flags)) { <answer> (test_bit(IDXD_FLAG_CONFIGURABLE, 
<token> (wq_pasid_enabled(wq)) { <answer> if 
if (is_idxd_wq_kernel(wq) || <token> { <answer> wq_shared(wq)) 
u32 pasid = wq_dedicated(wq) ? <token> : 0; <answer> idxd->pasid 
__idxd_wq_set_pasid_locked(wq, <token> <answer> pasid); 
rc = <token> <answer> 0; 
if <token> &idxd->flags)) <answer> (test_bit(IDXD_FLAG_CONFIGURABLE, 
<token> = idxd_device_config(idxd); <answer> rc 
if (rc < <token> { <answer> 0) 
dev_dbg(dev, "Writing wq %d config failed: %d\n", <token> rc); <answer> wq->id, 
goto <token> <answer> err; 
<token> = idxd_wq_enable(wq); <answer> rc 
if (rc < 0) <token> <answer> { 
dev_dbg(dev, "wq %d <token> failed: %d\n", wq->id, rc); <answer> enabling 
goto <token> <answer> err; 
rc <token> idxd_wq_map_portal(wq); <answer> = 
if (rc <token> 0) { <answer> < 
idxd->cmd_status = <token> <answer> IDXD_SCMD_WQ_PORTAL_ERR; 
dev_dbg(dev, "wq %d portal mapping failed: %d\n", <token> rc); <answer> wq->id, 
goto <token> <answer> err_map_portal; 
wq->client_count = <token> <answer> 0; 
rc = <token> <answer> idxd_wq_request_irq(wq); 
if <token> < 0) { <answer> (rc 
idxd->cmd_status = <token> <answer> IDXD_SCMD_WQ_IRQ_ERR; 
dev_dbg(dev, "WQ %d <token> setup failed: %d\n", wq->id, rc); <answer> irq 
goto <token> <answer> err_irq; 
<token> = idxd_wq_alloc_resources(wq); <answer> rc 
if <token> < 0) { <answer> (rc 
idxd->cmd_status <token> IDXD_SCMD_WQ_RES_ALLOC_ERR; <answer> = 
dev_dbg(dev, "WQ resource <token> failed\n"); <answer> alloc 
goto <token> <answer> err_res_alloc; 
<token> = idxd_wq_init_percpu_ref(wq); <answer> rc 
if <token> < 0) { <answer> (rc 
idxd->cmd_status <token> IDXD_SCMD_PERCPU_ERR; <answer> = 
dev_dbg(dev, "percpu_ref <token> failed\n"); <answer> setup 
<token> err_ref; <answer> goto 
return <token> <answer> 0; 
if (idxd_wq_disable(wq, <token> <answer> false)) 
dev_dbg(dev, "wq %s disable failed\n", <token> <answer> dev_name(wq_confdev(wq))); 
<token> rc; <answer> return 
<token> IDXD); <answer> EXPORT_SYMBOL_NS_GPL(idxd_drv_enable_wq, 
void idxd_drv_disable_wq(struct idxd_wq <token> <answer> *wq) 
struct idxd_device *idxd = <token> <answer> wq->idxd; 
struct device *dev = <token> <answer> &idxd->pdev->dev; 
if <token> <answer> (idxd_wq_refcount(wq)) 
dev_warn(dev, "Clients has claim on <token> %d: %d\n", <answer> wq 
wq->id, <token> <answer> idxd_wq_refcount(wq)); 
<token> = IDXD_WQT_NONE; <answer> wq->type 
<token> = 0; <answer> wq->client_count 
EXPORT_SYMBOL_NS_GPL(idxd_drv_disable_wq, <token> <answer> IDXD); 
<token> idxd_device_drv_probe(struct idxd_dev *idxd_dev) <answer> int 
struct idxd_device *idxd = <token> <answer> idxd_dev_to_idxd(idxd_dev); 
int <token> = 0; <answer> rc 
if (idxd->state != IDXD_DEV_DISABLED) <token> <answer> { 
idxd->cmd_status <token> IDXD_SCMD_DEV_ENABLED; <answer> = 
<token> -ENXIO; <answer> return 
if <token> != IOMMU_PASID_INVALID) <answer> (idxd->pasid 
<token> 1); <answer> idxd_set_user_intr(idxd, 
rc = <token> <answer> idxd_device_evl_setup(idxd); 
if (rc <token> 0) { <answer> < 
<token> = IDXD_SCMD_DEV_EVL_ERR; <answer> idxd->cmd_status 
return <token> <answer> rc; 
<token> <stdio.h> <answer> #include 
<token> <stdlib.h> <answer> #include 
<token> <unistd.h> <answer> #include 
#include <token> <answer> <string.h> 
#include <token> <answer> "tm.h" 
#include <token> <answer> "utils.h" 
int <token> = 10000; <answer> num_loops 
int <token> <answer> test_tar(void) 
int <token> <answer> i; 
for (i = 0; i <token> num_loops; i++) <answer> < 
uint64_t result <token> 0; <answer> = 
<token> __volatile__( <answer> asm 
<token> 7, 1;" <answer> "li 
if ((result != 7) && (result <token> 9)) <answer> != 
return <token> <answer> 1; 
<token> 0; <answer> return 
int main(int argc, <token> *argv[]) <answer> char 
#include <token> <answer> <linux/fips.h> 
<token> <linux/module.h> <answer> #include 
<token> <crypto/internal/kpp.h> <answer> #include 
<token> <crypto/kpp.h> <answer> #include 
<token> <crypto/dh.h> <answer> #include 
<token> <crypto/rng.h> <answer> #include 
<token> <linux/mpi.h> <answer> #include 
<token> dh_ctx { <answer> struct 
static int _compute_val(const struct dh_ctx *ctx, MPI <token> MPI val) <answer> base, 
static int <token> dh_ctx *ctx, MPI y) <answer> dh_is_pubkey_valid(struct 
MPI val, <token> <answer> q; 
<token> ret; <answer> int 
<token> (!fips_enabled) <answer> if 
return <token> <answer> 0; 
<token> (unlikely(!ctx->p)) <answer> if 
return <token> <answer> -EINVAL; 
if (mpi_cmp_ui(y, 1) < 1 || mpi_cmp(y, ctx->p) <token> 0) <answer> >= 
<token> -EINVAL; <answer> return 
val = <token> <answer> mpi_alloc(0); 
<token> (!val) <answer> if 
<token> -ENOMEM; <answer> return 
<token> = mpi_alloc(mpi_get_nlimbs(ctx->p)); <answer> q 
<token> (!q) { <answer> if 
return <token> <answer> -ENOMEM; 
mpi_rshift(q, <token> 1); <answer> ctx->p, 
<token> = mpi_powm(val, y, q, ctx->p); <answer> ret 
if (ret) <token> <answer> { 
return <token> <answer> ret; 
ret = mpi_cmp_ui(val, <token> <answer> 1); 
if (ret != <token> <answer> 0) 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
static int dh_compute_value(struct <token> *req) <answer> kpp_request 
struct crypto_kpp *tfm <token> crypto_kpp_reqtfm(req); <answer> = 
struct dh_ctx *ctx = <token> <answer> dh_get_ctx(tfm); 
MPI base, <token> = mpi_alloc(0); <answer> val 
<token> ret = 0; <answer> int 
int <token> <answer> sign; 
<token> (!val) <answer> if 
return <token> <answer> -ENOMEM; 
if (unlikely(!ctx->xa)) <token> <answer> { 
<token> = -EINVAL; <answer> ret 
<token> err_free_val; <answer> goto 
<token> (req->src) { <answer> if 
base <token> mpi_read_raw_from_sgl(req->src, req->src_len); <answer> = 
if <token> { <answer> (!base) 
<token> = -EINVAL; <answer> ret 
<token> err_free_val; <answer> goto 
ret = dh_is_pubkey_valid(ctx, <token> <answer> base); 
if <token> <answer> (ret) 
<token> err_free_base; <answer> goto 
} <token> { <answer> else 
base = <token> <answer> ctx->g; 
ret = _compute_val(ctx, base, <token> <answer> val); 
<token> (ret) <answer> if 
goto <token> <answer> err_free_base; 
if (fips_enabled) <token> <answer> { 
<token> = roundup_pow_of_two(2 * safe_prime->max_strength); <answer> n 
WARN_ON_ONCE(n & ((1u << 6) - <token> <answer> 1)); 
oversampling_size = (n + <token> * sizeof(__be64); <answer> 1) 
key <token> kmalloc(oversampling_size, GFP_KERNEL); <answer> = 
if <token> <answer> (!key) 
return <token> <answer> ERR_PTR(-ENOMEM); 
err = <token> <answer> -EFAULT; 
<token> (crypto_get_default_rng()) <answer> if 
goto <token> <answer> out_err; 
err = crypto_rng_get_bytes(crypto_default_rng, (u8 <token> <answer> *)key, 
<token> (err) <answer> if 
<token> out_err; <answer> goto 
h <token> be64_to_cpu(key[0]); <answer> = 
h = __add_u64_to_be(key + <token> n, h); <answer> 1, 
h = __add_u64_to_be(key + 1, <token> h); <answer> n, 
<token> (o) <answer> if 
key[n] <token> cpu_to_be64(1); <answer> = 
<token> <linux/kstrtox.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/rtc.h> 
#include <token> <answer> "rtc-core.h" 
<token> ssize_t <answer> static 
name_show(struct device *dev, struct device_attribute <token> char *buf) <answer> *attr, 
return sprintf(buf, "%s <token> dev_driver_string(dev->parent), <answer> %s\n", 
<token> DEVICE_ATTR_RO(name); <answer> static 
static <token> <answer> ssize_t 
date_show(struct <token> *dev, struct device_attribute *attr, char *buf) <answer> device 
ssize_t <token> <answer> retval; 
<token> rtc_time tm; <answer> struct 
<token> = rtc_read_time(to_rtc_device(dev), &tm); <answer> retval 
if <token> <answer> (retval) 
return <token> <answer> retval; 
return sprintf(buf, <token> &tm); <answer> "%ptRd\n", 
static <token> <answer> DEVICE_ATTR_RO(date); 
static <token> <answer> ssize_t 
time_show(struct device *dev, struct device_attribute *attr, char <token> <answer> *buf) 
ssize_t <token> <answer> retval; 
struct <token> tm; <answer> rtc_time 
<token> = rtc_read_time(to_rtc_device(dev), &tm); <answer> retval 
<token> (retval) <answer> if 
<token> retval; <answer> return 
return sprintf(buf, <token> &tm); <answer> "%ptRt\n", 
<token> DEVICE_ATTR_RO(time); <answer> static 
static <token> <answer> ssize_t 
<token> device *dev, struct device_attribute *attr, char *buf) <answer> since_epoch_show(struct 
ssize_t <token> <answer> retval; 
<token> rtc_time tm; <answer> struct 
retval <token> rtc_read_time(to_rtc_device(dev), &tm); <answer> = 
if (retval <token> 0) { <answer> == 
<token> time; <answer> time64_t 
<token> = rtc_tm_to_time64(&tm); <answer> time 
retval = sprintf(buf, "%lld\n", <token> <answer> time); 
return <token> <answer> retval; 
static <token> <answer> DEVICE_ATTR_RO(since_epoch); 
<token> ssize_t <answer> static 
max_user_freq_show(struct device *dev, struct device_attribute *attr, <token> *buf) <answer> char 
return <token> "%d\n", to_rtc_device(dev)->max_user_freq); <answer> sprintf(buf, 
<token> ssize_t <answer> static 
<token> device *dev, struct device_attribute *attr, <answer> max_user_freq_store(struct 
const char <token> size_t n) <answer> *buf, 
struct <token> *rtc = to_rtc_device(dev); <answer> rtc_device 
unsigned <token> val; <answer> long 
int <token> <answer> err; 
<token> = kstrtoul(buf, 0, &val); <answer> err 
<token> (err) <answer> if 
<token> err; <answer> return 
if (val >= 4096 <token> val == 0) <answer> || 
<token> -EINVAL; <answer> return 
<token> = (int)val; <answer> rtc->max_user_freq 
<token> n; <answer> return 
<token> DEVICE_ATTR_RW(max_user_freq); <answer> static 
<token> ssize_t <answer> static 
hctosys_show(struct device <token> struct device_attribute *attr, char *buf) <answer> *dev, 
<token> CONFIG_RTC_HCTOSYS_DEVICE <answer> #ifdef 
if (rtc_hctosys_ret == <token> && <answer> 0 
<token> == 0) <answer> CONFIG_RTC_HCTOSYS_DEVICE) 
return sprintf(buf, <token> <answer> "1\n"); 
<token> sprintf(buf, "0\n"); <answer> return 
static <token> <answer> DEVICE_ATTR_RO(hctosys); 
static <token> <answer> ssize_t 
wakealarm_show(struct <token> *dev, struct device_attribute *attr, char *buf) <answer> device 
<token> retval; <answer> ssize_t 
time64_t <token> <answer> alarm; 
<token> rtc_wkalrm alm; <answer> struct 
retval <token> rtc_read_alarm(to_rtc_device(dev), &alm); <answer> = 
if <token> == 0 && alm.enabled) { <answer> (retval 
<token> = rtc_tm_to_time64(&alm.time); <answer> alarm 
retval <token> sprintf(buf, "%lld\n", alarm); <answer> = 
<token> retval; <answer> return 
static <token> <answer> ssize_t 
<token> device *dev, struct device_attribute *attr, <answer> wakealarm_store(struct 
const char *buf, size_t <token> <answer> n) 
<token> retval; <answer> ssize_t 
<token> now, alarm; <answer> time64_t 
time64_t push = <token> <answer> 0; 
<token> rtc_wkalrm alm; <answer> struct 
struct rtc_device <token> = to_rtc_device(dev); <answer> *rtc 
const char <token> <answer> *buf_ptr; 
int adjust = <token> <answer> 0; 
<token> = rtc_read_time(rtc, &alm.time); <answer> retval 
if (retval <token> 0) <answer> < 
return <token> <answer> retval; 
<token> = rtc_tm_to_time64(&alm.time); <answer> now 
buf_ptr = <token> <answer> buf; 
<token> (*buf_ptr == '+') { <answer> if 
if (*buf_ptr <token> '=') { <answer> == 
push = <token> <answer> 1; 
} else <token> <answer> { 
adjust <token> 1; <answer> = 
retval = kstrtos64(buf_ptr, <token> &alarm); <answer> 0, 
if <token> <answer> (retval) 
<token> retval; <answer> return 
<token> (adjust) <answer> if 
<token> += now; <answer> alarm 
if (alarm > now || <token> { <answer> push) 
retval = <token> &alm); <answer> rtc_read_alarm(rtc, 
if (retval < <token> <answer> 0) 
return <token> <answer> retval; 
if <token> { <answer> (alm.enabled) 
if (push) <token> <answer> { 
<token> = rtc_tm_to_time64(&alm.time); <answer> push 
alarm += <token> <answer> push; 
<token> else <answer> } 
return <token> <answer> -EBUSY; 
} else if <token> <answer> (push) 
return <token> <answer> -EINVAL; 
<token> = 1; <answer> alm.enabled 
} <token> { <answer> else 
alm.enabled <token> 0; <answer> = 
alarm = <token> + 300; <answer> now 
<token> &alm.time); <answer> rtc_time64_to_tm(alarm, 
retval <token> rtc_set_alarm(rtc, &alm); <answer> = 
return <token> < 0) ? retval : n; <answer> (retval 
<token> DEVICE_ATTR_RW(wakealarm); <answer> static 
<token> ssize_t <answer> static 
offset_show(struct device *dev, struct device_attribute *attr, <token> *buf) <answer> char 
<token> retval; <answer> ssize_t 
<token> offset; <answer> long 
<token> = rtc_read_offset(to_rtc_device(dev), &offset); <answer> retval 
if (retval == <token> <answer> 0) 
<token> = sprintf(buf, "%ld\n", offset); <answer> retval 
return <token> <answer> retval; 
static <token> <answer> ssize_t 
offset_store(struct device *dev, struct <token> *attr, <answer> device_attribute 
const <token> *buf, size_t n) <answer> char 
<token> retval; <answer> ssize_t 
long <token> <answer> offset; 
<token> = kstrtol(buf, 10, &offset); <answer> retval 
if (retval == <token> <answer> 0) 
<token> = rtc_set_offset(to_rtc_device(dev), offset); <answer> retval 
return (retval < 0) ? <token> : n; <answer> retval 
<token> DEVICE_ATTR_RW(offset); <answer> static 
static <token> <answer> ssize_t 
range_show(struct device *dev, struct <token> *attr, char *buf) <answer> device_attribute 
return sprintf(buf, "[%lld,%llu]\n", <token> <answer> to_rtc_device(dev)->range_min, 
static <token> <answer> DEVICE_ATTR_RO(range); 
static struct <token> *rtc_attrs[] = { <answer> attribute 
static bool <token> rtc_device *rtc) <answer> rtc_does_wakealarm(struct 
if <token> <answer> (!device_can_wakeup(rtc->dev.parent)) 
<token> false; <answer> return 
return <token> rtc->features); <answer> !!test_bit(RTC_FEATURE_ALARM, 
static umode_t rtc_attr_is_visible(struct <token> *kobj, <answer> kobject 
struct attribute <token> int n) <answer> *attr, 
<token> device *dev = kobj_to_dev(kobj); <answer> struct 
<token> rtc_device *rtc = to_rtc_device(dev); <answer> struct 
<token> mode = attr->mode; <answer> umode_t 
if (attr <token> &dev_attr_wakealarm.attr) { <answer> == 
if <token> <answer> (!rtc_does_wakealarm(rtc)) 
mode = <token> <answer> 0; 
} else if (attr <token> &dev_attr_offset.attr) { <answer> == 
if <token> <answer> (!rtc->ops->set_offset) 
<token> = 0; <answer> mode 
} else if (attr <token> &dev_attr_range.attr) { <answer> == 
if <token> - rtc->range_min)) <answer> (!(rtc->range_max 
<token> = 0; <answer> mode 
<token> mode; <answer> return 
static struct attribute_group rtc_attr_group <token> { <answer> = 
.is_visible = <token> <answer> rtc_attr_is_visible, 
<token> = rtc_attrs, <answer> .attrs 
static const struct attribute_group *rtc_attr_groups[] = <token> <answer> { 
const struct <token> **rtc_get_dev_attribute_groups(void) <answer> attribute_group 
return <token> <answer> rtc_attr_groups; 
int rtc_add_groups(struct rtc_device <token> const struct attribute_group **grps) <answer> *rtc, 
size_t old_cnt = <token> add_cnt = 0, new_cnt; <answer> 0, 
const struct <token> **groups, **old; <answer> attribute_group 
<token> (!grps) <answer> if 
return <token> <answer> -EINVAL; 
<token> = rtc->dev.groups; <answer> groups 
<token> (groups) <answer> if 
<token> (; *groups; groups++) <answer> for 
<token> (groups = grps; *groups; groups++) <answer> for 
new_cnt = old_cnt + <token> + 1; <answer> add_cnt 
groups <token> devm_kcalloc(&rtc->dev, new_cnt, sizeof(*groups), GFP_KERNEL); <answer> = 
if <token> <answer> (!groups) 
<token> -ENOMEM; <answer> return 
<token> rtc->dev.groups, old_cnt * sizeof(*groups)); <answer> memcpy(groups, 
<token> + old_cnt, grps, add_cnt * sizeof(*groups)); <answer> memcpy(groups 
groups[old_cnt <token> add_cnt] = NULL; <answer> + 
old = <token> <answer> rtc->dev.groups; 
rtc->dev.groups = <token> <answer> groups; 
if <token> && old != rtc_attr_groups) <answer> (old 
<token> old); <answer> devm_kfree(&rtc->dev, 
return <token> <answer> 0; 
int rtc_add_group(struct rtc_device *rtc, const struct <token> *grp) <answer> attribute_group 
const <token> attribute_group *groups[] = { grp, NULL }; <answer> struct 
<token> rtc_add_groups(rtc, groups); <answer> return 
#include <token> <answer> <stdint.h> 
<token> <string.h> <answer> #include 
<token> <linux/stddef.h> <answer> #include 
#include <token> <answer> <linux/bpf.h> 
#include <token> <answer> <bpf/bpf_helpers.h> 
#include <token> <answer> "bpf_compiler.h" 
#include <token> <answer> <errno.h> 
<token> <fcntl.h> <answer> #include 
#include <token> <answer> <stdint.h> 
<token> <stdlib.h> <answer> #include 
<token> <string.h> <answer> #include 
<token> <sys/mman.h> <answer> #include 
<token> <unistd.h> <answer> #include 
#include <token> <answer> "libbpf_internal.h" 
#include <token> <answer> "zip.h" 
#pragma <token> diagnostic push <answer> GCC 
#pragma <token> diagnostic ignored "-Wpacked" <answer> GCC 
#pragma GCC diagnostic ignored <token> <answer> "-Wattributes" 
#define <token> 0x06054b50 <answer> END_OF_CD_RECORD_MAGIC 
__u16 <token> <answer> this_disk; 
<token> cd_disk; <answer> __u16 
<token> cd_records; <answer> __u16 
<token> cd_records_total; <answer> __u16 
<token> cd_offset; <answer> __u32 
<token> offset; <answer> __u32 
} <token> <answer> __attribute__((packed)); 
#define <token> 0x04034b50 <answer> LOCAL_FILE_HEADER_MAGIC 
static int try_parse_end_of_cd(struct zip_archive <token> __u32 offset) <answer> *archive, 
__u16 <token> cd_records; <answer> comment_length, 
struct <token> *eocd; <answer> end_of_cd_record 
__u32 cd_offset, <token> <answer> cd_size; 
eocd = check_access(archive, <token> sizeof(*eocd)); <answer> offset, 
<token> (!eocd || eocd->magic != END_OF_CD_RECORD_MAGIC) <answer> if 
<token> -EINVAL; <answer> return 
<token> = eocd->comment_length; <answer> comment_length 
if (offset + sizeof(*eocd) + comment_length != <token> <answer> archive->size) 
return <token> <answer> -EINVAL; 
cd_records = <token> <answer> eocd->cd_records; 
<token> (eocd->this_disk != 0 || eocd->cd_disk != 0 || eocd->cd_records_total != cd_records) <answer> if 
offset = archive->size - sizeof(struct <token> <answer> end_of_cd_record); 
limit = (int64_t)offset - (1 << <token> <answer> 16); 
for (; offset <token> 0 && offset > limit && rc != 0; offset--) { <answer> >= 
rc <token> try_parse_end_of_cd(archive, offset); <answer> = 
if <token> == -ENOTSUP) <answer> (rc 
return <token> <answer> rc; 
struct <token> *zip_archive_open(const char *path) <answer> zip_archive 
struct zip_archive <token> <answer> *archive; 
<token> err, fd; <answer> int 
<token> size; <answer> off_t 
void <token> <answer> *data; 
fd = open(path, O_RDONLY | <token> <answer> O_CLOEXEC); 
if <token> < 0) <answer> (fd 
return <token> <answer> ERR_PTR(-errno); 
size = lseek(fd, 0, <token> <answer> SEEK_END); 
if (size == (off_t)-1 || size > <token> { <answer> UINT32_MAX) 
<token> ERR_PTR(-EINVAL); <answer> return 
data = mmap(NULL, <token> PROT_READ, MAP_PRIVATE, fd, 0); <answer> size, 
err <token> -errno; <answer> = 
if <token> == MAP_FAILED) <answer> (data 
return <token> <answer> ERR_PTR(err); 
<token> = malloc(sizeof(*archive)); <answer> archive 
<token> (!archive) { <answer> if 
<token> size); <answer> munmap(data, 
return <token> <answer> ERR_PTR(-ENOMEM); 
archive->data = <token> <answer> data; 
archive->size <token> size; <answer> = 
err <token> find_cd(archive); <answer> = 
if (err) <token> <answer> { 
munmap(data, <token> <answer> size); 
<token> ERR_PTR(err); <answer> return 
return <token> <answer> archive; 
void zip_archive_close(struct <token> *archive) <answer> zip_archive 
munmap(archive->data, <token> <answer> archive->size); 
static struct local_file_header *local_file_header_at_offset(struct <token> *archive, <answer> zip_archive 
__u32 <token> <answer> offset) 
struct local_file_header <token> <answer> *lfh; 
<token> = check_access(archive, offset, sizeof(*lfh)); <answer> lfh 
if (!lfh || lfh->magic <token> LOCAL_FILE_HEADER_MAGIC) <answer> != 
return <token> <answer> NULL; 
return <token> <answer> lfh; 
<token> int get_entry_at_offset(struct zip_archive *archive, __u32 offset, struct zip_entry *out) <answer> static 
struct <token> *lfh; <answer> local_file_header 
__u32 <token> <answer> compressed_size; 
const <token> *name; <answer> char 
<token> *data; <answer> void 
<token> = local_file_header_at_offset(archive, offset); <answer> lfh 
<token> (!lfh) <answer> if 
return <token> <answer> -EINVAL; 
<token> += sizeof(*lfh); <answer> offset 
if <token> & FLAG_ENCRYPTED) || (lfh->flags & FLAG_HAS_DATA_DESCRIPTOR)) <answer> ((lfh->flags 
return <token> <answer> -EINVAL; 
name = check_access(archive, <token> lfh->file_name_length); <answer> offset, 
<token> (!name) <answer> if 
return <token> <answer> -EINVAL; 
offset += <token> <answer> lfh->file_name_length; 
if (!check_access(archive, <token> lfh->extra_field_length)) <answer> offset, 
<token> -EINVAL; <answer> return 
offset += <token> <answer> lfh->extra_field_length; 
compressed_size <token> lfh->compressed_size; <answer> = 
data = check_access(archive, <token> compressed_size); <answer> offset, 
if <token> <answer> (!data) 
return <token> <answer> -EINVAL; 
out->compression <token> lfh->compression; <answer> = 
out->name_length = <token> <answer> lfh->file_name_length; 
out->name = <token> <answer> name; 
out->data <token> data; <answer> = 
out->data_length <token> compressed_size; <answer> = 
out->data_offset = <token> <answer> offset; 
return <token> <answer> 0; 
int zip_archive_find_entry(struct zip_archive *archive, const <token> *file_name, <answer> char 
struct <token> *out) <answer> zip_entry 
size_t <token> = strlen(file_name); <answer> file_name_length 
__u32 i, offset = <token> <answer> archive->cd_offset; 
for (i = 0; <token> < archive->cd_records; ++i) { <answer> i 
<token> cdfh_name_length, cdfh_flags; <answer> __u16 
struct <token> *cdfh; <answer> cd_file_header 
const char <token> <answer> *cdfh_name; 
cdfh = check_access(archive, offset, <token> <answer> sizeof(*cdfh)); 
if (!cdfh || <token> != CD_FILE_HEADER_MAGIC) <answer> cdfh->magic 
<token> -EINVAL; <answer> return 
<token> += sizeof(*cdfh); <answer> offset 
<token> = cdfh->file_name_length; <answer> cdfh_name_length 
<token> = check_access(archive, offset, cdfh_name_length); <answer> cdfh_name 
if <token> <answer> (!cdfh_name) 
return <token> <answer> -EINVAL; 
cdfh_flags <token> cdfh->flags; <answer> = 
if ((cdfh_flags <token> FLAG_ENCRYPTED) == 0 && <answer> & 
(cdfh_flags & FLAG_HAS_DATA_DESCRIPTOR) <token> 0 && <answer> == 
file_name_length == <token> && <answer> cdfh_name_length 
memcmp(file_name, archive->data <token> offset, file_name_length) == 0) { <answer> + 
return get_entry_at_offset(archive, <token> out); <answer> cdfh->offset, 
<token> += cdfh_name_length; <answer> offset 
offset <token> cdfh->extra_field_length; <answer> += 
offset <token> cdfh->file_comment_length; <answer> += 
<token> -ENOENT; <answer> return 
#define pr_fmt(fmt) KBUILD_MODNAME <token> " fmt <answer> ": 
#define <token> "yellowfin" <answer> DRV_NAME 
#define <token> "2.1" <answer> DRV_VERSION 
<token> DRV_RELDATE "Sep 11, 2006" <answer> #define 
static int <token> <answer> rx_copybreak; 
#define <token> 16 <answer> TX_RING_SIZE 
<token> capability_flags { <answer> enum 
HasMII=1, FullTxStatus=2, <token> HasMulticastBug=8, FullRxStatus=16, <answer> IsGigabit=4, 
<token> yellowfin_desc { <answer> struct 
__le32 <token> <answer> dbdma_cmd; 
__le32 <token> <answer> addr; 
<token> branch_addr; <answer> __le32 
<token> result_status; <answer> __le32 
struct tx_status_words <token> <answer> { 
<token> __BIG_ENDIAN <answer> #ifdef 
u16 <token> <answer> tx_errs; 
<token> tx_cnt; <answer> u16 
<token> paused; <answer> u16 
u16 <token> <answer> total_tx_cnt; 
struct <token> *rx_ring; <answer> yellowfin_desc 
struct yellowfin_desc <token> <answer> *tx_ring; 
struct sk_buff* <token> <answer> rx_skbuff[RX_RING_SIZE]; 
<token> sk_buff* tx_skbuff[TX_RING_SIZE]; <answer> struct 
<token> rx_ring_dma; <answer> dma_addr_t 
<token> tx_ring_dma; <answer> dma_addr_t 
struct tx_status_words <token> <answer> *tx_status; 
dma_addr_t <token> <answer> tx_status_dma; 
static int <token> __iomem *ioaddr, int phy_id, int location) <answer> mdio_read(void 
int <token> <answer> i; 
iowrite16((phy_id<<8) <token> location, ioaddr + MII_Addr); <answer> + 
iowrite16(1, ioaddr <token> MII_Cmd); <answer> + 
for (i = <token> i >= 0; i--) <answer> 10000; 
if ((ioread16(ioaddr <token> MII_Status) & 1) == 0) <answer> + 
<token> ioread16(ioaddr + MII_Rd_Data); <answer> return 
static void <token> __iomem *ioaddr, int phy_id, int location, int value) <answer> mdio_write(void 
<token> i; <answer> int 
iowrite16((phy_id<<8) + <token> ioaddr + MII_Addr); <answer> location, 
<token> ioaddr + MII_Wr_Data); <answer> iowrite16(value, 
<token> ioaddr + DMACtrl); <answer> iowrite32(dma_ctrl, 
iowrite16(fifo_cfg, <token> + FIFOcfg); <answer> ioaddr 
dev->if_port <token> 0; <answer> = 
unsigned next_entry = yp->cur_tx <token> TX_RING_SIZE; <answer> % 
yp->tx_ring[next_entry<<1].dbdma_cmd <token> cpu_to_le32(CMD_STOP); <answer> = 
static irqreturn_t <token> irq, void *dev_instance) <answer> yellowfin_interrupt(int 
struct net_device *dev <token> dev_instance; <answer> = 
struct yellowfin_private <token> <answer> *yp; 
void <token> *ioaddr; <answer> __iomem 
int <token> = max_interrupt_work; <answer> boguscnt 
unsigned <token> handled = 0; <answer> int 
<token> = netdev_priv(dev); <answer> yp 
<token> = yp->base; <answer> ioaddr 
spin_lock <token> <answer> (&yp->lock); 
do <token> <answer> { 
u16 intr_status = ioread16(ioaddr <token> IntrClear); <answer> + 
if (yellowfin_debug <token> 4) <answer> > 
netdev_printk(KERN_DEBUG, dev, "Yellowfin <token> status %04x\n", <answer> interrupt, 
<token> (intr_status == 0) <answer> if 
<token> = 1; <answer> handled 
if (intr_status & (IntrRxDone | IntrEarlyRx)) <token> <answer> { 
<token> int yellowfin_rx(struct net_device *dev) <answer> static 
struct <token> *yp = netdev_priv(dev); <answer> yellowfin_private 
<token> entry = yp->cur_rx % RX_RING_SIZE; <answer> int 
int boguscnt = yp->dirty_rx + RX_RING_SIZE <token> yp->cur_rx; <answer> - 
if (yellowfin_debug <token> 4) { <answer> > 
<token> " In yellowfin_rx(), entry %d status %08x\n", <answer> printk(KERN_DEBUG 
<token> yp->rx_ring[entry].result_status); <answer> entry, 
<token> " #%d desc. %08x %08x %08x\n", <answer> printk(KERN_DEBUG 
entry, yp->rx_ring[entry].dbdma_cmd, <token> <answer> yp->rx_ring[entry].addr, 
if (pkt_len > <token> { <answer> rx_copybreak) 
<token> = rx_skb, pkt_len); <answer> skb_put(skb 
yp->rx_skbuff[entry] = <token> <answer> NULL; 
<token> else { <answer> } 
skb = <token> pkt_len + 2); <answer> netdev_alloc_skb(dev, 
<token> (skb == NULL) <answer> if 
if (yp->drv_flags & <token> { <answer> HasMulticastBug) 
bit = (ether_crc_le(3, ha->addr) >> 3) & <token> <answer> 0x3f; 
hash_table[bit >> <token> |= (1 << bit); <answer> 4] 
bit = (ether_crc_le(4, ha->addr) <token> 3) & 0x3f; <answer> >> 
hash_table[bit >> 4] <token> (1 << bit); <answer> |= 
bit = (ether_crc_le(5, ha->addr) >> 3) & <token> <answer> 0x3f; 
hash_table[bit >> 4] <token> (1 << bit); <answer> |= 
<token> = (ether_crc_le(6, ha->addr) >> 3) & 0x3f; <answer> bit 
hash_table[bit >> <token> |= (1 << bit); <answer> 4] 
<token> <linux/efi.h> <answer> #include 
#include <token> <answer> "../integrity.h" 
<token> __init int machine_keyring_init(void) <answer> static 
<token> rc; <answer> int 
rc = <token> <answer> integrity_init_keyring(INTEGRITY_KEYRING_MACHINE); 
if <token> <answer> (rc) 
return <token> <answer> rc; 
<token> keyring initialized\n"); <answer> pr_notice("Machine 
<token> 0; <answer> return 
void __init add_to_machine_keyring(const char *source, <token> void *data, size_t len) <answer> const 
key_perm_t <token> <answer> perm; 
<token> rc; <answer> int 
perm = (KEY_POS_ALL <token> ~KEY_POS_SETATTR) | KEY_USR_VIEW; <answer> & 
rc = integrity_load_cert(INTEGRITY_KEYRING_MACHINE, source, data, len, <token> <answer> perm); 
if (rc && <token> && <answer> efi_enabled(EFI_BOOT) 
rc <token> integrity_load_cert(INTEGRITY_KEYRING_PLATFORM, source, <answer> = 
data, <token> perm); <answer> len, 
if <token> <answer> (rc) 
<token> adding keys to machine keyring %s\n", source); <answer> pr_info("Error 
static __init <token> uefi_check_trust_mok_keys(void) <answer> bool 
struct efi_mokvar_table_entry <token> <answer> *mokvar_entry; 
mokvar_entry = <token> <answer> efi_mokvar_entry_find("MokListTrustedRT"); 
if <token> <answer> (mokvar_entry) 
<token> true; <answer> return 
<token> false; <answer> return 
static bool <token> trust_moklist(void) <answer> __init 
static bool <token> <answer> initialized; 
static bool <token> <answer> trust_mok; 
<token> (!initialized) { <answer> if 
initialized <token> true; <answer> = 
<token> = false; <answer> trust_mok 
<token> (uefi_check_trust_mok_keys()) <answer> if 
trust_mok <token> true; <answer> = 
<token> trust_mok; <answer> return 
bool <token> imputed_trust_enabled(void) <answer> __init 
if <token> <answer> (efi_enabled(EFI_BOOT)) 
return <token> <answer> trust_moklist(); 
<token> true; <answer> return 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/types.h> 
#include <token> <answer> <asm/dec/kn02.h> 
u32 <token> <answer> cached_kn02_csr; 
static <token> kn02_irq_base; <answer> int 
static void unmask_kn02_irq(struct <token> *d) <answer> irq_data 
volatile u32 *csr = <token> u32 *)CKSEG1ADDR(KN02_SLOT_BASE + <answer> (volatile 
cached_kn02_csr |= (1 << (d->irq - kn02_irq_base <token> 16)); <answer> + 
*csr <token> cached_kn02_csr; <answer> = 
static <token> mask_kn02_irq(struct irq_data *d) <answer> void 
volatile u32 *csr = (volatile <token> *)CKSEG1ADDR(KN02_SLOT_BASE + <answer> u32 
cached_kn02_csr <token> ~(1 << (d->irq - kn02_irq_base + 16)); <answer> &= 
*csr = <token> <answer> cached_kn02_csr; 
<token> void ack_kn02_irq(struct irq_data *d) <answer> static 
static <token> irq_chip kn02_irq_type = { <answer> struct 
.name <token> "KN02-CSR", <answer> = 
.irq_ack = <token> <answer> ack_kn02_irq, 
.irq_mask = <token> <answer> mask_kn02_irq, 
.irq_mask_ack <token> ack_kn02_irq, <answer> = 
<token> = unmask_kn02_irq, <answer> .irq_unmask 
<token> __init init_kn02_irqs(int base) <answer> void 
volatile u32 *csr = (volatile u32 *)CKSEG1ADDR(KN02_SLOT_BASE <token> <answer> + 
<token> i; <answer> int 
<token> <linux/ctype.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/libfdt.h> <answer> #include 
#include <token> <answer> <asm/cacheflush.h> 
#include <token> <answer> <asm/cpufeature.h> 
#include <token> <answer> <asm/setup.h> 
#include <token> <answer> "pi.h" 
<token> FTR_DESC_NAME_LEN 20 <answer> #define 
#define FTR_DESC_FIELD_LEN <token> <answer> 10 
#define FTR_ALIAS_NAME_LEN <token> <answer> 30 
<token> FTR_ALIAS_OPTION_LEN 116 <answer> #define 
static <token> __boot_status __initdata; <answer> u64 
<token> bool filter_t(u64 val); <answer> typedef 
<token> ftr_set_desc { <answer> struct 
char <token> <answer> name[FTR_DESC_NAME_LEN]; 
PREL64(struct <token> override); <answer> arm64_ftr_override, 
<token> { <answer> struct 
char <token> <answer> name[FTR_DESC_FIELD_LEN]; 
<token> shift; <answer> u8 
<token> width; <answer> u8 
PREL64(filter_t, <token> <answer> filter); 
} <token> <answer> fields[]; 
#define FIELD(n, s, f) { .name = n, .shift = s, .width = 4, .filter = <token> } <answer> f 
<token> bool __init mmfr1_vh_filter(u64 val) <answer> static 
return !(__boot_status == (BOOT_CPU_FLAG_E2H | BOOT_CPU_MODE_EL2) <token> <answer> && 
val == <token> <answer> 0); 
<token> const struct ftr_set_desc mmfr1 __prel64_initconst = { <answer> static 
.name <token> "id_aa64mmfr1", <answer> = 
.override = <token> <answer> &id_aa64mmfr1_override, 
.fields = <token> <answer> { 
FIELD("vh", <token> mmfr1_vh_filter), <answer> ID_AA64MMFR1_EL1_VH_SHIFT, 
static <token> __init mmfr2_varange_filter(u64 val) <answer> bool 
int <token> feat; <answer> __maybe_unused 
<token> (val) <answer> if 
return <token> <answer> false; 
#ifdef <token> <answer> CONFIG_ARM64_LPA2 
feat <token> cpuid_feature_extract_signed_field(read_sysreg(id_aa64mmfr0_el1), <answer> = 
<token> (feat >= ID_AA64MMFR0_EL1_TGRAN_LPA2) { <answer> if 
id_aa64mmfr0_override.val <token> <answer> |= 
<token> - 1) << ID_AA64MMFR0_EL1_TGRAN_SHIFT; <answer> (ID_AA64MMFR0_EL1_TGRAN_LPA2 
id_aa64mmfr0_override.mask |= <token> << ID_AA64MMFR0_EL1_TGRAN_SHIFT; <answer> 0xfU 
<token> true; <answer> return 
<token> const struct ftr_set_desc mmfr2 __prel64_initconst = { <answer> static 
<token> = "id_aa64mmfr2", <answer> .name 
<token> = &id_aa64mmfr2_override, <answer> .override 
.fields <token> { <answer> = 
FIELD("varange", <token> mmfr2_varange_filter), <answer> ID_AA64MMFR2_EL1_VARange_SHIFT, 
static bool __init pfr0_sve_filter(u64 <token> <answer> val) 
if (!val) <token> <answer> { 
id_aa64zfr0_override.val = <token> <answer> 0; 
id_aa64zfr0_override.mask = GENMASK(63, <token> <answer> 0); 
return <token> <answer> true; 
<token> const struct ftr_set_desc pfr0 __prel64_initconst = { <answer> static 
<token> = "id_aa64pfr0", <answer> .name 
.override = <token> <answer> &id_aa64pfr0_override, 
.fields <token> { <answer> = 
<token> ID_AA64PFR0_EL1_SVE_SHIFT, pfr0_sve_filter), <answer> FIELD("sve", 
<token> bool __init pfr1_sme_filter(u64 val) <answer> static 
if (!val) <token> <answer> { 
id_aa64smfr0_override.val = <token> <answer> 0; 
id_aa64smfr0_override.mask = GENMASK(63, <token> <answer> 0); 
<token> true; <answer> return 
static <token> struct ftr_set_desc pfr1 __prel64_initconst = { <answer> const 
<token> = "id_aa64pfr1", <answer> .name 
.override <token> &id_aa64pfr1_override, <answer> = 
.fields = <token> <answer> { 
<token> ID_AA64PFR1_EL1_BT_SHIFT, NULL ), <answer> FIELD("bt", 
FIELD("mte", <token> NULL), <answer> ID_AA64PFR1_EL1_MTE_SHIFT, 
FIELD("sme", <token> pfr1_sme_filter), <answer> ID_AA64PFR1_EL1_SME_SHIFT, 
static const <token> ftr_set_desc isar1 __prel64_initconst = { <answer> struct 
.name = <token> <answer> "id_aa64isar1", 
.override = <token> <answer> &id_aa64isar1_override, 
<token> = { <answer> .fields 
FIELD("gpi", ID_AA64ISAR1_EL1_GPI_SHIFT, <token> <answer> NULL), 
<token> ID_AA64ISAR1_EL1_GPA_SHIFT, NULL), <answer> FIELD("gpa", 
FIELD("api", ID_AA64ISAR1_EL1_API_SHIFT, <token> <answer> NULL), 
<token> ID_AA64ISAR1_EL1_APA_SHIFT, NULL), <answer> FIELD("apa", 
<token> const struct ftr_set_desc isar2 __prel64_initconst = { <answer> static 
<token> = "id_aa64isar2", <answer> .name 
.override = <token> <answer> &id_aa64isar2_override, 
.fields = <token> <answer> { 
FIELD("gpa3", ID_AA64ISAR2_EL1_GPA3_SHIFT, <token> <answer> NULL), 
<token> ID_AA64ISAR2_EL1_APA3_SHIFT, NULL), <answer> FIELD("apa3", 
FIELD("mops", <token> NULL), <answer> ID_AA64ISAR2_EL1_MOPS_SHIFT, 
static <token> struct ftr_set_desc smfr0 __prel64_initconst = { <answer> const 
.name = <token> <answer> "id_aa64smfr0", 
<token> = &id_aa64smfr0_override, <answer> .override 
.fields = <token> <answer> { 
<token> ID_AA64SMFR0_EL1_SMEver_SHIFT, NULL), <answer> FIELD("smever", 
filter <token> prel64_pointer(reg->fields[f].filter); <answer> = 
if <token> && !filter(v)) { <answer> (filter 
override->val |= <token> <answer> mask; 
override->mask <token> ~mask; <answer> &= 
override->val <token> ~mask; <answer> &= 
override->val |= <token> << shift) & mask; <answer> (v 
override->mask |= <token> <answer> mask; 
static __init void __parse_cmdline(const char *cmdline, bool <token> <answer> parse_aliases) 
do <token> <answer> { 
<token> buf[256]; <answer> char 
<token> len; <answer> size_t 
int <token> <answer> i; 
<token> = skip_spaces(cmdline); <answer> cmdline 
<token> DEBUG <answer> #undef 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/of_address.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
<token> <asm/ppc-pci.h> <answer> #include 
<token> <asm/pci-bridge.h> <answer> #include 
<token> <asm/io-workarounds.h> <answer> #include 
#define <token> <answer> SPIDER_PCI_DISABLE_PREFETCH 
struct <token> { <answer> spiderpci_iowa_private 
void <token> *regs; <answer> __iomem 
static <token> spiderpci_io_flush(struct iowa_bus *bus) <answer> void 
struct <token> *priv; <answer> spiderpci_iowa_private 
priv = <token> <answer> bus->private; 
in_be32(priv->regs + <token> <answer> SPIDER_PCI_DUMMY_READ); 
<token> SPIDER_PCI_MMIO_READ(name, ret) \ <answer> #define 
static ret spiderpci_##name(const PCI_IO_ADDR addr) <token> <answer> \ 
{ <token> <answer> \ 
ret val = __do_##name(addr); <token> <answer> \ 
spiderpci_io_flush(iowa_mem_find_bus(addr)); <token> <answer> \ 
return val; <token> <answer> \ 
#define <token> \ <answer> SPIDER_PCI_MMIO_READ_STR(name) 
static void spiderpci_##name(const PCI_IO_ADDR <token> void *buf, \ <answer> addr, 
unsigned <token> count) \ <answer> long 
<token> \ <answer> { 
__do_##name(addr, buf, <token> \ <answer> count); 
<token> \ <answer> spiderpci_io_flush(iowa_mem_find_bus(addr)); 
<token> u8) <answer> SPIDER_PCI_MMIO_READ(readb, 
<token> u16) <answer> SPIDER_PCI_MMIO_READ(readw, 
<token> u32) <answer> SPIDER_PCI_MMIO_READ(readl, 
<token> u64) <answer> SPIDER_PCI_MMIO_READ(readq, 
SPIDER_PCI_MMIO_READ(readw_be, <token> <answer> u16) 
<token> u32) <answer> SPIDER_PCI_MMIO_READ(readl_be, 
<token> u64) <answer> SPIDER_PCI_MMIO_READ(readq_be, 
static void spiderpci_memcpy_fromio(void *dest, const PCI_IO_ADDR <token> <answer> src, 
unsigned <token> n) <answer> long 
__do_memcpy_fromio(dest, <token> n); <answer> src, 
<token> int __init spiderpci_pci_setup_chip(struct pci_controller *phb, <answer> static 
<token> __iomem *regs) <answer> void 
<token> *dummy_page_va; <answer> void 
dma_addr_t <token> <answer> dummy_page_da; 
#ifdef <token> <answer> SPIDER_PCI_DISABLE_PREFETCH 
u32 <token> = in_be32(regs + SPIDER_PCI_VCI_CNTL_STAT); <answer> val 
pr_debug("SPIDER_IOWA:PVCI_Control_Status was 0x%08x\n", <token> <answer> val); 
<token> + SPIDER_PCI_VCI_CNTL_STAT, val | 0x8); <answer> out_be32(regs 
dummy_page_va <token> kmalloc(PAGE_SIZE, GFP_KERNEL); <answer> = 
if (!dummy_page_va) <token> <answer> { 
<token> dummy_page_va failed.\n"); <answer> pr_err("SPIDERPCI-IOWA:Alloc 
<token> -1; <answer> return 
dummy_page_da <token> dma_map_single(phb->parent, dummy_page_va, <answer> = 
PAGE_SIZE, <token> <answer> DMA_FROM_DEVICE); 
if <token> dummy_page_da)) { <answer> (dma_mapping_error(phb->parent, 
pr_err("SPIDER-IOWA:Map dummy <token> filed.\n"); <answer> page 
return <token> <answer> -1; 
out_be32(regs + <token> dummy_page_da); <answer> SPIDER_PCI_DUMMY_READ_BASE, 
return <token> <answer> 0; 
int __init <token> iowa_bus *bus, void *data) <answer> spiderpci_iowa_init(struct 
void __iomem *regs <token> NULL; <answer> = 
struct <token> *priv; <answer> spiderpci_iowa_private 
struct device_node <token> = bus->phb->dn; <answer> *np 
<token> resource r; <answer> struct 
unsigned long <token> = (unsigned long)data; <answer> offset 
<token> initialize for spider(%pOF)\n", <answer> pr_debug("SPIDERPCI-IOWA:Bus 
<token> = kzalloc(sizeof(*priv), GFP_KERNEL); <answer> priv 
if <token> { <answer> (!priv) 
"Can't allocate <token> spiderpci_iowa_private"); <answer> struct 
return <token> <answer> -1; 
if (of_address_to_resource(np, 0, <token> { <answer> &r)) 
pr_err("SPIDERPCI-IOWA:Can't get <token> <answer> resource.\n"); 
<token> error; <answer> goto 
regs <token> ioremap(r.start + offset, SPIDER_PCI_REG_SIZE); <answer> = 
if (!regs) <token> <answer> { 
<token> failed.\n"); <answer> pr_err("SPIDERPCI-IOWA:ioremap 
<token> error; <answer> goto 
priv->regs = <token> <answer> regs; 
bus->private <token> priv; <answer> = 
if <token> regs)) <answer> (spiderpci_pci_setup_chip(bus->phb, 
goto <token> <answer> error; 
<token> 0; <answer> return 
<token> = NULL; <answer> bus->private 
if <token> <answer> (regs) 
<token> -1; <answer> return 
<token> ppc_pci_io spiderpci_ops = { <answer> struct 
.readb <token> spiderpci_readb, <answer> = 
.readw = <token> <answer> spiderpci_readw, 
<token> = spiderpci_readl, <answer> .readl 
<token> = spiderpci_readq, <answer> .readq 
.readw_be = <token> <answer> spiderpci_readw_be, 
<token> = spiderpci_readl_be, <answer> .readl_be 
.readq_be = <token> <answer> spiderpci_readq_be, 
.readsb <token> spiderpci_readsb, <answer> = 
.readsw = <token> <answer> spiderpci_readsw, 
.readsl = <token> <answer> spiderpci_readsl, 
<token> = spiderpci_memcpy_fromio, <answer> .memcpy_fromio 
#include <token> <answer> <linux/component.h> 
<token> <linux/dma-mapping.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_platform.h> 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <drm/drm_atomic.h> 
<token> <drm/drm_atomic_helper.h> <answer> #include 
#include <token> <answer> <drm/drm_debugfs.h> 
#include <token> <answer> <drm/drm_drv.h> 
<token> <drm/drm_fbdev_dma.h> <answer> #include 
#include <token> <answer> <drm/drm_gem_dma_helper.h> 
<token> <drm/drm_gem_framebuffer_helper.h> <answer> #include 
<token> <drm/drm_of.h> <answer> #include 
<token> <drm/drm_probe_helper.h> <answer> #include 
<token> "sti_drv.h" <answer> #include 
#include <token> <answer> "sti_plane.h" 
#define <token> "sti" <answer> DRIVER_NAME 
#define DRIVER_DESC "STMicroelectronics <token> DRM" <answer> SoC 
#define DRIVER_DATE <token> <answer> "20140601" 
#define DRIVER_MAJOR <token> <answer> 1 
<token> DRIVER_MINOR 0 <answer> #define 
<token> STI_MAX_FB_HEIGHT 4096 <answer> #define 
<token> STI_MAX_FB_WIDTH 4096 <answer> #define 
static int sti_drm_fps_get(void *data, <token> *val) <answer> u64 
struct drm_device *drm_dev <token> data; <answer> = 
struct drm_plane <token> <answer> *p; 
unsigned int i = <token> <answer> 0; 
<token> = 0; <answer> *val 
<token> &drm_dev->mode_config.plane_list, head) { <answer> list_for_each_entry(p, 
<token> sti_plane *plane = to_sti_plane(p); <answer> struct 
*val |= <token> << i; <answer> plane->fps_info.output 
<token> 0; <answer> return 
static int sti_drm_fps_set(void *data, u64 <token> <answer> val) 
<token> drm_device *drm_dev = data; <answer> struct 
<token> drm_plane *p; <answer> struct 
unsigned int <token> = 0; <answer> i 
<token> &drm_dev->mode_config.plane_list, head) { <answer> list_for_each_entry(p, 
struct sti_plane <token> = to_sti_plane(p); <answer> *plane 
<token> 0, sizeof(plane->fps_info)); <answer> memset(&plane->fps_info, 
plane->fps_info.output = (val >> i) <token> 1; <answer> & 
<token> 0; <answer> return 
sti_drm_fps_get, <token> "%llu\n"); <answer> sti_drm_fps_set, 
static int sti_drm_fps_dbg_show(struct seq_file *s, void <token> <answer> *data) 
<token> drm_info_node *node = s->private; <answer> struct 
struct drm_device <token> = node->minor->dev; <answer> *dev 
struct <token> *p; <answer> drm_plane 
<token> &dev->mode_config.plane_list, head) { <answer> list_for_each_entry(p, 
struct sti_plane <token> = to_sti_plane(p); <answer> *plane 
seq_printf(s, <token> <answer> "%s%s\n", 
return <token> <answer> 0; 
static struct drm_info_list <token> = { <answer> sti_drm_dbg_list[] 
{"fps_get", sti_drm_fps_dbg_show, <token> <answer> 0}, 
static void sti_drm_dbg_init(struct <token> *minor) <answer> drm_minor 
minor->debugfs_root, <token> <answer> minor); 
debugfs_create_file("fps_show", <token> | S_IWUSR, minor->debugfs_root, <answer> S_IRUGO 
<token> &sti_drm_fps_fops); <answer> minor->dev, 
DRM_INFO("%s: <token> installed\n", DRIVER_NAME); <answer> debugfs 
static const struct drm_mode_config_funcs sti_mode_config_funcs = <token> <answer> { 
<token> = drm_gem_fb_create, <answer> .fb_create 
<token> = drm_atomic_helper_check, <answer> .atomic_check 
.atomic_commit <token> drm_atomic_helper_commit, <answer> = 
static void sti_mode_config_init(struct <token> *dev) <answer> drm_device 
<token> = 0; <answer> dev->mode_config.min_width 
dev->mode_config.min_height = <token> <answer> 0; 
dev->mode_config.max_width <token> STI_MAX_FB_WIDTH; <answer> = 
<token> = STI_MAX_FB_HEIGHT; <answer> dev->mode_config.max_height 
dev->mode_config.funcs = <token> <answer> &sti_mode_config_funcs; 
<token> = true; <answer> dev->mode_config.normalize_zpos 
static const <token> drm_driver sti_driver = { <answer> struct 
<token> = DRIVER_MODESET | DRIVER_GEM | DRIVER_ATOMIC, <answer> .driver_features 
.fops = <token> <answer> &sti_driver_fops, 
<token> = sti_drm_dbg_init, <answer> .debugfs_init 
.name = <token> <answer> DRIVER_NAME, 
.desc <token> DRIVER_DESC, <answer> = 
.date <token> DRIVER_DATE, <answer> = 
<token> = DRIVER_MAJOR, <answer> .major 
.minor = <token> <answer> DRIVER_MINOR, 
<token> int sti_init(struct drm_device *ddev) <answer> static 
<token> sti_private *private; <answer> struct 
private <token> kzalloc(sizeof(*private), GFP_KERNEL); <answer> = 
<token> (!private) <answer> if 
<token> -ENOMEM; <answer> return 
<token> = (void *)private; <answer> ddev->dev_private 
<token> ddev); <answer> dev_set_drvdata(ddev->dev, 
private->drm_dev <token> ddev; <answer> = 
return <token> <answer> 0; 
static void <token> drm_device *ddev) <answer> sti_cleanup(struct 
struct sti_private *private = <token> <answer> ddev->dev_private; 
<token> ddev); <answer> component_unbind_all(ddev->dev, 
<token> NULL); <answer> dev_set_drvdata(ddev->dev, 
ddev->dev_private <token> NULL; <answer> = 
static int sti_bind(struct device <token> <answer> *dev) 
struct drm_device <token> <answer> *ddev; 
<token> ret; <answer> int 
ddev = drm_dev_alloc(&sti_driver, <token> <answer> dev); 
<token> (IS_ERR(ddev)) <answer> if 
<token> PTR_ERR(ddev); <answer> return 
ret <token> sti_init(ddev); <answer> = 
if <token> <answer> (ret) 
goto <token> <answer> err_drm_dev_put; 
ret = component_bind_all(ddev->dev, <token> <answer> ddev); 
<token> (ret) <answer> if 
<token> err_cleanup; <answer> goto 
<token> = drm_dev_register(ddev, 0); <answer> ret 
<token> (ret) <answer> if 
goto <token> <answer> err_cleanup; 
<token> 32); <answer> drm_fbdev_dma_setup(ddev, 
<token> 0; <answer> return 
<token> ret; <answer> return 
static <token> sti_unbind(struct device *dev) <answer> void 
struct drm_device *ddev <token> dev_get_drvdata(dev); <answer> = 
static const struct component_master_ops sti_ops <token> { <answer> = 
.bind = <token> <answer> sti_bind, 
.unbind = <token> <answer> sti_unbind, 
static int <token> platform_device *pdev) <answer> sti_platform_probe(struct 
<token> device *dev = &pdev->dev; <answer> struct 
<token> device_node *node = dev->of_node; <answer> struct 
struct <token> *child_np; <answer> device_node 
struct <token> *match = NULL; <answer> component_match 
<token> DMA_BIT_MASK(32)); <answer> dma_set_coherent_mask(dev, 
child_np = of_get_next_available_child(node, <token> <answer> NULL); 
while (child_np) <token> <answer> { 
drm_of_component_match_add(dev, &match, <token> <answer> component_compare_of, 
child_np <token> of_get_next_available_child(node, child_np); <answer> = 
return <token> &sti_ops, match); <answer> component_master_add_with_match(dev, 
static void sti_platform_remove(struct <token> *pdev) <answer> platform_device 
component_master_del(&pdev->dev, <token> <answer> &sti_ops); 
static void <token> platform_device *pdev) <answer> sti_platform_shutdown(struct 
static const <token> of_device_id sti_dt_ids[] = { <answer> struct 
<token> .compatible = "st,sti-display-subsystem", }, <answer> { 
#include <token> <answer> <linux/module.h> 
<token> "mt76.h" <answer> #include 
bool __mt76_poll(struct <token> *dev, u32 offset, u32 mask, u32 val, <answer> mt76_dev 
int <token> <answer> timeout) 
<token> cur; <answer> u32 
timeout <token> 10; <answer> /= 
<token> { <answer> do 
cur = __mt76_rr(dev, offset) & <token> <answer> mask; 
if <token> == val) <answer> (cur 
return <token> <answer> true; 
} while (timeout-- > <token> <answer> 0); 
return <token> <answer> false; 
<token> ____mt76_poll_msec(struct mt76_dev *dev, u32 offset, u32 mask, u32 val, <answer> bool 
<token> timeout, int tick) <answer> int 
u32 <token> <answer> cur; 
<token> /= tick; <answer> timeout 
<token> { <answer> do 
<token> = __mt76_rr(dev, offset) & mask; <answer> cur 
if (cur == <token> <answer> val) 
return <token> <answer> true; 
<token> * tick, 2000 * tick); <answer> usleep_range(1000 
} while <token> > 0); <answer> (timeout-- 
<token> false; <answer> return 
int <token> *mask, int size) <answer> mt76_wcid_alloc(u32 
int i, <token> = 0, cur; <answer> idx 
for (i = 0; i < DIV_ROUND_UP(size, <token> i++) { <answer> 32); 
idx = <token> <answer> ffs(~mask[i]); 
if <token> <answer> (!idx) 
cur = <token> * 32 + idx; <answer> i 
if <token> >= size) <answer> (cur 
mask[i] <token> BIT(idx); <answer> |= 
return <token> <answer> cur; 
return <token> <answer> -1; 
int mt76_get_min_avg_rssi(struct mt76_dev <token> bool ext_phy) <answer> *dev, 
struct <token> *wcid; <answer> mt76_wcid 
int i, j, min_rssi = <token> <answer> 0; 
s8 <token> <answer> cur_rssi; 
for (i = 0; i <token> ARRAY_SIZE(dev->wcid_mask); i++) { <answer> < 
u32 mask <token> dev->wcid_mask[i]; <answer> = 
u32 phy_mask <token> dev->wcid_phy_mask[i]; <answer> = 
if <token> <answer> (!mask) 
for (j = i * 32; mask; <token> mask >>= 1, phy_mask >>= 1) { <answer> j++, 
if <token> & 1)) <answer> (!(mask 
if (!!(phy_mask & 1) <token> ext_phy) <answer> != 
wcid <token> rcu_dereference(dev->wcid[j]); <answer> = 
<token> (!wcid) <answer> if 
if (wcid->inactive_count++ < <token> <answer> 5) 
cur_rssi = <token> <answer> -ewma_signal_read(&wcid->rssi); 
cur_rssi = <token> <answer> 0; 
if (cur_rssi <token> min_rssi) <answer> < 
<token> = cur_rssi; <answer> min_rssi 
return <token> <answer> min_rssi; 
<token> __mt76_worker_fn(void *ptr) <answer> int 
struct mt76_worker *w <token> ptr; <answer> = 
while <token> { <answer> (!kthread_should_stop()) 
if <token> { <answer> (kthread_should_park()) 
<token> (!test_and_clear_bit(MT76_WORKER_SCHEDULED, &w->state)) { <answer> if 
set_bit(MT76_WORKER_RUNNING, <token> <answer> &w->state); 
clear_bit(MT76_WORKER_RUNNING, <token> <answer> &w->state); 
<token> 0; <answer> return 
<token> MT76x helpers"); <answer> MODULE_DESCRIPTION("MediaTek 
<token> BSD/GPL"); <answer> MODULE_LICENSE("Dual 
<token> "ieee754dp.h" <answer> #include 
<token> ieee754dp ieee754dp_neg(union ieee754dp x) <answer> union 
union ieee754dp <token> <answer> y; 
if (ieee754_csr.abs2008) <token> <answer> { 
y = <token> <answer> x; 
<token> = !DPSIGN(x); <answer> DPSIGN(y) 
} <token> { <answer> else 
unsigned int <token> <answer> oldrm; 
oldrm = <token> <answer> ieee754_csr.rm; 
ieee754_csr.rm <token> FPU_CSR_RD; <answer> = 
<token> = ieee754dp_sub(ieee754dp_zero(0), x); <answer> y 
ieee754_csr.rm = <token> <answer> oldrm; 
<token> y; <answer> return 
<token> ieee754dp ieee754dp_abs(union ieee754dp x) <answer> union 
<token> ieee754dp y; <answer> union 
<token> (ieee754_csr.abs2008) { <answer> if 
y = <token> <answer> x; 
DPSIGN(y) <token> 0; <answer> = 
<token> else { <answer> } 
<token> int oldrm; <answer> unsigned 
oldrm = <token> <answer> ieee754_csr.rm; 
ieee754_csr.rm = <token> <answer> FPU_CSR_RD; 
if <token> <answer> (DPSIGN(x)) 
y = <token> x); <answer> ieee754dp_sub(ieee754dp_zero(0), 
y <token> ieee754dp_add(ieee754dp_zero(0), x); <answer> = 
<token> = oldrm; <answer> ieee754_csr.rm 
<token> y; <answer> return 
<token> <kunit/test.h> <answer> #include 
<token> <sound/core.h> <answer> #include 
#include <token> <answer> <sound/pcm.h> 
#define SILENCE_BUFFER_MAX_FRAMES <token> <answer> 260 
#define SILENCE_BUFFER_SIZE (sizeof(u64) * <token> <answer> SILENCE_BUFFER_MAX_FRAMES) 
#define SILENCE(...) { __VA_ARGS__ <token> <answer> } 
#define DEFINE_FORMAT(fmt, pbits, wd, endianness, signd, silence_arr) { <token> <answer> \ 
.format = SNDRV_PCM_FORMAT_##fmt, .physical_bits = pbits, <token> <answer> \ 
.width = wd, .le = <token> .sd = signd, .silence = silence_arr, \ <answer> endianness, 
.name <token> #fmt, \ <answer> = 
#define WRONG_FORMAT_1 (__force snd_pcm_format_t)((__force <token> + 1) <answer> int)SNDRV_PCM_FORMAT_LAST 
#define WRONG_FORMAT_2 <token> snd_pcm_format_t)-1 <answer> (__force 
#define VALID_NAME <token> <answer> "ValidName" 
<token> NAME_W_SPEC_CHARS "In%v@1id name" <answer> #define 
#define <token> "Test name" <answer> NAME_W_SPACE 
#define NAME_W_SPACE_REMOVED <token> <answer> "Testname" 
<token> TEST_FIRST_COMPONENT "Component1" <answer> #define 
#define <token> "Component2" <answer> TEST_SECOND_COMPONENT 
<token> snd_format_test_data { <answer> struct 
snd_pcm_format_t <token> <answer> format; 
int <token> <answer> physical_bits; 
int <token> <answer> width; 
<token> le; <answer> int 
int <token> <answer> sd; 
unsigned char <token> <answer> silence[8]; 
unsigned <token> *name; <answer> char 
struct <token> { <answer> avail_test_data 
snd_pcm_uframes_t <token> <answer> buffer_size; 
snd_pcm_uframes_t <token> <answer> hw_ptr; 
snd_pcm_uframes_t <token> <answer> appl_ptr; 
<token> expected_avail; <answer> snd_pcm_uframes_t 
<token> struct snd_format_test_data valid_fmt[] = { <answer> static 
DEFINE_FORMAT(S8, 8, <token> -1, 1, SILENCE()), <answer> 8, 
DEFINE_FORMAT(U8, 8, 8, <token> 0, SILENCE(0x80)), <answer> -1, 
DEFINE_FORMAT(S16_LE, 16, 16, 1, 1, <token> <answer> SILENCE()), 
DEFINE_FORMAT(S16_BE, 16, 16, <token> 1, SILENCE()), <answer> 0, 
DEFINE_FORMAT(U16_LE, 16, 16, 1, <token> SILENCE(0x00, 0x80)), <answer> 0, 
DEFINE_FORMAT(U16_BE, <token> 16, 0, 0, SILENCE(0x80, 0x00)), <answer> 16, 
DEFINE_FORMAT(S24_LE, <token> 24, 1, 1, SILENCE()), <answer> 32, 
DEFINE_FORMAT(S24_BE, 32, <token> 0, 1, SILENCE()), <answer> 24, 
DEFINE_FORMAT(U24_LE, 32, 24, 1, 0, SILENCE(0x00, <token> 0x80)), <answer> 0x00, 
DEFINE_FORMAT(U24_BE, 32, 24, 0, <token> SILENCE(0x00, 0x80, 0x00, 0x00)), <answer> 0, 
DEFINE_FORMAT(S32_LE, 32, <token> 1, 1, SILENCE()), <answer> 32, 
DEFINE_FORMAT(S32_BE, 32, <token> 0, 1, SILENCE()), <answer> 32, 
DEFINE_FORMAT(U32_LE, 32, 32, 1, 0, SILENCE(0x00, 0x00, <token> 0x80)), <answer> 0x00, 
DEFINE_FORMAT(U32_BE, 32, 32, 0, 0, SILENCE(0x80, 0x00, 0x00, <token> <answer> 0x00)), 
DEFINE_FORMAT(FLOAT_LE, 32, 32, 1, <token> SILENCE()), <answer> -1, 
DEFINE_FORMAT(FLOAT_BE, 32, 32, 0, <token> SILENCE()), <answer> -1, 
DEFINE_FORMAT(FLOAT64_LE, <token> 64, 1, -1, SILENCE()), <answer> 64, 
DEFINE_FORMAT(FLOAT64_BE, 64, <token> 0, -1, SILENCE()), <answer> 64, 
DEFINE_FORMAT(IEC958_SUBFRAME_LE, 32, <token> 1, -1, SILENCE()), <answer> 32, 
DEFINE_FORMAT(IEC958_SUBFRAME_BE, 32, 32, 0, -1, <token> <answer> SILENCE()), 
DEFINE_FORMAT(MU_LAW, <token> 8, -1, -1, SILENCE(0x7f)), <answer> 8, 
DEFINE_FORMAT(A_LAW, 8, <token> -1, -1, SILENCE(0x55)), <answer> 8, 
DEFINE_FORMAT(IMA_ADPCM, <token> 4, -1, -1, SILENCE()), <answer> 4, 
DEFINE_FORMAT(G723_24, 3, 3, <token> -1, SILENCE()), <answer> -1, 
DEFINE_FORMAT(G723_40, 5, 5, -1, <token> SILENCE()), <answer> -1, 
DEFINE_FORMAT(DSD_U8, <token> 8, 1, 0, SILENCE(0x69)), <answer> 8, 
<token> 16, 16, 1, 0, SILENCE(0x69, 0x69)), <answer> DEFINE_FORMAT(DSD_U16_LE, 
DEFINE_FORMAT(DSD_U32_LE, 32, 32, 1, 0, SILENCE(0x69, 0x69, <token> 0x69)), <answer> 0x69, 
DEFINE_FORMAT(DSD_U16_BE, <token> 16, 0, 0, SILENCE(0x69, 0x69)), <answer> 16, 
DEFINE_FORMAT(DSD_U32_BE, 32, 32, 0, 0, SILENCE(0x69, <token> 0x69, 0x69)), <answer> 0x69, 
DEFINE_FORMAT(S20_LE, 32, 20, <token> 1, SILENCE()), <answer> 1, 
DEFINE_FORMAT(S20_BE, 32, 20, 0, 1, <token> <answer> SILENCE()), 
DEFINE_FORMAT(U20_LE, 32, 20, 1, 0, <token> 0x00, 0x08, 0x00)), <answer> SILENCE(0x00, 
<token> 32, 20, 0, 0, SILENCE(0x00, 0x08, 0x00, 0x00)), <answer> DEFINE_FORMAT(U20_BE, 
<token> 24, 24, 1, 1, SILENCE()), <answer> DEFINE_FORMAT(S24_3LE, 
<token> 24, 24, 0, 1, SILENCE()), <answer> DEFINE_FORMAT(S24_3BE, 
DEFINE_FORMAT(U24_3LE, 24, 24, 1, 0, SILENCE(0x00, <token> 0x80)), <answer> 0x00, 
<token> 24, 24, 0, 0, SILENCE(0x80, 0x00, 0x00)), <answer> DEFINE_FORMAT(U24_3BE, 
DEFINE_FORMAT(S20_3LE, 24, 20, 1, 1, <token> <answer> SILENCE()), 
DEFINE_FORMAT(S20_3BE, 24, 20, 0, 1, <token> <answer> SILENCE()), 
DEFINE_FORMAT(U20_3LE, 24, 20, 1, 0, SILENCE(0x00, <token> 0x08)), <answer> 0x00, 
DEFINE_FORMAT(U20_3BE, 24, 20, 0, 0, SILENCE(0x08, <token> 0x00)), <answer> 0x00, 
DEFINE_FORMAT(S18_3LE, 24, <token> 1, 1, SILENCE()), <answer> 18, 
DEFINE_FORMAT(S18_3BE, 24, 18, 0, 1, <token> <answer> SILENCE()), 
DEFINE_FORMAT(U18_3LE, 24, <token> 1, 0, SILENCE(0x00, 0x00, 0x02)), <answer> 18, 
DEFINE_FORMAT(U18_3BE, 24, <token> 0, 0, SILENCE(0x02, 0x00, 0x00)), <answer> 18, 
DEFINE_FORMAT(G723_24_1B, <token> 3, -1, -1, SILENCE()), <answer> 8, 
DEFINE_FORMAT(G723_40_1B, 8, 5, <token> -1, SILENCE()), <answer> -1, 
static void <token> kunit *test) <answer> test_phys_format_size(struct 
<token> i; <answer> u32 
for (i = 0; <token> < ARRAY_SIZE(valid_fmt); i++) { <answer> i 
KUNIT_EXPECT_EQ(test, <token> <answer> snd_pcm_format_physical_width(valid_fmt[i].format), 
<token> snd_pcm_format_physical_width(WRONG_FORMAT_1), -EINVAL); <answer> KUNIT_EXPECT_EQ(test, 
<token> snd_pcm_format_physical_width(WRONG_FORMAT_2), -EINVAL); <answer> KUNIT_EXPECT_EQ(test, 
static void test_format_width(struct kunit <token> <answer> *test) 
<token> i; <answer> u32 
for (i = 0; <token> < ARRAY_SIZE(valid_fmt); i++) { <answer> i 
KUNIT_EXPECT_EQ(test, <token> <answer> snd_pcm_format_width(valid_fmt[i].format), 
KUNIT_EXPECT_EQ(test, <token> -EINVAL); <answer> snd_pcm_format_width(WRONG_FORMAT_1), 
KUNIT_EXPECT_EQ(test, snd_pcm_format_width(WRONG_FORMAT_2), <token> <answer> -EINVAL); 
static <token> test_format_signed(struct kunit *test) <answer> void 
u32 <token> <answer> i; 
for (i = <token> i < ARRAY_SIZE(valid_fmt); i++) { <answer> 0; 
<token> snd_pcm_format_signed(valid_fmt[i].format), <answer> KUNIT_EXPECT_EQ(test, 
valid_fmt[i].sd < 0 ? -EINVAL : <token> <answer> valid_fmt[i].sd); 
KUNIT_EXPECT_EQ(test, <token> <answer> snd_pcm_format_unsigned(valid_fmt[i].format), 
valid_fmt[i].sd < 0 ? -EINVAL : 1 - <token> <answer> valid_fmt[i].sd); 
KUNIT_EXPECT_EQ(test, snd_pcm_format_width(WRONG_FORMAT_1), <token> <answer> -EINVAL); 
KUNIT_EXPECT_EQ(test, <token> -EINVAL); <answer> snd_pcm_format_width(WRONG_FORMAT_2), 
static <token> test_format_endianness(struct kunit *test) <answer> void 
u32 <token> <answer> i; 
<token> (i = 0; i < ARRAY_SIZE(valid_fmt); i++) { <answer> for 
<token> snd_pcm_format_little_endian(valid_fmt[i].format), <answer> KUNIT_EXPECT_EQ(test, 
valid_fmt[i].le <token> 0 ? -EINVAL : valid_fmt[i].le); <answer> < 
KUNIT_EXPECT_EQ(test, <token> <answer> snd_pcm_format_big_endian(valid_fmt[i].format), 
valid_fmt[i].le < 0 ? -EINVAL : <token> - valid_fmt[i].le); <answer> 1 
<token> snd_pcm_format_little_endian(WRONG_FORMAT_1), -EINVAL); <answer> KUNIT_EXPECT_EQ(test, 
<token> snd_pcm_format_little_endian(WRONG_FORMAT_2), -EINVAL); <answer> KUNIT_EXPECT_EQ(test, 
<token> snd_pcm_format_big_endian(WRONG_FORMAT_1), -EINVAL); <answer> KUNIT_EXPECT_EQ(test, 
KUNIT_EXPECT_EQ(test, <token> -EINVAL); <answer> snd_pcm_format_big_endian(WRONG_FORMAT_2), 
static void _test_fill_silence(struct kunit <token> struct snd_format_test_data *data, <answer> *test, 
u8 *buffer, <token> samples_count) <answer> size_t 
<token> sample_bytes = data->physical_bits >> 3; <answer> size_t 
<token> i; <answer> u32 
<token> snd_pcm_format_set_silence(data->format, buffer, samples_count), 0); <answer> KUNIT_ASSERT_EQ(test, 
<token> (i = 0; i < samples_count * sample_bytes; i++) <answer> for 
KUNIT_EXPECT_EQ(test, <token> data->silence[i % sample_bytes]); <answer> buffer[i], 
static void test_format_fill_silence(struct <token> *test) <answer> kunit 
u32 buf_samples[] = { 10, 20, 32, 64, <token> SILENCE_BUFFER_MAX_FRAMES }; <answer> 129, 
u8 <token> <answer> *buffer; 
u32 <token> j; <answer> i, 
buffer = kunit_kzalloc(test, SILENCE_BUFFER_SIZE, <token> <answer> GFP_KERNEL); 
for (i = 0; i < <token> i++) { <answer> ARRAY_SIZE(buf_samples); 
for <token> = 0; j < ARRAY_SIZE(valid_fmt); j++) <answer> (j 
_test_fill_silence(test, &valid_fmt[j], buffer, <token> <answer> buf_samples[i]); 
KUNIT_EXPECT_EQ(test, snd_pcm_format_set_silence(WRONG_FORMAT_1, buffer, 20), <token> <answer> -EINVAL); 
<token> snd_pcm_format_set_silence(SNDRV_PCM_FORMAT_LAST, buffer, 0), 0); <answer> KUNIT_EXPECT_EQ(test, 
static snd_pcm_uframes_t <token> buffer_size) <answer> calculate_boundary(snd_pcm_uframes_t 
snd_pcm_uframes_t boundary <token> buffer_size; <answer> = 
while (boundary * 2 <= <token> - buffer_size) <answer> 0x7fffffffUL 
<token> *= 2; <answer> boundary 
<token> boundary; <answer> return 
static struct avail_test_data p_avail_data[] = <token> <answer> { 
{ 128, <token> 10, 118 }, <answer> 1073741824UL, 
<token> <linux/clk-provider.h> <answer> #include 
<token> <linux/of_platform.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> "clk-mtk.h" 
#include <token> <answer> "clk-gate.h" 
<token> <dt-bindings/clock/mt8183-clk.h> <answer> #include 
static const struct mtk_gate_regs audio0_cg_regs <token> { <answer> = 
<token> = 0x0, <answer> .set_ofs 
<token> = 0x0, <answer> .clr_ofs 
<token> = 0x0, <answer> .sta_ofs 
static const <token> mtk_gate_regs audio1_cg_regs = { <answer> struct 
.set_ofs = <token> <answer> 0x4, 
<token> = 0x4, <answer> .clr_ofs 
<token> = 0x4, <answer> .sta_ofs 
#define GATE_AUDIO0(_id, _name, _parent, _shift) <token> <answer> \ 
GATE_MTK(_id, _name, _parent, <token> _shift, \ <answer> &audio0_cg_regs, 
#define GATE_AUDIO1(_id, _name, _parent, _shift) <token> <answer> \ 
GATE_MTK(_id, _name, _parent, &audio1_cg_regs, <token> \ <answer> _shift, 
<token> const struct mtk_gate audio_clks[] = { <answer> static 
if (new_s && <token> && <answer> old_s 
new_s->nr_blocks <token> old_s->nr_blocks && <answer> == 
<token> == old_s->nr_redundant && <answer> new_s->nr_redundant 
!memcmp(old_s->ptrs, <token> <answer> new_s->ptrs, 
new_s->nr_blocks * sizeof(struct <token> <answer> bch_extent_ptr))) 
<token> 0; <answer> return 
BUG_ON(new_s && <token> && <answer> old_s 
(new_s->nr_blocks != old_s->nr_blocks <token> <answer> || 
<token> != old_s->nr_redundant)); <answer> new_s->nr_redundant 
if <token> { <answer> (new_s) 
s64 sectors = <token> <answer> le16_to_cpu(new_s->sectors); 
<token> bch_replicas_padded r; <answer> struct 
bch2_bkey_to_replicas(&r.e, <token> <answer> new); 
int ret = bch2_update_replicas_list(trans, &r.e, sectors <token> new_s->nr_redundant); <answer> * 
<token> (ret) <answer> if 
return <token> <answer> ret; 
if (old_s) <token> <answer> { 
<token> sectors = -((s64) le16_to_cpu(old_s->sectors)); <answer> s64 
struct <token> r; <answer> bch_replicas_padded 
bch2_bkey_to_replicas(&r.e, <token> <answer> old); 
int ret = bch2_update_replicas_list(trans, <token> sectors * old_s->nr_redundant); <answer> &r.e, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
unsigned nr_blocks = new_s ? new_s->nr_blocks <token> old_s->nr_blocks; <answer> : 
for (unsigned i = 0; i < nr_blocks; i++) <token> <answer> { 
<token> (new_s && old_s && <answer> if 
if (new_s) <token> <answer> { 
<token> ret = bch2_trans_mark_stripe_bucket(trans, <answer> int 
<token> i, false); <answer> bkey_s_c_to_stripe(new), 
if <token> <answer> (ret) 
return <token> <answer> ret; 
if <token> { <answer> (old_s) 
int ret = <token> <answer> bch2_trans_mark_stripe_bucket(trans, 
bkey_s_c_to_stripe(old), <token> true); <answer> i, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if (flags & BTREE_TRIGGER_ATOMIC) <token> <answer> { 
struct <token> *m = genradix_ptr(&c->stripes, idx); <answer> stripe 
if (!m) <token> <answer> { 
struct printbuf buf1 <token> PRINTBUF; <answer> = 
<token> printbuf buf2 = PRINTBUF; <answer> struct 
bch2_bkey_val_to_text(&buf1, <token> old); <answer> c, 
<token> c, new); <answer> bch2_bkey_val_to_text(&buf2, 
bch_err_ratelimited(c, "error <token> nonexistent stripe %llu while marking\n" <answer> marking 
<token> %s\n" <answer> "old 
"new %s", <token> buf1.buf, buf2.buf); <answer> idx, 
return <token> <answer> -1; 
<token> (!new_s) { <answer> if 
<token> m, idx); <answer> bch2_stripes_heap_del(c, 
<token> 0, sizeof(*m)); <answer> memset(m, 
} <token> { <answer> else 
m->sectors <token> le16_to_cpu(new_s->sectors); <answer> = 
m->algorithm = <token> <answer> new_s->algorithm; 
<token> = new_s->nr_blocks; <answer> m->nr_blocks 
m->nr_redundant <token> new_s->nr_redundant; <answer> = 
m->blocks_nonempty <token> 0; <answer> = 
for (unsigned i = 0; <token> < new_s->nr_blocks; i++) <answer> i 
m->blocks_nonempty += <token> i); <answer> !!stripe_blockcount_get(new_s, 
<token> (!old_s) <answer> if 
bch2_stripes_heap_insert(c, m, <token> <answer> idx); 
<token> m, idx); <answer> bch2_stripes_heap_update(c, 
if (flags & <token> { <answer> BTREE_TRIGGER_GC) 
struct gc_stripe *m <token> <answer> = 
genradix_ptr_alloc(&c->gc_stripes, idx, <token> <answer> GFP_KERNEL); 
<token> (!m) { <answer> if 
bch_err(c, "error allocating memory for <token> idx %llu", <answer> gc_stripes, 
<token> -BCH_ERR_ENOMEM_mark_stripe; <answer> return 
m->alive = <token> <answer> true; 
<token> = le16_to_cpu(new_s->sectors); <answer> m->sectors 
m->nr_blocks <token> new_s->nr_blocks; <answer> = 
<token> = new_s->nr_redundant; <answer> m->nr_redundant 
for (unsigned i = <token> i < new_s->nr_blocks; i++) <answer> 0; 
m->ptrs[i] = <token> <answer> new_s->ptrs[i]; 
<token> new); <answer> bch2_bkey_to_replicas(&m->r.e, 
<token> 0, sizeof(m->block_sectors)); <answer> memset(m->block_sectors, 
for (unsigned <token> = 0; i < new_s->nr_blocks; i++) { <answer> i 
int ret = mark_stripe_bucket(trans, new, <token> flags); <answer> i, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
int ret <token> bch2_update_replicas(c, new, &m->r.e, <answer> = 
((s64) m->sectors <token> m->nr_redundant), <answer> * 
0, <token> <answer> true); 
if (ret) <token> <answer> { 
struct printbuf buf = <token> <answer> PRINTBUF; 
<token> c, new); <answer> bch2_bkey_val_to_text(&buf, 
bch2_fs_fatal_error(c, ": no replicas entry for %s", <token> <answer> buf.buf); 
return <token> <answer> ret; 
<token> 0; <answer> return 
static bool __bch2_stripe_is_open(struct bch_fs *c, u64 <token> <answer> idx) 
unsigned hash = hash_64(idx, <token> <answer> ilog2(ARRAY_SIZE(c->ec_stripes_new))); 
<token> ec_stripe_new *s; <answer> struct 
hlist_for_each_entry(s, <token> hash) <answer> &c->ec_stripes_new[hash], 
if <token> == idx) <answer> (s->idx 
return <token> <answer> true; 
return <token> <answer> false; 
static bool bch2_stripe_is_open(struct bch_fs <token> u64 idx) <answer> *c, 
bool <token> = false; <answer> ret 
ret = __bch2_stripe_is_open(c, <token> <answer> idx); 
return <token> <answer> ret; 
static <token> bch2_try_open_stripe(struct bch_fs *c, <answer> bool 
<token> ec_stripe_new *s, <answer> struct 
<token> idx) <answer> u64 
<token> ret; <answer> bool 
ret = <token> idx); <answer> !__bch2_stripe_is_open(c, 
if (ret) <token> <answer> { 
<token> hash = hash_64(idx, ilog2(ARRAY_SIZE(c->ec_stripes_new))); <answer> unsigned 
s->idx <token> idx; <answer> = 
hlist_add_head(&s->hash, <token> <answer> &c->ec_stripes_new[hash]); 
<token> ret; <answer> return 
static void <token> bch_fs *c, struct ec_stripe_new *s) <answer> bch2_stripe_close(struct 
s->idx = <token> <answer> 0; 
<token> 0; <answer> return 
if (extent_has_stripe_ptr(k, <token> <answer> s->key.k.p.offset)) 
<token> out; <answer> goto 
ptr_c = <token> k, &block); <answer> bkey_matches_stripe(v, 
if (!ptr_c || <token> <answer> ptr_c->cached) 
goto <token> <answer> out; 
dev = <token> <answer> v->ptrs[block].dev; 
<token> = bch2_trans_kmalloc(trans, bkey_bytes(k.k) + sizeof(stripe_ptr)); <answer> n 
ret = <token> <answer> PTR_ERR_OR_ZERO(n); 
if <token> <answer> (ret) 
goto <token> <answer> out; 
<token> k); <answer> bkey_reassemble(n, 
bch2_bkey_drop_ptrs(bkey_i_to_s(n), ptr, ptr->dev != <token> <answer> dev); 
<token> = bch2_bkey_has_device(bkey_i_to_s(n), dev); <answer> ec_ptr 
stripe_ptr <token> (struct bch_extent_stripe_ptr) { <answer> = 
.type = <token> << BCH_EXTENT_ENTRY_stripe_ptr, <answer> 1 
.block = <token> <answer> block, 
<token> = v->nr_redundant, <answer> .redundancy 
.idx = <token> <answer> s->key.k.p.offset, 
(union bch_extent_entry *) <token> <answer> ec_ptr, 
(union bch_extent_entry <token> &stripe_ptr); <answer> *) 
ret = bch2_trans_update(trans, <token> n, 0); <answer> &iter, 
bch2_trans_iter_exit(trans, <token> <answer> &iter); 
<token> ret; <answer> return 
static int <token> btree_trans *trans, struct ec_stripe_buf *s, <answer> ec_stripe_update_bucket(struct 
unsigned <token> <answer> block) 
struct bch_fs <token> = trans->c; <answer> *c 
struct <token> *v = &bkey_i_to_stripe(&s->key)->v; <answer> bch_stripe 
struct bch_extent_ptr bucket <token> v->ptrs[block]; <answer> = 
struct bpos bucket_pos <token> PTR_BUCKET_POS(c, &bucket); <answer> = 
<token> bpos bp_pos = POS_MIN; <answer> struct 
int ret = <token> <answer> 0; 
while (1) <token> <answer> { 
<token> = commit_do(trans, NULL, NULL, <answer> ret 
ec_stripe_update_extent(trans, bucket_pos, <token> <answer> bucket.gen, 
s, <token> <answer> &bp_pos)); 
if <token> <answer> (ret) 
<token> (bkey_eq(bp_pos, POS_MAX)) <answer> if 
bp_pos = <token> <answer> bpos_nosnap_successor(bp_pos); 
<token> ret; <answer> return 
static int ec_stripe_update_extents(struct <token> *c, struct ec_stripe_buf *s) <answer> bch_fs 
<token> btree_trans *trans = bch2_trans_get(c); <answer> struct 
struct bch_stripe *v <token> &bkey_i_to_stripe(&s->key)->v; <answer> = 
unsigned i, nr_data <token> v->nr_blocks - v->nr_redundant; <answer> = 
int <token> = 0; <answer> ret 
ret <token> bch2_btree_write_buffer_flush_sync(trans); <answer> = 
if <token> <answer> (ret) 
goto <token> <answer> err; 
for (i = 0; i < <token> i++) { <answer> nr_data; 
ret = <token> s, i); <answer> ec_stripe_update_bucket(trans, 
if <token> <answer> (ret) 
return <token> <answer> ret; 
static <token> zero_out_rest_of_ec_bucket(struct bch_fs *c, <answer> void 
<token> ec_stripe_new *s, <answer> struct 
unsigned <token> <answer> block, 
<token> open_bucket *ob) <answer> struct 
struct bch_dev <token> = bch_dev_bkey_exists(c, ob->dev); <answer> *ca 
unsigned offset = ca->mi.bucket_size - <token> <answer> ob->sectors_free; 
<token> ret; <answer> int 
if (!bch2_dev_get_ioref(ca, <token> { <answer> WRITE)) 
s->err = <token> <answer> -BCH_ERR_erofs_no_writes; 
memset(s->new_stripe.data[block] + (offset <token> 9), <answer> << 
ob->sectors_free <token> 9); <answer> << 
ret = <token> <answer> blkdev_issue_zeroout(ca->disk_sb.bdev, 
ob->bucket * <token> + offset, <answer> ca->mi.bucket_size 
<token> 0); <answer> GFP_KERNEL, 
if <token> <answer> (ret) 
<token> = ret; <answer> s->err 
void bch2_ec_stripe_new_free(struct bch_fs <token> struct ec_stripe_new *s) <answer> *c, 
if <token> <answer> (s->idx) 
<token> s); <answer> bch2_stripe_close(c, 
static <token> ec_stripe_create(struct ec_stripe_new *s) <answer> void 
struct bch_fs <token> = s->c; <answer> *c 
<token> open_bucket *ob; <answer> struct 
struct bch_stripe *v <token> &bkey_i_to_stripe(&s->new_stripe.key)->v; <answer> = 
<token> i, nr_data = v->nr_blocks - v->nr_redundant; <answer> unsigned 
int <token> <answer> ret; 
<token> == s); <answer> BUG_ON(s->h->s 
if (!s->err) <token> <answer> { 
for <token> = 0; i < nr_data; i++) <answer> (i 
if (s->blocks[i]) <token> <answer> { 
ob = <token> + s->blocks[i]; <answer> c->open_buckets 
if <token> <answer> (ob->sectors_free) 
zero_out_rest_of_ec_bucket(c, <token> i, ob); <answer> s, 
if (s->err) <token> <answer> { 
if <token> EROFS)) <answer> (!bch2_err_matches(s->err, 
bch_err(c, "error creating stripe: error writing data <token> <answer> buckets"); 
goto <token> <answer> err; 
<token> (s->have_existing_stripe) { <answer> if 
ec_validate_checksums(c, <token> <answer> &s->existing_stripe); 
if (ec_do_recov(c, &s->existing_stripe)) <token> <answer> { 
bch_err(c, "error creating stripe: error reading <token> stripe"); <answer> existing 
<token> err; <answer> goto 
for (i = 0; i < nr_data; <token> <answer> i++) 
if <token> i)) <answer> (stripe_blockcount_get(&bkey_i_to_stripe(&s->existing_stripe.key)->v, 
<token> (h->nr_active_devs < h->redundancy + 2) <answer> if 
bch_err(c, "insufficient <token> available to create stripe (have %u, need %u) - mismatched bucket sizes?", <answer> devices 
h->nr_active_devs, h->redundancy + <token> <answer> 2); 
list_add(&h->list, <token> <answer> &c->ec_stripe_head_list); 
<token> h; <answer> return 
void bch2_ec_stripe_head_put(struct bch_fs *c, struct <token> *h) <answer> ec_stripe_head 
if (h->s <token> <answer> && 
h->s->allocated <token> <answer> && 
h->s->nr_data) == <token> <answer> h->s->nr_data) 
ec_stripe_set_pending(c, <token> <answer> h); 
static struct <token> * <answer> ec_stripe_head 
__bch2_ec_stripe_head_get(struct <token> *trans, <answer> btree_trans 
<token> target, <answer> unsigned 
<token> algo, <answer> unsigned 
unsigned <token> <answer> redundancy, 
enum <token> watermark) <answer> bch_watermark 
struct <token> *c = trans->c; <answer> bch_fs 
struct ec_stripe_head <token> <answer> *h; 
int <token> <answer> ret; 
if <token> <answer> (!redundancy) 
return <token> <answer> NULL; 
<token> = bch2_trans_mutex_lock(trans, &c->ec_stripe_head_lock); <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ERR_PTR(ret); 
if (test_bit(BCH_FS_going_ro, &c->flags)) <token> <answer> { 
h = <token> <answer> ERR_PTR(-BCH_ERR_erofs_no_writes); 
<token> found; <answer> goto 
<token> &c->ec_stripe_head_list, list) <answer> list_for_each_entry(h, 
if (h->target == <token> && <answer> target 
<token> == algo && <answer> h->algo 
<token> == redundancy && <answer> h->redundancy 
h->watermark == watermark) <token> <answer> { 
<token> = bch2_trans_mutex_lock(trans, &h->lock); <answer> ret 
if <token> <answer> (ret) 
h = <token> <answer> ERR_PTR(ret); 
<token> found; <answer> goto 
h = ec_new_stripe_head_alloc(c, target, algo, redundancy, <token> <answer> watermark); 
<token> (!IS_ERR_OR_NULL(h) && <answer> if 
h->nr_active_devs < <token> + 2) { <answer> h->redundancy 
<token> = NULL; <answer> h 
return <token> <answer> h; 
static int <token> btree_trans *trans, struct ec_stripe_head *h, <answer> new_stripe_alloc_buckets(struct 
enum bch_watermark watermark, <token> closure *cl) <answer> struct 
struct bch_fs <token> = trans->c; <answer> *c 
struct bch_devs_mask devs = <token> <answer> h->devs; 
<token> open_bucket *ob; <answer> struct 
<token> open_buckets buckets; <answer> struct 
struct bch_stripe <token> = &bkey_i_to_stripe(&h->s->new_stripe.key)->v; <answer> *v 
<token> i, j, nr_have_parity = 0, nr_have_data = 0; <answer> unsigned 
bool have_cache = <token> <answer> true; 
int <token> = 0; <answer> ret 
<token> != h->s->nr_data + h->s->nr_parity); <answer> BUG_ON(v->nr_blocks 
BUG_ON(v->nr_redundant != <token> <answer> h->s->nr_parity); 
<token> h->s->blocks_gotten, v->nr_blocks) { <answer> for_each_set_bit(i, 
<token> devs.d); <answer> __clear_bit(v->ptrs[i].dev, 
if <token> < h->s->nr_data) <answer> (i 
BUG_ON(nr_have_data <token> h->s->nr_data); <answer> > 
BUG_ON(nr_have_parity > <token> <answer> h->s->nr_parity); 
<token> = 0; <answer> buckets.nr 
if <token> < h->s->nr_parity) { <answer> (nr_have_parity 
ret = bch2_bucket_alloc_set_trans(trans, <token> <answer> &buckets, 
<token> 0, <answer> &have_cache, 
open_bucket_for_each(c, &buckets, ob, <token> { <answer> i) 
<token> = find_next_zero_bit(h->s->blocks_gotten, <answer> j 
<token> + h->s->nr_parity, <answer> h->s->nr_data 
<token> >= h->s->nr_data + h->s->nr_parity); <answer> BUG_ON(j 
h->s->blocks[j] <token> buckets.v[i]; <answer> = 
v->ptrs[j] <token> bch2_ob_ptr(c, ob); <answer> = 
__set_bit(j, <token> <answer> h->s->blocks_gotten); 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> = 0; <answer> buckets.nr 
if <token> < h->s->nr_data) { <answer> (nr_have_data 
ret = <token> &buckets, <answer> bch2_bucket_alloc_set_trans(trans, 
<token> 0, <answer> &have_cache, 
open_bucket_for_each(c, &buckets, ob, i) <token> <answer> { 
j <token> find_next_zero_bit(h->s->blocks_gotten, <answer> = 
h->s->nr_data, <token> <answer> 0); 
BUG_ON(j >= <token> <answer> h->s->nr_data); 
h->s->blocks[j] <token> buckets.v[i]; <answer> = 
v->ptrs[j] = bch2_ob_ptr(c, <token> <answer> ob); 
__set_bit(j, <token> <answer> h->s->blocks_gotten); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
<token> 0; <answer> return 
idx = get_existing_stripe(c, <token> <answer> h); 
if <token> < 0) <answer> (idx 
<token> -BCH_ERR_stripe_alloc_blocked; <answer> return 
ret = get_stripe_key_trans(trans, <token> &h->s->existing_stripe); <answer> idx, 
bch2_fs_fatal_err_on(ret && !bch2_err_matches(ret, <token> c, <answer> BCH_ERR_transaction_restart), 
"reading stripe key: %s", <token> <answer> bch2_err_str(ret)); 
if (ret) <token> <answer> { 
<token> h->s); <answer> bch2_stripe_close(c, 
<token> ret; <answer> return 
<token> = &bkey_i_to_stripe(&h->s->existing_stripe.key)->v; <answer> existing_v 
<token> != h->s->nr_parity); <answer> BUG_ON(existing_v->nr_redundant 
<token> = existing_v->nr_blocks - <answer> h->s->nr_data 
ret = <token> 0, h->blocksize); <answer> ec_stripe_buf_init(&h->s->existing_stripe, 
if <token> { <answer> (ret) 
bch2_stripe_close(c, <token> <answer> h->s); 
<token> ret; <answer> return 
BUG_ON(h->s->existing_stripe.size <token> h->blocksize); <answer> != 
<token> != le16_to_cpu(existing_v->sectors)); <answer> BUG_ON(h->s->existing_stripe.size 
for_each_set_bit(i, h->s->blocks_gotten, new_v->nr_blocks) <token> <answer> { 
<token> c->open_buckets + h->s->blocks[i]); <answer> bch2_open_bucket_put(c, 
<token> = 0; <answer> h->s->blocks[i] 
memset(h->s->blocks_gotten, <token> sizeof(h->s->blocks_gotten)); <answer> 0, 
memset(h->s->blocks_allocated, 0, <token> <answer> sizeof(h->s->blocks_allocated)); 
for (i <token> 0; i < existing_v->nr_blocks; i++) { <answer> = 
if <token> i)) { <answer> (stripe_blockcount_get(existing_v, 
<token> h->s->blocks_gotten); <answer> __set_bit(i, 
<token> h->s->blocks_allocated); <answer> __set_bit(i, 
ec_block_io(c, <token> READ, i, &h->s->iodone); <answer> &h->s->existing_stripe, 
<token> &h->s->existing_stripe.key); <answer> bkey_copy(&h->s->new_stripe.key, 
h->s->have_existing_stripe <token> true; <answer> = 
<token> 0; <answer> return 
static <token> __bch2_ec_stripe_head_reserve(struct btree_trans *trans, struct ec_stripe_head *h) <answer> int 
struct bch_fs *c <token> trans->c; <answer> = 
struct <token> iter; <answer> btree_iter 
struct <token> k; <answer> bkey_s_c 
struct bpos min_pos <token> POS(0, 1); <answer> = 
struct bpos start_pos <token> bpos_max(min_pos, POS(0, c->ec_stripe_hint)); <answer> = 
<token> ret; <answer> int 
if <token> { <answer> (!h->s->res.sectors) 
<token> = bch2_disk_reservation_get(c, &h->s->res, <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ret; 
<token> iter, BTREE_ID_stripes, start_pos, <answer> for_each_btree_key_norestart(trans, 
BTREE_ITER_SLOTS|BTREE_ITER_INTENT, k, <token> { <answer> ret) 
if (bkey_gt(k.k->p, POS(0, U32_MAX))) <token> <answer> { 
if (start_pos.offset) <token> <answer> { 
start_pos <token> min_pos; <answer> = 
bch2_btree_iter_set_pos(&iter, <token> <answer> start_pos); 
ret <token> -BCH_ERR_ENOSPC_stripe_create; <answer> = 
if <token> && <answer> (bkey_deleted(k.k) 
bch2_try_open_stripe(c, h->s, <token> <answer> k.k->p.offset)) 
c->ec_stripe_hint <token> iter.pos.offset; <answer> = 
<token> (ret) <answer> if 
goto <token> <answer> err; 
<token> = ec_stripe_mem_alloc(trans, &iter); <answer> ret 
if <token> { <answer> (ret) 
<token> h->s); <answer> bch2_stripe_close(c, 
<token> err; <answer> goto 
h->s->new_stripe.key.k.p = <token> <answer> iter.pos; 
<token> &iter); <answer> bch2_trans_iter_exit(trans, 
return <token> <answer> ret; 
<token> &h->s->res); <answer> bch2_disk_reservation_put(c, 
<token> out; <answer> goto 
struct ec_stripe_head *bch2_ec_stripe_head_get(struct <token> *trans, <answer> btree_trans 
<token> target, <answer> unsigned 
<token> algo, <answer> unsigned 
unsigned <token> <answer> redundancy, 
<token> bch_watermark watermark, <answer> enum 
struct <token> *cl) <answer> closure 
struct bch_fs *c = <token> <answer> trans->c; 
struct <token> *h; <answer> ec_stripe_head 
bool waiting = <token> <answer> false; 
<token> ret; <answer> int 
h = __bch2_ec_stripe_head_get(trans, target, <token> redundancy, watermark); <answer> algo, 
if <token> <answer> (IS_ERR_OR_NULL(h)) 
return <token> <answer> h; 
if (!h->s) <token> <answer> { 
ret = ec_new_stripe_alloc(c, <token> <answer> h); 
if <token> { <answer> (ret) 
bch_err(c, "failed to allocate <token> stripe"); <answer> new 
<token> err; <answer> goto 
<token> (h->s->allocated) <answer> if 
<token> allocated; <answer> goto 
if <token> <answer> (h->s->have_existing_stripe) 
<token> alloc_existing; <answer> goto 
while (1) <token> <answer> { 
<token> = __bch2_ec_stripe_head_reuse(trans, h); <answer> ret 
<token> (!ret) <answer> if 
if (waiting || <token> || ret != -BCH_ERR_stripe_alloc_blocked) <answer> !cl 
<token> err; <answer> goto 
<token> (watermark == BCH_WATERMARK_copygc) { <answer> if 
<token> = new_stripe_alloc_buckets(trans, h, watermark, NULL) ?: <answer> ret 
<token> h); <answer> __bch2_ec_stripe_head_reserve(trans, 
<token> (ret) <answer> if 
<token> err; <answer> goto 
<token> allocate_buf; <answer> goto 
<token> = new_stripe_alloc_buckets(trans, h, watermark, cl); <answer> ret 
<token> (ret) <answer> if 
goto <token> <answer> err; 
<token> = ec_stripe_buf_init(&h->s->new_stripe, 0, h->blocksize); <answer> ret 
if <token> <answer> (ret) 
<token> err; <answer> goto 
h->s->allocated = <token> <answer> true; 
return <token> <answer> h; 
bch2_ec_stripe_head_put(c, <token> <answer> h); 
return <token> <answer> ERR_PTR(ret); 
static void __bch2_ec_stop(struct <token> *c, struct bch_dev *ca) <answer> bch_fs 
struct <token> *h; <answer> ec_stripe_head 
struct open_bucket <token> <answer> *ob; 
<token> i; <answer> unsigned 
<token> &c->ec_stripe_head_list, list) { <answer> list_for_each_entry(h, 
<token> (!h->s) <answer> if 
goto <token> <answer> unlock; 
<token> (!ca) <answer> if 
<token> found; <answer> goto 
for (i = 0; <token> < bkey_i_to_stripe(&h->s->new_stripe.key)->v.nr_blocks; i++) { <answer> i 
<token> (!h->s->blocks[i]) <answer> if 
ob = <token> + h->s->blocks[i]; <answer> c->open_buckets 
if <token> == ca->dev_idx) <answer> (ob->dev 
goto <token> <answer> found; 
<token> unlock; <answer> goto 
h->s->err = <token> <answer> -BCH_ERR_erofs_no_writes; 
ec_stripe_set_pending(c, <token> <answer> h); 
void bch2_ec_stop_dev(struct <token> *c, struct bch_dev *ca) <answer> bch_fs 
__bch2_ec_stop(c, <token> <answer> ca); 
void <token> bch_fs *c) <answer> bch2_fs_ec_stop(struct 
__bch2_ec_stop(c, <token> <answer> NULL); 
static bool bch2_fs_ec_flush_done(struct bch_fs <token> <answer> *c) 
bool <token> <answer> ret; 
<token> = list_empty(&c->ec_stripe_new_list); <answer> ret 
<token> ret; <answer> return 
void <token> bch_fs *c) <answer> bch2_fs_ec_flush(struct 
wait_event(c->ec_stripe_new_wait, <token> <answer> bch2_fs_ec_flush_done(c)); 
int bch2_stripes_read(struct <token> *c) <answer> bch_fs 
<token> ret = bch2_trans_run(c, <answer> int 
<token> iter, BTREE_ID_stripes, POS_MIN, <answer> for_each_btree_key(trans, 
<token> k, ({ <answer> BTREE_ITER_PREFETCH, 
<token> (k.k->type != KEY_TYPE_stripe) <answer> if 
ret <token> __ec_stripe_mem_alloc(c, k.k->p.offset, GFP_KERNEL); <answer> = 
if <token> <answer> (ret) 
<token> struct bch_stripe *s = bkey_s_c_to_stripe(k).v; <answer> const 
struct stripe *m <token> genradix_ptr(&c->stripes, k.k->p.offset); <answer> = 
m->sectors = <token> <answer> le16_to_cpu(s->sectors); 
m->algorithm = <token> <answer> s->algorithm; 
<token> = s->nr_blocks; <answer> m->nr_blocks 
m->nr_redundant = <token> <answer> s->nr_redundant; 
m->blocks_nonempty <token> 0; <answer> = 
for <token> i = 0; i < s->nr_blocks; i++) <answer> (unsigned 
<token> += !!stripe_blockcount_get(s, i); <answer> m->blocks_nonempty 
bch2_stripes_heap_insert(c, m, <token> <answer> k.k->p.offset); 
bch_err_fn(c, <token> <answer> ret); 
return <token> <answer> ret; 
void bch2_stripes_heap_to_text(struct printbuf <token> struct bch_fs *c) <answer> *out, 
ec_stripes_heap *h <token> &c->ec_stripes_heap; <answer> = 
struct stripe <token> <answer> *m; 
<token> i; <answer> size_t 
for (i = 0; i < min_t(size_t, h->used, 50); i++) <token> <answer> { 
m <token> genradix_ptr(&c->stripes, h->data[i].idx); <answer> = 
prt_printf(out, "%zu %u/%u+%u", <token> <answer> h->data[i].idx, 
m->nr_blocks <token> m->nr_redundant, <answer> - 
if <token> h->data[i].idx)) <answer> (bch2_stripe_is_open(c, 
prt_str(out, " <token> <answer> open"); 
void bch2_new_stripes_to_text(struct printbuf *out, <token> bch_fs *c) <answer> struct 
<token> ec_stripe_head *h; <answer> struct 
struct <token> *s; <answer> ec_stripe_new 
<token> &c->ec_stripe_head_list, list) { <answer> list_for_each_entry(h, 
prt_printf(out, "target <token> algo %u redundancy %u %s:\n", <answer> %u 
h->target, h->algo, <token> <answer> h->redundancy, 
if <token> <answer> (h->s) 
<token> "\tidx %llu blocks %u+%u allocated %u\n", <answer> prt_printf(out, 
<token> h->s->nr_data, h->s->nr_parity, <answer> h->s->idx, 
prt_printf(out, <token> flight:\n"); <answer> "in 
list_for_each_entry(s, &c->ec_stripe_new_list, list) <token> <answer> { 
prt_printf(out, "\tidx %llu blocks %u+%u ref %u <token> %s\n", <answer> %u 
<token> s->nr_data, s->nr_parity, <answer> s->idx, 
void bch2_fs_ec_exit(struct <token> *c) <answer> bch_fs 
struct ec_stripe_head <token> <answer> *h; 
unsigned <token> <answer> i; 
<token> (1) { <answer> while 
h = <token> <answer> list_first_entry_or_null(&c->ec_stripe_head_list, 
struct <token> list); <answer> ec_stripe_head, 
<token> (h) <answer> if 
<token> (!h) <answer> if 
if (h->s) <token> <answer> { 
for (i = 0; i < <token> i++) <answer> bkey_i_to_stripe(&h->s->new_stripe.key)->v.nr_blocks; 
void bch2_fs_ec_init_early(struct <token> *c) <answer> bch_fs 
<token> ec_stripe_create_work); <answer> INIT_WORK(&c->ec_stripe_create_work, 
<token> ec_stripe_delete_work); <answer> INIT_WORK(&c->ec_stripe_delete_work, 
<token> bch2_fs_ec_init(struct bch_fs *c) <answer> int 
return bioset_init(&c->ec_bioset, 1, offsetof(struct <token> bio), <answer> ec_bio, 
#include <token> <answer> <linux/delay.h> 
<token> <linux/i2c.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/mod_devicetable.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/sysfs.h> 
<token> <linux/iio/iio.h> <answer> #include 
<token> <linux/iio/sysfs.h> <answer> #include 
<token> (chan->type == IIO_HUMIDITYRELATIVE) <answer> if 
*val <token> clamp_val(*val, 786, 13893); <answer> = 
return <token> <answer> IIO_VAL_INT; 
case <token> <answer> IIO_CHAN_INFO_SCALE: 
if (chan->type == <token> <answer> IIO_TEMP) 
if (chan->type == <token> <answer> IIO_TEMP) 
<token> <linux/ethtool.h> <answer> #include 
#include <token> <answer> "mcp251xfd.h" 
<token> "mcp251xfd-ram.h" <answer> #include 
<token> void <answer> static 
mcp251xfd_ring_get_ringparam(struct <token> *ndev, <answer> net_device 
<token> ethtool_ringparam *ring, <answer> struct 
<token> kernel_ethtool_ringparam *kernel_ring, <answer> struct 
struct netlink_ext_ack <token> <answer> *extack) 
const struct mcp251xfd_priv *priv = <token> <answer> netdev_priv(ndev); 
<token> bool fd_mode = mcp251xfd_is_fd_mode(priv); <answer> const 
struct <token> layout; <answer> can_ram_layout 
can_ram_get_layout(&layout, &mcp251xfd_ram_config, NULL, <token> fd_mode); <answer> NULL, 
ring->rx_max_pending <token> layout.max_rx; <answer> = 
ring->tx_max_pending <token> layout.max_tx; <answer> = 
<token> = priv->rx_obj_num; <answer> ring->rx_pending 
<token> = priv->tx->obj_num; <answer> ring->tx_pending 
static <token> <answer> int 
mcp251xfd_ring_set_ringparam(struct <token> *ndev, <answer> net_device 
struct ethtool_ringparam <token> <answer> *ring, 
struct kernel_ethtool_ringparam <token> <answer> *kernel_ring, 
<token> netlink_ext_ack *extack) <answer> struct 
struct mcp251xfd_priv *priv <token> netdev_priv(ndev); <answer> = 
const bool <token> = mcp251xfd_is_fd_mode(priv); <answer> fd_mode 
struct can_ram_layout <token> <answer> layout; 
can_ram_get_layout(&layout, <token> ring, NULL, fd_mode); <answer> &mcp251xfd_ram_config, 
<token> ((layout.cur_rx != priv->rx_obj_num || <answer> if 
layout.cur_tx != <token> && <answer> priv->tx->obj_num) 
return <token> <answer> -EBUSY; 
priv->rx_obj_num <token> layout.cur_rx; <answer> = 
priv->rx_obj_num_coalesce_irq = <token> <answer> layout.rx_coalesce; 
priv->tx->obj_num = <token> <answer> layout.cur_tx; 
priv->tx_obj_num_coalesce_irq <token> layout.tx_coalesce; <answer> = 
return <token> <answer> 0; 
static int <token> net_device *ndev, <answer> mcp251xfd_ring_get_coalesce(struct 
struct ethtool_coalesce <token> <answer> *ec, 
struct kernel_ethtool_coalesce <token> <answer> *kec, 
struct netlink_ext_ack <token> <answer> *ext_ack) 
<token> mcp251xfd_priv *priv = netdev_priv(ndev); <answer> struct 
u32 <token> tx_max_frames; <answer> rx_max_frames, 
if (priv->rx_obj_num_coalesce_irq <token> 0) <answer> == 
<token> = 1; <answer> rx_max_frames 
<token> = priv->rx_obj_num_coalesce_irq; <answer> rx_max_frames 
<token> = rx_max_frames; <answer> ec->rx_max_coalesced_frames_irq 
ec->rx_coalesce_usecs_irq = <token> <answer> priv->rx_coalesce_usecs_irq; 
<token> (priv->tx_obj_num_coalesce_irq == 0) <answer> if 
<token> = 1; <answer> tx_max_frames 
tx_max_frames = <token> <answer> priv->tx_obj_num_coalesce_irq; 
ec->tx_max_coalesced_frames_irq <token> tx_max_frames; <answer> = 
ec->tx_coalesce_usecs_irq = <token> <answer> priv->tx_coalesce_usecs_irq; 
<token> 0; <answer> return 
static int mcp251xfd_ring_set_coalesce(struct <token> *ndev, <answer> net_device 
<token> ethtool_coalesce *ec, <answer> struct 
<token> kernel_ethtool_coalesce *kec, <answer> struct 
struct netlink_ext_ack <token> <answer> *ext_ack) 
<token> mcp251xfd_priv *priv = netdev_priv(ndev); <answer> struct 
const bool fd_mode = <token> <answer> mcp251xfd_is_fd_mode(priv); 
const struct <token> ring = { <answer> ethtool_ringparam 
.rx_pending = <token> <answer> priv->rx_obj_num, 
.tx_pending <token> priv->tx->obj_num, <answer> = 
struct can_ram_layout <token> <answer> layout; 
can_ram_get_layout(&layout, &mcp251xfd_ram_config, &ring, ec, <token> <answer> fd_mode); 
if ((layout.rx_coalesce != priv->rx_obj_num_coalesce_irq <token> <answer> || 
ec->rx_coalesce_usecs_irq <token> priv->rx_coalesce_usecs_irq || <answer> != 
layout.tx_coalesce <token> priv->tx_obj_num_coalesce_irq || <answer> != 
ec->tx_coalesce_usecs_irq <token> priv->tx_coalesce_usecs_irq) && <answer> != 
return <token> <answer> -EBUSY; 
priv->rx_obj_num <token> layout.cur_rx; <answer> = 
priv->rx_obj_num_coalesce_irq = <token> <answer> layout.rx_coalesce; 
priv->rx_coalesce_usecs_irq = <token> <answer> ec->rx_coalesce_usecs_irq; 
<token> = layout.cur_tx; <answer> priv->tx->obj_num 
priv->tx_obj_num_coalesce_irq <token> layout.tx_coalesce; <answer> = 
priv->tx_coalesce_usecs_irq <token> ec->tx_coalesce_usecs_irq; <answer> = 
return <token> <answer> 0; 
<token> const struct ethtool_ops mcp251xfd_ethtool_ops = { <answer> static 
.supported_coalesce_params <token> ETHTOOL_COALESCE_RX_USECS_IRQ | <answer> = 
ETHTOOL_COALESCE_RX_MAX_FRAMES_IRQ <token> <answer> | 
ETHTOOL_COALESCE_TX_USECS_IRQ <token> <answer> | 
<token> = mcp251xfd_ring_get_ringparam, <answer> .get_ringparam 
.set_ringparam = <token> <answer> mcp251xfd_ring_set_ringparam, 
<token> = mcp251xfd_ring_get_coalesce, <answer> .get_coalesce 
<token> = mcp251xfd_ring_set_coalesce, <answer> .set_coalesce 
<token> = can_ethtool_op_get_ts_info_hwts, <answer> .get_ts_info 
void mcp251xfd_ethtool_init(struct <token> *priv) <answer> mcp251xfd_priv 
<token> can_ram_layout layout; <answer> struct 
<token> = &mcp251xfd_ethtool_ops; <answer> priv->ndev->ethtool_ops 
can_ram_get_layout(&layout, &mcp251xfd_ram_config, NULL, NULL, <token> <answer> false); 
priv->rx_obj_num <token> layout.default_rx; <answer> = 
<token> = layout.default_tx; <answer> priv->tx->obj_num 
priv->rx_obj_num_coalesce_irq = <token> <answer> 0; 
priv->tx_obj_num_coalesce_irq <token> 0; <answer> = 
<token> = 0; <answer> priv->rx_coalesce_usecs_irq 
priv->tx_coalesce_usecs_irq = <token> <answer> 0; 
<token> <kunit/test.h> <answer> #include 
<token> <linux/skbuff.h> <answer> #include 
static const char hdr[] = <token> <answer> "abcdefgh"; 
#define GSO_TEST_SIZE <token> <answer> 1000 
static <token> __init_skb(struct sk_buff *skb) <answer> void 
memcpy(skb_mac_header(skb), <token> sizeof(hdr)); <answer> hdr, 
.id <token> GSO_TEST_GSO_BY_FRAGS, <answer> = 
.name = <token> <answer> "gso_by_frags", 
.nr_frag_skbs = <token> <answer> 4, 
.frag_skbs = (const unsigned <token> { 100, 200, 300, 400 }, <answer> int[]) 
.nr_segs <token> 4, <answer> = 
.segs = (const unsigned int[]) { 100, <token> 300, 400 }, <answer> 200, 
static void gso_test_case_to_desc(struct gso_test_case *t, char <token> <answer> *desc) 
sprintf(desc, "%s", <token> <answer> t->name); 
KUNIT_ARRAY_PARAM(gso_test, cases, <token> <answer> gso_test_case_to_desc); 
static <token> gso_test_func(struct kunit *test) <answer> void 
<token> int shinfo_size = SKB_DATA_ALIGN(sizeof(struct skb_shared_info)); <answer> const 
<token> sk_buff *skb, *segs, *cur, *next, *last; <answer> struct 
const struct gso_test_case <token> <answer> *tcase; 
netdev_features_t <token> <answer> features; 
<token> page *page; <answer> struct 
<token> i; <answer> int 
<token> = test->param_value; <answer> tcase 
<token> = alloc_page(GFP_KERNEL); <answer> page 
KUNIT_ASSERT_NOT_NULL(test, <token> <answer> page); 
<token> = build_skb(page_address(page), sizeof(hdr) + tcase->linear_len + shinfo_size); <answer> skb 
<token> skb); <answer> KUNIT_ASSERT_NOT_NULL(test, 
__skb_put(skb, sizeof(hdr) + <token> <answer> tcase->linear_len); 
if (tcase->nr_frags) <token> <answer> { 
unsigned int pg_off <token> 0; <answer> = 
page <token> alloc_page(GFP_KERNEL); <answer> = 
KUNIT_ASSERT_NOT_NULL(test, <token> <answer> page); 
<token> tcase->nr_frags - 1); <answer> page_ref_add(page, 
<token> (i = 0; i < tcase->nr_frags; i++) { <answer> for 
skb_fill_page_desc(skb, i, <token> pg_off, tcase->frags[i]); <answer> page, 
<token> += tcase->frags[i]; <answer> pg_off 
KUNIT_ASSERT_LE(test, <token> PAGE_SIZE); <answer> pg_off, 
skb->data_len <token> pg_off; <answer> = 
skb->len += <token> <answer> skb->data_len; 
skb->truesize <token> skb->data_len; <answer> += 
if (tcase->frag_skbs) <token> <answer> { 
<token> int total_size = 0, total_true_size = 0; <answer> unsigned 
struct sk_buff *frag_skb, <token> = NULL; <answer> *prev 
for <token> = 0; i < tcase->nr_frag_skbs; i++) { <answer> (i 
unsigned <token> frag_size; <answer> int 
<token> = alloc_page(GFP_KERNEL); <answer> page 
KUNIT_ASSERT_NOT_NULL(test, <token> <answer> page); 
frag_size <token> tcase->frag_skbs[i]; <answer> = 
frag_skb = <token> <answer> build_skb(page_address(page), 
<token> + shinfo_size); <answer> frag_size 
<token> frag_skb); <answer> KUNIT_ASSERT_NOT_NULL(test, 
__skb_put(frag_skb, <token> <answer> frag_size); 
<token> (prev) <answer> if 
prev->next <token> frag_skb; <answer> = 
skb_shinfo(skb)->frag_list <token> frag_skb; <answer> = 
<token> = frag_skb; <answer> prev 
<token> += frag_size; <answer> total_size 
total_true_size <token> frag_skb->truesize; <answer> += 
skb->len += <token> <answer> total_size; 
skb->data_len += <token> <answer> total_size; 
<token> += total_true_size; <answer> skb->truesize 
if (tcase->id == <token> <answer> GSO_TEST_GSO_BY_FRAGS) 
skb_shinfo(skb)->gso_size <token> GSO_BY_FRAGS; <answer> = 
features = NETIF_F_SG <token> NETIF_F_HW_CSUM; <answer> | 
if <token> == GSO_TEST_GSO_PARTIAL) <answer> (tcase->id 
features |= <token> <answer> NETIF_F_GSO_PARTIAL; 
if (tcase->id == <token> <answer> GSO_TEST_FRAG_LIST_NON_UNIFORM) 
features <token> ~NETIF_F_SG; <answer> &= 
segs <token> skb_segment(skb, features); <answer> = 
<token> (IS_ERR(segs)) { <answer> if 
KUNIT_FAIL(test, "segs <token> %pe", segs); <answer> error 
goto <token> <answer> free_gso_skb; 
} else <token> (!segs) { <answer> if 
KUNIT_FAIL(test, <token> segments"); <answer> "no 
<token> free_gso_skb; <answer> goto 
last <token> segs->prev; <answer> = 
for (cur = segs, i = 0; cur; <token> = next, i++) { <answer> cur 
next = <token> <answer> cur->next; 
KUNIT_ASSERT_EQ(test, cur->len, sizeof(hdr) <token> tcase->segs[i]); <answer> + 
#include <token> <answer> <linux/backlight.h> 
#include <token> <answer> <linux/delay.h> 
<token> <linux/gpio/consumer.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
<token> <linux/regulator/consumer.h> <answer> #include 
#include <token> <answer> <drm/drm_mipi_dsi.h> 
<token> <drm/drm_modes.h> <answer> #include 
<token> <drm/drm_panel.h> <answer> #include 
struct <token> { <answer> truly_nt35521 
struct <token> panel; <answer> drm_panel 
struct mipi_dsi_device <token> <answer> *dsi; 
struct <token> supplies[2]; <answer> regulator_bulk_data 
struct <token> *reset_gpio; <answer> gpio_desc 
<token> gpio_desc *blen_gpio; <answer> struct 
<token> inline <answer> static 
struct truly_nt35521 <token> drm_panel *panel) <answer> *to_truly_nt35521(struct 
return container_of(panel, struct <token> panel); <answer> truly_nt35521, 
<token> void truly_nt35521_reset(struct truly_nt35521 *ctx) <answer> static 
gpiod_set_value_cansleep(ctx->reset_gpio, <token> <answer> 1); 
<token> 2000); <answer> usleep_range(1000, 
<token> 1); <answer> gpiod_set_value_cansleep(ctx->reset_gpio, 
<token> 11000); <answer> usleep_range(10000, 
<token> 0); <answer> gpiod_set_value_cansleep(ctx->reset_gpio, 
static <token> truly_nt35521_on(struct truly_nt35521 *ctx) <answer> int 
struct mipi_dsi_device <token> = ctx->dsi; <answer> *dsi 
struct device <token> = &dsi->dev; <answer> *dev 
int <token> <answer> ret; 
<token> |= MIPI_DSI_MODE_LPM; <answer> dsi->mode_flags 
mipi_dsi_generic_write_seq(dsi, 0xf0, 0x55, 0xaa, 0x52, <token> 0x00); <answer> 0x08, 
<token> 0xff, 0xaa, 0x55, 0xa5, 0x80); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, <token> 0x11, 0x00); <answer> 0x6f, 
mipi_dsi_generic_write_seq(dsi, <token> 0x20, 0x00); <answer> 0xf7, 
mipi_dsi_generic_write_seq(dsi, <token> 0x01); <answer> 0x6f, 
mipi_dsi_generic_write_seq(dsi, 0xb1, <token> <answer> 0x21); 
<token> 0xbd, 0x01, 0xa0, 0x10, 0x08, 0x01); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xb8, 0x01, <token> 0x0c, 0x02); <answer> 0x02, 
mipi_dsi_generic_write_seq(dsi, <token> 0x11, 0x11); <answer> 0xbb, 
<token> 0xbc, 0x00, 0x00); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, <token> 0x02); <answer> 0xb6, 
mipi_dsi_generic_write_seq(dsi, 0xf0, 0x55, 0xaa, <token> 0x08, 0x01); <answer> 0x52, 
mipi_dsi_generic_write_seq(dsi, <token> 0x09, 0x09); <answer> 0xb0, 
mipi_dsi_generic_write_seq(dsi, 0xb1, <token> 0x09); <answer> 0x09, 
mipi_dsi_generic_write_seq(dsi, 0xbc, <token> 0x00); <answer> 0x8c, 
<token> 0xbd, 0x8c, 0x00); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xca, <token> <answer> 0x00); 
mipi_dsi_generic_write_seq(dsi, <token> 0x04); <answer> 0xc0, 
<token> 0xbe, 0xb5); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xb3, <token> 0x35); <answer> 0x35, 
mipi_dsi_generic_write_seq(dsi, 0xb4, <token> 0x25); <answer> 0x25, 
mipi_dsi_generic_write_seq(dsi, 0xb9, <token> 0x43); <answer> 0x43, 
mipi_dsi_generic_write_seq(dsi, 0xba, <token> 0x24); <answer> 0x24, 
mipi_dsi_generic_write_seq(dsi, 0xf0, <token> 0xaa, 0x52, 0x08, 0x02); <answer> 0x55, 
mipi_dsi_generic_write_seq(dsi, 0xee, <token> <answer> 0x03); 
mipi_dsi_generic_write_seq(dsi, <token> <answer> 0xb0, 
0x00, <token> 0x00, 0xb3, 0x00, 0xb6, 0x00, 0xc3, <answer> 0xb2, 
0x00, 0xce, 0x00, 0xe1, 0x00, 0xf3, <token> 0x11); <answer> 0x01, 
mipi_dsi_generic_write_seq(dsi, <token> <answer> 0xb1, 
0x01, 0x2e, 0x01, 0x5c, 0x01, 0x82, <token> 0xc3, <answer> 0x01, 
0x01, 0xfe, 0x02, 0x00, 0x02, 0x37, <token> 0x77); <answer> 0x02, 
mipi_dsi_generic_write_seq(dsi, <token> <answer> 0xb2, 
0x02, 0xa1, 0x02, 0xd7, 0x02, <token> 0x03, 0x2c, <answer> 0xfe, 
0x03, 0x4b, 0x03, 0x63, 0x03, <token> 0x03, 0x90); <answer> 0x8f, 
mipi_dsi_generic_write_seq(dsi, 0xb3, 0x03, 0x96, 0x03, <token> <answer> 0x98); 
mipi_dsi_generic_write_seq(dsi, <token> <answer> 0xb4, 
0x00, 0x81, 0x00, 0x8b, 0x00, 0x9c, <token> 0xa9, <answer> 0x00, 
0x00, 0xb5, 0x00, 0xcb, <token> 0xdf, 0x01, 0x02); <answer> 0x00, 
<token> 0xb5, <answer> mipi_dsi_generic_write_seq(dsi, 
0x01, 0x1f, 0x01, 0x51, 0x01, 0x7a, 0x01, <token> <answer> 0xbf, 
0x01, 0xfa, 0x01, 0xfc, 0x02, 0x34, 0x02, <token> <answer> 0x76); 
mipi_dsi_generic_write_seq(dsi, <token> <answer> 0xb6, 
0x02, 0x9f, 0x02, 0xd7, 0x02, <token> 0x03, 0x2c, <answer> 0xfc, 
0x03, 0x4a, 0x03, 0x63, 0x03, 0x8f, 0x03, <token> <answer> 0xa2); 
mipi_dsi_generic_write_seq(dsi, 0xb7, <token> 0xb8, 0x03, 0xba); <answer> 0x03, 
<token> 0xb8, <answer> mipi_dsi_generic_write_seq(dsi, 
0x00, 0x01, <token> 0x02, 0x00, 0x0e, 0x00, 0x2a, <answer> 0x00, 
0x00, 0x41, 0x00, 0x67, 0x00, 0x87, 0x00, <token> <answer> 0xb9); 
mipi_dsi_generic_write_seq(dsi, <token> <answer> 0xb9, 
0x00, 0xe2, 0x01, 0x22, 0x01, 0x54, <token> 0xa3, <answer> 0x01, 
<token> 0xe6, 0x01, 0xe7, 0x02, 0x24, 0x02, 0x67); <answer> 0x01, 
mipi_dsi_generic_write_seq(dsi, <token> <answer> 0xba, 
0x02, 0x93, 0x02, <token> 0x02, 0xf6, 0x03, 0x31, <answer> 0xcd, 
0x03, 0x6c, 0x03, 0xe9, 0x03, <token> 0x03, 0xf4); <answer> 0xef, 
mipi_dsi_generic_write_seq(dsi, <token> 0x03, 0xf6, 0x03, 0xf7); <answer> 0xbb, 
mipi_dsi_generic_write_seq(dsi, 0xf0, 0x55, 0xaa, <token> 0x08, 0x03); <answer> 0x52, 
<token> 0xb0, 0x22, 0x00); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, <token> 0x22, 0x00); <answer> 0xb1, 
mipi_dsi_generic_write_seq(dsi, 0xb2, <token> 0x00, 0x60, 0x00, 0x00); <answer> 0x05, 
mipi_dsi_generic_write_seq(dsi, 0xb3, <token> 0x00, 0x60, 0x00, 0x00); <answer> 0x05, 
mipi_dsi_generic_write_seq(dsi, 0xb4, 0x05, 0x00, 0x60, 0x00, <token> <answer> 0x00); 
mipi_dsi_generic_write_seq(dsi, <token> 0x05, 0x00, 0x60, 0x00, 0x00); <answer> 0xb5, 
mipi_dsi_generic_write_seq(dsi, 0xba, 0x53, <token> 0x60, 0x00, 0x00); <answer> 0x00, 
mipi_dsi_generic_write_seq(dsi, 0xbb, 0x53, 0x00, <token> 0x00, 0x00); <answer> 0x60, 
mipi_dsi_generic_write_seq(dsi, 0xbc, <token> 0x00, 0x60, 0x00, 0x00); <answer> 0x53, 
mipi_dsi_generic_write_seq(dsi, 0xbd, 0x53, 0x00, 0x60, 0x00, <token> <answer> 0x00); 
mipi_dsi_generic_write_seq(dsi, <token> 0x00, 0x34, 0x00, 0x00); <answer> 0xc0, 
mipi_dsi_generic_write_seq(dsi, 0xc1, 0x00, 0x00, 0x34, <token> <answer> 0x00); 
mipi_dsi_generic_write_seq(dsi, 0xc2, 0x00, 0x00, 0x34, <token> <answer> 0x00); 
mipi_dsi_generic_write_seq(dsi, 0xc3, 0x00, <token> 0x34, 0x00); <answer> 0x00, 
mipi_dsi_generic_write_seq(dsi, 0xc4, <token> <answer> 0x60); 
<token> 0xc5, 0xc0); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xc6, 0x00); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, <token> 0x00); <answer> 0xc7, 
mipi_dsi_generic_write_seq(dsi, 0xf0, 0x55, 0xaa, <token> 0x08, 0x05); <answer> 0x52, 
<token> 0xb0, 0x17, 0x06); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xb1, <token> 0x06); <answer> 0x17, 
mipi_dsi_generic_write_seq(dsi, 0xb2, 0x17, <token> <answer> 0x06); 
<token> 0xb3, 0x17, 0x06); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xb4, <token> 0x06); <answer> 0x17, 
mipi_dsi_generic_write_seq(dsi, 0xb5, 0x17, <token> <answer> 0x06); 
mipi_dsi_generic_write_seq(dsi, 0xb6, <token> 0x06); <answer> 0x17, 
mipi_dsi_generic_write_seq(dsi, 0xb7, <token> 0x06); <answer> 0x17, 
mipi_dsi_generic_write_seq(dsi, 0xb8, <token> <answer> 0x00); 
mipi_dsi_generic_write_seq(dsi, 0xb9, <token> 0x03); <answer> 0x00, 
mipi_dsi_generic_write_seq(dsi, <token> 0x00, 0x00); <answer> 0xba, 
<token> 0xbb, 0x02, 0x03); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xbc, 0x02, 0x03); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xbd, 0x03, <token> 0x00, 0x03, 0x03); <answer> 0x03, 
mipi_dsi_generic_write_seq(dsi, <token> 0x0b); <answer> 0xc0, 
<token> 0xc1, 0x09); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xc2, <token> <answer> 0xa6); 
<token> 0xc3, 0x05); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xc4, 0x00); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xc5, 0x02); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xc6, <token> <answer> 0x22); 
<token> 0xc7, 0x03); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, <token> 0x07, 0x20); <answer> 0xc8, 
mipi_dsi_generic_write_seq(dsi, <token> 0x03, 0x20); <answer> 0xc9, 
mipi_dsi_generic_write_seq(dsi, 0xca, 0x01, <token> <answer> 0x60); 
<token> 0xcb, 0x01, 0x60); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xcc, 0x00, 0x00, <token> <answer> 0x02); 
<token> 0xcd, 0x00, 0x00, 0x02); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xce, 0x00, 0x00, <token> <answer> 0x02); 
<token> 0xcf, 0x00, 0x00, 0x02); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xd1, 0x00, <token> 0x01, 0x07, 0x10); <answer> 0x05, 
mipi_dsi_generic_write_seq(dsi, 0xd2, 0x10, 0x05, 0x05, 0x03, <token> <answer> 0x10); 
mipi_dsi_generic_write_seq(dsi, 0xd3, 0x20, <token> 0x43, 0x07, 0x10); <answer> 0x00, 
mipi_dsi_generic_write_seq(dsi, 0xd4, 0x30, <token> 0x43, 0x07, 0x10); <answer> 0x00, 
<token> 0xd0, <answer> mipi_dsi_generic_write_seq(dsi, 
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, <token> <answer> 0x00); 
mipi_dsi_generic_write_seq(dsi, <token> <answer> 0xd5, 
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, <token> <answer> 0x00, 
0x00, <token> 0x00); <answer> 0x00, 
<token> 0xd6, <answer> mipi_dsi_generic_write_seq(dsi, 
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, <token> <answer> 0x00, 
<token> 0x00, 0x00); <answer> 0x00, 
mipi_dsi_generic_write_seq(dsi, <token> <answer> 0xd7, 
<token> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, <answer> 0x00, 
<token> 0x00, 0x00); <answer> 0x00, 
mipi_dsi_generic_write_seq(dsi, 0xd8, 0x00, 0x00, 0x00, <token> 0x00); <answer> 0x00, 
mipi_dsi_generic_write_seq(dsi, 0xe5, <token> <answer> 0x06); 
mipi_dsi_generic_write_seq(dsi, <token> 0x06); <answer> 0xe6, 
<token> 0xe7, 0x00); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xe8, 0x06); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xe9, <token> <answer> 0x06); 
mipi_dsi_generic_write_seq(dsi, 0xea, <token> <answer> 0x06); 
mipi_dsi_generic_write_seq(dsi, 0xeb, <token> <answer> 0x00); 
mipi_dsi_generic_write_seq(dsi, <token> 0x00); <answer> 0xec, 
mipi_dsi_generic_write_seq(dsi, <token> 0x30); <answer> 0xed, 
mipi_dsi_generic_write_seq(dsi, <token> 0x55, 0xaa, 0x52, 0x08, 0x06); <answer> 0xf0, 
mipi_dsi_generic_write_seq(dsi, 0xb0, 0x31, <token> <answer> 0x31); 
<token> 0xb1, 0x31, 0x31); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xb2, <token> 0x2e); <answer> 0x2d, 
mipi_dsi_generic_write_seq(dsi, <token> 0x31, 0x34); <answer> 0xb3, 
mipi_dsi_generic_write_seq(dsi, 0xb4, 0x29, <token> <answer> 0x2a); 
mipi_dsi_generic_write_seq(dsi, <token> 0x12, 0x10); <answer> 0xb5, 
mipi_dsi_generic_write_seq(dsi, 0xb6, 0x18, <token> <answer> 0x16); 
<token> 0xb7, 0x00, 0x02); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, <token> 0x08, 0x31); <answer> 0xb8, 
<token> 0xb9, 0x31, 0x31); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xba, <token> 0x31); <answer> 0x31, 
mipi_dsi_generic_write_seq(dsi, 0xbb, <token> 0x08); <answer> 0x31, 
mipi_dsi_generic_write_seq(dsi, 0xbc, 0x03, <token> <answer> 0x01); 
mipi_dsi_generic_write_seq(dsi, <token> 0x17, 0x19); <answer> 0xbd, 
mipi_dsi_generic_write_seq(dsi, <token> 0x11, 0x13); <answer> 0xbe, 
mipi_dsi_generic_write_seq(dsi, 0xbf, 0x2a, <token> <answer> 0x29); 
mipi_dsi_generic_write_seq(dsi, 0xc0, <token> 0x31); <answer> 0x34, 
mipi_dsi_generic_write_seq(dsi, 0xc1, 0x2e, <token> <answer> 0x2d); 
mipi_dsi_generic_write_seq(dsi, <token> 0x31, 0x31); <answer> 0xc2, 
mipi_dsi_generic_write_seq(dsi, <token> 0x31, 0x31); <answer> 0xc3, 
mipi_dsi_generic_write_seq(dsi, <token> 0x31, 0x31); <answer> 0xc4, 
mipi_dsi_generic_write_seq(dsi, 0xc5, 0x31, <token> <answer> 0x31); 
mipi_dsi_generic_write_seq(dsi, <token> 0x2e, 0x2d); <answer> 0xc6, 
mipi_dsi_generic_write_seq(dsi, <token> 0x31, 0x34); <answer> 0xc7, 
mipi_dsi_generic_write_seq(dsi, 0xc8, <token> 0x2a); <answer> 0x29, 
mipi_dsi_generic_write_seq(dsi, 0xc9, <token> 0x19); <answer> 0x17, 
mipi_dsi_generic_write_seq(dsi, 0xca, 0x11, <token> <answer> 0x13); 
<token> 0xcb, 0x03, 0x01); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xcc, 0x08, <token> <answer> 0x31); 
<token> 0xcd, 0x31, 0x31); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xce, 0x31, 0x31); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xcf, 0x31, 0x08); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xd0, 0x00, 0x02); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, <token> 0x12, 0x10); <answer> 0xd1, 
mipi_dsi_generic_write_seq(dsi, <token> 0x18, 0x16); <answer> 0xd2, 
<token> 0xd3, 0x2a, 0x29); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xd4, <token> 0x31); <answer> 0x34, 
<token> 0xd5, 0x2d, 0x2e); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xd6, 0x31, 0x31); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xd7, <token> 0x31); <answer> 0x31, 
mipi_dsi_generic_write_seq(dsi, 0xe5, 0x31, <token> <answer> 0x31); 
mipi_dsi_generic_write_seq(dsi, 0xe6, 0x31, <token> <answer> 0x31); 
mipi_dsi_generic_write_seq(dsi, 0xd8, 0x00, 0x00, 0x00, 0x00, <token> <answer> 0x00); 
mipi_dsi_generic_write_seq(dsi, 0xd9, 0x00, <token> 0x00, 0x00, 0x00); <answer> 0x00, 
<token> 0xe7, 0x00); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0x6f, 0x02); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xf7, 0x47); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0x6f, <token> <answer> 0x0a); 
mipi_dsi_generic_write_seq(dsi, 0xf7, <token> <answer> 0x02); 
mipi_dsi_generic_write_seq(dsi, 0x6f, <token> <answer> 0x17); 
mipi_dsi_generic_write_seq(dsi, <token> 0x60); <answer> 0xf4, 
<token> 0x6f, 0x01); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xf9, 0x46); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0x6f, 0x11); <answer> mipi_dsi_generic_write_seq(dsi, 
<token> 0xf3, 0x01); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, <token> 0x00); <answer> 0x35, 
<token> 0xf0, 0x55, 0xaa, 0x52, 0x08, 0x00); <answer> mipi_dsi_generic_write_seq(dsi, 
mipi_dsi_generic_write_seq(dsi, 0xd9, 0x02, <token> 0x00); <answer> 0x03, 
mipi_dsi_generic_write_seq(dsi, 0xf0, <token> 0xaa, 0x52, 0x00, 0x00); <answer> 0x55, 
mipi_dsi_generic_write_seq(dsi, 0xf0, 0x55, <token> 0x52, 0x08, 0x00); <answer> 0xaa, 
mipi_dsi_generic_write_seq(dsi, 0xb1, 0x6c, <token> <answer> 0x21); 
mipi_dsi_generic_write_seq(dsi, 0xf0, 0x55, 0xaa, 0x52, <token> 0x00); <answer> 0x00, 
<token> 0x35, 0x00); <answer> mipi_dsi_generic_write_seq(dsi, 
ret = <token> <answer> mipi_dsi_dcs_exit_sleep_mode(dsi); 
<token> (ret < 0) { <answer> if 
dev_err(dev, "Failed to <token> sleep mode: %d\n", ret); <answer> exit 
<token> ret; <answer> return 
ret = <token> <answer> mipi_dsi_dcs_set_display_on(dsi); 
if (ret < 0) <token> <answer> { 
dev_err(dev, <token> to set display on: %d\n", ret); <answer> "Failed 
<token> ret; <answer> return 
<token> 2000); <answer> usleep_range(1000, 
mipi_dsi_generic_write_seq(dsi, <token> 0x24); <answer> 0x53, 
return <token> <answer> 0; 
static int truly_nt35521_off(struct <token> *ctx) <answer> truly_nt35521 
struct mipi_dsi_device *dsi <token> ctx->dsi; <answer> = 
struct device <token> = &dsi->dev; <answer> *dev 
int <token> <answer> ret; 
<token> &= ~MIPI_DSI_MODE_LPM; <answer> dsi->mode_flags 
ret = <token> <answer> mipi_dsi_dcs_set_display_off(dsi); 
if (ret <token> 0) { <answer> < 
dev_err(dev, "Failed <token> set display off: %d\n", ret); <answer> to 
<token> ret; <answer> return 
ret <token> mipi_dsi_dcs_enter_sleep_mode(dsi); <answer> = 
<token> (ret < 0) { <answer> if 
<token> "Failed to enter sleep mode: %d\n", ret); <answer> dev_err(dev, 
return <token> <answer> ret; 
<token> 0; <answer> return 
<token> int truly_nt35521_prepare(struct drm_panel *panel) <answer> static 
struct <token> *ctx = to_truly_nt35521(panel); <answer> truly_nt35521 
struct device *dev <token> &ctx->dsi->dev; <answer> = 
int <token> <answer> ret; 
ret = <token> ctx->supplies); <answer> regulator_bulk_enable(ARRAY_SIZE(ctx->supplies), 
if (ret < 0) <token> <answer> { 
dev_err(dev, "Failed <token> enable regulators: %d\n", ret); <answer> to 
return <token> <answer> ret; 
ret <token> truly_nt35521_on(ctx); <answer> = 
if <token> < 0) { <answer> (ret 
dev_err(dev, "Failed to initialize panel: <token> ret); <answer> %d\n", 
gpiod_set_value_cansleep(ctx->reset_gpio, <token> <answer> 1); 
return <token> <answer> ret; 
return <token> <answer> 0; 
static int <token> drm_panel *panel) <answer> truly_nt35521_unprepare(struct 
struct truly_nt35521 *ctx = <token> <answer> to_truly_nt35521(panel); 
struct device *dev = <token> <answer> &ctx->dsi->dev; 
<token> ret; <answer> int 
ret <token> truly_nt35521_off(ctx); <answer> = 
if (ret < <token> <answer> 0) 
dev_err(dev, "Failed to un-initialize <token> %d\n", ret); <answer> panel: 
<token> 1); <answer> gpiod_set_value_cansleep(ctx->reset_gpio, 
<token> 0; <answer> return 
<token> int truly_nt35521_enable(struct drm_panel *panel) <answer> static 
struct <token> *ctx = to_truly_nt35521(panel); <answer> truly_nt35521 
gpiod_set_value_cansleep(ctx->blen_gpio, <token> <answer> 1); 
return <token> <answer> 0; 
static int <token> drm_panel *panel) <answer> truly_nt35521_disable(struct 
struct truly_nt35521 *ctx <token> to_truly_nt35521(panel); <answer> = 
<token> 0); <answer> gpiod_set_value_cansleep(ctx->blen_gpio, 
<token> 0; <answer> return 
static const struct drm_display_mode <token> = { <answer> truly_nt35521_mode 
.clock = (720 + 232 + 20 + 112) * (1280 + 18 + 1 + <token> * 60 / 1000, <answer> 18) 
.hdisplay <token> 720, <answer> = 
.hsync_start = <token> + 232, <answer> 720 
.hsync_end = <token> + 232 + 20, <answer> 720 
.htotal = 720 + <token> + 20 + 112, <answer> 232 
<token> = 1280, <answer> .vdisplay 
.vsync_start = <token> + 18, <answer> 1280 
.vsync_end <token> 1280 + 18 + 1, <answer> = 
.vtotal = 1280 + 18 + 1 <token> 18, <answer> + 
<token> = 65, <answer> .width_mm 
.height_mm = <token> <answer> 116, 
static int <token> drm_panel *panel, <answer> truly_nt35521_get_modes(struct 
<token> drm_connector *connector) <answer> struct 
<token> drm_display_mode *mode; <answer> struct 
mode = <token> &truly_nt35521_mode); <answer> drm_mode_duplicate(connector->dev, 
if <token> <answer> (!mode) 
<token> -ENOMEM; <answer> return 
mode->type = DRM_MODE_TYPE_DRIVER | <token> <answer> DRM_MODE_TYPE_PREFERRED; 
connector->display_info.width_mm = <token> <answer> mode->width_mm; 
<token> = mode->height_mm; <answer> connector->display_info.height_mm 
drm_mode_probed_add(connector, <token> <answer> mode); 
<token> 1; <answer> return 
static const struct drm_panel_funcs truly_nt35521_panel_funcs <token> { <answer> = 
.prepare = <token> <answer> truly_nt35521_prepare, 
.unprepare = <token> <answer> truly_nt35521_unprepare, 
.enable = <token> <answer> truly_nt35521_enable, 
<token> = truly_nt35521_disable, <answer> .disable 
.get_modes <token> truly_nt35521_get_modes, <answer> = 
<token> int truly_nt35521_bl_update_status(struct backlight_device *bl) <answer> static 
struct mipi_dsi_device *dsi <token> bl_get_data(bl); <answer> = 
u16 brightness <token> backlight_get_brightness(bl); <answer> = 
int <token> <answer> ret; 
ret = <token> brightness); <answer> mipi_dsi_dcs_set_display_brightness(dsi, 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
return <token> <answer> 0; 
static int truly_nt35521_bl_get_brightness(struct <token> *bl) <answer> backlight_device 
struct mipi_dsi_device *dsi = <token> <answer> bl_get_data(bl); 
u16 <token> <answer> brightness; 
int <token> <answer> ret; 
ret <token> mipi_dsi_dcs_get_display_brightness(dsi, &brightness); <answer> = 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
return brightness <token> 0xff; <answer> & 
static const struct backlight_ops truly_nt35521_bl_ops <token> { <answer> = 
<token> = truly_nt35521_bl_update_status, <answer> .update_status 
.get_brightness = <token> <answer> truly_nt35521_bl_get_brightness, 
static <token> backlight_device * <answer> struct 
<token> mipi_dsi_device *dsi) <answer> truly_nt35521_create_backlight(struct 
struct device *dev <token> &dsi->dev; <answer> = 
<token> struct backlight_properties props = { <answer> const 
.type = <token> <answer> BACKLIGHT_RAW, 
.brightness <token> 255, <answer> = 
.max_brightness <token> 255, <answer> = 
return devm_backlight_device_register(dev, dev_name(dev), dev, <token> <answer> dsi, 
<token> &props); <answer> &truly_nt35521_bl_ops, 
<token> int truly_nt35521_probe(struct mipi_dsi_device *dsi) <answer> static 
struct <token> *dev = &dsi->dev; <answer> device 
struct <token> *ctx; <answer> truly_nt35521 
<token> ret; <answer> int 
ctx <token> devm_kzalloc(dev, sizeof(*ctx), GFP_KERNEL); <answer> = 
if <token> <answer> (!ctx) 
<token> -ENOMEM; <answer> return 
ctx->supplies[0].supply = <token> <answer> "positive5"; 
ctx->supplies[1].supply = <token> <answer> "negative5"; 
<token> = devm_regulator_bulk_get(dev, ARRAY_SIZE(ctx->supplies), <answer> ret 
if (ret < 0) <token> <answer> { 
dev_err(dev, "Failed to <token> regulators: %d\n", ret); <answer> get 
return <token> <answer> ret; 
ctx->reset_gpio = <token> "reset", GPIOD_OUT_HIGH); <answer> devm_gpiod_get(dev, 
<token> (IS_ERR(ctx->reset_gpio)) <answer> if 
return <token> PTR_ERR(ctx->reset_gpio), <answer> dev_err_probe(dev, 
"Failed <token> get reset-gpios\n"); <answer> to 
ctx->blen_gpio <token> devm_gpiod_get(dev, "backlight", GPIOD_OUT_LOW); <answer> = 
if <token> <answer> (IS_ERR(ctx->blen_gpio)) 
<token> dev_err_probe(dev, PTR_ERR(ctx->blen_gpio), <answer> return 
"Failed to <token> backlight-gpios\n"); <answer> get 
ctx->dsi <token> dsi; <answer> = 
mipi_dsi_set_drvdata(dsi, <token> <answer> ctx); 
<token> = 4; <answer> dsi->lanes 
<token> = MIPI_DSI_FMT_RGB888; <answer> dsi->format 
dsi->mode_flags <token> MIPI_DSI_MODE_VIDEO | MIPI_DSI_MODE_VIDEO_BURST | <answer> = 
MIPI_DSI_MODE_VIDEO_HSE | <token> | <answer> MIPI_DSI_MODE_NO_EOT_PACKET 
drm_panel_init(&ctx->panel, <token> &truly_nt35521_panel_funcs, <answer> dev, 
<token> = truly_nt35521_create_backlight(dsi); <answer> ctx->panel.backlight 
<token> (IS_ERR(ctx->panel.backlight)) <answer> if 
<token> dev_err_probe(dev, PTR_ERR(ctx->panel.backlight), <answer> return 
<token> to create backlight\n"); <answer> "Failed 
ret = <token> <answer> mipi_dsi_attach(dsi); 
if (ret < 0) <token> <answer> { 
dev_err(dev, <token> to attach to DSI host: %d\n", ret); <answer> "Failed 
return <token> <answer> ret; 
return <token> <answer> 0; 
static void <token> mipi_dsi_device *dsi) <answer> truly_nt35521_remove(struct 
struct truly_nt35521 *ctx = <token> <answer> mipi_dsi_get_drvdata(dsi); 
<token> ret; <answer> int 
ret = <token> <answer> mipi_dsi_detach(dsi); 
if (ret <token> 0) <answer> < 
dev_err(&dsi->dev, "Failed to detach from <token> host: %d\n", ret); <answer> DSI 
static const <token> of_device_id truly_nt35521_of_match[] = { <answer> struct 
{ .compatible <token> "sony,tulip-truly-nt35521" }, <answer> = 
#include <token> <answer> <linux/sched/clock.h> 
#include <token> <answer> <linux/sysfs.h> 
#include <token> <answer> "v3d_drv.h" 
<token> ssize_t <answer> static 
gpu_stats_show(struct device *dev, struct <token> *attr, char *buf) <answer> device_attribute 
<token> drm_device *drm = dev_get_drvdata(dev); <answer> struct 
struct v3d_dev *v3d <token> to_v3d_dev(drm); <answer> = 
enum v3d_queue <token> <answer> queue; 
u64 <token> = local_clock(); <answer> timestamp 
u64 <token> <answer> active_runtime; 
ssize_t <token> = 0; <answer> len 
len += <token> "queue\ttimestamp\tjobs\truntime\n"); <answer> sysfs_emit(buf, 
for <token> = 0; queue < V3D_MAX_QUEUES; queue++) { <answer> (queue 
<token> (v3d->queue[queue].start_ns) <answer> if 
<token> = timestamp - v3d->queue[queue].start_ns; <answer> active_runtime 
active_runtime = <token> <answer> 0; 
len += sysfs_emit_at(buf, <token> "%s\t%llu\t%llu\t%llu\n", <answer> len, 
v3d->queue[queue].enabled_ns <token> active_runtime); <answer> + 
return <token> <answer> len; 
static <token> <answer> DEVICE_ATTR_RO(gpu_stats); 
<token> struct attribute *v3d_sysfs_entries[] = { <answer> static 
static struct attribute_group <token> = { <answer> v3d_sysfs_attr_group 
.attrs = <token> <answer> v3d_sysfs_entries, 
v3d_sysfs_init(struct <token> *dev) <answer> device 
<token> sysfs_create_group(&dev->kobj, &v3d_sysfs_attr_group); <answer> return 
v3d_sysfs_destroy(struct <token> *dev) <answer> device 
<token> sysfs_remove_group(&dev->kobj, &v3d_sysfs_attr_group); <answer> return 
<token> <linux/module.h> <answer> #include 
<token> <linux/moduleparam.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/slab.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/pm.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/regulator/consumer.h> <answer> #include 
#include <token> <answer> <linux/mfd/wm8400-audio.h> 
<token> <linux/mfd/wm8400-private.h> <answer> #include 
#include <token> <answer> <linux/mfd/core.h> 
#include <token> <answer> <sound/core.h> 
#include <token> <answer> <sound/pcm.h> 
#include <token> <answer> <sound/pcm_params.h> 
<token> <sound/soc.h> <answer> #include 
#include <token> <answer> <sound/initval.h> 
#include <token> <answer> <sound/tlv.h> 
#include <token> <answer> "wm8400.h" 
static <token> regulator_bulk_data power[] = { <answer> struct 
.supply = <token> <answer> "I2S1VDD", 
<token> = "I2S2VDD", <answer> .supply 
.supply <token> "DCVDD", <answer> = 
<token> = "AVDD", <answer> .supply 
.supply <token> "FLLVDD", <answer> = 
.supply <token> "HPVDD", <answer> = 
<token> = "SPKVDD", <answer> .supply 
static int <token> (struct snd_soc_dapm_widget *w, <answer> outmixer_event 
<token> snd_kcontrol * kcontrol, int event) <answer> struct 
<token> snd_soc_component *component = snd_soc_dapm_to_component(w->dapm); <answer> struct 
<token> soc_mixer_control *mc = <answer> struct 
<token> soc_mixer_control *)kcontrol->private_value; <answer> (struct 
u32 reg_shift <token> mc->shift; <answer> = 
<token> ret = 0; <answer> int 
<token> reg; <answer> u16 
<token> (reg_shift) { <answer> switch 
case WM8400_SPEAKER_MIXER <token> (WM8400_LDSPK << 8) : <answer> | 
reg <token> snd_soc_component_read(component, WM8400_OUTPUT_MIXER1); <answer> = 
if (reg & WM8400_LDLO) <token> <answer> { 
"Cannot set <token> Output Mixer 1 LDLO Set\n"); <answer> as 
ret = <token> <answer> -1; 
case <token> | (WM8400_RDSPK << 8): <answer> WM8400_SPEAKER_MIXER 
reg = snd_soc_component_read(component, <token> <answer> WM8400_OUTPUT_MIXER2); 
if (reg & WM8400_RDRO) <token> <answer> { 
"Cannot set as Output Mixer <token> RDRO Set\n"); <answer> 2 
ret = <token> <answer> -1; 
case WM8400_OUTPUT_MIXER1 <token> (WM8400_LDLO << 8): <answer> | 
reg = snd_soc_component_read(component, <token> <answer> WM8400_SPEAKER_MIXER); 
if (reg & WM8400_LDSPK) <token> <answer> { 
"Cannot set as <token> Mixer LDSPK Set\n"); <answer> Speaker 
ret = <token> <answer> -1; 
case WM8400_OUTPUT_MIXER2 <token> (WM8400_RDRO << 8): <answer> | 
reg = snd_soc_component_read(component, <token> <answer> WM8400_SPEAKER_MIXER); 
if (reg & WM8400_RDSPK) <token> <answer> { 
<token> set as Speaker Mixer RDSPK Set\n"); <answer> "Cannot 
ret = <token> <answer> -1; 
return <token> <answer> ret; 
{"Left ADC", <token> "Internal ADC Source"}, <answer> NULL, 
{"Right ADC", NULL, "Internal ADC <token> <answer> Source"}, 
<token> int wm8400_set_dai_sysclk(struct snd_soc_dai *codec_dai, <answer> static 
int clk_id, unsigned int freq, int <token> <answer> dir) 
struct <token> *component = codec_dai->component; <answer> snd_soc_component 
struct wm8400_priv *wm8400 = <token> <answer> snd_soc_component_get_drvdata(component); 
<token> = freq; <answer> wm8400->sysclk 
return <token> <answer> 0; 
<token> fll_factors { <answer> struct 
u16 <token> <answer> n; 
<token> k; <answer> u16 
u16 <token> <answer> outdiv; 
u16 <token> <answer> fratio; 
<token> freq_ref; <answer> u16 
#define FIXED_FLL_SIZE <token> << 16) * 10) <answer> ((1 
static int fll_factors(struct wm8400_priv *wm8400, struct <token> *factors, <answer> fll_factors 
unsigned int Fref, unsigned <token> Fout) <answer> int 
u64 <token> <answer> Kpart; 
unsigned int K, Nmod, <token> <answer> target; 
factors->outdiv = <token> <answer> 2; 
while (Fout <token> factors->outdiv < 90000000 || <answer> * 
Fout * factors->outdiv > <token> { <answer> 100000000) 
factors->outdiv *= <token> <answer> 2; 
<token> (factors->outdiv > 32) { <answer> if 
"Unsupported <token> output frequency %uHz\n", <answer> FLL 
<token> -EINVAL; <answer> return 
target = Fout * <token> <answer> factors->outdiv; 
factors->outdiv = factors->outdiv >> <token> <answer> 2; 
if (Fref <token> 48000) <answer> < 
factors->freq_ref <token> 1; <answer> = 
factors->freq_ref <token> 0; <answer> = 
if <token> < 1000000) <answer> (Fref 
<token> = 9; <answer> factors->fratio 
factors->fratio <token> 0; <answer> = 
memset(&factors, <token> sizeof(factors)); <answer> 0, 
wm8400->fll_out = <token> <answer> freq_out; 
<token> = freq_in; <answer> wm8400->fll_in 
<token> int wm8400_set_dai_fmt(struct snd_soc_dai *codec_dai, <answer> static 
unsigned int <token> <answer> fmt) 
struct <token> *component = codec_dai->component; <answer> snd_soc_component 
u16 <token> audio3; <answer> audio1, 
<token> = snd_soc_component_read(component, WM8400_AUDIO_INTERFACE_1); <answer> audio1 
<token> = snd_soc_component_read(component, WM8400_AUDIO_INTERFACE_3); <answer> audio3 
static <token> wm8400_hw_params(struct snd_pcm_substream *substream, <answer> int 
struct <token> *params, <answer> snd_pcm_hw_params 
struct snd_soc_dai <token> <answer> *dai) 
struct snd_soc_component *component = <token> <answer> dai->component; 
u16 audio1 = <token> WM8400_AUDIO_INTERFACE_1); <answer> snd_soc_component_read(component, 
<token> &= ~WM8400_AIF_WL_MASK; <answer> audio1 
static struct snd_soc_dai_driver wm8400_dai <token> { <answer> = 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/export.h> 
#include <token> <answer> <linux/mm.h> 
#include <token> <answer> <linux/kdev_t.h> 
#include <token> <answer> <linux/gfp.h> 
#include <token> <answer> <linux/bio.h> 
#include <token> <answer> <linux/fs.h> 
#include <token> <answer> <linux/buffer_head.h> 
<token> <linux/blkdev.h> <answer> #include 
#include <token> <answer> <linux/highmem.h> 
<token> <linux/prefetch.h> <answer> #include 
<token> <linux/mpage.h> <answer> #include 
<token> <linux/writeback.h> <answer> #include 
#include <token> <answer> <linux/backing-dev.h> 
#include <token> <answer> <linux/pagevec.h> 
<token> "ext4.h" <answer> #include 
<token> NUM_PREALLOC_POST_READ_CTXS 128 <answer> #define 
<token> struct kmem_cache *bio_post_read_ctx_cache; <answer> static 
static mempool_t <token> <answer> *bio_post_read_ctx_pool; 
BUILD_BUG_ON(STEP_VERITY + <token> != STEP_MAX); <answer> 1 
mempool_free(ctx, <token> <answer> bio_post_read_ctx_pool); 
bio->bi_private <token> NULL; <answer> = 
static <token> bio_post_read_processing(struct bio_post_read_ctx *ctx) <answer> void 
switch (++ctx->cur_step) <token> <answer> { 
case <token> <answer> STEP_DECRYPT: 
if (ctx->enabled_steps & <token> << STEP_DECRYPT)) { <answer> (1 
INIT_WORK(&ctx->work, <token> <answer> decrypt_work); 
case <token> <answer> STEP_VERITY: 
if (ctx->enabled_steps & <token> << STEP_VERITY)) { <answer> (1 
<token> verity_work); <answer> INIT_WORK(&ctx->work, 
static bool bio_post_read_required(struct <token> *bio) <answer> bio 
return bio->bi_private <token> !bio->bi_status; <answer> && 
static <token> mpage_end_io(struct bio *bio) <answer> void 
if (bio_post_read_required(bio)) <token> <answer> { 
struct bio_post_read_ctx <token> = bio->bi_private; <answer> *ctx 
ctx->cur_step <token> STEP_INITIAL; <answer> = 
<token> inline bool ext4_need_verity(const struct inode *inode, pgoff_t idx) <answer> static 
return <token> && <answer> fsverity_active(inode) 
idx < DIV_ROUND_UP(inode->i_size, <token> <answer> PAGE_SIZE); 
static <token> ext4_set_bio_post_read_ctx(struct bio *bio, <answer> void 
<token> struct inode *inode, <answer> const 
<token> first_idx) <answer> pgoff_t 
unsigned int post_read_steps <token> 0; <answer> = 
if <token> <answer> (fscrypt_inode_uses_fs_layer_crypto(inode)) 
post_read_steps |= 1 <token> STEP_DECRYPT; <answer> << 
if (ext4_need_verity(inode, <token> <answer> first_idx)) 
post_read_steps |= <token> << STEP_VERITY; <answer> 1 
<token> (post_read_steps) { <answer> if 
if ((map.m_flags <token> EXT4_MAP_MAPPED) && <answer> & 
<token> > map.m_lblk && <answer> block_in_file 
block_in_file <token> (map.m_lblk + map.m_len)) { <answer> < 
unsigned <token> = block_in_file - map.m_lblk; <answer> map_offset 
unsigned last <token> map.m_len - map_offset; <answer> = 
for (relative_block <token> 0; ; relative_block++) { <answer> = 
if <token> == last) { <answer> (relative_block 
while (page_block < blocks_per_page) <token> <answer> { 
if <token> < last_block) { <answer> (block_in_file 
map.m_lblk = <token> <answer> block_in_file; 
map.m_len = <token> - block_in_file; <answer> last_block 
if (ext4_map_blocks(NULL, inode, &map, 0) < <token> { <answer> 0) 
<token> 0, <answer> folio_zero_segment(folio, 
<token> next_page; <answer> goto 
if ((map.m_flags & EXT4_MAP_MAPPED) <token> 0) { <answer> == 
<token> = 0; <answer> fully_mapped 
if (first_hole == <token> <answer> blocks_per_page) 
<token> = page_block; <answer> first_hole 
if (first_hole != <token> <answer> blocks_per_page) 
if (bio && (last_block_in_bio != blocks[0] <token> 1 || <answer> - 
<token> inode, next_block))) { <answer> !fscrypt_mergeable_bio(bio, 
<token> = NULL; <answer> bio 
<token> (bio == NULL) { <answer> if 
<token> = bio_alloc(bdev, bio_max_segs(nr_pages), <answer> bio 
<token> GFP_KERNEL); <answer> REQ_OP_READ, 
fscrypt_set_bio_crypt_ctx(bio, <token> next_block, <answer> inode, 
<token> inode, folio->index); <answer> ext4_set_bio_post_read_ctx(bio, 
bio->bi_iter.bi_sector = blocks[0] << <token> - 9); <answer> (blkbits 
bio->bi_end_io = <token> <answer> mpage_end_io; 
if <token> <answer> (rac) 
bio->bi_opf |= <token> <answer> REQ_RAHEAD; 
length <token> first_hole << blkbits; <answer> = 
if (!bio_add_folio(bio, folio, length, <token> <answer> 0)) 
goto <token> <answer> submit_and_realloc; 
if (((map.m_flags & <token> && <answer> EXT4_MAP_BOUNDARY) 
(relative_block == <token> || <answer> map.m_len)) 
(first_hole <token> blocks_per_page)) { <answer> != 
bio <token> NULL; <answer> = 
} <token> <answer> else 
last_block_in_bio = <token> - 1]; <answer> blocks[blocks_per_page 
<token> (bio) { <answer> if 
bio <token> NULL; <answer> = 
<token> (!folio_test_uptodate(folio)) <answer> if 
<token> ext4_get_block); <answer> block_read_full_folio(folio, 
#define pr_fmt(fmt) <token> ": " fmt <answer> KBUILD_MODNAME 
<token> <linux/videodev2.h> <answer> #include 
<token> <linux/mutex.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/bitrev.h> 
<token> "tuner-i2c.h" <answer> #include 
#include <token> <answer> "r820t.h" 
#define <token> 5 <answer> REG_SHADOW_START 
#define NUM_REGS <token> <answer> 27 
<token> NUM_IMR 5 <answer> #define 
<token> IMR_TRIAL 9 <answer> #define 
#define <token> 49 <answer> VER_NUM 
static int <token> <answer> debug; 
module_param(debug, <token> 0644); <answer> int, 
<token> "enable verbose debug messages"); <answer> MODULE_PARM_DESC(debug, 
static int <token> <answer> no_imr_cal; 
module_param(no_imr_cal, <token> 0444); <answer> int, 
<token> "Disable IMR calibration at module init"); <answer> MODULE_PARM_DESC(no_imr_cal, 
<token> xtal_cap_value { <answer> enum 
XTAL_LOW_CAP_30P <token> 0, <answer> = 
struct <token> { <answer> r820t_sect_type 
u8 <token> <answer> phase_y; 
<token> gain_x; <answer> u8 
<token> value; <answer> u16 
struct r820t_priv <token> <answer> { 
<token> list_head hybrid_tuner_instance_list; <answer> struct 
<token> struct r820t_config *cfg; <answer> const 
struct tuner_i2c_props <token> <answer> i2c_props; 
struct mutex <token> <answer> lock; 
<token> regs[NUM_REGS]; <answer> u8 
u8 buf[NUM_REGS + <token> <answer> 1]; 
enum xtal_cap_value <token> <answer> xtal_cap_sel; 
static <token> <answer> LIST_HEAD(hybrid_tuner_instance_list); 
static <token> <answer> DEFINE_MUTEX(r820t_list_mutex); 
static void shadow_store(struct r820t_priv *priv, u8 reg, <token> u8 *val, <answer> const 
<token> len) <answer> int 
int r <token> reg - REG_SHADOW_START; <answer> = 
if (r < <token> { <answer> 0) 
len += <token> <answer> r; 
<token> = 0; <answer> r 
if (len <token> 0) <answer> <= 
if (len > NUM_REGS - <token> <answer> r) 
len = NUM_REGS - <token> <answer> r; 
tuner_dbg("%s: prev reg=%02x len=%d: <token> <answer> %*ph\n", 
__func__, r + REG_SHADOW_START, <token> len, val); <answer> len, 
memcpy(&priv->regs[r], <token> len); <answer> val, 
static int r820t_write(struct r820t_priv *priv, u8 <token> const u8 *val, <answer> reg, 
int <token> <answer> len) 
int rc, size, pos = <token> <answer> 0; 
static int <token> r820t_priv *priv, u32 freq) <answer> r820t_set_mux(struct 
const struct r820t_freq_range <token> <answer> *range; 
<token> i, rc; <answer> int 
<token> val, reg08, reg09; <answer> u8 
<token> (priv->cfg->rafael_chip != CHIP_R828D) { <answer> if 
if <token> > VCO_POWER_REF) <answer> (vco_fine_tune 
<token> = div_num - 1; <answer> div_num 
else if <token> < VCO_POWER_REF) <answer> (vco_fine_tune 
div_num = div_num <token> 1; <answer> + 
rc = <token> 0x10, div_num << 5, 0xe0); <answer> r820t_write_reg_mask(priv, 
if (rc <token> 0) <answer> < 
return <token> <answer> rc; 
vco_freq <token> freq * mix_div; <answer> = 
<token> = vco_freq / (2 * pll_ref); <answer> nint 
vco_fra = vco_freq - 2 * pll_ref * <token> <answer> nint; 
tuner_dbg("adjusting <token> parameters\n"); <answer> LNA 
if <token> != V4L2_TUNER_ANALOG_TV) { <answer> (type 
<token> = r820t_write_reg_mask(priv, 0x1c, mixer_top, 0x04); <answer> rc 
<token> (rc < 0) <answer> if 
return <token> <answer> rc; 
rc = r820t_write_reg_mask(priv, <token> mixer_top, 0x04); <answer> 0x1c, 
if (rc < <token> <answer> 0) 
return <token> <answer> rc; 
if_khz <token> 4070; <answer> = 
<token> = 60000; <answer> filt_cal_lo 
static const <token> r820t_lna_gain_steps[] = { <answer> int 
0, 9, 13, 40, 38, 13, 31, 22, 26, 31, 26, 14, 19, 5, <token> 13 <answer> 35, 
static const <token> r820t_mixer_gain_steps[] = { <answer> int 
0, 5, 10, 10, 19, 9, 10, 25, 17, 10, 8, 16, 13, <token> 3, -8 <answer> 6, 
static <token> r820t_set_gain_mode(struct r820t_priv *priv, <answer> int 
bool <token> <answer> set_manual_gain, 
int <token> <answer> gain) 
<token> rc; <answer> int 
if (set_manual_gain) <token> <answer> { 
int i, <token> = 0; <answer> total_gain 
uint8_t mix_index = 0, lna_index <token> 0; <answer> = 
u8 <token> <answer> data[4]; 
static int <token> r820t_priv *priv) <answer> r820t_standby(struct 
<token> rc; <answer> int 
static <token> r820t_xtal_check(struct r820t_priv *priv) <answer> int 
int rc, <token> <answer> i; 
u8 <token> val; <answer> data[3], 
<token> (fix_reg == 0x08) <answer> if 
<token> = 0x09; <answer> var_reg 
<token> = 0x08; <answer> var_reg 
for (i = <token> i < 3; i++) { <answer> 0; 
rc = r820t_write_reg(priv, <token> fix_val); <answer> fix_reg, 
if <token> < 0) <answer> (rc 
return <token> <answer> rc; 
<token> = r820t_write_reg(priv, var_reg, var_val); <answer> rc 
if (rc <token> 0) <answer> < 
return <token> <answer> rc; 
<token> = r820t_multi_read(priv); <answer> rc 
<token> (rc < 0) <answer> if 
<token> rc; <answer> return 
<token> = rc; <answer> iq[i].value 
if (fix_reg <token> 0x08) { <answer> == 
iq[i].gain_x = <token> <answer> fix_val; 
<token> = var_val; <answer> iq[i].phase_y 
} else <token> <answer> { 
iq[i].phase_y = <token> <answer> fix_val; 
<token> = var_val; <answer> iq[i].gain_x 
<token> = r820t_section(priv, iq_pont); <answer> rc 
if (rc < <token> <answer> 0) 
return <token> <answer> rc; 
<token> 0; <answer> return 
static int r820t_imr(struct r820t_priv <token> unsigned imr_mem, bool im_flag) <answer> *priv, 
<token> r820t_sect_type imr_point; <answer> struct 
<token> rc; <answer> int 
u32 <token> ring_freq, ring_ref; <answer> ring_vco, 
<token> n_ring, n; <answer> u8 
int reg18, <token> reg1f; <answer> reg19, 
<token> (priv->cfg->xtal > 24000000) <answer> if 
<token> = priv->cfg->xtal / 2000; <answer> ring_ref 
<token> = priv->cfg->xtal / 1000; <answer> ring_ref 
<token> = 15; <answer> n_ring 
for (n = 0; n < 16; <token> { <answer> n++) 
if ((16 + n) * 8 <token> ring_ref >= 3100000) { <answer> * 
<token> = n; <answer> n_ring 
reg18 <token> r820t_read_cache_reg(priv, 0x18); <answer> = 
reg19 = <token> 0x19); <answer> r820t_read_cache_reg(priv, 
reg1f = <token> 0x1f); <answer> r820t_read_cache_reg(priv, 
if <token> { <answer> (no_imr_cal) 
priv->init_done <token> true; <answer> = 
<token> 0; <answer> return 
static int r820t_init(struct <token> *fe) <answer> dvb_frontend 
<token> r820t_priv *priv = fe->tuner_priv; <answer> struct 
int <token> <answer> rc; 
<token> __func__); <answer> tuner_dbg("%s:\n", 
if <token> <answer> (fe->ops.i2c_gate_ctrl) 
<token> 1); <answer> fe->ops.i2c_gate_ctrl(fe, 
rc <token> r820t_imr_callibrate(priv); <answer> = 
<token> (rc < 0) <answer> if 
<token> err; <answer> goto 
#include <token> <answer> <stdio.h> 
<token> <stdlib.h> <answer> #include 
#include <token> <answer> <inttypes.h> 
<token> "annotate.h" <answer> #include 
<token> "annotate-data.h" <answer> #include 
#include <token> <answer> "debuginfo.h" 
#include <token> <answer> "debug.h" 
<token> "dso.h" <answer> #include 
<token> "dwarf-regs.h" <answer> #include 
#include <token> <answer> "evsel.h" 
#include <token> <answer> "evlist.h" 
<token> "map.h" <answer> #include 
<token> "map_symbol.h" <answer> #include 
#include <token> <answer> "strbuf.h" 
#include <token> <answer> "symbol.h" 
<token> "symbol_conf.h" <answer> #include 
static <token> data_type_cmp(const void *_key, const struct rb_node *node) <answer> int 
<token> struct annotated_data_type *key = _key; <answer> const 
struct <token> *type; <answer> annotated_data_type 
type = <token> struct annotated_data_type, node); <answer> rb_entry(node, 
if (key->self.size <token> type->self.size) <answer> != 
return <token> - type->self.size; <answer> key->self.size 
<token> strcmp(key->self.type_name, type->self.type_name); <answer> return 
static <token> data_type_less(struct rb_node *node_a, const struct rb_node *node_b) <answer> bool 
<token> annotated_data_type *a, *b; <answer> struct 
a = rb_entry(node_a, struct annotated_data_type, <token> <answer> node); 
b = <token> struct annotated_data_type, node); <answer> rb_entry(node_b, 
if (a->self.size != <token> <answer> b->self.size) 
<token> a->self.size < b->self.size; <answer> return 
<token> strcmp(a->self.type_name, b->self.type_name) < 0; <answer> return 
off <token> 0; <answer> = 
while (dwarf_nextcu(di->dbg, <token> &next_off, &header_size, <answer> off, 
NULL, NULL, <token> == 0) { <answer> NULL) 
if (dwarf_offdie(di->dbg, off + header_size, cu_die) <token> <answer> && 
dwarf_haspc(cu_die, <token> <answer> pc)) 
<token> true; <answer> return 
off <token> next_off; <answer> = 
<token> false; <answer> return 
if <token> { <answer> (is_pointer) 
<token> ((dwarf_tag(type_die) != DW_TAG_pointer_type && <answer> if 
dwarf_tag(type_die) != <token> || <answer> DW_TAG_array_type) 
die_get_real_type(type_die, type_die) <token> NULL) { <answer> == 
pr_debug("no pointer or no <token> <answer> type\n"); 
return <token> <answer> -1; 
struct annotated_data_type *find_data_type(struct map_symbol *ms, u64 <token> <answer> ip, 
struct annotated_op_loc *loc, <token> addr, <answer> u64 
const char <token> <answer> *var_name) 
struct annotated_data_type <token> = NULL; <answer> *result 
struct <token> *dso = map__dso(ms->map); <answer> dso 
struct <token> *di; <answer> debuginfo 
Dwarf_Die <token> <answer> type_die; 
<token> pc; <answer> u64 
<token> = debuginfo__new(dso->long_name); <answer> di 
if <token> == NULL) { <answer> (di 
pr_debug("cannot <token> the debug info\n"); <answer> get 
return <token> <answer> NULL; 
pc = <token> ip); <answer> map__rip_2objdump(ms->map, 
if (find_data_type_die(di, pc, addr, var_name, loc, &type_die) < <token> <answer> 0) 
<token> out; <answer> goto 
<token> = dso__findnew_data_type(dso, &type_die); <answer> result 
<token> result; <answer> return 
static int alloc_data_type_histograms(struct annotated_data_type *adt, <token> nr_entries) <answer> int 
<token> i; <answer> int 
<token> sz = sizeof(struct type_hist); <answer> size_t 
sz += sizeof(struct type_hist_entry) * <token> <answer> adt->self.size; 
for (i = <token> i < nr_entries; i++) { <answer> 0; 
<token> = zalloc(sz); <answer> adt->histograms[i] 
if (adt->histograms[i] <token> NULL) <answer> == 
<token> err; <answer> goto 
<token> 0; <answer> return 
while (--i >= <token> <answer> 0) 
<token> -ENOMEM; <answer> return 
static void delete_data_type_histograms(struct <token> *adt) <answer> annotated_data_type 
for <token> i = 0; i < adt->nr_histograms; i++) <answer> (int 
void annotated_data_type__tree_delete(struct <token> *root) <answer> rb_root 
struct <token> *pos; <answer> annotated_data_type 
while (!RB_EMPTY_ROOT(root)) <token> <answer> { 
struct rb_node *node <token> rb_first(root); <answer> = 
<token> root); <answer> rb_erase(node, 
pos = rb_entry(node, struct annotated_data_type, <token> <answer> node); 
int annotated_data_type__update_samples(struct <token> *adt, <answer> annotated_data_type 
<token> evsel *evsel, int offset, <answer> struct 
int nr_samples, <token> period) <answer> u64 
struct type_hist <token> <answer> *h; 
if (adt <token> NULL) <answer> == 
return <token> <answer> 0; 
if (adt->histograms <token> NULL) { <answer> == 
<token> nr = evsel->evlist->core.nr_entries; <answer> int 
if (alloc_data_type_histograms(adt, nr) < <token> <answer> 0) 
<token> -1; <answer> return 
<token> (offset < 0 || offset >= adt->self.size) <answer> if 
<token> -1; <answer> return 
h <token> adt->histograms[evsel->core.idx]; <answer> = 
<token> += nr_samples; <answer> h->nr_samples 
h->addr[offset].nr_samples <token> nr_samples; <answer> += 
<token> += period; <answer> h->period 
h->addr[offset].period <token> period; <answer> += 
<token> 0; <answer> return 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/fs.h> 
<token> <linux/blkdev.h> <answer> #include 
<token> <linux/bio.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/compiler.h> 
#include <token> <answer> <linux/blktrace_api.h> 
<token> <linux/hash.h> <answer> #include 
<token> <linux/uaccess.h> <answer> #include 
#include <token> <answer> <linux/pm_runtime.h> 
#include <token> <answer> <trace/events/block.h> 
#include <token> <answer> "elevator.h" 
<token> "blk.h" <answer> #include 
#include <token> <answer> "blk-mq-sched.h" 
#include <token> <answer> "blk-pm.h" 
<token> "blk-wbt.h" <answer> #include 
#include <token> <answer> "blk-cgroup.h" 
static <token> <answer> DEFINE_SPINLOCK(elv_list_lock); 
static <token> <answer> LIST_HEAD(elv_list); 
#define rq_hash_key(rq) (blk_rq_pos(rq) <token> blk_rq_sectors(rq)) <answer> + 
static bool elv_iosched_allow_bio_merge(struct request *rq, <token> bio *bio) <answer> struct 
struct request_queue *q = <token> <answer> rq->q; 
struct elevator_queue *e <token> q->elevator; <answer> = 
<token> (e->type->ops.allow_merge) <answer> if 
return e->type->ops.allow_merge(q, <token> bio); <answer> rq, 
<token> true; <answer> return 
bool elv_bio_merge_ok(struct request *rq, struct <token> *bio) <answer> bio 
if (!blk_rq_merge_ok(rq, <token> <answer> bio)) 
return <token> <answer> false; 
if (!elv_iosched_allow_bio_merge(rq, <token> <answer> bio)) 
return <token> <answer> false; 
return <token> <answer> true; 
static inline bool elv_support_features(struct <token> *q, <answer> request_queue 
const struct <token> *e) <answer> elevator_type 
return (q->required_elevator_features & <token> == <answer> e->elevator_features) 
static bool elevator_match(const struct elevator_type <token> const char *name) <answer> *e, 
return !strcmp(e->elevator_name, name) <token> <answer> || 
(e->elevator_alias <token> !strcmp(e->elevator_alias, name)); <answer> && 
<token> struct elevator_type *__elevator_find(const char *name) <answer> static 
struct <token> *e; <answer> elevator_type 
<token> &elv_list, list) <answer> list_for_each_entry(e, 
<token> (elevator_match(e, name)) <answer> if 
return <token> <answer> e; 
<token> NULL; <answer> return 
static struct elevator_type *elevator_find_get(struct request_queue <token> <answer> *q, 
const <token> *name) <answer> char 
struct elevator_type <token> <answer> *e; 
e <token> __elevator_find(name); <answer> = 
if (e && (!elv_support_features(q, e) <token> !elevator_tryget(e))) <answer> || 
<token> = NULL; <answer> e 
<token> e; <answer> return 
static const struct kobj_type <token> <answer> elv_ktype; 
struct elevator_queue *elevator_alloc(struct <token> *q, <answer> request_queue 
struct <token> *e) <answer> elevator_type 
<token> elevator_queue *eq; <answer> struct 
eq = kzalloc_node(sizeof(*eq), <token> q->node); <answer> GFP_KERNEL, 
if <token> <answer> (unlikely(!eq)) 
return <token> <answer> NULL; 
<token> = e; <answer> eq->type 
kobject_init(&eq->kobj, <token> <answer> &elv_ktype); 
return <token> <answer> eq; 
<token> void elevator_release(struct kobject *kobj) <answer> static 
<token> elevator_queue *e; <answer> struct 
e = container_of(kobj, struct elevator_queue, <token> <answer> kobj); 
void elevator_exit(struct <token> *q) <answer> request_queue 
struct <token> *e = q->elevator; <answer> elevator_queue 
blk_mq_exit_sched(q, <token> <answer> e); 
static inline <token> __elv_rqhash_del(struct request *rq) <answer> void 
rq->rq_flags &= <token> <answer> ~RQF_HASHED; 
void elv_rqhash_del(struct <token> *q, struct request *rq) <answer> request_queue 
if <token> <answer> (ELV_ON_HASH(rq)) 
void elv_rqhash_add(struct request_queue *q, <token> request *rq) <answer> struct 
struct elevator_queue <token> = q->elevator; <answer> *e 
hash_add(e->hash, <token> rq_hash_key(rq)); <answer> &rq->hash, 
rq->rq_flags |= <token> <answer> RQF_HASHED; 
void <token> request_queue *q, struct request *rq) <answer> elv_rqhash_reposition(struct 
elv_rqhash_add(q, <token> <answer> rq); 
struct <token> *elv_rqhash_find(struct request_queue *q, sector_t offset) <answer> request 
struct elevator_queue *e = <token> <answer> q->elevator; 
<token> hlist_node *next; <answer> struct 
struct <token> *rq; <answer> request 
hash_for_each_possible_safe(e->hash, rq, next, hash, offset) <token> <answer> { 
if (unlikely(!rq_mergeable(rq))) <token> <answer> { 
if (rq_hash_key(rq) <token> offset) <answer> == 
<token> rq; <answer> return 
<token> NULL; <answer> return 
<token> elv_rb_add(struct rb_root *root, struct request *rq) <answer> void 
struct rb_node <token> = &root->rb_node; <answer> **p 
struct rb_node *parent <token> NULL; <answer> = 
struct <token> *__rq; <answer> request 
while (*p) <token> <answer> { 
parent = <token> <answer> *p; 
__rq <token> rb_entry(parent, struct request, rb_node); <answer> = 
if (blk_rq_pos(rq) < <token> <answer> blk_rq_pos(__rq)) 
p = <token> <answer> &(*p)->rb_left; 
else if <token> >= blk_rq_pos(__rq)) <answer> (blk_rq_pos(rq) 
p <token> &(*p)->rb_right; <answer> = 
rb_link_node(&rq->rb_node, <token> p); <answer> parent, 
<token> root); <answer> rb_insert_color(&rq->rb_node, 
void elv_rb_del(struct rb_root *root, struct <token> *rq) <answer> request 
rb_erase(&rq->rb_node, <token> <answer> root); 
<token> request *elv_rb_find(struct rb_root *root, sector_t sector) <answer> struct 
<token> rb_node *n = root->rb_node; <answer> struct 
struct <token> *rq; <answer> request 
<token> (n) { <answer> while 
rq <token> rb_entry(n, struct request, rb_node); <answer> = 
if <token> < blk_rq_pos(rq)) <answer> (sector 
n <token> n->rb_left; <answer> = 
else if (sector > <token> <answer> blk_rq_pos(rq)) 
n = <token> <answer> n->rb_right; 
<token> rq; <answer> return 
return <token> <answer> NULL; 
enum elv_merge elv_merge(struct request_queue *q, struct request <token> <answer> **req, 
<token> bio *bio) <answer> struct 
struct elevator_queue <token> = q->elevator; <answer> *e 
struct request <token> <answer> *__rq; 
if <token> || !bio_mergeable(bio)) <answer> (blk_queue_nomerges(q) 
return <token> <answer> ELEVATOR_NO_MERGE; 
if (q->last_merge && elv_bio_merge_ok(q->last_merge, bio)) <token> <answer> { 
enum <token> ret = blk_try_merge(q->last_merge, bio); <answer> elv_merge 
if (ret != ELEVATOR_NO_MERGE) <token> <answer> { 
*req = <token> <answer> q->last_merge; 
return <token> <answer> ret; 
<token> (blk_queue_noxmerges(q)) <answer> if 
<token> ELEVATOR_NO_MERGE; <answer> return 
__rq <token> elv_rqhash_find(q, bio->bi_iter.bi_sector); <answer> = 
if (__rq && <token> bio)) { <answer> elv_bio_merge_ok(__rq, 
*req = <token> <answer> __rq; 
<token> (blk_discard_mergable(__rq)) <answer> if 
<token> ELEVATOR_DISCARD_MERGE; <answer> return 
<token> ELEVATOR_BACK_MERGE; <answer> return 
if <token> <answer> (e->type->ops.request_merge) 
return e->type->ops.request_merge(q, <token> bio); <answer> req, 
return <token> <answer> ELEVATOR_NO_MERGE; 
<token> elv_attempt_insert_merge(struct request_queue *q, struct request *rq, <answer> bool 
struct list_head <token> <answer> *free) 
struct <token> *__rq; <answer> request 
<token> ret; <answer> bool 
if <token> <answer> (blk_queue_nomerges(q)) 
<token> false; <answer> return 
<token> (q->last_merge && blk_attempt_req_merge(q, q->last_merge, rq)) { <answer> if 
<token> free); <answer> list_add(&rq->queuelist, 
<token> true; <answer> return 
<token> (blk_queue_noxmerges(q)) <answer> if 
<token> false; <answer> return 
ret <token> false; <answer> = 
<token> (1) { <answer> while 
__rq = elv_rqhash_find(q, <token> <answer> blk_rq_pos(rq)); 
<token> (!__rq || !blk_attempt_req_merge(q, __rq, rq)) <answer> if 
<token> free); <answer> list_add(&rq->queuelist, 
if (e->icq_cache) <token> <answer> { 
e->icq_cache = <token> <answer> NULL; 
static inline bool elv_support_iosched(struct request_queue <token> <answer> *q) 
<token> (!queue_is_mq(q) || <answer> if 
(q->tag_set && <token> & BLK_MQ_F_NO_SCHED))) <answer> (q->tag_set->flags 
return <token> <answer> false; 
<token> true; <answer> return 
static struct elevator_type <token> request_queue *q) <answer> *elevator_get_default(struct 
if (q->tag_set <token> q->tag_set->flags & BLK_MQ_F_NO_SCHED_BY_DEFAULT) <answer> && 
<token> NULL; <answer> return 
if <token> != 1 && <answer> (q->nr_hw_queues 
<token> NULL; <answer> return 
<token> elevator_find_get(q, "mq-deadline"); <answer> return 
static struct elevator_type <token> request_queue *q) <answer> *elevator_get_by_features(struct 
struct elevator_type *e, *found <token> NULL; <answer> = 
list_for_each_entry(e, <token> list) { <answer> &elv_list, 
<token> (elv_support_features(q, e)) { <answer> if 
found = <token> <answer> e; 
if <token> && !elevator_tryget(found)) <answer> (found 
found = <token> <answer> NULL; 
<token> found; <answer> return 
void elevator_init_mq(struct <token> *q) <answer> request_queue 
struct <token> *e; <answer> elevator_type 
<token> err; <answer> int 
if <token> <answer> (!elv_support_iosched(q)) 
<token> (unlikely(q->elevator)) <answer> if 
if <token> <answer> (!q->required_elevator_features) 
e <token> elevator_get_default(q); <answer> = 
<token> = elevator_get_by_features(q); <answer> e 
<token> (!e) <answer> if 
err <token> blk_mq_init_sched(q, e); <answer> = 
if (err) <token> <answer> { 
pr_warn("\"%s\" elevator initialization <token> " <answer> failed, 
<token> back to \"none\"\n", e->elevator_name); <answer> "falling 
int elevator_switch(struct request_queue *q, struct <token> *new_e) <answer> elevator_type 
<token> ret; <answer> int 
if (q->elevator) <token> <answer> { 
ret = blk_mq_init_sched(q, <token> <answer> new_e); 
if <token> <answer> (ret) 
goto <token> <answer> out_unfreeze; 
ret = <token> true); <answer> elv_register_queue(q, 
if <token> { <answer> (ret) 
goto <token> <answer> out_unfreeze; 
blk_add_trace_msg(q, "elv switch: <token> new_e->elevator_name); <answer> %s", 
<token> (ret) { <answer> if 
pr_warn("elv: switch to \"%s\" failed, falling back to <token> <answer> \"none\"\n", 
<token> ret; <answer> return 
<token> elevator_disable(struct request_queue *q) <answer> void 
blk_queue_flag_clear(QUEUE_FLAG_SQ_SCHED, <token> <answer> q); 
q->elevator = <token> <answer> NULL; 
<token> = q->tag_set->queue_depth; <answer> q->nr_requests 
<token> "elv switch: none"); <answer> blk_add_trace_msg(q, 
static int elevator_change(struct request_queue *q, const char <token> <answer> *elevator_name) 
<token> elevator_type *e; <answer> struct 
int <token> <answer> ret; 
<token> <linux/module.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/serial_8250.h> 
#include <token> <answer> <linux/string.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/console.h> <answer> #include 
#include <token> <answer> <linux/rtc.h> 
#include <token> <answer> <asm/bootinfo.h> 
<token> <asm/bootinfo-hp300.h> <answer> #include 
<token> <asm/byteorder.h> <answer> #include 
#include <token> <answer> <asm/machdep.h> 
<token> <asm/blinken.h> <answer> #include 
<token> KBUILD_MODNAME "foo" <answer> #define 
#include <token> <answer> <uapi/linux/bpf.h> 
#include <token> <answer> <linux/in.h> 
#include <token> <answer> <linux/if_ether.h> 
<token> <linux/if_packet.h> <answer> #include 
<token> <linux/if_vlan.h> <answer> #include 
<token> <linux/ip.h> <answer> #include 
<token> <linux/icmp.h> <answer> #include 
#include <token> <answer> <bpf/bpf_helpers.h> 
#define DEFAULT_TTL <token> <answer> 64 
#define <token> 600 <answer> MAX_PCKT_SIZE 
#define <token> 98 <answer> ICMP_TOOBIG_SIZE 
#define <token> 92 <answer> ICMP_TOOBIG_PAYLOAD_SIZE 
<token> <linux/clk.h> <answer> #include 
#include <token> <answer> <linux/component.h> 
#include <token> <answer> <linux/device.h> 
<token> <linux/dma-mapping.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/of_device.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/pm_runtime.h> 
<token> <drm/drm_aperture.h> <answer> #include 
#include <token> <answer> <drm/drm_atomic_helper.h> 
<token> <drm/drm_drv.h> <answer> #include 
#include <token> <answer> <drm/drm_fbdev_dma.h> 
#include <token> <answer> <drm/drm_vblank.h> 
#include <token> <answer> <soc/bcm2835/raspberrypi-firmware.h> 
<token> "uapi/drm/vc4_drm.h" <answer> #include 
#include <token> <answer> "vc4_drv.h" 
#include <token> <answer> "vc4_regs.h" 
<token> DRIVER_NAME "vc4" <answer> #define 
#define DRIVER_DESC "Broadcom VC4 <token> <answer> graphics" 
<token> DRIVER_DATE "20140616" <answer> #define 
<token> DRIVER_MAJOR 0 <answer> #define 
#define <token> 0 <answer> DRIVER_MINOR 
<token> DRIVER_PATCHLEVEL 0 <answer> #define 
<token> struct platform_driver *const component_drivers[] = { <answer> static 
static int <token> platform_device *pdev) <answer> vc4_platform_drm_probe(struct 
struct component_match *match = <token> <answer> NULL; 
struct device <token> = &pdev->dev; <answer> *dev 
vc4_match_add_drivers(dev, <token> <answer> &match, 
<token> ARRAY_SIZE(component_drivers)); <answer> component_drivers, 
return component_master_add_with_match(dev, <token> match); <answer> &vc4_drm_ops, 
static void <token> platform_device *pdev) <answer> vc4_platform_drm_remove(struct 
component_master_del(&pdev->dev, <token> <answer> &vc4_drm_ops); 
static void vc4_platform_drm_shutdown(struct <token> *pdev) <answer> platform_device 
<token> const struct of_device_id vc4_of_match[] = { <answer> static 
<token> .compatible = "brcm,bcm2711-vc5", }, <answer> { 
<token> .compatible = "brcm,bcm2835-vc4", }, <answer> { 
{ .compatible <token> "brcm,cygnus-vc4", }, <answer> = 
<token> vc4_of_match); <answer> MODULE_DEVICE_TABLE(of, 
static <token> platform_driver vc4_platform_driver = { <answer> struct 
.probe <token> vc4_platform_drm_probe, <answer> = 
.remove_new <token> vc4_platform_drm_remove, <answer> = 
<token> = vc4_platform_drm_shutdown, <answer> .shutdown 
.driver <token> { <answer> = 
.name <token> "vc4-drm", <answer> = 
<token> = vc4_of_match, <answer> .of_match_table 
<token> int __init vc4_drm_register(void) <answer> static 
<token> ret; <answer> int 
<token> (drm_firmware_drivers_only()) <answer> if 
<token> -ENODEV; <answer> return 
ret = <token> <answer> platform_register_drivers(component_drivers, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
ret <token> platform_driver_register(&vc4_platform_driver); <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
static <token> __exit vc4_drm_unregister(void) <answer> void 
MODULE_SOFTDEP("pre: <token> <answer> snd-soc-hdmi-codec"); 
MODULE_DESCRIPTION("Broadcom VC4 DRM <token> <answer> Driver"); 
MODULE_AUTHOR("Eric Anholt <token> <answer> <eric@anholt.net>"); 
MODULE_LICENSE("GPL <token> <answer> v2"); 
<token> _GNU_SOURCE <answer> #define 
<token> <stdio.h> <answer> #include 
<token> <stdbool.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/magic.h> <answer> #include 
#include <token> <answer> <linux/mman.h> 
<token> <sys/mman.h> <answer> #include 
#include <token> <answer> <sys/shm.h> 
#include <token> <answer> <sys/syscall.h> 
<token> <sys/vfs.h> <answer> #include 
#include <token> <answer> <unistd.h> 
<token> <string.h> <answer> #include 
#include <token> <answer> <fcntl.h> 
#include <token> <answer> <errno.h> 
#include <token> <answer> "../kselftest.h" 
<token> NR_TESTS 9 <answer> #define 
static const <token> * const dev_files[] = { <answer> char 
"/dev/zero", "/dev/null", <token> <answer> "/dev/urandom", 
"/proc/version", <token> <answer> "/proc" 
void <token> cachestat *cs) <answer> print_cachestat(struct 
"Using cachestat: Cached: <token> Dirty: %llu, Writeback: %llu, Evicted: %llu, Recently Evicted: %llu\n", <answer> %llu, 
cs->nr_cache, cs->nr_dirty, <token> <answer> cs->nr_writeback, 
<token> cs->nr_recently_evicted); <answer> cs->nr_evicted, 
bool write_exactly(int fd, <token> filesize) <answer> size_t 
int random_fd = <token> O_RDONLY); <answer> open("/dev/urandom", 
char <token> *data; <answer> *cursor, 
<token> remained; <answer> int 
<token> ret; <answer> bool 
if (random_fd < 0) <token> <answer> { 
ksft_print_msg("Unable <token> access urandom.\n"); <answer> to 
ret = <token> <answer> false; 
goto <token> <answer> out; 
data = <token> <answer> malloc(filesize); 
if (!data) <token> <answer> { 
<token> to allocate data.\n"); <answer> ksft_print_msg("Unable 
ret <token> false; <answer> = 
goto <token> <answer> close_random_fd; 
remained <token> filesize; <answer> = 
cursor = <token> <answer> data; 
<token> (remained) { <answer> while 
ssize_t read_len = read(random_fd, <token> remained); <answer> cursor, 
if (read_len <= <token> { <answer> 0) 
ksft_print_msg("Unable to read from <token> <answer> urandom.\n"); 
ret <token> false; <answer> = 
<token> out_free_data; <answer> goto 
remained -= <token> <answer> read_len; 
<token> += read_len; <answer> cursor 
static bool <token> fd) <answer> is_on_tmpfs(int 
struct <token> statfs_buf; <answer> statfs 
<token> (fstatfs(fd, &statfs_buf)) <answer> if 
<token> false; <answer> return 
return statfs_buf.f_type <token> TMPFS_MAGIC; <answer> == 
static int test_cachestat(const char *filename, bool write_random, <token> create, <answer> bool 
<token> test_fsync, unsigned long num_pages, <answer> bool 
<token> open_flags, mode_t open_mode) <answer> int 
size_t <token> = sysconf(_SC_PAGESIZE); <answer> PS 
int filesize = <token> * PS; <answer> num_pages 
<token> ret = KSFT_PASS; <answer> int 
<token> syscall_ret; <answer> long 
struct <token> cs; <answer> cachestat 
struct cachestat_range cs_range = { <token> filesize }; <answer> 0, 
int fd <token> open(filename, open_flags, open_mode); <answer> = 
<token> (fd == -1) { <answer> if 
ksft_print_msg("Unable to <token> file.\n"); <answer> create/open 
<token> = KSFT_FAIL; <answer> ret 
goto <token> <answer> out; 
} <token> { <answer> else 
<token> %s\n", filename); <answer> ksft_print_msg("Create/open 
if (write_random) <token> <answer> { 
if <token> filesize)) { <answer> (!write_exactly(fd, 
<token> to access urandom.\n"); <answer> ksft_print_msg("Unable 
ret <token> KSFT_FAIL; <answer> = 
<token> out1; <answer> goto 
syscall_ret = syscall(__NR_cachestat, <token> &cs_range, &cs, 0); <answer> fd, 
ksft_print_msg("Cachestat call returned %ld\n", <token> <answer> syscall_ret); 
if <token> { <answer> (syscall_ret) 
ksft_print_msg("Cachestat <token> non-zero.\n"); <answer> returned 
ret = <token> <answer> KSFT_FAIL; 
<token> out1; <answer> goto 
<token> else { <answer> } 
if <token> { <answer> (write_random) 
<token> (cs.nr_cache + cs.nr_evicted != num_pages) { <answer> if 
"Total number of cached <token> evicted pages is off.\n"); <answer> and 
ret <token> KSFT_FAIL; <answer> = 
if (test_fsync) <token> <answer> { 
<token> (is_on_tmpfs(fd)) { <answer> if 
<token> = KSFT_SKIP; <answer> ret 
} <token> if (fsync(fd)) { <answer> else 
<token> fails.\n"); <answer> ksft_print_msg("fsync 
<token> = KSFT_FAIL; <answer> ret 
<token> else { <answer> } 
syscall_ret = syscall(__NR_cachestat, fd, &cs_range, <token> 0); <answer> &cs, 
ksft_print_msg("Cachestat <token> (after fsync) returned %ld\n", <answer> call 
if (!syscall_ret) <token> <answer> { 
if <token> { <answer> (cs.nr_dirty) 
ret = <token> <answer> KSFT_FAIL; 
"Number of dirty should be zero after <token> <answer> fsync.\n"); 
} <token> { <answer> else 
<token> (after fsync) returned non-zero.\n"); <answer> ksft_print_msg("Cachestat 
ret <token> KSFT_FAIL; <answer> = 
<token> out1; <answer> goto 
<token> (create) <answer> if 
return <token> <answer> ret; 
bool <token> <answer> test_cachestat_shmem(void) 
size_t PS = <token> <answer> sysconf(_SC_PAGESIZE); 
<token> <linux/signal.h> <answer> #include 
<token> <linux/sched.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <media/dmxdev.h> <answer> #include 
<token> <media/dvbdev.h> <answer> #include 
<token> <media/dvb_demux.h> <answer> #include 
#include <token> <answer> <media/dvb_frontend.h> 
#include <token> <answer> <media/dvb_net.h> 
<token> "stv0299.h" <answer> #include 
<token> "mantis_common.h" <answer> #include 
<token> "mantis_ioc.h" <answer> #include 
#include <token> <answer> "mantis_dvb.h" 
#include <token> <answer> "mantis_vp1033.h" 
<token> "mantis_reg.h" <answer> #include 
static u8 lgtdqcs001f_inittab[] = <token> <answer> { 
0x01, <token> <answer> 0x15, 
<token> 0x30, <answer> 0x02, 
0x03, <token> <answer> 0x00, 
<token> 0x2a, <answer> 0x04, 
0x05, <token> <answer> 0x85, 
<token> 0x02, <answer> 0x06, 
0x07, <token> <answer> 0x00, 
<token> 0x00, <answer> 0x08, 
0x0c, <token> <answer> 0x01, 
<token> 0x81, <answer> 0x0d, 
0x0e, <token> <answer> 0x44, 
<token> 0x94, <answer> 0x0f, 
0x10, <token> <answer> 0x3c, 
<token> 0x84, <answer> 0x11, 
0x12, <token> <answer> 0xb9, 
0x13, <token> <answer> 0xb5, 
<token> 0x4f, <answer> 0x14, 
0x15, <token> <answer> 0xc9, 
0x16, <token> <answer> 0x80, 
<token> 0x36, <answer> 0x17, 
<token> 0xfb, <answer> 0x18, 
0x19, <token> <answer> 0xcf, 
<token> 0xbc, <answer> 0x1a, 
<token> 0x2b, <answer> 0x1c, 
<token> 0x27, <answer> 0x1d, 
0x1e, <token> <answer> 0x00, 
0x1f, <token> <answer> 0x0b, 
<token> 0xa1, <answer> 0x20, 
<token> 0x60, <answer> 0x21, 
0x22, <token> <answer> 0x00, 
<token> 0x00, <answer> 0x23, 
0x28, <token> <answer> 0x00, 
0x29, <token> <answer> 0x28, 
0x2a, <token> <answer> 0x14, 
0x2b, <token> <answer> 0x0f, 
0x2c, <token> <answer> 0x09, 
0x2d, <token> <answer> 0x05, 
<token> 0x1f, <answer> 0x31, 
<token> 0x19, <answer> 0x32, 
<token> 0xfc, <answer> 0x33, 
0x34, <token> <answer> 0x13, 
0xff, <token> <answer> 0xff, 
<token> MANTIS_MODEL_NAME "VP-1033" <answer> #define 
#define <token> "DVB-S/DSS" <answer> MANTIS_DEV_TYPE 
<token> int lgtdqcs001f_tuner_set(struct dvb_frontend *fe) <answer> static 
struct dtv_frontend_properties *p <token> &fe->dtv_property_cache; <answer> = 
struct <token> *mantis = fe->dvb->priv; <answer> mantis_pci 
struct i2c_adapter *adapter <token> &mantis->adapter; <answer> = 
u8 <token> <answer> buf[4]; 
u32 <token> <answer> div; 
struct i2c_msg msg = {.addr = 0x61, .flags = 0, .buf <token> buf, .len = sizeof(buf)}; <answer> = 
<token> = p->frequency / 250; <answer> div 
buf[0] = (div <token> 8) & 0x7f; <answer> >> 
buf[1] = div <token> 0xff; <answer> & 
buf[2] = <token> <answer> 0x83; 
buf[3] = <token> <answer> 0xc0; 
<token> (p->frequency < 1531000) <answer> if 
<token> |= 0x04; <answer> buf[3] 
buf[3] <token> ~0x04; <answer> &= 
if (i2c_transfer(adapter, &msg, 1) <token> 0) { <answer> < 
<token> 1, "Write: I2C Transfer failed"); <answer> dprintk(MANTIS_ERROR, 
<token> -EIO; <answer> return 
<token> 0; <answer> return 
static int lgtdqcs001f_set_symbol_rate(struct <token> *fe, <answer> dvb_frontend 
u32 srate, <token> ratio) <answer> u32 
u8 <token> = 0; <answer> aclk 
u8 bclk = <token> <answer> 0; 
if <token> < 1500000) { <answer> (srate 
aclk <token> 0xb7; <answer> = 
bclk = <token> <answer> 0x47; 
} else if (srate < <token> { <answer> 3000000) 
aclk = <token> <answer> 0xb7; 
bclk <token> 0x4b; <answer> = 
} <token> if (srate < 7000000) { <answer> else 
aclk = <token> <answer> 0xb7; 
bclk <token> 0x4f; <answer> = 
} else <token> (srate < 14000000) { <answer> if 
aclk <token> 0xb7; <answer> = 
bclk = <token> <answer> 0x53; 
} else if <token> < 30000000) { <answer> (srate 
aclk <token> 0xb6; <answer> = 
bclk <token> 0x53; <answer> = 
} else if (srate < 45000000) <token> <answer> { 
<token> = 0xb4; <answer> aclk 
<token> = 0x51; <answer> bclk 
stv0299_writereg(fe, 0x13, <token> <answer> aclk); 
stv0299_writereg(fe, 0x14, <token> <answer> bclk); 
<token> 0x1f, (ratio >> 16) & 0xff); <answer> stv0299_writereg(fe, 
stv0299_writereg(fe, 0x20, (ratio >> 8) <token> 0xff); <answer> & 
stv0299_writereg(fe, 0x21, ratio <token> 0xf0); <answer> & 
<token> 0; <answer> return 
static struct <token> lgtdqcs001f_config = { <answer> stv0299_config 
<token> = 0x68, <answer> .demod_address 
.inittab = <token> <answer> lgtdqcs001f_inittab, 
.mclk = <token> <answer> 88000000UL, 
<token> = 0, <answer> .invert 
.skip_reinit = <token> <answer> 0, 
<token> = STV0299_VOLT13_OP0, <answer> .volt13_op0_op1 
<token> = 100, <answer> .min_delay_ms 
<token> = lgtdqcs001f_set_symbol_rate, <answer> .set_symbol_rate 
static int vp1033_frontend_init(struct mantis_pci *mantis, struct dvb_frontend <token> <answer> *fe) 
struct <token> *adapter = &mantis->adapter; <answer> i2c_adapter 
int <token> = 0; <answer> err 
err <token> mantis_frontend_power(mantis, POWER_ON); <answer> = 
if (err <token> 0) { <answer> == 
dprintk(MANTIS_ERROR, <token> "Probing for STV0299 (DVB-S)"); <answer> 1, 
fe <token> dvb_attach(stv0299_attach, &lgtdqcs001f_config, adapter); <answer> = 
<token> (fe) { <answer> if 
<token> = lgtdqcs001f_tuner_set; <answer> fe->ops.tuner_ops.set_params 
dprintk(MANTIS_ERROR, 1, <token> STV0299 DVB-S frontend @ 0x%02x", <answer> "found 
dprintk(MANTIS_ERROR, 1, "Mantis DVB-S STV0299 <token> attach success"); <answer> frontend 
} <token> { <answer> else 
<token> -1; <answer> return 
} <token> { <answer> else 
dprintk(MANTIS_ERROR, 1, "Frontend <token> <%s> POWER ON failed! <%d>", <answer> on 
return <token> <answer> -EIO; 
mantis->fe <token> fe; <answer> = 
dprintk(MANTIS_ERROR, <token> "Done!"); <answer> 1, 
<token> 0; <answer> return 
struct <token> vp1033_config = { <answer> mantis_hwconfig 
.model_name = <token> <answer> MANTIS_MODEL_NAME, 
.dev_type <token> MANTIS_DEV_TYPE, <answer> = 
<token> = MANTIS_TS_204, <answer> .ts_size 
.baud_rate = <token> <answer> MANTIS_BAUD_9600, 
.parity <token> MANTIS_PARITY_NONE, <answer> = 
.bytes = <token> <answer> 0, 
.frontend_init <token> vp1033_frontend_init, <answer> = 
.power = <token> <answer> GPIF_A12, 
.reset = <token> <answer> GPIF_A13, 
<token> "device.h" <answer> #include 
#include <token> <answer> "peer.h" 
<token> "socket.h" <answer> #include 
#include <token> <answer> "queueing.h" 
#include <token> <answer> "messages.h" 
#include <token> <answer> <linux/ctype.h> 
#include <token> <answer> <linux/net.h> 
<token> <linux/if_vlan.h> <answer> #include 
<token> <linux/if_ether.h> <answer> #include 
#include <token> <answer> <linux/inetdevice.h> 
<token> <net/udp_tunnel.h> <answer> #include 
<token> <net/ipv6.h> <answer> #include 
static <token> send4(struct wg_device *wg, struct sk_buff *skb, <answer> int 
struct endpoint *endpoint, u8 ds, struct <token> *cache) <answer> dst_cache 
struct flowi4 <token> = { <answer> fl 
<token> = endpoint->src4.s_addr, <answer> .saddr 
.daddr <token> endpoint->addr4.sin_addr.s_addr, <answer> = 
.fl4_dport = <token> <answer> endpoint->addr4.sin_port, 
.flowi4_mark <token> wg->fwmark, <answer> = 
.flowi4_proto = <token> <answer> IPPROTO_UDP 
struct rtable *rt <token> NULL; <answer> = 
<token> sock *sock; <answer> struct 
int ret = <token> <answer> 0; 
skb->dev = <token> <answer> wg->dev; 
skb->mark <token> wg->fwmark; <answer> = 
sock = <token> <answer> rcu_dereference_bh(wg->sock4); 
<token> (unlikely(!sock)) { <answer> if 
ret <token> -ENONET; <answer> = 
goto <token> <answer> err; 
fl.fl4_sport <token> inet_sk(sock)->inet_sport; <answer> = 
<token> (cache) <answer> if 
rt = dst_cache_get_ip4(cache, <token> <answer> &fl.saddr); 
if <token> { <answer> (!rt) 
<token> flowi4_to_flowi_common(&fl)); <answer> security_sk_classify_flow(sock, 
if (unlikely(!inet_confirm_addr(sock_net(sock), NULL, <token> <answer> 0, 
fl.saddr, RT_SCOPE_HOST))) <token> <answer> { 
endpoint->src4.s_addr <token> 0; <answer> = 
endpoint->src_if4 <token> 0; <answer> = 
fl.saddr = <token> <answer> 0; 
if <token> <answer> (cache) 
<token> = ip_route_output_flow(sock_net(sock), &fl, sock); <answer> rt 
if (unlikely(endpoint->src_if4 <token> ((IS_ERR(rt) && <answer> && 
PTR_ERR(rt) == -EINVAL) <token> (!IS_ERR(rt) && <answer> || 
rt->dst.dev->ifindex != <token> { <answer> endpoint->src_if4)))) 
<token> = 0; <answer> endpoint->src4.s_addr 
endpoint->src_if4 <token> 0; <answer> = 
fl.saddr = <token> <answer> 0; 
<token> (cache) <answer> if 
<token> (!IS_ERR(rt)) <answer> if 
rt <token> ip_route_output_flow(sock_net(sock), &fl, sock); <answer> = 
if <token> { <answer> (IS_ERR(rt)) 
ret = <token> <answer> PTR_ERR(rt); 
net_dbg_ratelimited("%s: No <token> to %pISpfsc, error %d\n", <answer> route 
wg->dev->name, <token> ret); <answer> &endpoint->addr, 
goto <token> <answer> err; 
if <token> <answer> (cache) 
<token> &rt->dst, fl.saddr); <answer> dst_cache_set_ip4(cache, 
skb->ignore_df = <token> <answer> 1; 
udp_tunnel_xmit_skb(rt, sock, skb, fl.saddr, fl.daddr, <token> <answer> ds, 
ip4_dst_hoplimit(&rt->dst), <token> fl.fl4_sport, <answer> 0, 
fl.fl4_dport, false, <token> <answer> false); 
goto <token> <answer> out; 
<token> ret; <answer> return 
static int send6(struct wg_device *wg, struct sk_buff <token> <answer> *skb, 
struct <token> *endpoint, u8 ds, struct dst_cache *cache) <answer> endpoint 
<token> IS_ENABLED(CONFIG_IPV6) <answer> #if 
struct flowi6 fl <token> { <answer> = 
.saddr = <token> <answer> endpoint->src6, 
.daddr = <token> <answer> endpoint->addr6.sin6_addr, 
.fl6_dport = <token> <answer> endpoint->addr6.sin6_port, 
<token> = wg->fwmark, <answer> .flowi6_mark 
<token> = endpoint->addr6.sin6_scope_id, <answer> .flowi6_oif 
<token> = IPPROTO_UDP <answer> .flowi6_proto 
<token> ret; <answer> return 
<token> wg_socket_endpoint_from_skb(struct endpoint *endpoint, <answer> int 
const struct sk_buff <token> <answer> *skb) 
memset(endpoint, <token> sizeof(*endpoint)); <answer> 0, 
if (skb->protocol == htons(ETH_P_IP)) <token> <answer> { 
endpoint->addr4.sin_family <token> AF_INET; <answer> = 
endpoint->addr4.sin_port = <token> <answer> udp_hdr(skb)->source; 
endpoint->addr4.sin_addr.s_addr = <token> <answer> ip_hdr(skb)->saddr; 
endpoint->src4.s_addr = <token> <answer> ip_hdr(skb)->daddr; 
<token> = skb->skb_iif; <answer> endpoint->src_if4 
} else if (IS_ENABLED(CONFIG_IPV6) <token> skb->protocol == htons(ETH_P_IPV6)) { <answer> && 
<token> = AF_INET6; <answer> endpoint->addr6.sin6_family 
endpoint->addr6.sin6_port <token> udp_hdr(skb)->source; <answer> = 
<token> = ipv6_hdr(skb)->saddr; <answer> endpoint->addr6.sin6_addr 
<token> = ipv6_iface_scope_id( <answer> endpoint->addr6.sin6_scope_id 
<token> skb->skb_iif); <answer> &ipv6_hdr(skb)->saddr, 
endpoint->src6 <token> ipv6_hdr(skb)->daddr; <answer> = 
} else <token> <answer> { 
<token> -EINVAL; <answer> return 
<token> 0; <answer> return 
static bool endpoint_eq(const <token> endpoint *a, const struct endpoint *b) <answer> struct 
return (a->addr.sa_family == <token> && b->addr.sa_family == AF_INET && <answer> AF_INET 
a->addr4.sin_port == <token> && <answer> b->addr4.sin_port 
<token> == b->addr4.sin_addr.s_addr && <answer> a->addr4.sin_addr.s_addr 
a->src4.s_addr <token> b->src4.s_addr && a->src_if4 == b->src_if4) || <answer> == 
(a->addr.sa_family <token> AF_INET6 && <answer> == 
b->addr.sa_family == AF_INET6 <token> <answer> && 
<token> == b->addr6.sin6_port && <answer> a->addr6.sin6_port 
ipv6_addr_equal(&a->addr6.sin6_addr, <token> && <answer> &b->addr6.sin6_addr) 
a->addr6.sin6_scope_id == <token> && <answer> b->addr6.sin6_scope_id 
ipv6_addr_equal(&a->src6, &b->src6)) <token> <answer> || 
unlikely(!a->addr.sa_family <token> !b->addr.sa_family); <answer> && 
<token> wg_socket_set_peer_endpoint(struct wg_peer *peer, <answer> void 
<token> struct endpoint *endpoint) <answer> const 
<token> (endpoint_eq(endpoint, &peer->endpoint)) <answer> if 
if (endpoint->addr.sa_family == AF_INET) <token> <answer> { 
<token> = endpoint->addr4; <answer> peer->endpoint.addr4 
peer->endpoint.src4 = <token> <answer> endpoint->src4; 
peer->endpoint.src_if4 = <token> <answer> endpoint->src_if4; 
} else if (IS_ENABLED(CONFIG_IPV6) && endpoint->addr.sa_family <token> AF_INET6) { <answer> == 
<token> = endpoint->addr6; <answer> peer->endpoint.addr6 
peer->endpoint.src6 = <token> <answer> endpoint->src6; 
<token> else { <answer> } 
goto <token> <answer> out; 
void wg_socket_set_peer_endpoint_from_skb(struct wg_peer <token> <answer> *peer, 
<token> struct sk_buff *skb) <answer> const 
<token> endpoint endpoint; <answer> struct 
if (!wg_socket_endpoint_from_skb(&endpoint, <token> <answer> skb)) 
<token> &endpoint); <answer> wg_socket_set_peer_endpoint(peer, 
void wg_socket_clear_peer_endpoint_src(struct <token> *peer) <answer> wg_peer 
<token> 0, sizeof(peer->endpoint.src6)); <answer> memset(&peer->endpoint.src6, 
static int wg_receive(struct sock <token> struct sk_buff *skb) <answer> *sk, 
struct <token> *wg; <answer> wg_device 
if <token> <answer> (unlikely(!sk)) 
<token> err; <answer> goto 
wg <token> sk->sk_user_data; <answer> = 
<token> (unlikely(!wg)) <answer> if 
<token> err; <answer> goto 
wg_packet_receive(wg, <token> <answer> skb); 
<token> 0; <answer> return 
<token> 0; <answer> return 
static void sock_free(struct sock <token> <answer> *sock) 
if <token> <answer> (unlikely(!sock)) 
static void <token> socket *sock) <answer> set_sock_opts(struct 
sock->sk->sk_allocation <token> GFP_ATOMIC; <answer> = 
<token> = INT_MAX; <answer> sock->sk->sk_sndbuf 
int wg_socket_init(struct wg_device *wg, u16 <token> <answer> port) 
<token> net *net; <answer> struct 
int <token> <answer> ret; 
struct udp_tunnel_sock_cfg cfg <token> { <answer> = 
.sk_user_data = <token> <answer> wg, 
<token> = 1, <answer> .encap_type 
<token> = wg_receive <answer> .encap_rcv 
struct <token> *new4 = NULL, *new6 = NULL; <answer> socket 
struct udp_port_cfg port4 = <token> <answer> { 
.family = <token> <answer> AF_INET, 
.local_ip.s_addr <token> htonl(INADDR_ANY), <answer> = 
.local_udp_port = <token> <answer> htons(port), 
<token> = true <answer> .use_udp_checksums 
<token> IS_ENABLED(CONFIG_IPV6) <answer> #if 
int <token> = 0; <answer> retries 
struct <token> port6 = { <answer> udp_port_cfg 
.family = <token> <answer> AF_INET6, 
.local_ip6 = <token> <answer> IN6ADDR_ANY_INIT, 
.use_udp6_tx_checksums = <token> <answer> true, 
.use_udp6_rx_checksums <token> true, <answer> = 
.ipv6_v6only = <token> <answer> true 
<token> = rcu_dereference(wg->creating_net); <answer> net 
net = net ? <token> : NULL; <answer> maybe_get_net(net) 
<token> (unlikely(!net)) <answer> if 
<token> -ENONET; <answer> return 
<token> IS_ENABLED(CONFIG_IPV6) <answer> #if 
ret = <token> &port4, &new4); <answer> udp_sock_create(net, 
if (ret <token> 0) { <answer> < 
<token> Could not create IPv4 socket\n", wg->dev->name); <answer> pr_err("%s: 
<token> out; <answer> goto 
<token> new4, &cfg); <answer> setup_udp_tunnel_sock(net, 
#if <token> <answer> IS_ENABLED(CONFIG_IPV6) 
if <token> { <answer> (ipv6_mod_enabled()) 
port6.local_udp_port = <token> <answer> inet_sk(new4->sk)->inet_sport; 
<token> = udp_sock_create(net, &port6, &new6); <answer> ret 
if <token> < 0) { <answer> (ret 
if <token> == -EADDRINUSE && !port && retries++ < 100) <answer> (ret 
<token> retry; <answer> goto 
pr_err("%s: Could <token> create IPv6 socket\n", <answer> not 
goto <token> <answer> out; 
setup_udp_tunnel_sock(net, new6, <token> <answer> &cfg); 
wg_socket_reinit(wg, new4->sk, new6 ? new6->sk : <token> <answer> NULL); 
ret <token> 0; <answer> = 
return <token> <answer> ret; 
void wg_socket_reinit(struct wg_device <token> struct sock *new4, <answer> *wg, 
<token> sock *new6) <answer> struct 
struct sock <token> *old6; <answer> *old4, 
old4 = <token> <answer> rcu_dereference_protected(wg->sock4, 
<token> = rcu_dereference_protected(wg->sock6, <answer> old6 
<token> new4); <answer> rcu_assign_pointer(wg->sock4, 
rcu_assign_pointer(wg->sock6, <token> <answer> new6); 
<token> (new4) <answer> if 
<token> = ntohs(inet_sk(new4)->inet_sport); <answer> wg->incoming_port 
<token> "qlcnic.h" <answer> #include 
static const struct qlcnic_mailbox_metadata <token> = { <answer> qlcnic_mbx_tbl[] 
{QLCNIC_CMD_CREATE_RX_CTX, 4, <token> <answer> 1}, 
{QLCNIC_CMD_DESTROY_RX_CTX, <token> 1}, <answer> 2, 
{QLCNIC_CMD_CREATE_TX_CTX, <token> 1}, <answer> 4, 
{QLCNIC_CMD_DESTROY_TX_CTX, 3, <token> <answer> 1}, 
{QLCNIC_CMD_INTRPT_TEST, <token> 1}, <answer> 4, 
{QLCNIC_CMD_SET_MTU, <token> 1}, <answer> 4, 
{QLCNIC_CMD_READ_PHY, 4, <token> <answer> 2}, 
<token> 5, 1}, <answer> {QLCNIC_CMD_WRITE_PHY, 
{QLCNIC_CMD_READ_HW_REG, 4, <token> <answer> 1}, 
{QLCNIC_CMD_GET_FLOW_CTL, 4, <token> <answer> 2}, 
<token> 4, 1}, <answer> {QLCNIC_CMD_SET_FLOW_CTL, 
{QLCNIC_CMD_READ_MAX_MTU, 4, <token> <answer> 2}, 
{QLCNIC_CMD_READ_MAX_LRO, 4, <token> <answer> 2}, 
<token> 4, 3}, <answer> {QLCNIC_CMD_MAC_ADDRESS, 
<token> 4, 1}, <answer> {QLCNIC_CMD_GET_PCI_INFO, 
{QLCNIC_CMD_GET_NIC_INFO, <token> 1}, <answer> 4, 
{QLCNIC_CMD_SET_NIC_INFO, 4, <token> <answer> 1}, 
<token> 4, 3}, <answer> {QLCNIC_CMD_GET_ESWITCH_CAPABILITY, 
{QLCNIC_CMD_TOGGLE_ESWITCH, 4, <token> <answer> 1}, 
{QLCNIC_CMD_GET_ESWITCH_STATUS, 4, <token> <answer> 3}, 
{QLCNIC_CMD_SET_PORTMIRRORING, 4, <token> <answer> 1}, 
<token> 4, 1}, <answer> {QLCNIC_CMD_CONFIGURE_ESWITCH, 
{QLCNIC_CMD_GET_MAC_STATS, <token> 1}, <answer> 4, 
{QLCNIC_CMD_GET_ESWITCH_PORT_CONFIG, <token> 3}, <answer> 4, 
<token> 4, 1}, <answer> {QLCNIC_CMD_GET_ESWITCH_STATS, 
{QLCNIC_CMD_CONFIG_PORT, 4, <token> <answer> 1}, 
{QLCNIC_CMD_TEMP_SIZE, 4, <token> <answer> 4}, 
{QLCNIC_CMD_GET_TEMP_HDR, <token> 1}, <answer> 4, 
{QLCNIC_CMD_82XX_SET_DRV_VER, 4, <token> <answer> 1}, 
{QLCNIC_CMD_GET_LED_STATUS, <token> 2}, <answer> 4, 
<token> 2, 3}, <answer> {QLCNIC_CMD_MQ_TX_CONFIG_INTR, 
{QLCNIC_CMD_DCB_QUERY_CAP, 1, <token> <answer> 2}, 
{QLCNIC_CMD_DCB_QUERY_PARAM, <token> 1}, <answer> 4, 
static inline u32 <token> qlcnic_hardware_context *ahw) <answer> qlcnic_get_cmd_signature(struct 
return (ahw->pci_func <token> 0xff) | ((ahw->fw_hal_version & 0xff) << 8) | <answer> & 
<token> << 16); <answer> (0xcafe 
int qlcnic_config_switch_port(struct qlcnic_adapter <token> <answer> *adapter, 
<token> qlcnic_esw_func_cfg *esw_cfg) <answer> struct 
struct device <token> = &adapter->pdev->dev; <answer> *dev 
struct <token> cmd; <answer> qlcnic_cmd_args 
int err = <token> index; <answer> -EIO, 
u32 arg1, arg2 <token> 0; <answer> = 
<token> pci_func; <answer> u8 
if <token> != QLCNIC_MGMT_FUNC) { <answer> (adapter->ahw->op_mode 
dev_err(&adapter->pdev->dev, "%s: Not <token> management function\n", <answer> a 
<token> err; <answer> return 
<token> = esw_cfg->pci_func; <answer> pci_func 
<token> = qlcnic_is_valid_nic_func(adapter, pci_func); <answer> index 
if <token> < 0) <answer> (index 
return <token> <answer> err; 
arg1 = <token> & BIT_0); <answer> (adapter->npars[index].phy_port 
arg1 |= (pci_func <token> 8); <answer> << 
if <token> &arg1, &arg2)) <answer> (__qlcnic_get_eswitch_port_config(adapter, 
return <token> <answer> err; 
arg1 &= ~(0x0ff <token> 8); <answer> << 
<token> |= (pci_func << 8); <answer> arg1 
arg1 &= ~(BIT_2 <token> BIT_3); <answer> | 
<token> (esw_cfg->op_mode) { <answer> switch 
<token> QLCNIC_PORT_DEFAULTS: <answer> case 
<token> |= (BIT_4 | BIT_6 | BIT_7); <answer> arg1 
arg2 <token> (BIT_0 | BIT_1); <answer> |= 
if (adapter->ahw->capabilities & <token> <answer> QLCNIC_FW_CAPABILITY_TSO) 
arg2 <token> (BIT_2 | BIT_3); <answer> |= 
if <token> <answer> (!(esw_cfg->discard_tagged)) 
arg1 &= <token> <answer> ~BIT_4; 
if <token> <answer> (!(esw_cfg->promisc_mode)) 
<token> &= ~BIT_6; <answer> arg1 
if <token> <answer> (!(esw_cfg->mac_override)) 
arg1 <token> ~BIT_7; <answer> &= 
if <token> <answer> (!(esw_cfg->mac_anti_spoof)) 
<token> &= ~BIT_0; <answer> arg2 
if (!(esw_cfg->offload_flags & <token> <answer> BIT_0)) 
arg2 &= <token> | BIT_2 | BIT_3); <answer> ~(BIT_1 
if (!(esw_cfg->offload_flags & <token> <answer> BIT_1)) 
<token> &= ~BIT_2; <answer> arg2 
if <token> & BIT_2)) <answer> (!(esw_cfg->offload_flags 
arg2 &= <token> <answer> ~BIT_3; 
case <token> <answer> QLCNIC_ADD_VLAN: 
arg1 &= <token> << 16); <answer> ~(0x0ffff 
arg1 |= (BIT_2 | <token> <answer> BIT_5); 
<token> |= (esw_cfg->vlan_id << 16); <answer> arg1 
case <token> <answer> QLCNIC_DEL_VLAN: 
<token> |= (BIT_3 | BIT_5); <answer> arg1 
arg1 &= <token> << 16); <answer> ~(0x0ffff 
<token> "%s: Invalid opmode 0x%x\n", <answer> dev_err(&adapter->pdev->dev, 
<token> esw_cfg->op_mode); <answer> __func__, 
<token> err; <answer> return 
err = <token> adapter, <answer> qlcnic_alloc_mbx_args(&cmd, 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> = arg1; <answer> cmd.req.arg[1] 
<token> = arg2; <answer> cmd.req.arg[2] 
<token> = qlcnic_issue_cmd(adapter, &cmd); <answer> err 
<token> (err != QLCNIC_RCODE_SUCCESS) <answer> if 
<token> "Failed to configure eswitch for vNIC function %d\n", <answer> dev_err(dev, 
dev_info(dev, "Configured eSwitch for <token> function %d\n", <answer> vNIC 
return <token> <answer> err; 
qlcnic_get_eswitch_port_config(struct <token> *adapter, <answer> qlcnic_adapter 
struct qlcnic_esw_func_cfg <token> <answer> *esw_cfg) 
u32 <token> arg2; <answer> arg1, 
int <token> <answer> index; 
<token> phy_port; <answer> u8 
<token> (adapter->ahw->op_mode == QLCNIC_MGMT_FUNC) { <answer> if 
index = qlcnic_is_valid_nic_func(adapter, <token> <answer> esw_cfg->pci_func); 
if (index < <token> <answer> 0) 
<token> -EIO; <answer> return 
phy_port <token> adapter->npars[index].phy_port; <answer> = 
<token> else { <answer> } 
phy_port = <token> <answer> adapter->ahw->physical_port; 
<token> = phy_port; <answer> arg1 
arg1 |= (esw_cfg->pci_func <token> 8); <answer> << 
if (__qlcnic_get_eswitch_port_config(adapter, <token> &arg2)) <answer> &arg1, 
<token> -EIO; <answer> return 
esw_cfg->discard_tagged <token> !!(arg1 & BIT_4); <answer> = 
<token> = !!(arg1 & BIT_5); <answer> esw_cfg->host_vlan_tag 
<token> = !!(arg1 & BIT_6); <answer> esw_cfg->promisc_mode 
<token> = !!(arg1 & BIT_7); <answer> esw_cfg->mac_override 
esw_cfg->vlan_id <token> LSW(arg1 >> 16); <answer> = 
esw_cfg->mac_anti_spoof = (arg2 <token> 0x1); <answer> & 
esw_cfg->offload_flags = <token> >> 1) & 0x7); <answer> ((arg2 
return <token> <answer> 0; 
#define <token> "starfive_starlink_pmu" <answer> STARLINK_PMU_PDEV_NAME 
#define pr_fmt(fmt) STARLINK_PMU_PDEV_NAME ": <token> fmt <answer> " 
<token> <linux/bitmap.h> <answer> #include 
<token> <linux/cpu_pm.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/mod_devicetable.h> 
#include <token> <answer> <linux/perf_event.h> 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/sysfs.h> <answer> #include 
#define STARLINK_PMU_MAX_COUNTERS <token> <answer> 64 
#define STARLINK_PMU_NUM_COUNTERS <token> <answer> 16 
<token> STARLINK_PMU_IDX_CYCLE_COUNTER 63 <answer> #define 
#define <token> 0x060 <answer> STARLINK_PMU_EVENT_SELECT 
#define STARLINK_PMU_EVENT_COUNTER <token> <answer> 0x160 
#define <token> GENMASK_ULL(63, 0) <answer> STARLINK_PMU_COUNTER_MASK 
#define <token> 0x058 <answer> STARLINK_PMU_CYCLE_COUNTER 
<token> STARLINK_PMU_CONTROL 0x040 <answer> #define 
<token> STARLINK_PMU_GLOBAL_ENABLE BIT_ULL(0) <answer> #define 
<token> STARLINK_PMU_INTERRUPT_ENABLE 0x050 <answer> #define 
#define <token> 0x048 <answer> STARLINK_PMU_COUNTER_OVERFLOW_STATUS 
#define STARLINK_PMU_CYCLE_OVERFLOW_MASK <token> <answer> BIT_ULL(63) 
<token> STARLINK_CYCLES 0x058 <answer> #define 
#define <token> 0x04000701 <answer> CACHE_READ_REQUEST 
<token> CACHE_WRITE_REQUEST 0x03000001 <answer> #define 
#define CACHE_RELEASE_REQUEST <token> <answer> 0x0003e001 
<token> CACHE_READ_HIT 0x00901202 <answer> #define 
#define <token> 0x04008002 <answer> CACHE_READ_MISS 
#define CACHE_WRITE_HIT <token> <answer> 0x006c0002 
#define CACHE_WRITE_MISS <token> <answer> 0x03000002 
#define <token> 0x00000403 <answer> CACHE_WRITEBACK 
#define to_starlink_pmu(p) (container_of(p, struct <token> pmu)) <answer> starlink_pmu, 
#define <token> _config) \ <answer> STARLINK_FORMAT_ATTR(_name, 
(&((struct dev_ext_attribute[]) <token> \ <answer> { 
{ .attr <token> __ATTR(_name, 0444, starlink_pmu_sysfs_format_show, NULL), \ <answer> = 
.var = (void *)_config, } <token> <answer> \ 
#define STARLINK_EVENT_ATTR(_name, _id) <token> <answer> \ 
PMU_EVENT_ATTR_ID(_name, <token> _id) <answer> starlink_pmu_sysfs_event_show, 
static int <token> <answer> starlink_pmu_cpuhp_state; 
struct <token> { <answer> starlink_hw_events 
<token> perf_event *events[STARLINK_PMU_MAX_COUNTERS]; <answer> struct 
DECLARE_BITMAP(used_mask, <token> <answer> STARLINK_PMU_MAX_COUNTERS); 
struct starlink_pmu <token> <answer> { 
struct <token> pmu; <answer> pmu 
struct starlink_hw_events __percpu <token> <answer> *hw_events; 
struct <token> node; <answer> hlist_node 
struct <token> starlink_pmu_pm_nb; <answer> notifier_block 
<token> __iomem *pmu_base; <answer> void 
cpumask_t <token> <answer> cpumask; 
int <token> <answer> irq; 
<token> ssize_t <answer> static 
<token> device *dev, <answer> starlink_pmu_sysfs_format_show(struct 
struct <token> *attr, <answer> device_attribute 
char <token> <answer> *buf) 
struct dev_ext_attribute *eattr <token> container_of(attr, <answer> = 
struct <token> attr); <answer> dev_ext_attribute, 
<token> sysfs_emit(buf, "%s\n", (char *)eattr->var); <answer> return 
static <token> attribute *starlink_pmu_format_attrs[] = { <answer> struct 
STARLINK_FORMAT_ATTR(event, <token> <answer> "config:0-31"), 
static const struct attribute_group starlink_pmu_format_attr_group <token> { <answer> = 
.name = <token> <answer> "format", 
<token> = starlink_pmu_format_attrs, <answer> .attrs 
static <token> <answer> ssize_t 
starlink_pmu_sysfs_event_show(struct <token> *dev, <answer> device 
struct device_attribute <token> <answer> *attr, 
<token> *buf) <answer> char 
struct perf_pmu_events_attr *eattr <token> container_of(attr, <answer> = 
struct <token> attr); <answer> perf_pmu_events_attr, 
<token> sysfs_emit(buf, "event=0x%02llx\n", eattr->id); <answer> return 
static <token> attribute *starlink_pmu_event_attrs[] = { <answer> struct 
<token> STARLINK_CYCLES), <answer> STARLINK_EVENT_ATTR(cycles, 
STARLINK_EVENT_ATTR(read_request, <token> <answer> CACHE_READ_REQUEST), 
<token> CACHE_WRITE_REQUEST), <answer> STARLINK_EVENT_ATTR(write_request, 
STARLINK_EVENT_ATTR(release_request, <token> <answer> CACHE_RELEASE_REQUEST), 
STARLINK_EVENT_ATTR(read_hit, <token> <answer> CACHE_READ_HIT), 
<token> CACHE_READ_MISS), <answer> STARLINK_EVENT_ATTR(read_miss, 
<token> CACHE_WRITE_HIT), <answer> STARLINK_EVENT_ATTR(write_hit, 
<token> CACHE_WRITE_MISS), <answer> STARLINK_EVENT_ATTR(write_miss, 
<token> CACHE_WRITEBACK), <answer> STARLINK_EVENT_ATTR(writeback, 
<token> const struct attribute_group starlink_pmu_events_attr_group = { <answer> static 
.name <token> "events", <answer> = 
.attrs <token> starlink_pmu_event_attrs, <answer> = 
<token> ssize_t <answer> static 
cpumask_show(struct device *dev, <token> device_attribute *attr, char *buf) <answer> struct 
struct starlink_pmu *starlink_pmu = <token> <answer> to_starlink_pmu(dev_get_drvdata(dev)); 
return cpumap_print_to_pagebuf(true, <token> &starlink_pmu->cpumask); <answer> buf, 
<token> DEVICE_ATTR_RO(cpumask); <answer> static 
<token> struct attribute *starlink_pmu_cpumask_attrs[] = { <answer> static 
static const struct attribute_group starlink_pmu_cpumask_attr_group <token> { <answer> = 
.attrs = <token> <answer> starlink_pmu_cpumask_attrs, 
static const struct attribute_group <token> = { <answer> *starlink_pmu_attr_groups[] 
static void <token> perf_event *event) <answer> starlink_pmu_set_event_period(struct 
struct starlink_pmu <token> = to_starlink_pmu(event->pmu); <answer> *starlink_pmu 
struct hw_perf_event <token> = &event->hw; <answer> *hwc 
int idx <token> event->hw.idx; <answer> = 
u64 val = <token> >> 1; <answer> STARLINK_PMU_COUNTER_MASK 
<token> val); <answer> local64_set(&hwc->prev_count, 
if (hwc->config == <token> <answer> STARLINK_CYCLES) 
<token> starlink_pmu->pmu_base + STARLINK_PMU_CYCLE_COUNTER); <answer> writeq(val, 
writeq(val, starlink_pmu->pmu_base + STARLINK_PMU_EVENT_COUNTER <token> <answer> + 
<token> * sizeof(u64)); <answer> idx 
static void starlink_pmu_counter_start(struct <token> *event, <answer> perf_event 
struct starlink_pmu <token> <answer> *starlink_pmu) 
struct hw_perf_event *hwc = <token> <answer> &event->hw; 
int idx <token> event->hw.idx; <answer> = 
<token> val; <answer> u64 
val = readq(starlink_pmu->pmu_base + <token> <answer> STARLINK_PMU_INTERRUPT_ENABLE); 
if <token> == STARLINK_CYCLES) { <answer> (hwc->config 
val <token> STARLINK_PMU_CYCLE_OVERFLOW_MASK; <answer> |= 
} else <token> <answer> { 
<token> starlink_pmu->pmu_base + <answer> writeq(event->hw.config, 
STARLINK_PMU_EVENT_SELECT + idx <token> sizeof(u64)); <answer> * 
val <token> BIT_ULL(idx); <answer> |= 
writeq(val, starlink_pmu->pmu_base <token> STARLINK_PMU_INTERRUPT_ENABLE); <answer> + 
writeq(STARLINK_PMU_GLOBAL_ENABLE, starlink_pmu->pmu_base <token> <answer> + 
static <token> starlink_pmu_counter_stop(struct perf_event *event, <answer> void 
struct <token> *starlink_pmu) <answer> starlink_pmu 
struct hw_perf_event <token> = &event->hw; <answer> *hwc 
int idx <token> event->hw.idx; <answer> = 
<token> val; <answer> u64 
val <token> readq(starlink_pmu->pmu_base + STARLINK_PMU_CONTROL); <answer> = 
val &= <token> <answer> ~STARLINK_PMU_GLOBAL_ENABLE; 
writeq(val, starlink_pmu->pmu_base + <token> <answer> STARLINK_PMU_CONTROL); 
val = <token> + STARLINK_PMU_INTERRUPT_ENABLE); <answer> readq(starlink_pmu->pmu_base 
if <token> == STARLINK_CYCLES) <answer> (hwc->config 
<token> &= ~STARLINK_PMU_CYCLE_OVERFLOW_MASK; <answer> val 
<token> &= ~BIT_ULL(idx); <answer> val 
<token> starlink_pmu->pmu_base + STARLINK_PMU_INTERRUPT_ENABLE); <answer> writeq(val, 
static <token> starlink_pmu_update(struct perf_event *event) <answer> void 
<token> starlink_pmu *starlink_pmu = to_starlink_pmu(event->pmu); <answer> struct 
struct hw_perf_event <token> = &event->hw; <answer> *hwc 
int idx <token> hwc->idx; <answer> = 
u64 prev_raw_count, <token> <answer> new_raw_count; 
<token> oldval; <answer> u64 
<token> delta; <answer> u64 
<token> { <answer> do 
<token> = local64_read(&hwc->prev_count); <answer> prev_raw_count 
<token> (hwc->config == STARLINK_CYCLES) <answer> if 
new_raw_count = readq(starlink_pmu->pmu_base <token> <answer> + 
<token> = readq(starlink_pmu->pmu_base + <answer> new_raw_count 
STARLINK_PMU_EVENT_COUNTER <token> <answer> + 
idx <token> sizeof(u64)); <answer> * 
oldval = local64_cmpxchg(&hwc->prev_count, <token> <answer> prev_raw_count, 
} while (oldval != <token> <answer> prev_raw_count); 
delta = (new_raw_count <token> prev_raw_count) & STARLINK_PMU_COUNTER_MASK; <answer> - 
<token> &event->count); <answer> local64_add(delta, 
static void <token> perf_event *event, int flags) <answer> starlink_pmu_start(struct 
<token> starlink_pmu *starlink_pmu = to_starlink_pmu(event->pmu); <answer> struct 
struct <token> *hwc = &event->hw; <answer> hw_perf_event 
if <token> & PERF_HES_STOPPED))) <answer> (WARN_ON_ONCE(!(hwc->state 
if <token> & PERF_EF_RELOAD) <answer> (flags 
WARN_ON_ONCE(!(event->hw.state & <token> <answer> PERF_HES_UPTODATE)); 
<token> = 0; <answer> hwc->state 
<token> starlink_pmu); <answer> starlink_pmu_counter_start(event, 
static void starlink_pmu_stop(struct perf_event *event, <token> flags) <answer> int 
struct starlink_pmu *starlink_pmu = <token> <answer> to_starlink_pmu(event->pmu); 
<token> hw_perf_event *hwc = &event->hw; <answer> struct 
<token> (hwc->state & PERF_HES_STOPPED) <answer> if 
<token> starlink_pmu); <answer> starlink_pmu_counter_stop(event, 
hwc->state |= <token> | PERF_HES_UPTODATE; <answer> PERF_HES_STOPPED 
static int starlink_pmu_add(struct <token> *event, int flags) <answer> perf_event 
struct starlink_pmu *starlink_pmu = <token> <answer> to_starlink_pmu(event->pmu); 
<token> starlink_hw_events *hw_events = <answer> struct 
struct hw_perf_event <token> = &event->hw; <answer> *hwc 
unsigned long *used_mask = <token> <answer> hw_events->used_mask; 
<token> n_events = STARLINK_PMU_NUM_COUNTERS; <answer> u32 
int <token> <answer> idx; 
if (hwc->config == <token> { <answer> STARLINK_CYCLES) 
<token> = STARLINK_PMU_IDX_CYCLE_COUNTER; <answer> idx 
<token> else { <answer> } 
<token> = find_first_zero_bit(used_mask, n_events); <answer> idx 
if <token> != event->pmu && <answer> (event->group_leader->pmu 
<token> false; <answer> return 
for_each_sibling_event(sibling, leader) <token> <answer> { 
if <token> != event->pmu && !is_software_event(sibling)) <answer> (sibling->pmu 
<token> false; <answer> return 
return counter <token> STARLINK_PMU_NUM_COUNTERS; <answer> <= 
static <token> starlink_pmu_event_init(struct perf_event *event) <answer> int 
<token> starlink_pmu *starlink_pmu = to_starlink_pmu(event->pmu); <answer> struct 
struct hw_perf_event *hwc <token> &event->hw; <answer> = 
if <token> <answer> (hwc->sample_period) 
return <token> <answer> -EOPNOTSUPP; 
if (event->cpu <token> 0 || event->attach_state & PERF_ATTACH_TASK) <answer> < 
return <token> <answer> -EOPNOTSUPP; 
if <token> <answer> (!starlink_pmu_validate_event_group(event)) 
<token> -EINVAL; <answer> return 
hwc->idx = <token> <answer> -1; 
<token> = event->attr.config; <answer> hwc->config 
<token> = cpumask_first(&starlink_pmu->cpumask); <answer> event->cpu 
return <token> <answer> 0; 
static irqreturn_t <token> irq_num, void *data) <answer> starlink_pmu_handle_irq(int 
struct starlink_pmu *starlink_pmu = <token> <answer> data; 
struct <token> *hw_events = <answer> starlink_hw_events 
<token> handled = false; <answer> bool 
<token> idx; <answer> int 
u64 <token> <answer> overflow_status; 
<token> (idx = 0; idx < STARLINK_PMU_MAX_COUNTERS; idx++) { <answer> for 
struct perf_event <token> = hw_events->events[idx]; <answer> *event 
<token> (!event) <answer> if 
<token> = readq(starlink_pmu->pmu_base + <answer> overflow_status 
if (!(overflow_status <token> BIT_ULL(idx))) <answer> & 
writeq(BIT_ULL(idx), <token> + <answer> starlink_pmu->pmu_base 
handled <token> true; <answer> = 
return <token> <answer> IRQ_RETVAL(handled); 
static int starlink_setup_irqs(struct starlink_pmu <token> <answer> *starlink_pmu, 
<token> platform_device *pdev) <answer> struct 
<token> ret, irq; <answer> int 
irq = platform_get_irq(pdev, <token> <answer> 0); 
if <token> < 0) <answer> (irq 
<token> -EINVAL; <answer> return 
ret = devm_request_irq(&pdev->dev, irq, <token> <answer> starlink_pmu_handle_irq, 
<token> STARLINK_PMU_PDEV_NAME, starlink_pmu); <answer> 0, 
<token> (ret) <answer> if 
return dev_err_probe(&pdev->dev, ret, <token> to request IRQ\n"); <answer> "Failed 
starlink_pmu->irq = <token> <answer> irq; 
return <token> <answer> 0; 
static <token> starlink_pmu_pm_notify(struct notifier_block *b, <answer> int 
unsigned long cmd, void <token> <answer> *v) 
struct starlink_pmu <token> = container_of(b, struct starlink_pmu, <answer> *starlink_pmu 
struct <token> *hw_events = <answer> starlink_hw_events 
int <token> = bitmap_weight(hw_events->used_mask, <answer> enabled 
struct <token> *event; <answer> perf_event 
<token> idx; <answer> int 
<token> (!enabled) <answer> if 
<token> NOTIFY_OK; <answer> return 
for (idx = 0; idx < <token> idx++) { <answer> STARLINK_PMU_MAX_COUNTERS; 
event <token> hw_events->events[idx]; <answer> = 
<token> (!event) <answer> if 
<token> (cmd) { <answer> switch 
<token> CPU_PM_ENTER: <answer> case 
static int rx_copybreak = <token> <answer> 200; 
static unsigned int use_mmio = <token> <answer> 2; 
static const int multicast_filter_limit <token> 32; <answer> = 
#define <token> 2 <answer> TXHI_ENTRIES 
<token> TXLO_ENTRIES 128 <answer> #define 
#define <token> 32 <answer> RX_ENTRIES 
#define <token> 16 <answer> COMMAND_ENTRIES 
#define <token> 32 <answer> RESPONSE_ENTRIES 
#define <token> (COMMAND_ENTRIES * sizeof(struct cmd_desc)) <answer> COMMAND_RING_SIZE 
#define RESPONSE_RING_SIZE <token> * sizeof(struct resp_desc)) <answer> (RESPONSE_ENTRIES 
#define <token> 128 <answer> RXFREE_ENTRIES 
#define RXENT_ENTRIES <token> - 1) <answer> (RXFREE_ENTRIES 
static <token> struct pci_device_id typhoon_pci_tbl[] = { <answer> const 
{ PCI_VENDOR_ID_3COM, <token> <answer> PCI_DEVICE_ID_3COM_3CR990, 
<token> PCI_ANY_ID, 0, 0,TYPHOON_TX }, <answer> PCI_ANY_ID, 
{ PCI_VENDOR_ID_3COM, <token> <answer> PCI_DEVICE_ID_3COM_3CR990_TX_95, 
PCI_ANY_ID, PCI_ANY_ID, <token> 0, TYPHOON_TX95 }, <answer> 0, 
<token> PCI_VENDOR_ID_3COM, PCI_DEVICE_ID_3COM_3CR990_TX_97, <answer> { 
<token> PCI_ANY_ID, 0, 0, TYPHOON_TX97 }, <answer> PCI_ANY_ID, 
{ <token> PCI_DEVICE_ID_3COM_3CR990B, <answer> PCI_VENDOR_ID_3COM, 
PCI_ANY_ID, 0x1000, 0, 0, TYPHOON_TXM <token> <answer> }, 
{ <token> PCI_DEVICE_ID_3COM_3CR990B, <answer> PCI_VENDOR_ID_3COM, 
<token> 0x1102, 0, 0, TYPHOON_FXM }, <answer> PCI_ANY_ID, 
<token> PCI_VENDOR_ID_3COM, PCI_DEVICE_ID_3COM_3CR990B, <answer> { 
PCI_ANY_ID, 0x2000, 0, <token> TYPHOON_BSVR }, <answer> 0, 
{ PCI_VENDOR_ID_3COM, <token> <answer> PCI_DEVICE_ID_3COM_3CR990_FX, 
<token> 0x1101, 0, 0, TYPHOON_FX95 }, <answer> PCI_ANY_ID, 
{ PCI_VENDOR_ID_3COM, <token> <answer> PCI_DEVICE_ID_3COM_3CR990_FX, 
<token> 0x1102, 0, 0, TYPHOON_FX97 }, <answer> PCI_ANY_ID, 
{ <token> PCI_DEVICE_ID_3COM_3CR990_FX, <answer> PCI_VENDOR_ID_3COM, 
<token> 0x2101, 0, 0, TYPHOON_FX95SVR }, <answer> PCI_ANY_ID, 
{ <token> PCI_DEVICE_ID_3COM_3CR990_FX, <answer> PCI_VENDOR_ID_3COM, 
<token> 0x2102, 0, 0, TYPHOON_FX97SVR }, <answer> PCI_ANY_ID, 
{ PCI_VENDOR_ID_3COM, <token> <answer> PCI_DEVICE_ID_3COM_3CR990SVR95, 
PCI_ANY_ID, PCI_ANY_ID, 0, 0, TYPHOON_SVR95 <token> <answer> }, 
{ <token> PCI_DEVICE_ID_3COM_3CR990SVR97, <answer> PCI_VENDOR_ID_3COM, 
PCI_ANY_ID, PCI_ANY_ID, 0, 0, TYPHOON_SVR97 <token> <answer> }, 
{ PCI_VENDOR_ID_3COM, <token> <answer> PCI_DEVICE_ID_3COM_3CR990SVR, 
PCI_ANY_ID, PCI_ANY_ID, 0, <token> TYPHOON_SVR }, <answer> 0, 
{ 0, <token> <answer> } 
MODULE_DEVICE_TABLE(pci, <token> <answer> typhoon_pci_tbl); 
#define __3xp_aligned <token> <answer> ____cacheline_aligned 
struct typhoon_shared <token> <answer> { 
struct <token> iface; <answer> typhoon_interface 
struct typhoon_indexes indexes <token> <answer> __3xp_aligned; 
<token> tx_desc txLo[TXLO_ENTRIES] __3xp_aligned; <answer> struct 
<token> rx_desc rxLo[RX_ENTRIES] __3xp_aligned; <answer> struct 
<token> rx_desc rxHi[RX_ENTRIES] __3xp_aligned; <answer> struct 
struct cmd_desc <token> __3xp_aligned; <answer> cmd[COMMAND_ENTRIES] 
<token> resp_desc resp[RESPONSE_ENTRIES] __3xp_aligned; <answer> struct 
<token> rx_free rxBuff[RXFREE_ENTRIES] __3xp_aligned; <answer> struct 
u32 <token> <answer> zeroWord; 
<token> tx_desc txHi[TXHI_ENTRIES]; <answer> struct 
} <token> <answer> __packed; 
struct <token> { <answer> rxbuff_ent 
struct sk_buff <token> <answer> *skb; 
<token> dma_addr; <answer> dma_addr_t 
struct typhoon <token> <answer> { 
enum <token> { <answer> state_values 
Sleeping = 0, <token> <answer> Running, 
#define typhoon_post_pci_writes(x) <token> <answer> \ 
do { if (likely(use_mmio)) ioread32(x+TYPHOON_REG_HEARTBEAT); } while <token> <answer> (0) 
<token> TYPHOON_UDELAY 50 <answer> #define 
#define TYPHOON_RESET_TIMEOUT_SLEEP <token> * HZ) <answer> (6 
#define TYPHOON_RESET_TIMEOUT_NOSLEEP ((6 * 1000000) <token> TYPHOON_UDELAY) <answer> / 
#define <token> ((1000000 / 2) / TYPHOON_UDELAY) <answer> TYPHOON_WAIT_TIMEOUT 
<token> defined(NETIF_F_TSO) <answer> #if 
#define skb_tso_size(x) <token> <answer> (skb_shinfo(x)->gso_size) 
#define TSO_NUM_DESCRIPTORS <token> <answer> 2 
#define <token> TYPHOON_OFFLOAD_TCP_SEGMENT <answer> TSO_OFFLOAD_ON 
<token> NETIF_F_TSO 0 <answer> #define 
#define skb_tso_size(x) <token> <answer> 0 
#define TSO_NUM_DESCRIPTORS <token> <answer> 0 
#define TSO_OFFLOAD_ON <token> <answer> 0 
<token> inline void <answer> static 
typhoon_inc_index(u32 *index, const int count, <token> int num_entries) <answer> const 
*index += count * sizeof(struct <token> <answer> cmd_desc); 
*index %= num_entries <token> sizeof(struct cmd_desc); <answer> * 
<token> inline void <answer> static 
typhoon_inc_cmd_index(u32 *index, const int <token> <answer> count) 
<token> count, COMMAND_ENTRIES); <answer> typhoon_inc_index(index, 
static <token> void <answer> inline 
typhoon_inc_resp_index(u32 *index, const <token> count) <answer> int 
typhoon_inc_index(index, <token> RESPONSE_ENTRIES); <answer> count, 
<token> inline void <answer> static 
typhoon_inc_rxfree_index(u32 <token> const int count) <answer> *index, 
typhoon_inc_index(index, <token> RXFREE_ENTRIES); <answer> count, 
static inline <token> <answer> void 
<token> *index, const int count) <answer> typhoon_inc_tx_index(u32 
if (wait_type <token> WaitSleep) <answer> == 
<token> err; <answer> return 
static <token> <answer> int 
typhoon_wait_status(void <token> *ioaddr, u32 wait_value) <answer> __iomem 
int i, err = <token> <answer> 0; 
<token> (i = 0; i < TYPHOON_WAIT_TIMEOUT; i++) { <answer> for 
if (ioread32(ioaddr + TYPHOON_REG_STATUS) == <token> <answer> wait_value) 
<token> out; <answer> goto 
<token> = -ETIMEDOUT; <answer> err 
<token> err; <answer> return 
static inline <token> <answer> void 
typhoon_media_status(struct net_device <token> struct resp_desc *resp) <answer> *dev, 
if <token> & TYPHOON_MEDIA_STAT_NO_LINK) <answer> (resp->parm1 
<token> inline void <answer> static 
typhoon_hello(struct typhoon <token> <answer> *tp) 
struct basic_ring *ring = <token> <answer> &tp->cmdRing; 
<token> cmd_desc *cmd; <answer> struct 
if (spin_trylock(&tp->command_lock)) <token> <answer> { 
cmd = (struct cmd_desc *)(ring->ringBase + <token> <answer> ring->lastWrite); 
<token> 1); <answer> typhoon_inc_cmd_index(&ring->lastWrite, 
<token> TYPHOON_CMD_HELLO_RESP); <answer> INIT_COMMAND_NO_RESPONSE(cmd, 
<token> tp->ioaddr + TYPHOON_REG_CMD_READY); <answer> iowrite32(ring->lastWrite, 
static <token> <answer> int 
typhoon_process_response(struct <token> *tp, int resp_size, <answer> typhoon 
<token> resp_desc *resp_save) <answer> struct 
<token> typhoon_indexes *indexes = tp->indexes; <answer> struct 
<token> resp_desc *resp; <answer> struct 
u8 *base = <token> <answer> tp->respRing.ringBase; 
int count, len, <token> <answer> wrap_len; 
u32 <token> <answer> cleared; 
u32 <token> <answer> ready; 
<token> = le32_to_cpu(indexes->respCleared); <answer> cleared 
ready = <token> <answer> le32_to_cpu(indexes->respReady); 
while <token> != ready) { <answer> (cleared 
resp = (struct resp_desc <token> + cleared); <answer> *)(base 
count = <token> + 1; <answer> resp->numDesc 
if (resp_save && resp->seqNo) <token> <answer> { 
if (count > resp_size) <token> <answer> { 
resp_save->flags = <token> <answer> TYPHOON_RESP_ERROR; 
goto <token> <answer> cleanup; 
<token> = 0; <answer> wrap_len 
<token> = count * sizeof(*resp); <answer> len 
if (unlikely(cleared <token> len > RESPONSE_RING_SIZE)) { <answer> + 
wrap_len = cleared + <token> - RESPONSE_RING_SIZE; <answer> len 
len = <token> - cleared; <answer> RESPONSE_RING_SIZE 
memcpy(resp_save, resp, <token> <answer> len); 
<token> (unlikely(wrap_len)) { <answer> if 
<token> += len / sizeof(*resp); <answer> resp_save 
memcpy(resp_save, base, <token> <answer> wrap_len); 
resp_save = <token> <answer> NULL; 
} else if (resp->cmd == TYPHOON_CMD_READ_MEDIA_STATUS) <token> <answer> { 
<token> resp); <answer> typhoon_media_status(tp->dev, 
} else if (resp->cmd <token> TYPHOON_CMD_HELLO_RESP) { <answer> == 
<token> else { <answer> } 
<token> unexpected response 0x%04x:%d:0x%02x:0x%04x:%08x:%08x\n", <answer> "dumping 
<token> resp->flags, <answer> resp->numDesc, 
<token> count); <answer> typhoon_inc_resp_index(&cleared, 
indexes->respCleared = <token> <answer> cpu_to_le32(cleared); 
return <token> == NULL; <answer> resp_save 
<token> inline int <answer> static 
<token> lastWrite, int lastRead, int ringSize) <answer> typhoon_num_free(int 
<token> /= sizeof(struct cmd_desc); <answer> lastWrite 
lastRead /= sizeof(struct <token> <answer> cmd_desc); 
return (ringSize + lastRead - lastWrite - <token> % ringSize; <answer> 1) 
<token> inline int <answer> static 
<token> typhoon *tp) <answer> typhoon_num_free_cmd(struct 
<token> lastWrite = tp->cmdRing.lastWrite; <answer> int 
int <token> = le32_to_cpu(tp->indexes->cmdCleared); <answer> cmdCleared 
<token> typhoon_num_free(lastWrite, cmdCleared, COMMAND_ENTRIES); <answer> return 
static inline <token> <answer> int 
typhoon_num_free_resp(struct <token> *tp) <answer> typhoon 
int <token> = le32_to_cpu(tp->indexes->respReady); <answer> respReady 
int respCleared <token> le32_to_cpu(tp->indexes->respCleared); <answer> = 
return typhoon_num_free(respReady, <token> RESPONSE_ENTRIES); <answer> respCleared, 
static inline <token> <answer> int 
typhoon_num_free_tx(struct <token> *ring) <answer> transmit_ring 
tp->awaiting_resp = <token> <answer> 1; 
<token> (resp == NULL) { <answer> if 
<token> = &local_resp; <answer> resp 
num_resp = <token> <answer> 1; 
wrap_len <token> 0; <answer> = 
len = num_cmd <token> sizeof(*cmd); <answer> * 
if (unlikely(ring->lastWrite + len > COMMAND_RING_SIZE)) <token> <answer> { 
wrap_len = ring->lastWrite + len <token> COMMAND_RING_SIZE; <answer> - 
<token> = COMMAND_RING_SIZE - ring->lastWrite; <answer> len 
memcpy(ring->ringBase + ring->lastWrite, cmd, <token> <answer> len); 
if (unlikely(wrap_len)) <token> <answer> { 
<token> cmd_desc *wrap_ptr = cmd; <answer> struct 
wrap_ptr += <token> / sizeof(*cmd); <answer> len 
memcpy(ring->ringBase, wrap_ptr, <token> <answer> wrap_len); 
typhoon_inc_cmd_index(&ring->lastWrite, <token> <answer> num_cmd); 
iowrite32(ring->lastWrite, tp->ioaddr <token> TYPHOON_REG_CMD_READY); <answer> + 
if ((cmd->flags & <token> == 0) <answer> TYPHOON_CMD_RESPOND) 
<token> out; <answer> goto 
<token> = 0; <answer> got_resp 
for (i = 0; i < <token> && !got_resp; i++) { <answer> TYPHOON_WAIT_TIMEOUT 
if <token> != indexes->respReady) <answer> (indexes->respCleared 
got_resp = <token> num_resp, <answer> typhoon_process_response(tp, 
<token> (!got_resp) { <answer> if 
err <token> -ETIMEDOUT; <answer> = 
<token> out; <answer> goto 
if <token> & TYPHOON_RESP_ERROR) <answer> (resp->flags 
err = <token> <answer> -EIO; 
<token> (tp->awaiting_resp) { <answer> if 
tp->awaiting_resp <token> 0; <answer> = 
if (indexes->respCleared != <token> <answer> indexes->respReady) 
iowrite32(1, tp->ioaddr <token> TYPHOON_REG_SELF_INTERRUPT); <answer> + 
return <token> <answer> err; 
static inline <token> <answer> void 
<token> sk_buff *skb, struct transmit_ring *txRing, <answer> typhoon_tso_fill(struct 
<token> ring_dma) <answer> u32 
<token> tcpopt_desc *tcpd; <answer> struct 
<token> tcpd_offset = ring_dma; <answer> u32 
tcpd = (struct tcpopt_desc *) (txRing->ringBase + <token> <answer> txRing->lastWrite); 
tcpd_offset += <token> <answer> txRing->lastWrite; 
tcpd_offset += offsetof(struct tcpopt_desc, <token> <answer> bytesTx); 
<token> 1); <answer> typhoon_inc_tx_index(&txRing->lastWrite, 
tcpd->flags <token> TYPHOON_OPT_DESC | TYPHOON_OPT_TCP_SEG; <answer> = 
<token> = 1; <answer> tcpd->numDesc 
tcpd->mss_flags <token> cpu_to_le16(skb_tso_size(skb)); <answer> = 
<token> |= TYPHOON_TSO_FIRST | TYPHOON_TSO_LAST; <answer> tcpd->mss_flags 
tcpd->respAddrLo = <token> <answer> cpu_to_le32(tcpd_offset); 
tcpd->bytesTx = <token> <answer> cpu_to_le32(skb->len); 
<token> = 0; <answer> tcpd->status 
static <token> <answer> netdev_tx_t 
typhoon_start_tx(struct sk_buff *skb, struct <token> *dev) <answer> net_device 
struct typhoon *tp = <token> <answer> netdev_priv(dev); 
<token> transmit_ring *txRing; <answer> struct 
struct <token> *txd, *first_txd; <answer> tx_desc 
<token> skb_dma; <answer> dma_addr_t 
<token> numDesc; <answer> int 
txRing <token> &tp->txLoRing; <answer> = 
numDesc <token> skb_shinfo(skb)->nr_frags + 1; <answer> = 
if <token> <answer> (skb_is_gso(skb)) 
while (unlikely(typhoon_num_free_tx(txRing) < (numDesc + <token> <answer> 2))) 
first_txd = (struct tx_desc <token> (txRing->ringBase + txRing->lastWrite); <answer> *) 
<token> 1); <answer> typhoon_inc_tx_index(&txRing->lastWrite, 
<token> = TYPHOON_TX_DESC | TYPHOON_DESC_VALID; <answer> first_txd->flags 
first_txd->numDesc = <token> <answer> 0; 
first_txd->len <token> 0; <answer> = 
first_txd->tx_addr = (u64)((unsigned <token> skb); <answer> long) 
first_txd->processFlags <token> 0; <answer> = 
if (skb->ip_summed <token> CHECKSUM_PARTIAL) { <answer> == 
if (skb_shinfo(skb)->nr_frags == 0) <token> <answer> { 
skb_dma = dma_map_single(&tp->tx_pdev->dev, <token> <answer> skb->data, 
skb->len, <token> <answer> DMA_TO_DEVICE); 
txd->flags = TYPHOON_FRAG_DESC <token> TYPHOON_DESC_VALID; <answer> | 
txd->len <token> cpu_to_le16(skb->len); <answer> = 
<token> = cpu_to_le32(skb_dma); <answer> txd->frag.addr 
txd->frag.addrHi = <token> <answer> 0; 
<token> else { <answer> } 
int i, <token> <answer> len; 
<token> = skb_headlen(skb); <answer> len 
<token> = dma_map_single(&tp->tx_pdev->dev, skb->data, len, <answer> skb_dma 
<token> = TYPHOON_FRAG_DESC | TYPHOON_DESC_VALID; <answer> txd->flags 
txd->len <token> cpu_to_le16(len); <answer> = 
txd->frag.addr = <token> <answer> cpu_to_le32(skb_dma); 
txd->frag.addrHi <token> 0; <answer> = 
for (i <token> 0; i < skb_shinfo(skb)->nr_frags; i++) { <answer> = 
const <token> *frag = &skb_shinfo(skb)->frags[i]; <answer> skb_frag_t 
<token> *frag_addr; <answer> void 
<token> = (struct tx_desc *) (txRing->ringBase + <answer> txd 
<token> 1); <answer> typhoon_inc_tx_index(&txRing->lastWrite, 
<token> = skb_frag_size(frag); <answer> len 
frag_addr = <token> <answer> skb_frag_address(frag); 
<token> = dma_map_single(&tp->tx_pdev->dev, frag_addr, <answer> skb_dma 
<token> DMA_TO_DEVICE); <answer> len, 
txd->flags <token> TYPHOON_FRAG_DESC | TYPHOON_DESC_VALID; <answer> = 
txd->len = <token> <answer> cpu_to_le16(len); 
txd->frag.addr = <token> <answer> cpu_to_le32(skb_dma); 
<token> = 0; <answer> txd->frag.addrHi 
iowrite32(txRing->lastWrite, tp->tx_ioaddr <token> txRing->writeRegister); <answer> + 
numDesc = <token> + TSO_NUM_DESCRIPTORS + 1; <answer> MAX_SKB_FRAGS 
if (typhoon_num_free_tx(txRing) < (numDesc + 2)) <token> <answer> { 
if (typhoon_num_free_tx(txRing) >= <token> + 2)) <answer> (numDesc 
return <token> <answer> NETDEV_TX_OK; 
<token> void <answer> static 
typhoon_set_rx_mode(struct net_device <token> <answer> *dev) 
<token> typhoon *tp = netdev_priv(dev); <answer> struct 
struct <token> xp_cmd; <answer> cmd_desc 
u32 <token> <answer> mc_filter[2]; 
<token> filter; <answer> __le16 
filter <token> TYPHOON_RX_FILTER_DIRECTED | TYPHOON_RX_FILTER_BROADCAST; <answer> = 
if (dev->flags & <token> { <answer> IFF_PROMISC) 
filter |= <token> <answer> TYPHOON_RX_FILTER_PROMISCOUS; 
} else <token> ((netdev_mc_count(dev) > multicast_filter_limit) || <answer> if 
(dev->flags <token> IFF_ALLMULTI)) { <answer> & 
stats->tx_packets <token> le32_to_cpu(s->txPackets) + <answer> = 
stats->tx_bytes = le64_to_cpu(s->txBytes) <token> <answer> + 
stats->tx_errors <token> le32_to_cpu(s->txCarrierLost) + <answer> = 
stats->tx_carrier_errors = <token> + <answer> le32_to_cpu(s->txCarrierLost) 
stats->collisions <token> le32_to_cpu(s->txMultipleCollisions) + <answer> = 
<token> = le32_to_cpu(s->rxPacketsGood) + <answer> stats->rx_packets 
<token> = le64_to_cpu(s->rxBytesGood) + <answer> stats->rx_bytes 
stats->rx_fifo_errors = <token> + <answer> le32_to_cpu(s->rxFifoOverruns) 
stats->rx_errors = <token> + <answer> le32_to_cpu(s->rxFifoOverruns) 
le32_to_cpu(s->BadSSD) <token> le32_to_cpu(s->rxCrcErrors) + <answer> + 
stats->rx_crc_errors = <token> + <answer> le32_to_cpu(s->rxCrcErrors) 
stats->rx_length_errors = le32_to_cpu(s->rxOversized) <token> <answer> + 
tp->speed <token> (s->linkStatus & TYPHOON_LINK_100MBPS) ? <answer> = 
<token> : SPEED_10; <answer> SPEED_100 
tp->duplex = <token> & TYPHOON_LINK_FULL_DUPLEX) ? <answer> (s->linkStatus 
DUPLEX_FULL : <token> <answer> DUPLEX_HALF; 
return <token> <answer> 0; 
static struct net_device_stats <token> <answer> * 
typhoon_get_stats(struct net_device <token> <answer> *dev) 
struct typhoon *tp = <token> <answer> netdev_priv(dev); 
struct net_device_stats <token> = &tp->dev->stats; <answer> *stats 
struct <token> *saved = &tp->stats_saved; <answer> net_device_stats 
if <token> == Sleeping) <answer> (tp->card_state 
return <token> <answer> saved; 
if <token> < 0) { <answer> (typhoon_do_get_stats(tp) 
netdev_err(dev, "error getting <token> <answer> stats\n"); 
<token> saved; <answer> return 
return <token> <answer> stats; 
<token> void <answer> static 
typhoon_get_drvinfo(struct net_device *dev, <token> ethtool_drvinfo *info) <answer> struct 
struct typhoon *tp <token> netdev_priv(dev); <answer> = 
struct pci_dev *pci_dev = <token> <answer> tp->pdev; 
struct cmd_desc <token> <answer> xp_cmd; 
struct <token> xp_resp[3]; <answer> resp_desc 
if (tp->card_state == Sleeping) <token> <answer> { 
<token> "Sleep image", <answer> strscpy(info->fw_version, 
} else <token> <answer> { 
INIT_COMMAND_WITH_RESPONSE(&xp_cmd, <token> <answer> TYPHOON_CMD_READ_VERSIONS); 
if (typhoon_issue_command(tp, 1, &xp_cmd, 3, xp_resp) < <token> { <answer> 0) 
<token> "Unknown runtime", <answer> strscpy(info->fw_version, 
} <token> { <answer> else 
u32 sleep_ver <token> le32_to_cpu(xp_resp[0].parm2); <answer> = 
snprintf(info->fw_version, <token> <answer> sizeof(info->fw_version), 
<token> sleep_ver >> 24, <answer> "%02x.%03x.%03x", 
(sleep_ver >> <token> & 0xfff, sleep_ver & 0xfff); <answer> 12) 
<token> KBUILD_MODNAME, sizeof(info->driver)); <answer> strscpy(info->driver, 
strscpy(info->bus_info, <token> sizeof(info->bus_info)); <answer> pci_name(pci_dev), 
static <token> <answer> int 
typhoon_get_link_ksettings(struct net_device <token> <answer> *dev, 
<token> ethtool_link_ksettings *cmd) <answer> struct 
struct <token> *tp = netdev_priv(dev); <answer> typhoon 
u32 supported, advertising <token> 0; <answer> = 
supported <token> SUPPORTED_100baseT_Half | SUPPORTED_100baseT_Full | <answer> = 
switch (tp->xcvr_select) <token> <answer> { 
case <token> <answer> TYPHOON_XCVR_10HALF: 
<token> = ADVERTISED_10baseT_Half; <answer> advertising 
case <token> <answer> TYPHOON_XCVR_10FULL: 
advertising <token> ADVERTISED_10baseT_Full; <answer> = 
<token> TYPHOON_XCVR_100HALF: <answer> case 
advertising <token> ADVERTISED_100baseT_Half; <answer> = 
<token> TYPHOON_XCVR_100FULL: <answer> case 
advertising <token> ADVERTISED_100baseT_Full; <answer> = 
<token> TYPHOON_XCVR_AUTONEG: <answer> case 
advertising <token> ADVERTISED_10baseT_Half | <answer> = 
<token> | <answer> ADVERTISED_10baseT_Full 
<token> | <answer> ADVERTISED_100baseT_Half 
<token> | <answer> ADVERTISED_100baseT_Full 
if (tp->capabilities <token> TYPHOON_FIBER) { <answer> & 
supported |= <token> <answer> SUPPORTED_FIBRE; 
advertising |= <token> <answer> ADVERTISED_FIBRE; 
cmd->base.port = <token> <answer> PORT_FIBRE; 
<token> else { <answer> } 
<token> |= SUPPORTED_10baseT_Half | <answer> supported 
<token> | <answer> SUPPORTED_10baseT_Full 
<token> |= ADVERTISED_TP; <answer> advertising 
cmd->base.port <token> PORT_TP; <answer> = 
<token> = tp->shared_dma + shared_offset(indexes); <answer> shared_dma 
<token> = cpu_to_le32(shared_dma); <answer> iface->ringIndex 
shared_dma <token> tp->shared_dma + shared_offset(txLo); <answer> = 
<token> = cpu_to_le32(shared_dma); <answer> iface->txLoAddr 
iface->txLoSize = <token> * sizeof(struct tx_desc)); <answer> cpu_to_le32(TXLO_ENTRIES 
shared_dma = <token> + shared_offset(txHi); <answer> tp->shared_dma 
iface->txHiAddr <token> cpu_to_le32(shared_dma); <answer> = 
iface->txHiSize = <token> * sizeof(struct tx_desc)); <answer> cpu_to_le32(TXHI_ENTRIES 
shared_dma = tp->shared_dma + <token> <answer> shared_offset(rxBuff); 
iface->rxBuffAddr <token> cpu_to_le32(shared_dma); <answer> = 
<token> = cpu_to_le32(RXFREE_ENTRIES * <answer> iface->rxBuffSize 
sizeof(struct <token> <answer> rx_free)); 
<token> = tp->shared_dma + shared_offset(rxLo); <answer> shared_dma 
<token> = cpu_to_le32(shared_dma); <answer> iface->rxLoAddr 
iface->rxLoSize <token> cpu_to_le32(RX_ENTRIES * sizeof(struct rx_desc)); <answer> = 
<token> = tp->shared_dma + shared_offset(rxHi); <answer> shared_dma 
iface->rxHiAddr = <token> <answer> cpu_to_le32(shared_dma); 
iface->rxHiSize = <token> * sizeof(struct rx_desc)); <answer> cpu_to_le32(RX_ENTRIES 
shared_dma = tp->shared_dma + <token> <answer> shared_offset(cmd); 
<token> = cpu_to_le32(shared_dma); <answer> iface->cmdAddr 
iface->cmdSize = <token> <answer> cpu_to_le32(COMMAND_RING_SIZE); 
shared_dma = <token> + shared_offset(resp); <answer> tp->shared_dma 
iface->respAddr = <token> <answer> cpu_to_le32(shared_dma); 
iface->respSize = <token> <answer> cpu_to_le32(RESPONSE_RING_SIZE); 
shared_dma <token> tp->shared_dma + shared_offset(zeroWord); <answer> = 
iface->zeroAddr <token> cpu_to_le32(shared_dma); <answer> = 
tp->indexes = <token> <answer> &tp->shared->indexes; 
tp->txLoRing.ringBase = (u8 *) <token> <answer> tp->shared->txLo; 
<token> = (u8 *) tp->shared->txHi; <answer> tp->txHiRing.ringBase 
tp->rxLoRing.ringBase = (u8 <token> tp->shared->rxLo; <answer> *) 
<token> = (u8 *) tp->shared->rxHi; <answer> tp->rxHiRing.ringBase 
<token> = (u8 *) tp->shared->rxBuff; <answer> tp->rxBuffRing.ringBase 
<token> = (u8 *) tp->shared->cmd; <answer> tp->cmdRing.ringBase 
tp->respRing.ringBase = (u8 <token> tp->shared->resp; <answer> *) 
tp->txLoRing.writeRegister = <token> <answer> TYPHOON_REG_TX_LO_READY; 
tp->txHiRing.writeRegister <token> TYPHOON_REG_TX_HI_READY; <answer> = 
<token> = le32_to_cpu(iface->txLoAddr); <answer> tp->txlo_dma_addr 
tp->card_state <token> Sleeping; <answer> = 
tp->offload = TYPHOON_OFFLOAD_IP_CHKSUM | <token> <answer> TYPHOON_OFFLOAD_TCP_CHKSUM; 
tp->offload |= TYPHOON_OFFLOAD_UDP_CHKSUM | <token> <answer> TSO_OFFLOAD_ON; 
<token> |= TYPHOON_OFFLOAD_VLAN; <answer> tp->offload 
<token> = -ENOMEM; <answer> err 
dpage <token> dma_alloc_coherent(&pdev->dev, PAGE_SIZE, &dpage_dma, GFP_ATOMIC); <answer> = 
<token> (!dpage) { <answer> if 
netdev_err(tp->dev, "no DMA <token> for firmware\n"); <answer> mem 
goto <token> <answer> err_out; 
<token> = ioread32(ioaddr + TYPHOON_REG_INTR_ENABLE); <answer> irqEnabled 
iowrite32(irqEnabled | <token> <answer> TYPHOON_INTR_BOOTCMD, 
<token> + TYPHOON_REG_INTR_ENABLE); <answer> ioaddr 
irqMasked = ioread32(ioaddr + <token> <answer> TYPHOON_REG_INTR_MASK); 
<token> | TYPHOON_INTR_BOOTCMD, <answer> iowrite32(irqMasked 
ioaddr <token> TYPHOON_REG_INTR_MASK); <answer> + 
err <token> -ETIMEDOUT; <answer> = 
if (typhoon_wait_status(ioaddr, TYPHOON_STATUS_WAITING_FOR_HOST) < <token> { <answer> 0) 
netdev_err(tp->dev, "card <token> timeout\n"); <answer> ready 
goto <token> <answer> err_out_irq; 
numSections = <token> <answer> le32_to_cpu(fHdr->numSections); 
load_addr <token> le32_to_cpu(fHdr->startAddr); <answer> = 
iowrite32(TYPHOON_INTR_BOOTCMD, ioaddr <token> TYPHOON_REG_INTR_STATUS); <answer> + 
iowrite32(load_addr, <token> + TYPHOON_REG_DOWNLOAD_BOOT_ADDR); <answer> ioaddr 
hmac = <token> <answer> le32_to_cpu(fHdr->hmacDigest[0]); 
<token> ioaddr + TYPHOON_REG_DOWNLOAD_HMAC_0); <answer> iowrite32(hmac, 
hmac <token> le32_to_cpu(fHdr->hmacDigest[1]); <answer> = 
<token> ioaddr + TYPHOON_REG_DOWNLOAD_HMAC_1); <answer> iowrite32(hmac, 
<token> = le32_to_cpu(fHdr->hmacDigest[2]); <answer> hmac 
iowrite32(hmac, <token> + TYPHOON_REG_DOWNLOAD_HMAC_2); <answer> ioaddr 
<token> = le32_to_cpu(fHdr->hmacDigest[3]); <answer> hmac 
iowrite32(hmac, ioaddr + <token> <answer> TYPHOON_REG_DOWNLOAD_HMAC_3); 
hmac <token> le32_to_cpu(fHdr->hmacDigest[4]); <answer> = 
iowrite32(hmac, <token> + TYPHOON_REG_DOWNLOAD_HMAC_4); <answer> ioaddr 
<token> ioaddr + TYPHOON_REG_COMMAND); <answer> iowrite32(TYPHOON_BOOTCMD_RUNTIME_IMAGE, 
<token> += sizeof(struct typhoon_file_header); <answer> image_data 
for (i <token> 0; i < numSections; i++) { <answer> = 
sHdr = (struct typhoon_section_header *) <token> <answer> image_data; 
<token> += sizeof(struct typhoon_section_header); <answer> image_data 
load_addr <token> le32_to_cpu(sHdr->startAddr); <answer> = 
section_len <token> le32_to_cpu(sHdr->len); <answer> = 
while (section_len) <token> <answer> { 
len = min_t(u32, section_len, <token> <answer> PAGE_SIZE); 
if <token> < 0 || <answer> (typhoon_wait_interrupt(ioaddr) 
ioread32(ioaddr <token> TYPHOON_REG_STATUS) != <answer> + 
TYPHOON_STATUS_WAITING_FOR_SEGMENT) <token> <answer> { 
netdev_err(tp->dev, <token> ready timeout\n"); <answer> "segment 
goto <token> <answer> err_out_irq; 
<token> = csum_fold(csum_partial_copy_nocheck(image_data, <answer> csum 
dpage, <token> <answer> len)); 
iowrite32(len, ioaddr <token> TYPHOON_REG_BOOT_LENGTH); <answer> + 
iowrite32(le16_to_cpu((__force <token> <answer> __le16)csum), 
<token> + TYPHOON_REG_BOOT_CHECKSUM); <answer> ioaddr 
ioaddr + <token> <answer> TYPHOON_REG_BOOT_DEST_ADDR); 
iowrite32(0, ioaddr <token> TYPHOON_REG_BOOT_DATA_HI); <answer> + 
iowrite32(dpage_dma, ioaddr <token> TYPHOON_REG_BOOT_DATA_LO); <answer> + 
ioaddr <token> TYPHOON_REG_COMMAND); <answer> + 
image_data += <token> <answer> len; 
<token> += len; <answer> load_addr 
section_len <token> len; <answer> -= 
<token> (typhoon_wait_interrupt(ioaddr) < 0 || <answer> if 
ioread32(ioaddr + TYPHOON_REG_STATUS) <token> <answer> != 
TYPHOON_STATUS_WAITING_FOR_SEGMENT) <token> <answer> { 
netdev_err(tp->dev, <token> segment ready timeout\n"); <answer> "final 
<token> err_out_irq; <answer> goto 
iowrite32(TYPHOON_BOOTCMD_DNLD_COMPLETE, ioaddr <token> TYPHOON_REG_COMMAND); <answer> + 
if (typhoon_wait_status(ioaddr, TYPHOON_STATUS_WAITING_FOR_BOOT) < <token> { <answer> 0) 
netdev_err(tp->dev, "boot <token> timeout, status 0x%0x\n", <answer> ready 
ioread32(ioaddr <token> TYPHOON_REG_STATUS)); <answer> + 
<token> err_out_irq; <answer> goto 
<token> = 0; <answer> err 
iowrite32(irqMasked, <token> + TYPHOON_REG_INTR_MASK); <answer> ioaddr 
iowrite32(irqEnabled, ioaddr <token> TYPHOON_REG_INTR_ENABLE); <answer> + 
dma_free_coherent(&pdev->dev, <token> dpage, dpage_dma); <answer> PAGE_SIZE, 
<token> err; <answer> return 
static <token> <answer> int 
typhoon_boot_3XP(struct <token> *tp, u32 initial_status) <answer> typhoon 
void __iomem <token> = tp->ioaddr; <answer> *ioaddr 
if (typhoon_wait_status(ioaddr, initial_status) < <token> { <answer> 0) 
netdev_err(tp->dev, "boot ready <token> <answer> timeout\n"); 
<token> out_timeout; <answer> goto 
<token> ioaddr + TYPHOON_REG_BOOT_RECORD_ADDR_HI); <answer> iowrite32(0, 
iowrite32(tp->shared_dma, ioaddr + <token> <answer> TYPHOON_REG_BOOT_RECORD_ADDR_LO); 
ioaddr + <token> <answer> TYPHOON_REG_COMMAND); 
if <token> TYPHOON_STATUS_RUNNING) < 0) { <answer> (typhoon_wait_status(ioaddr, 
netdev_err(tp->dev, "boot finish timeout (status <token> <answer> 0x%x)\n", 
ioread32(ioaddr <token> TYPHOON_REG_STATUS)); <answer> + 
<token> out_timeout; <answer> goto 
iowrite32(0, ioaddr <token> TYPHOON_REG_TX_HI_READY); <answer> + 
<token> ioaddr + TYPHOON_REG_CMD_READY); <answer> iowrite32(0, 
iowrite32(0, ioaddr + <token> <answer> TYPHOON_REG_TX_LO_READY); 
iowrite32(TYPHOON_BOOTCMD_BOOT, ioaddr <token> TYPHOON_REG_COMMAND); <answer> + 
<token> 0; <answer> return 
<token> -ETIMEDOUT; <answer> return 
<token> u32 <answer> static 
<token> typhoon *tp, struct transmit_ring *txRing, <answer> typhoon_clean_tx(struct 
volatile __le32 <token> index) <answer> * 
u32 lastRead = <token> <answer> txRing->lastRead; 
struct tx_desc <token> <answer> *tx; 
<token> skb_dma; <answer> dma_addr_t 
int <token> <answer> dma_len; 
<token> type; <answer> int 
while <token> != le32_to_cpu(*index)) { <answer> (lastRead 
tx = (struct tx_desc *) (txRing->ringBase + <token> <answer> lastRead); 
type = tx->flags & <token> <answer> TYPHOON_TYPE_MASK; 
if (type <token> TYPHOON_TX_DESC) { <answer> == 
unsigned long ptr <token> tx->tx_addr; <answer> = 
<token> sk_buff *skb = (struct sk_buff *) ptr; <answer> struct 
} else <token> (type == TYPHOON_FRAG_DESC) { <answer> if 
skb_dma <token> (dma_addr_t) le32_to_cpu(tx->frag.addr); <answer> = 
dma_len = <token> <answer> le16_to_cpu(tx->len); 
<token> skb_dma, dma_len, <answer> dma_unmap_single(&tp->pdev->dev, 
tx->flags <token> 0; <answer> = 
<token> 1); <answer> typhoon_inc_tx_index(&lastRead, 
<token> lastRead; <answer> return 
static <token> <answer> void 
typhoon_tx_complete(struct typhoon *tp, struct transmit_ring <token> <answer> *txRing, 
volatile __le32 * <token> <answer> index) 
u32 <token> <answer> lastRead; 
int numDesc = MAX_SKB_FRAGS <token> 1; <answer> + 
<token> = NULL; <answer> rxb->skb 
r = (struct rx_free *) (ring->ringBase <token> ring->lastWrite); <answer> + 
<token> 1); <answer> typhoon_inc_rxfree_index(&ring->lastWrite, 
<token> = idx; <answer> r->virtAddr 
<token> = cpu_to_le32(rxb->dma_addr); <answer> r->physAddr 
skb_reserve(skb, <token> <answer> 2); 
dma_addr = <token> skb->data, PKT_BUF_SZ, <answer> dma_map_single(&tp->pdev->dev, 
r = (struct rx_free *) (ring->ringBase <token> ring->lastWrite); <answer> + 
<token> 1); <answer> typhoon_inc_rxfree_index(&ring->lastWrite, 
<token> = idx; <answer> r->virtAddr 
<token> = cpu_to_le32(dma_addr); <answer> r->physAddr 
<token> = skb; <answer> rxb->skb 
<token> = dma_addr; <answer> rxb->dma_addr 
return <token> <answer> 0; 
static <token> <answer> int 
<token> typhoon *tp, pci_power_t state, __le16 events) <answer> typhoon_sleep(struct 
int <token> <answer> err; 
err = <token> events); <answer> typhoon_sleep_early(tp, 
if <token> <answer> (err) 
<token> err; <answer> return 
<token> state, 1); <answer> pci_enable_wake(tp->pdev, 
<token> pci_set_power_state(tp->pdev, state); <answer> return 
static <token> <answer> int 
typhoon_wakeup(struct typhoon *tp, <token> wait_type) <answer> int 
void <token> *ioaddr = tp->ioaddr; <answer> __iomem 
iowrite32(TYPHOON_BOOTCMD_WAKEUP, ioaddr <token> TYPHOON_REG_COMMAND); <answer> + 
<token> (typhoon_wait_status(ioaddr, TYPHOON_STATUS_WAITING_FOR_HOST) < 0 || <answer> if 
(tp->capabilities & <token> <answer> TYPHOON_WAKEUP_NEEDS_RESET)) 
return typhoon_reset(ioaddr, <token> <answer> wait_type); 
return <token> <answer> 0; 
static <token> <answer> int 
typhoon_start_runtime(struct typhoon <token> <answer> *tp) 
struct net_device *dev = <token> <answer> tp->dev; 
void __iomem <token> = tp->ioaddr; <answer> *ioaddr 
struct cmd_desc <token> <answer> xp_cmd; 
int <token> <answer> err; 
err = <token> <answer> typhoon_download_firmware(tp); 
if (err < <token> { <answer> 0) 
netdev_err(tp->dev, "cannot load runtime <token> 3XP\n"); <answer> on 
<token> error_out; <answer> goto 
if (typhoon_boot_3XP(tp, TYPHOON_STATUS_WAITING_FOR_BOOT) <token> 0) { <answer> < 
<token> "cannot boot 3XP\n"); <answer> netdev_err(tp->dev, 
<token> = -EIO; <answer> err 
<token> error_out; <answer> goto 
<token> TYPHOON_CMD_SET_MAX_PKT_SIZE); <answer> INIT_COMMAND_NO_RESPONSE(&xp_cmd, 
<token> = cpu_to_le16(PKT_BUF_SZ); <answer> xp_cmd.parm1 
err = <token> 1, &xp_cmd, 0, NULL); <answer> typhoon_issue_command(tp, 
<token> (err < 0) <answer> if 
goto <token> <answer> error_out; 
<token> TYPHOON_CMD_SET_MAC_ADDRESS); <answer> INIT_COMMAND_NO_RESPONSE(&xp_cmd, 
xp_cmd.parm1 = cpu_to_le16(ntohs(*(__be16 <token> <answer> *)&dev->dev_addr[0])); 
xp_cmd.parm2 = cpu_to_le32(ntohl(*(__be32 <token> <answer> *)&dev->dev_addr[2])); 
err = <token> 1, &xp_cmd, 0, NULL); <answer> typhoon_issue_command(tp, 
if (err <token> 0) <answer> < 
goto <token> <answer> error_out; 
<token> TYPHOON_CMD_IRQ_COALESCE_CTRL); <answer> INIT_COMMAND_WITH_RESPONSE(&xp_cmd, 
xp_cmd.parm1 = <token> <answer> 0; 
<token> = typhoon_issue_command(tp, 1, &xp_cmd, 0, NULL); <answer> err 
if (err < <token> <answer> 0) 
goto <token> <answer> error_out; 
<token> TYPHOON_CMD_XCVR_SELECT); <answer> INIT_COMMAND_NO_RESPONSE(&xp_cmd, 
xp_cmd.parm1 <token> tp->xcvr_select; <answer> = 
err = typhoon_issue_command(tp, 1, <token> 0, NULL); <answer> &xp_cmd, 
if (err <token> 0) <answer> < 
goto <token> <answer> error_out; 
<token> TYPHOON_CMD_VLAN_TYPE_WRITE); <answer> INIT_COMMAND_NO_RESPONSE(&xp_cmd, 
xp_cmd.parm1 <token> cpu_to_le16(ETH_P_8021Q); <answer> = 
err = typhoon_issue_command(tp, 1, <token> 0, NULL); <answer> &xp_cmd, 
if (err < <token> <answer> 0) 
goto <token> <answer> error_out; 
<token> TYPHOON_CMD_SET_OFFLOAD_TASKS); <answer> INIT_COMMAND_NO_RESPONSE(&xp_cmd, 
xp_cmd.parm2 <token> tp->offload; <answer> = 
<token> = tp->offload; <answer> xp_cmd.parm3 
err = typhoon_issue_command(tp, <token> &xp_cmd, 0, NULL); <answer> 1, 
if <token> < 0) <answer> (err 
<token> error_out; <answer> goto 
<token> TYPHOON_CMD_TX_ENABLE); <answer> INIT_COMMAND_NO_RESPONSE(&xp_cmd, 
err = typhoon_issue_command(tp, 1, &xp_cmd, <token> NULL); <answer> 0, 
<token> (err < 0) <answer> if 
goto <token> <answer> error_out; 
<token> TYPHOON_CMD_RX_ENABLE); <answer> INIT_COMMAND_WITH_RESPONSE(&xp_cmd, 
err = typhoon_issue_command(tp, <token> &xp_cmd, 0, NULL); <answer> 1, 
if (err < <token> <answer> 0) 
goto <token> <answer> error_out; 
tp->card_state <token> Running; <answer> = 
<token> ioaddr + TYPHOON_REG_INTR_ENABLE); <answer> iowrite32(TYPHOON_INTR_ENABLE_ALL, 
iowrite32(TYPHOON_INTR_NONE, ioaddr <token> TYPHOON_REG_INTR_MASK); <answer> + 
<token> 0; <answer> return 
<token> WaitNoSleep); <answer> typhoon_reset(ioaddr, 
return <token> <answer> err; 
<token> int <answer> static 
typhoon_stop_runtime(struct typhoon *tp, <token> wait_type) <answer> int 
struct typhoon_indexes *indexes <token> tp->indexes; <answer> = 
struct transmit_ring *txLo = <token> <answer> &tp->txLoRing; 
void __iomem *ioaddr = <token> <answer> tp->ioaddr; 
<token> cmd_desc xp_cmd; <answer> struct 
int <token> <answer> i; 
<token> ioaddr + TYPHOON_REG_INTR_ENABLE); <answer> iowrite32(TYPHOON_INTR_NONE, 
<token> TYPHOON_CMD_RX_DISABLE); <answer> INIT_COMMAND_NO_RESPONSE(&xp_cmd, 
<token> 1, &xp_cmd, 0, NULL); <answer> typhoon_issue_command(tp, 
for (i = 0; i < <token> i++) { <answer> TYPHOON_WAIT_TIMEOUT; 
if <token> == cpu_to_le32(txLo->lastWrite)) <answer> (indexes->txLoCleared 
<token> (i == TYPHOON_WAIT_TIMEOUT) <answer> if 
netdev_err(tp->dev, <token> timed out waiting for Tx to complete\n"); <answer> "halt 
<token> TYPHOON_CMD_TX_DISABLE); <answer> INIT_COMMAND_NO_RESPONSE(&xp_cmd, 
typhoon_issue_command(tp, 1, &xp_cmd, <token> NULL); <answer> 0, 
tp->card_state = <token> <answer> Sleeping; 
memcpy(&tp->stats_saved, &tp->dev->stats, <token> net_device_stats)); <answer> sizeof(struct 
<token> TYPHOON_CMD_HALT); <answer> INIT_COMMAND_NO_RESPONSE(&xp_cmd, 
typhoon_issue_command(tp, 1, &xp_cmd, 0, <token> <answer> NULL); 
if (typhoon_wait_status(ioaddr, TYPHOON_STATUS_HALTED) < <token> <answer> 0) 
netdev_err(tp->dev, "timed out <token> for 3XP to halt\n"); <answer> waiting 
if <token> wait_type) < 0) { <answer> (typhoon_reset(ioaddr, 
<token> "unable to reset 3XP\n"); <answer> netdev_err(tp->dev, 
<token> -ETIMEDOUT; <answer> return 
if <token> <answer> (!netif_running(dev)) 
<token> 0; <answer> return 
if (typhoon_wakeup(tp, WaitNoSleep) < <token> { <answer> 0) 
netdev_err(dev, "critical: could <token> wake up in resume\n"); <answer> not 
<token> reset; <answer> goto 
<token> (typhoon_start_runtime(tp) < 0) { <answer> if 
netdev_err(dev, "critical: could not <token> runtime in resume\n"); <answer> start 
goto <token> <answer> reset; 
return <token> <answer> 0; 
<token> NoWait); <answer> typhoon_reset(tp->ioaddr, 
return <token> <answer> -EBUSY; 
static int <token> <answer> __maybe_unused 
<token> device *dev_d) <answer> typhoon_suspend(struct 
struct pci_dev *pdev = <token> <answer> to_pci_dev(dev_d); 
struct net_device *dev = <token> <answer> pci_get_drvdata(pdev); 
<token> typhoon *tp = netdev_priv(dev); <answer> struct 
struct cmd_desc <token> <answer> xp_cmd; 
if <token> <answer> (!netif_running(dev)) 
<token> 0; <answer> return 
<token> = ioread32(ioaddr + TYPHOON_REG_INTR_STATUS); <answer> val 
if ((val & TYPHOON_INTR_SELF) <token> 0) { <answer> == 
<token> ioaddr + TYPHOON_REG_SELF_INTERRUPT); <answer> iowrite32(1, 
ioread32(ioaddr + <token> <answer> TYPHOON_REG_INTR_STATUS); 
val = ioread32(ioaddr <token> TYPHOON_REG_INTR_STATUS); <answer> + 
if <token> & TYPHOON_INTR_SELF) <answer> (val 
<token> = 1; <answer> mode 
iowrite32(TYPHOON_INTR_ALL, ioaddr <token> TYPHOON_REG_INTR_MASK); <answer> + 
<token> ioaddr + TYPHOON_REG_INTR_STATUS); <answer> iowrite32(TYPHOON_INTR_ALL, 
<token> ioaddr + TYPHOON_REG_INTR_ENABLE); <answer> iowrite32(TYPHOON_INTR_NONE, 
ioread32(ioaddr <token> TYPHOON_REG_INTR_STATUS); <answer> + 
<token> ioaddr); <answer> pci_iounmap(pdev, 
<token> (!mode) <answer> if 
pr_info("%s: <token> back to port IO\n", pci_name(pdev)); <answer> falling 
return <token> <answer> mode; 
#if MAX_SKB_FRAGS <token> 32 <answer> > 
<token> <net/vxlan.h> <answer> #include 
static <token> typhoon_features_check(struct sk_buff *skb, <answer> netdev_features_t 
<token> net_device *dev, <answer> struct 
<token> features) <answer> netdev_features_t 
<token> (skb_shinfo(skb)->nr_frags > 32 && skb_is_gso(skb)) <answer> if 
features <token> ~NETIF_F_GSO_MASK; <answer> &= 
features = <token> features); <answer> vlan_features_check(skb, 
return vxlan_features_check(skb, <token> <answer> features); 
static const <token> net_device_ops typhoon_netdev_ops = { <answer> struct 
.ndo_open <token> typhoon_open, <answer> = 
<token> = typhoon_close, <answer> .ndo_stop 
#if MAX_SKB_FRAGS > <token> <answer> 32 
.ndo_features_check = <token> <answer> typhoon_features_check, 
.ndo_start_xmit = <token> <answer> typhoon_start_tx, 
.ndo_set_rx_mode = <token> <answer> typhoon_set_rx_mode, 
<token> = typhoon_tx_timeout, <answer> .ndo_tx_timeout 
.ndo_get_stats <token> typhoon_get_stats, <answer> = 
.ndo_validate_addr <token> eth_validate_addr, <answer> = 
.ndo_set_mac_address <token> eth_mac_addr, <answer> = 
static <token> <answer> int 
<token> pci_dev *pdev, const struct pci_device_id *ent) <answer> typhoon_init_one(struct 
struct <token> *dev; <answer> net_device 
struct <token> *tp; <answer> typhoon 
int card_id = <token> ent->driver_data; <answer> (int) 
u8 addr[ETH_ALEN] <token> <answer> __aligned(4); 
void <token> *ioaddr; <answer> __iomem 
<token> *shared; <answer> void 
dma_addr_t <token> <answer> shared_dma; 
struct <token> xp_cmd; <answer> cmd_desc 
struct resp_desc <token> <answer> xp_resp[3]; 
int err <token> 0; <answer> = 
const <token> *err_msg; <answer> char 
<token> = alloc_etherdev(sizeof(*tp)); <answer> dev 
if (dev <token> NULL) { <answer> == 
err_msg = "unable to <token> new net device"; <answer> alloc 
err <token> -ENOMEM; <answer> = 
<token> error_out; <answer> goto 
SET_NETDEV_DEV(dev, <token> <answer> &pdev->dev); 
err <token> pci_enable_device(pdev); <answer> = 
if (err < <token> { <answer> 0) 
err_msg = <token> to enable device"; <answer> "unable 
goto <token> <answer> error_out_dev; 
err <token> pci_set_mwi(pdev); <answer> = 
if (err <token> 0) { <answer> < 
err_msg = <token> to set MWI"; <answer> "unable 
goto <token> <answer> error_out_disable; 
err <token> dma_set_mask(&pdev->dev, DMA_BIT_MASK(32)); <answer> = 
<token> (err < 0) { <answer> if 
err_msg = "No usable DMA <token> <answer> configuration"; 
goto <token> <answer> error_out_mwi; 
if (!(pci_resource_flags(pdev, 0) <token> IORESOURCE_IO)) { <answer> & 
err_msg = "region #1 not a PCI IO <token> aborting"; <answer> resource, 
<token> = -ENODEV; <answer> err 
<token> error_out_mwi; <answer> goto 
if (pci_resource_len(pdev, 0) <token> 128) { <answer> < 
err_msg = "Invalid <token> IO region size, aborting"; <answer> PCI 
<token> = -ENODEV; <answer> err 
<token> error_out_mwi; <answer> goto 
if (!(pci_resource_flags(pdev, 1) & <token> { <answer> IORESOURCE_MEM)) 
err_msg = "region #1 not a PCI <token> resource, aborting"; <answer> MMIO 
err = <token> <answer> -ENODEV; 
goto <token> <answer> error_out_mwi; 
<token> (pci_resource_len(pdev, 1) < 128) { <answer> if 
err_msg = <token> PCI MMIO region size, aborting"; <answer> "Invalid 
<token> = -ENODEV; <answer> err 
<token> error_out_mwi; <answer> goto 
err = pci_request_regions(pdev, <token> <answer> KBUILD_MODNAME); 
if (err <token> 0) { <answer> < 
<token> = "could not request regions"; <answer> err_msg 
<token> error_out_mwi; <answer> goto 
if (use_mmio != 0 && <token> != 1) <answer> use_mmio 
<token> = typhoon_test_mmio(pdev); <answer> use_mmio 
ioaddr = pci_iomap(pdev, <token> 128); <answer> use_mmio, 
<token> (!ioaddr) { <answer> if 
err_msg = "cannot remap <token> aborting"; <answer> registers, 
err <token> -EIO; <answer> = 
goto <token> <answer> error_out_regions; 
shared <token> dma_alloc_coherent(&pdev->dev, sizeof(struct typhoon_shared), <answer> = 
<token> GFP_KERNEL); <answer> &shared_dma, 
<token> (!shared) { <answer> if 
err_msg = "could <token> allocate DMA memory"; <answer> not 
err <token> -ENOMEM; <answer> = 
<token> error_out_remap; <answer> goto 
dev->irq <token> pdev->irq; <answer> = 
tp <token> netdev_priv(dev); <answer> = 
tp->shared = <token> <answer> shared; 
tp->shared_dma = <token> <answer> shared_dma; 
<token> = pdev; <answer> tp->pdev 
tp->tx_pdev <token> pdev; <answer> = 
<token> = ioaddr; <answer> tp->ioaddr 
tp->tx_ioaddr = <token> <answer> ioaddr; 
tp->dev = <token> <answer> dev; 
err <token> typhoon_reset(ioaddr, WaitSleep); <answer> = 
if (err <token> 0) { <answer> < 
err_msg = "could <token> reset 3XP"; <answer> not 
goto <token> <answer> error_out_dma; 
err = typhoon_boot_3XP(tp, <token> <answer> TYPHOON_STATUS_WAITING_FOR_HOST); 
if <token> < 0) { <answer> (err 
<token> = "cannot boot 3XP sleep image"; <answer> err_msg 
goto <token> <answer> error_out_reset; 
INIT_COMMAND_WITH_RESPONSE(&xp_cmd, <token> <answer> TYPHOON_CMD_READ_MAC_ADDRESS); 
err = typhoon_issue_command(tp, <token> &xp_cmd, 1, xp_resp); <answer> 1, 
<token> (err < 0) { <answer> if 
err_msg = "cannot read <token> address"; <answer> MAC 
<token> error_out_reset; <answer> goto 
<token> *)&addr[0] = htons(le16_to_cpu(xp_resp[0].parm1)); <answer> *(__be16 
*(__be32 *)&addr[2] = <token> <answer> htonl(le32_to_cpu(xp_resp[0].parm2)); 
eth_hw_addr_set(dev, <token> <answer> addr); 
<token> (!is_valid_ether_addr(dev->dev_addr)) { <answer> if 
err_msg = "Could not <token> valid ethernet address, aborting"; <answer> obtain 
<token> = -EIO; <answer> err 
goto <token> <answer> error_out_reset; 
INIT_COMMAND_WITH_RESPONSE(&xp_cmd, <token> <answer> TYPHOON_CMD_READ_VERSIONS); 
<token> = typhoon_issue_command(tp, 1, &xp_cmd, 3, xp_resp); <answer> err 
if <token> < 0) { <answer> (err 
err_msg = "Could not get Sleep <token> version"; <answer> Image 
<token> error_out_reset; <answer> goto 
tp->capabilities <token> typhoon_card_info[card_id].capabilities; <answer> = 
tp->xcvr_select <token> TYPHOON_XCVR_AUTONEG; <answer> = 
if (xp_resp[0].numDesc != <token> <answer> 0) 
tp->capabilities <token> TYPHOON_WAKEUP_NEEDS_RESET; <answer> |= 
<token> = typhoon_sleep(tp, PCI_D3hot, 0); <answer> err 
if (err <token> 0) { <answer> < 
err_msg = "cannot put <token> to sleep"; <answer> adapter 
<token> error_out_reset; <answer> goto 
dev->hw_features <token> NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_TSO | <answer> = 
<token> = dev->hw_features | <answer> dev->features 
NETIF_F_HW_VLAN_CTAG_RX | <token> <answer> NETIF_F_RXCSUM; 
err <token> register_netdev(dev); <answer> = 
if (err <token> 0) { <answer> < 
err_msg <token> "unable to register netdev"; <answer> = 
<token> error_out_reset; <answer> goto 
pci_set_drvdata(pdev, <token> <answer> dev); 
netdev_info(dev, "%s at %s <token> %pM\n", <answer> 0x%llx, 
use_mmio ? <token> : "IO", <answer> "MMIO" 
(unsigned <token> long)pci_resource_start(pdev, use_mmio), <answer> long 
<token> (xp_resp[0].numDesc == 0) { <answer> if 
u16 monthday = le32_to_cpu(xp_resp[0].parm2) & <token> <answer> 0xffff; 
netdev_info(dev, <token> 1.0 Sleep Image built %02u/%02u/2000\n", <answer> "Typhoon 
monthday >> <token> monthday & 0xff); <answer> 8, 
} else if <token> == 2) { <answer> (xp_resp[0].numDesc 
u32 sleep_ver = <token> <answer> le32_to_cpu(xp_resp[0].parm2); 
u8 *ver_string <token> (u8 *) &xp_resp[1]; <answer> = 
ver_string[25] <token> 0; <answer> = 
netdev_info(dev, <token> 1.1+ Sleep Image version %02x.%03x.%03x %s\n", <answer> "Typhoon 
sleep_ver >> 24, (sleep_ver <token> 12) & 0xfff, <answer> >> 
<token> & 0xfff, ver_string); <answer> sleep_ver 
} else <token> <answer> { 
netdev_warn(dev, "Unknown Sleep Image version <token> <answer> (%u:%04x)\n", 
xp_resp[0].numDesc, <token> <answer> le32_to_cpu(xp_resp[0].parm2)); 
return <token> <answer> 0; 
typhoon_reset(ioaddr, <token> <answer> NoWait); 
<token> sizeof(struct typhoon_shared), shared, <answer> dma_free_coherent(&pdev->dev, 
<token> ioaddr); <answer> pci_iounmap(pdev, 
pr_err("%s: %s\n", pci_name(pdev), <token> <answer> err_msg); 
return <token> <answer> err; 
static <token> <answer> void 
typhoon_remove_one(struct <token> *pdev) <answer> pci_dev 
struct net_device *dev = <token> <answer> pci_get_drvdata(pdev); 
struct <token> *tp = netdev_priv(dev); <answer> typhoon 
pci_set_power_state(pdev, <token> <answer> PCI_D0); 
typhoon_reset(tp->ioaddr, <token> <answer> NoWait); 
pci_iounmap(pdev, <token> <answer> tp->ioaddr); 
dma_free_coherent(&pdev->dev, <token> typhoon_shared), <answer> sizeof(struct 
<token> tp->shared_dma); <answer> tp->shared, 
static SIMPLE_DEV_PM_OPS(typhoon_pm_ops, typhoon_suspend, <token> <answer> typhoon_resume); 
static struct <token> typhoon_driver = { <answer> pci_driver 
.name = <token> <answer> KBUILD_MODNAME, 
.id_table = <token> <answer> typhoon_pci_tbl, 
<token> = typhoon_init_one, <answer> .probe 
.remove <token> typhoon_remove_one, <answer> = 
.driver.pm = <token> <answer> &typhoon_pm_ops, 
static <token> __init <answer> int 
return <token> <answer> pci_register_driver(&typhoon_driver); 
static <token> __exit <answer> void 
#include <token> <answer> "ext2.h" 
#include <token> <answer> "xattr.h" 
const struct inode_operations ext2_symlink_inode_operations = <token> <answer> { 
.get_link <token> page_get_link, <answer> = 
<token> = ext2_getattr, <answer> .getattr 
.setattr = <token> <answer> ext2_setattr, 
.listxattr <token> ext2_listxattr, <answer> = 
<token> struct inode_operations ext2_fast_symlink_inode_operations = { <answer> const 
<token> = simple_get_link, <answer> .get_link 
<token> = ext2_getattr, <answer> .getattr 
.setattr <token> ext2_setattr, <answer> = 
.listxattr = <token> <answer> ext2_listxattr, 
#include <token> <answer> <linux/blkdev.h> 
#include <token> <answer> "blk-mq-debugfs.h" 
int <token> *data, struct seq_file *m) <answer> queue_zone_wlock_show(void 
struct <token> *q = data; <answer> request_queue 
<token> int i; <answer> unsigned 
if <token> <answer> (!q->disk->seq_zones_wlock) 
<token> 0; <answer> return 
for (i = 0; i < <token> i++) <answer> q->disk->nr_zones; 
<token> (test_bit(i, q->disk->seq_zones_wlock)) <answer> if 
<token> "%u\n", i); <answer> seq_printf(m, 
<token> 0; <answer> return 
<token> -EINPROGRESS); <answer> crypto_request_complete(req->base, 
static bool <token> qat_alg_req *req) <answer> qat_alg_try_enqueue(struct 
struct qat_instance_backlog <token> = req->backlog; <answer> *backlog 
struct adf_etr_ring_data *tx_ring <token> req->tx_ring; <answer> = 
<token> *fw_req = req->fw_req; <answer> u32 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/firmware/imx/sci.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/of_address.h> <answer> #include 
<token> <linux/pinctrl/pinctrl.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> "../core.h" <answer> #include 
#include <token> <answer> "pinctrl-imx.h" 
<token> IMX_SC_PAD_FUNC_GET_WAKEUP 9 <answer> #define 
#define <token> 4 <answer> IMX_SC_PAD_FUNC_SET_WAKEUP 
WARN_ON(num_configs != <token> <answer> 2); 
<token> = configs[1]; <answer> conf 
val <token> conf | BM_PAD_CTL_IFMUX_ENABLE | BM_PAD_CTL_GP_ENABLE; <answer> = 
val <token> mux << BP_PAD_CTL_IFMUX; <answer> |= 
hdr->ver <token> IMX_SC_RPC_VERSION; <answer> = 
hdr->svc = <token> <answer> IMX_SC_RPC_SVC_PAD; 
hdr->func <token> IMX_SC_PAD_FUNC_SET; <answer> = 
<token> = 3; <answer> hdr->size 
<token> = pin_id; <answer> msg.pad 
msg.val = <token> <answer> val; 
ret <token> imx_scu_call_rpc(pinctrl_ipc_handle, &msg, true); <answer> = 
dev_dbg(ipctl->dev, "write: pin_id %u config 0x%x val <token> <answer> 0x%x\n", 
pin_id, conf, <token> <answer> val); 
<token> ret; <answer> return 
<token> imx_pinctrl_parse_pin_scu(struct imx_pinctrl *ipctl, <answer> void 
unsigned <token> *pin_id, struct imx_pin *pin, <answer> int 
const <token> **list_p) <answer> __be32 
const struct imx_pinctrl_soc_info *info = <token> <answer> ipctl->info; 
struct imx_pin_scu *pin_scu <token> &pin->conf.scu; <answer> = 
const <token> *list = *list_p; <answer> __be32 
pin->pin = <token> <answer> be32_to_cpu(*list++); 
<token> = pin->pin; <answer> *pin_id 
pin_scu->mux_mode = <token> <answer> be32_to_cpu(*list++); 
<token> = be32_to_cpu(*list++); <answer> pin_scu->config 
<token> = list; <answer> *list_p 
dev_dbg(ipctl->dev, "%s: <token> 0x%08lx", info->pins[pin->pin].name, <answer> 0x%x 
pin_scu->mux_mode, <token> <answer> pin_scu->config); 
<token> Aisheng <aisheng.dong@nxp.com>"); <answer> MODULE_AUTHOR("Dong 
<token> i.MX SCU common pinctrl driver"); <answer> MODULE_DESCRIPTION("NXP 
MODULE_LICENSE("GPL <token> <answer> v2"); 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/mod_devicetable.h> 
#include <token> <answer> <linux/pinctrl/pinctrl.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> "pinctrl-uniphier.h" <answer> #include 
static const struct pinctrl_pin_desc uniphier_pro4_pins[] = <token> <answer> { 
UNIPHIER_PINCTRL_PIN(0, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CK24O", 
0, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 0, 
<token> "VC27A", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(1, 
1, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 1, 
UNIPHIER_PINCTRL_PIN(2, "CK27AI", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
2, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
2, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(3, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CK27AO", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 3, 
3, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(4, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CKSEL", 
4, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
4, <token> <answer> UNIPHIER_PIN_PULL_UP), 
<token> "CK27AV", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(5, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 5, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 5, 
<token> "AEXCKA", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(6, 
6, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 6, 
UNIPHIER_PINCTRL_PIN(7, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "ASEL", 
7, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
7, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(8, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "ARCRESET", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 8, 
8, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "ARCUNLOCK", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(9, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 9, 
9, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(10, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "XSRST", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 10, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 10, 
UNIPHIER_PINCTRL_PIN(11, "XNMIRQ", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 11, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 11, 
UNIPHIER_PINCTRL_PIN(12, "XSCIRQ", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
12, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
12, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(13, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "EXTRG", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 13, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 13, 
<token> "TRCCLK", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(14, 
14, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
14, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "TRCCTL", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(15, 
15, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 15, 
UNIPHIER_PINCTRL_PIN(16, "TRCD0", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
16, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 16, 
UNIPHIER_PINCTRL_PIN(17, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "TRCD1", 
17, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 17, 
<token> "TRCD2", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(18, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 18, 
18, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(19, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "TRCD3", 
19, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 19, 
UNIPHIER_PINCTRL_PIN(20, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "TRCD4", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 20, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 20, 
UNIPHIER_PINCTRL_PIN(21, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "TRCD5", 
21, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 21, 
UNIPHIER_PINCTRL_PIN(22, "TRCD6", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
22, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 22, 
UNIPHIER_PINCTRL_PIN(23, "TRCD7", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
23, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
23, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "XECS1", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(24, 
24, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 24, 
UNIPHIER_PINCTRL_PIN(25, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "ERXW", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 25, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 25, 
UNIPHIER_PINCTRL_PIN(26, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "XERWE0", 
26, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
26, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(27, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "XERWE1", 
27, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
27, <token> <answer> UNIPHIER_PIN_PULL_UP), 
<token> "ES0", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(28, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 28, 
28, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(29, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "ES1", 
29, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 29, 
UNIPHIER_PINCTRL_PIN(30, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "ES2", 
30, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 30, 
<token> "ED0", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(31, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 31, 
31, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(32, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "ED1", 
32, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
32, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(33, "ED2", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
33, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 33, 
<token> "ED3", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(34, 
34, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
34, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(35, "ED4", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 35, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 35, 
<token> "ED5", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(36, 
36, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 36, 
<token> "ED6", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(37, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 37, 
37, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(38, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "ED7", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 38, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 38, 
UNIPHIER_PINCTRL_PIN(39, "BOOTSWAP", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
-1, <token> <answer> UNIPHIER_PIN_DRV_NONE, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 39, 
UNIPHIER_PINCTRL_PIN(40, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "NFD0", 
<token> UNIPHIER_PIN_DRV_2BIT, <answer> 2, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 40, 
<token> "NFD1", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(41, 
3, <token> <answer> UNIPHIER_PIN_DRV_2BIT, 
41, <token> <answer> UNIPHIER_PIN_PULL_UP), 
<token> "NFD2", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(42, 
4, <token> <answer> UNIPHIER_PIN_DRV_2BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 42, 
<token> "NFD3", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(43, 
5, <token> <answer> UNIPHIER_PIN_DRV_2BIT, 
43, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(44, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "NFD4", 
6, <token> <answer> UNIPHIER_PIN_DRV_2BIT, 
44, <token> <answer> UNIPHIER_PIN_PULL_UP), 
<token> "NFD5", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(45, 
7, <token> <answer> UNIPHIER_PIN_DRV_2BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 45, 
UNIPHIER_PINCTRL_PIN(46, "NFD6", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
8, <token> <answer> UNIPHIER_PIN_DRV_2BIT, 
46, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(47, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "NFD7", 
<token> UNIPHIER_PIN_DRV_2BIT, <answer> 9, 
47, <token> <answer> UNIPHIER_PIN_PULL_UP), 
<token> "NFALE", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(48, 
48, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
48, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "NFCLE", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(49, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 49, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 49, 
UNIPHIER_PINCTRL_PIN(50, "XNFRE", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 50, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 50, 
UNIPHIER_PINCTRL_PIN(51, "XNFWE", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
0, <token> <answer> UNIPHIER_PIN_DRV_2BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 51, 
UNIPHIER_PINCTRL_PIN(52, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "XNFWP", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 52, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 52, 
<token> "XNFCE0", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(53, 
1, <token> <answer> UNIPHIER_PIN_DRV_2BIT, 
53, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(54, "NRYBY0", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 54, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 54, 
UNIPHIER_PINCTRL_PIN(55, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "DMDSCLTST", 
-1, <token> <answer> UNIPHIER_PIN_DRV_NONE, 
-1, <token> <answer> UNIPHIER_PIN_PULL_NONE), 
UNIPHIER_PINCTRL_PIN(56, "DMDSDATST", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_FIXED4, <answer> -1, 
-1, <token> <answer> UNIPHIER_PIN_PULL_NONE), 
UNIPHIER_PINCTRL_PIN(57, <token> 3, <answer> "AGCI0", 
-1, <token> <answer> UNIPHIER_PIN_DRV_FIXED4, 
55, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(58, "DMDSCL0", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_FIXED4, <answer> -1, 
<token> UNIPHIER_PIN_PULL_NONE), <answer> -1, 
<token> "DMDSDA0", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(59, 
<token> UNIPHIER_PIN_DRV_FIXED4, <answer> -1, 
-1, <token> <answer> UNIPHIER_PIN_PULL_NONE), 
UNIPHIER_PINCTRL_PIN(60, "AGCBS0", <token> <answer> 5, 
-1, <token> <answer> UNIPHIER_PIN_DRV_FIXED4, 
56, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(61, "DMDSCL1", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_FIXED4, <answer> -1, 
-1, <token> <answer> UNIPHIER_PIN_PULL_NONE), 
UNIPHIER_PINCTRL_PIN(62, "DMDSDA1", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_FIXED4, <answer> -1, 
<token> UNIPHIER_PIN_PULL_NONE), <answer> -1, 
<token> "ANTSHORT", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(63, 
57, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 57, 
UNIPHIER_PINCTRL_PIN(64, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CH0CLK", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 58, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 58, 
UNIPHIER_PINCTRL_PIN(65, "CH0VAL", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 59, 
59, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "CH0PSYNC", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(66, 
60, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 60, 
UNIPHIER_PINCTRL_PIN(67, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CH0DATA", 
61, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 61, 
<token> "CH1CLK", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(68, 
62, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 62, 
<token> "CH1VAL", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(69, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 63, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 63, 
<token> "CH1PSYNC", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(70, 
64, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 64, 
UNIPHIER_PINCTRL_PIN(71, "CH1DATA", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
65, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
65, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(72, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CH2CLK", 
66, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
66, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(73, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CH2VAL", 
67, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
67, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "CH2PSYNC", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(74, 
68, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
68, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "CH2DATA", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(75, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 69, 
69, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(76, "CH3CLK", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 70, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 70, 
UNIPHIER_PINCTRL_PIN(77, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CH3VAL", 
71, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 71, 
UNIPHIER_PINCTRL_PIN(78, "CH3PSYNC", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 72, 
72, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "CH3DATA", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(79, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 73, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 73, 
UNIPHIER_PINCTRL_PIN(80, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CH4CLK", 
74, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
74, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(81, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CH4VAL", 
75, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 75, 
<token> "CH4PSYNC", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(82, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 76, 
76, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(83, "CH4DATA", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
77, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 77, 
UNIPHIER_PINCTRL_PIN(84, "CH5CLK", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
78, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 78, 
UNIPHIER_PINCTRL_PIN(85, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CH5VAL", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 79, 
79, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(86, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CH5PSYNC", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 80, 
80, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "CH5DATA", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(87, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 81, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 81, 
<token> "CH6CLK", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(88, 
82, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 82, 
<token> "CH6VAL", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(89, 
83, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 83, 
UNIPHIER_PINCTRL_PIN(90, "CH6PSYNC", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
84, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 84, 
<token> "CH6DATA", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(91, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 85, 
85, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(92, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "CKFEO", 
86, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 86, 
UNIPHIER_PINCTRL_PIN(93, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "XFERST", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 87, 
87, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(94, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "P_FE_ON", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 88, 
88, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(95, "P_TU0_ON", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 89, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 89, 
UNIPHIER_PINCTRL_PIN(96, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "XFEIRQ0", 
90, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
90, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(97, "XFEIRQ1", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
91, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
91, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "XFEIRQ2", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(98, 
92, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
92, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(99, "XFEIRQ3", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 93, 
93, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(100, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "XFEIRQ4", 
94, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 94, 
UNIPHIER_PINCTRL_PIN(101, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "XFEIRQ5", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 95, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 95, 
<token> "XFEIRQ6", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(102, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 96, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 96, 
UNIPHIER_PINCTRL_PIN(103, "SMTCLK0", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 97, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 97, 
UNIPHIER_PINCTRL_PIN(104, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SMTRST0", 
98, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
98, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(105, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SMTCMD0", 
99, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
99, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(106, "SMTD0", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 100, 
100, <token> <answer> UNIPHIER_PIN_PULL_UP), 
<token> "SMTSEL0", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(107, 
101, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 101, 
<token> "SMTDET0", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(108, 
102, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
102, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(109, "SMTCLK1", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
103, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 103, 
UNIPHIER_PINCTRL_PIN(110, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SMTRST1", 
104, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 104, 
UNIPHIER_PINCTRL_PIN(111, "SMTCMD1", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
105, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
105, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(112, "SMTD1", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
106, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
106, <token> <answer> UNIPHIER_PIN_PULL_UP), 
<token> "SMTSEL1", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(113, 
107, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
107, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "SMTDET1", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(114, 
108, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
108, <token> <answer> UNIPHIER_PIN_PULL_UP), 
<token> "XINTM", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(115, 
109, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 109, 
<token> "SCLKM", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(116, 
110, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 110, 
UNIPHIER_PINCTRL_PIN(117, "SBMTP", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
111, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 111, 
UNIPHIER_PINCTRL_PIN(118, "SBPTM", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
112, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 112, 
UNIPHIER_PINCTRL_PIN(119, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "XMPREQ", 
113, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 113, 
UNIPHIER_PINCTRL_PIN(120, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "XINTP", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 114, 
114, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(121, "LPST", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
115, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
115, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "SDBOOT", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(122, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 116, 
116, <token> <answer> UNIPHIER_PIN_PULL_UP), 
<token> "BFAIL", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(123, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 117, 
117, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(124, "XFWE", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 118, 
118, <token> <answer> UNIPHIER_PIN_PULL_UP), 
<token> "RF_COM_RDY", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(125, 
119, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
119, <token> <answer> UNIPHIER_PIN_PULL_UP), 
<token> "XDIAG0", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(126, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 120, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 120, 
UNIPHIER_PINCTRL_PIN(127, "RXD0", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 121, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 121, 
<token> "TXD0", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(128, 
122, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
122, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(129, "RXD1", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 123, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 123, 
UNIPHIER_PINCTRL_PIN(130, "TXD1", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
124, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 124, 
<token> "RXD2", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(131, 
125, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
125, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(132, "TXD2", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
126, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 126, 
<token> "SS0CS", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(133, 
127, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
127, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(134, "SS0CLK", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 128, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 128, 
UNIPHIER_PINCTRL_PIN(135, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SS0DO", 
129, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
129, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(136, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SS0DI", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 130, 
130, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(137, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "MS0CS0", 
131, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
131, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(138, "MS0CLK", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
132, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
132, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(139, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "MS0DI", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 133, 
133, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(140, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "MS0DO", 
134, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 134, 
UNIPHIER_PINCTRL_PIN(141, "XMDMRST", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 135, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 135, 
UNIPHIER_PINCTRL_PIN(142, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SCL0", 
-1, <token> <answer> UNIPHIER_PIN_DRV_FIXED4, 
-1, <token> <answer> UNIPHIER_PIN_PULL_NONE), 
UNIPHIER_PINCTRL_PIN(143, "SDA0", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_FIXED4, <answer> -1, 
<token> UNIPHIER_PIN_PULL_NONE), <answer> -1, 
UNIPHIER_PINCTRL_PIN(144, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SCL1", 
-1, <token> <answer> UNIPHIER_PIN_DRV_FIXED4, 
-1, <token> <answer> UNIPHIER_PIN_PULL_NONE), 
<token> "SDA1", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(145, 
<token> UNIPHIER_PIN_DRV_FIXED4, <answer> -1, 
<token> UNIPHIER_PIN_PULL_NONE), <answer> -1, 
UNIPHIER_PINCTRL_PIN(146, "SCL2", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
-1, <token> <answer> UNIPHIER_PIN_DRV_FIXED4, 
-1, <token> <answer> UNIPHIER_PIN_PULL_NONE), 
UNIPHIER_PINCTRL_PIN(147, "SDA2", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
-1, <token> <answer> UNIPHIER_PIN_DRV_FIXED4, 
-1, <token> <answer> UNIPHIER_PIN_PULL_NONE), 
UNIPHIER_PINCTRL_PIN(148, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SCL3", 
-1, <token> <answer> UNIPHIER_PIN_DRV_FIXED4, 
<token> UNIPHIER_PIN_PULL_NONE), <answer> -1, 
UNIPHIER_PINCTRL_PIN(149, "SDA3", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_FIXED4, <answer> -1, 
-1, <token> <answer> UNIPHIER_PIN_PULL_NONE), 
UNIPHIER_PINCTRL_PIN(150, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SD0DAT0", 
<token> UNIPHIER_PIN_DRV_2BIT, <answer> 12, 
136, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(151, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SD0DAT1", 
13, <token> <answer> UNIPHIER_PIN_DRV_2BIT, 
137, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(152, "SD0DAT2", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
14, <token> <answer> UNIPHIER_PIN_DRV_2BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 138, 
UNIPHIER_PINCTRL_PIN(153, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SD0DAT3", 
<token> UNIPHIER_PIN_DRV_2BIT, <answer> 15, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 139, 
<token> "SD0CMD", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(154, 
<token> UNIPHIER_PIN_DRV_2BIT, <answer> 11, 
141, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(155, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SD0CLK", 
<token> UNIPHIER_PIN_DRV_2BIT, <answer> 10, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 140, 
UNIPHIER_PINCTRL_PIN(156, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "SD0CD", 
142, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 142, 
<token> "SD0WP", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(157, 
143, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 143, 
UNIPHIER_PINCTRL_PIN(158, "SD0VTCG", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
144, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 144, 
<token> "CK25O", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(159, 
145, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 145, 
<token> "RGMII_TXCLK", 6, <answer> UNIPHIER_PINCTRL_PIN(160, 
146, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
146, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "RGMII_TXD0", 6, <answer> UNIPHIER_PINCTRL_PIN(161, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 147, 
147, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "RGMII_TXD1", 6, <answer> UNIPHIER_PINCTRL_PIN(162, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 148, 
148, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "RGMII_TXD2", 6, <answer> UNIPHIER_PINCTRL_PIN(163, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 149, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 149, 
UNIPHIER_PINCTRL_PIN(164, <token> 6, <answer> "RGMII_TXD3", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 150, 
150, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(165, "RGMII_TXCTL", <token> <answer> 6, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 151, 
151, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "MII_TXER", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(166, 
152, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 152, 
UNIPHIER_PINCTRL_PIN(167, "RGMII_RXCLK", <token> <answer> 6, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 153, 
153, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "RGMII_RXD0", 6, <answer> UNIPHIER_PINCTRL_PIN(168, 
154, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 154, 
UNIPHIER_PINCTRL_PIN(169, "RGMII_RXD1", <token> <answer> 6, 
155, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 155, 
UNIPHIER_PINCTRL_PIN(170, <token> 6, <answer> "RGMII_RXD2", 
156, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
156, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "RGMII_RXD3", 6, <answer> UNIPHIER_PINCTRL_PIN(171, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 157, 
157, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(172, "RGMII_RXCTL", <token> <answer> 6, 
158, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 158, 
<token> "MII_RXER", 6, <answer> UNIPHIER_PINCTRL_PIN(173, 
159, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
159, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "MII_CRS", 6, <answer> UNIPHIER_PINCTRL_PIN(174, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 160, 
160, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(175, "MII_COL", <token> <answer> 6, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 161, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 161, 
<token> "MDC", 6, <answer> UNIPHIER_PINCTRL_PIN(176, 
162, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
162, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(177, <token> 6, <answer> "MDIO", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 163, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 163, 
<token> "MDIO_INTL", 6, <answer> UNIPHIER_PINCTRL_PIN(178, 
164, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 164, 
<token> "XETH_RST", 6, <answer> UNIPHIER_PINCTRL_PIN(179, 
165, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
165, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "USB0VBUS", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(180, 
166, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
166, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "USB0OD", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(181, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 167, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 167, 
UNIPHIER_PINCTRL_PIN(182, "USB1VBUS", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
168, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 168, 
UNIPHIER_PINCTRL_PIN(183, "USB1OD", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 169, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 169, 
UNIPHIER_PINCTRL_PIN(184, "USB2VBUS", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
170, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 170, 
<token> "USB2OD", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(185, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 171, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 171, 
UNIPHIER_PINCTRL_PIN(186, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "USB2ID", 
172, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_UP), <answer> 172, 
<token> "USB3VBUS", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(187, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 173, 
173, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "USB3OD", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(188, 
174, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
174, <token> <answer> UNIPHIER_PIN_PULL_UP), 
UNIPHIER_PINCTRL_PIN(189, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "LINKCLK", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 175, 
175, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "LINKREQ", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(190, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 176, 
176, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
UNIPHIER_PINCTRL_PIN(191, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "LINKCTL0", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 177, 
177, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "LINKCTL1", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(192, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 178, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 178, 
UNIPHIER_PINCTRL_PIN(193, <token> UNIPHIER_PIN_IECTRL_NONE, <answer> "LINKDT0", 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 179, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 179, 
UNIPHIER_PINCTRL_PIN(194, "LINKDT1", <token> <answer> UNIPHIER_PIN_IECTRL_NONE, 
<token> UNIPHIER_PIN_DRV_1BIT, <answer> 180, 
180, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
<token> "LINKDT2", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(195, 
181, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
<token> UNIPHIER_PIN_PULL_DOWN), <answer> 181, 
<token> "LINKDT3", UNIPHIER_PIN_IECTRL_NONE, <answer> UNIPHIER_PINCTRL_PIN(196, 
182, <token> <answer> UNIPHIER_PIN_DRV_1BIT, 
182, <token> <answer> UNIPHIER_PIN_PULL_DOWN), 
