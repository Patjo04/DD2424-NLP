<token> <linux/module.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/uaccess.h> 
<token> <linux/debugfs.h> <answer> #include 
<token> <linux/component.h> <answer> #include 
#include <token> <answer> <linux/of_irq.h> 
<token> <linux/phy/phy.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <drm/display/drm_dp_aux_bus.h> 
#include <token> <answer> <drm/drm_edid.h> 
#include <token> <answer> "msm_drv.h" 
#include <token> <answer> "msm_kms.h" 
<token> "dp_ctrl.h" <answer> #include 
#include <token> <answer> "dp_catalog.h" 
#include <token> <answer> "dp_aux.h" 
#include <token> <answer> "dp_reg.h" 
#include <token> <answer> "dp_link.h" 
<token> "dp_panel.h" <answer> #include 
<token> "dp_display.h" <answer> #include 
<token> "dp_drm.h" <answer> #include 
#include <token> <answer> "dp_audio.h" 
<token> "dp_debug.h" <answer> #include 
static bool <token> = false; <answer> psr_enabled 
module_param(psr_enabled, bool, <token> <answer> 0); 
MODULE_PARM_DESC(psr_enabled, <token> PSR for eDP and DP displays"); <answer> "enable 
<token> HPD_STRING_SIZE 30 <answer> #define 
<token> { <answer> enum 
dp_link_psm_config(dp->link, &dp->panel->link_info, <token> <answer> false); 
rc = <token> <answer> dp_ctrl_on_link(dp->ctrl); 
if (rc) <token> <answer> { 
DRM_ERROR("failed to complete DP link <token> <answer> training\n"); 
<token> end; <answer> goto 
<token> EV_USER_NOTIFICATION, true, 0); <answer> dp_add_event(dp, 
<token> rc; <answer> return 
static void dp_display_host_phy_init(struct <token> *dp) <answer> dp_display_private 
drm_dbg_dp(dp->drm_dev, <token> core_init=%d phy_init=%d\n", <answer> "type=%d 
dp->dp_display.connector_type, <token> <answer> dp->core_initialized, 
<token> (!dp->phy_initialized) { <answer> if 
dp->phy_initialized <token> true; <answer> = 
static void <token> dp_display_private *dp) <answer> dp_display_host_phy_exit(struct 
drm_dbg_dp(dp->drm_dev, "type=%d <token> phy_init=%d\n", <answer> core_init=%d 
dp->dp_display.connector_type, <token> <answer> dp->core_initialized, 
<token> (dp->phy_initialized) { <answer> if 
<token> = false; <answer> dp->phy_initialized 
static void dp_display_host_init(struct <token> *dp) <answer> dp_display_private 
drm_dbg_dp(dp->drm_dev, "type=%d <token> phy_init=%d\n", <answer> core_init=%d 
<token> dp->core_initialized, <answer> dp->dp_display.connector_type, 
dp_ctrl_reset_irq_ctrl(dp->ctrl, <token> <answer> true); 
dp->core_initialized = <token> <answer> true; 
static void <token> dp_display_private *dp) <answer> dp_display_host_deinit(struct 
<token> "type=%d core_init=%d phy_init=%d\n", <answer> drm_dbg_dp(dp->drm_dev, 
dp->dp_display.connector_type, <token> <answer> dp->core_initialized, 
<token> false); <answer> dp_ctrl_reset_irq_ctrl(dp->ctrl, 
dp->core_initialized = <token> <answer> false; 
static <token> dp_display_usbpd_configure_cb(struct device *dev) <answer> int 
<token> dp_display_private *dp = dev_get_dp_display_private(dev); <answer> struct 
<token> dp_display_process_hpd_high(dp); <answer> return 
static int <token> device *dev) <answer> dp_display_notify_disconnect(struct 
struct <token> *dp = dev_get_dp_display_private(dev); <answer> dp_display_private 
dp_add_event(dp, EV_USER_NOTIFICATION, false, <token> <answer> 0); 
<token> 0; <answer> return 
<token> void dp_display_handle_video_request(struct dp_display_private *dp) <answer> static 
if (dp->link->sink_request <token> DP_TEST_LINK_VIDEO_PATTERN) { <answer> & 
<token> = true; <answer> dp->panel->video_test 
static int dp_display_handle_port_status_changed(struct <token> *dp) <answer> dp_display_private 
int <token> = 0; <answer> rc 
if (drm_dp_is_branch(dp->panel->dpcd) && dp->link->sink_count == 0) <token> <answer> { 
drm_dbg_dp(dp->drm_dev, "sink count is zero, nothing <token> do\n"); <answer> to 
if (dp->hpd_state != <token> { <answer> ST_DISCONNECTED) 
dp->hpd_state = <token> <answer> ST_DISCONNECT_PENDING; 
dp_add_event(dp, EV_USER_NOTIFICATION, false, <token> <answer> 0); 
} else <token> <answer> { 
<token> (dp->hpd_state == ST_DISCONNECTED) { <answer> if 
dp->hpd_state = <token> <answer> ST_MAINLINK_READY; 
rc = <token> <answer> dp_display_process_hpd_high(dp); 
if <token> <answer> (rc) 
dp->hpd_state <token> ST_DISCONNECTED; <answer> = 
<token> rc; <answer> return 
static int <token> dp_display_private *dp) <answer> dp_display_handle_irq_hpd(struct 
u32 sink_request = <token> <answer> dp->link->sink_request; 
<token> "%d\n", sink_request); <answer> drm_dbg_dp(dp->drm_dev, 
<token> (dp->hpd_state == ST_DISCONNECTED) { <answer> if 
<token> (sink_request & DP_LINK_STATUS_UPDATED) { <answer> if 
drm_dbg_dp(dp->drm_dev, "Disconnected <token> %d\n", <answer> sink_request: 
DRM_ERROR("Disconnected, no <token> <answer> DP_LINK_STATUS_UPDATED\n"); 
<token> -EINVAL; <answer> return 
if <token> & DP_TEST_LINK_VIDEO_PATTERN) <answer> (sink_request 
<token> 0; <answer> return 
static int dp_display_usbpd_attention_cb(struct <token> *dev) <answer> device 
int rc <token> 0; <answer> = 
u32 <token> <answer> sink_request; 
struct dp_display_private *dp = <token> <answer> dev_get_dp_display_private(dev); 
<token> (state == ST_DISPLAY_OFF) { <answer> if 
dp->hpd_state <token> ST_DISCONNECTED; <answer> = 
} else <token> <answer> { 
dp->hpd_state <token> ST_DISCONNECT_PENDING; <answer> = 
} <token> { <answer> else 
dp_display->power_on = <token> <answer> false; 
drm_dbg_dp(dp->drm_dev, "sink count: %d\n", <token> <answer> dp->link->sink_count); 
<token> 0; <answer> return 
int dp_display_set_plugged_cb(struct msm_dp <token> <answer> *dp_display, 
hdmi_codec_plugged_cb <token> struct device *codec_dev) <answer> fn, 
bool <token> <answer> plugged; 
<token> = fn; <answer> dp_display->plugged_cb 
dp_display->codec_dev = <token> <answer> codec_dev; 
plugged = <token> <answer> dp_display->link_ready; 
<token> plugged); <answer> dp_display_handle_plugged_change(dp_display, 
return <token> <answer> 0; 
enum drm_mode_status dp_bridge_mode_valid(struct <token> *bridge, <answer> drm_bridge 
const struct drm_display_info <token> <answer> *info, 
const struct <token> *mode) <answer> drm_display_mode 
const u32 num_components = 3, default_bpp <token> 24; <answer> = 
struct dp_display_private <token> <answer> *dp_display; 
<token> dp_link_info *link_info; <answer> struct 
u32 mode_rate_khz = 0, supported_rate_khz <token> 0, mode_bpp = 0; <answer> = 
struct <token> *dp; <answer> msm_dp 
int mode_pclk_khz = <token> <answer> mode->clock; 
dp <token> to_dp_bridge(bridge)->dp_display; <answer> = 
<token> (!dp || !mode_pclk_khz || !dp->connector) { <answer> if 
DRM_ERROR("invalid <token> <answer> params\n"); 
return <token> <answer> -EINVAL; 
if (mode->clock > <token> <answer> DP_MAX_PIXEL_CLK_KHZ) 
<token> MODE_CLOCK_HIGH; <answer> return 
dp_display <token> container_of(dp, struct dp_display_private, dp_display); <answer> = 
<token> = &dp_display->panel->link_info; <answer> link_info 
if <token> mode) && <answer> (drm_mode_is_420_only(&dp->connector->display_info, 
<token> /= 2; <answer> mode_pclk_khz 
mode_bpp = dp->connector->display_info.bpc <token> num_components; <answer> * 
<token> (!mode_bpp) <answer> if 
mode_bpp <token> default_bpp; <answer> = 
<token> = dp_panel_get_mode_bpp(dp_display->panel, <answer> mode_bpp 
<token> mode_pclk_khz); <answer> mode_bpp, 
mode_rate_khz <token> mode_pclk_khz * mode_bpp; <answer> = 
supported_rate_khz = link_info->num_lanes * link_info->rate <token> 8; <answer> * 
if (mode_rate_khz <token> supported_rate_khz) <answer> > 
<token> MODE_BAD; <answer> return 
return <token> <answer> MODE_OK; 
int <token> msm_dp *dp) <answer> dp_display_get_modes(struct 
<token> dp_display_private *dp_display; <answer> struct 
if <token> { <answer> (!dp) 
DRM_ERROR("invalid <token> <answer> params\n"); 
return <token> <answer> 0; 
<token> = container_of(dp, struct dp_display_private, dp_display); <answer> dp_display 
<token> dp_panel_get_modes(dp_display->panel, <answer> return 
bool dp_display_check_video_test(struct <token> *dp) <answer> msm_dp 
struct <token> *dp_display; <answer> dp_display_private 
dp_display = container_of(dp, <token> dp_display_private, dp_display); <answer> struct 
return <token> <answer> dp_display->panel->video_test; 
int dp_display_get_test_bpp(struct <token> *dp) <answer> msm_dp 
struct dp_display_private <token> <answer> *dp_display; 
if (!dp) <token> <answer> { 
<token> params\n"); <answer> DRM_ERROR("invalid 
return <token> <answer> 0; 
dp_display = container_of(dp, struct <token> dp_display); <answer> dp_display_private, 
<token> dp_link_bit_depth_to_bpp( <answer> return 
<token> msm_dp_snapshot(struct msm_disp_state *disp_state, struct msm_dp *dp) <answer> void 
<token> dp_display_private *dp_display; <answer> struct 
dp_display = <token> struct dp_display_private, dp_display); <answer> container_of(dp, 
if (!dp->power_on) <token> <answer> { 
dp_catalog_snapshot(dp_display->catalog, <token> <answer> disp_state); 
void dp_display_set_psr(struct msm_dp *dp_display, bool <token> <answer> enter) 
struct <token> *dp; <answer> dp_display_private 
<token> (!dp_display) { <answer> if 
<token> params\n"); <answer> DRM_ERROR("invalid 
dp = container_of(dp_display, struct <token> dp_display); <answer> dp_display_private, 
<token> enter); <answer> dp_ctrl_set_psr(dp->ctrl, 
static int <token> *data) <answer> hpd_event_thread(void 
<token> dp_display_private *dp_priv; <answer> struct 
unsigned long <token> <answer> flag; 
<token> dp_event *todo; <answer> struct 
<token> timeout_mode = 0; <answer> int 
<token> = (struct dp_display_private *)data; <answer> dp_priv 
<token> (1) { <answer> while 
if <token> { <answer> (timeout_mode) 
(dp_priv->event_pndx == dp_priv->event_gndx) <token> <answer> || 
kthread_should_stop(), <token> <answer> EVENT_TIMEOUT); 
} else <token> <answer> { 
(dp_priv->event_pndx != dp_priv->event_gndx) <token> <answer> || 
if <token> <answer> (kthread_should_stop()) 
spin_lock_irqsave(&dp_priv->event_lock, <token> <answer> flag); 
<token> = &dp_priv->event_list[dp_priv->event_gndx]; <answer> todo 
if <token> { <answer> (todo->delay) 
struct <token> *todo_next; <answer> dp_event 
dp_priv->event_gndx %= <token> <answer> DP_EVENT_Q_MAX; 
dp->next_bridge = <token> dp->pdev->dev.of_node, 1, 0); <answer> devm_drm_of_get_bridge(&dp->pdev->dev, 
if <token> { <answer> (IS_ERR(dp->next_bridge)) 
ret <token> PTR_ERR(dp->next_bridge); <answer> = 
<token> = NULL; <answer> dp->next_bridge 
if <token> || ret != -ENODEV) <answer> (dp->is_edp 
<token> ret; <answer> return 
<token> = component_add(dev, &dp_display_comp_ops); <answer> ret 
<token> (ret) <answer> if 
<token> add failed, rc=%d\n", ret); <answer> DRM_ERROR("component 
<token> ret; <answer> return 
static int <token> drm_dp_aux *aux) <answer> dp_auxbus_done_probe(struct 
return <token> <answer> dp_display_probe_tail(aux->dev); 
<token> int dp_display_probe(struct platform_device *pdev) <answer> static 
int rc = <token> <answer> 0; 
struct <token> *dp; <answer> dp_display_private 
const struct msm_dp_desc <token> <answer> *desc; 
if (!pdev || !pdev->dev.of_node) <token> <answer> { 
<token> not found\n"); <answer> DRM_ERROR("pdev 
<token> -ENODEV; <answer> return 
dp <token> devm_kzalloc(&pdev->dev, sizeof(*dp), GFP_KERNEL); <answer> = 
if <token> <answer> (!dp) 
<token> -ENOMEM; <answer> return 
<token> = dp_display_get_desc(pdev); <answer> desc 
if <token> <answer> (!desc) 
<token> -EINVAL; <answer> return 
<token> = pdev; <answer> dp->dp_display.pdev 
dp->name = <token> <answer> "drm_dp"; 
dp->id = <token> <answer> desc->id; 
<token> = desc->connector_type; <answer> dp->dp_display.connector_type 
dp->wide_bus_supported <token> desc->wide_bus_supported; <answer> = 
dp->dp_display.is_edp <token> <answer> = 
(dp->dp_display.connector_type <token> DRM_MODE_CONNECTOR_eDP); <answer> == 
<token> = dp_init_sub_modules(dp); <answer> rc 
if <token> { <answer> (rc) 
<token> sub module failed\n"); <answer> DRM_ERROR("init 
<token> -EPROBE_DEFER; <answer> return 
if (dp->dp_display.is_edp) <token> <answer> { 
return <token> <answer> 0; 
static const struct dev_pm_ops <token> = { <answer> dp_pm_ops 
<token> dp_pm_runtime_resume, NULL) <answer> SET_RUNTIME_PM_OPS(dp_pm_runtime_suspend, 
<token> struct platform_driver dp_display_driver = { <answer> static 
.probe <token> dp_display_probe, <answer> = 
.remove_new = <token> <answer> dp_display_remove, 
.driver <token> { <answer> = 
.name <token> "msm-dp-display", <answer> = 
<token> = dp_dt_match, <answer> .of_match_table 
.suppress_bind_attrs = <token> <answer> true, 
.pm <token> &dp_pm_ops, <answer> = 
int <token> msm_dp_register(void) <answer> __init 
int <token> <answer> ret; 
ret <token> platform_driver_register(&dp_display_driver); <answer> = 
if <token> <answer> (ret) 
<token> display driver register failed"); <answer> DRM_ERROR("Dp 
<token> ret; <answer> return 
void <token> msm_dp_unregister(void) <answer> __exit 
bool msm_dp_is_yuv_420_enabled(const struct <token> *dp_display, <answer> msm_dp 
const <token> drm_display_mode *mode) <answer> struct 
<token> dp_display_private *dp; <answer> struct 
const struct drm_display_info <token> <answer> *info; 
<token> = container_of(dp_display, struct dp_display_private, dp_display); <answer> dp 
<token> = &dp_display->connector->display_info; <answer> info 
return dp->panel->vsc_sdp_supported <token> drm_mode_is_420_only(info, mode); <answer> && 
<token> msm_dp_needs_periph_flush(const struct msm_dp *dp_display, <answer> bool 
const <token> drm_display_mode *mode) <answer> struct 
<token> msm_dp_is_yuv_420_enabled(dp_display, mode); <answer> return 
bool msm_dp_wide_bus_available(const <token> msm_dp *dp_display) <answer> struct 
<token> dp_display_private *dp; <answer> struct 
dp = <token> struct dp_display_private, dp_display); <answer> container_of(dp_display, 
<token> (dp->dp_mode.out_fmt_is_yuv_420) <answer> if 
<token> false; <answer> return 
<token> dp->wide_bus_supported; <answer> return 
void dp_display_debugfs_init(struct msm_dp <token> struct dentry *root, bool is_edp) <answer> *dp_display, 
<token> dp_display_private *dp; <answer> struct 
struct device <token> <answer> *dev; 
int <token> <answer> rc; 
dp = <token> struct dp_display_private, dp_display); <answer> container_of(dp_display, 
dev <token> &dp->dp_display.pdev->dev; <answer> = 
<token> = dp_debug_get(dev, dp->panel, <answer> dp->debug 
dp->link, <token> <answer> dp->dp_display.connector, 
root, <token> <answer> is_edp); 
if <token> { <answer> (IS_ERR(dp->debug)) 
rc <token> PTR_ERR(dp->debug); <answer> = 
DRM_ERROR("failed to initialize debug, <token> = %d\n", rc); <answer> rc 
<token> = NULL; <answer> dp->debug 
int msm_dp_modeset_init(struct <token> *dp_display, struct drm_device *dev, <answer> msm_dp 
struct drm_encoder *encoder, bool <token> <answer> yuv_supported) 
struct <token> *dp_priv; <answer> dp_display_private 
int <token> <answer> ret; 
dp_display->drm_dev = <token> <answer> dev; 
dp_priv = container_of(dp_display, struct <token> dp_display); <answer> dp_display_private, 
<token> = dp_bridge_init(dp_display, dev, encoder); <answer> ret 
if <token> { <answer> (ret) 
"failed to create dp <token> %d\n", ret); <answer> bridge: 
return <token> <answer> ret; 
<token> = dp_drm_connector_init(dp_display, encoder, yuv_supported); <answer> dp_display->connector 
<token> (IS_ERR(dp_display->connector)) { <answer> if 
ret <token> PTR_ERR(dp_display->connector); <answer> = 
"failed to create dp connector: %d\n", <token> <answer> ret); 
<token> = NULL; <answer> dp_display->connector 
<token> ret; <answer> return 
<token> = dp_display->connector; <answer> dp_priv->panel->connector 
return <token> <answer> 0; 
void dp_bridge_atomic_enable(struct drm_bridge <token> <answer> *drm_bridge, 
<token> drm_bridge_state *old_bridge_state) <answer> struct 
struct <token> *dp_bridge = to_dp_bridge(drm_bridge); <answer> msm_dp_bridge 
struct msm_dp *dp = <token> <answer> dp_bridge->dp_display; 
int rc = <token> <answer> 0; 
struct <token> *dp_display; <answer> dp_display_private 
<token> state; <answer> u32 
bool <token> = false; <answer> force_link_train 
dp_display = container_of(dp, struct dp_display_private, <token> <answer> dp_display); 
if (!dp_display->dp_mode.drm_mode.clock) <token> <answer> { 
DRM_ERROR("invalid <token> <answer> params\n"); 
<token> (dp->is_edp) <answer> if 
dp_hpd_plug_handle(dp_display, <token> <answer> 0); 
<token> (pm_runtime_resume_and_get(&dp->pdev->dev)) { <answer> if 
DRM_ERROR("failed to <token> <answer> pm_runtime_resume\n"); 
state = <token> <answer> dp_display->hpd_state; 
<token> (state != ST_DISPLAY_OFF && state != ST_MAINLINK_READY) { <answer> if 
<token> = dp_display_set_mode(dp, &dp_display->dp_mode); <answer> rc 
if <token> { <answer> (rc) 
<token> to perform a mode set, rc=%d\n", rc); <answer> DRM_ERROR("Failed 
state <token> dp_display->hpd_state; <answer> = 
if (state == <token> { <answer> ST_DISPLAY_OFF) 
force_link_train = <token> <answer> true; 
<token> force_link_train); <answer> dp_display_enable(dp_display, 
rc <token> dp_display_post_enable(dp); <answer> = 
if <token> { <answer> (rc) 
DRM_ERROR("DP display <token> enable failed, rc=%d\n", rc); <answer> post 
if (pm_runtime_resume_and_get(&dp_display->pdev->dev)) <token> <answer> { 
DRM_ERROR("failed <token> resume power\n"); <answer> to 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/etherdevice.h> <answer> #include 
<token> <linux/pm_runtime.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
#include <token> <answer> "wlcore.h" 
<token> "debug.h" <answer> #include 
#include <token> <answer> "io.h" 
<token> "ps.h" <answer> #include 
<token> "tx.h" <answer> #include 
#include <token> <answer> "event.h" 
<token> "hw_ops.h" <answer> #include 
<token> "../wl12xx/reg.h" <answer> #include 
<token> int wl1271_set_default_wep_key(struct wl1271 *wl, <answer> static 
struct wl12xx_vif *wlvif, u8 <token> <answer> id) 
int <token> <answer> ret; 
<token> is_ap = (wlvif->bss_type == BSS_TYPE_AP_BSS); <answer> bool 
if <token> <answer> (is_ap) 
ret = wl12xx_cmd_set_default_wep_key(wl, <token> <answer> id, 
ret <token> wl12xx_cmd_set_default_wep_key(wl, id, wlvif->sta.hlid); <answer> = 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
wl1271_debug(DEBUG_CRYPT, "default wep key idx: %d", <token> <answer> (int)id); 
<token> 0; <answer> return 
static int wl1271_alloc_tx_id(struct wl1271 <token> struct sk_buff *skb) <answer> *wl, 
<token> id; <answer> int 
id = find_first_zero_bit(wl->tx_frames_map, <token> <answer> wl->num_tx_desc); 
<token> (id >= wl->num_tx_desc) <answer> if 
return <token> <answer> -EBUSY; 
<token> wl->tx_frames_map); <answer> __set_bit(id, 
<token> = skb; <answer> wl->tx_frames[id] 
return <token> <answer> id; 
void wl1271_free_tx_id(struct wl1271 *wl, int <token> <answer> id) 
<token> (__test_and_clear_bit(id, wl->tx_frames_map)) { <answer> if 
<token> (unlikely(wl->tx_frames_cnt == wl->num_tx_desc)) <answer> if 
clear_bit(WL1271_FLAG_FW_TX_BUSY, <token> <answer> &wl->flags); 
<token> = NULL; <answer> wl->tx_frames[id] 
static void wl1271_tx_ap_update_inconnection_sta(struct <token> *wl, <answer> wl1271 
<token> wl12xx_vif *wlvif, <answer> struct 
struct <token> *skb) <answer> sk_buff 
struct ieee80211_hdr <token> <answer> *hdr; 
hdr = <token> ieee80211_hdr *)(skb->data + <answer> (struct 
<token> wl1271_tx_hw_descr)); <answer> sizeof(struct 
if <token> <answer> (!ieee80211_is_auth(hdr->frame_control)) 
wl1271_acx_set_inconnection_sta(wl, wlvif, <token> <answer> hdr->addr1); 
wlcore_update_inconn_sta(wl, wlvif, <token> true); <answer> NULL, 
<token> = jiffies; <answer> wlvif->pending_auth_reply_time 
static void <token> wl1271 *wl, <answer> wl1271_tx_regulate_link(struct 
<token> wl12xx_vif *wlvif, <answer> struct 
<token> hlid) <answer> u8 
<token> fw_ps; <answer> bool 
<token> tx_pkts; <answer> u8 
if (WARN_ON(!test_bit(hlid, <token> <answer> wlvif->links_map))) 
fw_ps <token> test_bit(hlid, &wl->ap_fw_ps_map); <answer> = 
<token> = wl->links[hlid].allocated_pkts; <answer> tx_pkts 
if (wl->active_link_count > (wl->ap_count*2 + 1) && fw_ps <token> <answer> && 
tx_pkts <token> WL1271_PS_STA_MAX_PACKETS) <answer> >= 
wl12xx_ps_link_start(wl, <token> hlid, true); <answer> wlvif, 
<token> wl12xx_is_dummy_packet(struct wl1271 *wl, struct sk_buff *skb) <answer> bool 
return wl->dummy_packet <token> skb; <answer> == 
static u8 wl12xx_tx_get_hlid_ap(struct wl1271 *wl, struct wl12xx_vif <token> <answer> *wlvif, 
struct sk_buff *skb, <token> ieee80211_sta *sta) <answer> struct 
if <token> { <answer> (sta) 
struct wl1271_station <token> <answer> *wl_sta; 
wl_sta = (struct <token> *)sta->drv_priv; <answer> wl1271_station 
return <token> <answer> wl_sta->hlid; 
<token> else { <answer> } 
<token> ieee80211_hdr *hdr; <answer> struct 
<token> (!test_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags)) <answer> if 
<token> wl->system_hlid; <answer> return 
hdr = (struct <token> *)skb->data; <answer> ieee80211_hdr 
if <token> <answer> (is_multicast_ether_addr(ieee80211_get_DA(hdr))) 
return <token> <answer> wlvif->ap.bcast_hlid; 
<token> wlvif->ap.global_hlid; <answer> return 
<token> wl12xx_tx_get_hlid(struct wl1271 *wl, struct wl12xx_vif *wlvif, <answer> u8 
struct sk_buff *skb, <token> ieee80211_sta *sta) <answer> struct 
struct <token> *control; <answer> ieee80211_tx_info 
<token> (wlvif->bss_type == BSS_TYPE_AP_BSS) <answer> if 
return wl12xx_tx_get_hlid_ap(wl, wlvif, <token> sta); <answer> skb, 
control <token> IEEE80211_SKB_CB(skb); <answer> = 
if (control->flags & IEEE80211_TX_CTL_TX_OFFCHAN) <token> <answer> { 
wl1271_debug(DEBUG_TX, "tx <token> <answer> offchannel"); 
return <token> <answer> wlvif->dev_hlid; 
<token> wlvif->sta.hlid; <answer> return 
unsigned int wlcore_calc_packet_alignment(struct <token> *wl, <answer> wl1271 
unsigned <token> packet_length) <answer> int 
if ((wl->quirks & <token> || <answer> WLCORE_QUIRK_TX_PAD_LAST_FRAME) 
<token> & WLCORE_QUIRK_TX_BLOCKSIZE_ALIGN)) <answer> !(wl->quirks 
<token> ALIGN(packet_length, WL1271_TX_ALIGN_TO); <answer> return 
return <token> WL12XX_BUS_BLOCK_SIZE); <answer> ALIGN(packet_length, 
static int wl1271_tx_allocate(struct wl1271 *wl, <token> wl12xx_vif *wlvif, <answer> struct 
struct sk_buff *skb, <token> extra, u32 buf_offset, <answer> u32 
u8 <token> bool is_gem) <answer> hlid, 
struct wl1271_tx_hw_descr <token> <answer> *desc; 
u32 total_len = skb->len <token> sizeof(struct wl1271_tx_hw_descr) + extra; <answer> + 
u32 <token> <answer> total_blocks; 
<token> id, ret = -EBUSY, ac; <answer> int 
<token> spare_blocks; <answer> u32 
if (buf_offset + total_len <token> wl->aggr_buf_size) <answer> > 
<token> -EAGAIN; <answer> return 
<token> = wlcore_hw_get_spare_blocks(wl, is_gem); <answer> spare_blocks 
if (wl->tx_allocated_blocks == <token> || <answer> total_blocks 
test_and_clear_bit(WL1271_FLAG_REINIT_TX_WDOG, <token> <answer> &wl->flags)) 
ac = <token> <answer> wl1271_tx_get_queue(skb_get_queue_mapping(skb)); 
<token> (test_bit(hlid, wl->links_map)) <answer> if 
ret = <token> <answer> 0; 
"tx_allocate: size: %d, blocks: %d, id: <token> <answer> %d", 
total_len, total_blocks, <token> <answer> id); 
<token> else { <answer> } 
wl1271_free_tx_id(wl, <token> <answer> id); 
return <token> <answer> ret; 
static void wl1271_tx_fill_hdr(struct wl1271 *wl, <token> wl12xx_vif *wlvif, <answer> struct 
<token> sk_buff *skb, u32 extra, <answer> struct 
struct ieee80211_tx_info *control, <token> hlid) <answer> u8 
struct <token> *desc; <answer> wl1271_tx_hw_descr 
<token> ac, rate_idx; <answer> int 
s64 <token> <answer> hosttime; 
u16 tx_attr <token> 0; <answer> = 
<token> frame_control; <answer> __le16 
<token> ieee80211_hdr *hdr; <answer> struct 
<token> *frame_start; <answer> u8 
<token> is_dummy; <answer> bool 
<token> = (struct wl1271_tx_hw_descr *) skb->data; <answer> desc 
frame_start = (u8 <token> + 1); <answer> *)(desc 
hdr = (struct <token> *)(frame_start + extra); <answer> ieee80211_hdr 
frame_control <token> hdr->frame_control; <answer> = 
tx_attr = (SESSION_COUNTER_INVALID <token> <answer> << 
TX_HW_ATTR_OFST_SESSION_COUNTER) <token> <answer> & 
tx_attr <token> TX_HW_ATTR_TX_DUMMY_REQ; <answer> |= 
} else if (wlvif) <token> <answer> { 
<token> session_id = wl->session_ids[hlid]; <answer> u8 
if ((wl->quirks & WLCORE_QUIRK_AP_ZERO_SESSION_ID) <token> <answer> && 
(wlvif->bss_type == <token> <answer> BSS_TYPE_AP_BSS)) 
session_id = <token> <answer> 0; 
if <token> == cpu_to_be16(ETH_P_PAE)) <answer> (skb->protocol 
rate_idx <token> wlvif->sta.basic_rate_idx; <answer> = 
else <token> (control->flags & IEEE80211_TX_CTL_NO_CCK_RATE) <answer> if 
rate_idx = <token> <answer> wlvif->sta.p2p_rate_idx; 
<token> if (ieee80211_is_data(frame_control)) <answer> else 
rate_idx <token> wlvif->sta.ap_rate_idx; <answer> = 
rate_idx <token> wlvif->sta.basic_rate_idx; <answer> = 
} else <token> <answer> { 
<token> (hlid == wlvif->ap.global_hlid) <answer> if 
rate_idx <token> wlvif->ap.mgmt_rate_idx; <answer> = 
else if <token> == wlvif->ap.bcast_hlid || <answer> (hlid 
<token> == cpu_to_be16(ETH_P_PAE) || <answer> skb->protocol 
<token> = wlvif->ap.bcast_rate_idx; <answer> rate_idx 
<token> = wlvif->ap.ucast_rate_idx[ac]; <answer> rate_idx 
tx_attr |= rate_idx <token> TX_HW_ATTR_OFST_RATE_POLICY; <answer> << 
total_len = <token> skb->len); <answer> wlcore_calc_packet_alignment(wl, 
<token> + buf_offset, skb->data, skb->len); <answer> memcpy(wl->aggr_buf 
memset(wl->aggr_buf + buf_offset + skb->len, <token> total_len - skb->len); <answer> 0, 
for (i = 0; i < <token> i++) { <answer> NUM_TX_QUEUES; 
ac = <token> <answer> wl1271_tx_get_queue(i); 
if (wl->tx_queue_count[ac] <token> <answer> && 
wl->tx_allocated_pkts[ac] < <token> { <answer> min_pkts) 
<token> = ac; <answer> q 
min_pkts <token> wl->tx_allocated_pkts[q]; <answer> = 
<token> q; <answer> return 
static struct sk_buff *wlcore_lnk_dequeue(struct wl1271 <token> <answer> *wl, 
<token> wl1271_link *lnk, u8 q) <answer> struct 
struct <token> *skb; <answer> sk_buff 
<token> long flags; <answer> unsigned 
skb <token> skb_dequeue(&lnk->tx_queue[q]); <answer> = 
if <token> { <answer> (skb) 
<token> flags); <answer> spin_lock_irqsave(&wl->wl_lock, 
WARN_ON_ONCE(wl->tx_queue_count[q] <token> 0); <answer> <= 
if (lnk->wlvif) <token> <answer> { 
WARN_ON_ONCE(lnk->wlvif->tx_queue_count[q] <token> 0); <answer> <= 
spin_unlock_irqrestore(&wl->wl_lock, <token> <answer> flags); 
<token> skb; <answer> return 
static struct <token> *wlcore_lnk_dequeue_high_prio(struct wl1271 *wl, <answer> sk_buff 
u8 hlid, u8 <token> <answer> ac, 
u8 <token> <answer> *low_prio_hlid) 
struct wl1271_link *lnk = <token> <answer> &wl->links[hlid]; 
<token> (!wlcore_hw_lnk_high_prio(wl, hlid, lnk)) { <answer> if 
if (*low_prio_hlid <token> WL12XX_INVALID_LINK_ID && <answer> == 
<token> && <answer> !skb_queue_empty(&lnk->tx_queue[ac]) 
wlcore_hw_lnk_low_prio(wl, hlid, <token> <answer> lnk)) 
if <token> { <answer> (!skb) 
<token> wlvif) { <answer> wl12xx_for_each_wlvif(wl, 
if <token> <answer> (!wlvif->tx_queue_count[ac]) 
<token> next; <answer> goto 
skb = <token> wlvif, ac, hlid, <answer> wlcore_vif_dequeue_high_prio(wl, 
if (skb) <token> <answer> { 
wl->last_wlvif = <token> <answer> wlvif; 
if <token> == wl->last_wlvif) <answer> (wlvif 
<token> wlcore_tx_work_locked(struct wl1271 *wl) <answer> int 
struct <token> *wlvif; <answer> wl12xx_vif 
<token> sk_buff *skb; <answer> struct 
<token> wl1271_tx_hw_descr *desc; <answer> struct 
u32 buf_offset = 0, last_len = <token> <answer> 0; 
bool <token> = false; <answer> sent_packets 
unsigned long active_hlids[BITS_TO_LONGS(WLCORE_MAX_LINKS)] = <token> <answer> {0}; 
int <token> = 0; <answer> ret 
int bus_ret <token> 0; <answer> = 
<token> hlid; <answer> u8 
<token> (unlikely(wl->state != WLCORE_STATE_ON)) <answer> if 
<token> 0; <answer> return 
while <token> = wl1271_skb_dequeue(wl, &hlid))) { <answer> ((skb 
struct ieee80211_tx_info *info = <token> <answer> IEEE80211_SKB_CB(skb); 
bool has_data <token> false; <answer> = 
<token> = NULL; <answer> wlvif 
if <token> skb)) <answer> (!wl12xx_is_dummy_packet(wl, 
wlvif <token> wl12xx_vif_to_data(info->control.vif); <answer> = 
hlid = <token> <answer> wl->system_hlid; 
has_data = wlvif <token> wl1271_tx_is_data_present(skb); <answer> && 
ret = <token> wlvif, skb, buf_offset, <answer> wl1271_prepare_tx_frame(wl, 
<token> (ret == -EAGAIN) { <answer> if 
wl1271_skb_queue_head(wl, wlvif, skb, <token> <answer> hlid); 
buf_offset = wlcore_hw_pre_pkt_send(wl, <token> <answer> buf_offset, 
<token> = wlcore_write_data(wl, REG_SLV_MEM_DATA, <answer> bus_ret 
<token> buf_offset, true); <answer> wl->aggr_buf, 
<token> (bus_ret < 0) <answer> if 
<token> out; <answer> goto 
<token> = true; <answer> sent_packets 
<token> = 0; <answer> buf_offset 
} else if (ret == <token> { <answer> -EBUSY) 
wl1271_skb_queue_head(wl, wlvif, <token> hlid); <answer> skb, 
<token> wlvif, skb, hlid); <answer> wl1271_skb_queue_head(wl, 
ieee80211_free_txskb(wl->hw, <token> <answer> skb); 
goto <token> <answer> out_ack; 
<token> = ret; <answer> last_len 
buf_offset <token> last_len; <answer> += 
if <token> { <answer> (has_data) 
<token> = (struct wl1271_tx_hw_descr *) skb->data; <answer> desc 
<token> active_hlids); <answer> __set_bit(desc->hlid, 
if (buf_offset) <token> <answer> { 
buf_offset = wlcore_hw_pre_pkt_send(wl, buf_offset, <token> <answer> last_len); 
bus_ret = wlcore_write_data(wl, <token> wl->aggr_buf, <answer> REG_SLV_MEM_DATA, 
<token> true); <answer> buf_offset, 
<token> (bus_ret < 0) <answer> if 
<token> out; <answer> goto 
sent_packets = <token> <answer> true; 
if <token> { <answer> (sent_packets) 
<token> (wl->quirks & WLCORE_QUIRK_END_OF_TRANSACTION) { <answer> if 
bus_ret <token> wlcore_write32(wl, WL12XX_HOST_WR_ACCESS, <answer> = 
if <token> < 0) <answer> (bus_ret 
goto <token> <answer> out; 
<token> active_hlids); <answer> wl12xx_rearm_rx_streaming(wl, 
return <token> <answer> bus_ret; 
void wl1271_tx_work(struct <token> *work) <answer> work_struct 
struct <token> *wl = container_of(work, struct wl1271, tx_work); <answer> wl1271 
<token> ret; <answer> int 
ret = <token> <answer> pm_runtime_resume_and_get(wl->dev); 
<token> (ret < 0) <answer> if 
goto <token> <answer> out; 
<token> = wlcore_tx_work_locked(wl); <answer> ret 
if (ret <token> 0) { <answer> < 
<token> out; <answer> goto 
static u8 <token> rate_class_index) <answer> wl1271_tx_get_rate_flags(u8 
<token> flags = 0; <answer> u8 
if (rate_class_index <= <token> <answer> 8) 
flags |= <token> <answer> IEEE80211_TX_RC_MCS; 
if (rate_class_index <token> 0) <answer> == 
flags <token> IEEE80211_TX_RC_SHORT_GI; <answer> |= 
<token> flags; <answer> return 
static <token> wl1271_tx_complete_packet(struct wl1271 *wl, <answer> void 
struct wl1271_tx_hw_res_descr <token> <answer> *result) 
struct ieee80211_tx_info <token> <answer> *info; 
struct ieee80211_vif <token> <answer> *vif; 
struct <token> *wlvif; <answer> wl12xx_vif 
struct sk_buff <token> <answer> *skb; 
int id = <token> <answer> result->id; 
int rate <token> -1; <answer> = 
u8 rate_flags <token> 0; <answer> = 
u8 <token> = 0; <answer> retries 
for (i = 0; i < wl->num_tx_desc; <token> { <answer> i++) 
if (wl->tx_frames[i] <token> NULL) <answer> == 
skb = <token> <answer> wl->tx_frames[i]; 
<token> i); <answer> wl1271_free_tx_id(wl, 
wl1271_debug(DEBUG_TX, "freeing <token> 0x%p", skb); <answer> skb 
if (!wl12xx_is_dummy_packet(wl, <token> { <answer> skb)) 
info <token> IEEE80211_SKB_CB(skb); <answer> = 
<token> sizeof(struct wl1271_tx_hw_descr)); <answer> skb_pull(skb, 
if <token> & WLCORE_QUIRK_TKIP_HEADER_SPACE) && <answer> ((wl->quirks 
<token> && <answer> info->control.hw_key 
info->control.hw_key->cipher <token> <answer> == 
WLAN_CIPHER_SUITE_TKIP) <token> <answer> { 
int hdrlen <token> ieee80211_get_hdrlen_from_skb(skb); <answer> = 
<token> + WL1271_EXTRA_SPACE_TKIP, <answer> memmove(skb->data 
skb->data, <token> <answer> hdrlen); 
skb_pull(skb, <token> <answer> WL1271_EXTRA_SPACE_TKIP); 
<token> = -1; <answer> info->status.rates[0].idx 
<token> = 0; <answer> info->status.rates[0].count 
<token> skb); <answer> ieee80211_tx_status_ni(wl->hw, 
#define <token> 500000 <answer> WL1271_TX_FLUSH_TIMEOUT 
spin_unlock_irqrestore(&wl->wl_lock, <token> <answer> flags); 
<token> wlcore_wake_queues(struct wl1271 *wl, <answer> void 
enum wlcore_queue_stop_reason <token> <answer> reason) 
int <token> <answer> i; 
unsigned long <token> <answer> flags; 
spin_lock_irqsave(&wl->wl_lock, <token> <answer> flags); 
spin_unlock_irqrestore(&wl->wl_lock, <token> <answer> flags); 
<token> wlcore_is_queue_stopped_by_reason(struct wl1271 *wl, <answer> bool 
struct wl12xx_vif <token> u8 queue, <answer> *wlvif, 
<token> wlcore_queue_stop_reason reason) <answer> enum 
unsigned long <token> <answer> flags; 
bool <token> <answer> stopped; 
<token> flags); <answer> spin_lock_irqsave(&wl->wl_lock, 
stopped = wlcore_is_queue_stopped_by_reason_locked(wl, wlvif, <token> <answer> queue, 
spin_unlock_irqrestore(&wl->wl_lock, <token> <answer> flags); 
<token> stopped; <answer> return 
bool wlcore_is_queue_stopped_by_reason_locked(struct <token> *wl, <answer> wl1271 
struct <token> *wlvif, u8 queue, <answer> wl12xx_vif 
<token> wlcore_queue_stop_reason reason) <answer> enum 
int hwq <token> wlcore_tx_get_mac80211_queue(wlvif, queue); <answer> = 
return test_bit(reason, <token> <answer> &wl->queue_stop_reasons[hwq]); 
bool wlcore_is_queue_stopped_locked(struct wl1271 <token> struct wl12xx_vif *wlvif, <answer> *wl, 
<token> queue) <answer> u8 
int hwq = wlcore_tx_get_mac80211_queue(wlvif, <token> <answer> queue); 
<token> !!wl->queue_stop_reasons[hwq]; <answer> return 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/netdevice.h> 
<token> <linux/bitfield.h> <answer> #include 
#include <token> <answer> <linux/of_mdio.h> 
<token> "spl2sw_register.h" <answer> #include 
<token> "spl2sw_define.h" <answer> #include 
<token> "spl2sw_desc.h" <answer> #include 
<token> "spl2sw_mac.h" <answer> #include 
void <token> spl2sw_common *comm) <answer> spl2sw_mac_hw_stop(struct 
u32 <token> <answer> reg; 
if (comm->enable == 0) <token> <answer> { 
reg = MAC_W_LAN_PORT_0 | <token> mac->vlan_id) | MAC_W_MAC_CMD; <answer> FIELD_PREP(MAC_W_VID, 
writel(reg, <token> + L2SW_WT_MAC_AD0); <answer> comm->l2sw_reg_base 
reg = readl(comm->l2sw_reg_base + <token> <answer> L2SW_CPU_CNTL); 
reg &= ~(MAC_EN_SOC1_AGING <token> MAC_EN_SOC0_AGING | <answer> | 
MAC_DIS_BC2CPU_P1 | <token> | <answer> MAC_DIS_BC2CPU_P0 
<token> | MAC_DIS_MC2CPU_P0); <answer> MAC_DIS_MC2CPU_P1 
reg |= MAC_DIS_LRN_SOC1 <token> MAC_DIS_LRN_SOC0; <answer> | 
writel(reg, <token> + L2SW_CPU_CNTL); <answer> comm->l2sw_reg_base 
<token> = readl(comm->l2sw_reg_base + L2SW_PORT_CNTL0); <answer> reg 
reg &= ~(MAC_DIS_RMC2CPU_P1 | <token> <answer> MAC_DIS_RMC2CPU_P0); 
reg <token> MAC_EN_FLOW_CTL_P1 | MAC_EN_FLOW_CTL_P0 | <answer> |= 
MAC_EN_BACK_PRESS_P1 <token> MAC_EN_BACK_PRESS_P0; <answer> | 
writel(reg, comm->l2sw_reg_base + <token> <answer> L2SW_PORT_CNTL0); 
<token> = readl(comm->l2sw_reg_base + L2SW_MAC_FORCE_MODE); <answer> reg 
reg <token> ~(MAC_EXT_PHY1_ADDR | MAC_EXT_PHY0_ADDR); <answer> &= 
reg |= <token> 31) | FIELD_PREP(MAC_EXT_PHY0_ADDR, 31); <answer> FIELD_PREP(MAC_EXT_PHY1_ADDR, 
reg |= <token> | MAC_FORCE_RMII_EN_0; <answer> MAC_FORCE_RMII_EN_1 
writel(reg, <token> + L2SW_MAC_FORCE_MODE); <answer> comm->l2sw_reg_base 
reg = <token> 1) | FIELD_PREP(MAC_P0_PVID, 0); <answer> FIELD_PREP(MAC_P1_PVID, 
writel(reg, <token> + L2SW_PVID_CONFIG0); <answer> comm->l2sw_reg_base 
reg = FIELD_PREP(MAC_VLAN_MEMSET_1, 0xa) <token> FIELD_PREP(MAC_VLAN_MEMSET_0, 9); <answer> | 
<token> comm->l2sw_reg_base + L2SW_VLAN_MEMSET_CONFIG0); <answer> writel(reg, 
reg = readl(comm->l2sw_reg_base + <token> <answer> L2SW_SW_GLB_CNTL); 
reg &= <token> | MAC_LED_FLASH_TIME | MAC_BC_STORM_PREV); <answer> ~(MAC_RMC_TB_FAULT_RULE 
reg |= FIELD_PREP(MAC_RMC_TB_FAULT_RULE, <token> | <answer> 1) 
<token> 1) | <answer> FIELD_PREP(MAC_LED_FLASH_TIME, 
FIELD_PREP(MAC_BC_STORM_PREV, <token> <answer> 1); 
<token> comm->l2sw_reg_base + L2SW_SW_GLB_CNTL); <answer> writel(reg, 
writel(MAC_INT_MASK_DEF, comm->l2sw_reg_base <token> L2SW_SW_INT_MASK_0); <answer> + 
void spl2sw_mac_rx_mode_set(struct spl2sw_mac <token> <answer> *mac) 
struct spl2sw_common *comm = <token> <answer> mac->comm; 
struct net_device *ndev <token> mac->ndev; <answer> = 
u32 <token> reg, rx_mode; <answer> mask, 
netdev_dbg(ndev, <token> = %08x\n", ndev->flags); <answer> "ndev->flags 
mask <token> FIELD_PREP(MAC_DIS_MC2CPU, mac->lan_port) | <answer> = 
<token> mac->lan_port); <answer> FIELD_PREP(MAC_DIS_UN2CPU, 
reg = readl(comm->l2sw_reg_base <token> L2SW_CPU_CNTL); <answer> + 
if <token> & IFF_PROMISC) { <answer> (ndev->flags 
<token> <linux/module.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
<token> <linux/pinctrl/pinctrl.h> <answer> #include 
#include <token> <answer> <linux/regmap.h> 
<token> <linux/pinctrl/pinconf-generic.h> <answer> #include 
#include <token> <answer> <dt-bindings/pinctrl/mt65xx.h> 
#include <token> <answer> "pinctrl-mtk-common.h" 
#include <token> <answer> "pinctrl-mtk-mt2712.h" 
static const struct mtk_pin_spec_pupd_set_samereg mt2712_spec_pupd[] <token> { <answer> = 
MTK_PIN_PUPD_SPEC_SR(18, <token> 2, 1, 0), <answer> 0xe50, 
MTK_PIN_PUPD_SPEC_SR(19, 0xe60, <token> 11, 10), <answer> 12, 
MTK_PIN_PUPD_SPEC_SR(20, 0xe50, <token> 4, 3), <answer> 5, 
MTK_PIN_PUPD_SPEC_SR(21, 0xe60, 15, <token> 13), <answer> 14, 
<token> 0xe50, 8, 7, 6), <answer> MTK_PIN_PUPD_SPEC_SR(22, 
MTK_PIN_PUPD_SPEC_SR(23, <token> 2, 1, 0), <answer> 0xe70, 
<token> 0xf30, 2, 1, 0), <answer> MTK_PIN_PUPD_SPEC_SR(30, 
MTK_PIN_PUPD_SPEC_SR(31, 0xf30, 6, 5, <token> <answer> 4), 
MTK_PIN_PUPD_SPEC_SR(32, 0xf30, 10, <token> 8), <answer> 9, 
MTK_PIN_PUPD_SPEC_SR(33, <token> 14, 13, 12), <answer> 0xf30, 
MTK_PIN_PUPD_SPEC_SR(34, 0xf40, 2, 1, <token> <answer> 0), 
MTK_PIN_PUPD_SPEC_SR(35, 0xf40, 6, 5, <token> <answer> 4), 
MTK_PIN_PUPD_SPEC_SR(36, 0xf40, 10, <token> 8), <answer> 9, 
MTK_PIN_PUPD_SPEC_SR(37, 0xc40, 2, <token> 0), <answer> 1, 
MTK_PIN_PUPD_SPEC_SR(38, 0xc60, 2, 1, <token> <answer> 0), 
MTK_PIN_PUPD_SPEC_SR(39, 0xc60, 2, 1, <token> <answer> 0), 
MTK_PIN_PUPD_SPEC_SR(40, <token> 2, 1, 0), <answer> 0xc60, 
MTK_PIN_PUPD_SPEC_SR(41, 0xc60, <token> 1, 0), <answer> 2, 
MTK_PIN_PUPD_SPEC_SR(42, 0xc60, 2, 1, <token> <answer> 0), 
<token> 0xc60, 2, 1, 0), <answer> MTK_PIN_PUPD_SPEC_SR(43, 
<token> 0xc60, 2, 1, 0), <answer> MTK_PIN_PUPD_SPEC_SR(44, 
MTK_PIN_PUPD_SPEC_SR(45, <token> 2, 1, 0), <answer> 0xc60, 
MTK_PIN_PUPD_SPEC_SR(46, 0xc50, 2, 1, <token> <answer> 0), 
<token> 0xda0, 2, 1, 0), <answer> MTK_PIN_PUPD_SPEC_SR(47, 
MTK_PIN_PUPD_SPEC_SR(48, <token> 2, 1, 0), <answer> 0xd90, 
MTK_PIN_PUPD_SPEC_SR(49, 0xdf0, 14, 13, <token> <answer> 12), 
<token> 0xdf0, 10, 9, 8), <answer> MTK_PIN_PUPD_SPEC_SR(50, 
MTK_PIN_PUPD_SPEC_SR(51, 0xdf0, 6, <token> 4), <answer> 5, 
<token> 0xdf0, 2, 1, 0), <answer> MTK_PIN_PUPD_SPEC_SR(52, 
MTK_PIN_PUPD_SPEC_SR(53, 0xd50, <token> 1, 0), <answer> 2, 
MTK_PIN_PUPD_SPEC_SR(54, 0xd80, 2, 1, <token> <answer> 0), 
MTK_PIN_PUPD_SPEC_SR(55, 0xe00, 2, <token> 0), <answer> 1, 
MTK_PIN_PUPD_SPEC_SR(56, 0xd40, 2, 1, <token> <answer> 0), 
MTK_PIN_PUPD_SPEC_SR(63, 0xc80, <token> 1, 0), <answer> 2, 
MTK_PIN_PUPD_SPEC_SR(64, 0xdb0, 14, 13, <token> <answer> 12), 
MTK_PIN_PUPD_SPEC_SR(65, 0xdb0, <token> 5, 4), <answer> 6, 
MTK_PIN_PUPD_SPEC_SR(66, 0xdb0, 10, 9, <token> <answer> 8), 
MTK_PIN_PUPD_SPEC_SR(67, 0xcd0, 2, <token> 0), <answer> 1, 
MTK_PIN_PUPD_SPEC_SR(68, <token> 2, 1, 0), <answer> 0xdb0, 
MTK_PIN_PUPD_SPEC_SR(69, 0xc90, <token> 1, 0), <answer> 2, 
MTK_PIN_PUPD_SPEC_SR(70, 0xcc0, <token> 1, 0), <answer> 2, 
MTK_PIN_PUPD_SPEC_SR(89, 0xce0, 2, <token> 0), <answer> 1, 
<token> 0xdd0, 14, 13, 12), <answer> MTK_PIN_PUPD_SPEC_SR(90, 
MTK_PIN_PUPD_SPEC_SR(91, <token> 10, 9, 8), <answer> 0xdd0, 
MTK_PIN_PUPD_SPEC_SR(92, <token> 6, 5, 4), <answer> 0xdd0, 
MTK_PIN_PUPD_SPEC_SR(93, <token> 2, 1, 0), <answer> 0xdd0, 
MTK_PIN_PUPD_SPEC_SR(94, 0xd20, 2, 1, <token> <answer> 0), 
MTK_PIN_PUPD_SPEC_SR(95, <token> 2, 1, 0), <answer> 0xcf0, 
<token> 0xd30, 2, 1, 0), <answer> MTK_PIN_PUPD_SPEC_SR(96, 
MTK_PIN_PUPD_SPEC_SR(135, 0xe50, 11, 10, <token> <answer> 9), 
MTK_PIN_PUPD_SPEC_SR(136, 0xe50, <token> 13, 12), <answer> 14, 
MTK_PIN_PUPD_SPEC_SR(137, 0xe70, 5, <token> 3), <answer> 4, 
MTK_PIN_PUPD_SPEC_SR(138, 0xe70, <token> 7, 6), <answer> 8, 
MTK_PIN_PUPD_SPEC_SR(139, 0xe70, <token> 10, 9), <answer> 11, 
MTK_PIN_PUPD_SPEC_SR(140, 0xe70, <token> 13, 12), <answer> 14, 
MTK_PIN_PUPD_SPEC_SR(141, 0xe60, <token> 1, 0), <answer> 2, 
MTK_PIN_PUPD_SPEC_SR(142, 0xe60, 5, <token> 3) <answer> 4, 
<token> const struct mtk_pin_ies_smt_set mt2712_smt_set[] = { <answer> static 
MTK_PIN_IES_SMT_SPEC(0, 3, 0x900, <token> <answer> 2), 
MTK_PIN_IES_SMT_SPEC(4, <token> 0x900, 0), <answer> 7, 
<token> 11, 0x900, 1), <answer> MTK_PIN_IES_SMT_SPEC(8, 
MTK_PIN_IES_SMT_SPEC(12, <token> 0x8d0, 6), <answer> 12, 
MTK_PIN_IES_SMT_SPEC(13, <token> 0x8d0, 7), <answer> 13, 
MTK_PIN_IES_SMT_SPEC(14, 14, <token> 6), <answer> 0x8d0, 
MTK_PIN_IES_SMT_SPEC(15, 15, <token> 7), <answer> 0x8d0, 
MTK_PIN_IES_SMT_SPEC(18, 23, <token> 1), <answer> 0x8d0, 
MTK_PIN_IES_SMT_SPEC(24, 25, 0x8d0, <token> <answer> 2), 
<token> 26, 0x8d0, 3), <answer> MTK_PIN_IES_SMT_SPEC(26, 
MTK_PIN_IES_SMT_SPEC(27, 27, <token> 4), <answer> 0x8d0, 
MTK_PIN_IES_SMT_SPEC(28, <token> 0x8d0, 3), <answer> 29, 
MTK_PIN_IES_SMT_SPEC(30, 36, 0xf50, <token> <answer> 13), 
MTK_PIN_IES_SMT_SPEC(37, 37, <token> 13), <answer> 0xc40, 
<token> 45, 0xc60, 13), <answer> MTK_PIN_IES_SMT_SPEC(38, 
MTK_PIN_IES_SMT_SPEC(46, 46, <token> 13), <answer> 0xc50, 
<token> 47, 0xda0, 13), <answer> MTK_PIN_IES_SMT_SPEC(47, 
MTK_PIN_IES_SMT_SPEC(48, 48, <token> 13), <answer> 0xd90, 
MTK_PIN_IES_SMT_SPEC(49, 52, <token> 13), <answer> 0xd60, 
MTK_PIN_IES_SMT_SPEC(53, 53, 0xd50, <token> <answer> 13), 
<token> 54, 0xd80, 13), <answer> MTK_PIN_IES_SMT_SPEC(54, 
<token> 55, 0xe00, 13), <answer> MTK_PIN_IES_SMT_SPEC(55, 
MTK_PIN_IES_SMT_SPEC(56, 56, <token> 13), <answer> 0xd40, 
<token> 62, 0x900, 3), <answer> MTK_PIN_IES_SMT_SPEC(57, 
<token> 63, 0xc80, 13), <answer> MTK_PIN_IES_SMT_SPEC(63, 
<token> 66, 0xca0, 13), <answer> MTK_PIN_IES_SMT_SPEC(64, 
MTK_PIN_IES_SMT_SPEC(67, 67, <token> 13), <answer> 0xc80, 
MTK_PIN_IES_SMT_SPEC(68, 68, 0xca0, <token> <answer> 13), 
MTK_PIN_IES_SMT_SPEC(69, 69, 0xc90, <token> <answer> 13), 
MTK_PIN_IES_SMT_SPEC(70, 70, <token> 13), <answer> 0xc80, 
MTK_PIN_IES_SMT_SPEC(71, <token> 0x8d0, 8), <answer> 74, 
MTK_PIN_IES_SMT_SPEC(75, 77, <token> 9), <answer> 0x8d0, 
MTK_PIN_IES_SMT_SPEC(78, 81, 0x8d0, <token> <answer> 10), 
MTK_PIN_IES_SMT_SPEC(82, <token> 0x8d0, 9), <answer> 88, 
MTK_PIN_IES_SMT_SPEC(89, 89, 0xce0, <token> <answer> 13), 
<token> 93, 0xd00, 13), <answer> MTK_PIN_IES_SMT_SPEC(90, 
<token> 94, 0xce0, 13), <answer> MTK_PIN_IES_SMT_SPEC(94, 
<token> 96, 0xcf0, 13), <answer> MTK_PIN_IES_SMT_SPEC(95, 
MTK_PIN_IES_SMT_SPEC(97, 100, 0x8d0, <token> <answer> 11), 
MTK_PIN_IES_SMT_SPEC(101, 104, 0x8d0, <token> <answer> 12), 
MTK_PIN_IES_SMT_SPEC(105, 105, <token> 13), <answer> 0x8d0, 
MTK_PIN_IES_SMT_SPEC(106, <token> 0x8d0, 14), <answer> 106, 
MTK_PIN_IES_SMT_SPEC(107, 107, <token> 15), <answer> 0x8d0, 
MTK_PIN_IES_SMT_SPEC(108, 108, 0x8e0, <token> <answer> 0), 
<token> 109, 0x8e0, 1), <answer> MTK_PIN_IES_SMT_SPEC(109, 
MTK_PIN_IES_SMT_SPEC(110, <token> 0x8e0, 2), <answer> 110, 
MTK_PIN_IES_SMT_SPEC(111, <token> 0x8d0, 13), <answer> 111, 
MTK_PIN_IES_SMT_SPEC(112, 112, 0x8d0, <token> <answer> 14), 
MTK_PIN_IES_SMT_SPEC(113, 113, 0x8d0, <token> <answer> 15), 
MTK_PIN_IES_SMT_SPEC(114, 114, 0x8e0, <token> <answer> 0), 
<token> 115, 0x8e0, 1), <answer> MTK_PIN_IES_SMT_SPEC(115, 
MTK_PIN_IES_SMT_SPEC(116, 116, <token> 2), <answer> 0x8e0, 
MTK_PIN_IES_SMT_SPEC(117, <token> 0x8e0, 3), <answer> 117, 
MTK_PIN_IES_SMT_SPEC(118, <token> 0x8e0, 4), <answer> 118, 
MTK_PIN_IES_SMT_SPEC(119, <token> 0x8e0, 5), <answer> 119, 
<token> 120, 0x8e0, 3), <answer> MTK_PIN_IES_SMT_SPEC(120, 
MTK_PIN_IES_SMT_SPEC(121, 121, 0x8e0, <token> <answer> 4), 
MTK_PIN_IES_SMT_SPEC(122, 122, 0x8e0, <token> <answer> 5), 
MTK_PIN_IES_SMT_SPEC(123, 126, 0x8e0, <token> <answer> 6), 
MTK_PIN_IES_SMT_SPEC(127, 130, <token> 7), <answer> 0x8e0, 
MTK_PIN_IES_SMT_SPEC(131, 134, <token> 8), <answer> 0x8e0, 
<token> 142, 0x8d0, 1), <answer> MTK_PIN_IES_SMT_SPEC(135, 
MTK_PIN_IES_SMT_SPEC(143, 147, 0x8e0, <token> <answer> 9), 
MTK_PIN_IES_SMT_SPEC(148, 152, <token> 10), <answer> 0x8e0, 
MTK_PIN_IES_SMT_SPEC(153, 156, <token> 11), <answer> 0x8e0, 
MTK_PIN_IES_SMT_SPEC(157, 160, <token> 12), <answer> 0x8e0, 
MTK_PIN_IES_SMT_SPEC(161, 164, 0x8e0, <token> <answer> 13), 
<token> 168, 0x8e0, 14), <answer> MTK_PIN_IES_SMT_SPEC(165, 
MTK_PIN_IES_SMT_SPEC(169, 170, 0x8e0, <token> <answer> 15), 
MTK_PIN_IES_SMT_SPEC(171, 172, 0x8f0, <token> <answer> 0), 
MTK_PIN_IES_SMT_SPEC(173, 173, 0x8f0, <token> <answer> 1), 
MTK_PIN_IES_SMT_SPEC(174, 175, <token> 2), <answer> 0x8f0, 
MTK_PIN_IES_SMT_SPEC(176, <token> 0x8f0, 1), <answer> 176, 
MTK_PIN_IES_SMT_SPEC(177, 177, <token> 3), <answer> 0x8f0, 
MTK_PIN_IES_SMT_SPEC(178, <token> 0x8f0, 4), <answer> 178, 
MTK_PIN_IES_SMT_SPEC(179, 179, <token> 3), <answer> 0x8f0, 
MTK_PIN_IES_SMT_SPEC(180, 180, <token> 4), <answer> 0x8f0, 
<token> 181, 0x8f0, 5), <answer> MTK_PIN_IES_SMT_SPEC(181, 
MTK_PIN_IES_SMT_SPEC(182, <token> 0x8f0, 6), <answer> 182, 
<token> 183, 0x8f0, 5), <answer> MTK_PIN_IES_SMT_SPEC(183, 
MTK_PIN_IES_SMT_SPEC(184, 184, 0x8f0, <token> <answer> 6), 
MTK_PIN_IES_SMT_SPEC(185, 186, <token> 7), <answer> 0x8f0, 
MTK_PIN_IES_SMT_SPEC(187, 187, <token> 8), <answer> 0x8f0, 
MTK_PIN_IES_SMT_SPEC(188, 188, <token> 9), <answer> 0x8f0, 
MTK_PIN_IES_SMT_SPEC(189, 189, <token> 8), <answer> 0x8f0, 
<token> 190, 0x8f0, 9), <answer> MTK_PIN_IES_SMT_SPEC(190, 
MTK_PIN_IES_SMT_SPEC(191, <token> 0x8f0, 10), <answer> 191, 
MTK_PIN_IES_SMT_SPEC(192, <token> 0x8f0, 11), <answer> 192, 
MTK_PIN_IES_SMT_SPEC(193, 194, 0x8f0, <token> <answer> 10), 
<token> 195, 0x8f0, 11), <answer> MTK_PIN_IES_SMT_SPEC(195, 
MTK_PIN_IES_SMT_SPEC(196, <token> 0x8f0, 12), <answer> 199, 
MTK_PIN_IES_SMT_SPEC(200, <token> 0x8f0, 13), <answer> 203, 
MTK_PIN_IES_SMT_SPEC(204, 206, 0x8f0, <token> <answer> 14), 
MTK_PIN_IES_SMT_SPEC(207, 209, 0x8f0, <token> <answer> 15) 
static const <token> mtk_pin_ies_smt_set mt2712_ies_set[] = { <answer> struct 
<token> 3, 0x8c0, 2), <answer> MTK_PIN_IES_SMT_SPEC(0, 
<token> 7, 0x8c0, 0), <answer> MTK_PIN_IES_SMT_SPEC(4, 
MTK_PIN_IES_SMT_SPEC(8, 9, <token> 1), <answer> 0x8c0, 
MTK_PIN_IES_SMT_SPEC(10, <token> 0x8c0, 4), <answer> 11, 
MTK_PIN_IES_SMT_SPEC(12, <token> 0x890, 6), <answer> 12, 
MTK_PIN_IES_SMT_SPEC(13, 13, <token> 7), <answer> 0x890, 
<token> 14, 0x890, 6), <answer> MTK_PIN_IES_SMT_SPEC(14, 
<token> 15, 0x890, 7), <answer> MTK_PIN_IES_SMT_SPEC(15, 
MTK_PIN_IES_SMT_SPEC(18, 23, <token> 1), <answer> 0x890, 
MTK_PIN_IES_SMT_SPEC(24, 25, 0x890, <token> <answer> 2), 
MTK_PIN_IES_SMT_SPEC(26, 26, <token> 3), <answer> 0x890, 
<token> 27, 0x890, 4), <answer> MTK_PIN_IES_SMT_SPEC(27, 
MTK_PIN_IES_SMT_SPEC(28, <token> 0x890, 3), <answer> 29, 
MTK_PIN_IES_SMT_SPEC(30, 36, 0xf50, <token> <answer> 14), 
MTK_PIN_IES_SMT_SPEC(37, 37, 0xc40, <token> <answer> 14), 
MTK_PIN_IES_SMT_SPEC(38, <token> 0xc60, 14), <answer> 45, 
<token> 46, 0xc50, 14), <answer> MTK_PIN_IES_SMT_SPEC(46, 
<token> 47, 0xda0, 14), <answer> MTK_PIN_IES_SMT_SPEC(47, 
MTK_PIN_IES_SMT_SPEC(48, 48, <token> 14), <answer> 0xd90, 
<token> 52, 0xd60, 14), <answer> MTK_PIN_IES_SMT_SPEC(49, 
MTK_PIN_IES_SMT_SPEC(53, <token> 0xd50, 14), <answer> 53, 
MTK_PIN_IES_SMT_SPEC(54, 54, 0xd80, <token> <answer> 14), 
<token> 55, 0xe00, 14), <answer> MTK_PIN_IES_SMT_SPEC(55, 
<token> 56, 0xd40, 14), <answer> MTK_PIN_IES_SMT_SPEC(56, 
MTK_PIN_IES_SMT_SPEC(57, <token> 0x8c0, 3), <answer> 62, 
MTK_PIN_IES_SMT_SPEC(63, <token> 0xc80, 14), <answer> 63, 
MTK_PIN_IES_SMT_SPEC(64, 66, <token> 14), <answer> 0xca0, 
<token> 68, 0xc80, 14), <answer> MTK_PIN_IES_SMT_SPEC(67, 
MTK_PIN_IES_SMT_SPEC(69, 69, <token> 14), <answer> 0xc90, 
<token> 70, 0xc80, 14), <answer> MTK_PIN_IES_SMT_SPEC(70, 
MTK_PIN_IES_SMT_SPEC(71, 74, 0x890, <token> <answer> 8), 
MTK_PIN_IES_SMT_SPEC(75, <token> 0x890, 9), <answer> 77, 
<token> 81, 0x890, 10), <answer> MTK_PIN_IES_SMT_SPEC(78, 
MTK_PIN_IES_SMT_SPEC(82, <token> 0x890, 9), <answer> 88, 
MTK_PIN_IES_SMT_SPEC(89, <token> 0xce0, 14), <answer> 89, 
<token> 93, 0xd00, 14), <answer> MTK_PIN_IES_SMT_SPEC(90, 
MTK_PIN_IES_SMT_SPEC(94, 94, 0xce0, <token> <answer> 14), 
MTK_PIN_IES_SMT_SPEC(95, 96, 0xcf0, <token> <answer> 14), 
MTK_PIN_IES_SMT_SPEC(97, 100, <token> 11), <answer> 0x890, 
MTK_PIN_IES_SMT_SPEC(101, <token> 0x890, 12), <answer> 104, 
<token> 105, 0x890, 13), <answer> MTK_PIN_IES_SMT_SPEC(105, 
MTK_PIN_IES_SMT_SPEC(106, 106, 0x890, <token> <answer> 14), 
MTK_PIN_IES_SMT_SPEC(107, <token> 0x890, 15), <answer> 107, 
MTK_PIN_IES_SMT_SPEC(108, 108, 0x8a0, <token> <answer> 0), 
MTK_PIN_IES_SMT_SPEC(109, 109, 0x8a0, <token> <answer> 1), 
MTK_PIN_IES_SMT_SPEC(110, 110, <token> 2), <answer> 0x8a0, 
MTK_PIN_IES_SMT_SPEC(111, <token> 0x890, 13), <answer> 111, 
MTK_PIN_IES_SMT_SPEC(112, 112, 0x890, <token> <answer> 14), 
MTK_PIN_IES_SMT_SPEC(113, <token> 0x890, 15), <answer> 113, 
MTK_PIN_IES_SMT_SPEC(114, 114, <token> 0), <answer> 0x8a0, 
MTK_PIN_IES_SMT_SPEC(115, 115, <token> 1), <answer> 0x8a0, 
MTK_PIN_IES_SMT_SPEC(116, 116, 0x8a0, <token> <answer> 2), 
<token> 117, 0x8a0, 3), <answer> MTK_PIN_IES_SMT_SPEC(117, 
<token> 118, 0x8a0, 4), <answer> MTK_PIN_IES_SMT_SPEC(118, 
MTK_PIN_IES_SMT_SPEC(119, <token> 0x8a0, 5), <answer> 119, 
MTK_PIN_IES_SMT_SPEC(120, 120, <token> 3), <answer> 0x8a0, 
<token> 121, 0x8a0, 4), <answer> MTK_PIN_IES_SMT_SPEC(121, 
<token> 122, 0x8a0, 5), <answer> MTK_PIN_IES_SMT_SPEC(122, 
MTK_PIN_IES_SMT_SPEC(123, 126, 0x8a0, <token> <answer> 6), 
MTK_PIN_IES_SMT_SPEC(127, 130, 0x8a0, <token> <answer> 7), 
MTK_PIN_IES_SMT_SPEC(131, 135, 0x8a0, <token> <answer> 8), 
MTK_PIN_IES_SMT_SPEC(136, 142, 0x890, <token> <answer> 1), 
MTK_PIN_IES_SMT_SPEC(143, 147, 0x8a0, <token> <answer> 9), 
MTK_PIN_IES_SMT_SPEC(148, 152, <token> 10), <answer> 0x8a0, 
MTK_PIN_IES_SMT_SPEC(153, 156, 0x8a0, <token> <answer> 11), 
MTK_PIN_IES_SMT_SPEC(157, 160, <token> 12), <answer> 0x8a0, 
MTK_PIN_IES_SMT_SPEC(161, 164, <token> 13), <answer> 0x8a0, 
MTK_PIN_IES_SMT_SPEC(165, 168, 0x8a0, <token> <answer> 14), 
MTK_PIN_IES_SMT_SPEC(169, 170, 0x8a0, <token> <answer> 15), 
<token> 172, 0x8b0, 0), <answer> MTK_PIN_IES_SMT_SPEC(171, 
MTK_PIN_IES_SMT_SPEC(173, <token> 0x8b0, 1), <answer> 173, 
MTK_PIN_IES_SMT_SPEC(174, 175, <token> 2), <answer> 0x8b0, 
<token> 176, 0x8b0, 1), <answer> MTK_PIN_IES_SMT_SPEC(176, 
<token> 177, 0x8b0, 3), <answer> MTK_PIN_IES_SMT_SPEC(177, 
MTK_PIN_IES_SMT_SPEC(178, 178, <token> 4), <answer> 0x8b0, 
MTK_PIN_IES_SMT_SPEC(179, 179, <token> 3), <answer> 0x8b0, 
MTK_PIN_IES_SMT_SPEC(180, 180, 0x8b0, <token> <answer> 4), 
MTK_PIN_IES_SMT_SPEC(181, <token> 0x8b0, 5), <answer> 181, 
MTK_PIN_IES_SMT_SPEC(182, <token> 0x8b0, 6), <answer> 182, 
MTK_PIN_IES_SMT_SPEC(183, 183, 0x8b0, <token> <answer> 5), 
MTK_PIN_IES_SMT_SPEC(184, 184, 0x8b0, <token> <answer> 6), 
MTK_PIN_IES_SMT_SPEC(185, <token> 0x8b0, 7), <answer> 186, 
MTK_PIN_IES_SMT_SPEC(187, 187, 0x8b0, <token> <answer> 8), 
<token> 188, 0x8b0, 9), <answer> MTK_PIN_IES_SMT_SPEC(188, 
MTK_PIN_IES_SMT_SPEC(189, <token> 0x8b0, 8), <answer> 189, 
MTK_PIN_IES_SMT_SPEC(190, <token> 0x8b0, 9), <answer> 190, 
MTK_PIN_IES_SMT_SPEC(191, <token> 0x8b0, 10), <answer> 191, 
MTK_PIN_IES_SMT_SPEC(192, <token> 0x8b0, 11), <answer> 192, 
MTK_PIN_IES_SMT_SPEC(193, 194, <token> 10), <answer> 0x8b0, 
MTK_PIN_IES_SMT_SPEC(195, <token> 0x8b0, 11), <answer> 195, 
MTK_PIN_IES_SMT_SPEC(196, 199, 0x8b0, <token> <answer> 12), 
MTK_PIN_IES_SMT_SPEC(200, <token> 0x8b0, 13), <answer> 203, 
MTK_PIN_IES_SMT_SPEC(204, 206, 0x8b0, <token> <answer> 14), 
MTK_PIN_IES_SMT_SPEC(207, <token> 0x8b0, 15) <answer> 209, 
static const struct mtk_drv_group_desc mt2712_drv_grp[] <token> { <answer> = 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/gpio/consumer.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/regulator/consumer.h> 
<token> <video/mipi_display.h> <answer> #include 
#include <token> <answer> <drm/drm_crtc.h> 
#include <token> <answer> <drm/drm_device.h> 
#include <token> <answer> <drm/drm_mipi_dsi.h> 
<token> <drm/drm_modes.h> <answer> #include 
<token> <drm/drm_panel.h> <answer> #include 
<token> kingdisplay_panel { <answer> struct 
struct <token> base; <answer> drm_panel 
struct <token> *link; <answer> mipi_dsi_device 
<token> regulator *supply; <answer> struct 
struct <token> *enable_gpio; <answer> gpio_desc 
<token> prepared; <answer> bool 
<token> enabled; <answer> bool 
struct <token> { <answer> kingdisplay_panel_cmd 
char <token> <answer> cmd; 
char <token> <answer> data; 
static const struct kingdisplay_panel_cmd init_code[] <token> { <answer> = 
<token> _GNU_SOURCE <answer> #define 
#include <token> <answer> <stdlib.h> 
#include <token> <answer> <stdio.h> 
<token> <string.h> <answer> #include 
<token> <sys/signal.h> <answer> #include 
<token> <sys/ucontext.h> <answer> #include 
#include <token> <answer> <err.h> 
#include <token> <answer> <setjmp.h> 
#include <token> <answer> <errno.h> 
#include <token> <answer> "helpers.h" 
static <token> sethandler(int sig, void (*handler)(int, siginfo_t *, void *), <answer> void 
int <token> <answer> flags) 
struct sigaction <token> <answer> sa; 
<token> 0, sizeof(sa)); <answer> memset(&sa, 
sa.sa_sigaction = <token> <answer> handler; 
sa.sa_flags = <token> | flags; <answer> SA_SIGINFO 
<token> (sigaction(sig, &sa, 0)) <answer> if 
<token> "sigaction"); <answer> err(1, 
<token> volatile sig_atomic_t sig_traps; <answer> static 
static sigjmp_buf <token> <answer> jmpbuf; 
<token> volatile sig_atomic_t n_errs; <answer> static 
#ifdef <token> <answer> __x86_64__ 
#define REG_AX <token> <answer> REG_RAX 
#define <token> REG_RIP <answer> REG_IP 
#define <token> REG_EAX <answer> REG_AX 
#define REG_IP <token> <answer> REG_EIP 
static void sigsegv_or_sigbus(int sig, siginfo_t *info, void <token> <answer> *ctx_void) 
<token> *ctx = (ucontext_t*)ctx_void; <answer> ucontext_t 
<token> ax = (long)ctx->uc_mcontext.gregs[REG_AX]; <answer> long 
if <token> != -EFAULT && ax != -ENOSYS) { <answer> (ax 
printf("[FAIL]\tAX had the wrong <token> 0x%lx\n", <answer> value: 
<token> long)ax); <answer> (unsigned 
<token> = 0x%lx\n", (unsigned long)ctx->uc_mcontext.gregs[REG_IP]); <answer> printf("\tIP 
} else <token> <answer> { 
printf("[OK]\tSeems <token> <answer> okay\n"); 
<token> 1); <answer> siglongjmp(jmpbuf, 
<token> volatile sig_atomic_t sigtrap_consecutive_syscalls; <answer> static 
static void sigtrap(int sig, siginfo_t *info, <token> *ctx_void) <answer> void 
ucontext_t *ctx <token> (ucontext_t*)ctx_void; <answer> = 
unsigned short *ip = (unsigned <token> *)ctx->uc_mcontext.gregs[REG_IP]; <answer> short 
if (*ip == 0x340f || <token> == 0x050f) { <answer> *ip 
sethandler(SIGBUS, <token> SA_ONSTACK); <answer> sigsegv_or_sigbus, 
<token> sigill, SA_ONSTACK); <answer> sethandler(SIGILL, 
printf("[RUN]\tSYSENTER with <token> state\n"); <answer> invalid 
if (sigsetjmp(jmpbuf, 1) == 0) <token> <answer> { 
asm <token> ( <answer> volatile 
<token> $-1, %%eax\n\t" <answer> "movl 
<token> $-1, %%ebx\n\t" <answer> "movl 
"movl $-1, <token> <answer> %%ecx\n\t" 
"movl $-1, <token> <answer> %%edx\n\t" 
<token> $-1, %%esi\n\t" <answer> "movl 
"movl <token> %%edi\n\t" <answer> $-1, 
"movl <token> %%ebp\n\t" <answer> $-1, 
"movl $-1, <token> <answer> %%esp\n\t" 
: : <token> "memory", "flags"); <answer> : 
<token> with invalid state\n"); <answer> printf("[RUN]\tSYSCALL 
if (sigsetjmp(jmpbuf, 1) == 0) <token> <answer> { 
asm volatile <token> <answer> ( 
<token> $-1, %%eax\n\t" <answer> "movl 
"movl <token> %%ebx\n\t" <answer> $-1, 
"movl $-1, <token> <answer> %%ecx\n\t" 
"movl <token> %%edx\n\t" <answer> $-1, 
<token> $-1, %%esi\n\t" <answer> "movl 
"movl <token> %%edi\n\t" <answer> $-1, 
"movl $-1, <token> <answer> %%ebp\n\t" 
"movl $-1, <token> <answer> %%esp\n\t" 
<token> <linux/errno.h> <answer> #include 
<token> <linux/etherdevice.h> <answer> #include 
#include <token> <answer> <linux/gfp.h> 
<token> <linux/hdlc.h> <answer> #include 
#include <token> <answer> <linux/if_arp.h> 
#include <token> <answer> <linux/inetdevice.h> 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/pkt_sched.h> <answer> #include 
#include <token> <answer> <linux/poll.h> 
#include <token> <answer> <linux/rtnetlink.h> 
<token> <linux/skbuff.h> <answer> #include 
static int raw_eth_ioctl(struct net_device *dev, struct if_settings <token> <answer> *ifs); 
static netdev_tx_t eth_tx(struct sk_buff *skb, struct <token> *dev) <answer> net_device 
int pad = ETH_ZLEN - <token> <answer> skb->len; 
#include <token> <answer> "amdgpu.h" 
<token> "soc15.h" <answer> #include 
#include <token> <answer> "soc15_hw_ip.h" 
<token> "vega10_ip_offset.h" <answer> #include 
#include <token> <answer> "soc15_common.h" 
<token> "vega12_inc.h" <answer> #include 
<token> "vega12_ppsmc.h" <answer> #include 
<token> "vega12_baco.h" <answer> #include 
static const struct soc15_baco_cmd_entry pre_baco_tbl[] <token> { <answer> = 
{ <token> NBIF_HWID, 0, mmBIF_DOORBELL_CNTL_BASE_IDX, mmBIF_DOORBELL_CNTL, BIF_DOORBELL_CNTL__DOORBELL_MONITOR_EN_MASK, BIF_DOORBELL_CNTL__DOORBELL_MONITOR_EN__SHIFT, 0, 0 }, <answer> CMD_READMODIFYWRITE, 
{ CMD_WRITE, NBIF_HWID, 0, mmBIF_FB_EN_BASE_IDX, mmBIF_FB_EN, 0, 0, 0, 0 <token> <answer> }, 
{ CMD_READMODIFYWRITE, NBIF_HWID, 0, mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, BACO_CNTL__BACO_DSTATE_BYPASS_MASK, BACO_CNTL__BACO_DSTATE_BYPASS__SHIFT, <token> 1 }, <answer> 0, 
{ CMD_READMODIFYWRITE, NBIF_HWID, 0, mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, BACO_CNTL__BACO_RST_INTR_MASK_MASK, BACO_CNTL__BACO_RST_INTR_MASK__SHIFT, <token> 1 } <answer> 0, 
static const struct <token> enter_baco_tbl[] = { <answer> soc15_baco_cmd_entry 
{ CMD_WAITFOR, THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, <token> THM_BACO_CNTL__SOC_DOMAIN_IDLE__SHIFT, 0xffffffff, 0x80000000 }, <answer> THM_BACO_CNTL__SOC_DOMAIN_IDLE_MASK, 
{ CMD_READMODIFYWRITE, NBIF_HWID, 0, mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, <token> BACO_CNTL__BACO_EN__SHIFT, 0, 1 }, <answer> BACO_CNTL__BACO_EN_MASK, 
{ CMD_READMODIFYWRITE, NBIF_HWID, 0, mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, BACO_CNTL__BACO_BIF_LCLK_SWITCH_MASK, BACO_CNTL__BACO_BIF_LCLK_SWITCH__SHIFT, 0, 1 <token> <answer> }, 
{ <token> NBIF_HWID, 0, mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, BACO_CNTL__BACO_DUMMY_EN_MASK, BACO_CNTL__BACO_DUMMY_EN__SHIFT, 0, 1 }, <answer> CMD_READMODIFYWRITE, 
{ CMD_READMODIFYWRITE, THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, <token> THM_BACO_CNTL__BACO_SOC_VDCI_RESET__SHIFT, 0, 1 }, <answer> THM_BACO_CNTL__BACO_SOC_VDCI_RESET_MASK, 
<token> CMD_READMODIFYWRITE, THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_SMNCLK_MUX_MASK, THM_BACO_CNTL__BACO_SMNCLK_MUX__SHIFT, 0, 1 }, <answer> { 
{ CMD_READMODIFYWRITE, THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_ISO_EN_MASK, <token> 0, 1 }, <answer> THM_BACO_CNTL__BACO_ISO_EN__SHIFT, 
{ <token> THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_AEB_ISO_EN_MASK, THM_BACO_CNTL__BACO_AEB_ISO_EN__SHIFT, 0, 1 }, <answer> CMD_READMODIFYWRITE, 
{ CMD_READMODIFYWRITE, THM_HWID, 0, <token> mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_ANA_ISO_EN_MASK, THM_BACO_CNTL__BACO_ANA_ISO_EN__SHIFT, 0, 1 }, <answer> mmTHM_BACO_CNTL_BASE_IDX, 
{ CMD_READMODIFYWRITE, THM_HWID, 0, <token> mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_SOC_REFCLK_OFF_MASK, THM_BACO_CNTL__BACO_SOC_REFCLK_OFF__SHIFT, 0, 1 }, <answer> mmTHM_BACO_CNTL_BASE_IDX, 
{ <token> NBIF_HWID, 0, mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, BACO_CNTL__BACO_POWER_OFF_MASK, BACO_CNTL__BACO_POWER_OFF__SHIFT, 0, 1 }, <answer> CMD_READMODIFYWRITE, 
{ CMD_DELAY_MS, 0, 0, <token> 5, 0 }, <answer> 0, 
{ CMD_READMODIFYWRITE, THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_RESET_EN_MASK, THM_BACO_CNTL__BACO_RESET_EN__SHIFT, 0, <token> }, <answer> 1 
{ CMD_READMODIFYWRITE, THM_HWID, 0, <token> mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_PWROKRAW_CNTL_MASK, THM_BACO_CNTL__BACO_PWROKRAW_CNTL__SHIFT, 0, 0 }, <answer> mmTHM_BACO_CNTL_BASE_IDX, 
{ CMD_WAITFOR, <token> 0, mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, BACO_CNTL__BACO_MODE_MASK, BACO_CNTL__BACO_MODE__SHIFT, 0xffffffff, 0x100 } <answer> NBIF_HWID, 
<token> const struct soc15_baco_cmd_entry exit_baco_tbl[] = { <answer> static 
{ CMD_READMODIFYWRITE, NBIF_HWID, <token> mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, BACO_CNTL__BACO_POWER_OFF_MASK, BACO_CNTL__BACO_POWER_OFF__SHIFT, 0, 0 }, <answer> 0, 
{ CMD_DELAY_MS, 0, 0, 0, 0, 0, <token> 10, 0 }, <answer> 0, 
{ CMD_READMODIFYWRITE, THM_HWID, 0, <token> mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_SOC_REFCLK_OFF_MASK, THM_BACO_CNTL__BACO_SOC_REFCLK_OFF__SHIFT, 0, 0 }, <answer> mmTHM_BACO_CNTL_BASE_IDX, 
{ CMD_READMODIFYWRITE, THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_ANA_ISO_EN_MASK, THM_BACO_CNTL__BACO_ANA_ISO_EN__SHIFT, 0, <token> }, <answer> 0 
{ <token> THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_AEB_ISO_EN_MASK, THM_BACO_CNTL__BACO_AEB_ISO_EN__SHIFT, 0, 0 }, <answer> CMD_READMODIFYWRITE, 
{ <token> THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_ISO_EN_MASK, THM_BACO_CNTL__BACO_ISO_EN__SHIFT, 0, 0 }, <answer> CMD_READMODIFYWRITE, 
{ CMD_READMODIFYWRITE, THM_HWID, <token> mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_PWROKRAW_CNTL_MASK, THM_BACO_CNTL__BACO_PWROKRAW_CNTL__SHIFT, 0, 1 }, <answer> 0, 
{ CMD_READMODIFYWRITE, <token> 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_SMNCLK_MUX_MASK, THM_BACO_CNTL__BACO_SMNCLK_MUX__SHIFT, 0, 0 }, <answer> THM_HWID, 
{ CMD_READMODIFYWRITE, THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_SOC_VDCI_RESET_MASK, THM_BACO_CNTL__BACO_SOC_VDCI_RESET__SHIFT, 0, 0 <token> <answer> }, 
{ <token> THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_EXIT_MASK, THM_BACO_CNTL__BACO_EXIT__SHIFT, 0, 1 }, <answer> CMD_READMODIFYWRITE, 
<token> CMD_READMODIFYWRITE, THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_RESET_EN_MASK, THM_BACO_CNTL__BACO_RESET_EN__SHIFT, 0, 0 }, <answer> { 
{ CMD_WAITFOR, THM_HWID, 0, mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_EXIT_MASK, 0, 0xffffffff, <token> }, <answer> 0 
{ CMD_READMODIFYWRITE, THM_HWID, <token> mmTHM_BACO_CNTL_BASE_IDX, mmTHM_BACO_CNTL, THM_BACO_CNTL__BACO_SB_AXI_FENCE_MASK, THM_BACO_CNTL__BACO_SB_AXI_FENCE__SHIFT, 0, 0 }, <answer> 0, 
<token> CMD_READMODIFYWRITE, NBIF_HWID, 0, mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, BACO_CNTL__BACO_DUMMY_EN_MASK, BACO_CNTL__BACO_DUMMY_EN__SHIFT, 0, 0 }, <answer> { 
{ CMD_READMODIFYWRITE, NBIF_HWID, 0, mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, BACO_CNTL__BACO_BIF_LCLK_SWITCH_MASK, BACO_CNTL__BACO_BIF_LCLK_SWITCH__SHIFT, 0, 0 <token> <answer> }, 
{ CMD_READMODIFYWRITE, NBIF_HWID, 0, mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, BACO_CNTL__BACO_EN_MASK, BACO_CNTL__BACO_EN__SHIFT, <token> 0 }, <answer> 0, 
{ CMD_WAITFOR, NBIF_HWID, 0, mmRCC_BACO_CNTL_MISC_BASE_IDX, mmBACO_CNTL, BACO_CNTL__BACO_MODE_MASK, 0, <token> 0 } <answer> 0xffffffff, 
static const <token> soc15_baco_cmd_entry clean_baco_tbl[] = { <answer> struct 
{ CMD_WRITE, NBIF_HWID, 0, mmBIOS_SCRATCH_6_BASE_IDX, mmBIOS_SCRATCH_6, 0, 0, <token> 0 }, <answer> 0, 
<token> CMD_WRITE, NBIF_HWID, 0, mmBIOS_SCRATCH_7_BASE_IDX, mmBIOS_SCRATCH_7, 0, 0, 0, 0 } <answer> { 
int vega12_baco_set_state(struct pp_hwmgr *hwmgr, enum BACO_STATE <token> <answer> state) 
<token> BACO_STATE cur_state; <answer> enum 
<token> &cur_state); <answer> smu9_baco_get_state(hwmgr, 
<token> (cur_state == state) <answer> if 
#include <token> <answer> <linux/init.h> 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/netdevice.h> 
<token> <net/net_namespace.h> <answer> #include 
#include <token> <answer> <net/netfilter/nf_tables.h> 
<token> <linux/netfilter_ipv4.h> <answer> #include 
#include <token> <answer> <linux/netfilter_ipv6.h> 
<token> <linux/netfilter_bridge.h> <answer> #include 
<token> <linux/netfilter_arp.h> <answer> #include 
#include <token> <answer> <net/netfilter/nf_tables_ipv4.h> 
<token> <net/netfilter/nf_tables_ipv6.h> <answer> #include 
<token> CONFIG_NF_TABLES_IPV4 <answer> #ifdef 
static unsigned <token> nft_do_chain_ipv4(void *priv, <answer> int 
<token> sk_buff *skb, <answer> struct 
<token> struct nf_hook_state *state) <answer> const 
struct <token> pkt; <answer> nft_pktinfo 
nft_set_pktinfo(&pkt, skb, <token> <answer> state); 
<token> nft_do_chain(&pkt, priv); <answer> return 
static const struct nft_chain_type <token> = { <answer> nft_chain_filter_ipv4 
.name <token> "filter", <answer> = 
.type = <token> <answer> NFT_CHAIN_T_DEFAULT, 
.family = <token> <answer> NFPROTO_IPV4, 
<token> = (1 << NF_INET_LOCAL_IN) | <answer> .hook_mask 
(1 << <token> | <answer> NF_INET_LOCAL_OUT) 
<token> << NF_INET_FORWARD) | <answer> (1 
(1 << <token> | <answer> NF_INET_PRE_ROUTING) 
(1 << <token> <answer> NF_INET_POST_ROUTING), 
.hooks = <token> <answer> { 
<token> = nft_do_chain_ipv4, <answer> [NF_INET_LOCAL_IN] 
<token> = nft_do_chain_ipv4, <answer> [NF_INET_LOCAL_OUT] 
[NF_INET_FORWARD] = <token> <answer> nft_do_chain_ipv4, 
<token> = nft_do_chain_ipv4, <answer> [NF_INET_PRE_ROUTING] 
[NF_INET_POST_ROUTING] = <token> <answer> nft_do_chain_ipv4, 
<token> void nft_chain_filter_ipv4_init(void) <answer> static 
<token> void nft_chain_filter_ipv4_fini(void) <answer> static 
static inline <token> nft_chain_filter_ipv4_init(void) {} <answer> void 
static inline <token> nft_chain_filter_ipv4_fini(void) {} <answer> void 
static int nf_tables_netdev_event(struct <token> *this, <answer> notifier_block 
unsigned long event, void <token> <answer> *ptr) 
struct net_device <token> = netdev_notifier_info_to_dev(ptr); <answer> *dev 
<token> nft_base_chain *basechain; <answer> struct 
<token> nftables_pernet *nft_net; <answer> struct 
struct nft_chain <token> *nr; <answer> *chain, 
struct nft_table <token> <answer> *table; 
struct nft_ctx ctx = <token> <answer> { 
.net <token> dev_net(dev), <answer> = 
if <token> != NETDEV_UNREGISTER && <answer> (event 
event <token> NETDEV_CHANGENAME) <answer> != 
<token> NOTIFY_DONE; <answer> return 
nft_net = <token> <answer> nft_pernet(ctx.net); 
<token> &nft_net->tables, list) { <answer> list_for_each_entry(table, 
if (table->family != NFPROTO_NETDEV <token> <answer> && 
<token> != NFPROTO_INET) <answer> table->family 
<token> = table->family; <answer> ctx.family 
<token> = table; <answer> ctx.table 
<token> nr, &table->chains, list) { <answer> list_for_each_entry_safe(chain, 
<token> (!nft_is_base_chain(chain)) <answer> if 
basechain = <token> <answer> nft_base_chain(chain); 
if (table->family == <token> && <answer> NFPROTO_INET 
basechain->ops.hooknum <token> NF_INET_INGRESS) <answer> != 
<token> = chain; <answer> ctx.chain 
nft_netdev_event(event, <token> &ctx); <answer> dev, 
return <token> <answer> NOTIFY_DONE; 
static struct notifier_block <token> = { <answer> nf_tables_netdev_notifier 
.notifier_call <token> nf_tables_netdev_event, <answer> = 
static <token> nft_chain_filter_netdev_init(void) <answer> int 
<token> err; <answer> int 
err = <token> <answer> register_netdevice_notifier(&nf_tables_netdev_notifier); 
<token> (err) <answer> if 
goto <token> <answer> err_register_netdevice_notifier; 
<token> 0; <answer> return 
<token> err; <answer> return 
<token> void nft_chain_filter_netdev_fini(void) <answer> static 
static inline <token> nft_chain_filter_netdev_init(void) { return 0; } <answer> int 
<token> inline void nft_chain_filter_netdev_fini(void) {} <answer> static 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/mfd/syscon.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_platform.h> 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> "mtu3.h" 
#include <token> <answer> "mtu3_dr.h" 
<token> void ssusb_wakeup_ip_sleep_set(struct ssusb_mtk *ssusb, bool enable) <answer> static 
u32 reg, msk, <token> <answer> val; 
switch <token> { <answer> (ssusb->uwk_vers) 
case <token> <answer> SSUSB_UWK_V1: 
<token> = ssusb->uwk_reg_base + PERI_WK_CTRL1; <answer> reg 
msk = WC1_IS_EN <token> WC1_IS_C(0xf) | WC1_IS_P; <answer> | 
val = <token> ? (WC1_IS_EN | WC1_IS_C(0x8)) : 0; <answer> enable 
<token> SSUSB_UWK_V1_1: <answer> case 
reg = <token> + PERI_WK_CTRL0; <answer> ssusb->uwk_reg_base 
<token> = WC0_IS_EN | WC0_IS_C(0xf) | WC0_IS_P; <answer> msk 
val = enable ? (WC0_IS_EN <token> WC0_IS_C(0x1)) : 0; <answer> | 
<token> SSUSB_UWK_V1_2: <answer> case 
reg <token> ssusb->uwk_reg_base + PERI_WK_CTRL0; <answer> = 
msk = WC0_SSUSB0_CDEN <token> WC0_IS_SPM_EN; <answer> | 
val <token> enable ? msk : 0; <answer> = 
case <token> <answer> SSUSB_UWK_V1_3: 
reg = <token> + PERI_WK_CTRL1_8195; <answer> ssusb->uwk_reg_base 
msk = WC1_IS_EN_P0_95 | WC1_IS_C_95(0xf) <token> WC1_IS_P_95; <answer> | 
val = enable <token> (WC1_IS_EN_P0_95 | WC1_IS_C_95(0x1)) : 0; <answer> ? 
<token> SSUSB_UWK_V1_5: <answer> case 
reg = ssusb->uwk_reg_base <token> PERI_WK_CTRL0_8195; <answer> + 
msk = WC0_IS_EN_P2_95 | WC0_IS_C_95(0x7) <token> WC0_IS_P_95; <answer> | 
<token> = enable ? (WC0_IS_EN_P2_95 | WC0_IS_C_95(0x1)) : 0; <answer> val 
case <token> <answer> SSUSB_UWK_V1_6: 
reg <token> ssusb->uwk_reg_base + PERI_WK_CTRL0_8195; <answer> = 
msk = <token> | WC0_IS_C_95(0x7) | WC0_IS_P_95; <answer> WC0_IS_EN_P3_95 
val = enable ? (WC0_IS_EN_P3_95 | WC0_IS_C_95(0x1)) <token> 0; <answer> : 
<token> SSUSB_UWK_V2: <answer> case 
reg <token> ssusb->uwk_reg_base + PERI_SSUSB_SPM_CTRL; <answer> = 
msk = SSC_IP_SLEEP_EN <token> SSC_SPM_INT_EN; <answer> | 
val <token> enable ? msk : 0; <answer> = 
regmap_update_bits(ssusb->uwk, reg, <token> val); <answer> msk, 
int ssusb_wakeup_of_property_parse(struct ssusb_mtk <token> <answer> *ssusb, 
struct device_node <token> <answer> *dn) 
<token> of_phandle_args args; <answer> struct 
int <token> <answer> ret; 
<token> MTU3_DR_FORCE_HOST); <answer> ssusb_set_force_mode(ssusb, 
int ssusb_host_init(struct ssusb_mtk *ssusb, struct <token> *parent_dn) <answer> device_node 
struct device *parent_dev <token> ssusb->dev; <answer> = 
<token> ret; <answer> int 
ret = of_platform_populate(parent_dn, <token> NULL, parent_dev); <answer> NULL, 
if <token> { <answer> (ret) 
dev_dbg(parent_dev, "failed to create child devices at <token> <answer> %pOF\n", 
return <token> <answer> ret; 
dev_info(parent_dev, "xHCI platform device <token> success...\n"); <answer> register 
return <token> <answer> 0; 
void ssusb_host_exit(struct <token> *ssusb) <answer> ssusb_mtk 
#include <token> <answer> <linux/ring_buffer.h> 
<token> <linux/utsname.h> <answer> #include 
<token> <linux/stacktrace.h> <answer> #include 
#include <token> <answer> <linux/writeback.h> 
#include <token> <answer> <linux/kallsyms.h> 
#include <token> <answer> <linux/security.h> 
<token> <linux/seq_file.h> <answer> #include 
<token> <linux/irqflags.h> <answer> #include 
#include <token> <answer> <linux/debugfs.h> 
<token> <linux/tracefs.h> <answer> #include 
#include <token> <answer> <linux/pagemap.h> 
<token> <linux/hardirq.h> <answer> #include 
#include <token> <answer> <linux/linkage.h> 
<token> <linux/uaccess.h> <answer> #include 
<token> <linux/vmalloc.h> <answer> #include 
#include <token> <answer> <linux/ftrace.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/percpu.h> <answer> #include 
#include <token> <answer> <linux/splice.h> 
#include <token> <answer> <linux/kdebug.h> 
<token> <linux/string.h> <answer> #include 
#include <token> <answer> <linux/mount.h> 
#include <token> <answer> <linux/rwsem.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/ctype.h> 
<token> <linux/init.h> <answer> #include 
<token> <linux/panic_notifier.h> <answer> #include 
<token> <linux/poll.h> <answer> #include 
<token> <linux/nmi.h> <answer> #include 
#include <token> <answer> <linux/fs.h> 
#include <token> <answer> <linux/trace.h> 
<token> <linux/sched/clock.h> <answer> #include 
#include <token> <answer> <linux/sched/rt.h> 
#include <token> <answer> <linux/fsnotify.h> 
#include <token> <answer> <linux/irq_work.h> 
<token> <linux/workqueue.h> <answer> #include 
<token> bool __read_mostly tracing_selftest_running; <answer> static 
bool <token> tracing_selftest_disabled; <answer> __read_mostly 
void __init disable_tracing_selftest(const char <token> <answer> *reason) 
<token> (!tracing_selftest_disabled) { <answer> if 
tracing_selftest_disabled = <token> <answer> true; 
pr_info("Ftrace startup test is disabled due to <token> reason); <answer> %s\n", 
#define tracing_selftest_running <token> <answer> 0 
<token> tracing_selftest_disabled 0 <answer> #define 
<token> trace_taskinfo_save); <answer> DEFINE_PER_CPU(bool, 
static <token> tracing_disabled = 1; <answer> int 
cpumask_var_t __read_mostly <token> <answer> tracing_buffer_mask; 
union trace_eval_map_item <token> <answer> *next; 
<token> trace_eval_map_item { <answer> union 
struct trace_eval_map <token> <answer> map; 
struct <token> head; <answer> trace_eval_map_head 
struct <token> tail; <answer> trace_eval_map_tail 
static union <token> *trace_eval_maps; <answer> trace_eval_map_item 
rcu_assign_pointer(*list, <token> <answer> export); 
static <token> int <answer> inline 
rm_trace_export(struct <token> **list, struct trace_export *export) <answer> trace_export 
struct <token> **p; <answer> trace_export 
for <token> = list; *p != NULL; p = &(*p)->next) <answer> (p 
if (*p == <token> <answer> export) 
<token> (*p != export) <answer> if 
<token> -1; <answer> return 
rcu_assign_pointer(*p, <token> <answer> (*p)->next); 
<token> 0; <answer> return 
<token> inline void <answer> static 
add_ftrace_export(struct <token> **list, struct trace_export *export) <answer> trace_export 
<token> export); <answer> add_trace_export(list, 
<token> inline int <answer> static 
rm_ftrace_export(struct trace_export **list, <token> trace_export *export) <answer> struct 
int <token> <answer> ret; 
ret = <token> export); <answer> rm_trace_export(list, 
<token> ret; <answer> return 
<token> register_ftrace_export(struct trace_export *export) <answer> int 
<token> (WARN_ON_ONCE(!export->write)) <answer> if 
return <token> <answer> -1; 
<token> export); <answer> add_ftrace_export(&ftrace_exports_list, 
<token> 0; <answer> return 
int unregister_ftrace_export(struct <token> *export) <answer> trace_export 
int <token> <answer> ret; 
ret = rm_ftrace_export(&ftrace_exports_list, <token> <answer> export); 
return <token> <answer> ret; 
static <token> trace_array global_trace = { <answer> struct 
.trace_flags = <token> <answer> TRACE_DEFAULT_FLAGS, 
<token> trace_set_ring_buffer_expanded(struct trace_array *tr) <answer> void 
<token> (!tr) <answer> if 
tr = <token> <answer> &global_trace; 
tr->ring_buffer_expanded <token> true; <answer> = 
int <token> trace_array *this_tr) <answer> trace_array_get(struct 
<token> trace_array *tr; <answer> struct 
int ret <token> -ENODEV; <answer> = 
list_for_each_entry(tr, <token> list) { <answer> &ftrace_trace_arrays, 
if <token> == this_tr) { <answer> (tr 
ret <token> 0; <answer> = 
return <token> <answer> ret; 
<token> void __trace_array_put(struct trace_array *this_tr) <answer> static 
void <token> trace_array *this_tr) <answer> trace_array_put(struct 
if <token> <answer> (!this_tr) 
int <token> trace_array *tr) <answer> tracing_check_open_get_tr(struct 
<token> ret; <answer> int 
<token> = security_locked_down(LOCKDOWN_TRACEFS); <answer> ret 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> (tracing_disabled) <answer> if 
<token> -ENODEV; <answer> return 
if (tr && trace_array_get(tr) <token> 0) <answer> < 
<token> -ENODEV; <answer> return 
return <token> <answer> 0; 
int call_filter_check_discard(struct trace_event_call <token> void *rec, <answer> *call, 
struct trace_buffer <token> <answer> *buffer, 
struct ring_buffer_event <token> <answer> *event) 
if (unlikely(call->flags & TRACE_EVENT_FL_FILTERED) <token> <answer> && 
<token> rec)) { <answer> !filter_match_preds(call->filter, 
<token> event); <answer> __trace_event_discard_commit(buffer, 
<token> 1; <answer> return 
return <token> <answer> 0; 
trace_find_filtered_pid(struct trace_pid_list *filtered_pids, <token> search_pid) <answer> pid_t 
return trace_pid_list_is_set(filtered_pids, <token> <answer> search_pid); 
trace_ignore_this_task(struct <token> *filtered_pids, <answer> trace_pid_list 
struct <token> *filtered_no_pids, <answer> trace_pid_list 
struct task_struct <token> <answer> *task) 
return <token> && <answer> (filtered_pids 
!trace_find_filtered_pid(filtered_pids, <token> || <answer> task->pid)) 
<token> && <answer> (filtered_no_pids 
trace_find_filtered_pid(filtered_no_pids, <token> <answer> task->pid)); 
<token> trace_filter_add_remove_task(struct trace_pid_list *pid_list, <answer> void 
struct <token> *self, <answer> task_struct 
struct task_struct <token> <answer> *task) 
if <token> <answer> (!pid_list) 
void *trace_pid_next(struct trace_pid_list *pid_list, <token> *v, loff_t *pos) <answer> void 
<token> pid = (unsigned long)v; <answer> long 
unsigned int <token> <answer> next; 
<token> *trace_pid_start(struct trace_pid_list *pid_list, loff_t *pos) <answer> void 
unsigned <token> pid; <answer> long 
unsigned int <token> <answer> first; 
<token> l = 0; <answer> loff_t 
if (trace_pid_list_first(pid_list, &first) <token> 0) <answer> < 
return <token> <answer> NULL; 
pid <token> first; <answer> = 
int trace_pid_show(struct seq_file *m, void <token> <answer> *v) 
unsigned long pid = (unsigned long)v <token> 1; <answer> - 
seq_printf(m, "%lu\n", <token> <answer> pid); 
return <token> <answer> 0; 
<token> = trace_pid_list_alloc(); <answer> pid_list 
<token> (!pid_list) { <answer> if 
<token> -ENOMEM; <answer> return 
if <token> { <answer> (filtered_pids) 
<token> tracing_is_enabled(void) <answer> int 
return <token> <answer> !global_trace.buffer_disabled; 
#ifdef <token> <answer> CONFIG_SMP 
<token> DECLARE_RWSEM(all_cpu_access_lock); <answer> static 
static DEFINE_PER_CPU(struct mutex, <token> <answer> cpu_access_lock); 
static <token> void trace_access_lock(int cpu) <answer> inline 
if (cpu == RING_BUFFER_ALL_CPUS) <token> <answer> { 
<token> = 0; <answer> tr->buffer_disabled 
void <token> <answer> tracing_on(void) 
<token> __always_inline void <answer> static 
<token> trace_buffer *buffer, struct ring_buffer_event *event) <answer> __buffer_unlock_commit(struct 
__this_cpu_write(trace_taskinfo_save, <token> <answer> true); 
int __trace_puts(unsigned long ip, <token> char *str, int size) <answer> const 
return __trace_array_puts(&global_trace, ip, <token> size); <answer> str, 
int <token> long ip, const char *str) <answer> __trace_bputs(unsigned 
struct <token> *event; <answer> ring_buffer_event 
<token> trace_buffer *buffer; <answer> struct 
struct <token> *entry; <answer> bputs_entry 
<token> int trace_ctx; <answer> unsigned 
int size = sizeof(struct <token> <answer> bputs_entry); 
int ret <token> 0; <answer> = 
if <token> & TRACE_ITER_PRINTK)) <answer> (!(global_trace.trace_flags 
return <token> <answer> 0; 
if <token> || tracing_disabled)) <answer> (unlikely(tracing_selftest_running 
<token> 0; <answer> return 
trace_ctx <token> tracing_gen_ctx(); <answer> = 
buffer <token> global_trace.array_buffer.buffer; <answer> = 
event = __trace_buffer_lock_reserve(buffer, <token> size, <answer> TRACE_BPUTS, 
<token> (!event) <answer> if 
<token> out; <answer> goto 
entry = <token> <answer> ring_buffer_event_data(event); 
entry->ip <token> ip; <answer> = 
entry->str <token> str; <answer> = 
__buffer_unlock_commit(buffer, <token> <answer> event); 
ftrace_trace_stack(&global_trace, <token> trace_ctx, 4, NULL); <answer> buffer, 
ret = <token> <answer> 1; 
return <token> <answer> ret; 
#ifdef <token> <answer> CONFIG_TRACER_SNAPSHOT 
static <token> tracing_snapshot_instance_cond(struct trace_array *tr, <answer> void 
<token> *cond_data) <answer> void 
struct tracer *tracer = <token> <answer> tr->current_trace; 
unsigned long <token> <answer> flags; 
<token> (in_nmi()) { <answer> if 
trace_array_puts(tr, "*** SNAPSHOT <token> FROM NMI CONTEXT ***\n"); <answer> CALLED 
<token> "*** snapshot is being ignored ***\n"); <answer> trace_array_puts(tr, 
if (!tr->allocated_snapshot) <token> <answer> { 
trace_array_puts(tr, "*** SNAPSHOT NOT ALLOCATED <token> <answer> ***\n"); 
trace_array_puts(tr, "*** stopping trace <token> ***\n"); <answer> here! 
<token> tracing_snapshot(void) <answer> void 
<token> trace_array *tr = &global_trace; <answer> struct 
void tracing_snapshot_cond(struct trace_array <token> void *cond_data) <answer> *tr, 
tracing_snapshot_instance_cond(tr, <token> <answer> cond_data); 
void *tracing_cond_snapshot_data(struct trace_array <token> <answer> *tr) 
void *cond_data = <token> <answer> NULL; 
<token> (tr->cond_snapshot) <answer> if 
cond_data = <token> <answer> tr->cond_snapshot->cond_data; 
return <token> <answer> cond_data; 
static int resize_buffer_duplicate_size(struct array_buffer <token> <answer> *trace_buf, 
<token> array_buffer *size_buf, int cpu_id); <answer> struct 
static <token> set_buffer_entries(struct array_buffer *buf, unsigned long val); <answer> void 
int tracing_alloc_snapshot_instance(struct <token> *tr) <answer> trace_array 
<token> order; <answer> int 
<token> ret; <answer> int 
<token> (!tr->allocated_snapshot) { <answer> if 
ring_buffer_subbuf_order_set(tr->max_buffer.buffer, <token> <answer> 0); 
ring_buffer_resize(tr->max_buffer.buffer, <token> RING_BUFFER_ALL_CPUS); <answer> 1, 
set_buffer_entries(&tr->max_buffer, <token> <answer> 1); 
tr->allocated_snapshot <token> false; <answer> = 
static <token> tracing_arm_snapshot_locked(struct trace_array *tr) <answer> int 
int <token> <answer> ret; 
if (tr->snapshot == <token> { <answer> UINT_MAX) 
return <token> <answer> -EBUSY; 
ret = <token> <answer> tracing_alloc_snapshot_instance(tr); 
<token> (ret) { <answer> if 
return <token> <answer> ret; 
int tracing_arm_snapshot(struct <token> *tr) <answer> trace_array 
int <token> <answer> ret; 
ret <token> tracing_arm_snapshot_locked(tr); <answer> = 
<token> ret; <answer> return 
void tracing_disarm_snapshot(struct trace_array <token> <answer> *tr) 
if <token> <answer> (!WARN_ON(!tr->snapshot)) 
int <token> <answer> tracing_alloc_snapshot(void) 
<token> trace_array *tr = &global_trace; <answer> struct 
<token> ret; <answer> int 
ret = <token> <answer> tracing_alloc_snapshot_instance(tr); 
<token> < 0); <answer> WARN_ON(ret 
<token> ret; <answer> return 
void <token> <answer> tracing_snapshot_alloc(void) 
<token> ret; <answer> int 
ret = <token> <answer> tracing_alloc_snapshot(); 
if <token> < 0) <answer> (ret 
<token> tracing_snapshot_cond_enable(struct trace_array *tr, void *cond_data, <answer> int 
cond_update_fn_t <token> <answer> update) 
<token> cond_snapshot *cond_snapshot; <answer> struct 
<token> ret = 0; <answer> int 
<token> = kzalloc(sizeof(*cond_snapshot), GFP_KERNEL); <answer> cond_snapshot 
<token> (!cond_snapshot) <answer> if 
return <token> <answer> -ENOMEM; 
cond_snapshot->cond_data <token> cond_data; <answer> = 
cond_snapshot->update = <token> <answer> update; 
<token> (tr->current_trace->use_max_tr) { <answer> if 
ret = <token> <answer> -EBUSY; 
<token> fail_unlock; <answer> goto 
<token> (tr->cond_snapshot) { <answer> if 
<token> = -EBUSY; <answer> ret 
goto <token> <answer> fail_unlock; 
<token> = tracing_arm_snapshot_locked(tr); <answer> ret 
if <token> <answer> (ret) 
goto <token> <answer> fail_unlock; 
tr->cond_snapshot = <token> <answer> cond_snapshot; 
<token> ret; <answer> return 
return <token> <answer> ret; 
int <token> trace_array *tr) <answer> tracing_snapshot_cond_disable(struct 
int ret = <token> <answer> 0; 
if <token> <answer> (!tr->cond_snapshot) 
ret = <token> <answer> -EINVAL; 
<token> { <answer> else 
<token> = NULL; <answer> tr->cond_snapshot 
<token> ret; <answer> return 
void <token> <answer> tracing_snapshot(void) 
WARN_ONCE(1, "Snapshot <token> not enabled, but internal snapshot used"); <answer> feature 
void tracing_snapshot_cond(struct <token> *tr, void *cond_data) <answer> trace_array 
<token> "Snapshot feature not enabled, but internal conditional snapshot used"); <answer> WARN_ONCE(1, 
<token> tracing_alloc_snapshot(void) <answer> int 
WARN_ONCE(1, "Snapshot feature not enabled, <token> snapshot allocation used"); <answer> but 
return <token> <answer> -ENODEV; 
void <token> <answer> tracing_snapshot_alloc(void) 
tr->buffer_disabled = <token> <answer> 1; 
<token> tracing_off(void) <answer> void 
<token> disable_trace_on_warning(void) <answer> void 
if (__disable_trace_on_warning) <token> <answer> { 
trace_array_printk_buf(global_trace.array_buffer.buffer, <token> <answer> _THIS_IP_, 
"Disabling <token> due to warning\n"); <answer> tracing 
<token> tracer_tracing_is_on(struct trace_array *tr) <answer> bool 
if <token> <answer> (tr->array_buffer.buffer) 
return <token> <answer> ring_buffer_record_is_set_on(tr->array_buffer.buffer); 
return <token> <answer> !tr->buffer_disabled; 
<token> tracing_is_on(void) <answer> int 
return <token> <answer> tracer_tracing_is_on(&global_trace); 
<token> int __init set_buf_size(char *str) <answer> static 
unsigned long <token> <answer> buf_size; 
if <token> <answer> (!str) 
return <token> <answer> 0; 
buf_size = <token> &str); <answer> memparse(str, 
<token> = max(4096UL, buf_size); <answer> trace_buf_size 
return <token> <answer> 1; 
<token> set_buf_size); <answer> __setup("trace_buf_size=", 
<token> int __init set_tracing_thresh(char *str) <answer> static 
unsigned <token> threshold; <answer> long 
<token> ret; <answer> int 
<token> (!str) <answer> if 
return <token> <answer> 0; 
ret = kstrtoul(str, <token> &threshold); <answer> 0, 
if (ret < <token> <answer> 0) 
<token> 0; <answer> return 
tracing_thresh = <token> * 1000; <answer> threshold 
return <token> <answer> 1; 
__setup("tracing_thresh=", <token> <answer> set_tracing_thresh); 
unsigned long nsecs_to_usecs(unsigned <token> nsecs) <answer> long 
return nsecs / <token> <answer> 1000; 
#undef <token> <answer> C 
#define C(a, <token> b <answer> b) 
int trace_parser_get_init(struct trace_parser *parser, int <token> <answer> size) 
memset(parser, 0, <token> <answer> sizeof(*parser)); 
parser->buffer <token> kmalloc(size, GFP_KERNEL); <answer> = 
if <token> <answer> (!parser->buffer) 
return <token> <answer> 1; 
parser->size <token> size; <answer> = 
<token> 0; <answer> return 
void trace_parser_put(struct trace_parser <token> <answer> *parser) 
<token> = NULL; <answer> parser->buffer 
<token> trace_get_user(struct trace_parser *parser, const char __user *ubuf, <answer> int 
<token> cnt, loff_t *ppos) <answer> size_t 
<token> ch; <answer> char 
size_t read <token> 0; <answer> = 
<token> ret; <answer> ssize_t 
<token> (!*ppos) <answer> if 
<token> = get_user(ch, ubuf++); <answer> ret 
<token> (ret) <answer> if 
goto <token> <answer> out; 
<token> (!parser->cont) { <answer> if 
<token> void <answer> static 
__update_max_tr(struct trace_array *tr, struct <token> *tsk, int cpu) <answer> task_struct 
struct <token> *trace_buf = &tr->array_buffer; <answer> array_buffer 
struct <token> *max_buf = &tr->max_buffer; <answer> array_buffer 
struct trace_array_cpu <token> = per_cpu_ptr(trace_buf->data, cpu); <answer> *data 
struct trace_array_cpu *max_data = <token> cpu); <answer> per_cpu_ptr(max_buf->data, 
max_buf->cpu <token> cpu; <answer> = 
max_buf->time_start <token> data->preempt_timestamp; <answer> = 
max_data->saved_latency = <token> <answer> tr->max_latency; 
max_data->critical_start <token> data->critical_start; <answer> = 
max_data->critical_end <token> data->critical_end; <answer> = 
strncpy(max_data->comm, <token> TASK_COMM_LEN); <answer> tsk->comm, 
max_data->pid <token> tsk->pid; <answer> = 
if (tsk == <token> <answer> current) 
<token> = current_uid(); <answer> max_data->uid 
max_data->uid <token> task_uid(tsk); <answer> = 
max_data->nice = tsk->static_prio <token> 20 - MAX_RT_PRIO; <answer> - 
max_data->policy <token> tsk->policy; <answer> = 
max_data->rt_priority = <token> <answer> tsk->rt_priority; 
<token> trace_array *tr, struct task_struct *tsk, int cpu, <answer> update_max_tr(struct 
void <token> <answer> *cond_data) 
<token> (tr->stop_count) <answer> if 
<token> (!tr->allocated_snapshot) { <answer> if 
update_max_tr_single(struct trace_array *tr, struct task_struct *tsk, <token> cpu) <answer> int 
int <token> <answer> ret; 
<token> (tr->stop_count) <answer> if 
if (!tr->allocated_snapshot) <token> <answer> { 
<token> _THIS_IP_, <answer> trace_array_printk_buf(tr->max_buffer.buffer, 
"Failed to swap buffers due to commit or resize <token> progress\n"); <answer> in 
WARN_ON_ONCE(ret && ret != -EAGAIN <token> ret != -EBUSY); <answer> && 
__update_max_tr(tr, <token> cpu); <answer> tsk, 
if <token> <answer> (iter->snapshot) 
<token> = &iter->tr->max_buffer; <answer> iter->array_buffer 
return <token> <answer> ret; 
#ifdef <token> <answer> CONFIG_FTRACE_STARTUP_TEST 
static bool <token> <answer> selftests_can_run; 
struct trace_selftests <token> <answer> { 
struct <token> list; <answer> list_head 
<token> tracer *type; <answer> struct 
<token> LIST_HEAD(postponed_selftests); <answer> static 
static int save_selftest(struct <token> *type) <answer> tracer 
struct trace_selftests <token> <answer> *selftest; 
selftest = kmalloc(sizeof(*selftest), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!selftest) 
<token> -ENOMEM; <answer> return 
selftest->type <token> type; <answer> = 
list_add(&selftest->list, <token> <answer> &postponed_selftests); 
return <token> <answer> 0; 
static <token> run_tracer_selftest(struct tracer *type) <answer> int 
<token> trace_array *tr = &global_trace; <answer> struct 
<token> tracer *saved_tracer = tr->current_trace; <answer> struct 
int <token> <answer> ret; 
if <token> || tracing_selftest_disabled) <answer> (!type->selftest 
return <token> <answer> 0; 
<token> (!selftests_can_run) <answer> if 
return <token> <answer> save_selftest(type); 
<token> (!tracing_is_on()) { <answer> if 
pr_warn("Selftest for tracer %s skipped due to tracing <token> <answer> disabled\n", 
return <token> <answer> 0; 
tr->current_trace <token> type; <answer> = 
#ifdef <token> <answer> CONFIG_TRACER_MAX_TRACE 
if (type->use_max_tr) <token> <answer> { 
<token> = true; <answer> tracing_selftest_running 
<token> = run_tracer_selftest(type); <answer> ret 
tracing_selftest_running <token> false; <answer> = 
<token> ret; <answer> return 
<token> __init int init_trace_selftests(void) <answer> static 
struct trace_selftests <token> *n; <answer> *p, 
struct tracer *t, <token> <answer> **last; 
int <token> <answer> ret; 
selftests_can_run <token> true; <answer> = 
if <token> <answer> (list_empty(&postponed_selftests)) 
<token> out; <answer> goto 
pr_info("Running postponed <token> tests:\n"); <answer> tracer 
tracing_selftest_running <token> true; <answer> = 
list_for_each_entry_safe(p, n, &postponed_selftests, <token> { <answer> list) 
ret = <token> <answer> run_tracer_selftest(p->type); 
int __init <token> tracer *type) <answer> register_tracer(struct 
struct <token> *t; <answer> tracer 
int <token> = 0; <answer> ret 
if <token> { <answer> (!type->name) 
pr_info("Tracer must <token> a name\n"); <answer> have 
<token> -1; <answer> return 
<token> (strlen(type->name) >= MAX_TRACER_SIZE) { <answer> if 
pr_info("Tracer <token> a name longer than %d\n", MAX_TRACER_SIZE); <answer> has 
<token> -1; <answer> return 
<token> (security_locked_down(LOCKDOWN_TRACEFS)) { <answer> if 
pr_warn("Can not register tracer %s due <token> lockdown\n", <answer> to 
<token> -EPERM; <answer> return 
for (t = trace_types; t; t = t->next) <token> <answer> { 
if (strcmp(type->name, t->name) == 0) <token> <answer> { 
<token> tracing_start(void) <answer> void 
<token> tracing_start_tr(&global_trace); <answer> return 
static void tracing_stop_tr(struct trace_array <token> <answer> *tr) 
struct trace_buffer <token> <answer> *buffer; 
unsigned long <token> <answer> flags; 
raw_spin_lock_irqsave(&tr->start_lock, <token> <answer> flags); 
if <token> <answer> (tr->stop_count++) 
goto <token> <answer> out; 
void <token> <answer> tracing_stop(void) 
return <token> <answer> tracing_stop_tr(&global_trace); 
enum print_line_t <token> trace_seq *s) <answer> trace_handle_return(struct 
<token> trace_seq_has_overflowed(s) ? <answer> return 
TRACE_TYPE_PARTIAL_LINE <token> TRACE_TYPE_HANDLED; <answer> : 
static unsigned short <token> <answer> migration_disable_value(void) 
<token> defined(CONFIG_SMP) <answer> #if 
<token> current->migration_disabled; <answer> return 
<token> 0; <answer> return 
unsigned <token> tracing_gen_ctx_irq_test(unsigned int irqs_status) <answer> int 
<token> int trace_flags = irqs_status; <answer> unsigned 
unsigned int <token> <answer> pc; 
pc <token> preempt_count(); <answer> = 
<token> (pc & NMI_MASK) <answer> if 
trace_flags <token> TRACE_FLAG_NMI; <answer> |= 
if (pc & <token> <answer> HARDIRQ_MASK) 
<token> |= TRACE_FLAG_HARDIRQ; <answer> trace_flags 
if <token> <answer> (in_serving_softirq()) 
trace_flags |= <token> <answer> TRACE_FLAG_SOFTIRQ; 
if <token> >> (SOFTIRQ_SHIFT + 1)) <answer> (softirq_count() 
<token> |= TRACE_FLAG_BH_OFF; <answer> trace_flags 
if <token> <answer> (tif_need_resched()) 
trace_flags <token> TRACE_FLAG_NEED_RESCHED; <answer> |= 
if <token> <answer> (test_preempt_need_resched()) 
trace_flags <token> TRACE_FLAG_PREEMPT_RESCHED; <answer> |= 
return (trace_flags << 16) <token> (min_t(unsigned int, pc & 0xff, 0xf)) | <answer> | 
(min_t(unsigned int, migration_disable_value(), <token> << 4; <answer> 0xf)) 
<token> ring_buffer_event * <answer> struct 
trace_buffer_lock_reserve(struct <token> *buffer, <answer> trace_buffer 
<token> type, <answer> int 
unsigned long <token> <answer> len, 
unsigned int <token> <answer> trace_ctx) 
<token> __trace_buffer_lock_reserve(buffer, type, len, trace_ctx); <answer> return 
<token> ring_buffer_event *, trace_buffered_event); <answer> DEFINE_PER_CPU(struct 
<token> trace_buffered_event_cnt); <answer> DEFINE_PER_CPU(int, 
<token> int trace_buffered_event_ref; <answer> static 
<token> trace_buffered_event_enable(void) <answer> void 
<token> ring_buffer_event *event; <answer> struct 
struct <token> *page; <answer> page 
<token> cpu; <answer> int 
if <token> <answer> (trace_buffered_event_ref++) 
<token> { <answer> for_each_tracing_cpu(cpu) 
page = <token> <answer> alloc_pages_node(cpu_to_node(cpu), 
GFP_KERNEL | <token> 0); <answer> __GFP_NORETRY, 
void <token> <answer> trace_buffered_event_disable(void) 
<token> cpu; <answer> int 
<token> (WARN_ON_ONCE(!trace_buffered_event_ref)) <answer> if 
<token> (--trace_buffered_event_ref) <answer> if 
if ((entry = <token> { <answer> __this_cpu_read(trace_buffered_event))) 
int <token> = PAGE_SIZE - struct_size(entry, array, 1); <answer> max_len 
val = <token> <answer> this_cpu_inc_return(trace_buffered_event_cnt); 
if (val == 1 && <token> <= max_len)) { <answer> likely(len 
<token> type, trace_ctx); <answer> trace_event_setup(entry, 
<token> = len; <answer> entry->array[0] 
if (!entry && trace_file->flags & <token> { <answer> EVENT_FILE_FL_TRIGGER_COND) 
<token> = temp_buffer; <answer> *current_rb 
<token> = __trace_buffer_lock_reserve(*current_rb, type, len, <answer> entry 
<token> entry; <answer> return 
static <token> <answer> DEFINE_RAW_SPINLOCK(tracepoint_iter_lock); 
<token> DEFINE_MUTEX(tracepoint_printk_mutex); <answer> static 
static <token> output_printk(struct trace_event_buffer *fbuffer) <answer> void 
struct <token> *event_call; <answer> trace_event_call 
struct trace_event_file <token> <answer> *file; 
<token> trace_event *event; <answer> struct 
<token> long flags; <answer> unsigned 
struct <token> *iter = tracepoint_print_iter; <answer> trace_iterator 
<token> (!tracepoint_print_iter) <answer> if 
tracepoint_printk = <token> <answer> 0; 
<token> (save_tracepoint_printk == tracepoint_printk) <answer> if 
<token> out; <answer> goto 
if <token> <answer> (tracepoint_printk) 
return <token> <answer> ret; 
void trace_event_buffer_commit(struct trace_event_buffer <token> <answer> *fbuffer) 
enum event_trigger_type tt = <token> <answer> ETT_NONE; 
<token> trace_event_file *file = fbuffer->trace_file; <answer> struct 
if (__event_trigger_test_discard(file, <token> fbuffer->event, <answer> fbuffer->buffer, 
fbuffer->entry, <token> <answer> &tt)) 
<token> discard; <answer> goto 
<token> (static_key_false(&tracepoint_printk_key.key)) <answer> if 
if <token> <answer> (static_branch_unlikely(&trace_event_exports_enabled)) 
<token> TRACE_EXPORT_EVENT); <answer> ftrace_exports(fbuffer->event, 
<token> fbuffer->buffer, <answer> trace_buffer_unlock_commit_regs(file->tr, 
fbuffer->event, <token> fbuffer->regs); <answer> fbuffer->trace_ctx, 
<token> (tt) <answer> if 
event_triggers_post_call(file, <token> <answer> tt); 
# define <token> 3 <answer> STACK_SKIP 
void trace_buffer_unlock_commit_regs(struct trace_array <token> <answer> *tr, 
struct trace_buffer <token> <answer> *buffer, 
<token> ring_buffer_event *event, <answer> struct 
unsigned int <token> <answer> trace_ctx, 
struct <token> *regs) <answer> pt_regs 
<token> event); <answer> __buffer_unlock_commit(buffer, 
ftrace_trace_stack(tr, buffer, trace_ctx, regs ? 0 : STACK_SKIP, <token> <answer> regs); 
ftrace_trace_userstack(tr, <token> trace_ctx); <answer> buffer, 
<token> trace_buffer *buffer, <answer> trace_buffer_unlock_commit_nostack(struct 
struct ring_buffer_event <token> <answer> *event) 
<token> event); <answer> __buffer_unlock_commit(buffer, 
trace_function(struct trace_array *tr, unsigned long ip, unsigned <token> <answer> long 
parent_ip, unsigned int <token> <answer> trace_ctx) 
struct <token> *call = &event_function; <answer> trace_event_call 
struct trace_buffer *buffer <token> tr->array_buffer.buffer; <answer> = 
struct <token> *event; <answer> ring_buffer_event 
<token> ftrace_entry *entry; <answer> struct 
<token> = __trace_buffer_lock_reserve(buffer, TRACE_FN, sizeof(*entry), <answer> event 
if <token> <answer> (!event) 
<token> = ring_buffer_event_data(event); <answer> entry 
entry->ip = <token> <answer> ip; 
entry->parent_ip <token> parent_ip; <answer> = 
if (!call_filter_check_discard(call, <token> buffer, event)) { <answer> entry, 
if <token> <answer> (static_branch_unlikely(&trace_function_exports_enabled)) 
ftrace_exports(event, <token> <answer> TRACE_EXPORT_FUNCTION); 
<token> event); <answer> __buffer_unlock_commit(buffer, 
#ifdef <token> <answer> CONFIG_STACKTRACE 
<token> CONFIG_UNWINDER_ORC <answer> #ifndef 
<token> (!regs) <answer> if 
stackidx = __this_cpu_inc_return(ftrace_stack_reserve) - <token> <answer> 1; 
fstack = this_cpu_ptr(ftrace_stacks.stacks) + <token> <answer> stackidx; 
size = <token> <answer> ARRAY_SIZE(fstack->calls); 
if (regs) <token> <answer> { 
<token> = stack_trace_save_regs(regs, fstack->calls, <answer> nr_entries 
<token> skip); <answer> size, 
<token> else { <answer> } 
nr_entries = <token> size, skip); <answer> stack_trace_save(fstack->calls, 
event <token> __trace_buffer_lock_reserve(buffer, TRACE_STACK, <answer> = 
struct_size(entry, <token> nr_entries), <answer> caller, 
<token> (!event) <answer> if 
goto <token> <answer> out; 
entry <token> ring_buffer_event_data(event); <answer> = 
entry->size = <token> <answer> nr_entries; 
memcpy(&entry->caller, <token> <answer> fstack->calls, 
<token> caller, nr_entries)); <answer> flex_array_size(entry, 
if (!call_filter_check_discard(call, <token> buffer, event)) <answer> entry, 
__buffer_unlock_commit(buffer, <token> <answer> event); 
<token> (unlikely(in_nmi())) <answer> if 
__ftrace_trace_stack(buffer, trace_ctx, <token> NULL); <answer> skip, 
void trace_dump_stack(int <token> <answer> skip) 
if <token> || tracing_selftest_running) <answer> (tracing_disabled 
<token> CONFIG_UNWINDER_ORC <answer> #ifndef 
<token> (unlikely(in_nmi())) <answer> if 
if <token> <answer> (__this_cpu_read(user_stack_count)) 
goto <token> <answer> out; 
event <token> __trace_buffer_lock_reserve(buffer, TRACE_USER_STACK, <answer> = 
<token> trace_ctx); <answer> sizeof(*entry), 
<token> (!event) <answer> if 
goto <token> <answer> out_drop_count; 
entry <token> ring_buffer_event_data(event); <answer> = 
entry->tgid <token> current->tgid; <answer> = 
memset(&entry->caller, <token> sizeof(entry->caller)); <answer> 0, 
stack_trace_save_user(entry->caller, <token> <answer> FTRACE_STACK_ENTRIES); 
if (!call_filter_check_discard(call, <token> buffer, event)) <answer> entry, 
__buffer_unlock_commit(buffer, <token> <answer> event); 
static <token> *get_trace_buf(void) <answer> char 
<token> trace_buffer_struct *buffer = this_cpu_ptr(trace_percpu_buffer); <answer> struct 
<token> (!trace_percpu_buffer || buffer->nesting >= 4) <answer> if 
return <token> <answer> NULL; 
if <token> <answer> (global_trace.array_buffer.buffer) 
void <token> <answer> trace_printk_start_comm(void) 
int trace_vbprintk(unsigned long ip, const <token> *fmt, va_list args) <answer> char 
<token> trace_event_call *call = &event_bprint; <answer> struct 
struct <token> *event; <answer> ring_buffer_event 
struct trace_buffer <token> <answer> *buffer; 
struct trace_array <token> = &global_trace; <answer> *tr 
struct bprint_entry <token> <answer> *entry; 
unsigned <token> trace_ctx; <answer> int 
char <token> <answer> *tbuffer; 
int len = <token> size; <answer> 0, 
if (unlikely(tracing_selftest_running <token> tracing_disabled)) <answer> || 
return <token> <answer> 0; 
<token> 0) <answer> __printf(3, 
int trace_array_printk(struct <token> *tr, <answer> trace_array 
unsigned long ip, const char <token> ...) <answer> *fmt, 
<token> ret; <answer> int 
<token> ap; <answer> va_list 
<token> (!tr) <answer> if 
<token> -ENOENT; <answer> return 
int <token> trace_array *tr) <answer> trace_array_init_printk(struct 
if <token> <answer> (!tr) 
return <token> <answer> -ENOENT; 
if (cpu_file > RING_BUFFER_ALL_CPUS) <token> <answer> { 
if (ring_buffer_empty_cpu(buffer, <token> <answer> cpu_file)) 
return <token> <answer> NULL; 
ent = peek_next_entry(iter, cpu_file, <token> missing_events); <answer> ent_ts, 
if <token> <answer> (ent_cpu) 
<token> = cpu_file; <answer> *ent_cpu 
return <token> <answer> ent; 
<token> { <answer> for_each_tracing_cpu(cpu) 
if (ring_buffer_empty_cpu(buffer, <token> <answer> cpu)) 
ent = peek_next_entry(iter, cpu, <token> &lost_events); <answer> &ts, 
if (ent && (!next || ts <token> next_ts)) { <answer> < 
<token> = ent; <answer> next 
next_cpu <token> cpu; <answer> = 
next_ts <token> ts; <answer> = 
next_lost <token> lost_events; <answer> = 
<token> = iter->ent_size; <answer> next_size 
iter->ent_size = <token> <answer> next_size; 
if <token> <answer> (ent_cpu) 
*ent_cpu = <token> <answer> next_cpu; 
<token> (ent_ts) <answer> if 
*ent_ts <token> next_ts; <answer> = 
if <token> <answer> (missing_events) 
<token> = next_lost; <answer> *missing_events 
<token> next; <answer> return 
#define STATIC_FMT_BUF_SIZE <token> <answer> 128 
static char <token> <answer> static_fmt_buf[STATIC_FMT_BUF_SIZE]; 
<token> *trace_iter_expand_format(struct trace_iterator *iter) <answer> char 
<token> *tmp; <answer> char 
if (!iter->tr || iter->fmt == <token> <answer> static_fmt_buf) 
<token> NULL; <answer> return 
tmp = krealloc(iter->fmt, <token> + STATIC_FMT_BUF_SIZE, <answer> iter->fmt_size 
<token> (tmp) { <answer> if 
iter->fmt_size <token> STATIC_FMT_BUF_SIZE; <answer> += 
iter->fmt <token> tmp; <answer> = 
<token> tmp; <answer> return 
if <token> <answer> (!iter->ent) 
<token> false; <answer> return 
trace_event <token> ftrace_find_event(iter->ent->type); <answer> = 
if <token> <answer> (!trace_event) 
return <token> <answer> false; 
event = container_of(trace_event, struct trace_event_call, <token> <answer> event); 
<token> ((event->flags & TRACE_EVENT_FL_DYNAMIC) || !event->module) <answer> if 
return <token> <answer> false; 
va_start(ap, <token> <answer> fmt); 
vsnprintf(buf, 16, <token> ap); <answer> "%d", 
ret <token> va_arg(ap, int); <answer> = 
return <token> <answer> ret; 
<token> void test_can_verify(void) <answer> static 
if <token> %d", 0, 1)) { <answer> (!test_can_verify_check("%d 
pr_info("trace event string <token> disabled\n"); <answer> verifier 
void trace_check_vprintf(struct trace_iterator *iter, <token> char *fmt, <answer> const 
va_list <token> <answer> ap) 
const <token> *p = fmt; <answer> char 
const char <token> <answer> *str; 
<token> i, j; <answer> int 
<token> (WARN_ON_ONCE(!fmt)) <answer> if 
if <token> <answer> (static_branch_unlikely(&trace_no_verify)) 
goto <token> <answer> print; 
if <token> <answer> (!trace_iter_expand_format(iter)) 
<token> print; <answer> goto 
if <token> == '\\' && p[i+1]) { <answer> (p[i] 
if (p[i] <token> '%') { <answer> == 
if <token> { <answer> (iter->seq.full) 
p = <token> <answer> ""; 
<token> (star) <answer> if 
len <token> va_arg(ap, int); <answer> = 
if (WARN_ONCE(!trace_safe_str(iter, <token> star, len), <answer> str, 
<token> '%s' current_buffer: '%s'", <answer> "fmt: 
fmt, <token> { <answer> seq_buf_str(&iter->seq.seq))) 
<token> ret; <answer> int 
if (iter->temp == <token> && <answer> static_temp_buf 
STATIC_TEMP_BUF_SIZE <token> ent_size) <answer> < 
return <token> <answer> NULL; 
if (iter->ent && iter->ent != iter->temp) <token> <answer> { 
<token> ((!iter->temp || iter->temp_size < iter->ent_size) && <answer> if 
!WARN_ON_ONCE(iter->temp == static_temp_buf)) <token> <answer> { 
<token> *temp; <answer> void 
temp = kmalloc(iter->ent_size, <token> <answer> GFP_KERNEL); 
<token> (!temp) <answer> if 
<token> NULL; <answer> return 
<token> = temp; <answer> iter->temp 
<token> = iter->ent_size; <answer> iter->temp_size 
<token> iter->ent, iter->ent_size); <answer> memcpy(iter->temp, 
iter->ent = <token> <answer> iter->temp; 
entry <token> __find_next_entry(iter, ent_cpu, NULL, ent_ts); <answer> = 
<token> (ring_buffer_iter_peek(buf_iter, &ts)) { <answer> while 
<token> (ts >= iter->array_buffer->time_start) <answer> if 
<token> cpu)->skipped_entries = entries; <answer> per_cpu_ptr(iter->array_buffer->data, 
static void *s_start(struct <token> *m, loff_t *pos) <answer> seq_file 
struct <token> *iter = m->private; <answer> trace_iterator 
struct trace_array *tr <token> iter->tr; <answer> = 
int <token> = iter->cpu_file; <answer> cpu_file 
<token> *p = NULL; <answer> void 
loff_t <token> = 0; <answer> l 
<token> cpu; <answer> int 
if (unlikely(tr->current_trace != iter->trace)) <token> <answer> { 
if <token> <answer> (iter->leftover) 
<token> = iter; <answer> p 
else <token> <answer> { 
l <token> *pos - 1; <answer> = 
p = s_next(m, <token> &l); <answer> p, 
return <token> <answer> p; 
static void s_stop(struct seq_file *m, void <token> <answer> *p) 
struct <token> *iter = m->private; <answer> trace_iterator 
#ifdef <token> <answer> CONFIG_TRACER_MAX_TRACE 
<token> (iter->snapshot && iter->trace->use_max_tr) <answer> if 
<token> void <answer> static 
get_total_entries_cpu(struct array_buffer *buf, unsigned <token> *total, <answer> long 
unsigned <token> *entries, int cpu) <answer> long 
<token> long count; <answer> unsigned 
count = ring_buffer_entries_cpu(buf->buffer, <token> <answer> cpu); 
if (per_cpu_ptr(buf->data, cpu)->skipped_entries) <token> <answer> { 
count -= <token> cpu)->skipped_entries; <answer> per_cpu_ptr(buf->data, 
ret <token> trace_print_seq(m, &iter->seq); <answer> = 
iter->leftover <token> ret; <answer> = 
return <token> <answer> 0; 
static <token> int tracing_get_cpu(struct inode *inode) <answer> inline 
static void <token> trace_iterator *iter) <answer> free_trace_iter_content(struct 
iter->temp = kmalloc(128, <token> <answer> GFP_KERNEL); 
if <token> <answer> (iter->temp) 
iter->temp_size = <token> <answer> 128; 
iter->fmt = <token> <answer> NULL; 
iter->fmt_size <token> 0; <answer> = 
iter->trace <token> tr->current_trace; <answer> = 
<token> (!zalloc_cpumask_var(&iter->started, GFP_KERNEL)) <answer> if 
<token> fail; <answer> goto 
iter->tr <token> tr; <answer> = 
<token> CONFIG_TRACER_MAX_TRACE <answer> #ifdef 
<token> (!iter->snapshot && (tr->trace_flags & TRACE_ITER_PAUSE_ON_TRACE)) <answer> if 
<token> (iter->cpu_file == RING_BUFFER_ALL_CPUS) { <answer> if 
<token> { <answer> for_each_tracing_cpu(cpu) 
<token> = <answer> iter->buffer_iter[cpu] 
<token> GFP_KERNEL); <answer> cpu, 
for_each_tracing_cpu(cpu) <token> <answer> { 
tracing_iter_reset(iter, <token> <answer> cpu); 
<token> else { <answer> } 
cpu <token> iter->cpu_file; <answer> = 
<token> = <answer> iter->buffer_iter[cpu] 
<token> GFP_KERNEL); <answer> cpu, 
tracing_iter_reset(iter, <token> <answer> cpu); 
return <token> <answer> iter; 
<token> file); <answer> seq_release_private(inode, 
return <token> <answer> ERR_PTR(-ENOMEM); 
int <token> inode *inode, struct file *filp) <answer> tracing_open_generic(struct 
<token> ret; <answer> int 
ret <token> tracing_check_open_get_tr(NULL); <answer> = 
if <token> <answer> (ret) 
return <token> <answer> ret; 
<token> = inode->i_private; <answer> filp->private_data 
<token> 0; <answer> return 
bool <token> <answer> tracing_is_disabled(void) 
return (tracing_disabled) ? true: <token> <answer> false; 
<token> tracing_open_generic_tr(struct inode *inode, struct file *filp) <answer> int 
struct <token> *tr = inode->i_private; <answer> trace_array 
<token> ret; <answer> int 
ret = <token> <answer> tracing_check_open_get_tr(tr); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
filp->private_data = <token> <answer> inode->i_private; 
return <token> <answer> 0; 
int tracing_open_file_tr(struct <token> *inode, struct file *filp) <answer> inode 
struct trace_event_file <token> = inode->i_private; <answer> *file 
int <token> <answer> ret; 
ret <token> tracing_check_open_get_tr(file->tr); <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
static <token> <answer> bool 
trace_ok_for_array(struct tracer *t, struct <token> *tr) <answer> trace_array 
return (tr->flags & TRACE_ARRAY_FL_GLOBAL) <token> t->allow_instances; <answer> || 
if (cpumask_test_cpu(cpu, tr->tracing_cpumask) <token> <answer> && 
!cpumask_test_cpu(cpu, tracing_cpumask_new)) <token> <answer> { 
atomic_inc(&per_cpu_ptr(tr->array_buffer.data, <token> <answer> cpu)->disabled); 
<token> cpu); <answer> ring_buffer_record_disable_cpu(tr->array_buffer.buffer, 
#ifdef <token> <answer> CONFIG_TRACER_MAX_TRACE 
ring_buffer_record_disable_cpu(tr->max_buffer.buffer, <token> <answer> cpu); 
if (!cpumask_test_cpu(cpu, <token> && <answer> tr->tracing_cpumask) 
<token> tracing_cpumask_new)) { <answer> cpumask_test_cpu(cpu, 
atomic_dec(&per_cpu_ptr(tr->array_buffer.data, <token> <answer> cpu)->disabled); 
<token> cpu); <answer> ring_buffer_record_enable_cpu(tr->array_buffer.buffer, 
#ifdef <token> <answer> CONFIG_TRACER_MAX_TRACE 
ring_buffer_record_enable_cpu(tr->max_buffer.buffer, <token> <answer> cpu); 
<token> tracing_cpumask_new); <answer> cpumask_copy(tr->tracing_cpumask, 
return <token> <answer> 0; 
static <token> <answer> ssize_t 
tracing_cpumask_write(struct file *filp, const char <token> *ubuf, <answer> __user 
size_t count, loff_t <token> <answer> *ppos) 
<token> trace_array *tr = file_inode(filp)->i_private; <answer> struct 
cpumask_var_t <token> <answer> tracing_cpumask_new; 
<token> err; <answer> int 
if <token> GFP_KERNEL)) <answer> (!zalloc_cpumask_var(&tracing_cpumask_new, 
<token> -ENOMEM; <answer> return 
err <token> cpumask_parse_user(ubuf, count, tracing_cpumask_new); <answer> = 
<token> (err) <answer> if 
goto <token> <answer> err_free; 
err = tracing_set_cpumask(tr, <token> <answer> tracing_cpumask_new); 
if <token> <answer> (err) 
<token> err_free; <answer> goto 
return <token> <answer> count; 
return <token> <answer> err; 
static const struct file_operations tracing_cpumask_fops = <token> <answer> { 
<token> = tracing_open_generic_tr, <answer> .open 
.read = <token> <answer> tracing_cpumask_read, 
.write = <token> <answer> tracing_cpumask_write, 
.release = <token> <answer> tracing_release_generic_tr, 
.llseek <token> generic_file_llseek, <answer> = 
static int tracing_trace_options_show(struct seq_file *m, void <token> <answer> *v) 
struct <token> *trace_opts; <answer> tracer_opt 
<token> trace_array *tr = m->private; <answer> struct 
<token> tracer_flags; <answer> u32 
<token> i; <answer> int 
tracer_flags <token> tr->current_trace->flags->val; <answer> = 
trace_opts <token> tr->current_trace->flags->opts; <answer> = 
for (i <token> 0; trace_options[i]; i++) { <answer> = 
if <token> & (1 << i)) <answer> (tr->trace_flags 
seq_printf(m, "%s\n", <token> <answer> trace_options[i]); 
seq_printf(m, "no%s\n", <token> <answer> trace_options[i]); 
for (i = 0; trace_opts[i].name; <token> { <answer> i++) 
if (tracer_flags <token> trace_opts[i].bit) <answer> & 
seq_printf(m, <token> trace_opts[i].name); <answer> "%s\n", 
seq_printf(m, "no%s\n", <token> <answer> trace_opts[i].name); 
<token> 0; <answer> return 
static int <token> trace_array *tr, <answer> __set_tracer_option(struct 
struct tracer_flags <token> <answer> *tracer_flags, 
struct tracer_opt <token> int neg) <answer> *opts, 
struct <token> *trace = tracer_flags->trace; <answer> tracer 
<token> ret; <answer> int 
<token> = trace->set_flag(tr, tracer_flags->val, opts->bit, !neg); <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ret; 
if <token> <answer> (neg) 
<token> &= ~opts->bit; <answer> tracer_flags->val 
tracer_flags->val |= <token> <answer> opts->bit; 
<token> 0; <answer> return 
if <token> > strlen(option)) <answer> (orig_len 
option[strlen(option)] = ' <token> <answer> '; 
return <token> <answer> ret; 
static <token> __init apply_trace_boot_options(void) <answer> void 
char *buf <token> trace_boot_options_buf; <answer> = 
char <token> <answer> *option; 
while <token> { <answer> (true) 
option = strsep(&buf, <token> <answer> ","); 
<token> (!option) <answer> if 
if <token> <answer> (*option) 
<token> option); <answer> trace_set_options(&global_trace, 
ptr = <token> <answer> update_eval_map(ptr); 
if <token> <answer> (WARN_ON_ONCE(!ptr)) 
<token> NULL; <answer> return 
<token> = update_eval_map(ptr); <answer> ptr 
<token> ptr; <answer> return 
<token> void *eval_map_start(struct seq_file *m, loff_t *pos) <answer> static 
union trace_eval_map_item <token> <answer> *v; 
loff_t l = <token> <answer> 0; 
v = <token> <answer> trace_eval_maps; 
if <token> <answer> (v) 
while (v && l < *pos) <token> <answer> { 
v <token> eval_map_next(m, v, &l); <answer> = 
return <token> <answer> v; 
<token> void eval_map_stop(struct seq_file *m, void *v) <answer> static 
static int eval_map_show(struct seq_file *m, <token> *v) <answer> void 
union <token> *ptr = v; <answer> trace_eval_map_item 
<token> "%s %ld (%s)\n", <answer> seq_printf(m, 
ptr->map.eval_string, <token> <answer> ptr->map.eval_value, 
return <token> <answer> 0; 
static const <token> seq_operations tracing_eval_map_seq_ops = { <answer> struct 
.start = <token> <answer> eval_map_start, 
.next = <token> <answer> eval_map_next, 
<token> = eval_map_stop, <answer> .stop 
<token> = eval_map_show, <answer> .show 
static int tracing_eval_map_open(struct inode *inode, struct file <token> <answer> *filp) 
int <token> <answer> ret; 
ret <token> tracing_check_open_get_tr(NULL); <answer> = 
<token> (ret) <answer> if 
return <token> <answer> ret; 
<token> seq_open(filp, &tracing_eval_map_seq_ops); <answer> return 
static const <token> file_operations tracing_eval_map_fops = { <answer> struct 
<token> = tracing_eval_map_open, <answer> .open 
.read <token> seq_read, <answer> = 
.llseek = <token> <answer> seq_lseek, 
.release <token> seq_release, <answer> = 
static inline union trace_eval_map_item <token> <answer> * 
trace_eval_jmp_to_tail(union <token> *ptr) <answer> trace_eval_map_item 
<token> = kmalloc_array(len + 2, sizeof(*map_array), GFP_KERNEL); <answer> map_array 
if <token> { <answer> (!map_array) 
pr_warn("Unable to allocate <token> eval mapping\n"); <answer> trace 
<token> (!trace_eval_maps) <answer> if 
trace_eval_maps <token> map_array; <answer> = 
else <token> <answer> { 
ptr <token> trace_eval_maps; <answer> = 
<token> (;;) { <answer> for 
ptr = <token> <answer> trace_eval_jmp_to_tail(ptr); 
<token> (!ptr->tail.next) <answer> if 
<token> = ptr->tail.next; <answer> ptr 
<token> = map_array; <answer> ptr->tail.next 
map_array->head.mod = <token> <answer> mod; 
map_array->head.length = <token> <answer> len; 
for <token> = start; (unsigned long)map < (unsigned long)stop; map++) { <answer> (map 
<token> = **map; <answer> map_array->map 
memset(map_array, 0, <token> <answer> sizeof(*map_array)); 
<token> void trace_create_eval_file(struct dentry *d_tracer) <answer> static 
trace_create_file("eval_map", TRACE_MODE_READ, <token> <answer> d_tracer, 
<token> &tracing_eval_map_fops); <answer> NULL, 
<token> = 1; <answer> tracing_disabled 
<token> out_start; <answer> goto 
<token> cpu); <answer> update_buffer_entries(&tr->max_buffer, 
<token> tracing_update_buffers(struct trace_array *tr) <answer> int 
int ret <token> 0; <answer> = 
<token> (!tr->ring_buffer_expanded) <answer> if 
ret = __tracing_resize_ring_buffer(tr, <token> <answer> trace_buf_size, 
return <token> <answer> ret; 
struct <token> <answer> trace_option_dentry; 
<token> void <answer> static 
<token> trace_array *tr, struct tracer *tracer); <answer> create_trace_option_files(struct 
static void tracing_set_nop(struct trace_array <token> <answer> *tr) 
if (tr->current_trace == <token> <answer> &nop_trace) 
<token> (tr->current_trace->reset) <answer> if 
<token> = &nop_trace; <answer> tr->current_trace 
<token> bool tracer_options_updated; <answer> static 
static void add_tracer_options(struct trace_array *tr, <token> tracer *t) <answer> struct 
if (!had_max_tr <token> t->use_max_tr) { <answer> && 
<token> = tracing_arm_snapshot_locked(tr); <answer> ret 
<token> (ret) <answer> if 
goto <token> <answer> out; 
tr->current_trace <token> &nop_trace; <answer> = 
if <token> { <answer> (t->init) 
<token> = tracer_init(t, tr); <answer> ret 
if <token> { <answer> (ret) 
#ifdef <token> <answer> CONFIG_TRACER_MAX_TRACE 
<token> (t->use_max_tr) <answer> if 
<token> out; <answer> goto 
tr->current_trace <token> t; <answer> = 
<token> ret; <answer> return 
static <token> <answer> ssize_t 
tracing_set_trace_write(struct file *filp, const char <token> *ubuf, <answer> __user 
size_t cnt, loff_t <token> <answer> *ppos) 
struct trace_array *tr <token> filp->private_data; <answer> = 
<token> buf[MAX_TRACER_SIZE+1]; <answer> char 
char <token> <answer> *name; 
<token> ret; <answer> size_t 
int <token> <answer> err; 
ret = <token> <answer> cnt; 
if (cnt <token> MAX_TRACER_SIZE) <answer> > 
cnt <token> MAX_TRACER_SIZE; <answer> = 
if <token> ubuf, cnt)) <answer> (copy_from_user(buf, 
return <token> <answer> -EFAULT; 
buf[cnt] <token> 0; <answer> = 
name = <token> <answer> strim(buf); 
err = <token> name); <answer> tracing_set_tracer(tr, 
<token> (err) <answer> if 
return <token> <answer> err; 
*ppos += <token> <answer> ret; 
return <token> <answer> ret; 
<token> ssize_t <answer> static 
tracing_nsecs_read(unsigned <token> *ptr, char __user *ubuf, <answer> long 
<token> cnt, loff_t *ppos) <answer> size_t 
char <token> <answer> buf[64]; 
<token> r; <answer> int 
r <token> snprintf(buf, sizeof(buf), "%ld\n", <answer> = 
*ptr == <token> long)-1 ? -1 : nsecs_to_usecs(*ptr)); <answer> (unsigned 
if (r <token> sizeof(buf)) <answer> > 
r = <token> <answer> sizeof(buf); 
return simple_read_from_buffer(ubuf, cnt, ppos, buf, <token> <answer> r); 
static <token> <answer> ssize_t 
tracing_nsecs_write(unsigned long *ptr, const <token> __user *ubuf, <answer> char 
<token> cnt, loff_t *ppos) <answer> size_t 
unsigned <token> val; <answer> long 
<token> ret; <answer> int 
ret <token> kstrtoul_from_user(ubuf, cnt, 10, &val); <answer> = 
<token> (ret) <answer> if 
return <token> <answer> ret; 
*ptr = val * <token> <answer> 1000; 
<token> cnt; <answer> return 
static <token> <answer> ssize_t 
tracing_thresh_read(struct file *filp, <token> __user *ubuf, <answer> char 
size_t <token> loff_t *ppos) <answer> cnt, 
return <token> ubuf, cnt, ppos); <answer> tracing_nsecs_read(&tracing_thresh, 
static <token> <answer> ssize_t 
tracing_thresh_write(struct file <token> const char __user *ubuf, <answer> *filp, 
size_t <token> loff_t *ppos) <answer> cnt, 
struct trace_array <token> = filp->private_data; <answer> *tr 
int <token> <answer> ret; 
<token> = tracing_nsecs_write(&tracing_thresh, ubuf, cnt, ppos); <answer> ret 
if <token> < 0) <answer> (ret 
<token> out; <answer> goto 
if <token> { <answer> (tr->current_trace->update_thresh) 
<token> = tr->current_trace->update_thresh(tr); <answer> ret 
if (ret <token> 0) <answer> < 
goto <token> <answer> out; 
ret = <token> <answer> cnt; 
<token> ret; <answer> return 
#ifdef <token> <answer> CONFIG_TRACER_MAX_TRACE 
<token> ssize_t <answer> static 
tracing_max_lat_read(struct <token> *filp, char __user *ubuf, <answer> file 
size_t cnt, <token> *ppos) <answer> loff_t 
struct trace_array <token> = filp->private_data; <answer> *tr 
return tracing_nsecs_read(&tr->max_latency, ubuf, cnt, <token> <answer> ppos); 
<token> ssize_t <answer> static 
tracing_max_lat_write(struct file *filp, <token> char __user *ubuf, <answer> const 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/miscdevice.h> 
#include <token> <answer> <linux/compat.h> 
#include <token> <answer> <linux/fdtable.h> 
<token> <linux/magic.h> <answer> #include 
<token> <linux/nospec.h> <answer> #include 
#include <token> <answer> "autofs_i.h" 
typedef int (*ioctl_fn)(struct file <token> struct autofs_sb_info *, <answer> *, 
struct autofs_dev_ioctl <token> <answer> *); 
static int check_name(const char <token> <answer> *name) 
<token> (!strchr(name, '/')) <answer> if 
return <token> <answer> -EINVAL; 
<token> 0; <answer> return 
static int invalid_str(char *str, size_t <token> <answer> size) 
if <token> 0, size)) <answer> (memchr(str, 
return <token> <answer> 0; 
return <token> <answer> -EINVAL; 
static int check_dev_ioctl_version(int <token> struct autofs_dev_ioctl *param) <answer> cmd, 
int err <token> 0; <answer> = 
<token> ((param->ver_major != AUTOFS_DEV_IOCTL_VERSION_MAJOR) || <answer> if 
<token> > AUTOFS_DEV_IOCTL_VERSION_MINOR)) { <answer> (param->ver_minor 
pr_warn("ioctl control <token> version mismatch: " <answer> interface 
<token> user(%u.%u), cmd(0x%08x)\n", <answer> "kernel(%u.%u), 
param->ver_major, <token> cmd); <answer> param->ver_minor, 
err <token> -EINVAL; <answer> = 
<token> struct autofs_dev_ioctl * <answer> static 
copy_dev_ioctl(struct <token> __user *in) <answer> autofs_dev_ioctl 
<token> autofs_dev_ioctl tmp, *res; <answer> struct 
if (copy_from_user(&tmp, <token> AUTOFS_DEV_IOCTL_SIZE)) <answer> in, 
<token> ERR_PTR(-EFAULT); <answer> return 
<token> (tmp.size < AUTOFS_DEV_IOCTL_SIZE) <answer> if 
<token> ERR_PTR(-EINVAL); <answer> return 
if <token> > AUTOFS_DEV_IOCTL_SIZE + PATH_MAX) <answer> (tmp.size 
return <token> <answer> ERR_PTR(-ENAMETOOLONG); 
res = <token> tmp.size); <answer> memdup_user(in, 
<token> (!IS_ERR(res)) <answer> if 
<token> = tmp.size; <answer> res->size 
<token> res; <answer> return 
static inline void <token> autofs_dev_ioctl *param) <answer> free_dev_ioctl(struct 
static int validate_dev_ioctl(int <token> struct autofs_dev_ioctl *param) <answer> cmd, 
int <token> <answer> err; 
err = check_dev_ioctl_version(cmd, <token> <answer> param); 
if (err) <token> <answer> { 
pr_warn("invalid device control <token> version " <answer> module 
<token> for cmd(0x%08x)\n", cmd); <answer> "supplied 
<token> out; <answer> goto 
if <token> > AUTOFS_DEV_IOCTL_SIZE) { <answer> (param->size 
err = invalid_str(param->path, param->size <token> AUTOFS_DEV_IOCTL_SIZE); <answer> - 
<token> (err) { <answer> if 
"path string terminator missing <token> cmd(0x%08x)\n", <answer> for 
<token> out; <answer> goto 
err = <token> <answer> check_name(param->path); 
if (err) <token> <answer> { 
pr_warn("invalid path supplied <token> cmd(0x%08x)\n", <answer> for 
<token> out; <answer> goto 
<token> else { <answer> } 
unsigned int <token> = _IOC_NR(cmd); <answer> inr 
if <token> == AUTOFS_DEV_IOCTL_OPENMOUNT_CMD || <answer> (inr 
inr == AUTOFS_DEV_IOCTL_REQUESTER_CMD <token> <answer> || 
inr == <token> { <answer> AUTOFS_DEV_IOCTL_ISMOUNTPOINT_CMD) 
<token> = -EINVAL; <answer> err 
<token> out; <answer> goto 
err <token> 0; <answer> = 
<token> err; <answer> return 
<token> int autofs_dev_ioctl_open_mountpoint(const char *name, dev_t devid) <answer> static 
int err, <token> <answer> fd; 
<token> = get_unused_fd_flags(O_CLOEXEC); <answer> fd 
if (likely(fd >= <token> { <answer> 0)) 
struct file <token> <answer> *filp; 
<token> path path; <answer> struct 
err = find_autofs_mount(name, &path, test_by_dev, <token> <answer> &devid); 
<token> (err) <answer> if 
goto <token> <answer> out; 
<token> = dentry_open(&path, O_RDONLY, current_cred()); <answer> filp 
if (IS_ERR(filp)) <token> <answer> { 
err <token> PTR_ERR(filp); <answer> = 
goto <token> <answer> out; 
<token> filp); <answer> fd_install(fd, 
return <token> <answer> fd; 
return <token> <answer> err; 
static int autofs_dev_ioctl_ready(struct file <token> <answer> *fp, 
struct autofs_sb_info <token> <answer> *sbi, 
<token> autofs_dev_ioctl *param) <answer> struct 
<token> token; <answer> autofs_wqt_t 
token <token> (autofs_wqt_t) param->ready.token; <answer> = 
return <token> token, 0); <answer> autofs_wait_release(sbi, 
static <token> autofs_dev_ioctl_fail(struct file *fp, <answer> int 
struct <token> *sbi, <answer> autofs_sb_info 
struct <token> *param) <answer> autofs_dev_ioctl 
<token> token; <answer> autofs_wqt_t 
int <token> <answer> status; 
<token> = (autofs_wqt_t) param->fail.token; <answer> token 
<token> = param->fail.status < 0 ? param->fail.status : -ENOENT; <answer> status 
return autofs_wait_release(sbi, <token> status); <answer> token, 
static int <token> file *fp, <answer> autofs_dev_ioctl_setpipefd(struct 
struct <token> *sbi, <answer> autofs_sb_info 
struct autofs_dev_ioctl <token> <answer> *param) 
int <token> <answer> pipefd; 
int <token> = 0; <answer> err 
struct <token> *new_pid = NULL; <answer> pid 
if <token> == -1) <answer> (param->setpipefd.pipefd 
return <token> <answer> -EINVAL; 
pipefd <token> param->setpipefd.pipefd; <answer> = 
<token> (!(sbi->flags & AUTOFS_SBI_CATATONIC)) { <answer> if 
return <token> <answer> -EBUSY; 
<token> else { <answer> } 
struct <token> *pipe; <answer> file 
new_pid = get_task_pid(current, <token> <answer> PIDTYPE_PGID); 
<token> (ns_of_pid(new_pid) != ns_of_pid(sbi->oz_pgrp)) { <answer> if 
pr_warn("not allowed to change <token> namespace\n"); <answer> PID 
err <token> -EINVAL; <answer> = 
<token> out; <answer> goto 
<token> = fget(pipefd); <answer> pipe 
<token> (!pipe) { <answer> if 
err = <token> <answer> -EBADF; 
<token> out; <answer> goto 
<token> (autofs_prepare_pipe(pipe) < 0) { <answer> if 
<token> = -EPIPE; <answer> err 
<token> out; <answer> goto 
<token> new_pid); <answer> swap(sbi->oz_pgrp, 
sbi->pipefd <token> pipefd; <answer> = 
sbi->pipe = <token> <answer> pipe; 
sbi->flags <token> ~AUTOFS_SBI_CATATONIC; <answer> &= 
<token> err; <answer> return 
static int autofs_dev_ioctl_catatonic(struct <token> *fp, <answer> file 
<token> autofs_sb_info *sbi, <answer> struct 
struct <token> *param) <answer> autofs_dev_ioctl 
return <token> <answer> 0; 
static int <token> file *fp, <answer> autofs_dev_ioctl_requester(struct 
<token> autofs_sb_info *sbi, <answer> struct 
<token> autofs_dev_ioctl *param) <answer> struct 
struct <token> *ino; <answer> autofs_info 
struct path <token> <answer> path; 
<token> devid; <answer> dev_t 
int err <token> -ENOENT; <answer> = 
static int <token> file *fp, <answer> autofs_dev_ioctl_expire(struct 
<token> autofs_sb_info *sbi, <answer> struct 
struct autofs_dev_ioctl <token> <answer> *param) 
struct vfsmount <token> <answer> *mnt; 
<token> how; <answer> int 
how <token> param->expire.how; <answer> = 
mnt <token> fp->f_path.mnt; <answer> = 
return autofs_do_expire_multi(sbi->sb, mnt, <token> how); <answer> sbi, 
<token> int autofs_dev_ioctl_ismountpoint(struct file *fp, <answer> static 
struct autofs_sb_info <token> <answer> *sbi, 
struct autofs_dev_ioctl <token> <answer> *param) 
struct path <token> <answer> path; 
<token> char *name; <answer> const 
unsigned <token> type; <answer> int 
unsigned <token> devid, magic; <answer> int 
int err <token> -ENOENT; <answer> = 
#define <token> (cmd - _IOC_NR(AUTOFS_DEV_IOCTL_IOC_FIRST)) <answer> cmd_idx(cmd) 
static <token> lookup_dev_ioctl(unsigned int cmd) <answer> ioctl_fn 
static const <token> _ioctls[] = { <answer> ioctl_fn 
<token> int idx = cmd_idx(cmd); <answer> unsigned 
if (idx >= <token> <answer> ARRAY_SIZE(_ioctls)) 
<token> NULL; <answer> return 
idx <token> array_index_nospec(idx, ARRAY_SIZE(_ioctls)); <answer> = 
return <token> <answer> _ioctls[idx]; 
if (cmd != AUTOFS_DEV_IOCTL_VERSION_CMD <token> <answer> && 
<token> != AUTOFS_DEV_IOCTL_ISMOUNTPOINT_CMD && <answer> cmd 
<token> -EPERM; <answer> return 
if (cmd != AUTOFS_DEV_IOCTL_VERSION_CMD <token> <answer> && 
cmd != AUTOFS_DEV_IOCTL_OPENMOUNT_CMD <token> <answer> && 
cmd <token> AUTOFS_DEV_IOCTL_CLOSEMOUNT_CMD) { <answer> != 
<token> super_block *sb; <answer> struct 
fp <token> fget(param->ioctlfd); <answer> = 
if <token> { <answer> (!fp) 
if (cmd == <token> <answer> AUTOFS_DEV_IOCTL_ISMOUNTPOINT_CMD) 
<token> cont; <answer> goto 
err <token> -EBADF; <answer> = 
goto <token> <answer> out; 
sb <token> file_inode(fp)->i_sb; <answer> = 
if (sb->s_type != <token> { <answer> &autofs_fs_type) 
err = <token> <answer> -EINVAL; 
<token> out; <answer> goto 
sbi <token> autofs_sbi(sb); <answer> = 
if <token> && <answer> (!autofs_oz_mode(sbi) 
cmd != <token> { <answer> AUTOFS_DEV_IOCTL_CATATONIC_CMD) 
err <token> -EACCES; <answer> = 
goto <token> <answer> out; 
err = fn(fp, <token> param); <answer> sbi, 
if <token> <answer> (fp) 
if (err >= <token> && copy_to_user(user, param, AUTOFS_DEV_IOCTL_SIZE)) <answer> 0 
err = <token> <answer> -EFAULT; 
return <token> <answer> err; 
static long autofs_dev_ioctl(struct file *file, <token> int command, <answer> unsigned 
unsigned <token> u) <answer> long 
<token> err; <answer> int 
err = <token> (struct autofs_dev_ioctl __user *) u); <answer> _autofs_dev_ioctl(command, 
return <token> err; <answer> (long) 
#ifdef <token> <answer> CONFIG_COMPAT 
static <token> autofs_dev_ioctl_compat(struct file *file, unsigned int command, <answer> long 
unsigned <token> u) <answer> long 
return autofs_dev_ioctl(file, <token> (unsigned long) compat_ptr(u)); <answer> command, 
#define autofs_dev_ioctl_compat <token> <answer> NULL 
static const struct <token> _dev_ioctl_fops = { <answer> file_operations 
<token> = autofs_dev_ioctl, <answer> .unlocked_ioctl 
.compat_ioctl <token> autofs_dev_ioctl_compat, <answer> = 
.owner <token> THIS_MODULE, <answer> = 
.llseek <token> noop_llseek, <answer> = 
static struct <token> _autofs_dev_ioctl_misc = { <answer> miscdevice 
<token> = AUTOFS_MINOR, <answer> .minor 
<token> = AUTOFS_DEVICE_NAME, <answer> .name 
<token> = &_dev_ioctl_fops, <answer> .fops 
<token> = 0644, <answer> .mode 
<token> <linux/module.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/rtc.h> 
#include <token> <answer> <linux/bcd.h> 
#include <token> <answer> <linux/mfd/rk808.h> 
<token> <linux/platform_device.h> <answer> #include 
#define BIT_RTC_CTRL_REG_RTC_GET_TIME <token> <answer> BIT(6) 
<token> BIT_RTC_CTRL_REG_RTC_READSEL_M BIT(7) <answer> #define 
<token> BIT_RTC_INTERRUPTS_REG_IT_ALARM_M BIT(3) <answer> #define 
<token> RTC_STATUS_MASK 0xFE <answer> #define 
#define <token> 0x7F <answer> SECONDS_REG_MSK 
<token> MINUTES_REG_MAK 0x7F <answer> #define 
<token> HOURS_REG_MSK 0x3F <answer> #define 
#define DAYS_REG_MSK <token> <answer> 0x3F 
#define MONTHS_REG_MSK <token> <answer> 0x1F 
#define YEARS_REG_MSK <token> <answer> 0xFF 
#define <token> 0x7 <answer> WEEKS_REG_MSK 
static <token> nov2dec_transitions(struct rtc_time *tm) <answer> time64_t 
return (tm->tm_year + 1900) - 2016 + (tm->tm_mon + 1 > 11 ? 1 : <token> <answer> 0); 
<token> void rockchip_to_gregorian(struct rtc_time *tm) <answer> static 
ret = regmap_update_bits(rk808_rtc->regmap, <token> <answer> rk808_rtc->creg->ctrl_reg, 
<token> (ret) { <answer> if 
dev_err(dev, "Failed <token> update bits rtc_ctrl: %d\n", ret); <answer> to 
return <token> <answer> ret; 
ret <token> regmap_bulk_read(rk808_rtc->regmap, rk808_rtc->creg->seconds_reg, <answer> = 
<token> NUM_TIME_REGS); <answer> rtc_data, 
if (ret) <token> <answer> { 
dev_err(dev, "Failed to <token> read rtc_data: %d\n", ret); <answer> bulk 
return <token> <answer> ret; 
tm->tm_sec = bcd2bin(rtc_data[0] <token> SECONDS_REG_MSK); <answer> & 
tm->tm_min <token> bcd2bin(rtc_data[1] & MINUTES_REG_MAK); <answer> = 
tm->tm_hour = <token> & HOURS_REG_MSK); <answer> bcd2bin(rtc_data[2] 
tm->tm_mday = <token> & DAYS_REG_MSK); <answer> bcd2bin(rtc_data[3] 
tm->tm_mon = (bcd2bin(rtc_data[4] & MONTHS_REG_MSK)) <token> 1; <answer> - 
tm->tm_year = <token> & YEARS_REG_MSK)) + 100; <answer> (bcd2bin(rtc_data[5] 
<token> = bcd2bin(rtc_data[6] & WEEKS_REG_MSK); <answer> tm->tm_wday 
dev_dbg(dev, "RTC date/time %ptRd(%d) %ptRt\n", tm, tm->tm_wday, <token> <answer> tm); 
<token> ret; <answer> return 
static <token> rk808_alarm_irq(int irq, void *data) <answer> irqreturn_t 
struct <token> *rk808_rtc = data; <answer> rk808_rtc 
int <token> <answer> ret; 
ret <token> regmap_write(rk808_rtc->regmap, rk808_rtc->creg->status_reg, <answer> = 
if (ret) <token> <answer> { 
"%s:Failed to <token> RTC status: %d\n", __func__, ret); <answer> update 
return <token> <answer> ret; 
rtc_update_irq(rk808_rtc->rtc, 1, <token> | RTC_AF); <answer> RTC_IRQF 
<token> __func__, irq); <answer> "%s:irq=%d\n", 
return <token> <answer> IRQ_HANDLED; 
static const struct <token> rk808_rtc_ops = { <answer> rtc_class_ops 
.read_time = <token> <answer> rk808_rtc_readtime, 
.set_time <token> rk808_rtc_set_time, <answer> = 
<token> = rk808_rtc_readalarm, <answer> .read_alarm 
.set_alarm = <token> <answer> rk808_rtc_setalarm, 
.alarm_irq_enable <token> rk808_rtc_alarm_irq_enable, <answer> = 
<token> CONFIG_PM_SLEEP <answer> #ifdef 
static int rk808_rtc_resume(struct <token> *dev) <answer> device 
struct rk808_rtc *rk808_rtc = <token> <answer> dev_get_drvdata(dev); 
if <token> <answer> (device_may_wakeup(dev)) 
return <token> <answer> 0; 
static <token> <answer> SIMPLE_DEV_PM_OPS(rk808_rtc_pm_ops, 
<token> rk808_rtc_resume); <answer> rk808_rtc_suspend, 
static struct rk_rtc_compat_reg rk808_creg <token> { <answer> = 
.ctrl_reg = <token> <answer> RK808_RTC_CTRL_REG, 
<token> = RK808_RTC_STATUS_REG, <answer> .status_reg 
<token> = RK808_ALARM_SECONDS_REG, <answer> .alarm_seconds_reg 
.int_reg <token> RK808_RTC_INT_REG, <answer> = 
.seconds_reg = <token> <answer> RK808_SECONDS_REG, 
<token> struct rk_rtc_compat_reg rk817_creg = { <answer> static 
.ctrl_reg = <token> <answer> RK817_RTC_CTRL_REG, 
.status_reg = <token> <answer> RK817_RTC_STATUS_REG, 
.alarm_seconds_reg <token> RK817_ALARM_SECONDS_REG, <answer> = 
.int_reg <token> RK817_RTC_INT_REG, <answer> = 
.seconds_reg <token> RK817_SECONDS_REG, <answer> = 
static int rk808_rtc_probe(struct <token> *pdev) <answer> platform_device 
struct rk808 <token> = dev_get_drvdata(pdev->dev.parent); <answer> *rk808 
struct rk808_rtc <token> <answer> *rk808_rtc; 
int <token> <answer> ret; 
<token> = devm_kzalloc(&pdev->dev, sizeof(*rk808_rtc), GFP_KERNEL); <answer> rk808_rtc 
if (rk808_rtc <token> NULL) <answer> == 
<token> -ENOMEM; <answer> return 
switch <token> { <answer> (rk808->variant) 
<token> RK809_ID: <answer> case 
<token> RK817_ID: <answer> case 
<token> = &rk817_creg; <answer> rk808_rtc->creg 
rk808_rtc->creg = <token> <answer> &rk808_creg; 
platform_set_drvdata(pdev, <token> <answer> rk808_rtc); 
rk808_rtc->regmap <token> dev_get_regmap(pdev->dev.parent, NULL); <answer> = 
<token> (!rk808_rtc->regmap) <answer> if 
<token> -ENODEV; <answer> return 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/security.h> 
<token> <keys/keyring-type.h> <answer> #include 
<token> "internal.h" <answer> #include 
unsigned key_gc_delay = <token> * 60; <answer> 5 
static void key_garbage_collector(struct <token> *work); <answer> work_struct 
DECLARE_WORK(key_gc_work, <token> <answer> key_garbage_collector); 
static void <token> timer_list *); <answer> key_gc_timer_func(struct 
<token> DEFINE_TIMER(key_gc_timer, key_gc_timer_func); <answer> static 
static time64_t key_gc_next_run <token> TIME64_MAX; <answer> = 
static <token> key_type *key_gc_dead_keytype; <answer> struct 
<token> unsigned long key_gc_flags; <answer> static 
struct key_type key_type_dead <token> { <answer> = 
<token> = ".dead", <answer> .name 
void <token> gc_at) <answer> key_schedule_gc(time64_t 
unsigned <token> expires; <answer> long 
time64_t now <token> ktime_get_real_seconds(); <answer> = 
kenter("%lld", gc_at <token> now); <answer> - 
if (gc_at <= now <token> test_bit(KEY_GC_REAP_KEYTYPE, &key_gc_flags)) { <answer> || 
<token> else if (gc_at < key_gc_next_run) { <answer> } 
key_gc_next_run <token> gc_at; <answer> = 
expires = jiffies + (gc_at - now) * <token> <answer> HZ; 
mod_timer(&key_gc_timer, <token> <answer> expires); 
void key_set_expiry(struct key *key, time64_t <token> <answer> expiry) 
key->expiry = <token> <answer> expiry; 
if (expiry != <token> { <answer> TIME64_MAX) 
if (!(key->type->flags <token> KEY_TYPE_INSTANT_REAP)) <answer> & 
expiry += <token> <answer> key_gc_delay; 
void <token> <answer> key_schedule_gc_links(void) 
set_bit(KEY_GC_KEY_EXPIRED, <token> <answer> &key_gc_flags); 
static void key_gc_timer_func(struct timer_list <token> <answer> *unused) 
key_gc_next_run = <token> <answer> TIME64_MAX; 
void key_gc_keytype(struct key_type <token> <answer> *ktype) 
kenter("%s", <token> <answer> ktype->name); 
<token> = ktype; <answer> key_gc_dead_keytype 
<token> &key_gc_flags); <answer> set_bit(KEY_GC_REAPING_KEYTYPE, 
set_bit(KEY_GC_REAP_KEYTYPE, <token> <answer> &key_gc_flags); 
wait_on_bit(&key_gc_flags, <token> <answer> KEY_GC_REAPING_KEYTYPE, 
<token> = NULL; <answer> key_gc_dead_keytype 
static noinline void key_gc_unused_keys(struct list_head <token> <answer> *keys) 
while <token> { <answer> (!list_empty(keys)) 
struct <token> *key = <answer> key 
list_entry(keys->next, struct <token> graveyard_link); <answer> key, 
<token> state = key->state; <answer> short 
<token> %u", key->serial); <answer> kdebug("- 
<token> CONFIG_KEY_NOTIFICATIONS <answer> #ifdef 
<token> key->serial); <answer> remove_watch_list(key->watchers, 
<token> = NULL; <answer> key->watchers 
static void key_garbage_collector(struct <token> *work) <answer> work_struct 
<token> LIST_HEAD(graveyard); <answer> static 
<token> = rb_first(&key_serial_tree); <answer> cursor 
while <token> { <answer> (cursor) 
key = <token> struct key, serial_node); <answer> rb_entry(cursor, 
cursor <token> rb_next(cursor); <answer> = 
if <token> == 0) <answer> (refcount_read(&key->usage) 
<token> found_unreferenced_key; <answer> goto 
if (unlikely(gc_state & <token> { <answer> KEY_GC_REAPING_DEAD_1)) 
<token> (key->type == key_gc_dead_keytype) { <answer> if 
gc_state <token> KEY_GC_FOUND_DEAD_KEY; <answer> |= 
set_bit(KEY_FLAG_DEAD, <token> <answer> &key->flags); 
key->perm = <token> <answer> 0; 
<token> skip_dead_key; <answer> goto 
} else if (key->type == &key_type_keyring <token> <answer> && 
<token> { <answer> key->restrict_link) 
goto <token> <answer> found_restricted_keyring; 
<token> = key->expiry; <answer> expiry 
if (expiry != TIME64_MAX) <token> <answer> { 
if (!(key->type->flags & <token> <answer> KEY_TYPE_INSTANT_REAP)) 
expiry <token> key_gc_delay; <answer> += 
if <token> > limit && expiry < new_timer) { <answer> (expiry 
kdebug("will <token> %x in %lld", <answer> expire 
key_serial(key), <token> - limit); <answer> key->expiry 
new_timer <token> key->expiry; <answer> = 
if (unlikely(gc_state & <token> <answer> KEY_GC_REAPING_DEAD_2)) 
if <token> == key_gc_dead_keytype) <answer> (key->type 
<token> |= KEY_GC_FOUND_DEAD_KEY; <answer> gc_state 
if ((gc_state <token> KEY_GC_REAPING_LINKS) || <answer> & 
<token> & KEY_GC_REAPING_DEAD_2)) { <answer> unlikely(gc_state 
<token> (key->type == &key_type_keyring) <answer> if 
<token> found_keyring; <answer> goto 
if (unlikely(gc_state <token> KEY_GC_REAPING_DEAD_3)) <answer> & 
<token> (key->type == key_gc_dead_keytype) <answer> if 
goto <token> <answer> destroy_dead_key; 
if (spin_is_contended(&key_serial_lock) || <token> <answer> need_resched()) 
goto <token> <answer> contended; 
if <token> { <answer> (cursor) 
goto <token> <answer> continue_scanning; 
<token> complete"); <answer> kdebug("pass 
if (new_timer != <token> { <answer> TIME64_MAX) 
new_timer += <token> <answer> key_gc_delay; 
if (unlikely(gc_state & <token> || <answer> KEY_GC_REAPING_DEAD_2) 
<token> { <answer> !list_empty(&graveyard)) 
kdebug("gc <token> <answer> sync"); 
if (!list_empty(&graveyard)) <token> <answer> { 
<token> keys"); <answer> kdebug("gc 
if <token> & (KEY_GC_REAPING_DEAD_1 | <answer> (unlikely(gc_state 
KEY_GC_REAPING_DEAD_2))) <token> <answer> { 
<token> (!(gc_state & KEY_GC_FOUND_DEAD_KEY)) { <answer> if 
kdebug("dead <token> <answer> short"); 
<token> &= ~(KEY_GC_REAPING_DEAD_1 | KEY_GC_REAPING_DEAD_2); <answer> gc_state 
gc_state |= <token> <answer> KEY_GC_REAPING_DEAD_3; 
} <token> { <answer> else 
gc_state |= <token> <answer> KEY_GC_REAP_AGAIN; 
<token> (unlikely(gc_state & KEY_GC_REAPING_DEAD_3)) { <answer> if 
<token> wake"); <answer> kdebug("dead 
<token> &key_gc_flags); <answer> clear_bit(KEY_GC_REAPING_KEYTYPE, 
<token> KEY_GC_REAPING_KEYTYPE); <answer> wake_up_bit(&key_gc_flags, 
if <token> & KEY_GC_REAP_AGAIN) <answer> (gc_state 
<token> [end %x]", gc_state); <answer> kleave(" 
kdebug("unrefd <token> %d", key->serial); <answer> key 
<token> &key_serial_tree); <answer> rb_erase(&key->serial_node, 
list_add_tail(&key->graveyard_link, <token> <answer> &graveyard); 
gc_state <token> KEY_GC_REAP_AGAIN; <answer> |= 
goto <token> <answer> maybe_resched; 
<token> key_gc_dead_keytype); <answer> keyring_restriction_gc(key, 
<token> maybe_resched; <answer> goto 
<token> limit); <answer> keyring_gc(key, 
<token> maybe_resched; <answer> goto 
kdebug("destroy key <token> key->serial); <answer> %d", 
key->type <token> &key_type_dead; <answer> = 
<token> (key_gc_dead_keytype->destroy) <answer> if 
memset(&key->payload, KEY_DESTROY, <token> <answer> sizeof(key->payload)); 
<token> maybe_resched; <answer> goto 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/pci.h> 
<token> <linux/blkdev.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/dma-mapping.h> 
<token> <linux/device.h> <answer> #include 
<token> <linux/dmi.h> <answer> #include 
<token> <linux/gfp.h> <answer> #include 
<token> <scsi/scsi_host.h> <answer> #include 
#include <token> <answer> <scsi/scsi_cmnd.h> 
<token> <linux/libata.h> <answer> #include 
#include <token> <answer> "ahci.h" 
<token> DRV_NAME "acard-ahci" <answer> #define 
#define DRV_VERSION <token> <answer> "1.0" 
#define <token> 128 <answer> ACARD_AHCI_RX_FIS_SZ 
<token> { <answer> enum 
<token> = 5, <answer> AHCI_PCI_BAR 
enum board_ids <token> <answer> { 
<token> acard_sg { <answer> struct 
__le32 <token> <answer> addr; 
<token> addr_hi; <answer> __le32 
__le32 <token> <answer> reserved; 
ctl <token> readl(mmio + HOST_CTL); <answer> = 
ctl &= <token> <answer> ~HOST_IRQ_EN; 
writel(ctl, <token> + HOST_CTL); <answer> mmio 
for_each_sg(qc->sg, sg, <token> si) { <answer> qc->n_elem, 
dma_addr_t addr = <token> <answer> sg_dma_address(sg); 
<token> sg_len = sg_dma_len(sg); <answer> u32 
acard_sg[si].addr <token> cpu_to_le32(addr & 0xffffffff); <answer> = 
acard_sg[si].addr_hi = cpu_to_le32((addr >> 16) >> <token> <answer> 16); 
acard_sg[si].size <token> cpu_to_le32(sg_len); <answer> = 
<token> = si; <answer> last_si 
cmd_tbl = <token> + qc->hw_tag * AHCI_CMD_TBL_SZ; <answer> pp->cmd_tbl 
<token> qc->dev->link->pmp, 1, cmd_tbl); <answer> ata_tf_to_fis(&qc->tf, 
if <token> { <answer> (is_atapi) 
memset(cmd_tbl + <token> 0, 32); <answer> AHCI_CMD_TBL_CDB, 
memcpy(cmd_tbl + AHCI_CMD_TBL_CDB, qc->cdb, <token> <answer> qc->dev->cdb_len); 
if <token> & ATA_QCFLAG_DMAMAP) <answer> (qc->flags 
<token> cmd_tbl); <answer> acard_ahci_fill_sg(qc, 
opts = cmd_fis_len | (qc->dev->link->pmp <token> 12); <answer> << 
if <token> & ATA_TFLAG_WRITE) <answer> (qc->tf.flags 
opts <token> AHCI_CMD_WRITE; <answer> |= 
if <token> <answer> (is_atapi) 
opts |= AHCI_CMD_ATAPI | <token> <answer> AHCI_CMD_PREFETCH; 
<token> qc->hw_tag, opts); <answer> ahci_fill_cmd_slot(pp, 
return <token> <answer> AC_ERR_OK; 
static void acard_ahci_qc_fill_rtf(struct ata_queued_cmd <token> <answer> *qc) 
struct ahci_port_priv *pp = <token> <answer> qc->ap->private_data; 
u8 *rx_fis = <token> <answer> pp->rx_fis; 
if <token> <answer> (pp->fbs_enabled) 
rx_fis += qc->dev->link->pmp <token> ACARD_AHCI_RX_FIS_SZ; <answer> * 
if (qc->tf.protocol == ATA_PROT_PIO <token> qc->dma_dir == DMA_FROM_DEVICE && <answer> && 
!(qc->flags & <token> { <answer> ATA_QCFLAG_EH)) 
<token> + RX_FIS_PIO_SETUP, &qc->result_tf); <answer> ata_tf_from_fis(rx_fis 
qc->result_tf.status <token> (rx_fis + RX_FIS_PIO_SETUP)[15]; <answer> = 
} <token> <answer> else 
<token> + RX_FIS_D2H_REG, &qc->result_tf); <answer> ata_tf_from_fis(rx_fis 
static <token> acard_ahci_port_start(struct ata_port *ap) <answer> int 
struct ahci_host_priv *hpriv <token> ap->host->private_data; <answer> = 
struct device *dev = <token> <answer> ap->host->dev; 
<token> ahci_port_priv *pp; <answer> struct 
<token> *mem; <answer> void 
<token> mem_dma; <answer> dma_addr_t 
size_t <token> rx_fis_sz; <answer> dma_sz, 
pp <token> devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL); <answer> = 
if <token> <answer> (!pp) 
<token> -ENOMEM; <answer> return 
pp->cmd_slot <token> mem; <answer> = 
pp->cmd_slot_dma = <token> <answer> mem_dma; 
mem += <token> <answer> AHCI_CMD_SLOT_SZ; 
mem_dma += <token> <answer> AHCI_CMD_SLOT_SZ; 
pp->rx_fis <token> mem; <answer> = 
pp->rx_fis_dma = <token> <answer> mem_dma; 
<token> += rx_fis_sz; <answer> mem 
<token> += rx_fis_sz; <answer> mem_dma 
pp->cmd_tbl = <token> <answer> mem; 
pp->cmd_tbl_dma = <token> <answer> mem_dma; 
pp->intr_mask = <token> <answer> DEF_PORT_IRQ; 
<token> = pp; <answer> ap->private_data 
rc = pcim_iomap_regions_request_all(pdev, 1 <token> AHCI_PCI_BAR, DRV_NAME); <answer> << 
if (rc == <token> <answer> -EBUSY) 
if <token> <answer> (rc) 
return <token> <answer> rc; 
hpriv = <token> sizeof(*hpriv), GFP_KERNEL); <answer> devm_kzalloc(dev, 
<token> (!hpriv) <answer> if 
<token> -ENOMEM; <answer> return 
hpriv->irq = <token> <answer> pdev->irq; 
hpriv->flags |= <token> long)pi.private_data; <answer> (unsigned 
if <token> & AHCI_HFLAG_NO_MSI)) <answer> (!(hpriv->flags 
<token> = pcim_iomap_table(pdev)[AHCI_PCI_BAR]; <answer> hpriv->mmio 
n_ports = max(ahci_nr_ports(hpriv->cap), <token> <answer> fls(hpriv->port_map)); 
<token> = ata_host_alloc_pinfo(&pdev->dev, ppi, n_ports); <answer> host 
if <token> <answer> (!host) 
<token> -ENOMEM; <answer> return 
host->private_data = <token> <answer> hpriv; 
<token> (!(hpriv->cap & HOST_CAP_SSS) || ahci_ignore_sss) <answer> if 
host->flags |= <token> <answer> ATA_HOST_PARALLEL_SCAN; 
<token> "ahci: SSS flag set, parallel bus scan disabled\n"); <answer> printk(KERN_INFO 
for (i = 0; i < <token> i++) { <answer> host->n_ports; 
struct ata_port <token> = host->ports[i]; <answer> *ap 
<token> AHCI_PCI_BAR, -1, "abar"); <answer> ata_port_pbar_desc(ap, 
<token> AHCI_PCI_BAR, <answer> ata_port_pbar_desc(ap, 
0x100 + <token> * 0x80, "port"); <answer> ap->port_no 
#include <token> <answer> <drm/drm_file.h> 
#include <token> <answer> "radeon.h" 
static <token> radeon_debugfs_sa_init(struct radeon_device *rdev); <answer> void 
int radeon_ib_get(struct <token> *rdev, int ring, <answer> radeon_device 
struct radeon_ib <token> struct radeon_vm *vm, <answer> *ib, 
<token> size) <answer> unsigned 
int <token> <answer> r; 
r = radeon_sa_bo_new(&rdev->ring_tmp_bo, &ib->sa_bo, <token> 256); <answer> size, 
<token> (r) { <answer> if 
<token> "failed to get a new IB (%d)\n", r); <answer> dev_err(rdev->dev, 
<token> r; <answer> return 
ib->ring <token> ring; <answer> = 
ib->fence <token> NULL; <answer> = 
ib->ptr = <token> <answer> radeon_sa_bo_cpu_addr(ib->sa_bo); 
<token> = vm; <answer> ib->vm 
if (vm) <token> <answer> { 
<token> = drm_suballoc_soffset(ib->sa_bo) + RADEON_VA_IB_OFFSET; <answer> ib->gpu_addr 
<token> else { <answer> } 
ib->gpu_addr <token> radeon_sa_bo_gpu_addr(ib->sa_bo); <answer> = 
<token> = false; <answer> ib->is_const_ib 
return <token> <answer> 0; 
void radeon_ib_free(struct radeon_device <token> struct radeon_ib *ib) <answer> *rdev, 
radeon_sync_free(rdev, <token> ib->fence); <answer> &ib->sync, 
radeon_sa_bo_free(&ib->sa_bo, <token> <answer> ib->fence); 
<token> radeon_ib_schedule(struct radeon_device *rdev, struct radeon_ib *ib, <answer> int 
struct <token> *const_ib, bool hdp_flush) <answer> radeon_ib 
<token> radeon_ring *ring = &rdev->ring[ib->ring]; <answer> struct 
int r <token> 0; <answer> = 
<token> (!ib->length_dw || !ring->ready) { <answer> if 
int <token> radeon_device *rdev) <answer> radeon_ib_pool_init(struct 
int <token> <answer> r; 
<token> (rdev->ib_pool_ready) { <answer> if 
<token> 0; <answer> return 
if (rdev->family >= CHIP_BONAIRE) <token> <answer> { 
r <token> radeon_sa_bo_manager_init(rdev, &rdev->ring_tmp_bo, <answer> = 
RADEON_IB_POOL_SIZE*64*1024, <token> <answer> 256, 
<token> else { <answer> } 
r <token> radeon_sa_bo_manager_init(rdev, &rdev->ring_tmp_bo, <answer> = 
<token> 256, <answer> RADEON_IB_POOL_SIZE*64*1024, 
<token> 0); <answer> RADEON_GEM_DOMAIN_GTT, 
if (r) <token> <answer> { 
<token> r; <answer> return 
<token> = radeon_sa_bo_manager_start(rdev, &rdev->ring_tmp_bo); <answer> r 
if (r) <token> <answer> { 
<token> r; <answer> return 
<token> = true; <answer> rdev->ib_pool_ready 
<token> 0; <answer> return 
<token> radeon_ib_pool_fini(struct radeon_device *rdev) <answer> void 
<token> (rdev->ib_pool_ready) { <answer> if 
radeon_sa_bo_manager_suspend(rdev, <token> <answer> &rdev->ring_tmp_bo); 
<token> &rdev->ring_tmp_bo); <answer> radeon_sa_bo_manager_fini(rdev, 
rdev->ib_pool_ready = <token> <answer> false; 
int radeon_ib_ring_tests(struct <token> *rdev) <answer> radeon_device 
unsigned <token> <answer> i; 
int <token> <answer> r; 
for <token> = 0; i < RADEON_NUM_RINGS; ++i) { <answer> (i 
struct radeon_ring *ring <token> &rdev->ring[i]; <answer> = 
<token> (!ring->ready) <answer> if 
r <token> radeon_ib_test(rdev, i, ring); <answer> = 
<token> (r) { <answer> if 
radeon_fence_driver_force_completion(rdev, <token> <answer> i); 
ring->ready <token> false; <answer> = 
<token> = false; <answer> rdev->needs_reset 
<token> (i == RADEON_RING_TYPE_GFX_INDEX) { <answer> if 
<token> defined(CONFIG_DEBUG_FS) <answer> #if 
static <token> radeon_debugfs_sa_info_show(struct seq_file *m, void *unused) <answer> int 
<token> radeon_device *rdev = m->private; <answer> struct 
<token> m); <answer> radeon_sa_bo_dump_debug_info(&rdev->ring_tmp_bo, 
<token> 0; <answer> return 
static void radeon_debugfs_sa_init(struct <token> *rdev) <answer> radeon_device 
#if <token> <answer> defined(CONFIG_DEBUG_FS) 
struct dentry <token> = rdev->ddev->primary->debugfs_root; <answer> *root 
debugfs_create_file("radeon_sa_info", 0444, <token> rdev, <answer> root, 
<token> "bcachefs.h" <answer> #include 
<token> "bkey_methods.h" <answer> #include 
#include <token> <answer> "nocow_locking.h" 
<token> "util.h" <answer> #include 
#include <token> <answer> <linux/closure.h> 
bool <token> bucket_nocow_lock_table *t, struct bpos bucket) <answer> bch2_bucket_nocow_is_locked(struct 
<token> dev_bucket = bucket_to_u64(bucket); <answer> u64 
struct nocow_lock_bucket *l = <token> dev_bucket); <answer> bucket_nocow_lock(t, 
<token> i; <answer> unsigned 
for (i = 0; i < ARRAY_SIZE(l->b); <token> <answer> i++) 
if (l->b[i] == <token> && atomic_read(&l->l[i])) <answer> dev_bucket 
<token> true; <answer> return 
<token> false; <answer> return 
#define sign(v) (v < 0 ? -1 <token> v > 0 ? 1 : 0) <answer> : 
void bch2_bucket_nocow_unlock(struct <token> *t, struct bpos bucket, int flags) <answer> bucket_nocow_lock_table 
u64 dev_bucket = <token> <answer> bucket_to_u64(bucket); 
struct nocow_lock_bucket <token> = bucket_nocow_lock(t, dev_bucket); <answer> *l 
<token> lock_val = flags ? 1 : -1; <answer> int 
unsigned <token> <answer> i; 
for (i = 0; i <token> ARRAY_SIZE(l->b); i++) <answer> < 
if (l->b[i] <token> dev_bucket) { <answer> == 
<token> v = atomic_sub_return(lock_val, &l->l[i]); <answer> int 
BUG_ON(v <token> sign(v) != lock_val); <answer> && 
<token> (!v) <answer> if 
bool __bch2_bucket_nocow_trylock(struct <token> *l, <answer> nocow_lock_bucket 
<token> dev_bucket, int flags) <answer> u64 
int v, lock_val = <token> ? 1 : -1; <answer> flags 
<token> i; <answer> unsigned 
for (i = 0; i < <token> i++) <answer> ARRAY_SIZE(l->b); 
if (l->b[i] <token> dev_bucket) <answer> == 
<token> got_entry; <answer> goto 
for (i <token> 0; i < ARRAY_SIZE(l->b); i++) <answer> = 
if <token> { <answer> (!atomic_read(&l->l[i])) 
l->b[i] <token> dev_bucket; <answer> = 
<token> take_lock; <answer> goto 
<token> false; <answer> return 
v = <token> <answer> atomic_read(&l->l[i]); 
if (lock_val > 0 ? v <token> 0 : v > 0) <answer> < 
<token> fail; <answer> goto 
<token> = atomic_read(&l->l[i]); <answer> v 
<token> <linux/clk.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/dma-mapping.h> <answer> #include 
#include <token> <answer> <linux/host1x.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_graph.h> 
<token> <linux/of_platform.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/pm_runtime.h> <answer> #include 
#include <token> <answer> <linux/reset.h> 
#include <token> <answer> <drm/drm_atomic.h> 
#include <token> <answer> <drm/drm_atomic_helper.h> 
<token> <drm/drm_blend.h> <answer> #include 
#include <token> <answer> <drm/drm_fourcc.h> 
#include <token> <answer> <drm/drm_framebuffer.h> 
#include <token> <answer> <drm/drm_probe_helper.h> 
<token> "drm.h" <answer> #include 
<token> "dc.h" <answer> #include 
<token> "plane.h" <answer> #include 
<token> NFB 24 <answer> #define 
static const u32 tegra_shared_plane_formats[] = <token> <answer> { 
DRM_FORMAT_MOD_NVIDIA_16BX2_BLOCK(0) | <token> <answer> DRM_FORMAT_MOD_NVIDIA_SECTOR_LAYOUT, 
DRM_FORMAT_MOD_NVIDIA_16BX2_BLOCK(1) <token> DRM_FORMAT_MOD_NVIDIA_SECTOR_LAYOUT, <answer> | 
DRM_FORMAT_MOD_NVIDIA_16BX2_BLOCK(2) <token> DRM_FORMAT_MOD_NVIDIA_SECTOR_LAYOUT, <answer> | 
<token> | DRM_FORMAT_MOD_NVIDIA_SECTOR_LAYOUT, <answer> DRM_FORMAT_MOD_NVIDIA_16BX2_BLOCK(3) 
DRM_FORMAT_MOD_NVIDIA_16BX2_BLOCK(4) <token> DRM_FORMAT_MOD_NVIDIA_SECTOR_LAYOUT, <answer> | 
<token> | DRM_FORMAT_MOD_NVIDIA_SECTOR_LAYOUT, <answer> DRM_FORMAT_MOD_NVIDIA_16BX2_BLOCK(5) 
for (i = 0; i < hub->soc->num_wgrps; i++) <token> <answer> { 
<token> tegra_windowgroup *wgrp = &hub->wgrps[i]; <answer> struct 
for (i = 0; i < hub->soc->num_wgrps; i++) <token> <answer> { 
<token> tegra_windowgroup *wgrp = &hub->wgrps[i]; <answer> struct 
if <token> && owner == OWNER_MASK) <answer> (old 
dev_dbg(dev, "window %u not owned by head %u but %u\n", <token> <answer> index, 
<token> owner); <answer> old->pipe, 
value <token> ~OWNER_MASK; <answer> &= 
<token> (new) <answer> if 
value <token> OWNER(new->pipe); <answer> |= 
value |= <token> <answer> OWNER_MASK; 
tegra_dc_writel(dc, value, <token> <answer> offset); 
plane->dc = <token> <answer> new; 
return <token> <answer> 0; 
static void tegra_shared_plane_setup_scaler(struct tegra_plane <token> <answer> *plane) 
static const unsigned int coeffs[192] = <token> <answer> { 
<token> 0x3c70e400, 0x3bb037e4, 0x0c51cc9c, <answer> 0x00000000, 
0x00100001, 0x3bf0dbfa, 0x3d00f406, <token> <answer> 0x3fe003ff, 
<token> 0x3b80cbf5, 0x3da1040d, 0x3fb003fe, <answer> 0x00300002, 
0x00400002, <token> 0x3e511015, 0x3f9003fc, <answer> 0x3b20bff1, 
0x00500002, 0x3ad0b3ed, 0x3f21201d, <token> <answer> 0x3f5003fb, 
<token> 0x3aa0a3e9, 0x3ff13026, 0x3f2007f9, <answer> 0x00500003, 
0x00500403, <token> 0x00e1402f, 0x3ee007f7, <answer> 0x3a7097e6, 
<token> 0x3a608be4, 0x01d14c38, 0x3ea00bf6, <answer> 0x00500403, 
0x00500403, <token> 0x02e15c42, 0x3e500ff4, <answer> 0x3a507fe2, 
<token> 0x3a6073e1, 0x03f16c4d, 0x3e000ff2, <answer> 0x00500402, 
0x00400402, <token> 0x05117858, 0x3db013f0, <answer> 0x3a706be0, 
0x00300402, <token> 0x06318863, 0x3d6017ee, <answer> 0x3a905fe0, 
<token> 0x3ab057e0, 0x0771986e, 0x3d001beb, <answer> 0x00300402, 
0x00200001, 0x3af04fe1, 0x08a1a47a, <token> <answer> 0x3cb023e9, 
<token> 0x3b2047e2, 0x09e1b485, 0x3c6027e7, <answer> 0x00100001, 
0x00100000, 0x3b703fe2, <token> 0x3c002fe6, <answer> 0x0b11c091, 
<token> 0x0391103f, 0x3ff0a014, 0x0811606c, <answer> 0x3f203800, 
0x3f2037ff, 0x0351083c, <token> 0x3f203c00, <answer> 0x03e11842, 
0x3f302fff, <token> 0x04311c45, 0x3f104401, <answer> 0x03010439, 
0x3f302fff, <token> 0x04812448, 0x3f104802, <answer> 0x02c0fc35, 
0x3f4027ff, 0x0270f832, <token> 0x3f205003, <answer> 0x04c1284b, 
0x3f4023ff, <token> 0x0511304e, 0x3f205403, <answer> 0x0230f030, 
0x3f601fff, <token> 0x05613451, 0x3f205c04, <answer> 0x01f0e82d, 
0x3f701bfe, 0x01b0e02a, <token> 0x3f306006, <answer> 0x05a13c54, 
0x3f7017fe, <token> 0x05f14057, 0x3f406807, <answer> 0x0170d827, 
0x3f8017ff, 0x0140d424, 0x0641445a, <token> <answer> 0x3f406c08, 
0x3fa013ff, <token> 0x0681485d, 0x3f507409, <answer> 0x0100cc22, 
0x3fa00fff, 0x00d0c41f, <token> 0x3f607c0b, <answer> 0x06d14c60, 
0x3fc00fff, <token> 0x07115063, 0x3f80840c, <answer> 0x0090bc1c, 
0x3fd00bff, 0x0070b41a, <token> 0x3f908c0e, <answer> 0x07515465, 
<token> 0x0040b018, 0x07915868, 0x3fb0900f, <answer> 0x3fe007ff, 
<token> 0x0010a816, 0x07d15c6a, 0x3fd09811, <answer> 0x3ff00400, 
<token> 0x0460f442, 0x0240a827, 0x05c15859, <answer> 0x00a04c0e, 
<token> 0x0440f040, 0x0480fc43, 0x00b05010, <answer> 0x0090440d, 
0x0080400c, <token> 0x04910044, 0x00d05411, <answer> 0x0410ec3e, 
<token> 0x03f0e83d, 0x04b10846, 0x00e05812, <answer> 0x0070380b, 
0x0060340a, 0x03d0e43b, <token> 0x00f06013, <answer> 0x04d10c48, 
0x00503009, 0x03b0e039, <token> 0x01106415, <answer> 0x04e11449, 
0x00402c08, <token> 0x05011c4b, 0x01206c16, <answer> 0x0390d838, 
<token> 0x0370d436, 0x0511204c, 0x01407018, <answer> 0x00302807, 
0x00302406, <token> 0x0531244e, 0x01507419, <answer> 0x0340d034, 
0x00202005, 0x0320cc32, <token> 0x01707c1b, <answer> 0x05412c50, 
0x00101c04, <token> 0x05613451, 0x0180801d, <answer> 0x0300c431, 
0x00101803, <token> 0x05713853, 0x01a0881e, <answer> 0x02e0c02f, 
0x00101002, 0x02b0bc2d, <token> 0x01c08c20, <answer> 0x05814054, 
0x00000c02, 0x02a0b82c, <token> 0x01e09421, <answer> 0x05914455, 
0x00000801, 0x0280b02a, <token> 0x02009c23, <answer> 0x05a14c57, 
0x00000400, 0x0260ac28, 0x05b15458, <token> <answer> 0x0220a025, 
<token> int ratio, row, column; <answer> unsigned 
<token> (ratio = 0; ratio <= 2; ratio++) { <answer> for 
for (row = <token> row <= 15; row++) { <answer> 0; 
<token> (column = 0; column <= 3; column++) { <answer> for 
<token> int index = (ratio << 6) + (row << 2) + column; <answer> unsigned 
<token> value; <answer> u32 
<token> = COEFF_INDEX(index) | COEFF_DATA(coeffs[index]); <answer> value 
tegra_plane_writel(plane, <token> <answer> value, 
static void <token> tegra_dc *dc, <answer> tegra_dc_assign_shared_plane(struct 
struct tegra_plane <token> <answer> *plane) 
<token> value; <answer> u32 
int <token> <answer> err; 
<token> (!tegra_dc_owns_shared_plane(dc, plane)) { <answer> if 
<token> = tegra_shared_plane_set_owner(plane, dc); <answer> err 
<token> (err < 0) <answer> if 
value = tegra_plane_readl(plane, <token> <answer> DC_WIN_CORE_IHUB_LINEBUF_CONFIG); 
value |= <token> <answer> MODE_FOUR_LINES; 
tegra_plane_writel(plane, <token> DC_WIN_CORE_IHUB_LINEBUF_CONFIG); <answer> value, 
<token> = tegra_plane_readl(plane, DC_WIN_CORE_IHUB_WGRP_FETCH_METER); <answer> value 
value <token> SLOTS(1); <answer> = 
<token> value, DC_WIN_CORE_IHUB_WGRP_FETCH_METER); <answer> tegra_plane_writel(plane, 
if <token> > 2) { <answer> (new_plane_state->fb->format->num_planes 
<token> (new_plane_state->fb->pitches[2] != new_plane_state->fb->pitches[1]) { <answer> if 
<token> UV-plane configuration\n"); <answer> DRM_ERROR("unsupported 
<token> -EINVAL; <answer> return 
<token> (WARN_ON(p->dc == NULL)) <answer> if 
p->dc <token> dc; <answer> = 
value = tegra_plane_readl(p, <token> <answer> DC_WIN_WIN_OPTIONS); 
value <token> ~WIN_ENABLE; <answer> &= 
tegra_plane_writel(p, <token> DC_WIN_WIN_OPTIONS); <answer> value, 
tegra_dc_remove_shared_plane(dc, <token> <answer> p); 
static inline <token> compute_phase_incr(fixed20_12 in, unsigned int out) <answer> u32 
u64 tmp, <token> tmp2; <answer> tmp1, 
tmp <token> (u64)dfixed_trunc(in); <answer> = 
<token> = (u64)out; <answer> tmp2 
tmp1 = <token> << NFB) + (tmp2 >> 1); <answer> (tmp 
do_div(tmp1, <token> <answer> tmp2); 
<token> lower_32_bits(tmp1); <answer> return 
static void tegra_shared_plane_atomic_update(struct drm_plane <token> <answer> *plane, 
<token> drm_atomic_state *state) <answer> struct 
<token> drm_plane_state *new_state = drm_atomic_get_new_plane_state(state, <answer> struct 
struct tegra_plane_state *tegra_plane_state = <token> <answer> to_tegra_plane_state(new_state); 
struct tegra_dc *dc = <token> <answer> to_tegra_dc(new_state->crtc); 
unsigned int zpos <token> new_state->normalized_zpos; <answer> = 
struct drm_framebuffer *fb = <token> <answer> new_state->fb; 
struct <token> *p = to_tegra_plane(plane); <answer> tegra_plane 
u32 value, min_width, <token> = 0; <answer> bypass 
dma_addr_t base, <token> = 0; <answer> addr_flag 
unsigned int bpc, <token> <answer> planes; 
bool <token> <answer> yuv; 
<token> err; <answer> int 
<token> (tegra_plane_state->tiling.sector_layout == TEGRA_BO_SECTOR_LAYOUT_GPU) <answer> if 
addr_flag = <token> <answer> BIT_ULL(39); 
<token> = tegra_plane_state->iova[0] + fb->offsets[0]; <answer> base 
base |= <token> <answer> addr_flag; 
<token> tegra_plane_state->format, DC_WIN_COLOR_DEPTH); <answer> tegra_plane_writel(p, 
tegra_plane_writel(p, 0, <token> <answer> DC_WIN_PRECOMP_WGRP_PARAMS); 
value <token> V_POSITION(new_state->crtc_y) | <answer> = 
tegra_plane_writel(p, value, <token> <answer> DC_WIN_POSITION); 
value = V_SIZE(new_state->crtc_h) | <token> <answer> H_SIZE(new_state->crtc_w); 
tegra_plane_writel(p, <token> DC_WIN_SIZE); <answer> value, 
value <token> WIN_ENABLE | COLOR_EXPAND; <answer> = 
<token> value, DC_WIN_WIN_OPTIONS); <answer> tegra_plane_writel(p, 
value = V_SIZE(new_state->src_h <token> 16) | H_SIZE(new_state->src_w >> 16); <answer> >> 
tegra_plane_writel(p, <token> DC_WIN_CROPPED_SIZE); <answer> value, 
<token> upper_32_bits(base), DC_WINBUF_START_ADDR_HI); <answer> tegra_plane_writel(p, 
tegra_plane_writel(p, lower_32_bits(base), <token> <answer> DC_WINBUF_START_ADDR); 
value = <token> <answer> PITCH(fb->pitches[0]); 
tegra_plane_writel(p, value, <token> <answer> DC_WIN_PLANAR_STORAGE); 
if (yuv && <token> > 1) { <answer> planes 
<token> = tegra_plane_state->iova[1] + fb->offsets[1]; <answer> base 
<token> |= addr_flag; <answer> base 
tegra_plane_writel(p, upper_32_bits(base), <token> <answer> DC_WINBUF_START_ADDR_HI_U); 
<token> lower_32_bits(base), DC_WINBUF_START_ADDR_U); <answer> tegra_plane_writel(p, 
if <token> > 2) { <answer> (planes 
base <token> tegra_plane_state->iova[2] + fb->offsets[2]; <answer> = 
base <token> addr_flag; <answer> |= 
tegra_plane_writel(p, <token> DC_WINBUF_START_ADDR_HI_V); <answer> upper_32_bits(base), 
<token> lower_32_bits(base), DC_WINBUF_START_ADDR_V); <answer> tegra_plane_writel(p, 
value = <token> <answer> PITCH_U(fb->pitches[1]); 
if (planes <token> 2) <answer> > 
value |= <token> <answer> PITCH_V(fb->pitches[2]); 
tegra_plane_writel(p, value, <token> <answer> DC_WIN_PLANAR_STORAGE_UV); 
} <token> { <answer> else 
<token> 0, DC_WINBUF_START_ADDR_U); <answer> tegra_plane_writel(p, 
<token> 0, DC_WINBUF_START_ADDR_HI_U); <answer> tegra_plane_writel(p, 
<token> 0, DC_WINBUF_START_ADDR_V); <answer> tegra_plane_writel(p, 
tegra_plane_writel(p, <token> DC_WINBUF_START_ADDR_HI_V); <answer> 0, 
tegra_plane_writel(p, 0, <token> <answer> DC_WIN_PLANAR_STORAGE_UV); 
value <token> CLAMP_BEFORE_BLEND | INPUT_RANGE_FULL; <answer> = 
if <token> { <answer> (yuv) 
if (bpc < <token> <answer> 12) 
<token> |= DEGAMMA_YUV8_10; <answer> value 
value <token> DEGAMMA_YUV12; <answer> |= 
for_each_oldnew_crtc_in_state(state, crtc, old, new, <token> { <answer> i) 
struct tegra_dc_state *dc <token> to_dc_state(new); <answer> = 
<token> (new->active) { <answer> if 
if (!hub_state->clk <token> dc->pclk > hub_state->rate) { <answer> || 
hub_state->dc <token> to_tegra_dc(dc->base.crtc); <answer> = 
hub_state->clk = <token> <answer> hub_state->dc->clk; 
<token> = dc->pclk; <answer> hub_state->rate 
<token> 0; <answer> return 
static void tegra_display_hub_update(struct tegra_dc <token> <answer> *dc) 
u32 <token> <answer> value; 
<token> err; <answer> int 
err = <token> <answer> host1x_client_resume(&dc->client); 
if (err < 0) <token> <answer> { 
dev_err(dc->dev, "failed <token> resume: %d\n", err); <answer> to 
value <token> tegra_dc_readl(dc, DC_CMD_IHUB_COMMON_MISC_CTL); <answer> = 
<token> &= ~LATENCY_EVENT; <answer> value 
tegra_dc_writel(dc, value, <token> <answer> DC_CMD_IHUB_COMMON_MISC_CTL); 
value = <token> DC_DISP_IHUB_COMMON_DISPLAY_FETCH_METER); <answer> tegra_dc_readl(dc, 
value = <token> | WGRP_SLOTS(1); <answer> CURS_SLOTS(1) 
<token> value, DC_DISP_IHUB_COMMON_DISPLAY_FETCH_METER); <answer> tegra_dc_writel(dc, 
tegra_dc_writel(dc, COMMON_UPDATE, <token> <answer> DC_CMD_STATE_CONTROL); 
tegra_dc_readl(dc, <token> <answer> DC_CMD_STATE_CONTROL); 
tegra_dc_writel(dc, COMMON_ACTREQ, <token> <answer> DC_CMD_STATE_CONTROL); 
<token> DC_CMD_STATE_CONTROL); <answer> tegra_dc_readl(dc, 
void tegra_display_hub_atomic_commit(struct <token> *drm, <answer> drm_device 
<token> drm_atomic_state *state) <answer> struct 
struct tegra_drm *tegra = <token> <answer> drm->dev_private; 
<token> tegra_display_hub *hub = tegra->hub; <answer> struct 
<token> tegra_display_hub_state *hub_state; <answer> struct 
struct device *dev = <token> <answer> hub->client.dev; 
<token> err; <answer> int 
<token> = to_tegra_display_hub_state(hub->base.state); <answer> hub_state 
<token> (hub_state->clk) { <answer> if 
err <token> clk_set_rate(hub_state->clk, hub_state->rate); <answer> = 
<token> (err < 0) <answer> if 
dev_err(dev, "failed <token> set rate of %pC to %lu Hz\n", <answer> to 
hub_state->clk, <token> <answer> hub_state->rate); 
err = clk_set_parent(hub->clk_disp, <token> <answer> hub_state->clk); 
if (err < <token> <answer> 0) 
dev_err(dev, "failed to set parent of %pC <token> %pC: %d\n", <answer> to 
<token> hub_state->clk, err); <answer> hub->clk_disp, 
<token> (hub_state->dc) <answer> if 
static <token> tegra_display_hub_init(struct host1x_client *client) <answer> int 
<token> tegra_display_hub *hub = to_tegra_display_hub(client); <answer> struct 
struct <token> *drm = dev_get_drvdata(client->host); <answer> drm_device 
struct tegra_drm <token> = drm->dev_private; <answer> *tegra 
<token> tegra_display_hub_state *state; <answer> struct 
state = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*state), 
if <token> <answer> (!state) 
<token> -ENOMEM; <answer> return 
drm_atomic_private_obj_init(drm, &hub->base, <token> <answer> &state->base, 
tegra->hub <token> hub; <answer> = 
return <token> <answer> 0; 
static int tegra_display_hub_exit(struct <token> *client) <answer> host1x_client 
struct drm_device *drm = <token> <answer> dev_get_drvdata(client->host); 
struct <token> *tegra = drm->dev_private; <answer> tegra_drm 
tegra->hub <token> NULL; <answer> = 
<token> 0; <answer> return 
static <token> tegra_display_hub_runtime_suspend(struct host1x_client *client) <answer> int 
struct <token> *hub = to_tegra_display_hub(client); <answer> tegra_display_hub 
<token> device *dev = client->dev; <answer> struct 
unsigned <token> i = hub->num_heads; <answer> int 
<token> err; <answer> int 
<token> = reset_control_assert(hub->rst); <answer> err 
if (err <token> 0) <answer> < 
<token> err; <answer> return 
while <token> <answer> (i--) 
return <token> <answer> 0; 
<token> int tegra_display_hub_runtime_resume(struct host1x_client *client) <answer> static 
struct tegra_display_hub <token> = to_tegra_display_hub(client); <answer> *hub 
struct <token> *dev = client->dev; <answer> device 
unsigned <token> i; <answer> int 
<token> err; <answer> int 
<token> = pm_runtime_resume_and_get(dev); <answer> err 
if (err <token> 0) { <answer> < 
dev_err(dev, "failed <token> get runtime PM: %d\n", err); <answer> to 
return <token> <answer> err; 
<token> = clk_prepare_enable(hub->clk_disp); <answer> err 
if <token> < 0) <answer> (err 
goto <token> <answer> put_rpm; 
err <token> clk_prepare_enable(hub->clk_dsc); <answer> = 
<token> (err < 0) <answer> if 
goto <token> <answer> disable_disp; 
<token> = clk_prepare_enable(hub->clk_hub); <answer> err 
if <token> < 0) <answer> (err 
<token> disable_dsc; <answer> goto 
for (i <token> 0; i < hub->num_heads; i++) { <answer> = 
err <token> clk_prepare_enable(hub->clk_heads[i]); <answer> = 
<token> (err < 0) <answer> if 
goto <token> <answer> disable_heads; 
err = <token> <answer> reset_control_deassert(hub->rst); 
if (err < <token> <answer> 0) 
goto <token> <answer> disable_heads; 
return <token> <answer> 0; 
<token> (i--) <answer> while 
<token> err; <answer> return 
static const struct host1x_client_ops <token> = { <answer> tegra_display_hub_ops 
.init <token> tegra_display_hub_init, <answer> = 
.exit <token> tegra_display_hub_exit, <answer> = 
.suspend <token> tegra_display_hub_runtime_suspend, <answer> = 
.resume = <token> <answer> tegra_display_hub_runtime_resume, 
<token> int tegra_display_hub_probe(struct platform_device *pdev) <answer> static 
u64 dma_mask <token> dma_get_mask(pdev->dev.parent); <answer> = 
struct device_node *child = <token> <answer> NULL; 
<token> tegra_display_hub *hub; <answer> struct 
<token> clk *clk; <answer> struct 
<token> int i; <answer> unsigned 
int <token> <answer> err; 
<token> = dma_coerce_mask_and_coherent(&pdev->dev, dma_mask); <answer> err 
if <token> < 0) { <answer> (err 
dev_err(&pdev->dev, "failed to set <token> mask: %d\n", err); <answer> DMA 
return <token> <answer> err; 
<token> = devm_kzalloc(&pdev->dev, sizeof(*hub), GFP_KERNEL); <answer> hub 
if <token> <answer> (!hub) 
<token> -ENOMEM; <answer> return 
<token> = of_device_get_match_data(&pdev->dev); <answer> hub->soc 
hub->clk_disp = devm_clk_get(&pdev->dev, <token> <answer> "disp"); 
if <token> { <answer> (IS_ERR(hub->clk_disp)) 
<token> = PTR_ERR(hub->clk_disp); <answer> err 
<token> err; <answer> return 
if (hub->soc->supports_dsc) <token> <answer> { 
hub->clk_dsc <token> devm_clk_get(&pdev->dev, "dsc"); <answer> = 
if <token> { <answer> (IS_ERR(hub->clk_dsc)) 
<token> = PTR_ERR(hub->clk_dsc); <answer> err 
return <token> <answer> err; 
hub->clk_hub = devm_clk_get(&pdev->dev, <token> <answer> "hub"); 
<token> (IS_ERR(hub->clk_hub)) { <answer> if 
err = <token> <answer> PTR_ERR(hub->clk_hub); 
<token> err; <answer> return 
<token> = devm_reset_control_get(&pdev->dev, "misc"); <answer> hub->rst 
<token> (IS_ERR(hub->rst)) { <answer> if 
err = <token> <answer> PTR_ERR(hub->rst); 
return <token> <answer> err; 
hub->wgrps = <token> hub->soc->num_wgrps, <answer> devm_kcalloc(&pdev->dev, 
<token> GFP_KERNEL); <answer> sizeof(*hub->wgrps), 
<token> (!hub->wgrps) <answer> if 
<token> -ENOMEM; <answer> return 
for (i = 0; i <token> hub->soc->num_wgrps; i++) { <answer> < 
struct tegra_windowgroup *wgrp = <token> <answer> &hub->wgrps[i]; 
<token> id[16]; <answer> char 
snprintf(id, <token> "wgrp%u", i); <answer> sizeof(id), 
wgrp->usecount = <token> <answer> 0; 
<token> = i; <answer> wgrp->index 
wgrp->rst <token> devm_reset_control_get(&pdev->dev, id); <answer> = 
<token> (IS_ERR(wgrp->rst)) <answer> if 
return <token> <answer> PTR_ERR(wgrp->rst); 
<token> = reset_control_assert(wgrp->rst); <answer> err 
<token> (err < 0) <answer> if 
return <token> <answer> err; 
hub->num_heads = <token> <answer> of_get_child_count(pdev->dev.of_node); 
hub->clk_heads = devm_kcalloc(&pdev->dev, hub->num_heads, <token> <answer> sizeof(clk), 
<token> (!hub->clk_heads) <answer> if 
return <token> <answer> -ENOMEM; 
for (i = 0; i < hub->num_heads; i++) <token> <answer> { 
child <token> of_get_next_child(pdev->dev.of_node, child); <answer> = 
if <token> { <answer> (!child) 
<token> "failed to find node for head %u\n", <answer> dev_err(&pdev->dev, 
return <token> <answer> -ENODEV; 
<token> = devm_get_clk_from_child(&pdev->dev, child, "dc"); <answer> clk 
if (IS_ERR(clk)) <token> <answer> { 
dev_err(&pdev->dev, "failed to <token> clock for head %u\n", <answer> get 
return <token> <answer> PTR_ERR(clk); 
hub->clk_heads[i] = <token> <answer> clk; 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/clk-provider.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
<token> "common.h" <answer> #include 
static const struct coreclk_ratio <token> __initconst = { <answer> orion_coreclk_ratios[] 
{ .id <token> 0, .name = "ddrclk", } <answer> = 
#define SAR_MV88F5181_TCLK_FREQ <token> <answer> 8 
#define <token> 0x3 <answer> SAR_MV88F5181_TCLK_FREQ_MASK 
static u32 __init <token> __iomem *sar) <answer> mv88f5181_get_tclk_freq(void 
u32 opt = <token> >> SAR_MV88F5181_TCLK_FREQ) & <answer> (readl(sar) 
if (opt <token> 0) <answer> == 
return <token> <answer> 133333333; 
else <token> (opt == 1) <answer> if 
return <token> <answer> 150000000; 
else <token> (opt == 2) <answer> if 
<token> 166666667; <answer> return 
<token> 0; <answer> return 
<token> SAR_MV88F5181_CPU_FREQ 4 <answer> #define 
#define SAR_MV88F5181_CPU_FREQ_MASK <token> <answer> 0xf 
static u32 <token> mv88f5181_get_cpu_freq(void __iomem *sar) <answer> __init 
<token> opt = (readl(sar) >> SAR_MV88F5181_CPU_FREQ) & <answer> u32 
if (opt == <token> <answer> 0) 
return <token> <answer> 333333333; 
<token> if (opt == 1 || opt == 2) <answer> else 
<token> 400000000; <answer> return 
else if (opt <token> 3) <answer> == 
<token> 500000000; <answer> return 
<token> 0; <answer> return 
static void __init mv88f5181_get_clk_ratio(void __iomem *sar, int <token> <answer> id, 
int *mult, <token> *div) <answer> int 
u32 opt = (readl(sar) >> SAR_MV88F5181_CPU_FREQ) <token> <answer> & 
if <token> == 0 || opt == 1) { <answer> (opt 
*mult = <token> <answer> 1; 
*div = <token> <answer> 2; 
} else if (opt == 2 || opt <token> 3) { <answer> == 
<token> = 1; <answer> *mult 
*div = <token> <answer> 3; 
<token> else { <answer> } 
*mult = <token> <answer> 0; 
*div <token> 1; <answer> = 
<token> const struct coreclk_soc_desc mv88f5181_coreclks = { <answer> static 
<token> = mv88f5181_get_tclk_freq, <answer> .get_tclk_freq 
.get_cpu_freq = <token> <answer> mv88f5181_get_cpu_freq, 
.get_clk_ratio <token> mv88f5181_get_clk_ratio, <answer> = 
.ratios <token> orion_coreclk_ratios, <answer> = 
<token> = ARRAY_SIZE(orion_coreclk_ratios), <answer> .num_ratios 
static void __init <token> device_node *np) <answer> mv88f5181_clk_init(struct 
return mvebu_coreclk_setup(np, <token> <answer> &mv88f5181_coreclks); 
<token> "marvell,mv88f5181-core-clock", mv88f5181_clk_init); <answer> CLK_OF_DECLARE(mv88f5181_clk, 
<token> SAR_MV88F5182_TCLK_FREQ 8 <answer> #define 
#define SAR_MV88F5182_TCLK_FREQ_MASK <token> <answer> 0x3 
static u32 __init <token> __iomem *sar) <answer> mv88f5182_get_tclk_freq(void 
u32 opt = (readl(sar) >> <token> & <answer> SAR_MV88F5182_TCLK_FREQ) 
if <token> == 1) <answer> (opt 
<token> 150000000; <answer> return 
else <token> (opt == 2) <answer> if 
<token> 166666667; <answer> return 
<token> 0; <answer> return 
#define <token> 4 <answer> SAR_MV88F5182_CPU_FREQ 
#define SAR_MV88F5182_CPU_FREQ_MASK <token> <answer> 0xf 
static u32 <token> mv88f5182_get_cpu_freq(void __iomem *sar) <answer> __init 
u32 opt = <token> >> SAR_MV88F5182_CPU_FREQ) & <answer> (readl(sar) 
<token> (opt == 0) <answer> if 
return <token> <answer> 333333333; 
<token> if (opt == 1 || opt == 2) <answer> else 
<token> 400000000; <answer> return 
else if <token> == 3) <answer> (opt 
<token> 500000000; <answer> return 
return <token> <answer> 0; 
static void __init mv88f5182_get_clk_ratio(void __iomem *sar, <token> id, <answer> int 
int *mult, <token> *div) <answer> int 
<token> opt = (readl(sar) >> SAR_MV88F5182_CPU_FREQ) & <answer> u32 
if (opt == 0 || opt <token> 1) { <answer> == 
*mult <token> 1; <answer> = 
<token> = 2; <answer> *div 
} else if (opt == <token> || opt == 3) { <answer> 2 
*mult = <token> <answer> 1; 
<token> = 3; <answer> *div 
<token> else { <answer> } 
<token> = 0; <answer> *mult 
<token> = 1; <answer> *div 
<token> const struct coreclk_soc_desc mv88f5182_coreclks = { <answer> static 
<token> = mv88f5182_get_tclk_freq, <answer> .get_tclk_freq 
.get_cpu_freq = <token> <answer> mv88f5182_get_cpu_freq, 
.get_clk_ratio = <token> <answer> mv88f5182_get_clk_ratio, 
.ratios <token> orion_coreclk_ratios, <answer> = 
<token> = ARRAY_SIZE(orion_coreclk_ratios), <answer> .num_ratios 
static void __init mv88f5182_clk_init(struct device_node <token> <answer> *np) 
return mvebu_coreclk_setup(np, <token> <answer> &mv88f5182_coreclks); 
CLK_OF_DECLARE(mv88f5182_clk, <token> mv88f5182_clk_init); <answer> "marvell,mv88f5182-core-clock", 
<token> u32 __init mv88f5281_get_tclk_freq(void __iomem *sar) <answer> static 
<token> SAR_MV88F6183_TCLK_FREQ 9 <answer> #define 
#define <token> 0x1 <answer> SAR_MV88F6183_TCLK_FREQ_MASK 
static u32 __init mv88f6183_get_tclk_freq(void <token> *sar) <answer> __iomem 
u32 opt = (readl(sar) >> <token> & <answer> SAR_MV88F6183_TCLK_FREQ) 
<token> (opt == 0) <answer> if 
return <token> <answer> 133333333; 
else <token> (opt == 1) <answer> if 
<token> 166666667; <answer> return 
<token> 0; <answer> return 
#define <token> 1 <answer> SAR_MV88F6183_CPU_FREQ 
#define <token> 0x3f <answer> SAR_MV88F6183_CPU_FREQ_MASK 
static u32 <token> mv88f6183_get_cpu_freq(void __iomem *sar) <answer> __init 
u32 opt = <token> >> SAR_MV88F6183_CPU_FREQ) & <answer> (readl(sar) 
if (opt == <token> <answer> 9) 
return <token> <answer> 333333333; 
else if <token> == 17) <answer> (opt 
<token> 400000000; <answer> return 
return <token> <answer> 0; 
static void __init mv88f6183_get_clk_ratio(void __iomem <token> int id, <answer> *sar, 
int *mult, int <token> <answer> *div) 
u32 opt = (readl(sar) >> <token> & <answer> SAR_MV88F6183_CPU_FREQ) 
if (opt == 9 || opt == 17) <token> <answer> { 
<token> = 1; <answer> *mult 
*div <token> 2; <answer> = 
} <token> { <answer> else 
*mult = <token> <answer> 0; 
<token> = 1; <answer> *div 
<token> const struct coreclk_soc_desc mv88f6183_coreclks = { <answer> static 
.get_tclk_freq = <token> <answer> mv88f6183_get_tclk_freq, 
.get_cpu_freq <token> mv88f6183_get_cpu_freq, <answer> = 
.get_clk_ratio <token> mv88f6183_get_clk_ratio, <answer> = 
.ratios = <token> <answer> orion_coreclk_ratios, 
.num_ratios <token> ARRAY_SIZE(orion_coreclk_ratios), <answer> = 
static <token> __init mv88f6183_clk_init(struct device_node *np) <answer> void 
return <token> &mv88f6183_coreclks); <answer> mvebu_coreclk_setup(np, 
<token> "marvell,mv88f6183-core-clock", mv88f6183_clk_init); <answer> CLK_OF_DECLARE(mv88f6183_clk, 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/i2c.h> 
<token> <linux/i2c-mux.h> <answer> #include 
#include <token> <answer> <linux/iio/iio.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/pm_runtime.h> 
<token> "mpu3050.h" <answer> #include 
static const struct <token> mpu3050_i2c_regmap_config = { <answer> regmap_config 
<token> = 8, <answer> .reg_bits 
<token> = 8, <answer> .val_bits 
static int <token> i2c_mux_core *mux, u32 chan_id) <answer> mpu3050_i2c_bypass_select(struct 
struct mpu3050 <token> = i2c_mux_priv(mux); <answer> *mpu3050 
static const struct i2c_device_id <token> = { <answer> mpu3050_i2c_id[] 
{ <token> }, <answer> "mpu3050" 
MODULE_DEVICE_TABLE(i2c, <token> <answer> mpu3050_i2c_id); 
static const <token> of_device_id mpu3050_i2c_of_match[] = { <answer> struct 
{ .compatible = "invensense,mpu3050", .data = "mpu3050" <token> <answer> }, 
<token> (true) { <answer> while 
spin_lock_irqsave(&rtlpriv->locks.h2c_lock, <token> <answer> flag); 
if (rtlhal->h2c_setinprogress) <token> <answer> { 
rtl_dbg(rtlpriv, COMP_CMD, <token> <answer> DBG_LOUD, 
"H2C set in progress! <token> to set..element_id(%d).\n", <answer> Wait 
while (rtlhal->h2c_setinprogress) <token> <answer> { 
rtl_dbg(rtlpriv, COMP_CMD, <token> <answer> DBG_LOUD, 
"Wait 100 <token> (%d times)...\n", <answer> us 
if (h2c_waitcounter > <token> <answer> 1000) 
<token> flag); <answer> spin_unlock_irqrestore(&rtlpriv->locks.h2c_lock, 
<token> else { <answer> } 
<token> = true; <answer> rtlhal->h2c_setinprogress 
<token> flag); <answer> spin_unlock_irqrestore(&rtlpriv->locks.h2c_lock, 
<token> (!bwrite_sucess) { <answer> while 
if (!isfw_read) <token> <answer> { 
rtl_dbg(rtlpriv, COMP_CMD, <token> <answer> DBG_LOUD, 
"Write H2C reg <token> fail,Fw don't read.\n", <answer> BOX[%d] 
rlbm <token> 2; <answer> = 
<token> = 4; <answer> awake_intvl 
if <token> { <answer> (rtlpriv->mac80211.p2p) 
awake_intvl <token> 2; <answer> = 
<token> = 1; <answer> rlbm 
if (mode == FW_PS_ACTIVE_MODE) <token> <answer> { 
byte5 = <token> <answer> 0x40; 
<token> = FW_PWR_STATE_ACTIVE; <answer> power_state 
} else <token> <answer> { 
<token> (bt_ctrl_lps) { <answer> if 
byte5 <token> btc_ops->btc_get_lps_val(rtlpriv); <answer> = 
power_state <token> btc_ops->btc_get_rpwm_val(rtlpriv); <answer> = 
if ((rlbm <token> 2) && (byte5 & BIT(4))) { <answer> == 
<token> = 2; <answer> awake_intvl 
<token> = 2; <answer> rlbm 
} <token> { <answer> else 
byte5 = <token> <answer> 0x40; 
<token> = FW_PWR_STATE_RF_OFF; <answer> power_state 
SET_H2CCMD_PWRMODE_PARM_MODE(u1_h2c_set_pwrmode, ((mode) <token> 1 : 0)); <answer> ? 
SET_H2CCMD_PWRMODE_PARM_RLBM(u1_h2c_set_pwrmode, <token> <answer> rlbm); 
bt_ctrl_lps ? 0 <token> <answer> : 
<token> ? <answer> ((rtlpriv->mac80211.p2p) 
ppsc->smart_ps <token> 1)); <answer> : 
SET_H2CCMD_PWRMODE_PARM_ALL_QUEUE_UAPSD(u1_h2c_set_pwrmode, <token> <answer> 0); 
<token> power_state); <answer> SET_H2CCMD_PWRMODE_PARM_PWR_STATE(u1_h2c_set_pwrmode, 
<token> byte5); <answer> SET_H2CCMD_PWRMODE_PARM_BYTE5(u1_h2c_set_pwrmode, 
RT_PRINT_DATA(rtlpriv, COMP_CMD, <token> <answer> DBG_DMESG, 
"rtl92c_set_fw_pwrmode(): <token> <answer> u1_h2c_set_pwrmode\n", 
u1_h2c_set_pwrmode, <token> <answer> H2C_92E_PWEMODE_LENGTH); 
if <token> <answer> (rtlpriv->cfg->ops->get_btc_status()) 
btc_ops->btc_record_pwr_mode(rtlpriv, <token> <answer> u1_h2c_set_pwrmode, 
<token> H2C_92E_SETPWRMODE, H2C_92E_PWEMODE_LENGTH, <answer> rtl92ee_fill_h2c_cmd(hw, 
void <token> ieee80211_hw *hw, u8 mstatus) <answer> rtl92ee_set_fw_media_status_rpt_cmd(struct 
u8 parm[3] = { 0 , <token> , 0 }; <answer> 0 
SET_H2CCMD_MSRRPT_PARM_OPMODE(parm, <token> <answer> mstatus); 
<token> 0); <answer> SET_H2CCMD_MSRRPT_PARM_MACID_IND(parm, 
rtl92ee_fill_h2c_cmd(hw, <token> 3, parm); <answer> H2C_92E_MSRRPT, 
beacon <token> &reserved_page_packet[BEACON_PG * 128]; <answer> = 
<token> mac->mac_addr); <answer> SET_80211_HDR_ADDRESS2(beacon, 
SET_80211_HDR_ADDRESS3(beacon, <token> <answer> mac->bssid); 
p_pspoll = &reserved_page_packet[PSPOLL_PG * <token> <answer> 128]; 
SET_80211_PS_POLL_AID(p_pspoll, <token> | 0xc000)); <answer> (mac->assoc_id 
SET_80211_PS_POLL_BSSID(p_pspoll, <token> <answer> mac->bssid); 
<token> mac->mac_addr); <answer> SET_80211_PS_POLL_TA(p_pspoll, 
<token> PSPOLL_PG); <answer> SET_H2CCMD_RSVDPAGE_LOC_PSPOLL(u1rsvdpageloc, 
<token> = &reserved_page_packet[NULL_PG * 128]; <answer> nullfunc 
<token> mac->bssid); <answer> SET_80211_HDR_ADDRESS1(nullfunc, 
SET_80211_HDR_ADDRESS2(nullfunc, <token> <answer> mac->mac_addr); 
SET_80211_HDR_ADDRESS3(nullfunc, <token> <answer> mac->bssid); 
SET_H2CCMD_RSVDPAGE_LOC_NULL_DATA(u1rsvdpageloc, <token> <answer> NULL_PG); 
p_probersp = <token> * 128]; <answer> &reserved_page_packet[PROBERSP_PG 
<token> mac->bssid); <answer> SET_80211_HDR_ADDRESS1(p_probersp, 
SET_80211_HDR_ADDRESS2(p_probersp, <token> <answer> mac->mac_addr); 
SET_80211_HDR_ADDRESS3(p_probersp, <token> <answer> mac->bssid); 
SET_H2CCMD_RSVDPAGE_LOC_PROBE_RSP(u1rsvdpageloc, <token> <answer> PROBERSP_PG); 
qosnull <token> &reserved_page_packet[QOS_NULL_PG * 128]; <answer> = 
<token> mac->bssid); <answer> SET_80211_HDR_ADDRESS1(qosnull, 
SET_80211_HDR_ADDRESS2(qosnull, <token> <answer> mac->mac_addr); 
SET_80211_HDR_ADDRESS3(qosnull, <token> <answer> mac->bssid); 
SET_H2CCMD_RSVDPAGE_LOC_QOS_NULL_DATA(u1rsvdpageloc, <token> <answer> QOS_NULL_PG); 
btqosnull = &reserved_page_packet[BT_QOS_NULL_PG * <token> <answer> 128]; 
SET_80211_HDR_ADDRESS1(btqosnull, <token> <answer> mac->bssid); 
<token> mac->mac_addr); <answer> SET_80211_HDR_ADDRESS2(btqosnull, 
SET_80211_HDR_ADDRESS3(btqosnull, <token> <answer> mac->bssid); 
SET_H2CCMD_RSVDPAGE_LOC_BT_QOS_NULL_DATA(u1rsvdpageloc, <token> <answer> BT_QOS_NULL_PG); 
totalpacketlen = <token> <answer> TOTAL_RESERVED_PKT_LEN; 
RT_PRINT_DATA(rtlpriv, COMP_CMD, DBG_LOUD <token> <answer> , 
<token> HW_VAR_SET_TX_CMD: ALL\n", <answer> "rtl92ee_set_fw_rsvdpagepkt(): 
<token> totalpacketlen); <answer> &reserved_page_packet[0], 
RT_PRINT_DATA(rtlpriv, COMP_CMD, <token> , <answer> DBG_LOUD 
"rtl92ee_set_fw_rsvdpagepkt(): <token> ALL\n", <answer> HW_VAR_SET_TX_CMD: 
u1rsvdpageloc, <token> <answer> 3); 
skb <token> dev_alloc_skb(totalpacketlen); <answer> = 
if <token> <answer> (!skb) 
skb_put_data(skb, &reserved_page_packet, <token> <answer> totalpacketlen); 
rtstatus = <token> skb); <answer> rtl_cmd_send_packet(hw, 
if <token> <answer> (rtstatus) 
b_dlok = <token> <answer> true; 
if <token> { <answer> (b_dlok) 
rtl_dbg(rtlpriv, COMP_POWER, <token> <answer> DBG_LOUD, 
<token> RSVD page location to Fw.\n"); <answer> "Set 
RT_PRINT_DATA(rtlpriv, <token> DBG_LOUD , <answer> COMP_CMD, 
"H2C_RSVDPAGE:\n", <token> 3); <answer> u1rsvdpageloc, 
<token> H2C_92E_RSVDPAGE, <answer> rtl92ee_fill_h2c_cmd(hw, 
<token> u1rsvdpageloc); <answer> sizeof(u1rsvdpageloc), 
} else <token> <answer> { 
<token> COMP_ERR, DBG_WARNING, <answer> rtl_dbg(rtlpriv, 
"Set RSVD page location to <token> FAIL!!!!!!.\n"); <answer> Fw 
<token> <stdlib.h> <answer> #include 
#include <token> <answer> <string.h> 
#include <token> <answer> <bpf/libbpf.h> 
<token> <linux/rtnetlink.h> <answer> #include 
<token> <linux/tc_act/tc_bpf.h> <answer> #include 
<token> "bpf/nlattr.h" <answer> #include 
#include <token> <answer> "main.h" 
#include <token> <answer> "netlink_dumper.h" 
static void xdp_dump_prog_id(struct nlattr **tb, <token> attr, <answer> int 
<token> char *mode, <answer> const 
<token> new_json_object) <answer> bool 
if <token> <answer> (!tb[attr]) 
if <token> <answer> (new_json_object) 
NET_DUMP_STR("mode", " %s", <token> <answer> mode); 
NET_DUMP_UINT("id", " <token> %u", libbpf_nla_getattr_u32(tb[attr])) <answer> id 
<token> (new_json_object) <answer> if 
static int do_xdp_dump_one(struct nlattr *attr, unsigned int <token> <answer> ifindex, 
const char <token> <answer> *name) 
struct nlattr *tb[IFLA_XDP_MAX <token> 1]; <answer> + 
unsigned char <token> <answer> mode; 
if <token> IFLA_XDP_MAX, attr, NULL) < 0) <answer> (libbpf_nla_parse_nested(tb, 
return <token> <answer> -1; 
if <token> <answer> (!tb[IFLA_XDP_ATTACHED]) 
return <token> <answer> 0; 
<token> = libbpf_nla_getattr_u8(tb[IFLA_XDP_ATTACHED]); <answer> mode 
if (mode == <token> <answer> XDP_ATTACHED_NONE) 
return <token> <answer> 0; 
if <token> <answer> (name) 
NET_DUMP_STR("devname", <token> name); <answer> "%s", 
<token> "(%d)", ifindex); <answer> NET_DUMP_UINT("ifindex", 
<token> (mode == XDP_ATTACHED_MULTI) { <answer> if 
if (json_output) <token> <answer> { 
<token> "multi_attachments"); <answer> jsonw_name(json_wtr, 
xdp_dump_prog_id(tb, IFLA_XDP_SKB_PROG_ID, <token> true); <answer> "generic", 
xdp_dump_prog_id(tb, <token> "driver", true); <answer> IFLA_XDP_DRV_PROG_ID, 
xdp_dump_prog_id(tb, <token> "offload", true); <answer> IFLA_XDP_HW_PROG_ID, 
<token> (json_output) <answer> if 
} else if (mode == XDP_ATTACHED_DRV) <token> <answer> { 
xdp_dump_prog_id(tb, IFLA_XDP_PROG_ID, "driver", <token> <answer> false); 
} else if (mode == XDP_ATTACHED_SKB) <token> <answer> { 
xdp_dump_prog_id(tb, <token> "generic", false); <answer> IFLA_XDP_PROG_ID, 
<token> else if (mode == XDP_ATTACHED_HW) { <answer> } 
<token> IFLA_XDP_PROG_ID, "offload", false); <answer> xdp_dump_prog_id(tb, 
<token> 0; <answer> return 
int <token> ifinfomsg *ifinfo, struct nlattr **tb) <answer> do_xdp_dump(struct 
<token> (!tb[IFLA_XDP]) <answer> if 
<token> 0; <answer> return 
return <token> ifinfo->ifi_index, <answer> do_xdp_dump_one(tb[IFLA_XDP], 
static int do_bpf_dump_one_act(struct nlattr <token> <answer> *attr) 
struct nlattr *tb[TCA_ACT_BPF_MAX + <token> <answer> 1]; 
if <token> TCA_ACT_BPF_MAX, attr, NULL) < 0) <answer> (libbpf_nla_parse_nested(tb, 
return <token> <answer> -LIBBPF_ERRNO__NLPARSE; 
<token> (!tb[TCA_ACT_BPF_PARMS]) <answer> if 
<token> -LIBBPF_ERRNO__NLPARSE; <answer> return 
<token> (tb[TCA_ACT_BPF_NAME]) <answer> if 
<token> "%s", <answer> NET_DUMP_STR("name", 
if <token> <answer> (tb[TCA_ACT_BPF_ID]) 
NET_DUMP_UINT("id", <token> id %u", <answer> " 
<token> 0; <answer> return 
static int do_dump_one_act(struct nlattr <token> <answer> *attr) 
struct nlattr *tb[TCA_ACT_MAX + <token> <answer> 1]; 
if <token> <answer> (!attr) 
<token> 0; <answer> return 
if (libbpf_nla_parse_nested(tb, TCA_ACT_MAX, <token> NULL) < 0) <answer> attr, 
<token> -LIBBPF_ERRNO__NLPARSE; <answer> return 
<token> (tb[TCA_ACT_KIND] && <answer> if 
strcmp(libbpf_nla_data(tb[TCA_ACT_KIND]), "bpf") == <token> <answer> 0) 
return <token> <answer> do_bpf_dump_one_act(tb[TCA_ACT_OPTIONS]); 
return <token> <answer> 0; 
static int do_bpf_act_dump(struct <token> *attr) <answer> nlattr 
struct nlattr *tb[TCA_ACT_MAX_PRIO <token> 1]; <answer> + 
int <token> ret; <answer> act, 
if (libbpf_nla_parse_nested(tb, <token> attr, NULL) < 0) <answer> TCA_ACT_MAX_PRIO, 
<token> -LIBBPF_ERRNO__NLPARSE; <answer> return 
NET_START_ARRAY("act", " <token> ["); <answer> %s 
for (act = 0; <token> <= TCA_ACT_MAX_PRIO; act++) { <answer> act 
ret = <token> <answer> do_dump_one_act(tb[act]); 
if <token> <answer> (ret) 
<token> "); <answer> NET_END_ARRAY("] 
<token> ret; <answer> return 
static int do_bpf_filter_dump(struct nlattr <token> <answer> *attr) 
struct nlattr *tb[TCA_BPF_MAX + <token> <answer> 1]; 
<token> ret; <answer> int 
if <token> TCA_BPF_MAX, attr, NULL) < 0) <answer> (libbpf_nla_parse_nested(tb, 
return <token> <answer> -LIBBPF_ERRNO__NLPARSE; 
<token> (tb[TCA_BPF_NAME]) <answer> if 
NET_DUMP_STR("name", " <token> <answer> %s", 
if <token> <answer> (tb[TCA_BPF_ID]) 
NET_DUMP_UINT("id", " <token> %u", <answer> id 
<token> (tb[TCA_BPF_ACT]) { <answer> if 
ret <token> do_bpf_act_dump(tb[TCA_BPF_ACT]); <answer> = 
<token> (ret) <answer> if 
return <token> <answer> ret; 
<token> 0; <answer> return 
int do_filter_dump(struct tcmsg <token> struct nlattr **tb, const char *kind, <answer> *info, 
const char *devname, <token> ifindex) <answer> int 
int ret = <token> <answer> 0; 
if <token> && <answer> (tb[TCA_OPTIONS] 
strcmp(libbpf_nla_data(tb[TCA_KIND]), <token> == 0) { <answer> "bpf") 
<token> (devname[0] != '\0') <answer> if 
NET_DUMP_STR("devname", <token> devname); <answer> "%s", 
NET_DUMP_UINT("ifindex", "(%u)", <token> <answer> ifindex); 
<token> " %s", kind); <answer> NET_DUMP_STR("kind", 
ret <token> do_bpf_filter_dump(tb[TCA_OPTIONS]); <answer> = 
return <token> <answer> ret; 
#include <token> <answer> <stddef.h> 
<token> <linux/bpf.h> <answer> #include 
#include <token> <answer> <bpf/bpf_helpers.h> 
#include <token> <answer> "bpf_misc.h" 
<token> S { <answer> struct 
<token> x; <answer> int 
__noinline int <token> struct S *s) <answer> foo(const 
return bpf_get_prandom_u32() < <token> <answer> s->x; 
__failure __msg("invalid mem access <token> <answer> 'mem_or_null'") 
int global_func12(struct <token> *skb) <answer> __sk_buff 
const struct S s = {.x <token> skb->len }; <answer> = 
return <token> <answer> 1; 
#define pr_fmt(fmt) KBUILD_MODNAME ": <token> fmt <answer> " 
<token> <linux/types.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/skbuff.h> <answer> #include 
#include <token> <answer> <linux/netdevice.h> 
<token> <linux/in.h> <answer> #include 
#include <token> <answer> <linux/if_arp.h> 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/in6.h> 
<token> <linux/inetdevice.h> <answer> #include 
#include <token> <answer> <linux/netfilter_ipv4.h> 
<token> <linux/etherdevice.h> <answer> #include 
<token> <linux/if_ether.h> <answer> #include 
#include <token> <answer> <linux/if_vlan.h> 
#include <token> <answer> <linux/static_key.h> 
<token> <net/ip.h> <answer> #include 
<token> <net/icmp.h> <answer> #include 
#include <token> <answer> <net/protocol.h> 
<token> <net/ip_tunnels.h> <answer> #include 
#include <token> <answer> <net/ip6_tunnel.h> 
#include <token> <answer> <net/ip6_checksum.h> 
#include <token> <answer> <net/arp.h> 
<token> <net/checksum.h> <answer> #include 
#include <token> <answer> <net/dsfield.h> 
#include <token> <answer> <net/inet_ecn.h> 
#include <token> <answer> <net/xfrm.h> 
<token> <net/net_namespace.h> <answer> #include 
<token> <net/netns/generic.h> <answer> #include 
<token> <net/rtnetlink.h> <answer> #include 
#include <token> <answer> <net/dst_metadata.h> 
<token> <net/geneve.h> <answer> #include 
#include <token> <answer> <net/vxlan.h> 
<token> <net/erspan.h> <answer> #include 
const <token> ip_tunnel_encap_ops __rcu * <answer> struct 
iptun_encaps[MAX_IPTUN_ENCAP_OPS] <token> <answer> __read_mostly; 
<token> struct ip6_tnl_encap_ops __rcu * <answer> const 
ip6tun_encaps[MAX_IPTUN_ENCAP_OPS] <token> <answer> __read_mostly; 
void <token> sock *sk, struct rtable *rt, struct sk_buff *skb, <answer> iptunnel_xmit(struct 
__be32 src, __be32 dst, __u8 <token> <answer> proto, 
__u8 <token> __u8 ttl, __be16 df, bool xnet) <answer> tos, 
int pkt_len = skb->len - <token> <answer> skb_inner_network_offset(skb); 
struct net *net <token> dev_net(rt->dst.dev); <answer> = 
struct net_device *dev <token> skb->dev; <answer> = 
struct iphdr <token> <answer> *iph; 
<token> err; <answer> int 
skb_scrub_packet(skb, <token> <answer> xnet); 
<token> &rt->dst); <answer> skb_dst_set(skb, 
<token> 0, sizeof(*IPCB(skb))); <answer> memset(IPCB(skb), 
skb->encapsulation <token> 0; <answer> = 
<token> 0; <answer> return 
<token> int iptunnel_pmtud_build_icmp(struct sk_buff *skb, int mtu) <answer> static 
<token> struct iphdr *iph = ip_hdr(skb); <answer> const 
struct icmphdr <token> <answer> *icmph; 
<token> iphdr *niph; <answer> struct 
struct ethhdr <token> <answer> eh; 
int len, <token> <answer> err; 
if (!pskb_may_pull(skb, ETH_HLEN + <token> iphdr))) <answer> sizeof(struct 
<token> -EINVAL; <answer> return 
skb_copy_bits(skb, skb_mac_offset(skb), &eh, <token> <answer> ETH_HLEN); 
pskb_pull(skb, <token> <answer> ETH_HLEN); 
<token> = pskb_trim(skb, 576 - sizeof(*niph) - sizeof(*icmph)); <answer> err 
if <token> <answer> (err) 
return <token> <answer> err; 
len = skb->len + <token> <answer> sizeof(*icmph); 
err = skb_cow(skb, sizeof(*niph) + sizeof(*icmph) + <token> <answer> ETH_HLEN); 
<token> (err) <answer> if 
return <token> <answer> err; 
icmph <token> skb_push(skb, sizeof(*icmph)); <answer> = 
*icmph = <token> icmphdr) { <answer> (struct 
.type <token> ICMP_DEST_UNREACH, <answer> = 
<token> = ICMP_FRAG_NEEDED, <answer> .code 
<token> = 0, <answer> .checksum 
.un.frag.__unused <token> 0, <answer> = 
.un.frag.mtu = <token> <answer> htons(mtu), 
icmph->checksum = csum_fold(skb_checksum(skb, 0, <token> 0)); <answer> len, 
<token> = skb_push(skb, sizeof(*niph)); <answer> niph 
<token> = (struct iphdr) { <answer> *niph 
<token> = sizeof(*niph) / 4u, <answer> .ihl 
.version <token> 4, <answer> = 
.tos <token> 0, <answer> = 
<token> = htons(len + sizeof(*niph)), <answer> .tot_len 
.id = <token> <answer> 0, 
.frag_off <token> htons(IP_DF), <answer> = 
.ttl <token> iph->ttl, <answer> = 
<token> = IPPROTO_ICMP, <answer> .protocol 
.saddr <token> iph->daddr, <answer> = 
.daddr = <token> <answer> iph->saddr, 
<token> = CHECKSUM_NONE; <answer> skb->ip_summed 
eth_header(skb, skb->dev, <token> eh.h_source, eh.h_dest, 0); <answer> ntohs(eh.h_proto), 
return <token> <answer> skb->len; 
static int iptunnel_pmtud_check_icmp(struct sk_buff <token> int mtu) <answer> *skb, 
const struct icmphdr <token> = icmp_hdr(skb); <answer> *icmph 
<token> struct iphdr *iph = ip_hdr(skb); <answer> const 
if <token> < 576 || iph->frag_off != htons(IP_DF)) <answer> (mtu 
return <token> <answer> 0; 
if (ipv4_is_lbcast(iph->daddr) <token> ipv4_is_multicast(iph->daddr) || <answer> || 
<token> || ipv4_is_loopback(iph->saddr) || <answer> ipv4_is_zeronet(iph->saddr) 
ipv4_is_lbcast(iph->saddr) || <token> <answer> ipv4_is_multicast(iph->saddr)) 
<token> 0; <answer> return 
if (iph->protocol == IPPROTO_ICMP <token> icmp_is_err(icmph->type)) <answer> && 
<token> 0; <answer> return 
return <token> mtu); <answer> iptunnel_pmtud_build_icmp(skb, 
<token> IS_ENABLED(CONFIG_IPV6) <answer> #if 
static int iptunnel_pmtud_build_icmpv6(struct <token> *skb, int mtu) <answer> sk_buff 
const struct ipv6hdr <token> = ipv6_hdr(skb); <answer> *ip6h 
struct icmp6hdr <token> <answer> *icmp6h; 
struct <token> *nip6h; <answer> ipv6hdr 
<token> ethhdr eh; <answer> struct 
int len, <token> <answer> err; 
<token> csum; <answer> __wsum 
if (!pskb_may_pull(skb, ETH_HLEN + sizeof(struct <token> <answer> ipv6hdr))) 
return <token> <answer> -EINVAL; 
skb_copy_bits(skb, skb_mac_offset(skb), <token> ETH_HLEN); <answer> &eh, 
<token> ETH_HLEN); <answer> pskb_pull(skb, 
<token> = pskb_trim(skb, IPV6_MIN_MTU - sizeof(*nip6h) - sizeof(*icmp6h)); <answer> err 
if <token> <answer> (err) 
<token> err; <answer> return 
len <token> skb->len + sizeof(*icmp6h); <answer> = 
err = skb_cow(skb, sizeof(*nip6h) + sizeof(*icmp6h) <token> ETH_HLEN); <answer> + 
if <token> <answer> (err) 
<token> err; <answer> return 
<token> = skb_push(skb, sizeof(*icmp6h)); <answer> icmp6h 
<token> = (struct icmp6hdr) { <answer> *icmp6h 
.icmp6_type <token> ICMPV6_PKT_TOOBIG, <answer> = 
.icmp6_code = <token> <answer> 0, 
.icmp6_cksum <token> 0, <answer> = 
.icmp6_mtu = <token> <answer> htonl(mtu), 
nip6h = skb_push(skb, <token> <answer> sizeof(*nip6h)); 
*nip6h = <token> ipv6hdr) { <answer> (struct 
.priority <token> 0, <answer> = 
.version = <token> <answer> 6, 
.flow_lbl = <token> 0 }, <answer> { 
<token> = htons(len), <answer> .payload_len 
.nexthdr = <token> <answer> IPPROTO_ICMPV6, 
.hop_limit <token> ip6h->hop_limit, <answer> = 
<token> = ip6h->daddr, <answer> .saddr 
.daddr <token> ip6h->saddr, <answer> = 
csum = skb_checksum(skb, <token> len, 0); <answer> skb_transport_offset(skb), 
icmp6h->icmp6_cksum = <token> &nip6h->daddr, len, <answer> csum_ipv6_magic(&nip6h->saddr, 
IPPROTO_ICMPV6, <token> <answer> csum); 
<token> = CHECKSUM_NONE; <answer> skb->ip_summed 
<token> skb->dev, ntohs(eh.h_proto), eh.h_source, eh.h_dest, 0); <answer> eth_header(skb, 
return <token> <answer> skb->len; 
static <token> iptunnel_pmtud_check_icmpv6(struct sk_buff *skb, int mtu) <answer> int 
const struct ipv6hdr *ip6h <token> ipv6_hdr(skb); <answer> = 
int stype = <token> <answer> ipv6_addr_type(&ip6h->saddr); 
u8 <token> = ip6h->nexthdr; <answer> proto 
__be16 <token> <answer> frag_off; 
int <token> <answer> offset; 
if (mtu < <token> <answer> IPV6_MIN_MTU) 
<token> 0; <answer> return 
if (stype == IPV6_ADDR_ANY || stype == <token> || <answer> IPV6_ADDR_MULTICAST 
<token> == IPV6_ADDR_LOOPBACK) <answer> stype 
<token> 0; <answer> return 
<token> = ipv6_skip_exthdr(skb, sizeof(struct ipv6hdr), &proto, <answer> offset 
if (offset < 0 || (frag_off & <token> <answer> htons(~0x7))) 
<token> 0; <answer> return 
if <token> == IPPROTO_ICMPV6) { <answer> (proto 
<token> icmp6hdr *icmp6h; <answer> struct 
<token> (!pskb_may_pull(skb, skb_network_header(skb) + <answer> if 
offset + <token> - skb->data)) <answer> 1 
return <token> <answer> 0; 
<token> = (struct icmp6hdr *)(skb_network_header(skb) + offset); <answer> icmp6h 
if <token> || <answer> (icmpv6_is_err(icmp6h->icmp6_type) 
icmp6h->icmp6_type <token> NDISC_REDIRECT) <answer> == 
return <token> <answer> 0; 
return <token> mtu); <answer> iptunnel_pmtud_build_icmpv6(skb, 
int skb_tunnel_check_pmtu(struct sk_buff <token> struct dst_entry *encap_dst, <answer> *skb, 
int <token> bool reply) <answer> headroom, 
u32 mtu = <token> - headroom; <answer> dst_mtu(encap_dst) 
if ((skb_is_gso(skb) && skb_gso_validate_network_len(skb, <token> || <answer> mtu)) 
(!skb_is_gso(skb) <token> (skb->len - skb_network_offset(skb)) <= mtu)) <answer> && 
return <token> <answer> 0; 
<token> mtu); <answer> skb_dst_update_pmtu_no_confirm(skb, 
<token> (!reply || skb->pkt_type == PACKET_HOST) <answer> if 
<token> 0; <answer> return 
<token> (skb->protocol == htons(ETH_P_IP)) <answer> if 
return <token> mtu); <answer> iptunnel_pmtud_check_icmp(skb, 
#if <token> <answer> IS_ENABLED(CONFIG_IPV6) 
if (skb->protocol <token> htons(ETH_P_IPV6)) <answer> == 
return iptunnel_pmtud_check_icmpv6(skb, <token> <answer> mtu); 
<token> 0; <answer> return 
static const struct nla_policy ip_tun_policy[LWTUNNEL_IP_MAX <token> 1] = { <answer> + 
[LWTUNNEL_IP_UNSPEC] = { .strict_start_type = <token> }, <answer> LWTUNNEL_IP_OPTS 
<token> = { .type = NLA_U64 }, <answer> [LWTUNNEL_IP_ID] 
[LWTUNNEL_IP_DST] = { .type = NLA_U32 <token> <answer> }, 
[LWTUNNEL_IP_SRC] = <token> .type = NLA_U32 }, <answer> { 
[LWTUNNEL_IP_TTL] <token> { .type = NLA_U8 }, <answer> = 
[LWTUNNEL_IP_TOS] = { .type = <token> }, <answer> NLA_U8 
[LWTUNNEL_IP_FLAGS] <token> { .type = NLA_U16 }, <answer> = 
[LWTUNNEL_IP_OPTS] = { .type = <token> }, <answer> NLA_NESTED 
static const struct nla_policy ip_opts_policy[LWTUNNEL_IP_OPTS_MAX + 1] = <token> <answer> { 
[LWTUNNEL_IP_OPTS_GENEVE] = { <token> = NLA_NESTED }, <answer> .type 
[LWTUNNEL_IP_OPTS_VXLAN] = { .type = NLA_NESTED <token> <answer> }, 
[LWTUNNEL_IP_OPTS_ERSPAN] = { .type = NLA_NESTED <token> <answer> }, 
static const struct <token> <answer> nla_policy 
geneve_opt_policy[LWTUNNEL_IP_OPT_GENEVE_MAX + 1] <token> { <answer> = 
[LWTUNNEL_IP_OPT_GENEVE_CLASS] = <token> .type = NLA_U16 }, <answer> { 
[LWTUNNEL_IP_OPT_GENEVE_TYPE] <token> { .type = NLA_U8 }, <answer> = 
[LWTUNNEL_IP_OPT_GENEVE_DATA] = <token> .type = NLA_BINARY, .len = 128 }, <answer> { 
static <token> struct nla_policy <answer> const 
<token> + 1] = { <answer> vxlan_opt_policy[LWTUNNEL_IP_OPT_VXLAN_MAX 
[LWTUNNEL_IP_OPT_VXLAN_GBP] = { .type <token> NLA_U32 }, <answer> = 
static const struct <token> <answer> nla_policy 
<token> + 1] = { <answer> erspan_opt_policy[LWTUNNEL_IP_OPT_ERSPAN_MAX 
[LWTUNNEL_IP_OPT_ERSPAN_VER] = { .type <token> NLA_U8 }, <answer> = 
[LWTUNNEL_IP_OPT_ERSPAN_INDEX] = { .type = NLA_U32 <token> <answer> }, 
[LWTUNNEL_IP_OPT_ERSPAN_DIR] = { .type = <token> }, <answer> NLA_U8 
[LWTUNNEL_IP_OPT_ERSPAN_HWID] = <token> .type = NLA_U8 }, <answer> { 
static int ip_tun_parse_opts_geneve(struct nlattr <token> <answer> *attr, 
struct <token> *info, int opts_len, <answer> ip_tunnel_info 
struct <token> *extack) <answer> netlink_ext_ack 
struct nlattr *tb[LWTUNNEL_IP_OPT_GENEVE_MAX + <token> <answer> 1]; 
<token> data_len, err; <answer> int 
err <token> nla_parse_nested(tb, LWTUNNEL_IP_OPT_GENEVE_MAX, attr, <answer> = 
<token> extack); <answer> geneve_opt_policy, 
<token> (err) <answer> if 
<token> err; <answer> return 
if <token> || <answer> (!tb[LWTUNNEL_IP_OPT_GENEVE_CLASS] 
<token> || <answer> !tb[LWTUNNEL_IP_OPT_GENEVE_TYPE] 
return <token> <answer> -EINVAL; 
<token> = tb[LWTUNNEL_IP_OPT_GENEVE_DATA]; <answer> attr 
<token> = nla_len(attr); <answer> data_len 
if (data_len % <token> <answer> 4) 
return <token> <answer> -EINVAL; 
if (info) <token> <answer> { 
struct geneve_opt <token> = ip_tunnel_info_opts(info) + opts_len; <answer> *opt 
memcpy(opt->opt_data, nla_data(attr), <token> <answer> data_len); 
opt->length <token> data_len / 4; <answer> = 
attr = <token> <answer> tb[LWTUNNEL_IP_OPT_GENEVE_CLASS]; 
<token> = nla_get_be16(attr); <answer> opt->opt_class 
attr <token> tb[LWTUNNEL_IP_OPT_GENEVE_TYPE]; <answer> = 
opt->type = <token> <answer> nla_get_u8(attr); 
info->key.tun_flags |= <token> <answer> TUNNEL_GENEVE_OPT; 
return sizeof(struct geneve_opt) + <token> <answer> data_len; 
static int ip_tun_parse_opts_vxlan(struct nlattr <token> <answer> *attr, 
struct <token> *info, int opts_len, <answer> ip_tunnel_info 
struct <token> *extack) <answer> netlink_ext_ack 
<token> nlattr *tb[LWTUNNEL_IP_OPT_VXLAN_MAX + 1]; <answer> struct 
<token> err; <answer> int 
err = nla_parse_nested(tb, <token> attr, <answer> LWTUNNEL_IP_OPT_VXLAN_MAX, 
vxlan_opt_policy, <token> <answer> extack); 
if <token> <answer> (err) 
return <token> <answer> err; 
if <token> <answer> (!tb[LWTUNNEL_IP_OPT_VXLAN_GBP]) 
return <token> <answer> -EINVAL; 
if (info) <token> <answer> { 
struct vxlan_metadata *md <token> <answer> = 
<token> + opts_len; <answer> ip_tunnel_info_opts(info) 
<token> = tb[LWTUNNEL_IP_OPT_VXLAN_GBP]; <answer> attr 
md->gbp <token> nla_get_u32(attr); <answer> = 
<token> &= VXLAN_GBP_MASK; <answer> md->gbp 
info->key.tun_flags <token> TUNNEL_VXLAN_OPT; <answer> |= 
<token> sizeof(struct vxlan_metadata); <answer> return 
static int <token> nlattr *attr, <answer> ip_tun_parse_opts_erspan(struct 
struct ip_tunnel_info <token> int opts_len, <answer> *info, 
struct <token> *extack) <answer> netlink_ext_ack 
struct nlattr *tb[LWTUNNEL_IP_OPT_ERSPAN_MAX + <token> <answer> 1]; 
int <token> <answer> err; 
u8 <token> <answer> ver; 
err = nla_parse_nested(tb, LWTUNNEL_IP_OPT_ERSPAN_MAX, <token> <answer> attr, 
erspan_opt_policy, <token> <answer> extack); 
<token> (err) <answer> if 
<token> err; <answer> return 
<token> (!tb[LWTUNNEL_IP_OPT_ERSPAN_VER]) <answer> if 
<token> -EINVAL; <answer> return 
ver <token> nla_get_u8(tb[LWTUNNEL_IP_OPT_ERSPAN_VER]); <answer> = 
if (ver == 1) <token> <answer> { 
if <token> <answer> (!tb[LWTUNNEL_IP_OPT_ERSPAN_INDEX]) 
<token> -EINVAL; <answer> return 
} else if (ver == 2) <token> <answer> { 
if (!tb[LWTUNNEL_IP_OPT_ERSPAN_DIR] <token> <answer> || 
return <token> <answer> -EINVAL; 
<token> else { <answer> } 
return <token> <answer> -EINVAL; 
if (info) <token> <answer> { 
struct erspan_metadata *md <token> <answer> = 
ip_tunnel_info_opts(info) + <token> <answer> opts_len; 
md->version <token> ver; <answer> = 
<token> (ver == 1) { <answer> if 
attr <token> tb[LWTUNNEL_IP_OPT_ERSPAN_INDEX]; <answer> = 
<token> = nla_get_be32(attr); <answer> md->u.index 
} else <token> <answer> { 
<token> = tb[LWTUNNEL_IP_OPT_ERSPAN_DIR]; <answer> attr 
md->u.md2.dir = <token> <answer> nla_get_u8(attr); 
attr <token> tb[LWTUNNEL_IP_OPT_ERSPAN_HWID]; <answer> = 
<token> nla_get_u8(attr)); <answer> set_hwid(&md->u.md2, 
<token> |= TUNNEL_ERSPAN_OPT; <answer> info->key.tun_flags 
<token> sizeof(struct erspan_metadata); <answer> return 
static int ip_tun_parse_opts(struct nlattr <token> struct ip_tunnel_info *info, <answer> *attr, 
struct netlink_ext_ack <token> <answer> *extack) 
<token> err, rem, opt_len, opts_len = 0; <answer> int 
struct <token> *nla; <answer> nlattr 
<token> type = 0; <answer> __be16 
<token> (!attr) <answer> if 
return <token> <answer> 0; 
err = nla_validate(nla_data(attr), nla_len(attr), <token> <answer> LWTUNNEL_IP_OPTS_MAX, 
ip_opts_policy, <token> <answer> extack); 
if <token> <answer> (err) 
return <token> <answer> err; 
nla_for_each_attr(nla, nla_data(attr), nla_len(attr), <token> { <answer> rem) 
switch <token> { <answer> (nla_type(nla)) 
case <token> <answer> LWTUNNEL_IP_OPTS_GENEVE: 
if (type && type != <token> <answer> TUNNEL_GENEVE_OPT) 
return <token> <answer> -EINVAL; 
opt_len = ip_tun_parse_opts_geneve(nla, info, <token> <answer> opts_len, 
if <token> < 0) <answer> (opt_len 
return <token> <answer> opt_len; 
opts_len <token> opt_len; <answer> += 
if <token> > IP_TUNNEL_OPTS_MAX) <answer> (opts_len 
<token> -EINVAL; <answer> return 
type = <token> <answer> TUNNEL_GENEVE_OPT; 
<token> LWTUNNEL_IP_OPTS_VXLAN: <answer> case 
<token> (type) <answer> if 
<token> -EINVAL; <answer> return 
opt_len = ip_tun_parse_opts_vxlan(nla, <token> opts_len, <answer> info, 
if (opt_len <token> 0) <answer> < 
<token> opt_len; <answer> return 
opts_len <token> opt_len; <answer> += 
<token> = TUNNEL_VXLAN_OPT; <answer> type 
case <token> <answer> LWTUNNEL_IP_OPTS_ERSPAN: 
<token> (type) <answer> if 
return <token> <answer> -EINVAL; 
<token> = ip_tun_parse_opts_erspan(nla, info, opts_len, <answer> opt_len 
if (opt_len < <token> <answer> 0) 
<token> opt_len; <answer> return 
<token> += opt_len; <answer> opts_len 
type <token> TUNNEL_ERSPAN_OPT; <answer> = 
<token> -EINVAL; <answer> return 
return <token> <answer> opts_len; 
<token> int ip_tun_get_optlen(struct nlattr *attr, <answer> static 
struct <token> *extack) <answer> netlink_ext_ack 
return ip_tun_parse_opts(attr, <token> extack); <answer> NULL, 
static int ip_tun_set_opts(struct nlattr *attr, struct <token> *info, <answer> ip_tunnel_info 
struct <token> *extack) <answer> netlink_ext_ack 
<token> ip_tun_parse_opts(attr, info, extack); <answer> return 
static int ip_tun_build_state(struct net <token> struct nlattr *attr, <answer> *net, 
unsigned int family, const void <token> <answer> *cfg, 
struct <token> **ts, <answer> lwtunnel_state 
struct netlink_ext_ack <token> <answer> *extack) 
<token> nlattr *tb[LWTUNNEL_IP_MAX + 1]; <answer> struct 
struct lwtunnel_state <token> <answer> *new_state; 
<token> ip_tunnel_info *tun_info; <answer> struct 
int err, <token> <answer> opt_len; 
err = <token> LWTUNNEL_IP_MAX, attr, <answer> nla_parse_nested_deprecated(tb, 
<token> extack); <answer> ip_tun_policy, 
if (err < <token> <answer> 0) 
return <token> <answer> err; 
opt_len = <token> extack); <answer> ip_tun_get_optlen(tb[LWTUNNEL_IP_OPTS], 
if <token> < 0) <answer> (opt_len 
return <token> <answer> opt_len; 
new_state = lwtunnel_state_alloc(sizeof(*tun_info) <token> opt_len); <answer> + 
<token> (!new_state) <answer> if 
<token> -ENOMEM; <answer> return 
<token> = LWTUNNEL_ENCAP_IP; <answer> new_state->type 
<token> = lwt_tun_info(new_state); <answer> tun_info 
<token> = ip_tun_set_opts(tb[LWTUNNEL_IP_OPTS], tun_info, extack); <answer> err 
if (err < 0) <token> <answer> { 
return <token> <answer> err; 
<token> CONFIG_DST_CACHE <answer> #ifdef 
err <token> dst_cache_init(&tun_info->dst_cache, GFP_KERNEL); <answer> = 
if (err) <token> <answer> { 
<token> err; <answer> return 
<token> (tb[LWTUNNEL_IP_ID]) <answer> if 
tun_info->key.tun_id = <token> <answer> nla_get_be64(tb[LWTUNNEL_IP_ID]); 
if <token> <answer> (tb[LWTUNNEL_IP_DST]) 
tun_info->key.u.ipv4.dst = <token> <answer> nla_get_in_addr(tb[LWTUNNEL_IP_DST]); 
<token> (tb[LWTUNNEL_IP_SRC]) <answer> if 
tun_info->key.u.ipv4.src <token> nla_get_in_addr(tb[LWTUNNEL_IP_SRC]); <answer> = 
<token> (tb[LWTUNNEL_IP_TTL]) <answer> if 
<token> = nla_get_u8(tb[LWTUNNEL_IP_TTL]); <answer> tun_info->key.ttl 
<token> (tb[LWTUNNEL_IP_TOS]) <answer> if 
<token> = nla_get_u8(tb[LWTUNNEL_IP_TOS]); <answer> tun_info->key.tos 
if <token> <answer> (tb[LWTUNNEL_IP_FLAGS]) 
<token> |= <answer> tun_info->key.tun_flags 
<token> & <answer> (nla_get_be16(tb[LWTUNNEL_IP_FLAGS]) 
<token> = IP_TUNNEL_INFO_TX; <answer> tun_info->mode 
<token> = opt_len; <answer> tun_info->options_len 
*ts <token> new_state; <answer> = 
return <token> <answer> 0; 
static void ip_tun_destroy_state(struct <token> *lwtstate) <answer> lwtunnel_state 
#ifdef <token> <answer> CONFIG_DST_CACHE 
<token> ip_tunnel_info *tun_info = lwt_tun_info(lwtstate); <answer> struct 
static <token> ip_tun_fill_encap_opts_geneve(struct sk_buff *skb, <answer> int 
<token> ip_tunnel_info *tun_info) <answer> struct 
struct geneve_opt <token> <answer> *opt; 
struct <token> *nest; <answer> nlattr 
int <token> = 0; <answer> offset 
nest <token> nla_nest_start_noflag(skb, LWTUNNEL_IP_OPTS_GENEVE); <answer> = 
if <token> <answer> (!nest) 
<token> -ENOMEM; <answer> return 
while (tun_info->options_len > offset) <token> <answer> { 
opt <token> ip_tunnel_info_opts(tun_info) + offset; <answer> = 
if (nla_put_be16(skb, <token> <answer> LWTUNNEL_IP_OPT_GENEVE_CLASS, 
<token> || <answer> opt->opt_class) 
nla_put_u8(skb, LWTUNNEL_IP_OPT_GENEVE_TYPE, opt->type) <token> <answer> || 
nla_put(skb, LWTUNNEL_IP_OPT_GENEVE_DATA, <token> * 4, <answer> opt->length 
opt->opt_data)) <token> <answer> { 
<token> nest); <answer> nla_nest_cancel(skb, 
return <token> <answer> -ENOMEM; 
offset += sizeof(*opt) + opt->length <token> 4; <answer> * 
nla_nest_end(skb, <token> <answer> nest); 
return <token> <answer> 0; 
static int ip_tun_fill_encap_opts_vxlan(struct sk_buff <token> <answer> *skb, 
struct <token> *tun_info) <answer> ip_tunnel_info 
<token> vxlan_metadata *md; <answer> struct 
struct nlattr <token> <answer> *nest; 
nest <token> nla_nest_start_noflag(skb, LWTUNNEL_IP_OPTS_VXLAN); <answer> = 
<token> (!nest) <answer> if 
return <token> <answer> -ENOMEM; 
md <token> ip_tunnel_info_opts(tun_info); <answer> = 
if (nla_put_u32(skb, LWTUNNEL_IP_OPT_VXLAN_GBP, md->gbp)) <token> <answer> { 
<token> nest); <answer> nla_nest_cancel(skb, 
return <token> <answer> -ENOMEM; 
<token> nest); <answer> nla_nest_end(skb, 
<token> 0; <answer> return 
<token> int ip_tun_fill_encap_opts_erspan(struct sk_buff *skb, <answer> static 
struct ip_tunnel_info <token> <answer> *tun_info) 
struct <token> *md; <answer> erspan_metadata 
struct <token> *nest; <answer> nlattr 
nest <token> nla_nest_start_noflag(skb, LWTUNNEL_IP_OPTS_ERSPAN); <answer> = 
if <token> <answer> (!nest) 
return <token> <answer> -ENOMEM; 
md = <token> <answer> ip_tunnel_info_opts(tun_info); 
<token> (nla_put_u8(skb, LWTUNNEL_IP_OPT_ERSPAN_VER, md->version)) <answer> if 
<token> err; <answer> goto 
<token> (md->version == 1 && <answer> if 
<token> LWTUNNEL_IP_OPT_ERSPAN_INDEX, md->u.index)) <answer> nla_put_be32(skb, 
goto <token> <answer> err; 
if (md->version == 2 <token> <answer> && 
<token> LWTUNNEL_IP_OPT_ERSPAN_DIR, md->u.md2.dir) || <answer> (nla_put_u8(skb, 
nla_put_u8(skb, <token> <answer> LWTUNNEL_IP_OPT_ERSPAN_HWID, 
goto <token> <answer> err; 
nla_nest_end(skb, <token> <answer> nest); 
<token> 0; <answer> return 
nla_nest_cancel(skb, <token> <answer> nest); 
return <token> <answer> -ENOMEM; 
static int ip_tun_fill_encap_opts(struct sk_buff *skb, int <token> <answer> type, 
struct ip_tunnel_info <token> <answer> *tun_info) 
<token> nlattr *nest; <answer> struct 
<token> err = 0; <answer> int 
if (!(tun_info->key.tun_flags <token> TUNNEL_OPTIONS_PRESENT)) <answer> & 
return <token> <answer> 0; 
nest = <token> type); <answer> nla_nest_start_noflag(skb, 
if <token> <answer> (!nest) 
<token> -ENOMEM; <answer> return 
if <token> & TUNNEL_GENEVE_OPT) <answer> (tun_info->key.tun_flags 
<token> = ip_tun_fill_encap_opts_geneve(skb, tun_info); <answer> err 
else if <token> & TUNNEL_VXLAN_OPT) <answer> (tun_info->key.tun_flags 
err = <token> tun_info); <answer> ip_tun_fill_encap_opts_vxlan(skb, 
<token> if (tun_info->key.tun_flags & TUNNEL_ERSPAN_OPT) <answer> else 
err <token> ip_tun_fill_encap_opts_erspan(skb, tun_info); <answer> = 
if <token> { <answer> (err) 
<token> nest); <answer> nla_nest_cancel(skb, 
return <token> <answer> err; 
nla_nest_end(skb, <token> <answer> nest); 
return <token> <answer> 0; 
static int ip_tun_fill_encap_info(struct <token> *skb, <answer> sk_buff 
<token> lwtunnel_state *lwtstate) <answer> struct 
<token> ip_tunnel_info *tun_info = lwt_tun_info(lwtstate); <answer> struct 
<token> (nla_put_be64(skb, LWTUNNEL_IP_ID, tun_info->key.tun_id, <answer> if 
LWTUNNEL_IP_PAD) <token> <answer> || 
nla_put_in_addr(skb, LWTUNNEL_IP_DST, <token> || <answer> tun_info->key.u.ipv4.dst) 
nla_put_in_addr(skb, LWTUNNEL_IP_SRC, tun_info->key.u.ipv4.src) <token> <answer> || 
nla_put_u8(skb, LWTUNNEL_IP_TOS, <token> || <answer> tun_info->key.tos) 
<token> LWTUNNEL_IP_TTL, tun_info->key.ttl) || <answer> nla_put_u8(skb, 
nla_put_be16(skb, <token> tun_info->key.tun_flags) || <answer> LWTUNNEL_IP_FLAGS, 
<token> LWTUNNEL_IP_OPTS, tun_info)) <answer> ip_tun_fill_encap_opts(skb, 
<token> -ENOMEM; <answer> return 
return <token> <answer> 0; 
static int <token> ip_tunnel_info *info) <answer> ip_tun_opts_nlsize(struct 
int <token> <answer> opt_len; 
if (!(info->key.tun_flags & <token> <answer> TUNNEL_OPTIONS_PRESENT)) 
<token> 0; <answer> return 
<token> != 255); <answer> BUILD_BUG_ON(IP_TUNNEL_OPTS_MAX 
lwtunnel_encap_add_ops(&ip_tun_lwt_ops, <token> <answer> LWTUNNEL_ENCAP_IP); 
lwtunnel_encap_add_ops(&ip6_tun_lwt_ops, <token> <answer> LWTUNNEL_ENCAP_IP6); 
<token> ip_tunnel_need_metadata(void) <answer> void 
void <token> <answer> ip_tunnel_unneed_metadata(void) 
tmp16 = _rtl8723be_mdio_read(rtlpriv, <token> <answer> 0x01); 
if (tmp16 != <token> <answer> 0x0663) 
<token> 0x01, 0x0663); <answer> _rtl8723be_mdio_write(rtlpriv, 
tmp16 = <token> 0x04); <answer> _rtl8723be_mdio_read(rtlpriv, 
if (tmp16 <token> 0x7544) <answer> != 
_rtl8723be_mdio_write(rtlpriv, <token> 0x7544); <answer> 0x04, 
tmp16 <token> _rtl8723be_mdio_read(rtlpriv, 0x06); <answer> = 
<token> (tmp16 != 0xB880) <answer> if 
_rtl8723be_mdio_write(rtlpriv, 0x06, <token> <answer> 0xB880); 
tmp16 = _rtl8723be_mdio_read(rtlpriv, <token> <answer> 0x07); 
if <token> != 0x4000) <answer> (tmp16 
_rtl8723be_mdio_write(rtlpriv, 0x07, <token> <answer> 0x4000); 
tmp16 = <token> 0x08); <answer> _rtl8723be_mdio_read(rtlpriv, 
if (tmp16 <token> 0x9003) <answer> != 
_rtl8723be_mdio_write(rtlpriv, <token> 0x9003); <answer> 0x08, 
<token> = _rtl8723be_mdio_read(rtlpriv, 0x09); <answer> tmp16 
if <token> != 0x0D03) <answer> (tmp16 
_rtl8723be_mdio_write(rtlpriv, <token> 0x0D03); <answer> 0x09, 
<token> = _rtl8723be_mdio_read(rtlpriv, 0x0A); <answer> tmp16 
if (tmp16 != <token> <answer> 0x4037) 
<token> 0x0A, 0x4037); <answer> _rtl8723be_mdio_write(rtlpriv, 
tmp16 = <token> 0x0B); <answer> _rtl8723be_mdio_read(rtlpriv, 
if <token> != 0x0070) <answer> (tmp16 
_rtl8723be_mdio_write(rtlpriv, <token> 0x0070); <answer> 0x0B, 
tmp8 <token> _rtl8723be_dbi_read(rtlpriv, 0x719); <answer> = 
_rtl8723be_dbi_write(rtlpriv, 0x719, tmp8 <token> BIT(3) | BIT(4)); <answer> | 
<token> rtl8723be_enable_hw_security_config(struct ieee80211_hw *hw) <answer> void 
struct rtl_priv *rtlpriv = <token> <answer> rtl_priv(hw); 
<token> sec_reg_value; <answer> u8 
<token> COMP_INIT, DBG_DMESG, <answer> rtl_dbg(rtlpriv, 
"PairwiseEncAlgorithm = <token> GroupEncAlgorithm = %d\n", <answer> %d 
if <token> || rtlpriv->sec.use_sw_sec) { <answer> (rtlpriv->cfg->mod_params->sw_crypto 
<token> COMP_SEC, DBG_DMESG, <answer> rtl_dbg(rtlpriv, 
"not open hw <token> <answer> encryption\n"); 
sec_reg_value = SCR_TXENCENABLE | <token> <answer> SCR_RXDECENABLE; 
if <token> { <answer> (rtlpriv->sec.use_defaultkey) 
sec_reg_value |= <token> <answer> SCR_TXUSEDK; 
<token> |= SCR_RXUSEDK; <answer> sec_reg_value 
sec_reg_value |= (SCR_RXBCUSEDK | <token> <answer> SCR_TXBCUSEDK); 
<token> REG_CR + 1, 0x02); <answer> rtl_write_byte(rtlpriv, 
<token> COMP_SEC, DBG_DMESG, <answer> rtl_dbg(rtlpriv, 
"The SECR-value %x\n", <token> <answer> sec_reg_value); 
rtlpriv->cfg->ops->set_hw_reg(hw, <token> &sec_reg_value); <answer> HW_VAR_WPA_CONFIG, 
static <token> _rtl8723be_poweroff_adapter(struct ieee80211_hw *hw) <answer> void 
struct rtl_priv <token> = rtl_priv(hw); <answer> *rtlpriv 
struct rtl_hal *rtlhal = <token> <answer> rtl_hal(rtl_priv(hw)); 
<token> u1b_tmp; <answer> u8 
rtlhal->mac_func_enable <token> false; <answer> = 
tmp = rtl_read_byte(rtlpriv, REG_DBI_CTRL <token> 3); <answer> + 
if ((tmp & BIT(0)) <token> (tmp & BIT(1))) { <answer> || 
<token> COMP_INIT, DBG_LOUD, <answer> rtl_dbg(rtlpriv, 
"CheckPcieDMAHang8723BE(): <token> <answer> true!!\n"); 
return <token> <answer> true; 
return <token> <answer> false; 
static void _rtl8723be_reset_pcie_interface_dma(struct rtl_priv <token> <answer> *rtlpriv, 
<token> mac_power_on) <answer> bool 
u8 <token> <answer> tmp; 
<token> release_mac_rx_pause; <answer> bool 
u8 <token> <answer> backup_pcie_dma_pause; 
rtl_dbg(rtlpriv, <token> DBG_LOUD, <answer> COMP_INIT, 
tmp = <token> REG_RSV_CTRL); <answer> rtl_read_byte(rtlpriv, 
tmp <token> ~(BIT(1) | BIT(0)); <answer> &= 
rtl_write_byte(rtlpriv, <token> tmp); <answer> REG_RSV_CTRL, 
<token> = rtl_read_byte(rtlpriv, REG_PMC_DBG_CTRL2); <answer> tmp 
tmp <token> BIT(2); <answer> |= 
rtl_write_byte(rtlpriv, REG_PMC_DBG_CTRL2, <token> <answer> tmp); 
<token> = rtl_read_byte(rtlpriv, REG_RXDMA_CONTROL); <answer> tmp 
if (tmp & <token> { <answer> BIT(2)) 
rtl_write_byte(rtlpriv, REG_CR, <token> <answer> 0); 
tmp = rtl_read_byte(rtlpriv, REG_SYS_FUNC_EN <token> 1); <answer> + 
<token> &= ~(BIT(0)); <answer> tmp 
rtl_write_byte(rtlpriv, REG_SYS_FUNC_EN + 1, <token> <answer> tmp); 
tmp <token> rtl_read_byte(rtlpriv, REG_SYS_FUNC_EN + 1); <answer> = 
<token> |= BIT(0); <answer> tmp 
rtl_write_byte(rtlpriv, <token> + 1, tmp); <answer> REG_SYS_FUNC_EN 
if <token> { <answer> (mac_power_on) 
rtl_write_byte(rtlpriv, REG_CR, <token> <answer> 0xFF); 
tmp = <token> REG_MAC_PHY_CTRL_NORMAL + 2); <answer> rtl_read_byte(rtlpriv, 
<token> |= BIT(1); <answer> tmp 
rtl_write_byte(rtlpriv, REG_MAC_PHY_CTRL_NORMAL + <token> tmp); <answer> 2, 
<token> (!mac_power_on) { <answer> if 
if <token> { <answer> (release_mac_rx_pause) 
tmp = <token> REG_RXDMA_CONTROL); <answer> rtl_read_byte(rtlpriv, 
rtl_write_byte(rtlpriv, <token> <answer> REG_RXDMA_CONTROL, 
(tmp <token> (~BIT(2)))); <answer> & 
rtl_write_byte(rtlpriv, REG_PCIE_CTRL_REG + <token> <answer> 1, 
tmp <token> rtl_read_byte(rtlpriv, REG_PMC_DBG_CTRL2); <answer> = 
tmp <token> ~(BIT(2)); <answer> &= 
rtl_write_byte(rtlpriv, <token> tmp); <answer> REG_PMC_DBG_CTRL2, 
int rtl8723be_hw_init(struct <token> *hw) <answer> ieee80211_hw 
struct rtl_priv <token> = rtl_priv(hw); <answer> *rtlpriv 
struct rtl_hal <token> = rtl_hal(rtl_priv(hw)); <answer> *rtlhal 
<token> rtl_mac *mac = rtl_mac(rtl_priv(hw)); <answer> struct 
struct rtl_phy *rtlphy = <token> <answer> &(rtlpriv->phy); 
<token> rtl_ps_ctl *ppsc = rtl_psc(rtl_priv(hw)); <answer> struct 
struct rtl_pci *rtlpci <token> rtl_pcidev(rtl_pcipriv(hw)); <answer> = 
<token> rtstatus = true; <answer> bool 
<token> err; <answer> int 
u8 <token> <answer> tmp_u1b; 
unsigned long <token> <answer> flags; 
rtlpci->receive_config <token> rtl_read_dword(rtlpriv, REG_RCR); <answer> = 
<token> &= ~(RCR_ACRC32 | RCR_AICV); <answer> rtlpci->receive_config 
rtl_write_dword(rtlpriv, <token> rtlpci->receive_config); <answer> REG_RCR, 
rtlphy->rfreg_chnlval[0] <token> rtl_get_rfreg(hw, (enum radio_path)0, <answer> = 
<token> RFREG_OFFSET_MASK); <answer> RF_CHNLBW, 
rtlphy->rfreg_chnlval[1] = rtl_get_rfreg(hw, (enum <token> <answer> radio_path)1, 
RF_CHNLBW, <token> <answer> RFREG_OFFSET_MASK); 
<token> &= 0xFFF03FF; <answer> rtlphy->rfreg_chnlval[0] 
rtlphy->rfreg_chnlval[0] |= (BIT(10) <token> BIT(11)); <answer> | 
rtlhal->mac_func_enable = <token> <answer> true; 
<token> = ERFON; <answer> ppsc->rfpwr_state 
rtlpriv->cfg->ops->set_hw_reg(hw, HW_VAR_ETHER_ADDR, <token> <answer> mac->mac_addr); 
if <token> == ERFON) { <answer> (ppsc->rfpwr_state 
<token> 1); <answer> rtl8723be_phy_set_rfpath_switch(hw, 
if (rtlpriv->btcoexist.btc_info.ant_num == ANT_X2 <token> <answer> || 
!rtlpriv->cfg->ops->get_btc_status()) <token> <answer> { 
(rtlphy->iqk_initialized <token> <answer> ? 
true <token> false)); <answer> : 
<token> = true; <answer> rtlphy->iqk_initialized 
rtl_write_byte(rtlpriv, REG_NAV_UPPER, ((30000 + <token> / 128)); <answer> 127) 
if (mode <token> MSR_AP && rtlpriv->mac80211.link_state < MAC80211_LINKED) { <answer> != 
mode <token> MSR_NOLINK; <answer> = 
ledaction = <token> <answer> LED_CTL_NO_LINK; 
if (mode == <token> || mode == MSR_INFRA) { <answer> MSR_NOLINK 
} else if (mode == MSR_ADHOC || mode <token> MSR_AP) { <answer> == 
<token> else { <answer> } 
<token> COMP_ERR, DBG_WARNING, <answer> rtl_dbg(rtlpriv, 
<token> HW_VAR_MEDIA_STATUS: No such media status(%x).\n", <answer> "Set 
rtl_write_byte(rtlpriv, MSR, bt_msr <token> mode); <answer> | 
<token> ledaction); <answer> rtlpriv->cfg->ops->led_control(hw, 
if <token> == MSR_AP) <answer> (mode 
rtl_write_byte(rtlpriv, <token> + 1, 0x00); <answer> REG_BCNTCFG 
rtl_write_byte(rtlpriv, REG_BCNTCFG <token> 1, 0x66); <answer> + 
return <token> <answer> 0; 
void rtl8723be_set_check_bssid(struct ieee80211_hw <token> bool check_bssid) <answer> *hw, 
<token> rtl_priv *rtlpriv = rtl_priv(hw); <answer> struct 
struct rtl_pci *rtlpci <token> rtl_pcidev(rtl_pcipriv(hw)); <answer> = 
u32 reg_rcr <token> rtlpci->receive_config; <answer> = 
if (rtlpriv->psc.rfpwr_state != <token> <answer> ERFON) 
if (check_bssid) <token> <answer> { 
reg_rcr |= <token> | RCR_CBSSID_BCN); <answer> (RCR_CBSSID_DATA 
<token> HW_VAR_RCR, <answer> rtlpriv->cfg->ops->set_hw_reg(hw, 
<token> *)(&reg_rcr)); <answer> (u8 
_rtl8723be_set_bcn_ctrl_reg(hw, <token> BIT(4)); <answer> 0, 
<token> else if (!check_bssid) { <answer> } 
reg_rcr &= <token> | RCR_CBSSID_BCN)); <answer> (~(RCR_CBSSID_DATA 
<token> BIT(4), 0); <answer> _rtl8723be_set_bcn_ctrl_reg(hw, 
rtlpriv->cfg->ops->set_hw_reg(hw, <token> <answer> HW_VAR_RCR, 
<token> *)(&reg_rcr)); <answer> (u8 
int <token> ieee80211_hw *hw, <answer> rtl8723be_set_network_type(struct 
enum nl80211_iftype <token> <answer> type) 
struct <token> *rtlpriv = rtl_priv(hw); <answer> rtl_priv 
if <token> type)) <answer> (_rtl8723be_set_media_status(hw, 
<token> -EOPNOTSUPP; <answer> return 
<token> (rtlpriv->mac80211.link_state == MAC80211_LINKED) { <answer> if 
if (type != <token> <answer> NL80211_IFTYPE_AP) 
rtl8723be_set_check_bssid(hw, <token> <answer> true); 
} <token> { <answer> else 
<token> false); <answer> rtl8723be_set_check_bssid(hw, 
<token> 0; <answer> return 
void rtl8723be_set_qos(struct <token> *hw, int aci) <answer> ieee80211_hw 
struct rtl_priv *rtlpriv = <token> <answer> rtl_priv(hw); 
switch (aci) <token> <answer> { 
case <token> <answer> AC1_BK: 
rtl_write_dword(rtlpriv, REG_EDCA_BK_PARAM, <token> <answer> 0xa44f); 
case <token> <answer> AC0_BE: 
case <token> <answer> AC2_VI: 
rtl_write_dword(rtlpriv, <token> 0x5e4322); <answer> REG_EDCA_VI_PARAM, 
<token> AC3_VO: <answer> case 
<token> REG_EDCA_VO_PARAM, 0x2f3222); <answer> rtl_write_dword(rtlpriv, 
WARN_ONCE(true, <token> invalid aci: %d !\n", aci); <answer> "rtl8723be: 
void rtl8723be_enable_interrupt(struct ieee80211_hw <token> <answer> *hw) 
<token> rtl_priv *rtlpriv = rtl_priv(hw); <answer> struct 
struct <token> *rtlpci = rtl_pcidev(rtl_pcipriv(hw)); <answer> rtl_pci 
rtl_write_dword(rtlpriv, REG_HIMR, rtlpci->irq_mask[0] <token> 0xFFFFFFFF); <answer> & 
<token> REG_HIMRE, rtlpci->irq_mask[1] & 0xFFFFFFFF); <answer> rtl_write_dword(rtlpriv, 
<token> = true; <answer> rtlpci->irq_enabled 
<token> <linux/delay.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/pci.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/mei.h> 
#include <token> <answer> <linux/mei_cl_bus.h> 
<token> <linux/component.h> <answer> #include 
<token> <drm/drm_connector.h> <answer> #include 
<token> <drm/i915_component.h> <answer> #include 
<token> <drm/i915_pxp_tee_interface.h> <answer> #include 
<token> "mei_pxp.h" <answer> #include 
static inline int mei_pxp_reenable(const struct <token> *dev, struct mei_cl_device *cldev) <answer> device 
<token> ret; <answer> int 
dev_warn(dev, <token> to reset the channel...\n"); <answer> "Trying 
<token> = mei_cldev_disable(cldev); <answer> ret 
if (ret < <token> <answer> 0) 
<token> "mei_cldev_disable failed. %d\n", ret); <answer> dev_warn(dev, 
ret = <token> <answer> mei_cldev_enable(cldev); 
if (ret <token> 0) <answer> < 
dev_err(dev, "mei_cldev_enable failed. <token> ret); <answer> %d\n", 
return <token> <answer> ret; 
static <token> <answer> int 
mei_pxp_send_message(struct device *dev, const void *message, <token> size, unsigned long timeout_ms) <answer> size_t 
struct <token> *cldev; <answer> mei_cl_device 
<token> byte; <answer> ssize_t 
<token> ret; <answer> int 
if (!dev || <token> <answer> !message) 
return <token> <answer> -EINVAL; 
<token> = to_mei_cl_device(dev); <answer> cldev 
byte = mei_cldev_send_timeout(cldev, message, <token> timeout_ms); <answer> size, 
if (byte < 0) <token> <answer> { 
dev_dbg(dev, "mei_cldev_send failed. %zd\n", <token> <answer> byte); 
switch (byte) <token> <answer> { 
<token> -ENOMEM: <answer> case 
case <token> <answer> -ENODEV: 
<token> -ETIME: <answer> case 
ret = mei_pxp_reenable(dev, <token> <answer> cldev); 
if <token> <answer> (ret) 
byte <token> ret; <answer> = 
<token> byte; <answer> return 
return <token> <answer> 0; 
<token> int <answer> static 
mei_pxp_receive_message(struct device *dev, void *buffer, size_t <token> unsigned long timeout_ms) <answer> size, 
<token> mei_cl_device *cldev; <answer> struct 
<token> byte; <answer> ssize_t 
bool retry = <token> <answer> false; 
<token> ret; <answer> int 
if (!dev || <token> <answer> !buffer) 
<token> -EINVAL; <answer> return 
<token> = to_mei_cl_device(dev); <answer> cldev 
byte = mei_cldev_recv_timeout(cldev, buffer, size, <token> <answer> timeout_ms); 
if (byte < 0) <token> <answer> { 
<token> "mei_cldev_recv failed. %zd\n", byte); <answer> dev_dbg(dev, 
<token> (byte) { <answer> switch 
case <token> <answer> -ENOMEM: 
static ssize_t mei_pxp_gsc_command(struct device *dev, u8 client_id, <token> fence_id, <answer> u32 
struct scatterlist *sg_in, size_t <token> <answer> total_in_len, 
struct <token> *sg_out) <answer> scatterlist 
<token> mei_cl_device *cldev; <answer> struct 
cldev <token> to_mei_cl_device(dev); <answer> = 
<token> mei_cldev_send_gsc_command(cldev, client_id, fence_id, sg_in, total_in_len, sg_out); <answer> return 
static const struct i915_pxp_component_ops mei_pxp_ops = <token> <answer> { 
.owner = <token> <answer> THIS_MODULE, 
.send = <token> <answer> mei_pxp_send_message, 
.recv = <token> <answer> mei_pxp_receive_message, 
<token> = mei_pxp_gsc_command, <answer> .gsc_command 
static <token> mei_component_master_bind(struct device *dev) <answer> int 
struct mei_cl_device <token> = to_mei_cl_device(dev); <answer> *cldev 
<token> i915_pxp_component *comp_master = mei_cldev_get_drvdata(cldev); <answer> struct 
<token> ret; <answer> int 
comp_master->ops = <token> <answer> &mei_pxp_ops; 
comp_master->tee_dev = <token> <answer> dev; 
<token> = component_bind_all(dev, comp_master); <answer> ret 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
<token> 0; <answer> return 
static void mei_component_master_unbind(struct device <token> <answer> *dev) 
struct mei_cl_device <token> = to_mei_cl_device(dev); <answer> *cldev 
struct <token> *comp_master = mei_cldev_get_drvdata(cldev); <answer> i915_pxp_component 
<token> comp_master); <answer> component_unbind_all(dev, 
static const struct <token> mei_component_master_ops = { <answer> component_master_ops 
.bind <token> mei_component_master_bind, <answer> = 
.unbind = <token> <answer> mei_component_master_unbind, 
static int <token> device *dev, int subcomponent, <answer> mei_pxp_component_match(struct 
<token> *data) <answer> void 
struct device *base <token> data; <answer> = 
struct pci_dev <token> <answer> *pdev; 
<token> (!dev) <answer> if 
<token> 0; <answer> return 
<token> (!dev_is_pci(dev)) <answer> if 
<token> 0; <answer> return 
pdev <token> to_pci_dev(dev); <answer> = 
if <token> != PCI_VENDOR_ID_INTEL) <answer> (pdev->vendor 
return <token> <answer> 0; 
if (pdev->class != (PCI_CLASS_DISPLAY_VGA << 8) <token> <answer> && 
pdev->class != <token> << 8)) <answer> (PCI_CLASS_DISPLAY_OTHER 
<token> 0; <answer> return 
<token> (subcomponent != I915_COMPONENT_PXP) <answer> if 
<token> 0; <answer> return 
base <token> base->parent; <answer> = 
<token> <linux/dma-buf.h> <answer> #include 
<token> <drm/drm_prime.h> <answer> #include 
<token> <drm/radeon_drm.h> <answer> #include 
#include <token> <answer> <drm/ttm/ttm_tt.h> 
#include <token> <answer> "radeon.h" 
#include <token> <answer> "radeon_prime.h" 
struct sg_table *radeon_gem_prime_get_sg_table(struct <token> *obj) <answer> drm_gem_object 
struct <token> *bo = gem_to_radeon_bo(obj); <answer> radeon_bo 
return drm_prime_pages_to_sg(obj->dev, <token> <answer> bo->tbo.ttm->pages, 
<token> drm_gem_object *radeon_gem_prime_import_sg_table(struct drm_device *dev, <answer> struct 
struct <token> *attach, <answer> dma_buf_attachment 
<token> sg_table *sg) <answer> struct 
struct dma_resv <token> = attach->dmabuf->resv; <answer> *resv 
struct radeon_device <token> = dev->dev_private; <answer> *rdev 
struct <token> *bo; <answer> radeon_bo 
int <token> <answer> ret; 
dma_resv_lock(resv, <token> <answer> NULL); 
ret = radeon_bo_create(rdev, attach->dmabuf->size, PAGE_SIZE, <token> <answer> false, 
RADEON_GEM_DOMAIN_GTT, 0, sg, <token> &bo); <answer> resv, 
if <token> <answer> (ret) 
<token> ERR_PTR(ret); <answer> return 
bo->tbo.base.funcs <token> &radeon_gem_object_funcs; <answer> = 
list_add_tail(&bo->list, <token> <answer> &rdev->gem.objects); 
<token> = 1; <answer> bo->prime_shared_count 
return <token> <answer> &bo->tbo.base; 
int radeon_gem_prime_pin(struct <token> *obj) <answer> drm_gem_object 
<token> radeon_bo *bo = gem_to_radeon_bo(obj); <answer> struct 
int ret = <token> <answer> 0; 
ret = <token> false); <answer> radeon_bo_reserve(bo, 
if (unlikely(ret <token> 0)) <answer> != 
return <token> <answer> ret; 
<token> DEBUG <answer> #undef 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <linux/clk-provider.h> 
<token> <linux/delay.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/list.h> 
<token> <linux/mutex.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/cpu.h> 
<token> <linux/of.h> <answer> #include 
<token> <linux/of_address.h> <answer> #include 
<token> <linux/memblock.h> <answer> #include 
#include <token> <answer> <linux/platform_data/ti-sysc.h> 
#include <token> <answer> <dt-bindings/bus/ti-sysc.h> 
<token> <asm/system_misc.h> <answer> #include 
<token> "clock.h" <answer> #include 
<token> "omap_hwmod.h" <answer> #include 
<token> "soc.h" <answer> #include 
#include <token> <answer> "common.h" 
<token> "clockdomain.h" <answer> #include 
#include <token> <answer> "hdq1w.h" 
#include <token> <answer> "mmc.h" 
#include <token> <answer> "powerdomain.h" 
#include <token> <answer> "cm2xxx.h" 
<token> "cm3xxx.h" <answer> #include 
#include <token> <answer> "cm33xx.h" 
<token> "prm.h" <answer> #include 
<token> "prm3xxx.h" <answer> #include 
<token> "prm44xx.h" <answer> #include 
<token> "prm33xx.h" <answer> #include 
<token> "prminst44xx.h" <answer> #include 
#include <token> <answer> "pm.h" 
#include <token> <answer> "wd_timer.h" 
<token> LINKS_PER_OCP_IF 2 <answer> #define 
<token> OMAP4_RST_CTRL_ST_OFFSET 4 <answer> #define 
#define MOD_CLK_MAX_NAME_LEN <token> <answer> 32 
struct <token> { <answer> clkctrl_provider 
<token> num_addrs; <answer> int 
<token> *addr; <answer> u32 
u32 <token> <answer> *size; 
struct <token> *node; <answer> device_node 
struct <token> link; <answer> list_head 
static <token> <answer> LIST_HEAD(clkctrl_providers); 
struct omap_hwmod_reset <token> <answer> { 
<token> char *match; <answer> const 
<token> len; <answer> int 
int (*reset)(struct omap_hwmod <token> <answer> *oh); 
<token> omap_hwmod_soc_ops { <answer> struct 
void (*enable_module)(struct <token> *oh); <answer> omap_hwmod 
int (*disable_module)(struct omap_hwmod <token> <answer> *oh); 
int <token> omap_hwmod *oh); <answer> (*wait_target_ready)(struct 
int (*assert_hardreset)(struct omap_hwmod <token> <answer> *oh, 
struct omap_hwmod_rst_info <token> <answer> *ohri); 
int <token> omap_hwmod *oh, <answer> (*deassert_hardreset)(struct 
<token> omap_hwmod_rst_info *ohri); <answer> struct 
int <token> omap_hwmod *oh, <answer> (*is_hardreset_asserted)(struct 
struct omap_hwmod_rst_info <token> <answer> *ohri); 
<token> (*init_clkdm)(struct omap_hwmod *oh); <answer> int 
void <token> omap_hwmod *oh); <answer> (*update_context_lost)(struct 
<token> (*get_context_lost)(struct omap_hwmod *oh); <answer> int 
int (*disable_direct_prcm)(struct <token> *oh); <answer> omap_hwmod 
u32 (*xlate_clkctrl)(struct <token> *oh); <answer> omap_hwmod 
static <token> _update_sysc_cache(struct omap_hwmod *oh) <answer> int 
<token> (!oh->class->sysc) { <answer> if 
WARN(1, "omap_hwmod: %s: cannot <token> OCP_SYSCONFIG: not defined on hwmod's class\n", oh->name); <answer> read 
<token> -EINVAL; <answer> return 
static void _write_sysconfig(u32 v, <token> omap_hwmod *oh) <answer> struct 
<token> (!oh->class->sysc) { <answer> if 
WARN(1, "omap_hwmod: %s: cannot write <token> not defined on hwmod's class\n", oh->name); <answer> OCP_SYSCONFIG: 
<token> (oh->class->unlock) <answer> if 
omap_hwmod_write(v, <token> oh->class->sysc->sysc_offs); <answer> oh, 
if <token> <answer> (oh->class->lock) 
static <token> _set_master_standbymode(struct omap_hwmod *oh, u8 standbymode, <answer> int 
<token> *v) <answer> u32 
<token> mstandby_mask; <answer> u32 
<token> mstandby_shift; <answer> u8 
<token> (!oh->class->sysc || <answer> if 
!(oh->class->sysc->sysc_flags <token> SYSC_HAS_MIDLEMODE)) <answer> & 
<token> -EINVAL; <answer> return 
<token> (!oh->class->sysc->sysc_fields) { <answer> if 
WARN(1, "omap_hwmod: %s: offset <token> for sysconfig not provided in class\n", oh->name); <answer> struct 
return <token> <answer> -EINVAL; 
mstandby_shift = <token> <answer> oh->class->sysc->sysc_fields->midle_shift; 
<token> = (0x3 << mstandby_shift); <answer> mstandby_mask 
<token> &= ~mstandby_mask; <answer> *v 
*v |= __ffs(standbymode) <token> mstandby_shift; <answer> << 
return <token> <answer> 0; 
static int _set_slave_idlemode(struct omap_hwmod *oh, <token> idlemode, u32 *v) <answer> u8 
u32 <token> <answer> sidle_mask; 
<token> sidle_shift; <answer> u8 
if (!oh->class->sysc <token> <answer> || 
!(oh->class->sysc->sysc_flags <token> SYSC_HAS_SIDLEMODE)) <answer> & 
return <token> <answer> -EINVAL; 
if <token> { <answer> (!oh->class->sysc->sysc_fields) 
WARN(1, "omap_hwmod: %s: offset struct for sysconfig not provided in <token> oh->name); <answer> class\n", 
return <token> <answer> -EINVAL; 
sidle_shift <token> oh->class->sysc->sysc_fields->sidle_shift; <answer> = 
sidle_mask = (0x3 <token> sidle_shift); <answer> << 
<token> &= ~sidle_mask; <answer> *v 
*v |= __ffs(idlemode) <token> sidle_shift; <answer> << 
return <token> <answer> 0; 
static int _set_clockactivity(struct <token> *oh, u8 clockact, u32 *v) <answer> omap_hwmod 
u32 <token> <answer> clkact_mask; 
<token> clkact_shift; <answer> u8 
if (!oh->class->sysc <token> <answer> || 
!(oh->class->sysc->sysc_flags & <token> <answer> SYSC_HAS_CLOCKACTIVITY)) 
<token> -EINVAL; <answer> return 
<token> (!oh->class->sysc->sysc_fields) { <answer> if 
WARN(1, "omap_hwmod: %s: offset struct for sysconfig <token> provided in class\n", oh->name); <answer> not 
return <token> <answer> -EINVAL; 
clkact_shift = <token> <answer> oh->class->sysc->sysc_fields->clkact_shift; 
clkact_mask <token> (0x3 << clkact_shift); <answer> = 
*v &= <token> <answer> ~clkact_mask; 
*v <token> clockact << clkact_shift; <answer> |= 
return <token> <answer> 0; 
static int _set_softreset(struct <token> *oh, u32 *v) <answer> omap_hwmod 
<token> softrst_mask; <answer> u32 
<token> (!oh->class->sysc || <answer> if 
<token> & SYSC_HAS_SOFTRESET)) <answer> !(oh->class->sysc->sysc_flags 
<token> -EINVAL; <answer> return 
<token> (!oh->class->sysc->sysc_fields) { <answer> if 
WARN(1, "omap_hwmod: %s: <token> struct for sysconfig not provided in class\n", oh->name); <answer> offset 
<token> -EINVAL; <answer> return 
<token> = (0x1 << oh->class->sysc->sysc_fields->srst_shift); <answer> softrst_mask 
*v <token> softrst_mask; <answer> |= 
<token> 0; <answer> return 
static <token> _clear_softreset(struct omap_hwmod *oh, u32 *v) <answer> int 
u32 <token> <answer> softrst_mask; 
<token> (!oh->class->sysc || <answer> if 
<token> & SYSC_HAS_SOFTRESET)) <answer> !(oh->class->sysc->sysc_flags 
return <token> <answer> -EINVAL; 
if (!oh->class->sysc->sysc_fields) <token> <answer> { 
"omap_hwmod: %s: sysc_fields absent for sysconfig <token> <answer> class\n", 
<token> -EINVAL; <answer> return 
softrst_mask <token> (0x1 << oh->class->sysc->sysc_fields->srst_shift); <answer> = 
<token> &= ~softrst_mask; <answer> *v 
<token> 0; <answer> return 
static <token> _wait_softreset_complete(struct omap_hwmod *oh) <answer> int 
<token> omap_hwmod_class_sysconfig *sysc; <answer> struct 
<token> softrst_mask; <answer> u32 
<token> c = 0; <answer> int 
sysc <token> oh->class->sysc; <answer> = 
if (sysc->sysc_flags & <token> && sysc->syss_offs > 0) <answer> SYSS_HAS_RESET_STATUS 
omap_test_timeout((omap_hwmod_read(oh, <token> <answer> sysc->syss_offs) 
& <token> <answer> SYSS_RESETDONE_MASK), 
MAX_MODULE_SOFTRESET_WAIT, <token> <answer> c); 
else if (sysc->sysc_flags <token> SYSC_HAS_RESET_STATUS) { <answer> & 
softrst_mask = <token> << sysc->sysc_fields->srst_shift); <answer> (0x1 
<token> sysc->sysc_offs) <answer> omap_test_timeout(!(omap_hwmod_read(oh, 
<token> softrst_mask), <answer> & 
MAX_MODULE_SOFTRESET_WAIT, <token> <answer> c); 
<token> c; <answer> return 
static int <token> omap_hwmod *oh) <answer> _set_dmadisable(struct 
<token> v; <answer> u32 
<token> dmadisable_mask; <answer> u32 
if (!oh->class->sysc <token> <answer> || 
<token> & SYSC_HAS_DMADISABLE)) <answer> !(oh->class->sysc->sysc_flags 
<token> -EINVAL; <answer> return 
if (!oh->class->sysc->sysc_fields) <token> <answer> { 
WARN(1, "omap_hwmod: %s: offset <token> for sysconfig not provided in class\n", oh->name); <answer> struct 
return <token> <answer> -EINVAL; 
static int _set_module_autoidle(struct omap_hwmod *oh, <token> autoidle, <answer> u8 
<token> *v) <answer> u32 
u32 <token> <answer> autoidle_mask; 
<token> autoidle_shift; <answer> u8 
<token> (!oh->class->sysc || <answer> if 
!(oh->class->sysc->sysc_flags <token> SYSC_HAS_AUTOIDLE)) <answer> & 
<token> -EINVAL; <answer> return 
<token> (!oh->class->sysc->sysc_fields) { <answer> if 
WARN(1, "omap_hwmod: %s: offset struct for sysconfig <token> provided in class\n", oh->name); <answer> not 
<token> -EINVAL; <answer> return 
<token> = oh->class->sysc->sysc_fields->autoidle_shift; <answer> autoidle_shift 
autoidle_mask = <token> << autoidle_shift); <answer> (0x1 
*v &= <token> <answer> ~autoidle_mask; 
*v <token> autoidle << autoidle_shift; <answer> |= 
<token> 0; <answer> return 
static int <token> omap_hwmod *oh, u32 *v) <answer> _enable_wakeup(struct 
<token> (!oh->class->sysc || <answer> if 
!((oh->class->sysc->sysc_flags & <token> || <answer> SYSC_HAS_ENAWAKEUP) 
(oh->class->sysc->idlemodes & <token> || <answer> SIDLE_SMART_WKUP) 
<token> & MSTANDBY_SMART_WKUP))) <answer> (oh->class->sysc->idlemodes 
return <token> <answer> -EINVAL; 
if <token> { <answer> (!oh->class->sysc->sysc_fields) 
WARN(1, "omap_hwmod: %s: offset struct for sysconfig not <token> in class\n", oh->name); <answer> provided 
return <token> <answer> -EINVAL; 
if <token> & SYSC_HAS_ENAWAKEUP) <answer> (oh->class->sysc->sysc_flags 
*v |= <token> << oh->class->sysc->sysc_fields->enwkup_shift; <answer> 0x1 
if (oh->class->sysc->idlemodes & <token> <answer> SIDLE_SMART_WKUP) 
_set_slave_idlemode(oh, HWMOD_IDLEMODE_SMART_WKUP, <token> <answer> v); 
if (oh->class->sysc->idlemodes & <token> <answer> MSTANDBY_SMART_WKUP) 
<token> HWMOD_IDLEMODE_SMART_WKUP, v); <answer> _set_master_standbymode(oh, 
static int <token> omap_hwmod *oh, struct omap_hwmod *init_oh) <answer> _add_initiator_dep(struct 
struct clockdomain <token> *init_clkdm; <answer> *clkdm, 
<token> = _get_clkdm(oh); <answer> clkdm 
init_clkdm <token> _get_clkdm(init_oh); <answer> = 
<token> (!clkdm || !init_clkdm) <answer> if 
<token> -EINVAL; <answer> return 
<token> (clkdm && clkdm->flags & CLKDM_NO_AUTODEPS) <answer> if 
return <token> <answer> 0; 
return <token> init_clkdm); <answer> clkdm_add_sleepdep(clkdm, 
<token> int _del_initiator_dep(struct omap_hwmod *oh, struct omap_hwmod *init_oh) <answer> static 
struct <token> *clkdm, *init_clkdm; <answer> clockdomain 
<token> = _get_clkdm(oh); <answer> clkdm 
init_clkdm <token> _get_clkdm(init_oh); <answer> = 
if (!clkdm <token> !init_clkdm) <answer> || 
<token> -EINVAL; <answer> return 
if (clkdm && clkdm->flags <token> CLKDM_NO_AUTODEPS) <answer> & 
<token> 0; <answer> return 
return <token> init_clkdm); <answer> clkdm_del_sleepdep(clkdm, 
static const struct of_device_id ti_clkctrl_match_table[] __initconst = <token> <answer> { 
{ <token> = "ti,clkctrl" }, <answer> .compatible 
{ <token> <answer> } 
<token> int __init _setup_clkctrl_provider(struct device_node *np) <answer> static 
struct clkctrl_provider <token> <answer> *provider; 
int <token> <answer> i; 
provider = <token> SMP_CACHE_BYTES); <answer> memblock_alloc(sizeof(*provider), 
if <token> <answer> (!provider) 
return <token> <answer> -ENOMEM; 
<token> = np; <answer> provider->node 
provider->num_addrs <token> of_address_count(np); <answer> = 
<token> = <answer> provider->addr 
<token> *) * provider->num_addrs, <answer> memblock_alloc(sizeof(void 
if <token> <answer> (!provider->addr) 
<token> -ENOMEM; <answer> return 
provider->size <token> <answer> = 
memblock_alloc(sizeof(u32) <token> provider->num_addrs, <answer> * 
if <token> <answer> (!provider->size) 
return <token> <answer> -ENOMEM; 
for (i = 0; i < provider->num_addrs; <token> { <answer> i++) 
struct <token> res; <answer> resource 
<token> i, &res); <answer> of_address_to_resource(np, 
provider->addr[i] <token> res.start; <answer> = 
provider->size[i] = <token> <answer> resource_size(&res); 
pr_debug("%s: %pOF: <token> __func__, np, &res); <answer> %pR\n", 
<token> &clkctrl_providers); <answer> list_add(&provider->link, 
return <token> <answer> 0; 
static int __init <token> <answer> _init_clkctrl_providers(void) 
<token> device_node *np; <answer> struct 
int ret = <token> <answer> 0; 
<token> ti_clkctrl_match_table) { <answer> for_each_matching_node(np, 
ret <token> _setup_clkctrl_provider(np); <answer> = 
if <token> { <answer> (ret) 
<token> ret; <answer> return 
static u32 _omap4_xlate_clkctrl(struct omap_hwmod <token> <answer> *oh) 
if <token> <answer> (!oh->prcm.omap4.modulemode) 
<token> 0; <answer> return 
<token> omap_cm_xlate_clkctrl(oh->clkdm->prcm_partition, <answer> return 
static struct clk *_lookup_clkctrl_clk(struct omap_hwmod <token> <answer> *oh) 
<token> clkctrl_provider *provider; <answer> struct 
<token> clk *clk; <answer> struct 
<token> addr; <answer> u32 
if <token> <answer> (!soc_ops.xlate_clkctrl) 
return <token> <answer> NULL; 
addr = <token> <answer> soc_ops.xlate_clkctrl(oh); 
if <token> <answer> (!addr) 
<token> NULL; <answer> return 
pr_debug("%s: %s: addr=%x\n", <token> oh->name, addr); <answer> __func__, 
list_for_each_entry(provider, <token> link) { <answer> &clkctrl_providers, 
<token> i; <answer> int 
for <token> = 0; i < provider->num_addrs; i++) { <answer> (i 
if (provider->addr[i] <= <token> && <answer> addr 
<token> + provider->size[i] > addr) { <answer> provider->addr[i] 
struct <token> clkspec; <answer> of_phandle_args 
clkspec.np <token> provider->node; <answer> = 
clkspec.args_count = <token> <answer> 2; 
clkspec.args[0] = <token> - provider->addr[0]; <answer> addr 
clkspec.args[1] = <token> <answer> 0; 
clk = <token> <answer> of_clk_get_from_provider(&clkspec); 
pr_debug("%s: %s <token> %p (offset=%x, provider=%pOF)\n", <answer> got 
<token> oh->name, clk, <answer> __func__, 
clkspec.args[0], <token> <answer> provider->node); 
return <token> <answer> clk; 
<token> NULL; <answer> return 
static int <token> omap_hwmod *oh) <answer> _init_main_clk(struct 
int <token> = 0; <answer> ret 
struct clk *clk <token> NULL; <answer> = 
clk <token> _lookup_clkctrl_clk(oh); <answer> = 
if (!IS_ERR_OR_NULL(clk)) <token> <answer> { 
pr_debug("%s: mapped main_clk %s for <token> __func__, <answer> %s\n", 
<token> oh->name); <answer> __clk_get_name(clk), 
<token> = __clk_get_name(clk); <answer> oh->main_clk 
<token> = clk; <answer> oh->_clk 
} <token> { <answer> else 
if <token> <answer> (!oh->main_clk) 
return <token> <answer> 0; 
oh->_clk = clk_get(NULL, <token> <answer> oh->main_clk); 
<token> (IS_ERR(oh->_clk)) { <answer> if 
<token> %s: cannot clk_get main_clk %s\n", <answer> pr_warn("omap_hwmod: 
oh->name, <token> <answer> oh->main_clk); 
return <token> <answer> -EINVAL; 
<token> (!_get_clkdm(oh)) <answer> if 
pr_debug("omap_hwmod: %s: missing clockdomain <token> %s.\n", <answer> for 
oh->name, <token> <answer> oh->main_clk); 
return <token> <answer> ret; 
<token> int _init_interface_clks(struct omap_hwmod *oh) <answer> static 
<token> omap_hwmod_ocp_if *os; <answer> struct 
struct clk <token> <answer> *c; 
int <token> = 0; <answer> ret 
list_for_each_entry(os, &oh->slave_ports, <token> { <answer> node) 
if <token> <answer> (!os->clk) 
<token> = clk_get(NULL, os->clk); <answer> c 
<token> (IS_ERR(c)) { <answer> if 
pr_warn("omap_hwmod: <token> cannot clk_get interface_clk %s\n", <answer> %s: 
<token> os->clk); <answer> oh->name, 
ret = <token> <answer> -EINVAL; 
os->_clk = <token> <answer> c; 
return <token> <answer> ret; 
static int <token> omap_hwmod *oh) <answer> _init_opt_clks(struct 
struct <token> *oc; <answer> omap_hwmod_opt_clk 
<token> clk *c; <answer> struct 
<token> i; <answer> int 
<token> ret = 0; <answer> int 
for (i = oh->opt_clks_cnt, oc = oh->opt_clks; i > 0; i--, oc++) <token> <answer> { 
c = <token> oc->clk); <answer> clk_get(NULL, 
if (IS_ERR(c)) <token> <answer> { 
pr_warn("omap_hwmod: %s: cannot clk_get opt_clk <token> <answer> %s\n", 
oh->name, <token> <answer> oc->clk); 
ret = <token> <answer> -EINVAL; 
oc->_clk <token> c; <answer> = 
<token> ret; <answer> return 
static <token> _enable_optional_clocks(struct omap_hwmod *oh) <answer> void 
struct omap_hwmod_opt_clk <token> <answer> *oc; 
int <token> <answer> i; 
pr_debug("omap_hwmod: %s: <token> optional clocks\n", oh->name); <answer> enabling 
for (i = oh->opt_clks_cnt, oc = <token> i > 0; i--, oc++) <answer> oh->opt_clks; 
if <token> { <answer> (oc->_clk) 
pr_debug("omap_hwmod: <token> %s:%s\n", oc->role, <answer> enable 
static void <token> omap_hwmod *oh) <answer> _disable_optional_clocks(struct 
struct omap_hwmod_opt_clk <token> <answer> *oc; 
int <token> <answer> i; 
pr_debug("omap_hwmod: %s: <token> optional clocks\n", oh->name); <answer> disabling 
for (i = oh->opt_clks_cnt, oc = oh->opt_clks; i > <token> i--, oc++) <answer> 0; 
if (oc->_clk) <token> <answer> { 
pr_debug("omap_hwmod: disable %s:%s\n", <token> <answer> oc->role, 
static <token> _enable_clocks(struct omap_hwmod *oh) <answer> int 
<token> omap_hwmod_ocp_if *os; <answer> struct 
pr_debug("omap_hwmod: %s: enabling clocks\n", <token> <answer> oh->name); 
<token> (oh->flags & HWMOD_OPT_CLKS_NEEDED) <answer> if 
if <token> <answer> (oh->_clk) 
list_for_each_entry(os, &oh->slave_ports, node) <token> <answer> { 
if (os->_clk <token> (os->flags & OCPIF_SWSUP_IDLE)) { <answer> && 
static bool _omap4_clkctrl_managed_by_clkfwk(struct <token> *oh) <answer> omap_hwmod 
<token> (oh->prcm.omap4.flags & HWMOD_OMAP4_CLKFWK_CLKCTR_CLOCK) <answer> if 
<token> true; <answer> return 
<token> false; <answer> return 
static bool _omap4_has_clkctrl_clock(struct <token> *oh) <answer> omap_hwmod 
<token> (oh->prcm.omap4.clkctrl_offs) <answer> if 
return <token> <answer> true; 
if (!oh->prcm.omap4.clkctrl_offs <token> <answer> && 
oh->prcm.omap4.flags & <token> <answer> HWMOD_OMAP4_ZERO_CLKCTRL_OFFSET) 
<token> true; <answer> return 
return <token> <answer> false; 
static <token> _disable_clocks(struct omap_hwmod *oh) <answer> int 
struct <token> *os; <answer> omap_hwmod_ocp_if 
pr_debug("omap_hwmod: %s: <token> clocks\n", oh->name); <answer> disabling 
<token> (oh->_clk) <answer> if 
<token> &oh->slave_ports, node) { <answer> list_for_each_entry(os, 
if (os->_clk <token> (os->flags & OCPIF_SWSUP_IDLE)) { <answer> && 
if (oh->flags & <token> <answer> HWMOD_OPT_CLKS_NEEDED) 
static void _omap4_enable_module(struct <token> *oh) <answer> omap_hwmod 
if (!oh->clkdm || !oh->prcm.omap4.modulemode <token> <answer> || 
pr_debug("omap_hwmod: %s: %s: <token> <answer> %d\n", 
<token> __func__, oh->prcm.omap4.modulemode); <answer> oh->name, 
<token> oh->prcm.omap4.clkctrl_offs); <answer> oh->clkdm->cm_inst, 
static <token> _omap4_wait_target_disable(struct omap_hwmod *oh) <answer> int 
<token> (!oh) <answer> if 
return <token> <answer> -EINVAL; 
<token> (oh->_int_flags & _HWMOD_NO_MPU_PORT || !oh->clkdm) <answer> if 
<token> 0; <answer> return 
<token> (oh->flags & HWMOD_NO_IDLEST) <answer> if 
return <token> <answer> 0; 
<token> (_omap4_clkctrl_managed_by_clkfwk(oh)) <answer> if 
<token> 0; <answer> return 
<token> (!_omap4_has_clkctrl_clock(oh)) <answer> if 
<token> 0; <answer> return 
<token> omap_cm_wait_module_idle(oh->clkdm->prcm_partition, <answer> return 
oh->prcm.omap4.clkctrl_offs, <token> <answer> 0); 
static void __init _save_mpu_port_index(struct omap_hwmod <token> <answer> *oh) 
struct omap_hwmod_ocp_if <token> = NULL; <answer> *os 
<token> (!oh) <answer> if 
oh->_int_flags <token> _HWMOD_NO_MPU_PORT; <answer> |= 
list_for_each_entry(os, &oh->slave_ports, <token> { <answer> node) 
if <token> & OCP_USER_MPU) { <answer> (os->user 
<token> = os; <answer> oh->_mpu_port 
oh->_int_flags <token> ~_HWMOD_NO_MPU_PORT; <answer> &= 
static struct omap_hwmod_ocp_if <token> omap_hwmod *oh) <answer> *_find_mpu_rt_port(struct 
if (!oh || <token> & _HWMOD_NO_MPU_PORT || oh->slaves_cnt == 0) <answer> oh->_int_flags 
<token> NULL; <answer> return 
return <token> <answer> oh->_mpu_port; 
static void <token> omap_hwmod *oh) <answer> _enable_sysc(struct 
u8 <token> sf; <answer> idlemode, 
<token> v; <answer> u32 
<token> clkdm_act; <answer> bool 
struct clockdomain <token> <answer> *clkdm; 
<token> (!oh->class->sysc) <answer> if 
if (oh->flags <token> HWMOD_CONTROL_OPT_CLKS_IN_RESET) <answer> & 
if <token> & HWMOD_CONTROL_OPT_CLKS_IN_RESET) <answer> (oh->flags 
v = <token> <answer> oh->_sysc_cache; 
sf = <token> <answer> oh->class->sysc->sysc_flags; 
<token> = _get_clkdm(oh); <answer> clkdm 
if (sf <token> SYSC_HAS_SIDLEMODE) { <answer> & 
if (oh->flags & <token> || <answer> HWMOD_SWSUP_SIDLE 
oh->flags & HWMOD_SWSUP_SIDLE_ACT) <token> <answer> { 
idlemode = <token> <answer> HWMOD_IDLEMODE_NO; 
} else <token> <answer> { 
if (sf <token> SYSC_HAS_ENAWAKEUP) <answer> & 
<token> &v); <answer> _enable_wakeup(oh, 
if <token> & SIDLE_SMART_WKUP) <answer> (oh->class->sysc->idlemodes 
idlemode = <token> <answer> HWMOD_IDLEMODE_SMART_WKUP; 
idlemode <token> HWMOD_IDLEMODE_SMART; <answer> = 
clkdm_act <token> (clkdm && clkdm->flags & CLKDM_ACTIVE_WITH_MPU); <answer> = 
if <token> && !(oh->class->sysc->idlemodes & <answer> (clkdm_act 
(SIDLE_SMART <token> SIDLE_SMART_WKUP))) <answer> | 
<token> = HWMOD_IDLEMODE_FORCE; <answer> idlemode 
<token> idlemode, &v); <answer> _set_slave_idlemode(oh, 
if <token> & SYSC_HAS_MIDLEMODE) { <answer> (sf 
if (oh->flags & HWMOD_FORCE_MSTANDBY) <token> <answer> { 
<token> = HWMOD_IDLEMODE_FORCE; <answer> idlemode 
<token> else if (oh->flags & HWMOD_SWSUP_MSTANDBY) { <answer> } 
<token> = HWMOD_IDLEMODE_NO; <answer> idlemode 
<token> else { <answer> } 
<token> (sf & SYSC_HAS_ENAWAKEUP) <answer> if 
<token> &v); <answer> _enable_wakeup(oh, 
<token> (oh->class->sysc->idlemodes & MSTANDBY_SMART_WKUP) <answer> if 
idlemode <token> HWMOD_IDLEMODE_SMART_WKUP; <answer> = 
idlemode = <token> <answer> HWMOD_IDLEMODE_SMART; 
<token> idlemode, &v); <answer> _set_master_standbymode(oh, 
if ((oh->flags & HWMOD_SET_DEFAULT_CLOCKACT) <token> <answer> && 
(sf <token> SYSC_HAS_CLOCKACTIVITY)) <answer> & 
<token> CLOCKACT_TEST_ICLK, &v); <answer> _set_clockactivity(oh, 
_write_sysconfig(v, <token> <answer> oh); 
<token> (sf & SYSC_HAS_AUTOIDLE) { <answer> if 
idlemode <token> (oh->flags & HWMOD_NO_OCP_AUTOIDLE) ? <answer> = 
0 : <token> <answer> 1; 
<token> idlemode, &v); <answer> _set_module_autoidle(oh, 
<token> oh); <answer> _write_sysconfig(v, 
static <token> _idle_sysc(struct omap_hwmod *oh) <answer> void 
u8 <token> sf; <answer> idlemode, 
<token> v; <answer> u32 
<token> (!oh->class->sysc) <answer> if 
v <token> oh->_sysc_cache; <answer> = 
<token> = oh->class->sysc->sysc_flags; <answer> sf 
if (sf <token> SYSC_HAS_SIDLEMODE) { <answer> & 
<token> (oh->flags & HWMOD_SWSUP_SIDLE) { <answer> if 
idlemode = <token> <answer> HWMOD_IDLEMODE_FORCE; 
} else <token> <answer> { 
if (sf <token> SYSC_HAS_ENAWAKEUP) <answer> & 
<token> &v); <answer> _enable_wakeup(oh, 
<token> (oh->class->sysc->idlemodes & SIDLE_SMART_WKUP) <answer> if 
idlemode = <token> <answer> HWMOD_IDLEMODE_SMART_WKUP; 
<token> = HWMOD_IDLEMODE_SMART; <answer> idlemode 
<token> idlemode, &v); <answer> _set_slave_idlemode(oh, 
if (sf & <token> { <answer> SYSC_HAS_MIDLEMODE) 
if ((oh->flags & <token> || <answer> HWMOD_SWSUP_MSTANDBY) 
(oh->flags & HWMOD_FORCE_MSTANDBY)) <token> <answer> { 
idlemode = <token> <answer> HWMOD_IDLEMODE_FORCE; 
<token> else { <answer> } 
if (sf & <token> <answer> SYSC_HAS_ENAWAKEUP) 
_enable_wakeup(oh, <token> <answer> &v); 
if (oh->class->sysc->idlemodes & <token> <answer> MSTANDBY_SMART_WKUP) 
<token> = HWMOD_IDLEMODE_SMART_WKUP; <answer> idlemode 
idlemode = <token> <answer> HWMOD_IDLEMODE_SMART; 
_set_master_standbymode(oh, <token> &v); <answer> idlemode, 
static void <token> omap_hwmod *oh) <answer> _shutdown_sysc(struct 
u32 <token> <answer> v; 
<token> sf; <answer> u8 
if <token> <answer> (!oh->class->sysc) 
<token> = oh->_sysc_cache; <answer> v 
sf <token> oh->class->sysc->sysc_flags; <answer> = 
<token> (sf & SYSC_HAS_SIDLEMODE) <answer> if 
<token> HWMOD_IDLEMODE_FORCE, &v); <answer> _set_slave_idlemode(oh, 
<token> (sf & SYSC_HAS_MIDLEMODE) <answer> if 
_set_master_standbymode(oh, HWMOD_IDLEMODE_FORCE, <token> <answer> &v); 
<token> (sf & SYSC_HAS_AUTOIDLE) <answer> if 
_set_module_autoidle(oh, <token> &v); <answer> 1, 
<token> oh); <answer> _write_sysconfig(v, 
static <token> omap_hwmod *_lookup(const char *name) <answer> struct 
struct omap_hwmod *oh, <token> <answer> *temp_oh; 
oh <token> NULL; <answer> = 
list_for_each_entry(temp_oh, &omap_hwmod_list, node) <token> <answer> { 
if (!strcmp(name, temp_oh->name)) <token> <answer> { 
oh <token> temp_oh; <answer> = 
<token> oh; <answer> return 
static <token> _init_clkdm(struct omap_hwmod *oh) <answer> int 
if <token> { <answer> (!oh->clkdm_name) 
pr_debug("omap_hwmod: %s: missing <token> oh->name); <answer> clockdomain\n", 
<token> 0; <answer> return 
oh->clkdm = <token> <answer> clkdm_lookup(oh->clkdm_name); 
<token> (!oh->clkdm) { <answer> if 
pr_warn("omap_hwmod: %s: could not <token> to clkdm %s\n", <answer> associate 
<token> oh->clkdm_name); <answer> oh->name, 
return <token> <answer> 0; 
<token> %s: associated to clkdm %s\n", <answer> pr_debug("omap_hwmod: 
<token> oh->clkdm_name); <answer> oh->name, 
<token> 0; <answer> return 
<token> int _init_clocks(struct omap_hwmod *oh, struct device_node *np) <answer> static 
int ret = <token> <answer> 0; 
<token> (oh->_state != _HWMOD_STATE_REGISTERED) <answer> if 
return <token> <answer> 0; 
pr_debug("omap_hwmod: %s: looking <token> clocks\n", oh->name); <answer> up 
if <token> <answer> (soc_ops.init_clkdm) 
<token> |= soc_ops.init_clkdm(oh); <answer> ret 
ret |= <token> <answer> _init_main_clk(oh); 
ret <token> _init_interface_clks(oh); <answer> |= 
ret <token> _init_opt_clks(oh); <answer> |= 
<token> (!ret) <answer> if 
oh->_state = <token> <answer> _HWMOD_STATE_CLKS_INITED; 
pr_warn("omap_hwmod: %s: cannot <token> oh->name); <answer> _init_clocks\n", 
<token> ret; <answer> return 
static <token> _lookup_hardreset(struct omap_hwmod *oh, const char *name, <answer> int 
<token> omap_hwmod_rst_info *ohri) <answer> struct 
int <token> <answer> i; 
for (i = 0; i <token> oh->rst_lines_cnt; i++) { <answer> < 
const char *rst_line = <token> <answer> oh->rst_lines[i].name; 
if (!strcmp(rst_line, name)) <token> <answer> { 
ohri->rst_shift <token> oh->rst_lines[i].rst_shift; <answer> = 
ohri->st_shift = <token> <answer> oh->rst_lines[i].st_shift; 
pr_debug("omap_hwmod: %s: %s: %s: <token> %d st %d\n", <answer> rst 
oh->name, __func__, rst_line, <token> <answer> ohri->rst_shift, 
return <token> <answer> 0; 
return <token> <answer> -ENOENT; 
<token> int _assert_hardreset(struct omap_hwmod *oh, const char *name) <answer> static 
struct <token> ohri; <answer> omap_hwmod_rst_info 
int <token> = -EINVAL; <answer> ret 
if <token> <answer> (!oh) 
return <token> <answer> -EINVAL; 
<token> (!soc_ops.assert_hardreset) <answer> if 
return <token> <answer> -ENOSYS; 
ret = <token> name, &ohri); <answer> _lookup_hardreset(oh, 
if (ret <token> 0) <answer> < 
return <token> <answer> ret; 
ret = <token> &ohri); <answer> soc_ops.assert_hardreset(oh, 
<token> ret; <answer> return 
static int _deassert_hardreset(struct omap_hwmod *oh, const char <token> <answer> *name) 
<token> omap_hwmod_rst_info ohri; <answer> struct 
int ret = <token> <answer> -EINVAL; 
if <token> <answer> (!oh) 
<token> -EINVAL; <answer> return 
<token> (!soc_ops.deassert_hardreset) <answer> if 
<token> -ENOSYS; <answer> return 
ret = _lookup_hardreset(oh, name, <token> <answer> &ohri); 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
<token> (oh->clkdm) { <answer> if 
ret = <token> oh); <answer> clkdm_hwmod_enable(oh->clkdm, 
if (ret) <token> <answer> { 
WARN(1, "omap_hwmod: <token> could not enable clockdomain %s: %d\n", <answer> %s: 
oh->name, oh->clkdm->name, <token> <answer> ret); 
<token> ret; <answer> return 
<token> (soc_ops.enable_module) <answer> if 
ret = soc_ops.deassert_hardreset(oh, <token> <answer> &ohri); 
<token> (soc_ops.disable_module) <answer> if 
if <token> == -EBUSY) <answer> (ret 
pr_warn("omap_hwmod: %s: failed to hardreset\n", <token> <answer> oh->name); 
if (oh->clkdm) <token> <answer> { 
clkdm_hwmod_disable(oh->clkdm, <token> <answer> oh); 
<token> ret; <answer> return 
static <token> _read_hardreset(struct omap_hwmod *oh, const char *name) <answer> int 
struct omap_hwmod_rst_info <token> <answer> ohri; 
int ret <token> -EINVAL; <answer> = 
<token> (!oh) <answer> if 
return <token> <answer> -EINVAL; 
if <token> <answer> (!soc_ops.is_hardreset_asserted) 
<token> -ENOSYS; <answer> return 
ret = _lookup_hardreset(oh, <token> &ohri); <answer> name, 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
return <token> &ohri); <answer> soc_ops.is_hardreset_asserted(oh, 
static bool _are_all_hardreset_lines_asserted(struct <token> *oh) <answer> omap_hwmod 
<token> i, rst_cnt = 0; <answer> int 
if <token> == 0) <answer> (oh->rst_lines_cnt 
return <token> <answer> false; 
for (i = 0; i <token> oh->rst_lines_cnt; i++) <answer> < 
if (_read_hardreset(oh, oh->rst_lines[i].name) > <token> <answer> 0) 
if (oh->rst_lines_cnt == <token> <answer> rst_cnt) 
<token> true; <answer> return 
return <token> <answer> false; 
static bool _are_any_hardreset_lines_asserted(struct omap_hwmod <token> <answer> *oh) 
int rst_cnt = <token> <answer> 0; 
int <token> <answer> i; 
for (i = 0; i < oh->rst_lines_cnt && rst_cnt == <token> i++) <answer> 0; 
<token> (_read_hardreset(oh, oh->rst_lines[i].name) > 0) <answer> if 
return (rst_cnt) <token> true : false; <answer> ? 
static int _omap4_disable_module(struct omap_hwmod <token> <answer> *oh) 
int <token> <answer> v; 
<token> (!oh->clkdm || !oh->prcm.omap4.modulemode || <answer> if 
return <token> <answer> -EINVAL; 
<token> (_are_any_hardreset_lines_asserted(oh)) <answer> if 
return <token> <answer> 0; 
<token> %s: %s\n", oh->name, __func__); <answer> pr_debug("omap_hwmod: 
<token> oh->clkdm->cm_inst, <answer> omap_cm_module_disable(oh->clkdm->prcm_partition, 
v <token> _omap4_wait_target_disable(oh); <answer> = 
if <token> <answer> (v) 
pr_warn("omap_hwmod: %s: _wait_target_disable <token> <answer> failed\n", 
<token> 0; <answer> return 
static int <token> omap_hwmod *oh) <answer> _ocp_softreset(struct 
<token> v; <answer> u32 
<token> c = 0; <answer> int 
int ret <token> 0; <answer> = 
if <token> || <answer> (!oh->class->sysc 
<token> & SYSC_HAS_SOFTRESET)) <answer> !(oh->class->sysc->sysc_flags 
return <token> <answer> -ENOENT; 
if (oh->flags & <token> <answer> HWMOD_CONTROL_OPT_CLKS_IN_RESET) 
return <token> <answer> ret; 
static int <token> omap_hwmod *oh) <answer> _reset(struct 
<token> i, r; <answer> int 
<token> %s: resetting\n", oh->name); <answer> pr_debug("omap_hwmod: 
<token> (oh->class->reset) { <answer> if 
<token> = oh->class->reset(oh); <answer> r 
<token> else { <answer> } 
if (oh->rst_lines_cnt > 0) <token> <answer> { 
for (i = 0; i <token> oh->rst_lines_cnt; i++) <answer> < 
_assert_hardreset(oh, <token> <answer> oh->rst_lines[i].name); 
<token> 0; <answer> return 
<token> else { <answer> } 
<token> = _ocp_softreset(oh); <answer> r 
if (r == <token> <answer> -ENOENT) 
r <token> 0; <answer> = 
<token> (oh->class->sysc) { <answer> if 
<token> r; <answer> return 
static <token> _omap4_update_context_lost(struct omap_hwmod *oh) <answer> void 
<token> (oh->prcm.omap4.flags & HWMOD_OMAP4_NO_CONTEXT_LOSS_BIT) <answer> if 
<token> (!prm_was_any_context_lost_old(oh->clkdm->pwrdm.ptr->prcm_partition, <answer> if 
static <token> _omap4_get_context_lost(struct omap_hwmod *oh) <answer> int 
<token> oh->prcm.omap4.context_lost_counter; <answer> return 
static int <token> omap_hwmod *oh) <answer> _enable(struct 
<token> r; <answer> int 
pr_debug("omap_hwmod: %s: <token> oh->name); <answer> enabling\n", 
if (oh->_int_flags & _HWMOD_SKIP_ENABLE) <token> <answer> { 
oh->_int_flags <token> ~_HWMOD_SKIP_ENABLE; <answer> &= 
return <token> <answer> 0; 
if (oh->_state != <token> && <answer> _HWMOD_STATE_INITIALIZED 
<token> != _HWMOD_STATE_IDLE && <answer> oh->_state 
oh->_state != <token> { <answer> _HWMOD_STATE_DISABLED) 
<token> "omap_hwmod: %s: enabled state can only be entered from initialized, idle, or disabled state\n", <answer> WARN(1, 
return <token> <answer> -EINVAL; 
<token> (_are_all_hardreset_lines_asserted(oh)) <answer> if 
return <token> <answer> 0; 
_add_initiator_dep(oh, <token> <answer> mpu_oh); 
<token> (oh->clkdm) { <answer> if 
r = <token> oh); <answer> clkdm_hwmod_enable(oh->clkdm, 
<token> (r) { <answer> if 
WARN(1, "omap_hwmod: %s: <token> not enable clockdomain %s: %d\n", <answer> could 
oh->name, <token> r); <answer> oh->clkdm->name, 
<token> r; <answer> return 
<token> (soc_ops.enable_module) <answer> if 
if (oh->flags <token> HWMOD_BLOCK_WFI) <answer> & 
if <token> <answer> (soc_ops.update_context_lost) 
r = <token> ? soc_ops.wait_target_ready(oh) : <answer> (soc_ops.wait_target_ready) 
<token> (oh->clkdm && !(oh->flags & HWMOD_CLKDM_NOAUTO)) <answer> if 
<token> (!r) { <answer> if 
oh->_state = <token> <answer> _HWMOD_STATE_ENABLED; 
static <token> _idle(struct omap_hwmod *oh) <answer> int 
if (oh->flags & HWMOD_NO_IDLE) <token> <answer> { 
oh->_int_flags <token> _HWMOD_SKIP_ENABLE; <answer> |= 
<token> 0; <answer> return 
pr_debug("omap_hwmod: %s: <token> oh->name); <answer> idling\n", 
if <token> <answer> (_are_all_hardreset_lines_asserted(oh)) 
<token> 0; <answer> return 
if (oh->_state != <token> { <answer> _HWMOD_STATE_ENABLED) 
WARN(1, "omap_hwmod: %s: idle state <token> only be entered from enabled state\n", <answer> can 
return <token> <answer> -EINVAL; 
if <token> <answer> (oh->class->sysc) 
_del_initiator_dep(oh, <token> <answer> mpu_oh); 
if (oh->clkdm && !(oh->flags & <token> <answer> HWMOD_CLKDM_NOAUTO)) 
if (oh->flags & <token> <answer> HWMOD_BLOCK_WFI) 
<token> (soc_ops.disable_module) <answer> if 
if <token> { <answer> (oh->clkdm) 
<token> oh); <answer> clkdm_hwmod_disable(oh->clkdm, 
oh->_state <token> _HWMOD_STATE_IDLE; <answer> = 
return <token> <answer> 0; 
static int _shutdown(struct omap_hwmod <token> <answer> *oh) 
<token> ret, i; <answer> int 
<token> prev_state; <answer> u8 
if <token> <answer> (_are_all_hardreset_lines_asserted(oh)) 
return <token> <answer> 0; 
if (oh->_state != <token> && <answer> _HWMOD_STATE_IDLE 
oh->_state != _HWMOD_STATE_ENABLED) <token> <answer> { 
WARN(1, "omap_hwmod: %s: disabled state <token> only be entered from idle, or enabled state\n", <answer> can 
<token> -EINVAL; <answer> return 
pr_debug("omap_hwmod: <token> disabling\n", oh->name); <answer> %s: 
<token> (oh->class->pre_shutdown) { <answer> if 
prev_state = <token> <answer> oh->_state; 
<token> (oh->_state == _HWMOD_STATE_IDLE) <answer> if 
<token> = oh->class->pre_shutdown(oh); <answer> ret 
<token> (ret) { <answer> if 
if (prev_state <token> _HWMOD_STATE_IDLE) <answer> == 
<token> ret; <answer> return 
if (oh->class->sysc) <token> <answer> { 
if (oh->_state == <token> <answer> _HWMOD_STATE_IDLE) 
static int <token> device_node *np, <answer> of_dev_hwmod_lookup(struct 
struct omap_hwmod <token> <answer> *oh, 
<token> *index, <answer> int 
struct device_node <token> <answer> **found) 
<token> device_node *np0 = NULL; <answer> struct 
int <token> <answer> res; 
res = <token> oh); <answer> of_dev_find_hwmod(np, 
if (res <token> 0) { <answer> >= 
*found = <token> <answer> np; 
<token> = res; <answer> *index 
<token> 0; <answer> return 
for_each_child_of_node(np, np0) <token> <answer> { 
struct <token> *fc; <answer> device_node 
<token> i; <answer> int 
res = of_dev_hwmod_lookup(np0, <token> &i, &fc); <answer> oh, 
if (res == 0) <token> <answer> { 
*found = <token> <answer> fc; 
*index = <token> <answer> i; 
return <token> <answer> 0; 
*found <token> NULL; <answer> = 
*index = <token> <answer> 0; 
return <token> <answer> -ENODEV; 
static void omap_hwmod_fix_mpu_rt_idx(struct omap_hwmod <token> <answer> *oh, 
<token> device_node *np, <answer> struct 
struct resource <token> <answer> *res) 
struct device_node *child <token> NULL; <answer> = 
int <token> <answer> error; 
child = <token> child); <answer> of_get_next_child(np, 
if <token> <answer> (!child) 
<token> = of_address_to_resource(child, oh->mpu_rt_idx, res); <answer> error 
if <token> <answer> (error) 
pr_err("%s: <token> mapping mpu_rt_idx: %i\n", <answer> error 
<token> error); <answer> __func__, 
int omap_hwmod_parse_module_range(struct <token> *oh, <answer> omap_hwmod 
struct device_node <token> <answer> *np, 
<token> resource *res) <answer> struct 
struct property <token> <answer> *prop; 
const <token> *name; <answer> char 
int <token> <answer> err; 
<token> "compatible", prop, name) <answer> of_property_for_each_string(np, 
if <token> name, 8)) <answer> (!strncmp("ti,sysc-", 
<token> (!name) <answer> if 
return <token> <answer> -ENOENT; 
err = of_range_to_resource(np, 0, <token> <answer> res); 
if <token> <answer> (err) 
<token> err; <answer> return 
<token> %s %pOFn at %pR\n", <answer> pr_debug("omap_hwmod: 
oh->name, <token> res); <answer> np, 
<token> (oh && oh->mpu_rt_idx) { <answer> if 
<token> np, res); <answer> omap_hwmod_fix_mpu_rt_idx(oh, 
return <token> <answer> 0; 
return <token> <answer> 0; 
static int <token> _init_mpu_rt_base(struct omap_hwmod *oh, void *data, <answer> __init 
int index, <token> device_node *np) <answer> struct 
void __iomem *va_start = <token> <answer> NULL; 
<token> resource res; <answer> struct 
<token> error; <answer> int 
if <token> <answer> (!oh) 
<token> -EINVAL; <answer> return 
static int __init _init(struct omap_hwmod <token> void *data) <answer> *oh, 
<token> r, index; <answer> int 
struct <token> *np = NULL; <answer> device_node 
<token> device_node *bus; <answer> struct 
if (oh->_state != <token> <answer> _HWMOD_STATE_REGISTERED) 
<token> 0; <answer> return 
bus <token> of_find_node_by_name(NULL, "ocp"); <answer> = 
<token> (!bus) <answer> if 
return <token> <answer> -ENODEV; 
r <token> of_dev_hwmod_lookup(bus, oh, &index, &np); <answer> = 
if <token> <answer> (r) 
pr_debug("omap_hwmod: %s missing dt <token> oh->name); <answer> data\n", 
else <token> (np && index) <answer> if 
pr_warn("omap_hwmod: <token> using broken dt data from %pOFn\n", <answer> %s 
oh->name, <token> <answer> np); 
r = _init_mpu_rt_base(oh, <token> index, np); <answer> NULL, 
if (r < <token> { <answer> 0) 
WARN(1, "omap_hwmod: %s: doesn't have <token> register target base\n", <answer> mpu 
<token> 0; <answer> return 
r <token> _init_clocks(oh, np); <answer> = 
if <token> < 0) { <answer> (r 
WARN(1, "omap_hwmod: %s: <token> init clocks\n", oh->name); <answer> couldn't 
<token> -EINVAL; <answer> return 
if <token> { <answer> (np) 
struct <token> *child; <answer> device_node 
<token> np); <answer> parse_module_flags(oh, 
child = of_get_next_child(np, <token> <answer> NULL); 
if <token> <answer> (child) 
<token> child); <answer> parse_module_flags(oh, 
oh->_state = <token> <answer> _HWMOD_STATE_INITIALIZED; 
<token> 0; <answer> return 
<token> void _setup_iclk_autoidle(struct omap_hwmod *oh) <answer> static 
struct <token> *os; <answer> omap_hwmod_ocp_if 
if (oh->_state <token> _HWMOD_STATE_INITIALIZED) <answer> != 
list_for_each_entry(os, <token> node) { <answer> &oh->slave_ports, 
<token> (!os->_clk) <answer> if 
if <token> & OCPIF_SWSUP_IDLE) { <answer> (os->flags 
} else <token> <answer> { 
<token> int _setup_reset(struct omap_hwmod *oh) <answer> static 
int r <token> 0; <answer> = 
if (oh->_state <token> _HWMOD_STATE_INITIALIZED) <answer> != 
return <token> <answer> -EINVAL; 
if (oh->flags & <token> <answer> HWMOD_EXT_OPT_MAIN_CLK) 
return <token> <answer> -EPERM; 
if (oh->rst_lines_cnt <token> 0) { <answer> == 
<token> = _enable(oh); <answer> r 
<token> (r) { <answer> if 
pr_warn("omap_hwmod: %s: cannot be <token> for reset (%d)\n", <answer> enabled 
<token> oh->_state); <answer> oh->name, 
<token> -EINVAL; <answer> return 
if (!(oh->flags & <token> <answer> HWMOD_INIT_NO_RESET)) 
r = <token> <answer> _reset(oh); 
return <token> <answer> r; 
static void _setup_postsetup(struct <token> *oh) <answer> omap_hwmod 
<token> postsetup_state; <answer> u8 
if (oh->rst_lines_cnt > <token> <answer> 0) 
postsetup_state = <token> <answer> oh->_postsetup_state; 
if <token> == _HWMOD_STATE_UNKNOWN) <answer> (postsetup_state 
postsetup_state <token> _HWMOD_STATE_ENABLED; <answer> = 
if ((oh->flags & (HWMOD_INIT_NO_IDLE | <token> && <answer> HWMOD_NO_IDLE)) 
(postsetup_state <token> _HWMOD_STATE_IDLE)) { <answer> == 
<token> |= _HWMOD_SKIP_ENABLE; <answer> oh->_int_flags 
postsetup_state <token> _HWMOD_STATE_ENABLED; <answer> = 
if <token> == _HWMOD_STATE_IDLE) <answer> (postsetup_state 
else if <token> == _HWMOD_STATE_DISABLED) <answer> (postsetup_state 
else <token> (postsetup_state != _HWMOD_STATE_ENABLED) <answer> if 
WARN(1, "hwmod: %s: <token> postsetup state %d! defaulting to enabled\n", <answer> unknown 
<token> postsetup_state); <answer> oh->name, 
static <token> _setup(struct omap_hwmod *oh, void *data) <answer> int 
if <token> != _HWMOD_STATE_INITIALIZED) <answer> (oh->_state 
return <token> <answer> 0; 
if <token> { <answer> (oh->parent_hwmod) 
int <token> <answer> r; 
r = <token> <answer> _enable(oh->parent_hwmod); 
WARN(r, "hwmod: %s: <token> failed to enable parent hwmod %s\n", <answer> setup: 
<token> oh->parent_hwmod->name); <answer> oh->name, 
<token> (!_setup_reset(oh)) <answer> if 
if <token> { <answer> (oh->parent_hwmod) 
<token> postsetup_state; <answer> u8 
postsetup_state = <token> <answer> oh->parent_hwmod->_postsetup_state; 
if (postsetup_state == <token> <answer> _HWMOD_STATE_IDLE) 
<token> if (postsetup_state == _HWMOD_STATE_DISABLED) <answer> else 
else if (postsetup_state != <token> <answer> _HWMOD_STATE_ENABLED) 
WARN(1, <token> %s: unknown postsetup state %d! defaulting to enabled\n", <answer> "hwmod: 
oh->parent_hwmod->name, <token> <answer> postsetup_state); 
<token> 0; <answer> return 
static <token> _register(struct omap_hwmod *oh) <answer> int 
if (!oh || !oh->name <token> !oh->class || !oh->class->name || <answer> || 
<token> != _HWMOD_STATE_UNKNOWN)) <answer> (oh->_state 
return <token> <answer> -EINVAL; 
pr_debug("omap_hwmod: %s: registering\n", <token> <answer> oh->name); 
if <token> <answer> (_lookup(oh->name)) 
<token> -EEXIST; <answer> return 
<token> &omap_hwmod_list); <answer> list_add_tail(&oh->node, 
lockdep_set_class(&oh->_lock, <token> <answer> &oh->hwmod_key); 
<token> = _HWMOD_STATE_REGISTERED; <answer> oh->_state 
if <token> MPU_INITIATOR_NAME)) <answer> (!strcmp(oh->name, 
mpu_oh = <token> <answer> oh; 
return <token> <answer> 0; 
static <token> _add_link(struct omap_hwmod_ocp_if *oi) <answer> int 
pr_debug("omap_hwmod: %s -> %s: adding link\n", <token> <answer> oi->master->name, 
list_add(&oi->node, <token> <answer> &oi->slave->slave_ports); 
<token> 0; <answer> return 
static <token> __init _register_link(struct omap_hwmod_ocp_if *oi) <answer> int 
<token> (!oi || !oi->master || !oi->slave || !oi->user) <answer> if 
return <token> <answer> -EINVAL; 
if (oi->_int_flags & <token> <answer> _OCPIF_INT_FLAGS_REGISTERED) 
<token> -EEXIST; <answer> return 
pr_debug("omap_hwmod: registering link from %s <token> %s\n", <answer> to 
<token> oi->slave->name); <answer> oi->master->name, 
<token> (oi->master->_state != _HWMOD_STATE_REGISTERED) <answer> if 
if (oi->slave->_state <token> _HWMOD_STATE_REGISTERED) <answer> != 
<token> |= _OCPIF_INT_FLAGS_REGISTERED; <answer> oi->_int_flags 
<token> 0; <answer> return 
<token> int _omap2xxx_3xxx_wait_target_ready(struct omap_hwmod *oh) <answer> static 
<token> (!oh) <answer> if 
<token> -EINVAL; <answer> return 
<token> (oh->flags & HWMOD_NO_IDLEST) <answer> if 
<token> 0; <answer> return 
if <token> <answer> (!_find_mpu_rt_port(oh)) 
<token> 0; <answer> return 
static int _omap4_wait_target_ready(struct <token> *oh) <answer> omap_hwmod 
if <token> <answer> (!oh) 
return <token> <answer> -EINVAL; 
if (oh->flags & <token> || !oh->clkdm) <answer> HWMOD_NO_IDLEST 
return <token> <answer> 0; 
if <token> <answer> (!_find_mpu_rt_port(oh)) 
return <token> <answer> 0; 
if <token> <answer> (_omap4_clkctrl_managed_by_clkfwk(oh)) 
<token> 0; <answer> return 
<token> (!_omap4_has_clkctrl_clock(oh)) <answer> if 
return <token> <answer> 0; 
static int _omap2_assert_hardreset(struct omap_hwmod <token> <answer> *oh, 
struct <token> *ohri) <answer> omap_hwmod_rst_info 
return <token> 0, <answer> omap_prm_assert_hardreset(ohri->rst_shift, 
<token> 0); <answer> oh->prcm.omap2.module_offs, 
static int _omap2_deassert_hardreset(struct omap_hwmod <token> <answer> *oh, 
<token> omap_hwmod_rst_info *ohri) <answer> struct 
<token> omap_prm_deassert_hardreset(ohri->rst_shift, ohri->st_shift, 0, <answer> return 
oh->prcm.omap2.module_offs, <token> 0); <answer> 0, 
static int <token> omap_hwmod *oh, <answer> _omap2_is_hardreset_asserted(struct 
<token> omap_hwmod_rst_info *ohri) <answer> struct 
return omap_prm_is_hardreset_asserted(ohri->st_shift, <token> <answer> 0, 
<token> 0); <answer> oh->prcm.omap2.module_offs, 
static <token> _omap4_assert_hardreset(struct omap_hwmod *oh, <answer> int 
struct <token> *ohri) <answer> omap_hwmod_rst_info 
if <token> <answer> (!oh->clkdm) 
return <token> <answer> -EINVAL; 
<token> omap_prm_assert_hardreset(ohri->rst_shift, <answer> return 
static <token> _omap4_deassert_hardreset(struct omap_hwmod *oh, <answer> int 
struct omap_hwmod_rst_info <token> <answer> *ohri) 
if <token> <answer> (!oh->clkdm) 
<token> -EINVAL; <answer> return 
<token> (ohri->st_shift) <answer> if 
pr_err("omap_hwmod: %s: %s: hwmod <token> error: OMAP4 does not support st_shift\n", <answer> data 
<token> ohri->name); <answer> oh->name, 
<token> omap_prm_deassert_hardreset(ohri->rst_shift, ohri->rst_shift, <answer> return 
<token> + <answer> oh->prcm.omap4.rstctrl_offs 
<token> int _omap4_is_hardreset_asserted(struct omap_hwmod *oh, <answer> static 
struct omap_hwmod_rst_info <token> <answer> *ohri) 
if <token> <answer> (!oh->clkdm) 
<token> -EINVAL; <answer> return 
return <token> <answer> omap_prm_is_hardreset_asserted(ohri->rst_shift, 
<token> int _omap4_disable_direct_prcm(struct omap_hwmod *oh) <answer> static 
if <token> <answer> (!oh) 
<token> -EINVAL; <answer> return 
oh->prcm.omap4.flags |= <token> <answer> HWMOD_OMAP4_CLKFWK_CLKCTR_CLOCK; 
<token> 0; <answer> return 
static <token> _am33xx_deassert_hardreset(struct omap_hwmod *oh, <answer> int 
struct omap_hwmod_rst_info <token> <answer> *ohri) 
return omap_prm_deassert_hardreset(ohri->rst_shift, <token> <answer> ohri->st_shift, 
<token> omap_hwmod_softreset(struct omap_hwmod *oh) <answer> int 
u32 <token> <answer> v; 
int <token> <answer> ret; 
if <token> || !(oh->_sysc_cache)) <answer> (!oh 
return <token> <answer> -EINVAL; 
v <token> oh->_sysc_cache; <answer> = 
ret = _set_softreset(oh, <token> <answer> &v); 
<token> (ret) <answer> if 
goto <token> <answer> error; 
<token> oh); <answer> _write_sysconfig(v, 
<token> = _clear_softreset(oh, &v); <answer> ret 
<token> (ret) <answer> if 
goto <token> <answer> error; 
<token> oh); <answer> _write_sysconfig(v, 
return <token> <answer> ret; 
struct omap_hwmod *omap_hwmod_lookup(const <token> *name) <answer> char 
struct <token> *oh; <answer> omap_hwmod 
<token> (!name) <answer> if 
<token> NULL; <answer> return 
oh = <token> <answer> _lookup(name); 
return <token> <answer> oh; 
int omap_hwmod_for_each(int (*fn)(struct omap_hwmod *oh, <token> *data), <answer> void 
void <token> <answer> *data) 
<token> omap_hwmod *temp_oh; <answer> struct 
int ret <token> 0; <answer> = 
if <token> <answer> (!fn) 
<token> -EINVAL; <answer> return 
list_for_each_entry(temp_oh, &omap_hwmod_list, node) <token> <answer> { 
ret = <token> data); <answer> (*fn)(temp_oh, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
int __init omap_hwmod_register_links(struct <token> **ois) <answer> omap_hwmod_ocp_if 
<token> r, i; <answer> int 
<token> (!inited) <answer> if 
<token> -EINVAL; <answer> return 
<token> (!ois) <answer> if 
return <token> <answer> 0; 
static <token> __init _ensure_mpu_hwmod_is_setup(struct omap_hwmod *oh) <answer> void 
if (!mpu_oh || <token> == _HWMOD_STATE_UNKNOWN) <answer> mpu_oh->_state 
pr_err("omap_hwmod: %s: MPU initiator hwmod <token> not yet registered\n", <answer> %s 
<token> MPU_INITIATOR_NAME); <answer> __func__, 
else if (mpu_oh->_state == _HWMOD_STATE_REGISTERED && oh <token> mpu_oh) <answer> != 
static <token> __init omap_hwmod_setup_one(const char *oh_name) <answer> int 
<token> omap_hwmod *oh; <answer> struct 
pr_debug("omap_hwmod: %s: <token> oh_name, __func__); <answer> %s\n", 
<token> = _lookup(oh_name); <answer> oh 
if (!oh) <token> <answer> { 
WARN(1, "omap_hwmod: <token> hwmod not yet registered\n", oh_name); <answer> %s: 
<token> -EINVAL; <answer> return 
_init(oh, <token> <answer> NULL); 
<token> NULL); <answer> _setup(oh, 
<token> 0; <answer> return 
static void omap_hwmod_check_one(struct device <token> <answer> *dev, 
const char *name, s8 <token> u8 v2) <answer> v1, 
if (v1 < <token> <answer> 0) 
if (v1 != <token> <answer> v2) 
dev_warn(dev, "%s %d != %d\n", <token> v1, v2); <answer> name, 
<token> int omap_hwmod_check_sysc(struct device *dev, <answer> static 
const struct <token> *data, <answer> ti_sysc_module_data 
<token> sysc_regbits *sysc_fields) <answer> struct 
<token> struct sysc_regbits *regbits = data->cap->regbits; <answer> const 
omap_hwmod_check_one(dev, <token> <answer> "dmadisable_shift", 
omap_hwmod_check_one(dev, <token> <answer> "midle_shift", 
omap_hwmod_check_one(dev, <token> <answer> "sidle_shift", 
omap_hwmod_check_one(dev, <token> <answer> "clkact_shift", 
omap_hwmod_check_one(dev, <token> <answer> "enwkup_shift", 
omap_hwmod_check_one(dev, <token> <answer> "srst_shift", 
<token> "autoidle_shift", <answer> omap_hwmod_check_one(dev, 
<token> 0; <answer> return 
static int omap_hwmod_init_regbits(struct device <token> struct omap_hwmod *oh, <answer> *dev, 
const struct <token> *data, <answer> ti_sysc_module_data 
struct sysc_regbits <token> <answer> **sysc_fields) 
switch <token> { <answer> (data->cap->type) 
<token> TI_SYSC_OMAP2: <answer> case 
case <token> <answer> TI_SYSC_OMAP2_TIMER: 
<token> = &omap_hwmod_sysc_type1; <answer> *sysc_fields 
<token> KBUILD_MODNAME "foo" <answer> #define 
#include <token> <answer> <linux/ip.h> 
<token> <linux/ipv6.h> <answer> #include 
<token> <linux/in.h> <answer> #include 
#include <token> <answer> <linux/tcp.h> 
#include <token> <answer> <linux/udp.h> 
<token> <uapi/linux/bpf.h> <answer> #include 
<token> <bpf/bpf_helpers.h> <answer> #include 
#include <token> <answer> "bpf_legacy.h" 
#define <token> 9 <answer> DEFAULT_PKTGEN_UDP_PORT 
#define <token> 0x2000 <answer> IP_MF 
#define <token> 0x1FFF <answer> IP_OFFSET 
<token> inline int ip_is_fragment(struct __sk_buff *ctx, __u64 nhoff) <answer> static 
return load_half(ctx, <token> + offsetof(struct iphdr, frag_off)) <answer> nhoff 
& (IP_MF <token> IP_OFFSET); <answer> | 
int handle_ingress(struct __sk_buff <token> <answer> *skb) 
__u64 troff = ETH_HLEN <token> sizeof(struct iphdr); <answer> + 
if (load_half(skb, offsetof(struct ethhdr, <token> != ETH_P_IP) <answer> h_proto)) 
<token> 0; <answer> return 
if (load_byte(skb, ETH_HLEN + offsetof(struct iphdr, protocol)) != IPPROTO_UDP <token> <answer> || 
load_byte(skb, ETH_HLEN) != <token> <answer> 0x45) 
return <token> <answer> 0; 
if <token> ETH_HLEN)) <answer> (ip_is_fragment(skb, 
<token> 0; <answer> return 
if (load_half(skb, troff + <token> udphdr, dest)) == DEFAULT_PKTGEN_UDP_PORT) <answer> offsetof(struct 
return <token> <answer> TC_ACT_SHOT; 
<token> 0; <answer> return 
char <token> SEC("license") = "GPL"; <answer> _license[] 
#include <token> <answer> <linux/delay.h> 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/ioport.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <sound/core.h> 
<token> <sound/sb.h> <answer> #include 
#include <token> <answer> <sound/initval.h> 
<token> <asm/dma.h> <answer> #include 
<token> Kysela <perex@perex.cz>"); <answer> MODULE_AUTHOR("Jaroslav 
MODULE_DESCRIPTION("ALSA lowlevel driver <token> Sound Blaster cards"); <answer> for 
#define BUSY_LOOPS <token> <answer> 100000 
#undef <token> <answer> IO_DEBUG 
int snd_sbdsp_command(struct snd_sb <token> unsigned char val) <answer> *chip, 
<token> i; <answer> int 
#ifdef <token> <answer> IO_DEBUG 
snd_printk(KERN_DEBUG <token> 0x%x\n", val); <answer> "command 
<token> (i = BUSY_LOOPS; i; i--) <answer> for 
<token> ((inb(SBP(chip, STATUS)) & 0x80) == 0) { <answer> if 
outb(val, <token> COMMAND)); <answer> SBP(chip, 
return <token> <answer> 1; 
snd_printd("%s [0x%lx]: timeout (0x%x)\n", <token> chip->port, val); <answer> __func__, 
return <token> <answer> 0; 
int snd_sbdsp_get_byte(struct <token> *chip) <answer> snd_sb 
<token> val; <answer> int 
<token> i; <answer> int 
for (i = BUSY_LOOPS; i; i--) <token> <answer> { 
if (inb(SBP(chip, DATA_AVAIL)) <token> 0x80) { <answer> & 
<token> = inb(SBP(chip, READ)); <answer> val 
<token> IO_DEBUG <answer> #ifdef 
<token> "get_byte 0x%x\n", val); <answer> snd_printk(KERN_DEBUG 
<token> val; <answer> return 
snd_printd("%s [0x%lx]: <token> __func__, chip->port); <answer> timeout\n", 
<token> -ENODEV; <answer> return 
int snd_sbdsp_reset(struct snd_sb <token> <answer> *chip) 
<token> i; <answer> int 
outb(1, <token> RESET)); <answer> SBP(chip, 
outb(0, <token> RESET)); <answer> SBP(chip, 
for <token> = BUSY_LOOPS; i; i--) <answer> (i 
if (inb(SBP(chip, DATA_AVAIL)) & 0x80) <token> <answer> { 
if (inb(SBP(chip, READ)) <token> 0xaa) <answer> == 
return <token> <answer> 0; 
snd_printdd("%s [0x%lx] <token> __func__, chip->port); <answer> failed...\n", 
return <token> <answer> -ENODEV; 
static int snd_sbdsp_version(struct snd_sb <token> chip) <answer> * 
<token> int result; <answer> unsigned 
snd_sbdsp_command(chip, <token> <answer> SB_DSP_GET_VERSION); 
result = (short) snd_sbdsp_get_byte(chip) <token> 8; <answer> << 
result <token> (short) snd_sbdsp_get_byte(chip); <answer> |= 
<token> result; <answer> return 
static int snd_sbdsp_probe(struct snd_sb * <token> <answer> chip) 
<token> version; <answer> int 
int major, <token> <answer> minor; 
char <token> <answer> *str; 
unsigned <token> flags; <answer> long 
spin_lock_irqsave(&chip->reg_lock, <token> <answer> flags); 
if (snd_sbdsp_reset(chip) < 0) <token> <answer> { 
spin_unlock_irqrestore(&chip->reg_lock, <token> <answer> flags); 
return <token> <answer> -ENODEV; 
version = <token> <answer> snd_sbdsp_version(chip); 
if <token> < 0) { <answer> (version 
<token> flags); <answer> spin_unlock_irqrestore(&chip->reg_lock, 
return <token> <answer> -ENODEV; 
<token> flags); <answer> spin_unlock_irqrestore(&chip->reg_lock, 
major <token> version >> 8; <answer> = 
minor = <token> & 0xff; <answer> version 
snd_printdd("SB [0x%lx]: DSP chip <token> version = %i.%i\n", <answer> found, 
<token> major, minor); <answer> chip->port, 
switch (chip->hardware) <token> <answer> { 
case <token> <answer> SB_HW_AUTO: 
<token> (major) { <answer> switch 
case <token> <answer> 1: 
chip->hardware = <token> <answer> SB_HW_10; 
str <token> "1.0"; <answer> = 
<token> 2: <answer> case 
if <token> { <answer> (minor) 
chip->hardware <token> SB_HW_201; <answer> = 
str <token> "2.01+"; <answer> = 
<token> else { <answer> } 
<token> = SB_HW_20; <answer> chip->hardware 
str <token> "2.0"; <answer> = 
case <token> <answer> 3: 
chip->hardware <token> SB_HW_PRO; <answer> = 
str <token> "Pro"; <answer> = 
case <token> <answer> 4: 
chip->hardware <token> SB_HW_16; <answer> = 
str <token> "16"; <answer> = 
snd_printk(KERN_INFO "SB [0x%lx]: unknown DSP chip version <token> <answer> %i.%i\n", 
chip->port, <token> minor); <answer> major, 
<token> -ENODEV; <answer> return 
<token> SB_HW_ALS100: <answer> case 
str = <token> (ALS-100)"; <answer> "16 
<token> SB_HW_ALS4000: <answer> case 
str = "16 <token> <answer> (ALS-4000)"; 
case <token> <answer> SB_HW_DT019X: 
str <token> "(DT019X/ALS007)"; <answer> = 
case <token> <answer> SB_HW_CS5530: 
<token> = "16 (CS5530)"; <answer> str 
case <token> <answer> SB_HW_JAZZ16: 
<token> = "Pro (Jazz16)"; <answer> str 
<token> -ENODEV; <answer> return 
sprintf(chip->name, <token> Blaster %s", str); <answer> "Sound 
chip->version = (major << 8) | <token> <answer> minor; 
return <token> <answer> 0; 
int <token> snd_card *card, <answer> snd_sbdsp_create(struct 
<token> long port, <answer> unsigned 
<token> irq, <answer> int 
<token> irq_handler, <answer> irq_handler_t 
int <token> <answer> dma8, 
<token> dma16, <answer> int 
<token> short hardware, <answer> unsigned 
<token> snd_sb **r_chip) <answer> struct 
<token> snd_sb *chip; <answer> struct 
int <token> <answer> err; 
if <token> <answer> (snd_BUG_ON(!r_chip)) 
<token> -EINVAL; <answer> return 
*r_chip <token> NULL; <answer> = 
chip = devm_kzalloc(card->dev, sizeof(*chip), <token> <answer> GFP_KERNEL); 
<token> (!chip) <answer> if 
<token> -ENOMEM; <answer> return 
chip->irq <token> -1; <answer> = 
chip->dma8 = <token> <answer> -1; 
<token> = -1; <answer> chip->dma16 
chip->port <token> port; <answer> = 
<token> (devm_request_irq(card->dev, irq, irq_handler, <answer> if 
(hardware == SB_HW_ALS4000 <token> <answer> || 
hardware == SB_HW_CS5530) <token> <answer> ? 
<token> : 0, <answer> IRQF_SHARED 
"SoundBlaster", (void <token> chip)) { <answer> *) 
snd_printk(KERN_ERR "sb: can't grab irq %d\n", <token> <answer> irq); 
return <token> <answer> -EBUSY; 
<token> = irq; <answer> chip->irq 
card->sync_irq <token> chip->irq; <answer> = 
if (hardware <token> SB_HW_ALS4000) <answer> == 
<token> __skip_allocation; <answer> goto 
chip->res_port <token> devm_request_region(card->dev, port, 16, <answer> = 
if (!chip->res_port) <token> <answer> { 
snd_printk(KERN_ERR "sb: can't grab port 0x%lx\n", <token> <answer> port); 
return <token> <answer> -EBUSY; 
#ifdef <token> <answer> CONFIG_ISA 
if (dma8 >= 0 <token> snd_devm_request_dma(card->dev, dma8, <answer> && 
"SoundBlaster - 8bit")) <token> <answer> { 
snd_printk(KERN_ERR "sb: can't grab <token> %d\n", dma8); <answer> DMA8 
return <token> <answer> -EBUSY; 
chip->dma8 <token> dma8; <answer> = 
<token> (dma16 >= 0) { <answer> if 
if (hardware <token> SB_HW_ALS100 && (dma16 < 5 || dma16 > 7)) { <answer> != 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/i2c.h> 
#include <token> <answer> <linux/power_supply.h> 
<token> <linux/regmap.h> <answer> #include 
<token> <linux/types.h> <answer> #include 
<token> <linux/gpio/consumer.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/acpi.h> 
#include <token> <answer> <linux/of.h> 
#define <token> 0x00 <answer> BQ24257_REG_1 
#define <token> 0x01 <answer> BQ24257_REG_2 
#define <token> 0x02 <answer> BQ24257_REG_3 
#define BQ24257_REG_4 <token> <answer> 0x03 
#define <token> 0x04 <answer> BQ24257_REG_5 
#define <token> 0x05 <answer> BQ24257_REG_6 
#define <token> 0x06 <answer> BQ24257_REG_7 
#define <token> "Texas Instruments" <answer> BQ24257_MANUFACTURER 
#define <token> "pg" <answer> BQ24257_PG_GPIO 
<token> (ret >= BQ24257_IILIMIT_MAP_SIZE) <answer> if 
<token> -ENODATA; <answer> return 
val->intval = <token> <answer> bq24257_iilimit_map[ret]; 
<token> 0; <answer> return 
static int <token> bq24257_device *bq, <answer> bq24257_set_input_current_limit(struct 
const union <token> *val) <answer> power_supply_propval 
<token> (bq->iilimit_autoset_enable) <answer> if 
<token> bq24257_field_write(bq, F_IILIMIT, <answer> return 
static <token> bq24257_power_supply_get_property(struct power_supply *psy, <answer> int 
enum <token> psp, <answer> power_supply_property 
union <token> *val) <answer> power_supply_propval 
struct bq24257_device *bq = <token> <answer> power_supply_get_drvdata(psy); 
struct bq24257_state <token> <answer> state; 
state = <token> <answer> bq->state; 
switch (psp) <token> <answer> { 
<token> POWER_SUPPLY_PROP_STATUS: <answer> case 
<token> (!state.power_good) <answer> if 
val->intval <token> POWER_SUPPLY_STATUS_DISCHARGING; <answer> = 
else if (state.status <token> STATUS_READY) <answer> == 
val->intval <token> POWER_SUPPLY_STATUS_NOT_CHARGING; <answer> = 
else if (state.status == <token> <answer> STATUS_CHARGE_IN_PROGRESS) 
val->intval = <token> <answer> POWER_SUPPLY_STATUS_CHARGING; 
else if <token> == STATUS_CHARGE_DONE) <answer> (state.status 
val->intval <token> POWER_SUPPLY_STATUS_FULL; <answer> = 
val->intval = <token> <answer> POWER_SUPPLY_STATUS_UNKNOWN; 
case <token> <answer> POWER_SUPPLY_PROP_MANUFACTURER: 
<token> = BQ24257_MANUFACTURER; <answer> val->strval 
case <token> <answer> POWER_SUPPLY_PROP_MODEL_NAME: 
<token> = bq->info->name; <answer> val->strval 
<token> POWER_SUPPLY_PROP_ONLINE: <answer> case 
<token> = state.power_good; <answer> val->intval 
<token> POWER_SUPPLY_PROP_HEALTH: <answer> case 
switch (state.fault) <token> <answer> { 
<token> FAULT_NORMAL: <answer> case 
<token> = POWER_SUPPLY_HEALTH_GOOD; <answer> val->intval 
case <token> <answer> FAULT_INPUT_OVP: 
case <token> <answer> FAULT_BAT_OVP: 
val->intval <token> POWER_SUPPLY_HEALTH_OVERVOLTAGE; <answer> = 
case <token> <answer> FAULT_TS: 
case <token> <answer> FAULT_BAT_TS: 
<token> = POWER_SUPPLY_HEALTH_OVERHEAT; <answer> val->intval 
<token> FAULT_TIMER: <answer> case 
val->intval = <token> <answer> POWER_SUPPLY_HEALTH_SAFETY_TIMER_EXPIRE; 
val->intval = <token> <answer> POWER_SUPPLY_HEALTH_UNSPEC_FAILURE; 
case <token> <answer> POWER_SUPPLY_PROP_CONSTANT_CHARGE_CURRENT: 
val->intval = <token> <answer> bq24257_ichg_map[bq->init_data.ichg]; 
case <token> <answer> POWER_SUPPLY_PROP_CONSTANT_CHARGE_CURRENT_MAX: 
val->intval = bq24257_ichg_map[BQ24257_ICHG_MAP_SIZE - <token> <answer> 1]; 
<token> POWER_SUPPLY_PROP_CONSTANT_CHARGE_VOLTAGE: <answer> case 
val->intval <token> bq24257_vbat_map[bq->init_data.vbat]; <answer> = 
case <token> <answer> POWER_SUPPLY_PROP_CONSTANT_CHARGE_VOLTAGE_MAX: 
val->intval <token> bq24257_vbat_map[BQ24257_VBAT_MAP_SIZE - 1]; <answer> = 
case <token> <answer> POWER_SUPPLY_PROP_CHARGE_TERM_CURRENT: 
val->intval <token> bq24257_iterm_map[bq->init_data.iterm]; <answer> = 
<token> POWER_SUPPLY_PROP_INPUT_CURRENT_LIMIT: <answer> case 
return bq24257_get_input_current_limit(bq, <token> <answer> val); 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
static int bq24257_power_supply_set_property(struct <token> *psy, <answer> power_supply 
enum <token> prop, <answer> power_supply_property 
<token> union power_supply_propval *val) <answer> const 
struct <token> *bq = power_supply_get_drvdata(psy); <answer> bq24257_device 
switch (prop) <token> <answer> { 
<token> POWER_SUPPLY_PROP_INPUT_CURRENT_LIMIT: <answer> case 
<token> bq24257_set_input_current_limit(bq, val); <answer> return 
<token> -EINVAL; <answer> return 
<token> int bq24257_power_supply_property_is_writeable(struct power_supply *psy, <answer> static 
enum <token> psp) <answer> power_supply_property 
switch (psp) <token> <answer> { 
<token> POWER_SUPPLY_PROP_INPUT_CURRENT_LIMIT: <answer> case 
return <token> <answer> true; 
<token> false; <answer> return 
static <token> bq24257_get_chip_state(struct bq24257_device *bq, <answer> int 
struct <token> *state) <answer> bq24257_state 
int <token> <answer> ret; 
<token> = bq24257_field_read(bq, F_STAT); <answer> ret 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
state->status <token> ret; <answer> = 
<token> = bq24257_field_read(bq, F_FAULT); <answer> ret 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
state->fault = <token> <answer> ret; 
<token> (bq->pg) <answer> if 
state->power_good = <token> <answer> !gpiod_get_value_cansleep(bq->pg); 
switch <token> { <answer> (state->fault) 
case <token> <answer> FAULT_INPUT_OVP: 
case <token> <answer> FAULT_INPUT_UVLO: 
case <token> <answer> FAULT_INPUT_LDO_LOW: 
<token> = false; <answer> state->power_good 
state->power_good <token> true; <answer> = 
<token> 0; <answer> return 
static bool <token> bq24257_device *bq, <answer> bq24257_state_changed(struct 
<token> bq24257_state *new_state) <answer> struct 
<token> ret; <answer> int 
<token> = (bq->state.status != new_state->status || <answer> ret 
<token> != new_state->fault || <answer> bq->state.fault 
bq->state.power_good != <token> <answer> new_state->power_good); 
return <token> <answer> ret; 
enum bq24257_loop_status <token> <answer> { 
<token> bq24257_in_ilimit { <answer> enum 
enum bq24257_vovp <token> <answer> { 
enum bq24257_vindpm <token> <answer> { 
enum bq24257_port_type <token> <answer> { 
if (loop_status == LOOP_STATUS_IN_DPM && <token> == IILIMIT_500) <answer> iilimit 
<token> 0; <answer> return 
ret = <token> F_USB_DET); <answer> bq24257_field_read(bq, 
if (ret <token> 0) <answer> < 
<token> error; <answer> goto 
port_type = <token> <answer> ret; 
ret <token> bq24257_field_write(bq, F_IILIMIT, new_iilimit[port_type]); <answer> = 
if <token> < 0) <answer> (ret 
<token> error; <answer> goto 
ret = bq24257_field_write(bq, <token> SAFETY_TIMER_360); <answer> F_TMR, 
if (ret <token> 0) <answer> < 
goto <token> <answer> error; 
ret = bq24257_field_write(bq, F_CLR_VDP, <token> <answer> 1); 
if <token> < 0) <answer> (ret 
<token> error; <answer> goto 
dev_dbg(bq->dev, "port/loop = %d/%d <token> iilimit = %d\n", <answer> -> 
<token> loop_status, new_iilimit[port_type]); <answer> port_type, 
<token> 0; <answer> return 
<token> "%s: Error communicating with the chip.\n", __func__); <answer> dev_err(bq->dev, 
<token> ret; <answer> return 
static void <token> work_struct *work) <answer> bq24257_iilimit_setup_work(struct 
struct <token> *bq = container_of(work, struct bq24257_device, <answer> bq24257_device 
static void <token> bq24257_device *bq, <answer> bq24257_handle_state_change(struct 
<token> bq24257_state *new_state) <answer> struct 
int <token> <answer> ret; 
struct bq24257_state <token> <answer> old_state; 
old_state = <token> <answer> bq->state; 
if (!new_state->power_good) <token> <answer> { 
dev_dbg(bq->dev, "Power <token> <answer> removed\n"); 
if (bq->iilimit_autoset_enable) <token> <answer> { 
ret = bq24257_field_write(bq, F_IILIMIT, <token> <answer> bq->init_data.iilimit); 
if (ret < <token> <answer> 0) 
<token> error; <answer> goto 
<token> else if (!old_state.power_good) { <answer> } 
dev_dbg(bq->dev, "Power <token> <answer> inserted\n"); 
<token> (bq->iilimit_autoset_enable) <answer> if 
ret = bq24257_field_write(bq, F_WD_EN, <token> <answer> 0); 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
bq->init_data.iilimit <token> IILIMIT_500; <answer> = 
} <token> <answer> else 
<token> = <answer> bq->init_data.iilimit 
ret <token> device_property_read_u32(bq->dev, "ti,ovp-voltage", <answer> = 
<token> (ret < 0) <answer> if 
<token> = VOVP_6500; <answer> bq->init_data.vovp 
<token> = bq24257_find_idx(property, <answer> bq->init_data.vovp 
ret <token> device_property_read_u32(bq->dev, "ti,in-dpm-voltage", <answer> = 
if (ret <token> 0) <answer> < 
bq->init_data.vindpm = <token> <answer> VINDPM_4360; 
<token> = <answer> bq->init_data.vindpm 
return <token> <answer> 0; 
<token> int bq24257_probe(struct i2c_client *client) <answer> static 
<token> i2c_adapter *adapter = client->adapter; <answer> struct 
struct device *dev <token> &client->dev; <answer> = 
<token> bq24257_device *bq; <answer> struct 
int <token> <answer> ret; 
int <token> <answer> i; 
if <token> I2C_FUNC_SMBUS_BYTE_DATA)) { <answer> (!i2c_check_functionality(adapter, 
dev_err(dev, "No <token> for SMBUS_BYTE_DATA\n"); <answer> support 
return <token> <answer> -ENODEV; 
bq = devm_kzalloc(dev, sizeof(*bq), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!bq) 
return <token> <answer> -ENOMEM; 
bq->client = <token> <answer> client; 
<token> = dev; <answer> bq->dev 
<token> = i2c_get_match_data(client); <answer> bq->info 
<token> (!bq->info) <answer> if 
return dev_err_probe(dev, <token> "Failed to match device\n"); <answer> -ENODEV, 
bq->rmap = <token> &bq24257_regmap_config); <answer> devm_regmap_init_i2c(client, 
<token> (IS_ERR(bq->rmap)) { <answer> if 
dev_err(dev, "failed <token> allocate register map\n"); <answer> to 
return <token> <answer> PTR_ERR(bq->rmap); 
for (i = 0; i < ARRAY_SIZE(bq24257_reg_fields); i++) <token> <answer> { 
<token> struct reg_field *reg_fields = bq24257_reg_fields; <answer> const 
<token> = devm_regmap_field_alloc(dev, bq->rmap, <answer> bq->rmap_fields[i] 
<token> (IS_ERR(bq->rmap_fields[i])) { <answer> if 
dev_err(dev, "cannot <token> regmap field\n"); <answer> allocate 
return <token> <answer> PTR_ERR(bq->rmap_fields[i]); 
<token> bq); <answer> i2c_set_clientdata(client, 
if <token> { <answer> (!dev->platform_data) 
ret = <token> <answer> bq24257_fw_probe(bq); 
if <token> < 0) { <answer> (ret 
dev_err(dev, "Cannot read <token> properties.\n"); <answer> device 
<token> ret; <answer> return 
} <token> { <answer> else 
return <token> <answer> -ENODEV; 
if (bq->info->chip <token> BQ24250) <answer> == 
bq->iilimit_autoset_enable = <token> <answer> false; 
<token> (bq->iilimit_autoset_enable) <answer> if 
<token> (bq->info->chip != BQ24250) <answer> if 
<token> (PTR_ERR(bq->pg) == -EPROBE_DEFER) <answer> if 
return <token> <answer> PTR_ERR(bq->pg); 
else if <token> <answer> (!bq->pg) 
dev_info(bq->dev, "using SW-based power-good <token> <answer> detection\n"); 
<token> = bq24257_field_write(bq, F_RESET, 0); <answer> ret 
<token> (ret < 0) <answer> if 
<token> ret; <answer> return 
ret <token> bq24257_hw_init(bq); <answer> = 
<token> (ret < 0) { <answer> if 
dev_err(dev, "Cannot initialize the <token> <answer> chip.\n"); 
<token> ret; <answer> return 
ret = <token> <answer> bq24257_power_supply_init(bq); 
if (ret < <token> { <answer> 0) 
dev_err(dev, "Failed to register <token> supply\n"); <answer> power 
<token> ret; <answer> return 
ret = <token> client->irq, NULL, <answer> devm_request_threaded_irq(dev, 
IRQF_TRIGGER_FALLING <token> <answer> | 
IRQF_TRIGGER_RISING | <token> <answer> IRQF_ONESHOT, 
bq->info->name, <token> <answer> bq); 
<token> (ret) { <answer> if 
dev_err(dev, "Failed to <token> IRQ #%d\n", client->irq); <answer> request 
<token> ret; <answer> return 
return <token> <answer> 0; 
static void <token> i2c_client *client) <answer> bq24257_remove(struct 
<token> bq24257_device *bq = i2c_get_clientdata(client); <answer> struct 
<token> (bq->iilimit_autoset_enable) <answer> if 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/etherdevice.h> 
<token> <net/mac80211.h> <answer> #include 
<token> "iwl-debug.h" <answer> #include 
<token> "mvm.h" <answer> #include 
#include <token> <answer> "iwl-modparams.h" 
<token> "fw/api/power.h" <answer> #include 
#define <token> 25 <answer> POWER_KEEP_ALIVE_PERIOD_SEC 
int iwl_mvm_beacon_filter_send_cmd(struct <token> *mvm, <answer> iwl_mvm 
<token> iwl_beacon_filter_cmd *cmd) <answer> struct 
<token> len; <answer> u16 
<token> "ba_enable_beacon_abort is: %d\n", <answer> IWL_DEBUG_POWER(mvm, 
IWL_DEBUG_POWER(mvm, "ba_escape_timer <token> %d\n", <answer> is: 
IWL_DEBUG_POWER(mvm, <token> is: %d\n", <answer> "bf_debug_flag 
IWL_DEBUG_POWER(mvm, "bf_enable_beacon_filter is: <token> <answer> %d\n", 
IWL_DEBUG_POWER(mvm, <token> is: %d\n", <answer> "bf_energy_delta 
IWL_DEBUG_POWER(mvm, "bf_escape_timer <token> %d\n", <answer> is: 
IWL_DEBUG_POWER(mvm, <token> is: %d\n", <answer> "bf_roaming_energy_delta 
IWL_DEBUG_POWER(mvm, <token> is: %d\n", <answer> "bf_roaming_state 
IWL_DEBUG_POWER(mvm, "bf_temp_threshold <token> %d\n", <answer> is: 
IWL_DEBUG_POWER(mvm, "bf_temp_fast_filter <token> %d\n", <answer> is: 
IWL_DEBUG_POWER(mvm, "bf_temp_slow_filter is: <token> <answer> %d\n", 
IWL_DEBUG_POWER(mvm, "bf_threshold_absolute_low <token> %d, %d\n", <answer> is: 
IWL_DEBUG_POWER(mvm, "bf_threshold_absolute_high <token> %d, %d\n", <answer> is: 
if <token> <answer> (fw_has_api(&mvm->fw->ucode_capa, 
len <token> sizeof(struct iwl_beacon_filter_cmd); <answer> = 
len = <token> iwl_beacon_filter_cmd, <answer> offsetof(struct 
return <token> REPLY_BEACON_FILTERING_CMD, 0, <answer> iwl_mvm_send_cmd_pdu(mvm, 
len, <token> <answer> cmd); 
void iwl_mvm_beacon_filter_set_cqm_params(struct <token> *mvm, <answer> iwl_mvm 
<token> ieee80211_vif *vif, <answer> struct 
struct iwl_beacon_filter_cmd <token> <answer> *cmd) 
<token> iwl_mvm_vif *mvmvif = iwl_mvm_vif_from_mac80211(vif); <answer> struct 
if <token> { <answer> (vif->bss_conf.cqm_rssi_thold) 
<token> = <answer> cmd->bf_energy_delta 
<token> (vif->p2p && <answer> if 
(vif->bss_conf.p2p_noa_attr.oppps_ctwindow <token> <answer> & 
return <token> <answer> false; 
if (iwl_mvm_phy_ctx_count(mvm) <token> 2) <answer> >= 
return <token> <answer> false; 
<token> (vif->p2p) { <answer> if 
<token> = DIV_ROUND_UP(ieee80211_tu_to_usec(3 * dtimper * bi), <answer> keep_alive 
<token> = max(keep_alive, POWER_KEEP_ALIVE_PERIOD_SEC); <answer> keep_alive 
cmd->keep_alive_seconds <token> cpu_to_le16(keep_alive); <answer> = 
<token> (mvm->ps_disabled) <answer> if 
<token> |= cpu_to_le16(POWER_FLAGS_POWER_SAVE_ENA_MSK); <answer> cmd->flags 
if (!vif->cfg.ps <token> !mvmvif->pm_enabled) <answer> || 
<token> (iwl_mvm_vif_low_latency(mvmvif) && vif->p2p && <answer> if 
<token> || <answer> IWL_UCODE_TLV_CAPA_SHORT_PM_TIMEOUTS) 
cmd->flags |= <token> <answer> cpu_to_le16(POWER_FLAGS_POWER_MANAGEMENT_ENA_MSK); 
if <token> && <answer> (vif->bss_conf.beacon_rate 
(vif->bss_conf.beacon_rate->bitrate == <token> || <answer> 10 
vif->bss_conf.beacon_rate->bitrate == <token> { <answer> 60)) 
<token> |= cpu_to_le16(POWER_FLAGS_LPRX_ENA_MSK); <answer> cmd->flags 
<token> = POWER_LPRX_RSSI_THRESHOLD; <answer> cmd->lprx_rssi_threshold 
iwl_mvm_power_config_skip_dtim(mvm, <token> cmd); <answer> vif, 
<token> (test_bit(IWL_MVM_STATUS_IN_D3, &mvm->status)) { <answer> if 
cmd->rx_data_timeout <token> <answer> = 
<token> = <answer> cmd->tx_data_timeout 
} else if (iwl_mvm_vif_low_latency(mvmvif) && vif->p2p <token> <answer> && 
<token> { <answer> IWL_UCODE_TLV_CAPA_SHORT_PM_TIMEOUTS)) 
cmd->tx_data_timeout <token> <answer> = 
cmd->rx_data_timeout <token> <answer> = 
<token> else { <answer> } 
<token> = <answer> cmd->rx_data_timeout 
cmd->tx_data_timeout <token> <answer> = 
<token> (iwl_mvm_power_allow_uapsd(mvm, vif)) <answer> if 
<token> vif, cmd); <answer> iwl_mvm_power_configure_uapsd(mvm, 
#ifdef <token> <answer> CONFIG_IWLWIFI_DEBUGFS 
if (mvmvif->dbgfs_pm.mask & <token> <answer> MVM_DEBUGFS_PM_KEEP_ALIVE) 
<token> = <answer> cmd->keep_alive_seconds 
if (mvmvif->dbgfs_pm.mask & MVM_DEBUGFS_PM_SKIP_OVER_DTIM) <token> <answer> { 
<token> (mvmvif->dbgfs_pm.skip_over_dtim) <answer> if 
<token> |= <answer> cmd->flags 
cmd->flags <token> <answer> &= 
<token> (mvmvif->dbgfs_pm.mask & MVM_DEBUGFS_PM_RX_DATA_TIMEOUT) <answer> if 
cmd->rx_data_timeout <token> <answer> = 
if (mvmvif->dbgfs_pm.mask & <token> <answer> MVM_DEBUGFS_PM_TX_DATA_TIMEOUT) 
cmd->tx_data_timeout <token> <answer> = 
<token> (mvmvif->dbgfs_pm.mask & MVM_DEBUGFS_PM_SKIP_DTIM_PERIODS) <answer> if 
cmd->skip_dtim_periods <token> mvmvif->dbgfs_pm.skip_dtim_periods; <answer> = 
if <token> & MVM_DEBUGFS_PM_LPRX_ENA) { <answer> (mvmvif->dbgfs_pm.mask 
if <token> <answer> (mvmvif->dbgfs_pm.lprx_ena) 
cmd->flags |= <token> <answer> cpu_to_le16(POWER_FLAGS_LPRX_ENA_MSK); 
<token> &= cpu_to_le16(~POWER_FLAGS_LPRX_ENA_MSK); <answer> cmd->flags 
if (mvmvif->dbgfs_pm.mask & <token> <answer> MVM_DEBUGFS_PM_LPRX_RSSI_THRESHOLD) 
<token> = mvmvif->dbgfs_pm.lprx_rssi_threshold; <answer> cmd->lprx_rssi_threshold 
if <token> & MVM_DEBUGFS_PM_SNOOZE_ENABLE) { <answer> (mvmvif->dbgfs_pm.mask 
if <token> <answer> (mvmvif->dbgfs_pm.snooze_ena) 
cmd->flags <token> <answer> |= 
cmd->flags <token> <answer> &= 
<token> (mvmvif->dbgfs_pm.mask & MVM_DEBUGFS_PM_UAPSD_MISBEHAVING) { <answer> if 
u16 flag <token> POWER_FLAGS_UAPSD_MISBEHAVING_ENA_MSK; <answer> = 
if <token> <answer> (mvmvif->dbgfs_pm.uapsd_misbehaving) 
cmd->flags <token> cpu_to_le16(flag); <answer> |= 
cmd->flags &= <token> <answer> cpu_to_le16(flag); 
if <token> == *ap_sta_id) { <answer> (link_info->ap_sta_id 
void iwl_mvm_power_uapsd_misbehaving_ap_notif(struct iwl_mvm <token> <answer> *mvm, 
<token> iwl_rx_cmd_buffer *rxb) <answer> struct 
struct <token> *pkt = rxb_addr(rxb); <answer> iwl_rx_packet 
struct iwl_uapsd_misbehaving_ap_notif *notif = <token> *)pkt->data; <answer> (void 
u8 <token> = le32_to_cpu(notif->sta_id); <answer> ap_sta_id 
<token> IEEE80211_IFACE_ITER_NORMAL, <answer> mvm->hw, 
iwl_mvm_power_uapsd_misbehav_ap_iterator, <token> <answer> &ap_sta_id); 
struct iwl_power_vifs <token> <answer> { 
<token> iwl_mvm *mvm; <answer> struct 
struct ieee80211_vif <token> <answer> *bss_vif; 
struct ieee80211_vif <token> <answer> *p2p_vif; 
<token> ieee80211_vif *ap_vif; <answer> struct 
struct ieee80211_vif <token> <answer> *monitor_vif; 
<token> p2p_active; <answer> bool 
bool <token> <answer> bss_active; 
bool <token> <answer> ap_active; 
bool <token> <answer> monitor_active; 
static void iwl_mvm_power_disable_pm_iterator(void <token> u8* mac, <answer> *_data, 
struct <token> *vif) <answer> ieee80211_vif 
struct <token> *mvmvif = iwl_mvm_vif_from_mac80211(vif); <answer> iwl_mvm_vif 
<token> = false; <answer> mvmvif->pm_enabled 
static <token> iwl_mvm_power_ps_disabled_iterator(void *_data, u8* mac, <answer> void 
<token> ieee80211_vif *vif) <answer> struct 
struct iwl_mvm_vif <token> = iwl_mvm_vif_from_mac80211(vif); <answer> *mvmvif 
bool <token> = _data; <answer> *disable_ps 
<token> (iwl_mvm_vif_is_active(mvmvif)) <answer> if 
<token> |= mvmvif->ps_disabled; <answer> *disable_ps 
static void <token> *_data, u8 *mac, <answer> iwl_mvm_power_get_vifs_iterator(void 
struct ieee80211_vif <token> <answer> *vif) 
<token> iwl_mvm_vif *mvmvif = iwl_mvm_vif_from_mac80211(vif); <answer> struct 
<token> iwl_power_vifs *power_iterator = _data; <answer> struct 
bool <token> <answer> active; 
if <token> <answer> (!mvmvif->uploaded) 
active <token> iwl_mvm_vif_is_active(mvmvif); <answer> = 
switch <token> { <answer> (ieee80211_vif_type_p2p(vif)) 
case <token> <answer> NL80211_IFTYPE_P2P_DEVICE: 
case <token> <answer> NL80211_IFTYPE_P2P_GO: 
<token> NL80211_IFTYPE_AP: <answer> case 
<token> (client_same_channel && !vifs->ap_active) { <answer> if 
#include <token> <answer> <linux/gpio.h> 
<token> "gpio-cfg.h" <answer> #include 
<token> "keypad.h" <answer> #include 
<token> "gpio-samsung.h" <answer> #include 
void samsung_keypad_cfg_gpio(unsigned int <token> unsigned int cols) <answer> rows, 
<token> <linux/errno.h> <answer> #include 
<token> <linux/firmware.h> <answer> #include 
#include <token> <answer> <linux/pci.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/kfifo.h> <answer> #include 
<token> <linux/pm_runtime.h> <answer> #include 
#include <token> <answer> <linux/timer.h> 
<token> <asm/iosf_mbi.h> <answer> #include 
#include <token> <answer> <media/v4l2-event.h> 
#define <token> <answer> CREATE_TRACE_POINTS 
<token> "atomisp_trace_event.h" <answer> #include 
#include <token> <answer> "atomisp_cmd.h" 
#include <token> <answer> "atomisp_common.h" 
<token> "atomisp_fops.h" <answer> #include 
<token> "atomisp_internal.h" <answer> #include 
#include <token> <answer> "atomisp_ioctl.h" 
<token> "atomisp-regs.h" <answer> #include 
<token> "atomisp_tables.h" <answer> #include 
#include <token> <answer> "atomisp_compat.h" 
#include <token> <answer> "atomisp_subdev.h" 
#include <token> <answer> "atomisp_dfs_tables.h" 
#include <token> <answer> <hmm/hmm.h> 
<token> "sh_css_hrt.h" <answer> #include 
#include <token> <answer> "sh_css_defs.h" 
<token> "system_global.h" <answer> #include 
#include <token> <answer> "sh_css_internal.h" 
#include <token> <answer> "sh_css_sp.h" 
<token> "gp_device.h" <answer> #include 
#include <token> <answer> "device_access.h" 
<token> "irq.h" <answer> #include 
<token> "ia_css_types.h" <answer> #include 
<token> "ia_css_stream.h" <answer> #include 
<token> "ia_css_debug.h" <answer> #include 
<token> "bits.h" <answer> #include 
struct camera_mipi_info *atomisp_to_sensor_mipi_info(struct v4l2_subdev <token> <answer> *sd) 
<token> (struct camera_mipi_info *)v4l2_get_subdev_hostdata(sd); <answer> return 
<token> atomisp_video_pipe *atomisp_to_video_pipe(struct video_device *dev) <answer> struct 
return (struct atomisp_video_pipe <token> <answer> *) 
<token> struct atomisp_video_pipe, vdev); <answer> container_of(dev, 
static unsigned short <token> atomisp_sub_device *asd) <answer> atomisp_get_sensor_fps(struct 
struct v4l2_subdev_frame_interval fi = <token> 0 }; <answer> { 
struct atomisp_device *isp = <token> <answer> asd->isp; 
unsigned short fps = <token> <answer> 0; 
<token> ret; <answer> int 
ret <token> v4l2_subdev_call_state_active(isp->inputs[asd->input_curr].camera, <answer> = 
pad, get_frame_interval, <token> <answer> &fi); 
<token> (!ret && fi.interval.numerator) <answer> if 
fps = <token> / fi.interval.numerator; <answer> fi.interval.denominator 
<token> fps; <answer> return 
static int write_target_freq_to_hw(struct <token> *isp, <answer> atomisp_device 
unsigned int <token> <answer> new_freq) 
unsigned <token> ratio, timeout, guar_ratio; <answer> int 
u32 <token> = 0; <answer> isp_sspm1 
<token> i; <answer> int 
if (!isp->hpll_freq) <token> <answer> { 
dev_err(isp->dev, "failed to get hpll_freq. no change to <token> <answer> freq\n"); 
return <token> <answer> -EINVAL; 
iosf_mbi_read(BT_MBI_UNIT_PMC, <token> ISPSSPM1, &isp_sspm1); <answer> MBI_REG_READ, 
if (isp_sspm1 <token> ISP_FREQ_VALID_MASK) { <answer> & 
dev_dbg(isp->dev, "clearing ISPSSPM1 valid <token> <answer> bit.\n"); 
iosf_mbi_write(BT_MBI_UNIT_PMC, MBI_REG_WRITE, <token> <answer> ISPSSPM1, 
isp_sspm1 & ~(1 <token> ISP_FREQ_VALID_OFFSET)); <answer> << 
ratio = (2 * <token> + new_freq / 2) / new_freq - 1; <answer> isp->hpll_freq 
guar_ratio = (2 * isp->hpll_freq + 200 / 2) <token> 200 - 1; <answer> / 
<token> MBI_REG_READ, ISPSSPM1, &isp_sspm1); <answer> iosf_mbi_read(BT_MBI_UNIT_PMC, 
isp_sspm1 <token> ~(0x1F << ISP_REQ_FREQ_OFFSET); <answer> &= 
for (i <token> 0; i < ISP_DFS_TRY_TIMES; i++) { <answer> = 
iosf_mbi_write(BT_MBI_UNIT_PMC, MBI_REG_WRITE, <token> <answer> ISPSSPM1, 
| ratio <token> ISP_REQ_FREQ_OFFSET <answer> << 
| <token> << ISP_FREQ_VALID_OFFSET <answer> 1 
<token> guar_ratio << ISP_REQ_GUAR_FREQ_OFFSET); <answer> | 
<token> MBI_REG_READ, ISPSSPM1, &isp_sspm1); <answer> iosf_mbi_read(BT_MBI_UNIT_PMC, 
timeout = <token> <answer> 20; 
while ((isp_sspm1 & <token> && timeout) { <answer> ISP_FREQ_VALID_MASK) 
iosf_mbi_read(BT_MBI_UNIT_PMC, MBI_REG_READ, ISPSSPM1, <token> <answer> &isp_sspm1); 
dev_dbg(isp->dev, "waiting for ISPSSPM1 valid <token> to be 0.\n"); <answer> bit 
<token> (timeout != 0) <answer> if 
if (timeout <token> 0) { <answer> == 
dev_err(isp->dev, "DFS failed <token> to HW error.\n"); <answer> due 
return <token> <answer> -EINVAL; 
iosf_mbi_read(BT_MBI_UNIT_PMC, MBI_REG_READ, ISPSSPM1, <token> <answer> &isp_sspm1); 
timeout = <token> <answer> 10; 
while (((isp_sspm1 >> ISP_FREQ_STAT_OFFSET) != ratio) && timeout) <token> <answer> { 
<token> MBI_REG_READ, ISPSSPM1, &isp_sspm1); <answer> iosf_mbi_read(BT_MBI_UNIT_PMC, 
dev_dbg(isp->dev, "waiting for <token> status bit to be 0x%x.\n", <answer> ISPSSPM1 
if (timeout == <token> { <answer> 0) 
dev_err(isp->dev, "DFS target freq <token> rejected by HW.\n"); <answer> is 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
int atomisp_freq_scaling(struct <token> *isp, <answer> atomisp_device 
<token> atomisp_dfs_mode mode, <answer> enum 
<token> force) <answer> bool 
const <token> atomisp_dfs_config *dfs; <answer> struct 
unsigned int <token> <answer> new_freq; 
<token> atomisp_freq_scaling_rule curr_rules; <answer> struct 
<token> i, ret; <answer> int 
<token> short fps = 0; <answer> unsigned 
dfs = <token> <answer> isp->dfs; 
if <token> == 0 || dfs->max_freq_at_vmin == 0 || <answer> (dfs->lowest_freq 
dfs->highest_freq == 0 || dfs->dfs_table_size <token> 0 || <answer> == 
!dfs->dfs_table) <token> <answer> { 
dev_err(isp->dev, <token> configuration is invalid.\n"); <answer> "DFS 
return <token> <answer> -EINVAL; 
<token> (mode == ATOMISP_DFS_MODE_LOW) { <answer> if 
new_freq <token> dfs->lowest_freq; <answer> = 
<token> done; <answer> goto 
if (mode == ATOMISP_DFS_MODE_MAX) <token> <answer> { 
new_freq <token> dfs->highest_freq; <answer> = 
<token> done; <answer> goto 
<token> = atomisp_get_sensor_fps(&isp->asd); <answer> fps 
if <token> == 0) { <answer> (fps 
"Sensor didn't report <token> Using DFS max mode.\n"); <answer> FPS. 
new_freq <token> dfs->highest_freq; <answer> = 
<token> done; <answer> goto 
<token> = isp->asd.fmt[ATOMISP_SUBDEV_PAD_SOURCE].fmt.width; <answer> curr_rules.width 
curr_rules.height = <token> <answer> isp->asd.fmt[ATOMISP_SUBDEV_PAD_SOURCE].fmt.height; 
curr_rules.fps = <token> <answer> fps; 
<token> = isp->asd.run_mode->val; <answer> curr_rules.run_mode 
int <token> atomisp_device *isp) <answer> atomisp_reset(struct 
<token> void disable_isp_irq(enum hrt_isp_css_irq irq) <answer> static 
irq_disable_channel(IRQ0_ID, <token> <answer> irq); 
if (irq != <token> <answer> hrt_isp_css_irq_sp) 
<token> false); <answer> cnd_sp_irq_enable(SP0_ID, 
<token> void clear_isp_irq(enum hrt_isp_css_irq irq) <answer> static 
void atomisp_msi_irq_init(struct <token> *isp) <answer> atomisp_device 
<token> pci_dev *pdev = to_pci_dev(isp->dev); <answer> struct 
<token> msg32; <answer> u32 
<token> msg16; <answer> u16 
pci_read_config_dword(pdev, PCI_MSI_CAPID, <token> <answer> &msg32); 
<token> |= 1 << MSI_ENABLE_BIT; <answer> msg32 
pci_write_config_dword(pdev, PCI_MSI_CAPID, <token> <answer> msg32); 
msg32 = (1 << <token> | (1 << INTR_IIR); <answer> INTR_IER) 
pci_write_config_dword(pdev, PCI_INTERRUPT_CTRL, <token> <answer> msg32); 
pci_read_config_word(pdev, <token> &msg16); <answer> PCI_COMMAND, 
msg16 |= (PCI_COMMAND_MEMORY | PCI_COMMAND_MASTER <token> <answer> | 
<token> PCI_COMMAND, msg16); <answer> pci_write_config_word(pdev, 
void <token> atomisp_device *isp) <answer> atomisp_msi_irq_uninit(struct 
struct pci_dev <token> = to_pci_dev(isp->dev); <answer> *pdev 
u32 <token> <answer> msg32; 
<token> msg16; <answer> u16 
pci_read_config_dword(pdev, <token> &msg32); <answer> PCI_MSI_CAPID, 
<token> &= ~(1 << MSI_ENABLE_BIT); <answer> msg32 
pci_write_config_dword(pdev, PCI_MSI_CAPID, <token> <answer> msg32); 
msg32 = <token> <answer> 0x0; 
<token> PCI_INTERRUPT_CTRL, msg32); <answer> pci_write_config_dword(pdev, 
<token> PCI_COMMAND, &msg16); <answer> pci_read_config_word(pdev, 
<token> &= ~(PCI_COMMAND_MASTER); <answer> msg16 
pci_write_config_word(pdev, PCI_COMMAND, <token> <answer> msg16); 
<token> void atomisp_sof_event(struct atomisp_sub_device *asd) <answer> static 
struct v4l2_event <token> = {0}; <answer> event 
<token> = V4L2_EVENT_FRAME_SYNC; <answer> event.type 
event.u.frame_sync.frame_sequence <token> atomic_read(&asd->sof_count); <answer> = 
v4l2_event_queue(asd->subdev.devnode, <token> <answer> &event); 
void atomisp_eof_event(struct atomisp_sub_device <token> uint8_t exp_id) <answer> *asd, 
struct <token> event = {0}; <answer> v4l2_event 
<token> = V4L2_EVENT_FRAME_END; <answer> event.type 
<token> = exp_id; <answer> event.u.frame_sync.frame_sequence 
<token> &event); <answer> v4l2_event_queue(asd->subdev.devnode, 
static <token> atomisp_3a_stats_ready_event(struct atomisp_sub_device *asd, <answer> void 
<token> exp_id) <answer> uint8_t 
struct v4l2_event event = <token> <answer> {0}; 
<token> = V4L2_EVENT_ATOMISP_3A_STATS_READY; <answer> event.type 
event.u.frame_sync.frame_sequence <token> exp_id; <answer> = 
v4l2_event_queue(asd->subdev.devnode, <token> <answer> &event); 
static <token> atomisp_metadata_ready_event(struct atomisp_sub_device *asd, <answer> void 
enum atomisp_metadata_type <token> <answer> md_type) 
struct v4l2_event event = <token> <answer> {0}; 
<token> = V4L2_EVENT_ATOMISP_METADATA_READY; <answer> event.type 
event.u.data[0] = <token> <answer> md_type; 
v4l2_event_queue(asd->subdev.devnode, <token> <answer> &event); 
static <token> atomisp_reset_event(struct atomisp_sub_device *asd) <answer> void 
struct <token> event = {0}; <answer> v4l2_event 
<token> = V4L2_EVENT_ATOMISP_CSS_RESET; <answer> event.type 
<token> &event); <answer> v4l2_event_queue(asd->subdev.devnode, 
<token> void print_csi_rx_errors(enum mipi_port_id port, <answer> static 
struct <token> *isp) <answer> atomisp_device 
u32 infos = <token> <answer> 0; 
<token> &infos); <answer> atomisp_css_rx_get_irq_info(port, 
<token> "CSI Receiver port %d errors:\n", port); <answer> dev_err(isp->dev, 
<token> (infos & IA_CSS_RX_IRQ_INFO_BUFFER_OVERRUN) <answer> if 
dev_err(isp->dev, " buffer <token> <answer> overrun"); 
if (infos <token> IA_CSS_RX_IRQ_INFO_ERR_SOT) <answer> & 
<token> " start-of-transmission error"); <answer> dev_err(isp->dev, 
if (infos & <token> <answer> IA_CSS_RX_IRQ_INFO_ERR_SOT_SYNC) 
dev_err(isp->dev, " <token> sync error"); <answer> start-of-transmission 
if <token> & IA_CSS_RX_IRQ_INFO_ERR_CONTROL) <answer> (infos 
dev_err(isp->dev, " <token> error"); <answer> control 
if (infos <token> IA_CSS_RX_IRQ_INFO_ERR_ECC_DOUBLE) <answer> & 
dev_err(isp->dev, " <token> or more ECC errors"); <answer> 2 
if (infos & <token> <answer> IA_CSS_RX_IRQ_INFO_ERR_CRC) 
dev_err(isp->dev, " <token> mismatch"); <answer> CRC 
if <token> & IA_CSS_RX_IRQ_INFO_ERR_UNKNOWN_ID) <answer> (infos 
dev_err(isp->dev, " unknown <token> <answer> error"); 
if (infos <token> IA_CSS_RX_IRQ_INFO_ERR_FRAME_SYNC) <answer> & 
dev_err(isp->dev, " frame <token> error"); <answer> sync 
if <token> & IA_CSS_RX_IRQ_INFO_ERR_FRAME_DATA) <answer> (infos 
dev_err(isp->dev, <token> frame data error"); <answer> " 
<token> (infos & IA_CSS_RX_IRQ_INFO_ERR_DATA_TIMEOUT) <answer> if 
dev_err(isp->dev, " data <token> <answer> timeout"); 
if (infos & <token> <answer> IA_CSS_RX_IRQ_INFO_ERR_UNKNOWN_ESC) 
dev_err(isp->dev, " <token> escape command entry"); <answer> unknown 
<token> (infos & IA_CSS_RX_IRQ_INFO_ERR_LINE_SYNC) <answer> if 
dev_err(isp->dev, " line <token> error"); <answer> sync 
if (atomic_read(&isp->asd.sequence) == <token> <answer> atomic_read(&isp->asd.sequence_temp)) 
<token> atomic_read(&isp->asd.sof_count)); <answer> atomic_set(&isp->asd.sequence_temp, 
dev_dbg_ratelimited(isp->dev, "irq:0x%x (SOF)\n", <token> <answer> irq_infos); 
<token> &= ~IA_CSS_IRQ_INFO_CSS_RECEIVER_SOF; <answer> irq_infos 
if (irq_infos & <token> <answer> IA_CSS_IRQ_INFO_EVENTS_READY) 
<token> atomic_read(&isp->asd.sequence_temp)); <answer> atomic_set(&isp->asd.sequence, 
if ((irq_infos & IA_CSS_IRQ_INFO_INPUT_SYSTEM_ERROR) <token> <answer> || 
(irq_infos & <token> { <answer> IA_CSS_IRQ_INFO_IF_ERROR)) 
<token> (asd->params.dvs_6axis) <answer> if 
asd->params.css_update_params_needed <token> false; <answer> = 
<token> (frame) { <answer> if 
<token> irqflags); <answer> spin_lock_irqsave(&pipe->irq_lock, 
atomisp_buffer_done(frame, error <token> VB2_BUF_STATE_ERROR : VB2_BUF_STATE_DONE); <answer> ? 
spin_unlock_irqrestore(&pipe->irq_lock, <token> <answer> irqflags); 
if <token> { <answer> (requeue) 
<token> = atomisp_css_queue_buffer(asd, <answer> err 
<token> css_pipe_id, <answer> stream_id, 
<token> &buffer); <answer> buf_type, 
if <token> <answer> (err) 
dev_err(isp->dev, "%s, q to css fails: <token> <answer> %d\n", 
<token> err); <answer> __func__, 
if (!error && <token> <answer> q_buffers) 
void <token> work_struct *work) <answer> atomisp_assert_recovery_work(struct 
struct atomisp_device *isp = <token> struct atomisp_device, <answer> container_of(work, 
struct <token> *pdev = to_pci_dev(isp->dev); <answer> pci_dev 
<token> long flags; <answer> unsigned 
int <token> <answer> ret; 
<token> (!isp->asd.streaming) <answer> if 
goto <token> <answer> out_unlock; 
atomisp_css_irq_enable(isp, IA_CSS_IRQ_INFO_CSS_RECEIVER_SOF, <token> <answer> false); 
spin_lock_irqsave(&isp->lock, <token> <answer> flags); 
isp->asd.streaming = <token> <answer> false; 
spin_unlock_irqrestore(&isp->lock, <token> <answer> flags); 
<token> (atomisp_css_isr_thread(isp)) <answer> if 
goto <token> <answer> out; 
if <token> <answer> (isp->asd.streaming) 
dev_dbg(isp->dev, <token> __func__); <answer> "<%s\n", 
return <token> <answer> IRQ_HANDLED; 
static enum <token> <answer> ia_css_frame_format 
v4l2_fmt_to_sh_fmt(u32 <token> <answer> fmt) 
<token> (fmt) { <answer> switch 
<token> V4L2_PIX_FMT_YUV420: <answer> case 
return <token> <answer> IA_CSS_FRAME_FORMAT_YUV420; 
<token> V4L2_PIX_FMT_YVU420: <answer> case 
return <token> <answer> IA_CSS_FRAME_FORMAT_YV12; 
case <token> <answer> V4L2_PIX_FMT_YUV422P: 
return <token> <answer> IA_CSS_FRAME_FORMAT_YUV422; 
case <token> <answer> V4L2_PIX_FMT_YUV444: 
return <token> <answer> IA_CSS_FRAME_FORMAT_YUV444; 
<token> V4L2_PIX_FMT_NV12: <answer> case 
<token> IA_CSS_FRAME_FORMAT_NV12; <answer> return 
<token> V4L2_PIX_FMT_NV21: <answer> case 
return <token> <answer> IA_CSS_FRAME_FORMAT_NV21; 
case <token> <answer> V4L2_PIX_FMT_NV16: 
<token> IA_CSS_FRAME_FORMAT_NV16; <answer> return 
<token> V4L2_PIX_FMT_NV61: <answer> case 
return <token> <answer> IA_CSS_FRAME_FORMAT_NV61; 
<token> V4L2_PIX_FMT_UYVY: <answer> case 
return <token> <answer> IA_CSS_FRAME_FORMAT_UYVY; 
<token> V4L2_PIX_FMT_YUYV: <answer> case 
<token> IA_CSS_FRAME_FORMAT_YUYV; <answer> return 
case <token> <answer> V4L2_PIX_FMT_RGB24: 
return <token> <answer> IA_CSS_FRAME_FORMAT_PLANAR_RGB888; 
case <token> <answer> V4L2_PIX_FMT_RGB32: 
<token> IA_CSS_FRAME_FORMAT_RGBA888; <answer> return 
<token> V4L2_PIX_FMT_RGB565: <answer> case 
<token> IA_CSS_FRAME_FORMAT_RGB565; <answer> return 
<token> 0 <answer> #if 
case <token> <answer> V4L2_PIX_FMT_JPEG: 
<token> V4L2_PIX_FMT_CUSTOM_M10MO_RAW: <answer> case 
return <token> <answer> IA_CSS_FRAME_FORMAT_BINARY_8; 
<token> V4L2_PIX_FMT_SBGGR16: <answer> case 
<token> V4L2_PIX_FMT_SBGGR10: <answer> case 
case <token> <answer> V4L2_PIX_FMT_SGBRG10: 
<token> V4L2_PIX_FMT_SGRBG10: <answer> case 
<token> V4L2_PIX_FMT_SRGGB10: <answer> case 
<token> V4L2_PIX_FMT_SBGGR12: <answer> case 
case <token> <answer> V4L2_PIX_FMT_SGBRG12: 
<token> V4L2_PIX_FMT_SGRBG12: <answer> case 
case <token> <answer> V4L2_PIX_FMT_SRGGB12: 
case <token> <answer> V4L2_PIX_FMT_SBGGR8: 
<token> V4L2_PIX_FMT_SGBRG8: <answer> case 
case <token> <answer> V4L2_PIX_FMT_SGRBG8: 
<token> V4L2_PIX_FMT_SRGGB8: <answer> case 
<token> IA_CSS_FRAME_FORMAT_RAW; <answer> return 
return <token> <answer> -EINVAL; 
static int raw_output_format_match_input(u32 input, <token> output) <answer> u32 
<token> ((input == ATOMISP_INPUT_FORMAT_RAW_12) && <answer> if 
((output <token> V4L2_PIX_FMT_SRGGB12) || <answer> == 
<token> == V4L2_PIX_FMT_SGRBG12) || <answer> (output 
(output <token> V4L2_PIX_FMT_SBGGR12) || <answer> == 
(output <token> V4L2_PIX_FMT_SGBRG12))) <answer> == 
return <token> <answer> 0; 
if ((input == ATOMISP_INPUT_FORMAT_RAW_10) <token> <answer> && 
((output == V4L2_PIX_FMT_SRGGB10) <token> <answer> || 
(output <token> V4L2_PIX_FMT_SGRBG10) || <answer> == 
(output <token> V4L2_PIX_FMT_SBGGR10) || <answer> == 
<token> == V4L2_PIX_FMT_SGBRG10))) <answer> (output 
return <token> <answer> 0; 
if ((input <token> ATOMISP_INPUT_FORMAT_RAW_8) && <answer> == 
((output <token> V4L2_PIX_FMT_SRGGB8) || <answer> == 
<token> == V4L2_PIX_FMT_SGRBG8) || <answer> (output 
(output <token> V4L2_PIX_FMT_SBGGR8) || <answer> == 
(output <token> V4L2_PIX_FMT_SGBRG8))) <answer> == 
return <token> <answer> 0; 
if <token> == ATOMISP_INPUT_FORMAT_RAW_16) && (output == V4L2_PIX_FMT_SBGGR16)) <answer> ((input 
<token> 0; <answer> return 
return <token> <answer> -EINVAL; 
u32 atomisp_get_pixel_depth(u32 <token> <answer> pixelformat) 
<token> (pixelformat) { <answer> switch 
case <token> <answer> V4L2_PIX_FMT_YUV420: 
<token> V4L2_PIX_FMT_NV12: <answer> case 
<token> V4L2_PIX_FMT_NV21: <answer> case 
<token> V4L2_PIX_FMT_YVU420: <answer> case 
<token> 12; <answer> return 
case <token> <answer> V4L2_PIX_FMT_YUV422P: 
case <token> <answer> V4L2_PIX_FMT_YUYV: 
<token> V4L2_PIX_FMT_UYVY: <answer> case 
case <token> <answer> V4L2_PIX_FMT_NV16: 
case <token> <answer> V4L2_PIX_FMT_NV61: 
case <token> <answer> V4L2_PIX_FMT_RGB565: 
case <token> <answer> V4L2_PIX_FMT_SBGGR16: 
<token> V4L2_PIX_FMT_SBGGR12: <answer> case 
<token> V4L2_PIX_FMT_SGBRG12: <answer> case 
<token> V4L2_PIX_FMT_SGRBG12: <answer> case 
case <token> <answer> V4L2_PIX_FMT_SRGGB12: 
case <token> <answer> V4L2_PIX_FMT_SBGGR10: 
<token> V4L2_PIX_FMT_SGBRG10: <answer> case 
<token> V4L2_PIX_FMT_SGRBG10: <answer> case 
<token> V4L2_PIX_FMT_SRGGB10: <answer> case 
return <token> <answer> 16; 
case <token> <answer> V4L2_PIX_FMT_RGB24: 
<token> V4L2_PIX_FMT_YUV444: <answer> case 
<token> 24; <answer> return 
<token> V4L2_PIX_FMT_RGB32: <answer> case 
return <token> <answer> 32; 
<token> V4L2_PIX_FMT_JPEG: <answer> case 
<token> V4L2_PIX_FMT_CUSTOM_M10MO_RAW: <answer> case 
case <token> <answer> V4L2_PIX_FMT_SBGGR8: 
<token> V4L2_PIX_FMT_SGBRG8: <answer> case 
case <token> <answer> V4L2_PIX_FMT_SGRBG8: 
<token> V4L2_PIX_FMT_SRGGB8: <answer> case 
return <token> <answer> 8; 
static <token> atomisp_update_capture_mode(struct atomisp_sub_device *asd) <answer> void 
if <token> <answer> (asd->params.gdc_cac_en) 
<token> IA_CSS_CAPTURE_MODE_ADVANCED); <answer> atomisp_css_capture_set_mode(asd, 
<token> if (asd->params.low_light) <answer> else 
<token> IA_CSS_CAPTURE_MODE_LOW_LIGHT); <answer> atomisp_css_capture_set_mode(asd, 
else if (asd->video_out.sh_fmt <token> IA_CSS_FRAME_FORMAT_RAW) <answer> == 
atomisp_css_capture_set_mode(asd, <token> <answer> IA_CSS_CAPTURE_MODE_RAW); 
atomisp_css_capture_set_mode(asd, <token> <answer> IA_CSS_CAPTURE_MODE_PRIMARY); 
int atomisp_gdc_cac(struct atomisp_sub_device *asd, int <token> <answer> flag, 
<token> *value) <answer> __s32 
if (flag == 0) <token> <answer> { 
*value = <token> <answer> asd->params.gdc_cac_en; 
<token> 0; <answer> return 
asd->params.gdc_cac_en <token> !!*value; <answer> = 
if (asd->params.gdc_cac_en) <token> <answer> { 
asd->params.config.morph_table <token> asd->params.css_param.morph_table; <answer> = 
} <token> { <answer> else 
asd->params.config.morph_table = <token> <answer> NULL; 
<token> = true; <answer> asd->params.css_update_params_needed 
return <token> <answer> 0; 
int atomisp_low_light(struct atomisp_sub_device *asd, int <token> <answer> flag, 
<token> *value) <answer> __s32 
if (flag == <token> { <answer> 0) 
<token> = asd->params.low_light; <answer> *value 
<token> 0; <answer> return 
asd->params.low_light <token> (*value != 0); <answer> = 
<token> 0; <answer> return 
int atomisp_xnr(struct <token> *asd, int flag, <answer> atomisp_sub_device 
<token> *xnr_enable) <answer> int 
if (flag == <token> { <answer> 0) 
*xnr_enable = <token> <answer> asd->params.xnr_en; 
<token> 0; <answer> return 
atomisp_css_capture_enable_xnr(asd, <token> <answer> !!*xnr_enable); 
<token> 0; <answer> return 
int <token> atomisp_sub_device *asd, int flag, <answer> atomisp_nr(struct 
struct atomisp_nr_config <token> <answer> *arg) 
if <token> == 0) { <answer> (flag 
int atomisp_tnr(struct atomisp_sub_device *asd, <token> flag, <answer> int 
<token> atomisp_tnr_config *config) <answer> struct 
int <token> atomisp_sub_device *asd, int flag, <answer> atomisp_black_level(struct 
struct atomisp_ob_config <token> <answer> *config) 
if (flag == <token> { <answer> 0) 
int atomisp_ee(struct atomisp_sub_device <token> int flag, <answer> *asd, 
struct <token> *config) <answer> atomisp_ee_config 
if (flag <token> 0) { <answer> == 
int atomisp_gamma(struct atomisp_sub_device *asd, int <token> <answer> flag, 
<token> atomisp_gamma_table *config) <answer> struct 
if (flag == <token> { <answer> 0) 
<token> atomisp_ctc(struct atomisp_sub_device *asd, int flag, <answer> int 
struct atomisp_ctc_table <token> <answer> *config) 
if (flag <token> 0) { <answer> == 
int atomisp_gamma_correction(struct atomisp_sub_device <token> int flag, <answer> *asd, 
<token> atomisp_gc_config *config) <answer> struct 
if (flag == <token> { <answer> 0) 
int atomisp_formats(struct atomisp_sub_device *asd, int <token> <answer> flag, 
<token> atomisp_formats_config *config) <answer> struct 
if (flag == <token> { <answer> 0) 
err = <token> ATOMISP_INPUT_STREAM_GENERAL); <answer> atomisp_alloc_css_stat_bufs(asd, 
if (err) <token> <answer> { 
dev_err(isp->dev, "stat_buf <token> error\n"); <answer> allocate 
goto <token> <answer> err; 
if (atomisp_alloc_3a_output_buf(asd)) <token> <answer> { 
dev_err(isp->dev, "Failed to <token> memory for 3A statistics\n"); <answer> allocate 
goto <token> <answer> err; 
if <token> { <answer> (atomisp_alloc_dis_coef_buf(asd)) 
"Failed to allocate memory for <token> statistics\n"); <answer> DIS 
goto <token> <answer> err; 
<token> (atomisp_alloc_metadata_output_buf(asd)) { <answer> if 
dev_err(isp->dev, "Failed to <token> memory for metadata\n"); <answer> allocate 
goto <token> <answer> err; 
<token> void atomisp_curr_user_grid_info(struct atomisp_sub_device *asd, <answer> static 
<token> atomisp_grid_info *info) <answer> struct 
<token> &asd->params.curr_grid_info.s3a_grid, <answer> memcpy(info, 
sizeof(struct <token> <answer> ia_css_3a_grid_info)); 
int <token> atomisp_sub_device *asd, <answer> atomisp_compare_grid(struct 
struct atomisp_grid_info <token> <answer> *atomgrid) 
<token> atomisp_grid_info tmp = {0}; <answer> struct 
atomisp_curr_user_grid_info(asd, <token> <answer> &tmp); 
return memcmp(atomgrid, &tmp, <token> <answer> sizeof(tmp)); 
int atomisp_gdc_cac_table(struct atomisp_sub_device <token> int flag, <answer> *asd, 
struct <token> *config) <answer> atomisp_morph_table 
<token> ret; <answer> int 
int <token> <answer> i; 
struct atomisp_device <token> = asd->isp; <answer> *isp 
if (flag == <token> { <answer> 0) 
<token> atomisp_get_dis_stat(struct atomisp_sub_device *asd, <answer> int 
<token> atomisp_dis_statistics *stats) <answer> struct 
return <token> stats); <answer> atomisp_css_get_dis_stat(asd, 
int atomisp_set_array_res(struct <token> *asd, <answer> atomisp_sub_device 
struct atomisp_resolution <token> <answer> *config) 
<token> ">%s start\n", __func__); <answer> dev_dbg(asd->isp->dev, 
<token> (!config) { <answer> if 
dev_err(asd->isp->dev, <token> sensor array size is not valid\n"); <answer> "Set 
<token> -EINVAL; <answer> return 
<token> = config->width; <answer> asd->sensor_array_res.width 
asd->sensor_array_res.height <token> config->height; <answer> = 
return <token> <answer> 0; 
<token> atomisp_get_dvs2_bq_resolutions(struct atomisp_sub_device *asd, <answer> int 
<token> atomisp_dvs2_bq_resolutions *bq_res) <answer> struct 
struct ia_css_pipe_config *pipe_cfg <token> NULL; <answer> = 
struct <token> *stream = <answer> ia_css_stream 
<token> (!stream) { <answer> if 
dev_warn(asd->isp->dev, "stream <token> not created"); <answer> is 
<token> -EAGAIN; <answer> return 
pipe_cfg = <token> <answer> &asd->stream_env[ATOMISP_INPUT_STREAM_GENERAL] 
<token> (!bq_res) <answer> if 
<token> -EINVAL; <answer> return 
<token> = 12 / 2; <answer> bq_res->ispfilter_bq.width_bq 
<token> = 12 / 2; <answer> bq_res->ispfilter_bq.height_bq 
int atomisp_3a_stat(struct atomisp_sub_device <token> int flag, <answer> *asd, 
struct atomisp_3a_statistics <token> <answer> *config) 
struct <token> *isp = asd->isp; <answer> atomisp_device 
struct <token> *s3a_buf; <answer> atomisp_s3a_buf 
<token> long ret; <answer> unsigned 
if (flag <token> 0) <answer> != 
return <token> <answer> -EINVAL; 
return <token> <answer> -EAGAIN; 
if (list_empty(&asd->s3a_stats_ready)) <token> <answer> { 
<token> "3a statistics is not valid.\n"); <answer> dev_err(isp->dev, 
return <token> <answer> -EAGAIN; 
s3a_buf = <token> <answer> list_entry(asd->s3a_stats_ready.next, 
struct atomisp_s3a_buf, <token> <answer> list); 
<token> (s3a_buf->s3a_map) <answer> if 
<token> s3a_buf->s3a_map); <answer> asd->params.s3a_user_stat, 
config->exp_id <token> s3a_buf->s3a_data->exp_id; <answer> = 
config->isp_config_id <token> s3a_buf->s3a_data->isp_config_id; <answer> = 
ret = copy_to_user(config->data, <token> <answer> asd->params.s3a_user_stat->data, 
<token> (ret) { <answer> if 
dev_err(isp->dev, "copy to user <token> copied %lu bytes\n", <answer> failed: 
<token> -EFAULT; <answer> return 
int atomisp_calculate_real_zoom_region(struct <token> *asd, <answer> atomisp_sub_device 
<token> ia_css_dz_config *dz_config, <answer> struct 
enum <token> css_pipe_id) <answer> ia_css_pipe_id 
struct <token> *stream_env = <answer> atomisp_stream_env 
struct atomisp_resolution eff_res, <token> <answer> out_res; 
<token> w_offset, h_offset; <answer> int 
<token> 0, sizeof(eff_res)); <answer> memset(&eff_res, 
memset(&out_res, 0, <token> <answer> sizeof(out_res)); 
if (dz_config->dx || <token> <answer> dz_config->dy) 
return <token> <answer> 0; 
if <token> != IA_CSS_PIPE_ID_PREVIEW <answer> (css_pipe_id 
&& css_pipe_id != <token> { <answer> IA_CSS_PIPE_ID_CAPTURE) 
dev_err(asd->isp->dev, "%s the set pipe no support crop <token> <answer> region" 
<token> __func__); <answer> , 
return <token> <answer> -EINVAL; 
<token> = <answer> eff_res.width 
<token> = <answer> eff_res.height 
if (eff_res.width == 0 || eff_res.height == <token> { <answer> 0) 
dev_err(asd->isp->dev, <token> err effective resolution" <answer> "%s 
, <token> <answer> __func__); 
<token> -EINVAL; <answer> return 
if <token> <answer> (dz_config->zoom_region.resolution.width 
== <token> <answer> asd->sensor_array_res.width 
|| <token> <answer> dz_config->zoom_region.resolution.height 
<token> asd->sensor_array_res.height) { <answer> == 
if <token> { <answer> (!IS_ISP2401) 
<token> = dz_config->zoom_region.origin.x <answer> dz_config->zoom_region.origin.x 
<token> eff_res.width <answer> * 
/ <token> <answer> asd->sensor_array_res.width; 
dz_config->zoom_region.origin.y = <token> <answer> dz_config->zoom_region.origin.y 
<token> eff_res.height <answer> * 
<token> asd->sensor_array_res.height; <answer> / 
dz_config->zoom_region.resolution.width <token> dz_config->zoom_region.resolution.width <answer> = 
* <token> <answer> eff_res.width 
<token> asd->sensor_array_res.width; <answer> / 
dz_config->zoom_region.resolution.height = <token> <answer> dz_config->zoom_region.resolution.height 
<token> eff_res.height <answer> * 
<token> asd->sensor_array_res.height; <answer> / 
out_res.width = <token> <answer> stream_env->pipe_configs[css_pipe_id].output_info[0].res.width; 
out_res.height = <token> <answer> stream_env->pipe_configs[css_pipe_id].output_info[0].res.height; 
if (out_res.width == 0 || out_res.height == 0) <token> <answer> { 
dev_err(asd->isp->dev, "%s err current <token> output resolution" <answer> pipe 
, <token> <answer> __func__); 
<token> -EINVAL; <answer> return 
} else <token> <answer> { 
out_res.width <token> stream_env->pipe_configs[css_pipe_id].output_info[0].res.width; <answer> = 
out_res.height = <token> <answer> stream_env->pipe_configs[css_pipe_id].output_info[0].res.height; 
<token> (out_res.width == 0 || out_res.height == 0) { <answer> if 
dev_err(asd->isp->dev, "%s <token> current pipe output resolution" <answer> err 
, <token> <answer> __func__); 
return <token> <answer> -EINVAL; 
<token> (asd->sensor_array_res.width * out_res.height <answer> if 
<token> out_res.width * asd->sensor_array_res.height) { <answer> < 
h_offset = <token> <answer> asd->sensor_array_res.height 
- <token> <answer> asd->sensor_array_res.width 
* out_res.height <token> out_res.width; <answer> / 
h_offset = <token> / 2; <answer> h_offset 
<token> (dz_config->zoom_region.origin.y < h_offset) <answer> if 
dz_config->zoom_region.origin.y = <token> <answer> 0; 
dz_config->zoom_region.origin.y = dz_config->zoom_region.origin.y <token> h_offset; <answer> - 
w_offset <token> 0; <answer> = 
} <token> { <answer> else 
<token> = asd->sensor_array_res.width <answer> w_offset 
<token> asd->sensor_array_res.height <answer> - 
* <token> / out_res.height; <answer> out_res.width 
<token> = w_offset / 2; <answer> w_offset 
<token> (dz_config->zoom_region.origin.x < w_offset) <answer> if 
<token> = 0; <answer> dz_config->zoom_region.origin.x 
dz_config->zoom_region.origin.x = dz_config->zoom_region.origin.x <token> w_offset; <answer> - 
h_offset = <token> <answer> 0; 
dz_config->zoom_region.origin.x <token> dz_config->zoom_region.origin.x <answer> = 
* <token> <answer> eff_res.width 
/ (asd->sensor_array_res.width <token> 2 * w_offset); <answer> - 
dz_config->zoom_region.origin.y <token> dz_config->zoom_region.origin.y <answer> = 
* <token> <answer> eff_res.height 
/ (asd->sensor_array_res.height - 2 <token> h_offset); <answer> * 
dz_config->zoom_region.resolution.width = <token> <answer> dz_config->zoom_region.resolution.width 
* <token> <answer> eff_res.width 
<token> (asd->sensor_array_res.width - 2 * w_offset); <answer> / 
dz_config->zoom_region.resolution.height <token> dz_config->zoom_region.resolution.height <answer> = 
* <token> <answer> eff_res.height 
/ (asd->sensor_array_res.height - 2 * <token> <answer> h_offset); 
<token> (out_res.width * dz_config->zoom_region.resolution.height <answer> if 
> <token> * out_res.height) { <answer> dz_config->zoom_region.resolution.width 
dz_config->zoom_region.resolution.height <token> <answer> = 
* <token> / out_res.width; <answer> out_res.height 
} <token> { <answer> else 
<token> = <answer> dz_config->zoom_region.resolution.width 
* <token> / out_res.height; <answer> out_res.width 
<token> crop region:(%d,%d),(%d,%d) eff_res(%d, %d) array_size(%d,%d) out_res(%d, %d)\n", <answer> "%s 
<token> dz_config->zoom_region.origin.x, <answer> __func__, 
<token> eff_res.height, <answer> eff_res.width, 
<token> out_res.height); <answer> out_res.width, 
if <token> + <answer> ((dz_config->zoom_region.origin.x 
<token> eff_res.width) || <answer> > 
<token> + <answer> (dz_config->zoom_region.origin.y 
> <token> <answer> eff_res.height)) 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
<token> bool atomisp_check_zoom_region( <answer> static 
struct atomisp_sub_device <token> <answer> *asd, 
struct ia_css_dz_config <token> <answer> *dz_config) 
struct atomisp_resolution <token> <answer> config; 
bool <token> = false; <answer> flag 
unsigned <token> w, h; <answer> int 
memset(&config, <token> sizeof(struct atomisp_resolution)); <answer> 0, 
if <token> && dz_config->dy) <answer> (dz_config->dx 
return <token> <answer> true; 
config.width = <token> <answer> asd->sensor_array_res.width; 
config.height <token> asd->sensor_array_res.height; <answer> = 
w <token> dz_config->zoom_region.origin.x + <answer> = 
h = dz_config->zoom_region.origin.y <token> <answer> + 
if ((w <= config.width) && (h <= config.height) && w <token> 0 && h > 0) <answer> > 
flag <token> true; <answer> = 
<token> unsigned int long copy_from_compatible(void *to, const void *from, <answer> static 
unsigned long n, <token> from_user) <answer> bool 
<token> (from_user) <answer> if 
return copy_from_user(to, (void __user <token> n); <answer> *)from, 
memcpy(to, <token> n); <answer> from, 
<token> 0; <answer> return 
int atomisp_cp_general_isp_parameters(struct atomisp_sub_device <token> <answer> *asd, 
<token> atomisp_parameters *arg, <answer> struct 
<token> atomisp_css_params *css_param, <answer> struct 
bool <token> <answer> from_user) 
struct atomisp_parameters *cur_config <token> &css_param->update_flag; <answer> = 
if (!arg || !asd || <token> <answer> !css_param) 
<token> -EINVAL; <answer> return 
if (arg->wb_config && (from_user <token> !cur_config->wb_config)) { <answer> || 
if <token> arg->wb_config, <answer> (copy_from_compatible(&css_param->wb_config, 
sizeof(struct <token> <answer> ia_css_wb_config), 
<token> -EFAULT; <answer> return 
<token> = <answer> css_param->update_flag.wb_config 
(struct atomisp_wb_config <token> <answer> *)&css_param->wb_config; 
if (arg->ob_config && (from_user <token> !cur_config->ob_config)) { <answer> || 
if <token> arg->ob_config, <answer> (copy_from_compatible(&css_param->ob_config, 
sizeof(struct <token> <answer> ia_css_ob_config), 
return <token> <answer> -EFAULT; 
css_param->update_flag.ob_config <token> <answer> = 
(struct atomisp_ob_config <token> <answer> *)&css_param->ob_config; 
<token> (arg->dp_config && (from_user || !cur_config->dp_config)) { <answer> if 
<token> (copy_from_compatible(&css_param->dp_config, arg->dp_config, <answer> if 
<token> ia_css_dp_config), <answer> sizeof(struct 
<token> -EFAULT; <answer> return 
css_param->update_flag.dp_config <token> <answer> = 
(struct <token> *)&css_param->dp_config; <answer> atomisp_dp_config 
if (asd->run_mode->val <token> ATOMISP_RUN_MODE_VIDEO) { <answer> != 
<token> (arg->dz_config && (from_user || !cur_config->dz_config)) { <answer> if 
<token> (copy_from_compatible(&css_param->dz_config, <answer> if 
sizeof(struct <token> <answer> ia_css_dz_config), 
<token> -EFAULT; <answer> return 
if <token> <answer> (!atomisp_check_zoom_region(asd, 
<token> { <answer> &css_param->dz_config)) 
<token> "crop region error!"); <answer> dev_err(asd->isp->dev, 
<token> -EINVAL; <answer> return 
<token> = <answer> css_param->update_flag.dz_config 
(struct <token> *) <answer> atomisp_dz_config 
if (arg->nr_config <token> (from_user || !cur_config->nr_config)) { <answer> && 
if <token> arg->nr_config, <answer> (copy_from_compatible(&css_param->nr_config, 
sizeof(struct <token> <answer> ia_css_nr_config), 
<token> -EFAULT; <answer> return 
<token> = <answer> css_param->update_flag.nr_config 
(struct atomisp_nr_config <token> <answer> *)&css_param->nr_config; 
if <token> && (from_user || !cur_config->ee_config)) { <answer> (arg->ee_config 
if <token> arg->ee_config, <answer> (copy_from_compatible(&css_param->ee_config, 
sizeof(struct <token> <answer> ia_css_ee_config), 
return <token> <answer> -EFAULT; 
css_param->update_flag.ee_config <token> <answer> = 
(struct <token> *)&css_param->ee_config; <answer> atomisp_ee_config 
<token> (arg->tnr_config && (from_user || !cur_config->tnr_config)) { <answer> if 
<token> (copy_from_compatible(&css_param->tnr_config, <answer> if 
sizeof(struct <token> <answer> ia_css_tnr_config), 
<token> -EFAULT; <answer> return 
<token> = <answer> css_param->update_flag.tnr_config 
<token> atomisp_tnr_config *) <answer> (struct 
if (arg->a3a_config <token> (from_user || !cur_config->a3a_config)) { <answer> && 
<token> (copy_from_compatible(&css_param->s3a_config, <answer> if 
sizeof(struct <token> <answer> ia_css_3a_config), 
return <token> <answer> -EFAULT; 
css_param->update_flag.a3a_config <token> <answer> = 
(struct atomisp_3a_config <token> <answer> *)&css_param->s3a_config; 
if (arg->ctc_config && <token> || !cur_config->ctc_config)) { <answer> (from_user 
<token> (copy_from_compatible(&css_param->ctc_config, <answer> if 
<token> ia_css_ctc_config), <answer> sizeof(struct 
return <token> <answer> -EFAULT; 
css_param->update_flag.ctc_config <token> <answer> = 
(struct atomisp_ctc_config <token> <answer> *) 
if (arg->cnr_config && (from_user || <token> { <answer> !cur_config->cnr_config)) 
<token> (copy_from_compatible(&css_param->cnr_config, <answer> if 
sizeof(struct <token> <answer> ia_css_cnr_config), 
return <token> <answer> -EFAULT; 
<token> = <answer> css_param->update_flag.cnr_config 
<token> atomisp_cnr_config *) <answer> (struct 
if (arg->ecd_config && (from_user <token> !cur_config->ecd_config)) { <answer> || 
<token> (copy_from_compatible(&css_param->ecd_config, <answer> if 
<token> ia_css_ecd_config), <answer> sizeof(struct 
<token> -EFAULT; <answer> return 
css_param->update_flag.ecd_config <token> <answer> = 
(struct <token> *) <answer> atomisp_ecd_config 
if (arg->ynr_config && <token> || !cur_config->ynr_config)) { <answer> (from_user 
if <token> <answer> (copy_from_compatible(&css_param->ynr_config, 
sizeof(struct <token> <answer> ia_css_ynr_config), 
<token> -EFAULT; <answer> return 
<token> = <answer> css_param->update_flag.ynr_config 
<token> atomisp_ynr_config *) <answer> (struct 
if <token> && (from_user || !cur_config->fc_config)) { <answer> (arg->fc_config 
<token> (copy_from_compatible(&css_param->fc_config, <answer> if 
<token> ia_css_fc_config), <answer> sizeof(struct 
<token> -EFAULT; <answer> return 
<token> = <answer> css_param->update_flag.fc_config 
(struct atomisp_fc_config <token> <answer> *)&css_param->fc_config; 
<token> (arg->macc_config && (from_user || !cur_config->macc_config)) { <answer> if 
if <token> <answer> (copy_from_compatible(&css_param->macc_config, 
<token> ia_css_macc_config), <answer> sizeof(struct 
return <token> <answer> -EFAULT; 
<token> = <answer> css_param->update_flag.macc_config 
<token> atomisp_macc_config *) <answer> (struct 
<token> (arg->aa_config && (from_user || !cur_config->aa_config)) { <answer> if 
if <token> arg->aa_config, <answer> (copy_from_compatible(&css_param->aa_config, 
<token> ia_css_aa_config), <answer> sizeof(struct 
<token> -EFAULT; <answer> return 
<token> = <answer> css_param->update_flag.aa_config 
<token> atomisp_aa_config *)&css_param->aa_config; <answer> (struct 
if (arg->anr_config && (from_user <token> !cur_config->anr_config)) { <answer> || 
if <token> <answer> (copy_from_compatible(&css_param->anr_config, 
<token> ia_css_anr_config), <answer> sizeof(struct 
<token> -EFAULT; <answer> return 
<token> = <answer> css_param->update_flag.anr_config 
<token> atomisp_anr_config *) <answer> (struct 
if (arg->xnr_config && (from_user <token> !cur_config->xnr_config)) { <answer> || 
<token> (copy_from_compatible(&css_param->xnr_config, <answer> if 
<token> ia_css_xnr_config), <answer> sizeof(struct 
<token> -EFAULT; <answer> return 
css_param->update_flag.xnr_config <token> <answer> = 
(struct <token> *) <answer> atomisp_xnr_config 
<token> (arg->yuv2rgb_cc_config && <answer> if 
(from_user || !cur_config->yuv2rgb_cc_config)) <token> <answer> { 
if <token> <answer> (copy_from_compatible(&css_param->yuv2rgb_cc_config, 
sizeof(struct <token> <answer> ia_css_cc_config), 
return <token> <answer> -EFAULT; 
<token> = <answer> css_param->update_flag.yuv2rgb_cc_config 
(struct atomisp_cc_config <token> <answer> *) 
if (arg->rgb2yuv_cc_config <token> <answer> && 
<token> || !cur_config->rgb2yuv_cc_config)) { <answer> (from_user 
if <token> <answer> (copy_from_compatible(&css_param->rgb2yuv_cc_config, 
sizeof(struct <token> <answer> ia_css_cc_config), 
<token> -EFAULT; <answer> return 
css_param->update_flag.rgb2yuv_cc_config <token> <answer> = 
(struct atomisp_cc_config <token> <answer> *) 
if (arg->macc_table <token> (from_user || !cur_config->macc_table)) { <answer> && 
<token> (copy_from_compatible(&css_param->macc_table, <answer> if 
sizeof(struct <token> <answer> ia_css_macc_table), 
return <token> <answer> -EFAULT; 
css_param->update_flag.macc_table <token> <answer> = 
(struct atomisp_macc_table <token> <answer> *) 
if (arg->xnr_table && <token> || !cur_config->xnr_table)) { <answer> (from_user 
<token> (copy_from_compatible(&css_param->xnr_table, <answer> if 
sizeof(struct <token> <answer> ia_css_xnr_table), 
<token> -EFAULT; <answer> return 
css_param->update_flag.xnr_table <token> <answer> = 
(struct atomisp_xnr_table <token> <answer> *)&css_param->xnr_table; 
<token> (arg->r_gamma_table && (from_user || !cur_config->r_gamma_table)) { <answer> if 
if <token> <answer> (copy_from_compatible(&css_param->r_gamma_table, 
<token> ia_css_rgb_gamma_table), <answer> sizeof(struct 
<token> -EFAULT; <answer> return 
<token> = <answer> css_param->update_flag.r_gamma_table 
(struct <token> *) <answer> atomisp_rgb_gamma_table 
if (arg->g_gamma_table && <token> || !cur_config->g_gamma_table)) { <answer> (from_user 
<token> (copy_from_compatible(&css_param->g_gamma_table, <answer> if 
<token> ia_css_rgb_gamma_table), <answer> sizeof(struct 
<token> -EFAULT; <answer> return 
css_param->update_flag.g_gamma_table <token> <answer> = 
<token> atomisp_rgb_gamma_table *) <answer> (struct 
if (arg->b_gamma_table <token> (from_user || !cur_config->b_gamma_table)) { <answer> && 
if <token> <answer> (copy_from_compatible(&css_param->b_gamma_table, 
<token> ia_css_rgb_gamma_table), <answer> sizeof(struct 
<token> -EFAULT; <answer> return 
css_param->update_flag.b_gamma_table <token> <answer> = 
(struct <token> *) <answer> atomisp_rgb_gamma_table 
if (arg->anr_thres && <token> || !cur_config->anr_thres)) { <answer> (from_user 
if <token> arg->anr_thres, <answer> (copy_from_compatible(&css_param->anr_thres, 
<token> ia_css_anr_thres), <answer> sizeof(struct 
return <token> <answer> -EFAULT; 
<token> = <answer> css_param->update_flag.anr_thres 
<token> atomisp_anr_thres *)&css_param->anr_thres; <answer> (struct 
<token> (from_user) <answer> if 
css_param->isp_config_id <token> arg->isp_config_id; <answer> = 
return <token> <answer> 0; 
int <token> atomisp_sub_device *asd, <answer> atomisp_cp_lsc_table(struct 
struct atomisp_shading_table <token> <answer> *source_st, 
<token> atomisp_css_params *css_param, <answer> struct 
bool <token> <answer> from_user) 
unsigned <token> i; <answer> int 
<token> int len_table; <answer> unsigned 
<token> ia_css_shading_table *shading_table; <answer> struct 
<token> ia_css_shading_table *old_table; <answer> struct 
<token> atomisp_shading_table *st, dest_st; <answer> struct 
if <token> <answer> (!source_st) 
return <token> <answer> 0; 
if <token> <answer> (!css_param) 
<token> -EINVAL; <answer> return 
<token> (!from_user && css_param->update_flag.shading_table) <answer> if 
return <token> <answer> 0; 
if <token> { <answer> (IS_ISP2401) 
<token> (copy_from_compatible(&dest_st, source_st, <answer> if 
sizeof(struct <token> <answer> atomisp_shading_table), 
from_user)) <token> <answer> { 
dev_err(asd->isp->dev, <token> shading table failed!"); <answer> "copy 
<token> -EFAULT; <answer> return 
<token> = &dest_st; <answer> st 
} <token> { <answer> else 
st = <token> <answer> source_st; 
<token> = css_param->shading_table; <answer> old_table 
<token> -EAGAIN; <answer> return 
if <token> || <answer> (!coefs->hor_coefs.odd_real 
!coefs->hor_coefs.odd_imag <token> <answer> || 
!coefs->hor_coefs.even_real <token> <answer> || 
<token> || <answer> !coefs->hor_coefs.even_imag 
<token> || <answer> !coefs->ver_coefs.odd_real 
!coefs->ver_coefs.odd_imag <token> <answer> || 
!coefs->ver_coefs.even_real <token> <answer> || 
return <token> <answer> -EINVAL; 
if (!css_param->dvs2_coeff) <token> <answer> { 
<token> -EAGAIN; <answer> return 
if (!dvs2_coefs.hor_coefs.odd_real <token> <answer> || 
<token> || <answer> !dvs2_coefs.hor_coefs.odd_imag 
!dvs2_coefs.hor_coefs.even_real <token> <answer> || 
<token> || <answer> !dvs2_coefs.hor_coefs.even_imag 
!dvs2_coefs.ver_coefs.odd_real <token> <answer> || 
!dvs2_coefs.ver_coefs.odd_imag <token> <answer> || 
!dvs2_coefs.ver_coefs.even_real <token> <answer> || 
return <token> <answer> -EINVAL; 
if <token> { <answer> (!css_param->dvs2_coeff) 
void atomisp_handle_parameter_and_buffer(struct atomisp_video_pipe <token> <answer> *pipe) 
struct <token> *asd = pipe->asd; <answer> atomisp_sub_device 
struct ia_css_frame *frame <token> NULL, *frame_tmp; <answer> = 
struct atomisp_css_params_with_list *param = NULL, <token> <answer> *param_tmp; 
<token> need_to_enqueue_buffer = false; <answer> bool 
<token> i; <answer> int 
<token> (!asd->streaming) <answer> if 
<token> (list_empty(&pipe->per_frame_params) || <answer> if 
<token> frame_tmp, <answer> list_for_each_entry_safe(frame, 
<token> queue) { <answer> &pipe->buffers_waiting_for_param, 
i <token> frame->vb.vb2_buf.index; <answer> = 
if (pipe->frame_request_config_id[i]) <token> <answer> { 
list_for_each_entry_safe(param, <token> <answer> param_tmp, 
&pipe->per_frame_params, <token> { <answer> list) 
<token> (pipe->frame_request_config_id[i] != param->params.isp_config_id) <answer> if 
pipe->frame_request_config_id[i] <token> 0; <answer> = 
<token> param); <answer> atomisp_move_frame_to_activeq(frame, 
need_to_enqueue_buffer = <token> <answer> true; 
int <token> video_device *vdev, <answer> atomisp_set_parameters(struct 
struct <token> *arg) <answer> atomisp_parameters 
struct atomisp_video_pipe *pipe = <token> <answer> atomisp_to_video_pipe(vdev); 
struct <token> *asd = pipe->asd; <answer> atomisp_sub_device 
struct atomisp_css_params_with_list <token> = NULL; <answer> *param 
struct atomisp_css_params *css_param = <token> <answer> &asd->params.css_param; 
int <token> <answer> ret; 
if (!asd->stream_env[ATOMISP_INPUT_STREAM_GENERAL].stream) <token> <answer> { 
dev_err(asd->isp->dev, "%s: internal error!\n", <token> <answer> __func__); 
return <token> <answer> -EINVAL; 
dev_dbg(asd->isp->dev, "set parameter(per_frame_setting %d) isp_config_id <token> of %s\n", <answer> %d 
<token> arg->isp_config_id, vdev->name); <answer> arg->per_frame_setting, 
<token> (arg->per_frame_setting) { <answer> if 
param = <token> GFP_KERNEL); <answer> kvzalloc(sizeof(*param), 
if (!param) <token> <answer> { 
dev_err(asd->isp->dev, "%s: failed to <token> params buffer\n", <answer> alloc 
<token> -ENOMEM; <answer> return 
css_param = <token> <answer> &param->params; 
ret = atomisp_cp_general_isp_parameters(asd, arg, <token> true); <answer> css_param, 
if <token> <answer> (ret) 
goto <token> <answer> apply_parameter_failed; 
<token> = atomisp_cp_lsc_table(asd, arg->shading_table, css_param, true); <answer> ret 
<token> (ret) <answer> if 
goto <token> <answer> apply_parameter_failed; 
ret = atomisp_cp_morph_table(asd, arg->morph_table, css_param, <token> <answer> true); 
if <token> <answer> (ret) 
goto <token> <answer> apply_parameter_failed; 
ret <token> atomisp_css_cp_dvs2_coefs(asd, <answer> = 
(struct <token> *)arg->dvs2_coefs, <answer> ia_css_dvs2_coefficients 
css_param, <token> <answer> true); 
if <token> <answer> (ret) 
goto <token> <answer> apply_parameter_failed; 
ret = atomisp_cp_dvs_6axis_config(asd, <token> <answer> arg->dvs_6axis_config, 
css_param, <token> <answer> true); 
if <token> <answer> (ret) 
goto <token> <answer> apply_parameter_failed; 
if <token> { <answer> (!arg->per_frame_setting) 
int atomisp_param(struct <token> *asd, int flag, <answer> atomisp_sub_device 
struct atomisp_parm <token> <answer> *config) 
struct ia_css_pipe_config *vp_cfg <token> <answer> = 
config->metadata_config.metadata_height = <token> <answer> asd-> 
config->metadata_config.metadata_stride = <token> <answer> asd-> 
int atomisp_color_effect(struct atomisp_sub_device *asd, <token> flag, <answer> int 
<token> *effect) <answer> __s32 
struct ia_css_cc_config *cc_config <token> NULL; <answer> = 
<token> ia_css_macc_table *macc_table = NULL; <answer> struct 
struct ia_css_ctc_table <token> = NULL; <answer> *ctc_table 
<token> ret = 0; <answer> int 
struct <token> control; <answer> v4l2_control 
struct <token> *isp = asd->isp; <answer> atomisp_device 
if (flag == 0) <token> <answer> { 
*effect <token> asd->params.color_effect; <answer> = 
<token> 0; <answer> return 
control.id <token> V4L2_CID_COLORFX; <answer> = 
control.value = <token> <answer> *effect; 
ret <token> <answer> = 
v4l2_s_ctrl(NULL, <token> <answer> isp->inputs[asd->input_curr].camera->ctrl_handler, 
<token> (!ret) { <answer> if 
asd->params.color_effect = <token> <answer> (u32)*effect; 
<token> 0; <answer> return 
<token> (*effect == asd->params.color_effect) <answer> if 
<token> 0; <answer> return 
asd->params.macc_en = <token> <answer> false; 
<token> (*effect) { <answer> switch 
<token> V4L2_COLORFX_NONE: <answer> case 
<token> = &asd->params.css_param.macc_table; <answer> macc_table 
asd->params.macc_en <token> true; <answer> = 
<token> V4L2_COLORFX_SEPIA: <answer> case 
<token> = &sepia_cc_config; <answer> cc_config 
<token> V4L2_COLORFX_NEGATIVE: <answer> case 
cc_config = <token> <answer> &nega_cc_config; 
<token> V4L2_COLORFX_BW: <answer> case 
<token> = &mono_cc_config; <answer> cc_config 
case <token> <answer> V4L2_COLORFX_SKY_BLUE: 
macc_table <token> &blue_macc_table; <answer> = 
<token> = true; <answer> asd->params.macc_en 
<token> V4L2_COLORFX_GRASS_GREEN: <answer> case 
<token> = &green_macc_table; <answer> macc_table 
asd->params.macc_en <token> true; <answer> = 
case <token> <answer> V4L2_COLORFX_SKIN_WHITEN_LOW: 
<token> = &skin_low_macc_table; <answer> macc_table 
<token> = true; <answer> asd->params.macc_en 
<token> V4L2_COLORFX_SKIN_WHITEN: <answer> case 
macc_table = <token> <answer> &skin_medium_macc_table; 
asd->params.macc_en <token> true; <answer> = 
case <token> <answer> V4L2_COLORFX_SKIN_WHITEN_HIGH: 
macc_table <token> &skin_high_macc_table; <answer> = 
asd->params.macc_en <token> true; <answer> = 
case <token> <answer> V4L2_COLORFX_VIVID: 
ctc_table = <token> <answer> &vivid_ctc_table; 
<token> -EINVAL; <answer> return 
<token> (cc_config) <answer> if 
<token> = cc_config; <answer> asd->params.config.cc_config 
<token> (macc_table) <answer> if 
asd->params.config.macc_table <token> macc_table; <answer> = 
<token> (ctc_table) <answer> if 
atomisp_css_set_ctc_table(asd, <token> <answer> ctc_table); 
<token> = (u32)*effect; <answer> asd->params.color_effect 
asd->params.css_update_params_needed = <token> <answer> true; 
<token> 0; <answer> return 
int <token> atomisp_sub_device *asd, int flag, <answer> atomisp_bad_pixel(struct 
__s32 <token> <answer> *value) 
<token> (flag == 0) { <answer> if 
*value = <token> <answer> asd->params.bad_pixel_en; 
return <token> <answer> 0; 
<token> = !!*value; <answer> asd->params.bad_pixel_en 
<token> 0; <answer> return 
<token> atomisp_bad_pixel_param(struct atomisp_sub_device *asd, int flag, <answer> int 
<token> atomisp_dp_config *config) <answer> struct 
<token> (flag == 0) { <answer> if 
<token> atomisp_video_stable(struct atomisp_sub_device *asd, int flag, <answer> int 
__s32 <token> <answer> *value) 
if <token> == 0) <answer> (flag 
*value <token> asd->params.video_dis_en; <answer> = 
asd->params.video_dis_en = <token> <answer> !!*value; 
<token> 0; <answer> return 
int <token> atomisp_sub_device *asd, int flag, <answer> atomisp_fixed_pattern(struct 
<token> *value) <answer> __s32 
if (flag == 0) <token> <answer> { 
*value <token> asd->params.fpn_en; <answer> = 
<token> 0; <answer> return 
if (*value == <token> { <answer> 0) 
asd->params.fpn_en = <token> <answer> false; 
return <token> <answer> 0; 
<token> IA_CSS_FRAME_FORMAT_NV11: <answer> case 
<token> IA_CSS_FRAME_FORMAT_NV12: <answer> case 
<token> IA_CSS_FRAME_FORMAT_NV16: <answer> case 
case <token> <answer> IA_CSS_FRAME_FORMAT_NV21: 
<token> IA_CSS_FRAME_FORMAT_NV61: <answer> case 
<token> IA_CSS_FRAME_FORMAT_YV12: <answer> case 
<token> IA_CSS_FRAME_FORMAT_YV16: <answer> case 
case <token> <answer> IA_CSS_FRAME_FORMAT_YUV420: 
case <token> <answer> IA_CSS_FRAME_FORMAT_YUV420_16: 
<token> IA_CSS_FRAME_FORMAT_YUV422: <answer> case 
case <token> <answer> IA_CSS_FRAME_FORMAT_YUV422_16: 
case <token> <answer> IA_CSS_FRAME_FORMAT_YUV444: 
<token> IA_CSS_FRAME_FORMAT_YUV_LINE: <answer> case 
<token> IA_CSS_FRAME_FORMAT_PLANAR_RGB888: <answer> case 
case <token> <answer> IA_CSS_FRAME_FORMAT_QPLANE6: 
<token> IA_CSS_FRAME_FORMAT_BINARY_8: <answer> case 
<token> bytesperline; <answer> return 
<token> int <answer> static 
atomisp_v4l2_framebuffer_to_css_frame(const struct v4l2_framebuffer <token> <answer> *arg, 
<token> ia_css_frame **result) <answer> struct 
struct <token> *res = NULL; <answer> ia_css_frame 
unsigned int <token> <answer> padded_width; 
<token> ia_css_frame_format sh_format; <answer> enum 
char <token> = NULL; <answer> *tmp_buf 
int ret = <token> <answer> 0; 
sh_format <token> v4l2_fmt_to_sh_fmt(arg->fmt.pixelformat); <answer> = 
padded_width = <token> <answer> atomisp_bytesperline_to_padded_width( 
arg->fmt.bytesperline, <token> <answer> sh_format); 
if (ia_css_frame_allocate(&res, <token> arg->fmt.height, <answer> arg->fmt.width, 
sh_format, padded_width, 0)) <token> <answer> { 
ret = <token> <answer> -ENOMEM; 
<token> err; <answer> goto 
tmp_buf <token> vmalloc(arg->fmt.sizeimage); <answer> = 
if (!tmp_buf) <token> <answer> { 
ret <token> -ENOMEM; <answer> = 
<token> err; <answer> goto 
if (copy_from_user(tmp_buf, (void <token> __force *)arg->base, <answer> __user 
arg->fmt.sizeimage)) <token> <answer> { 
ret <token> -EFAULT; <answer> = 
<token> err; <answer> goto 
if <token> tmp_buf, arg->fmt.sizeimage)) { <answer> (hmm_store(res->data, 
ret = <token> <answer> -EINVAL; 
<token> err; <answer> goto 
if (ret && <token> <answer> res) 
if (ret <token> 0) <answer> == 
*result = <token> <answer> res; 
<token> ret; <answer> return 
int atomisp_fixed_pattern_table(struct atomisp_sub_device <token> <answer> *asd, 
#include <token> <answer> <linux/bitfield.h> 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <linux/clk-provider.h> 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/device.h> 
#include <token> <answer> <linux/dma-mapping.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
<token> <linux/ioport.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/of_platform.h> 
<token> <linux/timer.h> <answer> #include 
#include <token> <answer> <linux/types.h> 
#include <token> <answer> <linux/mmc/host.h> 
#include <token> <answer> <linux/mmc/mmc.h> 
#include <token> <answer> <linux/mmc/sdio.h> 
#include <token> <answer> <linux/mmc/slot-gpio.h> 
#define MESON_MX_SDIO_ARGU <token> <answer> 0x00 
#define MESON_MX_SDIO_SEND <token> <answer> 0x04 
#define <token> GENMASK(7, 0) <answer> MESON_MX_SDIO_SEND_COMMAND_INDEX_MASK 
#define <token> GENMASK(15, 8) <answer> MESON_MX_SDIO_SEND_CMD_RESP_BITS_MASK 
#define MESON_MX_SDIO_SEND_RESP_WITHOUT_CRC7 <token> <answer> BIT(16) 
#define <token> BIT(17) <answer> MESON_MX_SDIO_SEND_RESP_HAS_DATA 
<token> MESON_MX_SDIO_SEND_RESP_CRC7_FROM_8 BIT(18) <answer> #define 
<token> MESON_MX_SDIO_SEND_CHECK_DAT0_BUSY BIT(19) <answer> #define 
#define <token> BIT(20) <answer> MESON_MX_SDIO_SEND_DATA 
#define MESON_MX_SDIO_SEND_USE_INT_WINDOW <token> <answer> BIT(21) 
#define <token> GENMASK(31, 24) <answer> MESON_MX_SDIO_SEND_REPEAT_PACKAGE_TIMES_MASK 
<token> MESON_MX_SDIO_CONF 0x08 <answer> #define 
#define <token> 0 <answer> MESON_MX_SDIO_CONF_CMD_CLK_DIV_SHIFT 
<token> MESON_MX_SDIO_CONF_CMD_CLK_DIV_WIDTH 10 <answer> #define 
#define MESON_MX_SDIO_CONF_CMD_DISABLE_CRC <token> <answer> BIT(10) 
<token> MESON_MX_SDIO_CONF_CMD_OUT_AT_POSITIVE_EDGE BIT(11) <answer> #define 
#define MESON_MX_SDIO_CONF_CMD_ARGUMENT_BITS_MASK GENMASK(17, <token> <answer> 12) 
<token> MESON_MX_SDIO_CONF_RESP_LATCH_AT_NEGATIVE_EDGE BIT(18) <answer> #define 
<token> MESON_MX_SDIO_CONF_DATA_LATCH_AT_NEGATIVE_EDGE BIT(19) <answer> #define 
#define <token> BIT(20) <answer> MESON_MX_SDIO_CONF_BUS_WIDTH 
#define MESON_MX_SDIO_CONF_M_ENDIAN_MASK <token> 21) <answer> GENMASK(22, 
<token> MESON_MX_SDIO_CONF_WRITE_NWR_MASK GENMASK(28, 23) <answer> #define 
#define MESON_MX_SDIO_CONF_WRITE_CRC_OK_STATUS_MASK GENMASK(31, <token> <answer> 29) 
<token> MESON_MX_SDIO_IRQS 0x0c <answer> #define 
#define MESON_MX_SDIO_IRQS_STATUS_STATE_MACHINE_MASK <token> 0) <answer> GENMASK(3, 
<token> MESON_MX_SDIO_IRQS_CMD_BUSY BIT(4) <answer> #define 
#define <token> BIT(5) <answer> MESON_MX_SDIO_IRQS_RESP_CRC7_OK 
#define <token> BIT(6) <answer> MESON_MX_SDIO_IRQS_DATA_READ_CRC16_OK 
<token> MESON_MX_SDIO_IRQS_DATA_WRITE_CRC16_OK BIT(7) <answer> #define 
#define <token> BIT(8) <answer> MESON_MX_SDIO_IRQS_IF_INT 
#define MESON_MX_SDIO_IRQS_CMD_INT <token> <answer> BIT(9) 
<token> MESON_MX_SDIO_IRQS_STATUS_INFO_MASK GENMASK(15, 12) <answer> #define 
#define <token> BIT(16) <answer> MESON_MX_SDIO_IRQS_TIMING_OUT_INT 
#define MESON_MX_SDIO_IRQS_AMRISC_TIMING_OUT_INT_EN <token> <answer> BIT(17) 
#define <token> BIT(18) <answer> MESON_MX_SDIO_IRQS_ARC_TIMING_OUT_INT_EN 
#define <token> GENMASK(31, 19) <answer> MESON_MX_SDIO_IRQS_TIMING_OUT_COUNT_MASK 
<token> MESON_MX_SDIO_IRQC 0x10 <answer> #define 
#define <token> BIT(3) <answer> MESON_MX_SDIO_IRQC_ARC_IF_INT_EN 
#define <token> BIT(4) <answer> MESON_MX_SDIO_IRQC_ARC_CMD_INT_EN 
#define <token> GENMASK(7, 6) <answer> MESON_MX_SDIO_IRQC_IF_CONFIG_MASK 
#define MESON_MX_SDIO_IRQC_FORCE_DATA_CLK <token> <answer> BIT(8) 
#define <token> BIT(9) <answer> MESON_MX_SDIO_IRQC_FORCE_DATA_CMD 
<token> MESON_MX_SDIO_IRQC_FORCE_DATA_DAT_MASK GENMASK(13, 10) <answer> #define 
#define <token> BIT(15) <answer> MESON_MX_SDIO_IRQC_SOFT_RESET 
<token> MESON_MX_SDIO_IRQC_FORCE_HALT BIT(30) <answer> #define 
#define MESON_MX_SDIO_IRQC_HALT_HOLE <token> <answer> BIT(31) 
#define <token> 0x14 <answer> MESON_MX_SDIO_MULT 
#define MESON_MX_SDIO_MULT_PORT_SEL_MASK <token> 0) <answer> GENMASK(1, 
#define MESON_MX_SDIO_MULT_MEMORY_STICK_ENABLE <token> <answer> BIT(2) 
<token> MESON_MX_SDIO_MULT_MEMORY_STICK_SCLK_ALWAYS BIT(3) <answer> #define 
<token> MESON_MX_SDIO_MULT_STREAM_ENABLE BIT(4) <answer> #define 
<token> MESON_MX_SDIO_MULT_STREAM_8BITS_MODE BIT(5) <answer> #define 
#define <token> BIT(8) <answer> MESON_MX_SDIO_MULT_WR_RD_OUT_INDEX 
#define MESON_MX_SDIO_MULT_DAT0_DAT1_SWAPPED <token> <answer> BIT(10) 
#define <token> BIT(11) <answer> MESON_MX_SDIO_MULT_DAT1_DAT0_SWAPPED 
<token> MESON_MX_SDIO_MULT_RESP_READ_INDEX_MASK GENMASK(15, 12) <answer> #define 
<token> MESON_MX_SDIO_ADDR 0x18 <answer> #define 
#define <token> 0x1c <answer> MESON_MX_SDIO_EXT 
<token> MESON_MX_SDIO_EXT_DATA_RW_NUMBER_MASK GENMASK(29, 16) <answer> #define 
#define MESON_MX_SDIO_BOUNCE_REQ_SIZE (128 * <token> <answer> 1024) 
#define MESON_MX_SDIO_RESPONSE_CRC16_BITS <token> - 1) <answer> (16 
#define <token> 3 <answer> MESON_MX_SDIO_MAX_SLOTS 
<token> meson_mx_mmc_host { <answer> struct 
<token> device *controller_dev; <answer> struct 
<token> clk *parent_clk; <answer> struct 
struct <token> *core_clk; <answer> clk 
struct clk_divider <token> <answer> cfg_div; 
<token> clk *cfg_div_clk; <answer> struct 
struct clk_fixed_factor <token> <answer> fixed_factor; 
struct clk <token> <answer> *fixed_factor_clk; 
void <token> *base; <answer> __iomem 
<token> irq; <answer> int 
spinlock_t <token> <answer> irq_lock; 
<token> timer_list cmd_timeout; <answer> struct 
unsigned <token> slot_id; <answer> int 
struct mmc_host <token> <answer> *mmc; 
struct <token> *mrq; <answer> mmc_request 
<token> mmc_command *cmd; <answer> struct 
<token> error; <answer> int 
static void meson_mx_mmc_mask_bits(struct mmc_host *mmc, char reg, u32 <token> <answer> mask, 
u32 <token> <answer> val) 
struct meson_mx_mmc_host <token> = mmc_priv(mmc); <answer> *host 
u32 <token> <answer> regval; 
regval = <token> + reg); <answer> readl(host->base 
regval &= <token> <answer> ~mask; 
regval |= (val & <token> <answer> mask); 
writel(regval, <token> + reg); <answer> host->base 
static void meson_mx_mmc_soft_reset(struct <token> *host) <answer> meson_mx_mmc_host 
writel(MESON_MX_SDIO_IRQC_SOFT_RESET, host->base <token> MESON_MX_SDIO_IRQC); <answer> + 
static struct mmc_command *meson_mx_mmc_get_next_cmd(struct <token> *cmd) <answer> mmc_command 
if (cmd->opcode == <token> && !cmd->error) <answer> MMC_SET_BLOCK_COUNT 
return <token> <answer> cmd->mrq->cmd; 
<token> if (mmc_op_multi(cmd->opcode) && <answer> else 
(!cmd->mrq->sbc || <token> || cmd->data->error)) <answer> cmd->error 
<token> cmd->mrq->stop; <answer> return 
return <token> <answer> NULL; 
static void meson_mx_mmc_start_cmd(struct <token> *mmc, <answer> mmc_host 
<token> mmc_command *cmd) <answer> struct 
struct meson_mx_mmc_host *host = <token> <answer> mmc_priv(mmc); 
unsigned <token> pack_size; <answer> int 
unsigned <token> irqflags, timeout; <answer> long 
<token> mult, send = 0, ext = 0; <answer> u32 
host->cmd <token> cmd; <answer> = 
<token> (cmd->busy_timeout) <answer> if 
timeout <token> msecs_to_jiffies(cmd->busy_timeout); <answer> = 
<token> = msecs_to_jiffies(1000); <answer> timeout 
switch <token> { <answer> (mmc_resp_type(cmd)) 
<token> MMC_RSP_R1: <answer> case 
<token> MMC_RSP_R1B: <answer> case 
case <token> <answer> MMC_RSP_R3: 
if <token> <answer> (!cmd) 
return <token> <answer> IRQ_HANDLED; 
<token> = 0; <answer> cmd->error 
<token> cmd); <answer> meson_mx_mmc_read_response(host->mmc, 
if <token> { <answer> (cmd->data) 
if (!((irqs & MESON_MX_SDIO_IRQS_DATA_READ_CRC16_OK) <token> <answer> || 
(irqs & <token> <answer> MESON_MX_SDIO_IRQS_DATA_WRITE_CRC16_OK))) 
cmd->error <token> -EILSEQ; <answer> = 
} <token> { <answer> else 
if (!((irqs & MESON_MX_SDIO_IRQS_RESP_CRC7_OK) <token> <answer> || 
(send <token> MESON_MX_SDIO_SEND_RESP_WITHOUT_CRC7))) <answer> & 
<token> = -EILSEQ; <answer> cmd->error 
<token> IRQ_WAKE_THREAD; <answer> return 
static irqreturn_t <token> irq, void *data) <answer> meson_mx_mmc_irq(int 
struct meson_mx_mmc_host *host <token> (void *) data; <answer> = 
u32 irqs, <token> <answer> send; 
<token> ret; <answer> irqreturn_t 
irqs = readl(host->base <token> MESON_MX_SDIO_IRQS); <answer> + 
send = readl(host->base + <token> <answer> MESON_MX_SDIO_SEND); 
if (irqs & <token> <answer> MESON_MX_SDIO_IRQS_CMD_INT) 
ret = meson_mx_mmc_process_cmd_irq(host, irqs, <token> <answer> send); 
ret = <token> <answer> IRQ_HANDLED; 
if <token> <answer> (!host->cmd) 
"Timeout on CMD%u (IRQS <token> 0x%08x, ARGU = 0x%08x)\n", <answer> = 
<token> readl(host->base + MESON_MX_SDIO_IRQS), <answer> host->cmd->opcode, 
<token> + MESON_MX_SDIO_ARGU)); <answer> readl(host->base 
host->cmd->error <token> -ETIMEDOUT; <answer> = 
static struct mmc_host_ops meson_mx_mmc_ops = <token> <answer> { 
.request <token> meson_mx_mmc_request, <answer> = 
.set_ios <token> meson_mx_mmc_set_ios, <answer> = 
.get_cd = <token> <answer> mmc_gpio_get_cd, 
.get_ro <token> mmc_gpio_get_ro, <answer> = 
static struct platform_device *meson_mx_mmc_slot_pdev(struct <token> *parent) <answer> device 
<token> device_node *slot_node; <answer> struct 
struct <token> *pdev; <answer> platform_device 
slot_node <token> of_get_compatible_child(parent->of_node, "mmc-slot"); <answer> = 
if <token> { <answer> (!slot_node) 
dev_warn(parent, "no 'mmc-slot' <token> found\n"); <answer> sub-node 
<token> ERR_PTR(-ENOENT); <answer> return 
<token> = of_platform_device_create(slot_node, NULL, parent); <answer> pdev 
return <token> <answer> pdev; 
static int meson_mx_mmc_add_host(struct meson_mx_mmc_host <token> <answer> *host) 
struct mmc_host *mmc = <token> <answer> host->mmc; 
struct <token> *slot_dev = mmc_dev(mmc); <answer> device 
int <token> <answer> ret; 
if (of_property_read_u32(slot_dev->of_node, "reg", &host->slot_id)) <token> <answer> { 
dev_err(slot_dev, <token> 'reg' property\n"); <answer> "missing 
return <token> <answer> -EINVAL; 
if <token> >= MESON_MX_SDIO_MAX_SLOTS) { <answer> (host->slot_id 
dev_err(slot_dev, <token> 'reg' property value %d\n", <answer> "invalid 
<token> -EINVAL; <answer> return 
#define pr_fmt(fmt) KBUILD_MODNAME ": <token> fmt <answer> " 
#include <token> <answer> <linux/types.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/device.h> 
<token> <linux/gpio/consumer.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/spi/spi.h> 
#define <token> "0.1.1" <answer> DRV_VERSION 
#define DRV_DESC "Micrel KS8995 Ethernet <token> SPI driver" <answer> switch 
static inline __be16 create_spi_cmd(struct ks8995_switch *ks, int <token> <answer> cmd, 
unsigned <token> <answer> address) 
u16 result <token> cmd; <answer> = 
static <token> ks8995_get_revision(struct ks8995_switch *ks) <answer> int 
int <token> <answer> err; 
u8 id0, id1, <token> <answer> ksz8864_id; 
#include <token> <answer> <linux/compat.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/sched/signal.h> 
<token> <linux/sched/rt.h> <answer> #include 
#include <token> <answer> <linux/syscalls.h> 
<token> <linux/export.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/poll.h> 
#define <token> (100 * NSEC_PER_MSEC) <answer> MAX_SLACK 
static long __estimate_accuracy(struct <token> *tv) <answer> timespec64 
<token> slack; <answer> long 
int divfactor = <token> <answer> 1000; 
if (tv->tv_sec <token> 0) <answer> < 
<token> 0; <answer> return 
<token> (task_nice(current) > 0) <answer> if 
divfactor = <token> / 5; <answer> divfactor 
if (tv->tv_sec > MAX_SLACK / <token> <answer> (NSEC_PER_SEC/divfactor)) 
return <token> <answer> MAX_SLACK; 
slack = tv->tv_nsec <token> divfactor; <answer> / 
<token> += tv->tv_sec * (NSEC_PER_SEC/divfactor); <answer> slack 
if (slack <token> MAX_SLACK) <answer> > 
<token> MAX_SLACK; <answer> return 
return <token> <answer> slack; 
u64 select_estimate_accuracy(struct <token> *tv) <answer> timespec64 
u64 <token> <answer> ret; 
struct <token> now; <answer> timespec64 
<token> (rt_task(current)) <answer> if 
<token> 0; <answer> return 
now = <token> now); <answer> timespec64_sub(*tv, 
<token> = __estimate_accuracy(&now); <answer> ret 
if <token> < current->timer_slack_ns) <answer> (ret 
<token> current->timer_slack_ns; <answer> return 
<token> ret; <answer> return 
struct poll_table_page <token> <answer> { 
struct poll_table_page * <token> <answer> next; 
<token> poll_table_entry * entry; <answer> struct 
struct <token> entries[]; <answer> poll_table_entry 
#define POLL_TABLE_FULL(table) <token> <answer> \ 
((unsigned long)((table)->entry+1) > <token> + (unsigned long)(table)) <answer> PAGE_SIZE 
static void __pollwait(struct file <token> wait_queue_head_t *wait_address, <answer> *filp, 
<token> *p); <answer> poll_table 
void <token> poll_wqueues *pwq) <answer> poll_initwait(struct 
<token> __pollwait); <answer> init_poll_funcptr(&pwq->pt, 
pwq->polling_task = <token> <answer> current; 
pwq->triggered = <token> <answer> 0; 
pwq->error = <token> <answer> 0; 
<token> = NULL; <answer> pwq->table 
<token> = 0; <answer> pwq->inline_index 
static void free_poll_entry(struct <token> *entry) <answer> poll_table_entry 
<token> &entry->wait); <answer> remove_wait_queue(entry->wait_address, 
void poll_freewait(struct <token> *pwq) <answer> poll_wqueues 
struct poll_table_page <token> p = pwq->table; <answer> * 
<token> i; <answer> int 
for (i = 0; <token> < pwq->inline_index; i++) <answer> i 
free_poll_entry(pwq->inline_entries + <token> <answer> i); 
while <token> { <answer> (p) 
struct <token> * entry; <answer> poll_table_entry 
struct poll_table_page <token> <answer> *old; 
<token> = p->entry; <answer> entry 
do <token> <answer> { 
} <token> (entry > p->entries); <answer> while 
old = <token> <answer> p; 
<token> = p->next; <answer> p 
free_page((unsigned <token> old); <answer> long) 
static struct poll_table_entry *poll_get_entry(struct <token> *p) <answer> poll_wqueues 
struct <token> *table = p->table; <answer> poll_table_page 
if <token> < N_INLINE_POLL_ENTRIES) <answer> (p->inline_index 
return p->inline_entries <token> p->inline_index++; <answer> + 
if (!table <token> POLL_TABLE_FULL(table)) { <answer> || 
struct <token> *new_table; <answer> poll_table_page 
new_table <token> (struct poll_table_page *) __get_free_page(GFP_KERNEL); <answer> = 
<token> (!new_table) { <answer> if 
<token> = -ENOMEM; <answer> p->error 
return <token> <answer> NULL; 
<token> = new_table->entries; <answer> new_table->entry 
new_table->next = <token> <answer> table; 
p->table <token> new_table; <answer> = 
table = <token> <answer> new_table; 
<token> table->entry++; <answer> return 
static int __pollwake(wait_queue_entry_t *wait, unsigned <token> int sync, void *key) <answer> mode, 
struct <token> *pwq = wait->private; <answer> poll_wqueues 
DECLARE_WAITQUEUE(dummy_wait, <token> <answer> pwq->polling_task); 
pwq->triggered = <token> <answer> 1; 
return default_wake_function(&dummy_wait, mode, sync, <token> <answer> key); 
static int pollwake(wait_queue_entry_t *wait, unsigned mode, int sync, void <token> <answer> *key) 
<token> poll_table_entry *entry; <answer> struct 
entry = container_of(wait, <token> poll_table_entry, wait); <answer> struct 
if <token> && !(key_to_poll(key) & entry->key)) <answer> (key 
return <token> <answer> 0; 
return __pollwake(wait, mode, <token> key); <answer> sync, 
<token> 0); <answer> smp_store_mb(pwq->triggered, 
return <token> <answer> rc; 
int poll_select_set_timeout(struct timespec64 *to, time64_t sec, <token> nsec) <answer> long 
struct timespec64 <token> = {.tv_sec = sec, .tv_nsec = nsec}; <answer> ts 
<token> (!timespec64_valid(&ts)) <answer> if 
return <token> <answer> -EINVAL; 
if <token> == -ERESTARTNOHAND) <answer> (ret 
<token> = -EINTR; <answer> ret 
<token> ret; <answer> return 
<token> struct { <answer> typedef 
unsigned long <token> *out, *ex; <answer> *in, 
unsigned <token> *res_in, *res_out, *res_ex; <answer> long 
} <token> <answer> fd_set_bits; 
<token> FDS_BITPERLONG (8*sizeof(long)) <answer> #define 
#define <token> (((nr)+FDS_BITPERLONG-1)/FDS_BITPERLONG) <answer> FDS_LONGS(nr) 
<token> FDS_BYTES(nr) (FDS_LONGS(nr)*sizeof(long)) <answer> #define 
static <token> <answer> inline 
int get_fd_set(unsigned long <token> void __user *ufdset, unsigned long *fdset) <answer> nr, 
nr = <token> <answer> FDS_BYTES(nr); 
if <token> <answer> (ufdset) 
<token> copy_from_user(fdset, ufdset, nr) ? -EFAULT : 0; <answer> return 
memset(fdset, 0, <token> <answer> nr); 
return <token> <answer> 0; 
static inline unsigned long <token> <answer> __must_check 
set_fd_set(unsigned long nr, <token> __user *ufdset, unsigned long *fdset) <answer> void 
if <token> <answer> (ufdset) 
return __copy_to_user(ufdset, <token> FDS_BYTES(nr)); <answer> fdset, 
<token> 0; <answer> return 
static <token> <answer> inline 
void zero_fd_set(unsigned long nr, unsigned long <token> <answer> *fdset) 
memset(fdset, 0, <token> <answer> FDS_BYTES(nr)); 
#define <token> n) (fds->in + n) <answer> FDS_IN(fds, 
<token> FDS_OUT(fds, n) (fds->out + n) <answer> #define 
#define <token> n) (fds->ex + n) <answer> FDS_EX(fds, 
#define <token> n) (*FDS_IN(fds, n)|*FDS_OUT(fds, n)|*FDS_EX(fds, n)) <answer> BITS(fds, 
static int max_select_fd(unsigned long n, fd_set_bits <token> <answer> *fds) 
<token> long *open_fds; <answer> unsigned 
<token> long set; <answer> unsigned 
int <token> <answer> max; 
struct fdtable <token> <answer> *fdt; 
} else if (busy_flag <token> mask) <answer> & 
can_busy_loop = <token> <answer> true; 
if <token> <answer> (res_in) 
*rinp = <token> <answer> res_in; 
if <token> <answer> (res_out) 
<token> = res_out; <answer> *routp 
if <token> <answer> (res_ex) 
<token> = res_ex; <answer> *rexp 
wait->_qproc = <token> <answer> NULL; 
if (retval || <token> || signal_pending(current)) <answer> timed_out 
<token> (table.error) { <answer> if 
retval <token> table.error; <answer> = 
if <token> && !to) { <answer> (end_time 
expire = <token> <answer> timespec64_to_ktime(*end_time); 
to = <token> <answer> &expire; 
<token> (!poll_schedule_timeout(&table, TASK_INTERRUPTIBLE, <answer> if 
to, <token> <answer> slack)) 
timed_out <token> 1; <answer> = 
return <token> <answer> retval; 
int core_sys_select(int n, fd_set __user <token> fd_set __user *outp, <answer> *inp, 
fd_set __user *exp, struct <token> *end_time) <answer> timespec64 
<token> fds; <answer> fd_set_bits 
void <token> <answer> *bits; 
int ret, <token> <answer> max_fds; 
size_t size, <token> <answer> alloc_size; 
struct <token> *fdt; <answer> fdtable 
<token> = FDS_BYTES(n); <answer> size 
<token> = stack_fds; <answer> bits 
if (size <token> sizeof(stack_fds) / 6) { <answer> > 
struct <token> { <answer> sigset_argpack 
sigset_t __user <token> <answer> *p; 
<token> size; <answer> size_t 
static inline <token> get_sigset_argpack(struct sigset_argpack *to, <answer> int 
struct sigset_argpack __user <token> <answer> *from) 
if (from) <token> <answer> { 
<token> (!user_read_access_begin(from, sizeof(*from))) <answer> if 
return <token> <answer> -EFAULT; 
unsafe_get_user(to->p, &from->p, <token> <answer> Efault); 
<token> &from->size, Efault); <answer> unsafe_get_user(to->size, 
return <token> <answer> 0; 
return <token> <answer> -EFAULT; 
<token> int, n, fd_set __user *, inp, fd_set __user *, outp, <answer> SYSCALL_DEFINE6(pselect6, 
fd_set __user *, exp, struct __kernel_timespec __user <token> tsp, <answer> *, 
void __user <token> sig) <answer> *, 
struct sigset_argpack x = {NULL, <token> <answer> 0}; 
if (get_sigset_argpack(&x, <token> <answer> sig)) 
return <token> <answer> -EFAULT; 
return do_pselect(n, inp, <token> exp, tsp, x.p, x.size, PT_TIMESPEC); <answer> outp, 
<token> defined(CONFIG_COMPAT_32BIT_TIME) && !defined(CONFIG_64BIT) <answer> #if 
SYSCALL_DEFINE6(pselect6_time32, <token> n, fd_set __user *, inp, fd_set __user *, outp, <answer> int, 
fd_set __user *, <token> struct old_timespec32 __user *, tsp, <answer> exp, 
void __user <token> sig) <answer> *, 
struct sigset_argpack x = <token> 0}; <answer> {NULL, 
if <token> sig)) <answer> (get_sigset_argpack(&x, 
return <token> <answer> -EFAULT; 
return do_pselect(n, inp, outp, exp, tsp, <token> x.size, PT_OLD_TIMESPEC); <answer> x.p, 
#ifdef <token> <answer> __ARCH_WANT_SYS_OLD_SELECT 
struct <token> { <answer> sel_arg_struct 
unsigned <token> n; <answer> long 
fd_set __user *inp, <token> *exp; <answer> *outp, 
struct <token> __user *tvp; <answer> __kernel_old_timeval 
SYSCALL_DEFINE1(old_select, struct <token> __user *, arg) <answer> sel_arg_struct 
struct <token> a; <answer> sel_arg_struct 
if <token> arg, sizeof(a))) <answer> (copy_from_user(&a, 
return <token> <answer> -EFAULT; 
return kern_select(a.n, a.inp, a.outp, <token> a.tvp); <answer> a.exp, 
<token> poll_list { <answer> struct 
<token> poll_list *next; <answer> struct 
unsigned <token> len; <answer> int 
struct pollfd <token> <answer> entries[]; 
#define POLLFD_PER_PAGE ((PAGE_SIZE-sizeof(struct poll_list)) / <token> pollfd)) <answer> sizeof(struct 
static inline __poll_t <token> pollfd *pollfd, poll_table *pwait, <answer> do_pollfd(struct 
<token> *can_busy_poll, <answer> bool 
<token> busy_flag) <answer> __poll_t 
int fd <token> pollfd->fd; <answer> = 
__poll_t mask = 0, <token> <answer> filter; 
struct fd <token> <answer> f; 
<token> (fd < 0) <answer> if 
goto <token> <answer> out; 
mask <token> EPOLLNVAL; <answer> = 
f = <token> <answer> fdget(fd); 
if <token> <answer> (!f.file) 
goto <token> <answer> out; 
<token> (do_pollfd(pfd, pt, &can_busy_loop, <answer> if 
busy_flag)) <token> <answer> { 
pt->_qproc <token> NULL; <answer> = 
pt->_qproc <token> NULL; <answer> = 
if (!count) <token> <answer> { 
count <token> wait->error; <answer> = 
<token> (signal_pending(current)) <answer> if 
<token> = -ERESTARTNOHAND; <answer> count 
if <token> || timed_out) <answer> (count 
if (end_time <token> !to) { <answer> && 
<token> = timespec64_to_ktime(*end_time); <answer> expire 
<token> = &expire; <answer> to 
if <token> TASK_INTERRUPTIBLE, to, slack)) <answer> (!poll_schedule_timeout(wait, 
timed_out <token> 1; <answer> = 
return <token> <answer> count; 
#define N_STACK_PPS ((sizeof(stack_pps) <token> sizeof(struct poll_list)) / \ <answer> - 
sizeof(struct <token> <answer> pollfd)) 
static int do_sys_poll(struct pollfd __user <token> unsigned int nfds, <answer> *ufds, 
<token> timespec64 *end_time) <answer> struct 
<token> poll_wqueues table; <answer> struct 
int err = -EFAULT, <token> <answer> fdcount; 
<token> stack_pps[POLL_STACK_ALLOC/sizeof(long)]; <answer> long 
struct poll_list *const <token> = (struct poll_list *)stack_pps; <answer> head 
struct <token> *walk = head; <answer> poll_list 
<token> int todo = nfds; <answer> unsigned 
<token> int len; <answer> unsigned 
if (nfds <token> rlimit(RLIMIT_NOFILE)) <answer> > 
return <token> <answer> -EINVAL; 
<token> = min_t(unsigned int, nfds, N_STACK_PPS); <answer> len 
<token> (;;) { <answer> for 
walk->next <token> NULL; <answer> = 
walk->len = <token> <answer> len; 
if <token> <answer> (!len) 
<token> (copy_from_user(walk->entries, ufds + nfds-todo, <answer> if 
sizeof(struct pollfd) * <token> <answer> walk->len)) 
<token> out_fds; <answer> goto 
if (walk->len <token> todo) <answer> >= 
<token> -= walk->len; <answer> todo 
len <token> min(todo, POLLFD_PER_PAGE); <answer> = 
walk = walk->next <token> kmalloc(struct_size(walk, entries, len), <answer> = 
if (!walk) <token> <answer> { 
err = <token> <answer> -ENOMEM; 
goto <token> <answer> out_fds; 
fdcount = do_poll(head, <token> end_time); <answer> &table, 
if (!user_write_access_begin(ufds, nfds * <token> <answer> sizeof(*ufds))) 
goto <token> <answer> out_fds; 
for (walk = head; walk; <token> = walk->next) { <answer> walk 
struct pollfd *fds = <token> <answer> walk->entries; 
<token> int j; <answer> unsigned 
for (j = <token> j; fds++, ufds++, j--) <answer> walk->len; 
<token> &ufds->revents, Efault); <answer> unsafe_put_user(fds->revents, 
err <token> fdcount; <answer> = 
walk = <token> <answer> head->next; 
<token> (walk) { <answer> while 
struct poll_list *pos <token> walk; <answer> = 
walk <token> walk->next; <answer> = 
<token> err; <answer> return 
err = <token> <answer> -EFAULT; 
goto <token> <answer> out_fds; 
static long <token> restart_block *restart_block) <answer> do_restart_poll(struct 
struct pollfd <token> *ufds = restart_block->poll.ufds; <answer> __user 
int nfds <token> restart_block->poll.nfds; <answer> = 
struct timespec64 <token> = NULL, end_time; <answer> *to 
int <token> <answer> ret; 
if (restart_block->poll.has_timeout) <token> <answer> { 
end_time.tv_sec <token> restart_block->poll.tv_sec; <answer> = 
<token> = restart_block->poll.tv_nsec; <answer> end_time.tv_nsec 
to = <token> <answer> &end_time; 
ret = do_sys_poll(ufds, nfds, <token> <answer> to); 
<token> (ret == -ERESTARTNOHAND) <answer> if 
ret <token> set_restart_fn(restart_block, do_restart_poll); <answer> = 
<token> ret; <answer> return 
SYSCALL_DEFINE3(poll, struct pollfd __user *, ufds, unsigned <token> nfds, <answer> int, 
int, <token> <answer> timeout_msecs) 
struct timespec64 end_time, <token> = NULL; <answer> *to 
int <token> <answer> ret; 
if (timeout_msecs >= <token> { <answer> 0) 
to = <token> <answer> &end_time; 
poll_select_set_timeout(to, <token> / MSEC_PER_SEC, <answer> timeout_msecs 
<token> * (timeout_msecs % MSEC_PER_SEC)); <answer> NSEC_PER_MSEC 
ret = <token> nfds, to); <answer> do_sys_poll(ufds, 
if (ret == -ERESTARTNOHAND) <token> <answer> { 
struct restart_block <token> <answer> *restart_block; 
restart_block = <token> <answer> &current->restart_block; 
restart_block->poll.ufds <token> ufds; <answer> = 
restart_block->poll.nfds = <token> <answer> nfds; 
if <token> >= 0) { <answer> (timeout_msecs 
restart_block->poll.tv_sec <token> end_time.tv_sec; <answer> = 
restart_block->poll.tv_nsec = <token> <answer> end_time.tv_nsec; 
<token> = 1; <answer> restart_block->poll.has_timeout 
<token> else <answer> } 
restart_block->poll.has_timeout <token> 0; <answer> = 
<token> = set_restart_fn(restart_block, do_restart_poll); <answer> ret 
return <token> <answer> ret; 
SYSCALL_DEFINE5(ppoll, struct pollfd __user *, <token> unsigned int, nfds, <answer> ufds, 
struct __kernel_timespec __user *, tsp, const sigset_t __user <token> sigmask, <answer> *, 
size_t, <token> <answer> sigsetsize) 
struct timespec64 ts, <token> *to = NULL; <answer> end_time, 
<token> ret; <answer> int 
if (tsp) <token> <answer> { 
if <token> tsp)) <answer> (get_timespec64(&ts, 
return <token> <answer> -EFAULT; 
to <token> &end_time; <answer> = 
<token> (poll_select_set_timeout(to, ts.tv_sec, ts.tv_nsec)) <answer> if 
<token> -EINVAL; <answer> return 
ret = set_user_sigmask(sigmask, <token> <answer> sigsetsize); 
<token> (ret) <answer> if 
<token> ret; <answer> return 
ret = do_sys_poll(ufds, nfds, <token> <answer> to); 
return poll_select_finish(&end_time, tsp, <token> ret); <answer> PT_TIMESPEC, 
#if defined(CONFIG_COMPAT_32BIT_TIME) <token> !defined(CONFIG_64BIT) <answer> && 
SYSCALL_DEFINE5(ppoll_time32, struct pollfd __user *, <token> unsigned int, nfds, <answer> ufds, 
struct old_timespec32 __user *, tsp, const <token> __user *, sigmask, <answer> sigset_t 
size_t, <token> <answer> sigsetsize) 
struct timespec64 ts, <token> *to = NULL; <answer> end_time, 
int <token> <answer> ret; 
if <token> { <answer> (tsp) 
<token> (get_old_timespec32(&ts, tsp)) <answer> if 
<token> -EFAULT; <answer> return 
to <token> &end_time; <answer> = 
if (poll_select_set_timeout(to, <token> ts.tv_nsec)) <answer> ts.tv_sec, 
<token> -EINVAL; <answer> return 
<token> = set_user_sigmask(sigmask, sigsetsize); <answer> ret 
<token> (ret) <answer> if 
return <token> <answer> ret; 
ret <token> do_sys_poll(ufds, nfds, to); <answer> = 
return <token> tsp, PT_OLD_TIMESPEC, ret); <answer> poll_select_finish(&end_time, 
<token> CONFIG_COMPAT <answer> #ifdef 
#define <token> (8 * sizeof(compat_ulong_t)) <answer> __COMPAT_NFDBITS 
int compat_get_fd_set(unsigned long nr, <token> __user *ufdset, <answer> compat_ulong_t 
unsigned <token> *fdset) <answer> long 
if (ufdset) <token> <answer> { 
<token> compat_get_bitmap(fdset, ufdset, nr); <answer> return 
<token> else { <answer> } 
<token> fdset); <answer> zero_fd_set(nr, 
return <token> <answer> 0; 
int compat_set_fd_set(unsigned long <token> compat_ulong_t __user *ufdset, <answer> nr, 
unsigned long <token> <answer> *fdset) 
<token> (!ufdset) <answer> if 
return <token> <answer> 0; 
return compat_put_bitmap(ufdset, fdset, <token> <answer> nr); 
static int compat_core_sys_select(int n, compat_ulong_t <token> *inp, <answer> __user 
<token> __user *outp, compat_ulong_t __user *exp, <answer> compat_ulong_t 
struct <token> *end_time) <answer> timespec64 
<token> fds; <answer> fd_set_bits 
<token> *bits; <answer> void 
int <token> max_fds, ret = -EINVAL; <answer> size, 
struct fdtable <token> <answer> *fdt; 
long <token> <answer> stack_fds[SELECT_STACK_ALLOC/sizeof(long)]; 
if (n <token> 0) <answer> < 
goto <token> <answer> out_nofds; 
size <token> FDS_BYTES(n); <answer> = 
bits <token> stack_fds; <answer> = 
if (size > <token> / 6) { <answer> sizeof(stack_fds) 
<token> = kmalloc_array(6, size, GFP_KERNEL); <answer> bits 
ret = <token> <answer> -ENOMEM; 
<token> (!bits) <answer> if 
<token> out_nofds; <answer> goto 
<token> = (unsigned long *) bits; <answer> fds.in 
fds.out = (unsigned long *) (bits + <token> <answer> size); 
fds.ex <token> (unsigned long *) (bits + 2*size); <answer> = 
fds.res_in <token> (unsigned long *) (bits + 3*size); <answer> = 
fds.res_out <token> (unsigned long *) (bits + 4*size); <answer> = 
fds.res_ex = (unsigned long <token> (bits + 5*size); <answer> *) 
if <token> = compat_get_fd_set(n, inp, fds.in)) || <answer> ((ret 
(ret <token> compat_get_fd_set(n, outp, fds.out)) || <answer> = 
(ret <token> compat_get_fd_set(n, exp, fds.ex))) <answer> = 
<token> out; <answer> goto 
<token> fds.res_in); <answer> zero_fd_set(n, 
<token> fds.res_out); <answer> zero_fd_set(n, 
<token> fds.res_ex); <answer> zero_fd_set(n, 
ret = do_select(n, &fds, <token> <answer> end_time); 
if <token> < 0) <answer> (ret 
goto <token> <answer> out; 
if <token> { <answer> (!ret) 
ret <token> -ERESTARTNOHAND; <answer> = 
<token> (signal_pending(current)) <answer> if 
<token> out; <answer> goto 
ret = <token> <answer> 0; 
if <token> inp, fds.res_in) || <answer> (compat_set_fd_set(n, 
compat_set_fd_set(n, outp, <token> || <answer> fds.res_out) 
<token> exp, fds.res_ex)) <answer> compat_set_fd_set(n, 
ret <token> -EFAULT; <answer> = 
if <token> != stack_fds) <answer> (bits 
return <token> <answer> ret; 
static <token> do_compat_select(int n, compat_ulong_t __user *inp, <answer> int 
compat_ulong_t __user *outp, <token> __user *exp, <answer> compat_ulong_t 
struct old_timeval32 <token> *tvp) <answer> __user 
<token> timespec64 end_time, *to = NULL; <answer> struct 
struct <token> tv; <answer> old_timeval32 
<token> ret; <answer> int 
<token> (tvp) { <answer> if 
if (copy_from_user(&tv, <token> sizeof(tv))) <answer> tvp, 
<token> -EFAULT; <answer> return 
<token> = &end_time; <answer> to 
if <token> <answer> (poll_select_set_timeout(to, 
tv.tv_sec + <token> / USEC_PER_SEC), <answer> (tv.tv_usec 
(tv.tv_usec % USEC_PER_SEC) * <token> <answer> NSEC_PER_USEC)) 
<token> -EINVAL; <answer> return 
<token> = compat_core_sys_select(n, inp, outp, exp, to); <answer> ret 
return poll_select_finish(&end_time, tvp, <token> ret); <answer> PT_OLD_TIMEVAL, 
<token> int, n, compat_ulong_t __user *, inp, <answer> COMPAT_SYSCALL_DEFINE5(select, 
<token> __user *, outp, compat_ulong_t __user *, exp, <answer> compat_ulong_t 
<token> old_timeval32 __user *, tvp) <answer> struct 
return <token> inp, outp, exp, tvp); <answer> do_compat_select(n, 
<token> compat_sel_arg_struct { <answer> struct 
<token> n; <answer> compat_ulong_t 
compat_uptr_t <token> <answer> inp; 
<token> outp; <answer> compat_uptr_t 
compat_uptr_t <token> <answer> exp; 
compat_uptr_t <token> <answer> tvp; 
COMPAT_SYSCALL_DEFINE1(old_select, struct compat_sel_arg_struct <token> *, arg) <answer> __user 
struct compat_sel_arg_struct <token> <answer> a; 
<token> (copy_from_user(&a, arg, sizeof(a))) <answer> if 
<token> -EFAULT; <answer> return 
<token> do_compat_select(a.n, compat_ptr(a.inp), compat_ptr(a.outp), <answer> return 
<token> compat_ptr(a.tvp)); <answer> compat_ptr(a.exp), 
<token> long do_compat_pselect(int n, compat_ulong_t __user *inp, <answer> static 
<token> __user *outp, compat_ulong_t __user *exp, <answer> compat_ulong_t 
void __user *tsp, compat_sigset_t <token> *sigmask, <answer> __user 
compat_size_t <token> enum poll_time_type type) <answer> sigsetsize, 
struct <token> ts, end_time, *to = NULL; <answer> timespec64 
int <token> <answer> ret; 
if (tsp) <token> <answer> { 
<token> (type) { <answer> switch 
<token> PT_OLD_TIMESPEC: <answer> case 
if <token> tsp)) <answer> (get_old_timespec32(&ts, 
<token> -EFAULT; <answer> return 
case <token> <answer> PT_TIMESPEC: 
<token> (get_timespec64(&ts, tsp)) <answer> if 
return <token> <answer> -EFAULT; 
<token> = &end_time; <answer> to 
<token> (poll_select_set_timeout(to, ts.tv_sec, ts.tv_nsec)) <answer> if 
return <token> <answer> -EINVAL; 
ret = <token> sigsetsize); <answer> set_compat_user_sigmask(sigmask, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
ret = compat_core_sys_select(n, inp, outp, <token> to); <answer> exp, 
return poll_select_finish(&end_time, <token> type, ret); <answer> tsp, 
<token> compat_sigset_argpack { <answer> struct 
<token> p; <answer> compat_uptr_t 
<token> size; <answer> compat_size_t 
static inline <token> get_compat_sigset_argpack(struct compat_sigset_argpack *to, <answer> int 
<token> compat_sigset_argpack __user *from) <answer> struct 
if (from) <token> <answer> { 
if <token> sizeof(*from))) <answer> (!user_read_access_begin(from, 
return <token> <answer> -EFAULT; 
unsafe_get_user(to->p, <token> Efault); <answer> &from->p, 
<token> &from->size, Efault); <answer> unsafe_get_user(to->size, 
<token> 0; <answer> return 
return <token> <answer> -EFAULT; 
COMPAT_SYSCALL_DEFINE6(pselect6_time64, <token> n, compat_ulong_t __user *, inp, <answer> int, 
compat_ulong_t __user *, outp, compat_ulong_t <token> *, exp, <answer> __user 
struct __kernel_timespec <token> *, tsp, void __user *, sig) <answer> __user 
struct <token> x = {0, 0}; <answer> compat_sigset_argpack 
<token> (get_compat_sigset_argpack(&x, sig)) <answer> if 
<token> -EFAULT; <answer> return 
return do_compat_pselect(n, inp, outp, exp, tsp, <token> <answer> compat_ptr(x.p), 
x.size, <token> <answer> PT_TIMESPEC); 
<token> defined(CONFIG_COMPAT_32BIT_TIME) <answer> #if 
COMPAT_SYSCALL_DEFINE6(pselect6_time32, int, n, <token> __user *, inp, <answer> compat_ulong_t 
compat_ulong_t <token> *, outp, compat_ulong_t __user *, exp, <answer> __user 
struct old_timespec32 __user *, tsp, void __user *, <token> <answer> sig) 
struct compat_sigset_argpack <token> = {0, 0}; <answer> x 
if (get_compat_sigset_argpack(&x, <token> <answer> sig)) 
<token> -EFAULT; <answer> return 
return do_compat_pselect(n, inp, outp, exp, tsp, <token> <answer> compat_ptr(x.p), 
x.size, <token> <answer> PT_OLD_TIMESPEC); 
<token> defined(CONFIG_COMPAT_32BIT_TIME) <answer> #if 
COMPAT_SYSCALL_DEFINE5(ppoll_time32, struct <token> __user *, ufds, <answer> pollfd 
unsigned int, nfds, struct old_timespec32 <token> *, tsp, <answer> __user 
const compat_sigset_t <token> *, sigmask, compat_size_t, sigsetsize) <answer> __user 
struct timespec64 ts, <token> *to = NULL; <answer> end_time, 
int <token> <answer> ret; 
if <token> { <answer> (tsp) 
if (get_old_timespec32(&ts, <token> <answer> tsp)) 
<token> -EFAULT; <answer> return 
to <token> &end_time; <answer> = 
if (poll_select_set_timeout(to, ts.tv_sec, <token> <answer> ts.tv_nsec)) 
<token> -EINVAL; <answer> return 
ret = <token> sigsetsize); <answer> set_compat_user_sigmask(sigmask, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
ret <token> do_sys_poll(ufds, nfds, to); <answer> = 
return poll_select_finish(&end_time, tsp, <token> ret); <answer> PT_OLD_TIMESPEC, 
#include <token> <answer> <linux/clk-provider.h> 
<token> "sun8i_dw_hdmi.h" <answer> #include 
<token> sun8i_phy_clk { <answer> struct 
struct <token> hw; <answer> clk_hw 
<token> sun8i_hdmi_phy *phy; <answer> struct 
static inline struct sun8i_phy_clk *hw_to_phy_clk(struct <token> *hw) <answer> clk_hw 
<token> container_of(hw, struct sun8i_phy_clk, hw); <answer> return 
static int sun8i_phy_clk_determine_rate(struct clk_hw <token> <answer> *hw, 
struct <token> *req) <answer> clk_rate_request 
unsigned long rate = <token> <answer> req->rate; 
unsigned <token> best_rate = 0; <answer> long 
struct clk_hw <token> = NULL; <answer> *best_parent 
<token> clk_hw *parent; <answer> struct 
<token> best_div = 1; <answer> int 
int <token> p; <answer> i, 
for (p = 0; <token> < clk_hw_get_num_parents(hw); p++) { <answer> p 
<token> = clk_hw_get_parent_by_index(hw, p); <answer> parent 
if <token> <answer> (!parent) 
for (i = 1; i <token> 16; i++) { <answer> <= 
unsigned long ideal = rate * <token> <answer> i; 
unsigned <token> rounded; <answer> long 
rounded = <token> ideal); <answer> clk_hw_round_rate(parent, 
<token> (rounded == ideal) { <answer> if 
<token> = rounded; <answer> best_rate 
<token> = i; <answer> best_div 
best_parent = <token> <answer> parent; 
<token> (!best_rate || <answer> if 
abs(rate - rounded / <token> < <answer> i) 
<token> - best_rate / best_div)) { <answer> abs(rate 
<token> = rounded; <answer> best_rate 
best_div = <token> <answer> i; 
best_parent = <token> <answer> parent; 
if (best_rate / best_div <token> rate) <answer> == 
req->rate = best_rate / <token> <answer> best_div; 
req->best_parent_rate <token> best_rate; <answer> = 
req->best_parent_hw <token> best_parent; <answer> = 
<token> 0; <answer> return 
<token> unsigned long sun8i_phy_clk_recalc_rate(struct clk_hw *hw, <answer> static 
unsigned long <token> <answer> parent_rate) 
struct sun8i_phy_clk *priv = <token> <answer> hw_to_phy_clk(hw); 
u32 <token> <answer> reg; 
regmap_read(priv->phy->regs, <token> &reg); <answer> SUN8I_HDMI_PHY_PLL_CFG2_REG, 
reg = ((reg >> SUN8I_HDMI_PHY_PLL_CFG2_PREDIV_SHIFT) <token> <answer> & 
SUN8I_HDMI_PHY_PLL_CFG2_PREDIV_MSK) + <token> <answer> 1; 
return parent_rate / <token> <answer> reg; 
static int sun8i_phy_clk_set_rate(struct clk_hw *hw, <token> long rate, <answer> unsigned 
unsigned <token> parent_rate) <answer> long 
<token> sun8i_phy_clk *priv = hw_to_phy_clk(hw); <answer> struct 
unsigned long <token> = 0; <answer> best_rate 
u8 <token> = 0, m; <answer> best_m 
for (m <token> 1; m <= 16; m++) { <answer> = 
unsigned long <token> = parent_rate / m; <answer> tmp_rate 
if <token> > rate) <answer> (tmp_rate 
if (!best_rate <token> <answer> || 
<token> - tmp_rate) < (rate - best_rate)) { <answer> (rate 
<token> = tmp_rate; <answer> best_rate 
best_m = <token> <answer> m; 
regmap_update_bits(priv->phy->regs, <token> <answer> SUN8I_HDMI_PHY_PLL_CFG2_REG, 
<token> 0; <answer> return 
static u8 sun8i_phy_clk_get_parent(struct clk_hw <token> <answer> *hw) 
struct sun8i_phy_clk *priv = <token> <answer> hw_to_phy_clk(hw); 
<token> reg; <answer> u32 
regmap_read(priv->phy->regs, <token> &reg); <answer> SUN8I_HDMI_PHY_PLL_CFG1_REG, 
reg = (reg & <token> >> <answer> SUN8I_HDMI_PHY_PLL_CFG1_CKIN_SEL_MSK) 
return <token> <answer> reg; 
<token> int sun8i_phy_clk_set_parent(struct clk_hw *hw, u8 index) <answer> static 
struct sun8i_phy_clk *priv <token> hw_to_phy_clk(hw); <answer> = 
if <token> > 1) <answer> (index 
<token> -EINVAL; <answer> return 
regmap_update_bits(priv->phy->regs, <token> <answer> SUN8I_HDMI_PHY_PLL_CFG1_REG, 
<token> << SUN8I_HDMI_PHY_PLL_CFG1_CKIN_SEL_SHIFT); <answer> index 
<token> 0; <answer> return 
static const struct <token> sun8i_phy_clk_ops = { <answer> clk_ops 
.determine_rate = <token> <answer> sun8i_phy_clk_determine_rate, 
.recalc_rate = <token> <answer> sun8i_phy_clk_recalc_rate, 
.set_rate <token> sun8i_phy_clk_set_rate, <answer> = 
.get_parent = <token> <answer> sun8i_phy_clk_get_parent, 
.set_parent <token> sun8i_phy_clk_set_parent, <answer> = 
<token> sun8i_phy_clk_create(struct sun8i_hdmi_phy *phy, struct device *dev, <answer> int 
<token> second_parent) <answer> bool 
<token> clk_init_data init; <answer> struct 
struct sun8i_phy_clk <token> <answer> *priv; 
<token> char *parents[2]; <answer> const 
parents[0] <token> __clk_get_name(phy->clk_pll0); <answer> = 
<token> (!parents[0]) <answer> if 
<token> -ENODEV; <answer> return 
if <token> { <answer> (second_parent) 
parents[1] <token> __clk_get_name(phy->clk_pll1); <answer> = 
<token> (!parents[1]) <answer> if 
return <token> <answer> -ENODEV; 
priv = devm_kzalloc(dev, sizeof(*priv), <token> <answer> GFP_KERNEL); 
<token> (!priv) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = "hdmi-phy-clk"; <answer> init.name 
<token> = &sun8i_phy_clk_ops; <answer> init.ops 
init.parent_names <token> parents; <answer> = 
init.num_parents = <token> ? 2 : 1; <answer> second_parent 
<token> = CLK_SET_RATE_PARENT; <answer> init.flags 
priv->phy <token> phy; <answer> = 
priv->hw.init = <token> <answer> &init; 
phy->clk_phy = <token> &priv->hw); <answer> devm_clk_register(dev, 
<token> (IS_ERR(phy->clk_phy)) <answer> if 
<token> PTR_ERR(phy->clk_phy); <answer> return 
return <token> <answer> 0; 
<token> <linux/bitops.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/pci.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/seq_file.h> <answer> #include 
<token> <linux/crc32.h> <answer> #include 
#include <token> <answer> "net_driver.h" 
<token> "bitfield.h" <answer> #include 
<token> "efx.h" <answer> #include 
<token> "rx_common.h" <answer> #include 
#include <token> <answer> "tx_common.h" 
<token> "nic.h" <answer> #include 
<token> "farch_regs.h" <answer> #include 
#include <token> <answer> "sriov.h" 
<token> "siena_sriov.h" <answer> #include 
<token> "io.h" <answer> #include 
#include <token> <answer> "workarounds.h" 
#define <token> 16 <answer> TX_DC_ENTRIES 
#define <token> 1 <answer> TX_DC_ENTRIES_ORDER 
#define RX_DC_ENTRIES <token> <answer> 64 
#define <token> 3 <answer> RX_DC_ENTRIES_ORDER 
#define <token> 3600 <answer> EFX_INT_ERROR_EXPIRE 
#define <token> 5 <answer> EFX_MAX_INT_ERRORS 
static <token> void efx_write_buf_tbl(struct efx_nic *efx, efx_qword_t *value, <answer> inline 
unsigned int <token> <answer> index) 
efx_sram_writeq(efx, efx->membase + <token> <answer> efx->type->buf_tbl_base, 
value, <token> <answer> index); 
static bool <token> efx_oword_t *a, const efx_oword_t *b, <answer> efx_masked_compare_oword(const 
const <token> *mask) <answer> efx_oword_t 
return ((a->u64[0] <token> b->u64[0]) & mask->u64[0]) || <answer> ^ 
((a->u64[1] <token> b->u64[1]) & mask->u64[1]); <answer> ^ 
<token> efx_farch_test_registers(struct efx_nic *efx, <answer> int 
<token> struct efx_farch_register_test *regs, <answer> const 
<token> n_regs) <answer> size_t 
<token> address = 0; <answer> unsigned 
int <token> j; <answer> i, 
efx_oword_t mask, imask, <token> reg, buf; <answer> original, 
for (i = 0; i < n_regs; <token> { <answer> ++i) 
address <token> regs[i].address; <answer> = 
mask = imask = <token> <answer> regs[i].mask; 
<token> &original, address); <answer> efx_reado(efx, 
<token> void <answer> static 
efx_init_special_buffer(struct efx_nic <token> struct efx_special_buffer *buffer) <answer> *efx, 
<token> buf_desc; <answer> efx_qword_t 
unsigned <token> index; <answer> int 
dma_addr_t <token> <answer> dma_addr; 
int <token> <answer> i; 
<token> int efx_alloc_special_buffer(struct efx_nic *efx, <answer> static 
<token> efx_special_buffer *buffer, <answer> struct 
unsigned int <token> <answer> len) 
#ifdef <token> <answer> CONFIG_SFC_SIENA_SRIOV 
struct siena_nic_data *nic_data = <token> <answer> efx->nic_data; 
len = <token> EFX_BUF_SIZE); <answer> ALIGN(len, 
if (efx_siena_alloc_buffer(efx, &buffer->buf, <token> GFP_KERNEL)) <answer> len, 
return <token> <answer> -ENOMEM; 
<token> = len / EFX_BUF_SIZE; <answer> buffer->entries 
BUG_ON(buffer->buf.dma_addr & (EFX_BUF_SIZE - <token> <answer> 1)); 
<token> efx_farch_tx_write(struct efx_tx_queue *tx_queue) <answer> void 
struct <token> *buffer; <answer> efx_tx_buffer 
<token> *txd; <answer> efx_qword_t 
<token> write_ptr; <answer> unsigned 
unsigned old_write_count = <token> <answer> tx_queue->write_count; 
tx_queue->xmit_pending <token> false; <answer> = 
if (unlikely(tx_queue->write_count <token> tx_queue->insert_count)) <answer> == 
<token> { <answer> do 
write_ptr = tx_queue->write_count <token> tx_queue->ptr_mask; <answer> & 
buffer = <token> <answer> &tx_queue->buffer[write_ptr]; 
txd = efx_tx_desc(tx_queue, <token> <answer> write_ptr); 
EFX_WARN_ON_ONCE_PARANOID(buffer->flags & <token> <answer> EFX_TX_BUF_OPTION); 
void efx_farch_rx_write(struct <token> *rx_queue) <answer> efx_rx_queue 
struct efx_nic *efx = <token> <answer> rx_queue->efx; 
efx_dword_t <token> <answer> reg; 
unsigned <token> <answer> write_ptr; 
while (rx_queue->notified_count != rx_queue->added_count) <token> <answer> { 
rx_queue->notified_count & <token> <answer> rx_queue->ptr_mask); 
<token> = rx_queue->added_count & rx_queue->ptr_mask; <answer> write_ptr 
EFX_POPULATE_DWORD_1(reg, FRF_AZ_RX_DESC_WPTR_DWORD, <token> <answer> write_ptr); 
<token> &reg, FR_AZ_RX_DESC_UPD_DWORD_P0, <answer> efx_writed_page(efx, 
int efx_farch_rx_probe(struct efx_rx_queue <token> <answer> *rx_queue) 
struct efx_nic *efx <token> rx_queue->efx; <answer> = 
unsigned <token> <answer> entries; 
entries <token> rx_queue->ptr_mask + 1; <answer> = 
<token> efx_alloc_special_buffer(efx, &rx_queue->rxd, <answer> return 
entries <token> sizeof(efx_qword_t)); <answer> * 
void efx_farch_rx_init(struct <token> *rx_queue) <answer> efx_rx_queue 
<token> rx_desc_ptr; <answer> efx_oword_t 
struct efx_nic <token> = rx_queue->efx; <answer> *efx 
<token> jumbo_en; <answer> bool 
<token> bool efx_farch_flush_wake(struct efx_nic *efx) <answer> static 
netif_dbg(efx, <token> efx->net_dev, <answer> hw, 
"flush <token> on TXQ %d, so drain " <answer> complete 
"the queue\n", <token> <answer> tx_queue->queue); 
return <token> <answer> i; 
static <token> efx_farch_do_flush(struct efx_nic *efx) <answer> int 
if (efx_siena_sriov_enabled(efx)) <token> <answer> { 
<token> = efx_siena_mcdi_flush_rxqs(efx); <answer> rc 
<token> (!rc) <answer> if 
goto <token> <answer> wait; 
efx_for_each_channel(channel, <token> { <answer> efx) 
efx_for_each_channel_rx_queue(rx_queue, channel) <token> <answer> { 
if (atomic_read(&efx->rxq_flush_outstanding) <token> <answer> >= 
<token> (rx_queue->flush_pending) { <answer> if 
<token> = false; <answer> rx_queue->flush_pending 
timeout <token> wait_event_timeout(efx->flush_wq, <answer> = 
<token> (atomic_read(&efx->active_queues) && <answer> if 
<token> { <answer> !efx_check_tx_flush_complete(efx)) 
netif_err(efx, hw, efx->net_dev, "failed to flush %d <token> " <answer> queues 
"(rx %d+%d)\n", <token> <answer> atomic_read(&efx->active_queues), 
rc = <token> <answer> -ETIMEDOUT; 
<token> 0); <answer> atomic_set(&efx->active_queues, 
atomic_set(&efx->rxq_flush_pending, <token> <answer> 0); 
atomic_set(&efx->rxq_flush_outstanding, <token> <answer> 0); 
return <token> <answer> rc; 
int <token> efx_nic *efx) <answer> efx_farch_fini_dmaq(struct 
struct efx_channel <token> <answer> *channel; 
struct <token> *tx_queue; <answer> efx_tx_queue 
struct efx_rx_queue <token> <answer> *rx_queue; 
<token> rc = 0; <answer> int 
void efx_farch_finish_flr(struct efx_nic <token> <answer> *efx) 
<token> 0); <answer> atomic_set(&efx->rxq_flush_pending, 
<token> 0); <answer> atomic_set(&efx->rxq_flush_outstanding, 
<token> 0); <answer> atomic_set(&efx->active_queues, 
<token> efx_farch_ev_read_ack(struct efx_channel *channel) <answer> void 
efx_dword_t <token> <answer> reg; 
<token> efx_nic *efx = channel->efx; <answer> struct 
<token> FRF_AZ_EVQ_RPTR, <answer> EFX_POPULATE_DWORD_1(reg, 
<token> & channel->eventq_mask); <answer> channel->eventq_read_ptr 
<token> &reg, <answer> efx_writed(efx, 
efx->type->evq_rptr_tbl_base <token> <answer> + 
<token> * channel->channel); <answer> FR_BZ_EVQ_RPTR_STEP 
<token> void <answer> static 
efx_farch_handle_tx_event(struct efx_channel *channel, efx_qword_t <token> <answer> *event) 
unsigned int <token> <answer> tx_ev_desc_ptr; 
unsigned <token> tx_ev_q_label; <answer> int 
struct efx_tx_queue <token> <answer> *tx_queue; 
<token> efx_nic *efx = channel->efx; <answer> struct 
if <token> <answer> (unlikely(READ_ONCE(efx->reset_pending))) 
if (likely(EFX_QWORD_FIELD(*event, FSF_AZ_TX_EV_COMP))) <token> <answer> { 
if <token> <answer> (rx_ev_frm_trunc) 
else if <token> <answer> (rx_ev_tobe_disc) 
else if (!efx->loopback_selftest) <token> <answer> { 
<token> (rx_ev_ip_hdr_chksum_err) <answer> if 
else if <token> <answer> (rx_ev_tcp_udp_chksum_err) 
#ifdef <token> <answer> DEBUG 
if (rx_ev_other_err && net_ratelimit()) <token> <answer> { 
<token> rx_err, efx->net_dev, <answer> netif_dbg(efx, 
" <token> queue %d unexpected RX event " <answer> RX 
EFX_QWORD_FMT <token> <answer> "%s%s%s%s%s%s%s\n", 
efx_rx_queue_index(rx_queue), <token> <answer> EFX_QWORD_VAL(*event), 
rx_ev_buf_owner_id_err <token> " [OWNER_ID_ERR]" : "", <answer> ? 
<token> ? <answer> rx_ev_ip_hdr_chksum_err 
" [IP_HDR_CHKSUM_ERR]" : <token> <answer> "", 
<token> ? <answer> rx_ev_tcp_udp_chksum_err 
" [TCP_UDP_CHKSUM_ERR]" <token> "", <answer> : 
rx_ev_eth_crc_err ? " <token> : "", <answer> [ETH_CRC_ERR]" 
rx_ev_frm_trunc ? " <token> : "", <answer> [FRM_TRUNC]" 
rx_ev_tobe_disc <token> " [TOBE_DISC]" : "", <answer> ? 
rx_ev_pause_frm ? " <token> : ""); <answer> [PAUSE]" 
(void) <token> <answer> rx_ev_other_err; 
if (efx->net_dev->features <token> NETIF_F_RXALL) <answer> & 
<token> bool <answer> static 
<token> efx_rx_queue *rx_queue, unsigned index) <answer> efx_farch_handle_rx_bad_index(struct 
struct efx_channel <token> = efx_rx_queue_channel(rx_queue); <answer> *channel 
struct <token> *efx = rx_queue->efx; <answer> efx_nic 
<token> expected, dropped; <answer> unsigned 
if <token> && <answer> (rx_queue->scatter_n 
<token> == ((rx_queue->removed_count + rx_queue->scatter_n - 1) & <answer> index 
<token> { <answer> rx_queue->ptr_mask)) 
return <token> <answer> true; 
expected = rx_queue->removed_count <token> rx_queue->ptr_mask; <answer> & 
dropped <token> (index - expected) & rx_queue->ptr_mask; <answer> = 
netif_info(efx, rx_err, <token> <answer> efx->net_dev, 
<token> %d events (index=%d expected=%d)\n", <answer> "dropped 
dropped, <token> expected); <answer> index, 
<token> RESET_TYPE_DISABLE); <answer> efx_siena_schedule_reset(efx, 
return <token> <answer> false; 
<token> void <answer> static 
efx_farch_handle_rx_event(struct <token> *channel, const efx_qword_t *event) <answer> efx_channel 
<token> int rx_ev_desc_ptr, rx_ev_byte_cnt; <answer> unsigned 
<token> int rx_ev_hdr_type, rx_ev_mcast_pkt; <answer> unsigned 
<token> expected_ptr; <answer> unsigned 
bool rx_ev_pkt_ok, rx_ev_sop, <token> <answer> rx_ev_cont; 
<token> flags; <answer> u16 
struct efx_rx_queue <token> <answer> *rx_queue; 
struct <token> *efx = channel->efx; <answer> efx_nic 
<token> (unlikely(READ_ONCE(efx->reset_pending))) <answer> if 
rx_ev_cont <token> EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_JUMBO_CONT); <answer> = 
rx_ev_sop = EFX_QWORD_FIELD(*event, <token> <answer> FSF_AZ_RX_EV_SOP); 
WARN_ON(EFX_QWORD_FIELD(*event, <token> != <answer> FSF_AZ_RX_EV_Q_LABEL) 
rx_queue = <token> <answer> efx_channel_get_rx_queue(channel); 
rx_ev_desc_ptr = <token> FSF_AZ_RX_EV_DESC_PTR); <answer> EFX_QWORD_FIELD(*event, 
expected_ptr <token> ((rx_queue->removed_count + rx_queue->scatter_n) & <answer> = 
flags <token> 0; <answer> = 
<token> (rx_ev_hdr_type) { <answer> switch 
case <token> <answer> FSE_CZ_RX_EV_HDR_TYPE_IPV4V6_TCP: 
flags <token> EFX_RX_PKT_TCP; <answer> |= 
<token> FSE_CZ_RX_EV_HDR_TYPE_IPV4V6_UDP: <answer> case 
flags |= <token> <answer> EFX_RX_PKT_CSUMMED; 
<token> FSE_CZ_RX_EV_HDR_TYPE_IPV4V6_OTHER: <answer> case 
case <token> <answer> FSE_AZ_RX_EV_HDR_TYPE_OTHER: 
<token> else { <answer> } 
<token> = efx_farch_handle_rx_not_ok(rx_queue, event); <answer> flags 
<token> void <answer> static 
<token> efx_nic *efx, efx_qword_t *event) <answer> efx_farch_handle_tx_flush_done(struct 
struct efx_tx_queue <token> <answer> *tx_queue; 
<token> efx_channel *channel; <answer> struct 
int <token> <answer> qid; 
qid = <token> FSF_AZ_DRIVER_EV_SUBDATA); <answer> EFX_QWORD_FIELD(*event, 
if (qid < EFX_MAX_TXQ_PER_CHANNEL * (efx->n_tx_channels + efx->n_extra_tx_channels)) <token> <answer> { 
channel <token> efx_get_tx_channel(efx, qid / EFX_MAX_TXQ_PER_CHANNEL); <answer> = 
<token> = channel->tx_queue + (qid % EFX_MAX_TXQ_PER_CHANNEL); <answer> tx_queue 
<token> (atomic_cmpxchg(&tx_queue->flush_outstanding, 1, 0)) <answer> if 
static <token> <answer> void 
efx_farch_handle_rx_flush_done(struct <token> *efx, efx_qword_t *event) <answer> efx_nic 
struct <token> *channel; <answer> efx_channel 
struct <token> *rx_queue; <answer> efx_rx_queue 
int <token> <answer> qid; 
<token> failed; <answer> bool 
qid = <token> FSF_AZ_DRIVER_EV_RX_DESCQ_ID); <answer> EFX_QWORD_FIELD(*event, 
failed = <token> FSF_AZ_DRIVER_EV_RX_FLUSH_FAIL); <answer> EFX_QWORD_FIELD(*event, 
<token> (qid >= efx->n_channels) <answer> if 
channel = efx_get_channel(efx, <token> <answer> qid); 
<token> (!efx_channel_has_rx_queue(channel)) <answer> if 
rx_queue = <token> <answer> efx_channel_get_rx_queue(channel); 
<token> (failed) { <answer> if 
netif_info(efx, <token> efx->net_dev, <answer> hw, 
"RXQ %d flush <token> qid); <answer> retry\n", 
rx_queue->flush_pending = <token> <answer> true; 
<token> else { <answer> } 
<token> (efx_farch_flush_wake(efx)) <answer> if 
<token> void <answer> static 
efx_farch_handle_drain_event(struct efx_channel <token> <answer> *channel) 
struct efx_nic *efx <token> channel->efx; <answer> = 
<token> == 0); <answer> WARN_ON(atomic_read(&efx->active_queues) 
if <token> <answer> (efx_farch_flush_wake(efx)) 
static void efx_farch_handle_generated_event(struct <token> *channel, <answer> efx_channel 
<token> *event) <answer> efx_qword_t 
struct efx_nic *efx = <token> <answer> channel->efx; 
struct efx_rx_queue <token> = <answer> *rx_queue 
efx_channel_has_rx_queue(channel) <token> <answer> ? 
efx_channel_get_rx_queue(channel) <token> NULL; <answer> : 
<token> magic, code; <answer> unsigned 
magic <token> EFX_QWORD_FIELD(*event, FSF_AZ_DRV_GEN_EV_MAGIC); <answer> = 
code = <token> <answer> _EFX_CHANNEL_MAGIC_CODE(magic); 
<token> (magic == EFX_CHANNEL_MAGIC_TEST(channel)) { <answer> if 
<token> = raw_smp_processor_id(); <answer> channel->event_test_cpu 
} else if (rx_queue && <token> == EFX_CHANNEL_MAGIC_FILL(rx_queue)) { <answer> magic 
efx_siena_fast_push_rx_descriptors(rx_queue, <token> <answer> true); 
} else if (rx_queue && magic == EFX_CHANNEL_MAGIC_RX_DRAIN(rx_queue)) <token> <answer> { 
<token> else if (code == _EFX_CHANNEL_MAGIC_TX_DRAIN) { <answer> } 
} else <token> <answer> { 
netif_dbg(efx, hw, efx->net_dev, <token> %d received " <answer> "channel 
"generated <token> "EFX_QWORD_FMT"\n", <answer> event 
<token> EFX_QWORD_VAL(*event)); <answer> channel->channel, 
static <token> <answer> void 
efx_farch_handle_driver_event(struct efx_channel *channel, <token> *event) <answer> efx_qword_t 
struct <token> *efx = channel->efx; <answer> efx_nic 
unsigned int <token> <answer> ev_sub_code; 
<token> int ev_sub_data; <answer> unsigned 
<token> = EFX_QWORD_FIELD(*event, FSF_AZ_DRIVER_EV_SUBCODE); <answer> ev_sub_code 
ev_sub_data = <token> FSF_AZ_DRIVER_EV_SUBDATA); <answer> EFX_QWORD_FIELD(*event, 
<token> (ev_sub_code) { <answer> switch 
<token> FSE_AZ_TX_DESCQ_FLS_DONE_EV: <answer> case 
netif_vdbg(efx, hw, efx->net_dev, "channel %d TXQ <token> flushed\n", <answer> %d 
<token> ev_sub_data); <answer> channel->channel, 
<token> event); <answer> efx_farch_handle_tx_flush_done(efx, 
<token> CONFIG_SFC_SIENA_SRIOV <answer> #ifdef 
efx_siena_sriov_tx_flush_done(efx, <token> <answer> event); 
case <token> <answer> FSE_AZ_RX_DESCQ_FLS_DONE_EV: 
<token> hw, efx->net_dev, "channel %d RXQ %d flushed\n", <answer> netif_vdbg(efx, 
<token> ev_sub_data); <answer> channel->channel, 
efx_farch_handle_rx_flush_done(efx, <token> <answer> event); 
<token> CONFIG_SFC_SIENA_SRIOV <answer> #ifdef 
<token> event); <answer> efx_siena_sriov_rx_flush_done(efx, 
case <token> <answer> FSE_AZ_EVQ_INIT_DONE_EV: 
netif_dbg(efx, hw, <token> <answer> efx->net_dev, 
"channel %d <token> %d initialised\n", <answer> EVQ 
<token> ev_sub_data); <answer> channel->channel, 
case <token> <answer> FSE_AZ_SRM_UPD_DONE_EV: 
netif_vdbg(efx, <token> efx->net_dev, <answer> hw, 
"channel <token> SRAM update done\n", channel->channel); <answer> %d 
<token> FSE_AZ_WAKE_UP_EV: <answer> case 
netif_vdbg(efx, <token> efx->net_dev, <answer> hw, 
"channel <token> RXQ %d wakeup event\n", <answer> %d 
<token> ev_sub_data); <answer> channel->channel, 
<token> FSE_AZ_TIMER_EV: <answer> case 
netif_vdbg(efx, hw, <token> <answer> efx->net_dev, 
<token> %d RX queue %d timer expired\n", <answer> "channel 
channel->channel, <token> <answer> ev_sub_data); 
case <token> <answer> FSE_AA_RX_RECOVER_EV: 
netif_err(efx, rx_err, <token> <answer> efx->net_dev, 
"channel %d seen DRIVER RX_RESET <token> " <answer> event. 
<token> channel->channel); <answer> "Resetting.\n", 
efx_siena_schedule_reset(efx, <token> <answer> RESET_TYPE_DISABLE); 
case <token> <answer> FSE_BZ_RX_DSC_ERROR_EV: 
if (ev_sub_data < <token> { <answer> EFX_VI_BASE) 
<token> rx_err, efx->net_dev, <answer> netif_err(efx, 
<token> DMA Q %d reports descriptor fetch error." <answer> "RX 
" RX Q <token> is disabled.\n", ev_sub_data, <answer> %d 
efx_siena_schedule_reset(efx, <token> <answer> RESET_TYPE_DMA_ERROR); 
<token> CONFIG_SFC_SIENA_SRIOV <answer> #ifdef 
<token> ev_sub_data); <answer> efx_siena_sriov_desc_fetch_err(efx, 
case <token> <answer> FSE_BZ_TX_DSC_ERROR_EV: 
if (ev_sub_data < EFX_VI_BASE) <token> <answer> { 
netif_err(efx, <token> efx->net_dev, <answer> tx_err, 
"TX <token> Q %d reports descriptor fetch error." <answer> DMA 
" <token> Q %d is disabled.\n", ev_sub_data, <answer> TX 
<token> RESET_TYPE_DMA_ERROR); <answer> efx_siena_schedule_reset(efx, 
<token> CONFIG_SFC_SIENA_SRIOV <answer> #ifdef 
<token> ev_sub_data); <answer> efx_siena_sriov_desc_fetch_err(efx, 
netif_vdbg(efx, hw, <token> <answer> efx->net_dev, 
"channel <token> unknown driver event code %d " <answer> %d 
<token> %04x\n", channel->channel, ev_sub_code, <answer> "data 
int efx_farch_ev_process(struct efx_channel *channel, int <token> <answer> budget) 
struct efx_nic <token> = channel->efx; <answer> *efx 
unsigned int <token> <answer> read_ptr; 
efx_qword_t <token> *p_event; <answer> event, 
<token> ev_code; <answer> int 
int <token> = 0; <answer> spent 
if (budget <token> 0) <answer> <= 
return <token> <answer> spent; 
read_ptr = <token> <answer> channel->eventq_read_ptr; 
for <token> { <answer> (;;) 
p_event = <token> read_ptr); <answer> efx_event(channel, 
<token> = *p_event; <answer> event 
if <token> <answer> (!efx_event_present(&event)) 
int efx_farch_irq_test_generate(struct efx_nic <token> <answer> *efx) 
<token> true, true); <answer> efx_farch_interrupts(efx, 
<token> 0; <answer> return 
<token> efx_farch_fatal_interrupt(struct efx_nic *efx) <answer> irqreturn_t 
efx_oword_t <token> = efx->irq_status.addr; <answer> *int_ker 
efx_oword_t <token> <answer> fatal_intr; 
<token> error, mem_perr; <answer> int 
<token> &fatal_intr, FR_AZ_FATAL_INTR_KER); <answer> efx_reado(efx, 
error = EFX_OWORD_FIELD(fatal_intr, <token> <answer> FRF_AZ_FATAL_INTR); 
netif_err(efx, <token> efx->net_dev, "SYSTEM ERROR "EFX_OWORD_FMT" status " <answer> hw, 
EFX_OWORD_FMT ": <token> EFX_OWORD_VAL(*int_ker), <answer> %s\n", 
<token> ? "disabling bus mastering" : "no recognised error"); <answer> error 
irqreturn_t efx_farch_legacy_interrupt(int irq, void <token> <answer> *dev_id) 
struct efx_nic *efx <token> dev_id; <answer> = 
<token> soft_enabled = READ_ONCE(efx->irq_soft_enabled); <answer> bool 
<token> *int_ker = efx->irq_status.addr; <answer> efx_oword_t 
irqreturn_t <token> = IRQ_NONE; <answer> result 
<token> efx_channel *channel; <answer> struct 
efx_dword_t <token> <answer> reg; 
u32 <token> <answer> queues; 
int <token> <answer> syserr; 
if (EFX_DWORD_IS_ALL_ONES(reg) <token> efx_siena_try_recovery(efx) && <answer> && 
!efx->eeh_disabled_legacy_irq) <token> <answer> { 
efx->eeh_disabled_legacy_irq <token> true; <answer> = 
<token> (efx->irq_zero_count++ == 0) <answer> if 
<token> = IRQ_HANDLED; <answer> result 
irqreturn_t efx_farch_msi_interrupt(int irq, void <token> <answer> *dev_id) 
<token> efx_msi_context *context = dev_id; <answer> struct 
struct efx_nic *efx = <token> <answer> context->efx; 
efx_oword_t *int_ker = <token> <answer> efx->irq_status.addr; 
<token> syserr; <answer> int 
netif_vdbg(efx, <token> efx->net_dev, <answer> intr, 
"IRQ %d on CPU %d status <token> EFX_OWORD_FMT "\n", <answer> " 
<token> raw_smp_processor_id(), EFX_OWORD_VAL(*int_ker)); <answer> irq, 
if <token> <answer> (!likely(READ_ONCE(efx->irq_soft_enabled))) 
<token> IRQ_HANDLED; <answer> return 
void efx_farch_rx_push_indir_table(struct <token> *efx) <answer> efx_nic 
size_t <token> = 0; <answer> i 
<token> dword; <answer> efx_dword_t 
<token> != <answer> BUILD_BUG_ON(ARRAY_SIZE(efx->rss_context.rx_indir_table) 
for (i = <token> i < FR_BZ_RX_INDIRECTION_TBL_ROWS; i++) { <answer> 0; 
<token> FRF_BZ_IT_QUEUE, <answer> EFX_POPULATE_DWORD_1(dword, 
<token> &dword, <answer> efx_writed(efx, 
<token> + <answer> FR_BZ_RX_INDIRECTION_TBL 
FR_BZ_RX_INDIRECTION_TBL_STEP <token> i); <answer> * 
void <token> efx_nic *efx) <answer> efx_farch_rx_pull_indir_table(struct 
<token> i = 0; <answer> size_t 
<token> dword; <answer> efx_dword_t 
BUILD_BUG_ON(ARRAY_SIZE(efx->rss_context.rx_indir_table) <token> <answer> != 
<token> (i = 0; i < FR_BZ_RX_INDIRECTION_TBL_ROWS; i++) { <answer> for 
<token> &dword, <answer> efx_readd(efx, 
FR_BZ_RX_INDIRECTION_TBL <token> <answer> + 
FR_BZ_RX_INDIRECTION_TBL_STEP <token> i); <answer> * 
efx->rss_context.rx_indir_table[i] = EFX_DWORD_FIELD(dword, <token> <answer> FRF_BZ_IT_QUEUE); 
void efx_farch_dimension_resources(struct efx_nic *efx, unsigned <token> <answer> sram_lim_qw) 
unsigned <token> total_tx_channels; <answer> vi_count, 
<token> CONFIG_SFC_SIENA_SRIOV <answer> #ifdef 
struct siena_nic_data <token> <answer> *nic_data; 
<token> buftbl_min; <answer> unsigned 
total_tx_channels <token> efx->n_tx_channels + efx->n_extra_tx_channels; <answer> = 
vi_count = max(efx->n_channels, total_tx_channels * <token> <answer> EFX_MAX_TXQ_PER_CHANNEL); 
<token> CONFIG_SFC_SIENA_SRIOV <answer> #ifdef 
<token> = efx->nic_data; <answer> nic_data 
buftbl_min = <token> * EFX_MAX_DMAQ_SIZE + <answer> ((efx->n_rx_channels 
total_tx_channels * EFX_MAX_TXQ_PER_CHANNEL * EFX_MAX_DMAQ_SIZE <token> <answer> + 
efx->n_channels * <token> <answer> EFX_MAX_EVQ_SIZE) 
* sizeof(efx_qword_t) / <token> <answer> EFX_BUF_SIZE); 
if <token> { <answer> (efx->type->sriov_wanted) 
if <token> { <answer> (efx->type->sriov_wanted(efx)) 
unsigned vi_dc_entries, <token> <answer> buftbl_free; 
<token> entries_per_vf, vf_limit; <answer> unsigned 
nic_data->vf_buftbl_base = <token> <answer> buftbl_min; 
vi_dc_entries = RX_DC_ENTRIES <token> TX_DC_ENTRIES; <answer> + 
vi_count = <token> EFX_VI_BASE); <answer> max(vi_count, 
buftbl_free = (sram_lim_qw - buftbl_min <token> <answer> - 
<token> * vi_dc_entries); <answer> vi_count 
entries_per_vf = ((vi_dc_entries <token> <answer> + 
<token> * <answer> EFX_VF_BUFTBL_PER_VI) 
vf_limit <token> min(buftbl_free / entries_per_vf, <answer> = 
(1024U - <token> >> efx->vi_scale); <answer> EFX_VI_BASE) 
<token> (efx->vf_count > vf_limit) { <answer> if 
netif_err(efx, probe, <token> <answer> efx->net_dev, 
<token> VF count from from %d to %d\n", <answer> "Reducing 
efx->vf_count, <token> <answer> vf_limit); 
<token> = vf_limit; <answer> efx->vf_count 
<token> += efx->vf_count * efx_vf_size(efx); <answer> vi_count 
<token> = sram_lim_qw - vi_count * TX_DC_ENTRIES; <answer> efx->tx_dc_base 
efx->rx_dc_base = efx->tx_dc_base <token> vi_count * RX_DC_ENTRIES; <answer> - 
u32 efx_farch_fpga_ver(struct efx_nic <token> <answer> *efx) 
<token> altera_build; <answer> efx_oword_t 
<token> &altera_build, FR_AZ_ALTERA_BUILD); <answer> efx_reado(efx, 
return EFX_OWORD_FIELD(altera_build, <token> <answer> FRF_AZ_ALTERA_BUILD_VER); 
<token> efx_farch_init_common(struct efx_nic *efx) <answer> void 
<token> temp; <answer> efx_oword_t 
BUILD_BUG_ON(RX_DC_ENTRIES != (8 << <token> <answer> RX_DC_ENTRIES_ORDER)); 
EFX_POPULATE_OWORD_1(temp, FRF_AZ_RX_DC_SIZE, <token> <answer> RX_DC_ENTRIES_ORDER); 
efx_writeo(efx, <token> FR_AZ_RX_DC_CFG); <answer> &temp, 
EFX_POPULATE_OWORD_1(temp, FRF_AZ_RX_DC_PF_LWM, RX_DC_ENTRIES - <token> <answer> 8); 
efx_writeo(efx, &temp, <token> <answer> FR_AZ_RX_DC_PF_WM); 
FRF_AZ_ILL_ADR_INT_KER_EN, <token> <answer> 1, 
<token> 1, <answer> FRF_AZ_RBUF_OWN_INT_KER_EN, 
FRF_AZ_TBUF_OWN_INT_KER_EN, <token> <answer> 1); 
EFX_SET_OWORD_FIELD(temp, FRF_CZ_SRAM_PERR_INT_P_KER_EN, <token> <answer> 1); 
<token> &temp, FR_AZ_FATAL_INTR_KER); <answer> efx_writeo(efx, 
efx_reado(efx, &temp, <token> <answer> FR_AZ_TX_RESERVED); 
EFX_SET_OWORD_FIELD(temp, FRF_AZ_TX_RX_SPACER, <token> <answer> 0xfe); 
<token> FRF_AZ_TX_RX_SPACER_EN, 1); <answer> EFX_SET_OWORD_FIELD(temp, 
<token> FRF_AZ_TX_ONE_PKT_PER_Q, 1); <answer> EFX_SET_OWORD_FIELD(temp, 
<token> FRF_AZ_TX_PUSH_EN, 1); <answer> EFX_SET_OWORD_FIELD(temp, 
EFX_SET_OWORD_FIELD(temp, FRF_AZ_TX_DIS_NON_IP_EV, <token> <answer> 1); 
#define <token> 3 <answer> EFX_FARCH_FILTER_CTL_SRCH_FUDGE_WILD 
<token> EFX_FARCH_FILTER_CTL_SRCH_FUDGE_FULL 1 <answer> #define 
#define EFX_FARCH_FILTER_CTL_SRCH_MAX <token> <answer> 200 
#define EFX_FARCH_FILTER_CTL_SRCH_HINT_MAX <token> <answer> 5 
enum <token> { <answer> efx_farch_filter_type 
<token> = 0, <answer> EFX_FARCH_FILTER_TCP_FULL 
<token> = 4, <answer> EFX_FARCH_FILTER_MAC_FULL 
<token> = 8, <answer> EFX_FARCH_FILTER_UC_DEF 
<token> u16 efx_farch_filter_hash(u32 key) <answer> static 
<token> tmp; <answer> u16 
<token> u16 efx_farch_filter_increment(u32 key) <answer> static 
return key * 2 <token> 1; <answer> - 
<token> enum efx_farch_filter_table_id <answer> static 
<token> struct efx_farch_filter_spec *spec) <answer> efx_farch_filter_spec_table_id(const 
BUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_IP <token> <answer> != 
(EFX_FARCH_FILTER_TCP_FULL >> <token> <answer> 2)); 
BUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_IP <token> <answer> != 
<token> >> 2)); <answer> (EFX_FARCH_FILTER_TCP_WILD 
BUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_IP <token> <answer> != 
<token> >> 2)); <answer> (EFX_FARCH_FILTER_UDP_FULL 
<token> != <answer> BUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_IP 
(EFX_FARCH_FILTER_UDP_WILD >> <token> <answer> 2)); 
<token> != <answer> BUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_MAC 
<token> >> 2)); <answer> (EFX_FARCH_FILTER_MAC_FULL 
<token> != <answer> BUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_MAC 
(EFX_FARCH_FILTER_MAC_WILD >> <token> <answer> 2)); 
<token> != <answer> BUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_TX_MAC 
EFX_FARCH_FILTER_TABLE_RX_MAC + <token> <answer> 2); 
return (spec->type <token> 2) + ((spec->flags & EFX_FILTER_FLAG_TX) ? 2 : 0); <answer> >> 
<token> void efx_farch_filter_push_rx_config(struct efx_nic *efx) <answer> static 
struct <token> *state = efx->filter_state; <answer> efx_farch_filter_state 
<token> efx_farch_filter_table *table; <answer> struct 
efx_oword_t <token> <answer> filter_ctl; 
efx_reado(efx, &filter_ctl, <token> <answer> FR_BZ_RX_FILTER_CTL); 
table = <token> <answer> &state->table[EFX_FARCH_FILTER_TABLE_RX_IP]; 
EFX_SET_OWORD_FIELD(filter_ctl, <token> <answer> FRF_BZ_TCP_FULL_SRCH_LIMIT, 
<token> + <answer> table->search_limit[EFX_FARCH_FILTER_TCP_FULL] 
EFX_SET_OWORD_FIELD(filter_ctl, <token> <answer> FRF_BZ_TCP_WILD_SRCH_LIMIT, 
table->search_limit[EFX_FARCH_FILTER_TCP_WILD] <token> <answer> + 
<token> FRF_BZ_UDP_FULL_SRCH_LIMIT, <answer> EFX_SET_OWORD_FIELD(filter_ctl, 
<token> + <answer> table->search_limit[EFX_FARCH_FILTER_UDP_FULL] 
<token> FRF_BZ_UDP_WILD_SRCH_LIMIT, <answer> EFX_SET_OWORD_FIELD(filter_ctl, 
table->search_limit[EFX_FARCH_FILTER_UDP_WILD] <token> <answer> + 
table <token> &state->table[EFX_FARCH_FILTER_TABLE_RX_MAC]; <answer> = 
if <token> { <answer> (table->size) 
<token> FRF_CZ_ETHERNET_FULL_SEARCH_LIMIT, <answer> filter_ctl, 
table->search_limit[EFX_FARCH_FILTER_MAC_FULL] <token> <answer> + 
filter_ctl, <token> <answer> FRF_CZ_ETHERNET_WILDCARD_SEARCH_LIMIT, 
<token> + <answer> table->search_limit[EFX_FARCH_FILTER_MAC_WILD] 
table <token> &state->table[EFX_FARCH_FILTER_TABLE_RX_DEF]; <answer> = 
if <token> { <answer> (table->size) 
filter_ctl, <token> <answer> FRF_CZ_UNICAST_NOMATCH_Q_ID, 
filter_ctl, <token> <answer> FRF_CZ_UNICAST_NOMATCH_RSS_ENABLED, 
!!(table->spec[EFX_FARCH_FILTER_INDEX_UC_DEF].flags <token> <answer> & 
filter_ctl, <token> <answer> FRF_CZ_MULTICAST_NOMATCH_Q_ID, 
filter_ctl, <token> <answer> FRF_CZ_MULTICAST_NOMATCH_RSS_ENABLED, 
<token> & <answer> !!(table->spec[EFX_FARCH_FILTER_INDEX_MC_DEF].flags 
filter_ctl, <token> <answer> FRF_BZ_SCATTER_ENBL_NO_MATCH_Q, 
!!(table->spec[EFX_FARCH_FILTER_INDEX_UC_DEF].flags <token> <answer> & 
table->spec[EFX_FARCH_FILTER_INDEX_MC_DEF].flags <token> <answer> & 
<token> else { <answer> } 
filter_ctl, <token> <answer> FRF_BZ_SCATTER_ENBL_NO_MATCH_Q, 
efx_writeo(efx, <token> FR_BZ_RX_FILTER_CTL); <answer> &filter_ctl, 
static void efx_farch_filter_push_tx_limits(struct <token> *efx) <answer> efx_nic 
struct efx_farch_filter_state *state = <token> <answer> efx->filter_state; 
struct <token> *table; <answer> efx_farch_filter_table 
<token> tx_cfg; <answer> efx_oword_t 
efx_reado(efx, <token> FR_AZ_TX_CFG); <answer> &tx_cfg, 
table = <token> <answer> &state->table[EFX_FARCH_FILTER_TABLE_TX_MAC]; 
if <token> { <answer> (table->size) 
tx_cfg, <token> <answer> FRF_CZ_TX_ETH_FILTER_FULL_SEARCH_RANGE, 
table->search_limit[EFX_FARCH_FILTER_MAC_FULL] <token> <answer> + 
tx_cfg, <token> <answer> FRF_CZ_TX_ETH_FILTER_WILD_SEARCH_RANGE, 
<token> + <answer> table->search_limit[EFX_FARCH_FILTER_MAC_WILD] 
<token> &tx_cfg, FR_AZ_TX_CFG); <answer> efx_writeo(efx, 
static <token> <answer> int 
efx_farch_filter_from_gen_spec(struct <token> *spec, <answer> efx_farch_filter_spec 
const <token> efx_filter_spec *gen_spec) <answer> struct 
bool is_full <token> false; <answer> = 
if ((gen_spec->flags & <token> && gen_spec->rss_context) <answer> EFX_FILTER_FLAG_RX_RSS) 
<token> -EINVAL; <answer> return 
spec->priority = <token> <answer> gen_spec->priority; 
spec->flags <token> gen_spec->flags; <answer> = 
<token> = gen_spec->dmaq_id; <answer> spec->dmaq_id 
switch <token> { <answer> (gen_spec->match_flags) 
case <token> | EFX_FILTER_MATCH_IP_PROTO | <answer> (EFX_FILTER_MATCH_ETHER_TYPE 
<token> | EFX_FILTER_MATCH_LOC_PORT | <answer> EFX_FILTER_MATCH_LOC_HOST 
EFX_FILTER_MATCH_REM_HOST <token> EFX_FILTER_MATCH_REM_PORT): <answer> | 
is_full = <token> <answer> true; 
case <token> | EFX_FILTER_MATCH_IP_PROTO | <answer> (EFX_FILTER_MATCH_ETHER_TYPE 
EFX_FILTER_MATCH_LOC_HOST <token> EFX_FILTER_MATCH_LOC_PORT): { <answer> | 
__be32 rhost, host1, <token> <answer> host2; 
__be16 <token> port1, port2; <answer> rport, 
<token> & EFX_FILTER_FLAG_RX)); <answer> EFX_WARN_ON_PARANOID(!(gen_spec->flags 
if (gen_spec->ether_type <token> htons(ETH_P_IP)) <answer> != 
<token> -EPROTONOSUPPORT; <answer> return 
if <token> == 0 || <answer> (gen_spec->loc_port 
(is_full && gen_spec->rem_port == <token> <answer> 0)) 
return <token> <answer> -EADDRNOTAVAIL; 
<token> (gen_spec->ip_proto) { <answer> switch 
case <token> <answer> IPPROTO_TCP: 
spec->type = (is_full ? EFX_FARCH_FILTER_TCP_FULL <token> <answer> : 
case <token> <answer> IPPROTO_UDP: 
spec->type = (is_full ? <token> : <answer> EFX_FARCH_FILTER_UDP_FULL 
<token> -EPROTONOSUPPORT; <answer> return 
<token> = is_full ? gen_spec->rem_host[0] : 0; <answer> rhost 
<token> = is_full ? gen_spec->rem_port : 0; <answer> rport 
host1 = <token> <answer> rhost; 
host2 = <token> <answer> gen_spec->loc_host[0]; 
if (!is_full && gen_spec->ip_proto <token> IPPROTO_UDP) { <answer> == 
<token> = gen_spec->loc_port; <answer> port1 
port2 <token> rport; <answer> = 
} else <token> <answer> { 
port1 = <token> <answer> rport; 
<token> = gen_spec->loc_port; <answer> port2 
spec->data[0] = ntohl(host1) << 16 | <token> <answer> ntohs(port1); 
spec->data[1] = ntohs(port2) << 16 | ntohl(host1) <token> 16; <answer> >> 
<token> = ntohl(host2); <answer> spec->data[2] 
case EFX_FILTER_MATCH_LOC_MAC | <token> <answer> EFX_FILTER_MATCH_OUTER_VID: 
is_full = <token> <answer> true; 
case <token> <answer> EFX_FILTER_MATCH_LOC_MAC: 
spec->type = <token> ? EFX_FARCH_FILTER_MAC_FULL : <answer> (is_full 
spec->data[0] = is_full ? ntohs(gen_spec->outer_vid) : <token> <answer> 0; 
spec->data[1] <token> (gen_spec->loc_mac[2] << 24 | <answer> = 
gen_spec->loc_mac[3] <token> 16 | <answer> << 
gen_spec->loc_mac[4] <token> 8 | <answer> << 
<token> = (gen_spec->loc_mac[0] << 8 | <answer> spec->data[2] 
case <token> <answer> EFX_FILTER_MATCH_LOC_MAC_IG: 
spec->type <token> (is_multicast_ether_addr(gen_spec->loc_mac) ? <answer> = 
EFX_FARCH_FILTER_MC_DEF <token> <answer> : 
<token> 0, sizeof(*gen_spec)); <answer> memset(gen_spec, 
<token> = spec->priority; <answer> gen_spec->priority 
gen_spec->flags = <token> <answer> spec->flags; 
gen_spec->dmaq_id <token> spec->dmaq_id; <answer> = 
switch (spec->type) <token> <answer> { 
case <token> <answer> EFX_FARCH_FILTER_TCP_FULL: 
case <token> <answer> EFX_FARCH_FILTER_UDP_FULL: 
is_full <token> true; <answer> = 
<token> EFX_FARCH_FILTER_TCP_WILD: <answer> case 
case <token> { <answer> EFX_FARCH_FILTER_UDP_WILD: 
<token> host1, host2; <answer> __be32 
<token> port1, port2; <answer> __be16 
gen_spec->match_flags <token> <answer> = 
<token> | <answer> EFX_FILTER_MATCH_ETHER_TYPE 
<token> | <answer> EFX_FILTER_MATCH_IP_PROTO 
EFX_FILTER_MATCH_LOC_HOST | <token> <answer> EFX_FILTER_MATCH_LOC_PORT; 
if <token> <answer> (is_full) 
gen_spec->match_flags |= <token> | <answer> (EFX_FILTER_MATCH_REM_HOST 
<token> = htons(ETH_P_IP); <answer> gen_spec->ether_type 
gen_spec->ip_proto <token> <answer> = 
<token> == EFX_FARCH_FILTER_TCP_FULL || <answer> (spec->type 
spec->type == EFX_FARCH_FILTER_TCP_WILD) <token> <answer> ? 
IPPROTO_TCP <token> IPPROTO_UDP; <answer> : 
host1 = <token> >> 16 | spec->data[1] << 16); <answer> htonl(spec->data[0] 
port1 = <token> <answer> htons(spec->data[0]); 
host2 <token> htonl(spec->data[2]); <answer> = 
port2 = htons(spec->data[1] >> <token> <answer> 16); 
if (spec->flags & EFX_FILTER_FLAG_TX) <token> <answer> { 
<token> = host1; <answer> gen_spec->loc_host[0] 
gen_spec->rem_host[0] = <token> <answer> host2; 
} <token> { <answer> else 
gen_spec->loc_host[0] = <token> <answer> host2; 
gen_spec->rem_host[0] <token> host1; <answer> = 
if (!!(gen_spec->flags <token> EFX_FILTER_FLAG_TX) ^ <answer> & 
(!is_full && gen_spec->ip_proto <token> IPPROTO_UDP)) { <answer> == 
gen_spec->loc_port <token> port1; <answer> = 
gen_spec->rem_port <token> port2; <answer> = 
<token> else { <answer> } 
<token> = port2; <answer> gen_spec->loc_port 
gen_spec->rem_port = <token> <answer> port1; 
<token> EFX_FARCH_FILTER_MAC_FULL: <answer> case 
is_full = <token> <answer> true; 
<token> EFX_FARCH_FILTER_MAC_WILD: <answer> case 
gen_spec->match_flags = <token> <answer> EFX_FILTER_MATCH_LOC_MAC; 
<token> (is_full) <answer> if 
gen_spec->match_flags |= <token> <answer> EFX_FILTER_MATCH_OUTER_VID; 
gen_spec->loc_mac[0] = <token> >> 8; <answer> spec->data[2] 
<token> = spec->data[2]; <answer> gen_spec->loc_mac[1] 
<token> = spec->data[1] >> 24; <answer> gen_spec->loc_mac[2] 
<token> = spec->data[1] >> 16; <answer> gen_spec->loc_mac[3] 
gen_spec->loc_mac[4] <token> spec->data[1] >> 8; <answer> = 
gen_spec->loc_mac[5] <token> spec->data[1]; <answer> = 
gen_spec->outer_vid <token> htons(spec->data[0]); <answer> = 
case <token> <answer> EFX_FARCH_FILTER_UC_DEF: 
case <token> <answer> EFX_FARCH_FILTER_MC_DEF: 
gen_spec->match_flags <token> EFX_FILTER_MATCH_LOC_MAC_IG; <answer> = 
<token> = spec->type == EFX_FARCH_FILTER_MC_DEF; <answer> gen_spec->loc_mac[0] 
static <token> <answer> void 
efx_farch_filter_init_rx_auto(struct efx_nic <token> <answer> *efx, 
struct efx_farch_filter_spec <token> <answer> *spec) 
<token> = EFX_FILTER_PRI_AUTO; <answer> spec->priority 
spec->flags <token> (EFX_FILTER_FLAG_RX | <answer> = 
(efx_rss_enabled(efx) ? EFX_FILTER_FLAG_RX_RSS : <token> | <answer> 0) 
<token> ? EFX_FILTER_FLAG_RX_SCATTER : 0)); <answer> (efx->rx_scatter 
spec->dmaq_id <token> 0; <answer> = 
#define EFX_FARCH_FILTER_MATCH_PRI_COUNT <token> <answer> 5 
static const u8 efx_farch_filter_type_match_pri[EFX_FARCH_FILTER_TYPE_COUNT] <token> { <answer> = 
[EFX_FARCH_FILTER_TCP_FULL] = <token> <answer> 0, 
[EFX_FARCH_FILTER_UDP_FULL] <token> 0, <answer> = 
[EFX_FARCH_FILTER_TCP_WILD] <token> 1, <answer> = 
<token> = 1, <answer> [EFX_FARCH_FILTER_UDP_WILD] 
<token> = 2, <answer> [EFX_FARCH_FILTER_MAC_FULL] 
[EFX_FARCH_FILTER_MAC_WILD] = <token> <answer> 3, 
[EFX_FARCH_FILTER_UC_DEF] <token> 4, <answer> = 
[EFX_FARCH_FILTER_MC_DEF] <token> 4, <answer> = 
<token> const enum efx_farch_filter_table_id efx_farch_filter_range_table[] = { <answer> static 
<token> key = efx_farch_filter_build(&filter, &spec); <answer> u32 
unsigned <token> hash = efx_farch_filter_hash(key); <answer> int 
<token> int incr = efx_farch_filter_increment(key); <answer> unsigned 
<token> int max_rep_depth = table->search_limit[spec.type]; <answer> unsigned 
unsigned int <token> = <answer> max_ins_depth 
spec.priority <token> EFX_FILTER_PRI_HINT ? <answer> <= 
EFX_FARCH_FILTER_CTL_SRCH_HINT_MAX <token> <answer> : 
unsigned int i = hash & (table->size <token> 1); <answer> - 
<token> = -1; <answer> ins_index 
depth = <token> <answer> 1; 
<token> (;;) { <answer> for 
if <token> table->used_bitmap)) { <answer> (!test_bit(i, 
if (ins_index <token> 0) <answer> < 
ins_index <token> i; <answer> = 
<token> else if (efx_farch_filter_equal(&spec, <answer> } 
<token> { <answer> &table->spec[i])) 
if (rep_index <token> 0) { <answer> >= 
struct <token> *saved_spec = <answer> efx_farch_filter_spec 
if (spec.priority == saved_spec->priority && !replace_equal) <token> <answer> { 
rc <token> -EEXIST; <answer> = 
goto <token> <answer> out_unlock; 
if <token> < saved_spec->priority) { <answer> (spec.priority 
rc = <token> <answer> -EPERM; 
<token> out_unlock; <answer> goto 
if <token> == EFX_FILTER_PRI_AUTO || <answer> (saved_spec->priority 
saved_spec->flags & <token> <answer> EFX_FILTER_FLAG_RX_OVER_AUTO) 
spec.flags |= <token> <answer> EFX_FILTER_FLAG_RX_OVER_AUTO; 
if (ins_index != rep_index <token> rep_index >= 0) <answer> && 
<token> table, <answer> efx_farch_filter_table_clear_entry(efx, 
<token> hw, efx->net_dev, <answer> netif_vdbg(efx, 
"%s: filter type %d <token> %d rxq %u set", <answer> index 
__func__, spec.type, <token> spec.dmaq_id); <answer> ins_index, 
<token> = efx_farch_filter_make_id(&spec, ins_index); <answer> rc 
return <token> <answer> rc; 
<token> void <answer> static 
efx_farch_filter_table_clear_entry(struct <token> *efx, <answer> efx_nic 
struct <token> *table, <answer> efx_farch_filter_table 
<token> int filter_idx) <answer> unsigned 
static <token> filter; <answer> efx_oword_t 
<token> table->used_bitmap)); <answer> EFX_WARN_ON_PARANOID(!test_bit(filter_idx, 
if (unlikely(table->used == <token> { <answer> 0)) 
memset(table->search_limit, 0, <token> <answer> sizeof(table->search_limit)); 
if <token> == EFX_FARCH_FILTER_TABLE_TX_MAC) <answer> (table->id 
static int <token> efx_nic *efx, <answer> efx_farch_filter_remove(struct 
<token> efx_farch_filter_table *table, <answer> struct 
unsigned int <token> <answer> filter_idx, 
<token> efx_filter_priority priority) <answer> enum 
struct efx_farch_filter_spec <token> = &table->spec[filter_idx]; <answer> *spec 
if (!test_bit(filter_idx, table->used_bitmap) <token> <answer> || 
spec->priority != <token> <answer> priority) 
return <token> <answer> -ENOENT; 
<token> (spec->flags & EFX_FILTER_FLAG_RX_OVER_AUTO) { <answer> if 
<token> spec); <answer> efx_farch_filter_init_rx_auto(efx, 
<token> else { <answer> } 
efx_farch_filter_table_clear_entry(efx, table, <token> <answer> filter_idx); 
<token> 0; <answer> return 
int efx_farch_filter_remove_safe(struct <token> *efx, <answer> efx_nic 
enum <token> priority, <answer> efx_filter_priority 
<token> filter_id) <answer> u32 
struct efx_farch_filter_state *state <token> efx->filter_state; <answer> = 
<token> efx_farch_filter_table_id table_id; <answer> enum 
struct efx_farch_filter_table <token> <answer> *table; 
<token> int filter_idx; <answer> unsigned 
<token> rc; <answer> int 
table_id <token> efx_farch_filter_id_table_id(filter_id); <answer> = 
if <token> int)table_id >= EFX_FARCH_FILTER_TABLE_COUNT) <answer> ((unsigned 
<token> -ENOENT; <answer> return 
table = <token> <answer> &state->table[table_id]; 
filter_idx = <token> <answer> efx_farch_filter_id_index(filter_id); 
if (filter_idx >= <token> <answer> table->size) 
<token> -ENOENT; <answer> return 
rc <token> efx_farch_filter_remove(efx, table, filter_idx, priority); <answer> = 
<token> rc; <answer> return 
int efx_farch_filter_get_safe(struct efx_nic <token> <answer> *efx, 
<token> efx_filter_priority priority, <answer> enum 
u32 <token> struct efx_filter_spec *spec_buf) <answer> filter_id, 
struct <token> *state = efx->filter_state; <answer> efx_farch_filter_state 
enum <token> table_id; <answer> efx_farch_filter_table_id 
struct <token> *table; <answer> efx_farch_filter_table 
<token> efx_farch_filter_spec *spec; <answer> struct 
unsigned int <token> <answer> filter_idx; 
<token> rc = -ENOENT; <answer> int 
<token> = efx_farch_filter_id_table_id(filter_id); <answer> table_id 
if ((unsigned int)table_id <token> EFX_FARCH_FILTER_TABLE_COUNT) <answer> >= 
<token> out_unlock; <answer> goto 
table <token> &state->table[table_id]; <answer> = 
filter_idx = <token> <answer> efx_farch_filter_id_index(filter_id); 
if (filter_idx >= <token> <answer> table->size) 
goto <token> <answer> out_unlock; 
<token> = &table->spec[filter_idx]; <answer> spec 
if (test_bit(filter_idx, <token> && <answer> table->used_bitmap) 
spec->priority == <token> { <answer> priority) 
efx_farch_filter_to_gen_spec(spec_buf, <token> <answer> spec); 
rc <token> 0; <answer> = 
return <token> <answer> rc; 
static <token> <answer> void 
efx_farch_filter_table_clear(struct <token> *efx, <answer> efx_nic 
<token> efx_farch_filter_table_id table_id, <answer> enum 
<token> efx_filter_priority priority) <answer> enum 
struct efx_farch_filter_state *state <token> efx->filter_state; <answer> = 
struct efx_farch_filter_table *table <token> &state->table[table_id]; <answer> = 
unsigned <token> filter_idx; <answer> int 
for (filter_idx = 0; filter_idx <token> table->size; ++filter_idx) { <answer> < 
<token> (table->spec[filter_idx].priority != EFX_FILTER_PRI_AUTO) <answer> if 
<token> table, <answer> efx_farch_filter_remove(efx, 
<token> priority); <answer> filter_idx, 
int efx_farch_filter_clear_rx(struct <token> *efx, <answer> efx_nic 
enum efx_filter_priority <token> <answer> priority) 
<token> EFX_FARCH_FILTER_TABLE_RX_IP, <answer> efx_farch_filter_table_clear(efx, 
efx_farch_filter_table_clear(efx, <token> <answer> EFX_FARCH_FILTER_TABLE_RX_MAC, 
<token> EFX_FARCH_FILTER_TABLE_RX_DEF, <answer> efx_farch_filter_table_clear(efx, 
return <token> <answer> 0; 
u32 <token> efx_nic *efx, <answer> efx_farch_filter_count_rx_used(struct 
enum <token> priority) <answer> efx_filter_priority 
struct efx_farch_filter_state <token> = efx->filter_state; <answer> *state 
<token> efx_farch_filter_table_id table_id; <answer> enum 
struct <token> *table; <answer> efx_farch_filter_table 
<token> int filter_idx; <answer> unsigned 
u32 count <token> 0; <answer> = 
for (table_id = <token> <answer> EFX_FARCH_FILTER_TABLE_RX_IP; 
<token> <= EFX_FARCH_FILTER_TABLE_RX_DEF; <answer> table_id 
table_id++) <token> <answer> { 
<token> = &state->table[table_id]; <answer> table 
for (filter_idx = <token> filter_idx < table->size; filter_idx++) { <answer> 0; 
if (test_bit(filter_idx, table->used_bitmap) <token> <answer> && 
<token> == priority) <answer> table->spec[filter_idx].priority 
return <token> <answer> count; 
s32 <token> efx_nic *efx, <answer> efx_farch_filter_get_rx_ids(struct 
<token> efx_filter_priority priority, <answer> enum 
u32 <token> u32 size) <answer> *buf, 
<token> efx_farch_filter_state *state = efx->filter_state; <answer> struct 
enum <token> table_id; <answer> efx_farch_filter_table_id 
struct efx_farch_filter_table <token> <answer> *table; 
unsigned <token> filter_idx; <answer> int 
<token> count = 0; <answer> s32 
for (table_id <token> EFX_FARCH_FILTER_TABLE_RX_IP; <answer> = 
table_id <token> EFX_FARCH_FILTER_TABLE_RX_DEF; <answer> <= 
table_id++) <token> <answer> { 
table = <token> <answer> &state->table[table_id]; 
for (filter_idx = 0; filter_idx < table->size; filter_idx++) <token> <answer> { 
<token> (test_bit(filter_idx, table->used_bitmap) && <answer> if 
table->spec[filter_idx].priority == <token> { <answer> priority) 
if (count == size) <token> <answer> { 
count = <token> <answer> -EMSGSIZE; 
goto <token> <answer> out; 
buf[count++] = <token> <answer> efx_farch_filter_make_id( 
<token> filter_idx); <answer> &table->spec[filter_idx], 
<token> count; <answer> return 
<token> = 0; <answer> arfs_id 
<token> else { <answer> } 
rule <token> efx_siena_rps_hash_find(efx, &spec); <answer> = 
<token> (!rule) { <answer> if 
__set_bit_le(0xff, <token> <answer> mc_hash); 
<token> <dt-bindings/sound/qcom,q6afe.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/uaccess.h> <answer> #include 
#include <token> <answer> <linux/wait.h> 
#include <token> <answer> <linux/jiffies.h> 
#include <token> <answer> <linux/sched.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/kref.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_platform.h> 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/soc/qcom/apr.h> <answer> #include 
<token> <sound/soc.h> <answer> #include 
<token> <sound/soc-dai.h> <answer> #include 
<token> <sound/pcm.h> <answer> #include 
#include <token> <answer> <sound/pcm_params.h> 
<token> "q6dsp-errno.h" <answer> #include 
#include <token> <answer> "q6core.h" 
<token> "q6afe.h" <answer> #include 
u16 <token> <answer> slimbus_dev_id; 
u16 <token> <answer> bit_width; 
u16 <token> <answer> data_format; 
u16 <token> <answer> num_channels; 
<token> shared_ch_mapping[AFE_PORT_MAX_AUDIO_CHAN_CNT]; <answer> u8 
u32 <token> <answer> sample_rate; 
} <token> <answer> __packed; 
<token> afe_clk_cfg { <answer> struct 
u32 <token> <answer> i2s_cfg_minor_version; 
<token> clk_val1; <answer> u32 
u32 <token> <answer> clk_val2; 
<token> clk_src; <answer> u16 
<token> clk_root; <answer> u16 
u16 <token> <answer> clk_set_mode; 
<token> reserved; <answer> u16 
} <token> <answer> __packed; 
struct afe_digital_clk_cfg <token> <answer> { 
u32 <token> <answer> i2s_cfg_minor_version; 
<token> clk_val; <answer> u32 
u16 <token> <answer> clk_root; 
<token> reserved; <answer> u16 
<token> __packed; <answer> } 
<token> afe_param_id_i2s_cfg { <answer> struct 
u32 <token> <answer> i2s_cfg_minor_version; 
<token> bit_width; <answer> u16 
u16 <token> <answer> channel_mode; 
<token> mono_stereo; <answer> u16 
u16 <token> <answer> ws_src; 
u32 <token> <answer> sample_rate; 
u16 <token> <answer> data_format; 
u16 <token> <answer> reserved; 
<token> __packed; <answer> } 
struct <token> { <answer> afe_param_id_tdm_cfg 
<token> tdm_cfg_minor_version; <answer> u32 
u32 <token> <answer> num_channels; 
<token> sample_rate; <answer> u32 
<token> bit_width; <answer> u32 
<token> data_format; <answer> u16 
<token> sync_mode; <answer> u16 
u16 <token> <answer> sync_src; 
u16 <token> <answer> nslots_per_frame; 
u16 <token> <answer> ctrl_data_out_enable; 
<token> ctrl_invert_sync_pulse; <answer> u16 
<token> ctrl_sync_data_delay; <answer> u16 
<token> slot_width; <answer> u16 
<token> slot_mask; <answer> u32 
<token> __packed; <answer> } 
struct afe_param_id_cdc_dma_cfg <token> <answer> { 
<token> cdc_dma_cfg_minor_version; <answer> u32 
<token> sample_rate; <answer> u32 
u16 <token> <answer> bit_width; 
u16 <token> <answer> data_format; 
<token> num_channels; <answer> u16 
u16 <token> <answer> active_channels_mask; 
} <token> <answer> __packed; 
union afe_port_config <token> <answer> { 
struct <token> hdmi_multi_ch; <answer> afe_param_id_hdmi_multi_chan_audio_cfg 
struct afe_param_id_slimbus_cfg <token> <answer> slim_cfg; 
struct afe_param_id_i2s_cfg <token> <answer> i2s_cfg; 
struct afe_param_id_tdm_cfg <token> <answer> tdm_cfg; 
struct afe_param_id_cdc_dma_cfg <token> <answer> dma_cfg; 
<token> __packed; <answer> } 
struct afe_clk_set <token> <answer> { 
<token> clk_set_minor_version; <answer> uint32_t 
uint32_t <token> <answer> clk_id; 
uint32_t <token> <answer> clk_freq_in_hz; 
uint16_t <token> <answer> clk_attri; 
uint16_t <token> <answer> clk_root; 
uint32_t <token> <answer> enable; 
struct <token> { <answer> afe_param_id_slot_mapping_cfg 
u32 <token> <answer> minor_version; 
<token> num_channels; <answer> u16 
u16 <token> <answer> bitwidth; 
u32 <token> <answer> data_align_type; 
<token> ch_mapping[AFE_PORT_MAX_AUDIO_CHAN_CNT]; <answer> u16 
} <token> <answer> __packed; 
struct q6afe_port <token> <answer> { 
wait_queue_head_t <token> <answer> wait; 
union afe_port_config <token> <answer> port_cfg; 
<token> afe_param_id_slot_mapping_cfg *scfg; <answer> struct 
<token> aprv2_ibasic_rsp_result_t result; <answer> struct 
int <token> <answer> token; 
int <token> <answer> id; 
<token> cfg_type; <answer> int 
struct <token> *afe; <answer> q6afe 
struct kref <token> <answer> refcount; 
<token> list_head node; <answer> struct 
struct <token> { <answer> afe_cmd_remote_lpass_core_hw_vote_request 
uint32_t <token> <answer> hw_block_id; 
char <token> <answer> client_name[8]; 
<token> __packed; <answer> } 
struct <token> { <answer> afe_cmd_remote_lpass_core_hw_devote_request 
uint32_t <token> <answer> hw_block_id; 
<token> client_handle; <answer> uint32_t 
} <token> <answer> __packed; 
struct <token> { <answer> afe_port_map 
<token> port_id; <answer> int 
<token> token; <answer> int 
<token> is_rx; <answer> int 
int <token> <answer> is_dig_pcm; 
static struct <token> port_maps[AFE_PORT_MAX] = { <answer> afe_port_map 
[HDMI_RX] = { AFE_PORT_ID_MULTICHAN_HDMI_RX, HDMI_RX, <token> 1}, <answer> 1, 
[SLIMBUS_0_RX] <token> { AFE_PORT_ID_SLIMBUS_MULTI_CHAN_0_RX, <answer> = 
SLIMBUS_0_RX, <token> 1}, <answer> 1, 
<token> = { AFE_PORT_ID_SLIMBUS_MULTI_CHAN_1_RX, <answer> [SLIMBUS_1_RX] 
SLIMBUS_1_RX, <token> 1}, <answer> 1, 
[SLIMBUS_2_RX] = { <token> <answer> AFE_PORT_ID_SLIMBUS_MULTI_CHAN_2_RX, 
SLIMBUS_2_RX, 1, <token> <answer> 1}, 
[SLIMBUS_3_RX] = { <token> <answer> AFE_PORT_ID_SLIMBUS_MULTI_CHAN_3_RX, 
<token> 1, 1}, <answer> SLIMBUS_3_RX, 
[SLIMBUS_4_RX] = { <token> <answer> AFE_PORT_ID_SLIMBUS_MULTI_CHAN_4_RX, 
SLIMBUS_4_RX, <token> 1}, <answer> 1, 
<token> = { AFE_PORT_ID_SLIMBUS_MULTI_CHAN_5_RX, <answer> [SLIMBUS_5_RX] 
SLIMBUS_5_RX, 1, <token> <answer> 1}, 
[SLIMBUS_6_RX] = { <token> <answer> AFE_PORT_ID_SLIMBUS_MULTI_CHAN_6_RX, 
SLIMBUS_6_RX, 1, <token> <answer> 1}, 
[SLIMBUS_0_TX] <token> { AFE_PORT_ID_SLIMBUS_MULTI_CHAN_0_TX, <answer> = 
<token> 0, 1}, <answer> SLIMBUS_0_TX, 
[SLIMBUS_1_TX] <token> { AFE_PORT_ID_SLIMBUS_MULTI_CHAN_1_TX, <answer> = 
SLIMBUS_1_TX, <token> 1}, <answer> 0, 
[SLIMBUS_2_TX] = <token> AFE_PORT_ID_SLIMBUS_MULTI_CHAN_2_TX, <answer> { 
SLIMBUS_2_TX, 0, <token> <answer> 1}, 
[SLIMBUS_3_TX] = { <token> <answer> AFE_PORT_ID_SLIMBUS_MULTI_CHAN_3_TX, 
<token> 0, 1}, <answer> SLIMBUS_3_TX, 
[SLIMBUS_4_TX] = { <token> <answer> AFE_PORT_ID_SLIMBUS_MULTI_CHAN_4_TX, 
SLIMBUS_4_TX, <token> 1}, <answer> 0, 
[SLIMBUS_5_TX] = { <token> <answer> AFE_PORT_ID_SLIMBUS_MULTI_CHAN_5_TX, 
SLIMBUS_5_TX, <token> 1}, <answer> 0, 
<token> = { AFE_PORT_ID_SLIMBUS_MULTI_CHAN_6_TX, <answer> [SLIMBUS_6_TX] 
<token> 0, 1}, <answer> SLIMBUS_6_TX, 
[PRIMARY_MI2S_RX] = { <token> <answer> AFE_PORT_ID_PRIMARY_MI2S_RX, 
<token> 1, 1}, <answer> PRIMARY_MI2S_RX, 
[PRIMARY_MI2S_TX] <token> { AFE_PORT_ID_PRIMARY_MI2S_TX, <answer> = 
<token> 0, 1}, <answer> PRIMARY_MI2S_RX, 
[SECONDARY_MI2S_RX] = { <token> <answer> AFE_PORT_ID_SECONDARY_MI2S_RX, 
<token> 1, 1}, <answer> SECONDARY_MI2S_RX, 
<token> = { AFE_PORT_ID_SECONDARY_MI2S_TX, <answer> [SECONDARY_MI2S_TX] 
<token> 0, 1}, <answer> SECONDARY_MI2S_TX, 
<token> = { AFE_PORT_ID_TERTIARY_MI2S_RX, <answer> [TERTIARY_MI2S_RX] 
TERTIARY_MI2S_RX, <token> 1}, <answer> 1, 
[TERTIARY_MI2S_TX] <token> { AFE_PORT_ID_TERTIARY_MI2S_TX, <answer> = 
<token> 0, 1}, <answer> TERTIARY_MI2S_TX, 
[QUATERNARY_MI2S_RX] <token> { AFE_PORT_ID_QUATERNARY_MI2S_RX, <answer> = 
<token> 1, 1}, <answer> QUATERNARY_MI2S_RX, 
[QUATERNARY_MI2S_TX] <token> { AFE_PORT_ID_QUATERNARY_MI2S_TX, <answer> = 
<token> 0, 1}, <answer> QUATERNARY_MI2S_TX, 
[QUINARY_MI2S_RX] <token> { AFE_PORT_ID_QUINARY_MI2S_RX, <answer> = 
<token> 1, 1}, <answer> QUINARY_MI2S_RX, 
[QUINARY_MI2S_TX] <token> { AFE_PORT_ID_QUINARY_MI2S_TX, <answer> = 
QUINARY_MI2S_TX, <token> 1}, <answer> 0, 
[PRIMARY_TDM_RX_0] <token> { AFE_PORT_ID_PRIMARY_TDM_RX, <answer> = 
PRIMARY_TDM_RX_0, <token> 1}, <answer> 1, 
<token> = { AFE_PORT_ID_PRIMARY_TDM_TX, <answer> [PRIMARY_TDM_TX_0] 
PRIMARY_TDM_TX_0, 0, <token> <answer> 1}, 
[PRIMARY_TDM_RX_1] = <token> AFE_PORT_ID_PRIMARY_TDM_RX_1, <answer> { 
<token> 1, 1}, <answer> PRIMARY_TDM_RX_1, 
<token> = { AFE_PORT_ID_PRIMARY_TDM_TX_1, <answer> [PRIMARY_TDM_TX_1] 
<token> 0, 1}, <answer> PRIMARY_TDM_TX_1, 
<token> = { AFE_PORT_ID_PRIMARY_TDM_RX_2, <answer> [PRIMARY_TDM_RX_2] 
<token> 1, 1}, <answer> PRIMARY_TDM_RX_2, 
<token> = { AFE_PORT_ID_PRIMARY_TDM_TX_2, <answer> [PRIMARY_TDM_TX_2] 
<token> 0, 1}, <answer> PRIMARY_TDM_TX_2, 
[PRIMARY_TDM_RX_3] = { <token> <answer> AFE_PORT_ID_PRIMARY_TDM_RX_3, 
<token> 1, 1}, <answer> PRIMARY_TDM_RX_3, 
[PRIMARY_TDM_TX_3] = <token> AFE_PORT_ID_PRIMARY_TDM_TX_3, <answer> { 
PRIMARY_TDM_TX_3, <token> 1}, <answer> 0, 
<token> = { AFE_PORT_ID_PRIMARY_TDM_RX_4, <answer> [PRIMARY_TDM_RX_4] 
PRIMARY_TDM_RX_4, <token> 1}, <answer> 1, 
<token> = { AFE_PORT_ID_PRIMARY_TDM_TX_4, <answer> [PRIMARY_TDM_TX_4] 
<token> 0, 1}, <answer> PRIMARY_TDM_TX_4, 
[PRIMARY_TDM_RX_5] = { <token> <answer> AFE_PORT_ID_PRIMARY_TDM_RX_5, 
PRIMARY_TDM_RX_5, <token> 1}, <answer> 1, 
[PRIMARY_TDM_TX_5] <token> { AFE_PORT_ID_PRIMARY_TDM_TX_5, <answer> = 
<token> 0, 1}, <answer> PRIMARY_TDM_TX_5, 
<token> = { AFE_PORT_ID_PRIMARY_TDM_RX_6, <answer> [PRIMARY_TDM_RX_6] 
PRIMARY_TDM_RX_6, <token> 1}, <answer> 1, 
[PRIMARY_TDM_TX_6] = <token> AFE_PORT_ID_PRIMARY_TDM_TX_6, <answer> { 
PRIMARY_TDM_TX_6, 0, <token> <answer> 1}, 
[PRIMARY_TDM_RX_7] <token> { AFE_PORT_ID_PRIMARY_TDM_RX_7, <answer> = 
<token> 1, 1}, <answer> PRIMARY_TDM_RX_7, 
[PRIMARY_TDM_TX_7] = { <token> <answer> AFE_PORT_ID_PRIMARY_TDM_TX_7, 
<token> 0, 1}, <answer> PRIMARY_TDM_TX_7, 
[SECONDARY_TDM_RX_0] <token> { AFE_PORT_ID_SECONDARY_TDM_RX, <answer> = 
<token> 1, 1}, <answer> SECONDARY_TDM_RX_0, 
<token> = { AFE_PORT_ID_SECONDARY_TDM_TX, <answer> [SECONDARY_TDM_TX_0] 
<token> 0, 1}, <answer> SECONDARY_TDM_TX_0, 
[SECONDARY_TDM_RX_1] <token> { AFE_PORT_ID_SECONDARY_TDM_RX_1, <answer> = 
SECONDARY_TDM_RX_1, 1, <token> <answer> 1}, 
[SECONDARY_TDM_TX_1] <token> { AFE_PORT_ID_SECONDARY_TDM_TX_1, <answer> = 
<token> 0, 1}, <answer> SECONDARY_TDM_TX_1, 
[SECONDARY_TDM_RX_2] <token> { AFE_PORT_ID_SECONDARY_TDM_RX_2, <answer> = 
SECONDARY_TDM_RX_2, 1, <token> <answer> 1}, 
[SECONDARY_TDM_TX_2] <token> { AFE_PORT_ID_SECONDARY_TDM_TX_2, <answer> = 
<token> 0, 1}, <answer> SECONDARY_TDM_TX_2, 
<token> = { AFE_PORT_ID_SECONDARY_TDM_RX_3, <answer> [SECONDARY_TDM_RX_3] 
SECONDARY_TDM_RX_3, 1, <token> <answer> 1}, 
[SECONDARY_TDM_TX_3] = { <token> <answer> AFE_PORT_ID_SECONDARY_TDM_TX_3, 
SECONDARY_TDM_TX_3, <token> 1}, <answer> 0, 
[SECONDARY_TDM_RX_4] = { <token> <answer> AFE_PORT_ID_SECONDARY_TDM_RX_4, 
SECONDARY_TDM_RX_4, 1, <token> <answer> 1}, 
[SECONDARY_TDM_TX_4] = <token> AFE_PORT_ID_SECONDARY_TDM_TX_4, <answer> { 
SECONDARY_TDM_TX_4, 0, <token> <answer> 1}, 
[SECONDARY_TDM_RX_5] = <token> AFE_PORT_ID_SECONDARY_TDM_RX_5, <answer> { 
<token> 1, 1}, <answer> SECONDARY_TDM_RX_5, 
[SECONDARY_TDM_TX_5] = { <token> <answer> AFE_PORT_ID_SECONDARY_TDM_TX_5, 
SECONDARY_TDM_TX_5, <token> 1}, <answer> 0, 
[SECONDARY_TDM_RX_6] = { <token> <answer> AFE_PORT_ID_SECONDARY_TDM_RX_6, 
<token> 1, 1}, <answer> SECONDARY_TDM_RX_6, 
[SECONDARY_TDM_TX_6] = { <token> <answer> AFE_PORT_ID_SECONDARY_TDM_TX_6, 
SECONDARY_TDM_TX_6, 0, <token> <answer> 1}, 
[SECONDARY_TDM_RX_7] <token> { AFE_PORT_ID_SECONDARY_TDM_RX_7, <answer> = 
SECONDARY_TDM_RX_7, 1, <token> <answer> 1}, 
[SECONDARY_TDM_TX_7] <token> { AFE_PORT_ID_SECONDARY_TDM_TX_7, <answer> = 
<token> 0, 1}, <answer> SECONDARY_TDM_TX_7, 
[TERTIARY_TDM_RX_0] = <token> AFE_PORT_ID_TERTIARY_TDM_RX, <answer> { 
TERTIARY_TDM_RX_0, 1, <token> <answer> 1}, 
[TERTIARY_TDM_TX_0] = <token> AFE_PORT_ID_TERTIARY_TDM_TX, <answer> { 
<token> 0, 1}, <answer> TERTIARY_TDM_TX_0, 
<token> = { AFE_PORT_ID_TERTIARY_TDM_RX_1, <answer> [TERTIARY_TDM_RX_1] 
TERTIARY_TDM_RX_1, 1, <token> <answer> 1}, 
<token> = { AFE_PORT_ID_TERTIARY_TDM_TX_1, <answer> [TERTIARY_TDM_TX_1] 
TERTIARY_TDM_TX_1, <token> 1}, <answer> 0, 
<token> = { AFE_PORT_ID_TERTIARY_TDM_RX_2, <answer> [TERTIARY_TDM_RX_2] 
TERTIARY_TDM_RX_2, 1, <token> <answer> 1}, 
[TERTIARY_TDM_TX_2] = { <token> <answer> AFE_PORT_ID_TERTIARY_TDM_TX_2, 
TERTIARY_TDM_TX_2, <token> 1}, <answer> 0, 
[TERTIARY_TDM_RX_3] = <token> AFE_PORT_ID_TERTIARY_TDM_RX_3, <answer> { 
<token> 1, 1}, <answer> TERTIARY_TDM_RX_3, 
[TERTIARY_TDM_TX_3] = { <token> <answer> AFE_PORT_ID_TERTIARY_TDM_TX_3, 
TERTIARY_TDM_TX_3, 0, <token> <answer> 1}, 
<token> = { AFE_PORT_ID_TERTIARY_TDM_RX_4, <answer> [TERTIARY_TDM_RX_4] 
TERTIARY_TDM_RX_4, <token> 1}, <answer> 1, 
[TERTIARY_TDM_TX_4] <token> { AFE_PORT_ID_TERTIARY_TDM_TX_4, <answer> = 
<token> 0, 1}, <answer> TERTIARY_TDM_TX_4, 
<token> = { AFE_PORT_ID_TERTIARY_TDM_RX_5, <answer> [TERTIARY_TDM_RX_5] 
<token> 1, 1}, <answer> TERTIARY_TDM_RX_5, 
<token> = { AFE_PORT_ID_TERTIARY_TDM_TX_5, <answer> [TERTIARY_TDM_TX_5] 
TERTIARY_TDM_TX_5, 0, <token> <answer> 1}, 
<token> = { AFE_PORT_ID_TERTIARY_TDM_RX_6, <answer> [TERTIARY_TDM_RX_6] 
TERTIARY_TDM_RX_6, 1, <token> <answer> 1}, 
[TERTIARY_TDM_TX_6] <token> { AFE_PORT_ID_TERTIARY_TDM_TX_6, <answer> = 
<token> 0, 1}, <answer> TERTIARY_TDM_TX_6, 
<token> = { AFE_PORT_ID_TERTIARY_TDM_RX_7, <answer> [TERTIARY_TDM_RX_7] 
TERTIARY_TDM_RX_7, 1, <token> <answer> 1}, 
[TERTIARY_TDM_TX_7] <token> { AFE_PORT_ID_TERTIARY_TDM_TX_7, <answer> = 
TERTIARY_TDM_TX_7, <token> 1}, <answer> 0, 
[QUATERNARY_TDM_RX_0] <token> { AFE_PORT_ID_QUATERNARY_TDM_RX, <answer> = 
<token> 1, 1}, <answer> QUATERNARY_TDM_RX_0, 
<token> = { AFE_PORT_ID_QUATERNARY_TDM_TX, <answer> [QUATERNARY_TDM_TX_0] 
QUATERNARY_TDM_TX_0, 0, <token> <answer> 1}, 
[QUATERNARY_TDM_RX_1] = <token> AFE_PORT_ID_QUATERNARY_TDM_RX_1, <answer> { 
QUATERNARY_TDM_RX_1, 1, <token> <answer> 1}, 
[QUATERNARY_TDM_TX_1] = <token> AFE_PORT_ID_QUATERNARY_TDM_TX_1, <answer> { 
QUATERNARY_TDM_TX_1, 0, <token> <answer> 1}, 
[QUATERNARY_TDM_RX_2] <token> { AFE_PORT_ID_QUATERNARY_TDM_RX_2, <answer> = 
<token> 1, 1}, <answer> QUATERNARY_TDM_RX_2, 
[QUATERNARY_TDM_TX_2] = { <token> <answer> AFE_PORT_ID_QUATERNARY_TDM_TX_2, 
QUATERNARY_TDM_TX_2, <token> 1}, <answer> 0, 
[QUATERNARY_TDM_RX_3] <token> { AFE_PORT_ID_QUATERNARY_TDM_RX_3, <answer> = 
QUATERNARY_TDM_RX_3, <token> 1}, <answer> 1, 
[QUATERNARY_TDM_TX_3] <token> { AFE_PORT_ID_QUATERNARY_TDM_TX_3, <answer> = 
QUATERNARY_TDM_TX_3, <token> 1}, <answer> 0, 
[QUATERNARY_TDM_RX_4] = <token> AFE_PORT_ID_QUATERNARY_TDM_RX_4, <answer> { 
<token> 1, 1}, <answer> QUATERNARY_TDM_RX_4, 
[QUATERNARY_TDM_TX_4] = <token> AFE_PORT_ID_QUATERNARY_TDM_TX_4, <answer> { 
QUATERNARY_TDM_TX_4, 0, <token> <answer> 1}, 
[QUATERNARY_TDM_RX_5] = <token> AFE_PORT_ID_QUATERNARY_TDM_RX_5, <answer> { 
QUATERNARY_TDM_RX_5, <token> 1}, <answer> 1, 
[QUATERNARY_TDM_TX_5] = <token> AFE_PORT_ID_QUATERNARY_TDM_TX_5, <answer> { 
QUATERNARY_TDM_TX_5, 0, <token> <answer> 1}, 
[QUATERNARY_TDM_RX_6] <token> { AFE_PORT_ID_QUATERNARY_TDM_RX_6, <answer> = 
QUATERNARY_TDM_RX_6, 1, <token> <answer> 1}, 
<token> = { AFE_PORT_ID_QUATERNARY_TDM_TX_6, <answer> [QUATERNARY_TDM_TX_6] 
<token> 0, 1}, <answer> QUATERNARY_TDM_TX_6, 
[QUATERNARY_TDM_RX_7] <token> { AFE_PORT_ID_QUATERNARY_TDM_RX_7, <answer> = 
QUATERNARY_TDM_RX_7, <token> 1}, <answer> 1, 
[QUATERNARY_TDM_TX_7] <token> { AFE_PORT_ID_QUATERNARY_TDM_TX_7, <answer> = 
QUATERNARY_TDM_TX_7, 0, <token> <answer> 1}, 
[QUINARY_TDM_RX_0] <token> { AFE_PORT_ID_QUINARY_TDM_RX, <answer> = 
QUINARY_TDM_RX_0, 1, <token> <answer> 1}, 
[QUINARY_TDM_TX_0] = <token> AFE_PORT_ID_QUINARY_TDM_TX, <answer> { 
QUINARY_TDM_TX_0, <token> 1}, <answer> 0, 
[QUINARY_TDM_RX_1] = { <token> <answer> AFE_PORT_ID_QUINARY_TDM_RX_1, 
QUINARY_TDM_RX_1, 1, <token> <answer> 1}, 
[QUINARY_TDM_TX_1] <token> { AFE_PORT_ID_QUINARY_TDM_TX_1, <answer> = 
QUINARY_TDM_TX_1, <token> 1}, <answer> 0, 
[QUINARY_TDM_RX_2] = { <token> <answer> AFE_PORT_ID_QUINARY_TDM_RX_2, 
QUINARY_TDM_RX_2, 1, <token> <answer> 1}, 
[QUINARY_TDM_TX_2] <token> { AFE_PORT_ID_QUINARY_TDM_TX_2, <answer> = 
<token> 0, 1}, <answer> QUINARY_TDM_TX_2, 
[QUINARY_TDM_RX_3] <token> { AFE_PORT_ID_QUINARY_TDM_RX_3, <answer> = 
QUINARY_TDM_RX_3, <token> 1}, <answer> 1, 
<token> = { AFE_PORT_ID_QUINARY_TDM_TX_3, <answer> [QUINARY_TDM_TX_3] 
<token> 0, 1}, <answer> QUINARY_TDM_TX_3, 
[QUINARY_TDM_RX_4] <token> { AFE_PORT_ID_QUINARY_TDM_RX_4, <answer> = 
QUINARY_TDM_RX_4, 1, <token> <answer> 1}, 
<token> = { AFE_PORT_ID_QUINARY_TDM_TX_4, <answer> [QUINARY_TDM_TX_4] 
<token> 0, 1}, <answer> QUINARY_TDM_TX_4, 
[QUINARY_TDM_RX_5] <token> { AFE_PORT_ID_QUINARY_TDM_RX_5, <answer> = 
QUINARY_TDM_RX_5, <token> 1}, <answer> 1, 
[QUINARY_TDM_TX_5] = { <token> <answer> AFE_PORT_ID_QUINARY_TDM_TX_5, 
QUINARY_TDM_TX_5, <token> 1}, <answer> 0, 
<token> = { AFE_PORT_ID_QUINARY_TDM_RX_6, <answer> [QUINARY_TDM_RX_6] 
QUINARY_TDM_RX_6, <token> 1}, <answer> 1, 
[QUINARY_TDM_TX_6] <token> { AFE_PORT_ID_QUINARY_TDM_TX_6, <answer> = 
QUINARY_TDM_TX_6, <token> 1}, <answer> 0, 
[QUINARY_TDM_RX_7] = { <token> <answer> AFE_PORT_ID_QUINARY_TDM_RX_7, 
<token> 1, 1}, <answer> QUINARY_TDM_RX_7, 
<token> = { AFE_PORT_ID_QUINARY_TDM_TX_7, <answer> [QUINARY_TDM_TX_7] 
QUINARY_TDM_TX_7, 0, <token> <answer> 1}, 
<token> = { AFE_PORT_ID_HDMI_OVER_DP_RX, <answer> [DISPLAY_PORT_RX] 
DISPLAY_PORT_RX, <token> 1}, <answer> 1, 
[WSA_CODEC_DMA_RX_0] <token> { AFE_PORT_ID_WSA_CODEC_DMA_RX_0, <answer> = 
<token> 1, 1}, <answer> WSA_CODEC_DMA_RX_0, 
[WSA_CODEC_DMA_TX_0] <token> { AFE_PORT_ID_WSA_CODEC_DMA_TX_0, <answer> = 
<token> 0, 1}, <answer> WSA_CODEC_DMA_TX_0, 
[WSA_CODEC_DMA_RX_1] = { <token> <answer> AFE_PORT_ID_WSA_CODEC_DMA_RX_1, 
WSA_CODEC_DMA_RX_1, 1, <token> <answer> 1}, 
[WSA_CODEC_DMA_TX_1] = <token> AFE_PORT_ID_WSA_CODEC_DMA_TX_1, <answer> { 
WSA_CODEC_DMA_TX_1, 0, <token> <answer> 1}, 
<token> = { AFE_PORT_ID_WSA_CODEC_DMA_TX_2, <answer> [WSA_CODEC_DMA_TX_2] 
WSA_CODEC_DMA_TX_2, 0, <token> <answer> 1}, 
[VA_CODEC_DMA_TX_0] = <token> AFE_PORT_ID_VA_CODEC_DMA_TX_0, <answer> { 
<token> 0, 1}, <answer> VA_CODEC_DMA_TX_0, 
[VA_CODEC_DMA_TX_1] = { <token> <answer> AFE_PORT_ID_VA_CODEC_DMA_TX_1, 
VA_CODEC_DMA_TX_1, <token> 1}, <answer> 0, 
<token> = { AFE_PORT_ID_VA_CODEC_DMA_TX_2, <answer> [VA_CODEC_DMA_TX_2] 
<token> 0, 1}, <answer> VA_CODEC_DMA_TX_2, 
<token> = { AFE_PORT_ID_RX_CODEC_DMA_RX_0, <answer> [RX_CODEC_DMA_RX_0] 
RX_CODEC_DMA_RX_0, <token> 1}, <answer> 1, 
<token> = { AFE_PORT_ID_TX_CODEC_DMA_TX_0, <answer> [TX_CODEC_DMA_TX_0] 
TX_CODEC_DMA_TX_0, 0, <token> <answer> 1}, 
[RX_CODEC_DMA_RX_1] = <token> AFE_PORT_ID_RX_CODEC_DMA_RX_1, <answer> { 
RX_CODEC_DMA_RX_1, 1, <token> <answer> 1}, 
[TX_CODEC_DMA_TX_1] = { <token> <answer> AFE_PORT_ID_TX_CODEC_DMA_TX_1, 
TX_CODEC_DMA_TX_1, <token> 1}, <answer> 0, 
<token> = { AFE_PORT_ID_RX_CODEC_DMA_RX_2, <answer> [RX_CODEC_DMA_RX_2] 
<token> 1, 1}, <answer> RX_CODEC_DMA_RX_2, 
[TX_CODEC_DMA_TX_2] = { <token> <answer> AFE_PORT_ID_TX_CODEC_DMA_TX_2, 
TX_CODEC_DMA_TX_2, 0, <token> <answer> 1}, 
[RX_CODEC_DMA_RX_3] <token> { AFE_PORT_ID_RX_CODEC_DMA_RX_3, <answer> = 
RX_CODEC_DMA_RX_3, <token> 1}, <answer> 1, 
[TX_CODEC_DMA_TX_3] = { <token> <answer> AFE_PORT_ID_TX_CODEC_DMA_TX_3, 
TX_CODEC_DMA_TX_3, <token> 1}, <answer> 0, 
[RX_CODEC_DMA_RX_4] <token> { AFE_PORT_ID_RX_CODEC_DMA_RX_4, <answer> = 
RX_CODEC_DMA_RX_4, <token> 1}, <answer> 1, 
[TX_CODEC_DMA_TX_4] <token> { AFE_PORT_ID_TX_CODEC_DMA_TX_4, <answer> = 
<token> 0, 1}, <answer> TX_CODEC_DMA_TX_4, 
[RX_CODEC_DMA_RX_5] = <token> AFE_PORT_ID_RX_CODEC_DMA_RX_5, <answer> { 
<token> 1, 1}, <answer> RX_CODEC_DMA_RX_5, 
[TX_CODEC_DMA_TX_5] = { <token> <answer> AFE_PORT_ID_TX_CODEC_DMA_TX_5, 
<token> 0, 1}, <answer> TX_CODEC_DMA_TX_5, 
<token> = { AFE_PORT_ID_RX_CODEC_DMA_RX_6, <answer> [RX_CODEC_DMA_RX_6] 
RX_CODEC_DMA_RX_6, <token> 1}, <answer> 1, 
[RX_CODEC_DMA_RX_7] = { <token> <answer> AFE_PORT_ID_RX_CODEC_DMA_RX_7, 
<token> 1, 1}, <answer> RX_CODEC_DMA_RX_7, 
static void <token> kref *ref) <answer> q6afe_port_free(struct 
struct <token> *port; <answer> q6afe_port 
struct q6afe <token> <answer> *afe; 
unsigned <token> flags; <answer> long 
port <token> container_of(ref, struct q6afe_port, refcount); <answer> = 
afe <token> port->afe; <answer> = 
<token> flags); <answer> spin_lock_irqsave(&afe->port_list_lock, 
spin_unlock_irqrestore(&afe->port_list_lock, <token> <answer> flags); 
static struct q6afe_port *q6afe_find_port(struct <token> *afe, int token) <answer> q6afe 
struct <token> *p; <answer> q6afe_port 
struct <token> *ret = NULL; <answer> q6afe_port 
unsigned <token> flags; <answer> long 
<token> flags); <answer> spin_lock_irqsave(&afe->port_list_lock, 
<token> &afe->port_list, node) <answer> list_for_each_entry(p, 
if (p->token <token> token) { <answer> == 
ret <token> p; <answer> = 
spin_unlock_irqrestore(&afe->port_list_lock, <token> <answer> flags); 
return <token> <answer> ret; 
static int q6afe_callback(struct <token> *adev, struct apr_resp_pkt *data) <answer> apr_device 
struct q6afe *afe = <token> <answer> dev_get_drvdata(&adev->dev); 
<token> aprv2_ibasic_rsp_result_t *res; <answer> struct 
struct apr_hdr *hdr = <token> <answer> &data->hdr; 
struct q6afe_port <token> <answer> *port; 
<token> (!data->payload_size) <answer> if 
<token> 0; <answer> return 
<token> = data->payload; <answer> res 
switch (hdr->opcode) <token> <answer> { 
<token> APR_BASIC_RSP_RESULT: { <answer> case 
if <token> { <answer> (res->status) 
dev_err(afe->dev, "cmd = 0x%x <token> error = 0x%x\n", <answer> returned 
res->opcode, <token> <answer> res->status); 
switch <token> { <answer> (res->opcode) 
case <token> <answer> AFE_PORT_CMD_SET_PARAM_V2: 
<token> AFE_PORT_CMD_DEVICE_STOP: <answer> case 
<token> AFE_PORT_CMD_DEVICE_START: <answer> case 
<token> AFE_SVC_CMD_SET_PARAM: <answer> case 
port = q6afe_find_port(afe, <token> <answer> hdr->token); 
if (port) <token> <answer> { 
port->result = <token> <answer> *res; 
<token> q6afe_port_free); <answer> kref_put(&port->refcount, 
} else if (hdr->token <token> AFE_CLK_TOKEN) { <answer> == 
afe->result <token> *res; <answer> = 
<token> "Unknown cmd 0x%x\n", res->opcode); <answer> dev_err(afe->dev, 
<token> AFE_CMD_RSP_REMOTE_LPASS_CORE_HW_VOTE_REQUEST: <answer> case 
<token> = hdr->opcode; <answer> afe->result.opcode 
afe->result.status <token> res->status; <answer> = 
<token> 0; <answer> return 
int <token> index) <answer> q6afe_get_port_id(int 
if (index < 0 || index <token> AFE_PORT_MAX) <answer> >= 
<token> -EINVAL; <answer> return 
return <token> <answer> port_maps[index].port_id; 
static int afe_apr_send_pkt(struct q6afe *afe, struct apr_pkt <token> <answer> *pkt, 
struct q6afe_port *port, uint32_t <token> <answer> rsp_opcode) 
wait_queue_head_t <token> <answer> *wait; 
struct aprv2_ibasic_rsp_result_t <token> <answer> *result; 
<token> ret; <answer> int 
if <token> { <answer> (port) 
<token> = &port->wait; <answer> wait 
result <token> &port->result; <answer> = 
} else <token> <answer> { 
result <token> &afe->result; <answer> = 
<token> = &afe->wait; <answer> wait 
result->opcode <token> 0; <answer> = 
<token> = 0; <answer> result->status 
ret = <token> pkt); <answer> apr_send_pkt(afe->apr, 
<token> (ret < 0) { <answer> if 
<token> "packet not transmitted (%d)\n", ret); <answer> dev_err(afe->dev, 
<token> = -EINVAL; <answer> ret 
<token> err; <answer> goto 
ret = <token> (result->opcode == rsp_opcode), <answer> wait_event_timeout(*wait, 
if <token> { <answer> (!ret) 
ret = <token> <answer> -ETIMEDOUT; 
} else if (result->status <token> 0) { <answer> > 
dev_err(afe->dev, "DSP <token> error[%x]\n", <answer> returned 
ret <token> -EINVAL; <answer> = 
} <token> { <answer> else 
ret = <token> <answer> 0; 
<token> ret; <answer> return 
static int q6afe_set_param(struct q6afe *afe, struct <token> *port, <answer> q6afe_port 
void *data, <token> param_id, int module_id, int psize, <answer> int 
int <token> <answer> token) 
struct <token> *param; <answer> afe_svc_cmd_set_param 
<token> afe_port_param_data_v2 *pdata; <answer> struct 
struct <token> *pkt; <answer> apr_pkt 
int <token> pkt_size; <answer> ret, 
void <token> *pl; <answer> *p, 
pkt_size = <token> + sizeof(*param) + sizeof(*pdata) + psize; <answer> APR_HDR_SIZE 
p = kzalloc(pkt_size, <token> <answer> GFP_KERNEL); 
if <token> <answer> (!p) 
return <token> <answer> -ENOMEM; 
pkt = <token> <answer> p; 
param = <token> + APR_HDR_SIZE; <answer> p 
pdata = p <token> APR_HDR_SIZE + sizeof(*param); <answer> + 
pl = p + APR_HDR_SIZE + sizeof(*param) <token> sizeof(*pdata); <answer> + 
memcpy(pl, data, <token> <answer> psize); 
<token> = APR_HDR_FIELD(APR_MSG_TYPE_SEQ_CMD, <answer> pkt->hdr.hdr_field 
pkt->hdr.pkt_size <token> pkt_size; <answer> = 
<token> = 0; <answer> pkt->hdr.src_port 
<token> = 0; <answer> pkt->hdr.dest_port 
pkt->hdr.token <token> token; <answer> = 
pkt->hdr.opcode = <token> <answer> AFE_SVC_CMD_SET_PARAM; 
<token> = sizeof(*pdata) + psize; <answer> param->payload_size 
param->payload_address_lsw <token> 0x00; <answer> = 
param->payload_address_msw = <token> <answer> 0x00; 
param->mem_map_handle = <token> <answer> 0x00; 
pdata->module_id = <token> <answer> module_id; 
pdata->param_id = <token> <answer> param_id; 
pdata->param_size = <token> <answer> psize; 
ret = <token> pkt, port, AFE_SVC_CMD_SET_PARAM); <answer> afe_apr_send_pkt(afe, 
<token> (ret) <answer> if 
dev_err(afe->dev, "AFE set params failed <token> ret); <answer> %d\n", 
return <token> <answer> ret; 
static <token> q6afe_port_set_param(struct q6afe_port *port, void *data, <answer> int 
int param_id, int module_id, int <token> <answer> psize) 
return q6afe_set_param(port->afe, port, data, <token> module_id, <answer> param_id, 
psize, <token> <answer> port->token); 
static int q6afe_port_set_param_v2(struct q6afe_port *port, void <token> <answer> *data, 
int param_id, int module_id, int <token> <answer> psize) 
<token> afe_port_cmd_set_param_v2 *param; <answer> struct 
struct <token> *pdata; <answer> afe_port_param_data_v2 
struct <token> *afe = port->afe; <answer> q6afe 
<token> apr_pkt *pkt; <answer> struct 
u16 port_id = <token> <answer> port->id; 
<token> ret, pkt_size; <answer> int 
<token> *p, *pl; <answer> void 
pkt_size = <token> + sizeof(*param) + sizeof(*pdata) + psize; <answer> APR_HDR_SIZE 
p = kzalloc(pkt_size, <token> <answer> GFP_KERNEL); 
<token> (!p) <answer> if 
<token> -ENOMEM; <answer> return 
<token> = p; <answer> pkt 
param <token> p + APR_HDR_SIZE; <answer> = 
pdata = p + <token> + sizeof(*param); <answer> APR_HDR_SIZE 
pl = p + APR_HDR_SIZE + sizeof(*param) <token> sizeof(*pdata); <answer> + 
<token> data, psize); <answer> memcpy(pl, 
pkt->hdr.hdr_field = <token> <answer> APR_HDR_FIELD(APR_MSG_TYPE_SEQ_CMD, 
<token> = pkt_size; <answer> pkt->hdr.pkt_size 
pkt->hdr.src_port <token> 0; <answer> = 
pkt->hdr.dest_port <token> 0; <answer> = 
<token> = port->token; <answer> pkt->hdr.token 
pkt->hdr.opcode <token> AFE_PORT_CMD_SET_PARAM_V2; <answer> = 
param->port_id <token> port_id; <answer> = 
param->payload_size = sizeof(*pdata) + <token> <answer> psize; 
param->payload_address_lsw <token> 0x00; <answer> = 
<token> = 0x00; <answer> param->payload_address_msw 
<token> = 0x00; <answer> param->mem_map_handle 
pdata->module_id = <token> <answer> module_id; 
pdata->param_id = <token> <answer> param_id; 
pdata->param_size = <token> <answer> psize; 
ret = afe_apr_send_pkt(afe, <token> port, AFE_PORT_CMD_SET_PARAM_V2); <answer> pkt, 
if <token> <answer> (ret) 
dev_err(afe->dev, "AFE enable for <token> 0x%x failed %d\n", <answer> port 
port_id, <token> <answer> ret); 
<token> ret; <answer> return 
static int <token> q6afe_port *port, <answer> q6afe_port_set_lpass_clock(struct 
<token> afe_clk_cfg *cfg) <answer> struct 
return q6afe_port_set_param_v2(port, <token> <answer> cfg, 
static int q6afe_set_lpass_clock_v2(struct <token> *port, <answer> q6afe_port 
<token> afe_clk_set *cfg) <answer> struct 
return <token> cfg, AFE_PARAM_ID_CLOCK_SET, <answer> q6afe_port_set_param(port, 
<token> sizeof(*cfg)); <answer> AFE_MODULE_CLOCK_SET, 
static int q6afe_set_digital_codec_core_clock(struct q6afe_port <token> <answer> *port, 
struct <token> *cfg) <answer> afe_digital_clk_cfg 
return <token> cfg, <answer> q6afe_port_set_param_v2(port, 
int q6afe_set_lpass_clock(struct device *dev, <token> clk_id, int attri, <answer> int 
int clk_root, unsigned <token> freq) <answer> int 
struct q6afe *afe <token> dev_get_drvdata(dev->parent); <answer> = 
struct afe_clk_set cset <token> {0,}; <answer> = 
cset.clk_set_minor_version = <token> <answer> AFE_API_VERSION_CLOCK_SET; 
cset.clk_id = <token> <answer> clk_id; 
<token> = freq; <answer> cset.clk_freq_in_hz 
cset.clk_attri <token> attri; <answer> = 
<token> = clk_root; <answer> cset.clk_root 
<token> = !!freq; <answer> cset.enable 
return q6afe_set_param(afe, <token> &cset, AFE_PARAM_ID_CLOCK_SET, <answer> NULL, 
<token> sizeof(cset), <answer> AFE_MODULE_CLOCK_SET, 
int q6afe_port_set_sysclk(struct q6afe_port <token> int clk_id, <answer> *port, 
int clk_src, int <token> <answer> clk_root, 
unsigned int <token> int dir) <answer> freq, 
<token> afe_clk_cfg ccfg = {0,}; <answer> struct 
struct afe_clk_set cset = <token> <answer> {0,}; 
struct <token> dcfg = {0,}; <answer> afe_digital_clk_cfg 
<token> ret; <answer> int 
switch (clk_id) <token> <answer> { 
case <token> <answer> LPAIF_DIG_CLK: 
dcfg.i2s_cfg_minor_version = <token> <answer> AFE_API_VERSION_I2S_CONFIG; 
dcfg.clk_val <token> freq; <answer> = 
dcfg.clk_root = <token> <answer> clk_root; 
<token> = q6afe_set_digital_codec_core_clock(port, &dcfg); <answer> ret 
case <token> <answer> LPAIF_BIT_CLK: 
ccfg.i2s_cfg_minor_version = <token> <answer> AFE_API_VERSION_I2S_CONFIG; 
ccfg.clk_val1 = <token> <answer> freq; 
<token> = clk_src; <answer> ccfg.clk_src 
<token> = clk_root; <answer> ccfg.clk_root 
ccfg.clk_set_mode <token> Q6AFE_LPASS_MODE_CLK1_VALID; <answer> = 
ret = <token> &ccfg); <answer> q6afe_port_set_lpass_clock(port, 
<token> LPAIF_OSR_CLK: <answer> case 
ccfg.i2s_cfg_minor_version <token> AFE_API_VERSION_I2S_CONFIG; <answer> = 
ccfg.clk_val2 = <token> <answer> freq; 
ccfg.clk_src <token> clk_src; <answer> = 
<token> = clk_root; <answer> ccfg.clk_root 
ccfg.clk_set_mode <token> Q6AFE_LPASS_MODE_CLK2_VALID; <answer> = 
ret = <token> &ccfg); <answer> q6afe_port_set_lpass_clock(port, 
case Q6AFE_LPASS_CLK_ID_PRI_MI2S_IBIT <token> Q6AFE_LPASS_CLK_ID_QUI_MI2S_OSR: <answer> ... 
case Q6AFE_LPASS_CLK_ID_MCLK_1 ... <token> <answer> Q6AFE_LPASS_CLK_ID_INT_MCLK_1: 
case Q6AFE_LPASS_CLK_ID_PRI_TDM_IBIT <token> Q6AFE_LPASS_CLK_ID_QUIN_TDM_EBIT: <answer> ... 
case Q6AFE_LPASS_CLK_ID_WSA_CORE_MCLK ... <token> <answer> Q6AFE_LPASS_CLK_ID_VA_CORE_2X_MCLK: 
cset.clk_set_minor_version <token> AFE_API_VERSION_CLOCK_SET; <answer> = 
cset.clk_id <token> clk_id; <answer> = 
<token> = freq; <answer> cset.clk_freq_in_hz 
<token> = clk_src; <answer> cset.clk_attri 
cset.clk_root <token> clk_root; <answer> = 
cset.enable = <token> <answer> !!freq; 
ret = <token> &cset); <answer> q6afe_set_lpass_clock_v2(port, 
ret <token> -EINVAL; <answer> = 
return <token> <answer> ret; 
int <token> q6afe_port *port) <answer> q6afe_port_stop(struct 
struct <token> *stop; <answer> afe_port_cmd_device_stop 
struct q6afe *afe = <token> <answer> port->afe; 
<token> apr_pkt *pkt; <answer> struct 
<token> port_id = port->id; <answer> int 
int <token> = 0; <answer> ret 
int <token> pkt_size; <answer> index, 
<token> *p; <answer> void 
index <token> port->token; <answer> = 
if <token> < 0 || index >= AFE_PORT_MAX) { <answer> (index 
<token> "AFE port index[%d] invalid!\n", index); <answer> dev_err(afe->dev, 
<token> -EINVAL; <answer> return 
<token> = APR_HDR_SIZE + sizeof(*stop); <answer> pkt_size 
p = kzalloc(pkt_size, <token> <answer> GFP_KERNEL); 
if <token> <answer> (!p) 
return <token> <answer> -ENOMEM; 
pkt <token> p; <answer> = 
stop = p <token> APR_HDR_SIZE; <answer> + 
pkt->hdr.hdr_field = <token> <answer> APR_HDR_FIELD(APR_MSG_TYPE_SEQ_CMD, 
pkt->hdr.pkt_size <token> pkt_size; <answer> = 
pkt->hdr.src_port = <token> <answer> 0; 
pkt->hdr.dest_port <token> 0; <answer> = 
pkt->hdr.token <token> index; <answer> = 
<token> = AFE_PORT_CMD_DEVICE_STOP; <answer> pkt->hdr.opcode 
stop->port_id <token> port_id; <answer> = 
<token> = 0; <answer> stop->reserved 
ret = afe_apr_send_pkt(afe, pkt, port, <token> <answer> AFE_PORT_CMD_DEVICE_STOP); 
<token> (ret) <answer> if 
dev_err(afe->dev, "AFE close <token> %d\n", ret); <answer> failed 
<token> ret; <answer> return 
void q6afe_slim_port_prepare(struct q6afe_port <token> <answer> *port, 
struct <token> *cfg) <answer> q6afe_slim_cfg 
union afe_port_config *pcfg <token> &port->port_cfg; <answer> = 
<token> = AFE_API_VERSION_SLIMBUS_CONFIG; <answer> pcfg->slim_cfg.sb_cfg_minor_version 
pcfg->slim_cfg.sample_rate <token> cfg->sample_rate; <answer> = 
pcfg->slim_cfg.bit_width = <token> <answer> cfg->bit_width; 
<token> = cfg->num_channels; <answer> pcfg->slim_cfg.num_channels 
pcfg->slim_cfg.data_format = <token> <answer> cfg->data_format; 
<token> = cfg->ch_mapping[0]; <answer> pcfg->slim_cfg.shared_ch_mapping[0] 
pcfg->slim_cfg.shared_ch_mapping[1] <token> cfg->ch_mapping[1]; <answer> = 
pcfg->slim_cfg.shared_ch_mapping[2] = <token> <answer> cfg->ch_mapping[2]; 
pcfg->slim_cfg.shared_ch_mapping[3] <token> cfg->ch_mapping[3]; <answer> = 
void q6afe_tdm_port_prepare(struct <token> *port, <answer> q6afe_port 
struct <token> *cfg) <answer> q6afe_tdm_cfg 
union afe_port_config <token> = &port->port_cfg; <answer> *pcfg 
<token> = AFE_API_VERSION_TDM_CONFIG; <answer> pcfg->tdm_cfg.tdm_cfg_minor_version 
<token> = cfg->num_channels; <answer> pcfg->tdm_cfg.num_channels 
pcfg->tdm_cfg.sample_rate = <token> <answer> cfg->sample_rate; 
pcfg->tdm_cfg.bit_width <token> cfg->bit_width; <answer> = 
pcfg->tdm_cfg.data_format <token> cfg->data_format; <answer> = 
pcfg->tdm_cfg.sync_mode = <token> <answer> cfg->sync_mode; 
pcfg->tdm_cfg.sync_src = <token> <answer> cfg->sync_src; 
pcfg->tdm_cfg.nslots_per_frame = <token> <answer> cfg->nslots_per_frame; 
pcfg->tdm_cfg.slot_width <token> cfg->slot_width; <answer> = 
pcfg->tdm_cfg.slot_mask <token> cfg->slot_mask; <answer> = 
port->scfg = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*port->scfg), 
<token> (!port->scfg) <answer> if 
port->scfg->minor_version = <token> <answer> AFE_API_VERSION_SLOT_MAPPING_CONFIG; 
<token> = cfg->num_channels; <answer> port->scfg->num_channels 
<token> = cfg->bit_width; <answer> port->scfg->bitwidth 
port->scfg->data_align_type = <token> <answer> cfg->data_align_type; 
<token> cfg->ch_mapping, <answer> memcpy(port->scfg->ch_mapping, 
<token> * AFE_PORT_MAX_AUDIO_CHAN_CNT); <answer> sizeof(u16) 
void <token> q6afe_port *port, <answer> q6afe_hdmi_port_prepare(struct 
struct <token> *cfg) <answer> q6afe_hdmi_cfg 
union afe_port_config *pcfg = <token> <answer> &port->port_cfg; 
<token> = <answer> pcfg->hdmi_multi_ch.hdmi_cfg_minor_version 
pcfg->hdmi_multi_ch.datatype = <token> <answer> cfg->datatype; 
<token> = cfg->channel_allocation; <answer> pcfg->hdmi_multi_ch.channel_allocation 
pcfg->hdmi_multi_ch.sample_rate = <token> <answer> cfg->sample_rate; 
pcfg->hdmi_multi_ch.bit_width = <token> <answer> cfg->bit_width; 
int q6afe_i2s_port_prepare(struct q6afe_port *port, <token> q6afe_i2s_cfg *cfg) <answer> struct 
union afe_port_config *pcfg <token> &port->port_cfg; <answer> = 
struct device *dev <token> port->afe->dev; <answer> = 
<token> num_sd_lines; <answer> int 
pcfg->i2s_cfg.i2s_cfg_minor_version <token> AFE_API_VERSION_I2S_CONFIG; <answer> = 
pcfg->i2s_cfg.sample_rate = <token> <answer> cfg->sample_rate; 
pcfg->i2s_cfg.bit_width = <token> <answer> cfg->bit_width; 
pcfg->i2s_cfg.data_format = <token> <answer> AFE_LINEAR_PCM_DATA; 
switch (cfg->fmt & SND_SOC_DAIFMT_CLOCK_PROVIDER_MASK) <token> <answer> { 
case <token> <answer> SND_SOC_DAIFMT_BP_FP: 
<token> = AFE_PORT_CONFIG_I2S_WS_SRC_INTERNAL; <answer> pcfg->i2s_cfg.ws_src 
case <token> <answer> SND_SOC_DAIFMT_BC_FC: 
void q6afe_cdc_dma_port_prepare(struct q6afe_port <token> <answer> *port, 
<token> q6afe_cdc_dma_cfg *cfg) <answer> struct 
union afe_port_config <token> = &port->port_cfg; <answer> *pcfg 
struct afe_param_id_cdc_dma_cfg *dma_cfg = <token> <answer> &pcfg->dma_cfg; 
dma_cfg->cdc_dma_cfg_minor_version = <token> <answer> AFE_API_VERSION_CODEC_DMA_CONFIG; 
dma_cfg->sample_rate <token> cfg->sample_rate; <answer> = 
<token> = cfg->bit_width; <answer> dma_cfg->bit_width 
dma_cfg->data_format = <token> <answer> cfg->data_format; 
dma_cfg->num_channels <token> cfg->num_channels; <answer> = 
if <token> <answer> (!cfg->active_channels_mask) 
dma_cfg->active_channels_mask <token> (1 << cfg->num_channels) - 1; <answer> = 
int <token> q6afe_port *port) <answer> q6afe_port_start(struct 
struct afe_port_cmd_device_start <token> <answer> *start; 
struct q6afe *afe = <token> <answer> port->afe; 
int <token> = port->id; <answer> port_id 
<token> ret, param_id = port->cfg_type; <answer> int 
<token> apr_pkt *pkt; <answer> struct 
int <token> <answer> pkt_size; 
void <token> <answer> *p; 
ret = <token> &port->port_cfg, param_id, <answer> q6afe_port_set_param_v2(port, 
<token> (ret) { <answer> if 
dev_err(afe->dev, <token> enable for port 0x%x failed %d\n", <answer> "AFE 
port_id, <token> <answer> ret); 
return <token> <answer> ret; 
if (port->scfg) <token> <answer> { 
<token> = q6afe_port_set_param_v2(port, port->scfg, <answer> ret 
AFE_MODULE_TDM, <token> <answer> sizeof(*port->scfg)); 
if (ret) <token> <answer> { 
dev_err(afe->dev, "AFE enable <token> port 0x%x failed %d\n", <answer> for 
port_id, <token> <answer> ret); 
return <token> <answer> ret; 
<token> = APR_HDR_SIZE + sizeof(*start); <answer> pkt_size 
p = <token> GFP_KERNEL); <answer> kzalloc(pkt_size, 
<token> (!p) <answer> if 
<token> -ENOMEM; <answer> return 
pkt <token> p; <answer> = 
start = p + <token> <answer> APR_HDR_SIZE; 
<token> = APR_HDR_FIELD(APR_MSG_TYPE_SEQ_CMD, <answer> pkt->hdr.hdr_field 
pkt->hdr.pkt_size <token> pkt_size; <answer> = 
pkt->hdr.src_port = <token> <answer> 0; 
<token> = 0; <answer> pkt->hdr.dest_port 
<token> = port->token; <answer> pkt->hdr.token 
pkt->hdr.opcode <token> AFE_PORT_CMD_DEVICE_START; <answer> = 
<token> = port_id; <answer> start->port_id 
ret = <token> pkt, port, AFE_PORT_CMD_DEVICE_START); <answer> afe_apr_send_pkt(afe, 
<token> (ret) <answer> if 
dev_err(afe->dev, "AFE enable <token> port 0x%x failed %d\n", <answer> for 
<token> ret); <answer> port_id, 
<token> ret; <answer> return 
struct q6afe_port *q6afe_port_get_from_id(struct device <token> int id) <answer> *dev, 
<token> port_id; <answer> int 
struct q6afe <token> = dev_get_drvdata(dev->parent); <answer> *afe 
<token> q6afe_port *port; <answer> struct 
<token> long flags; <answer> unsigned 
int <token> <answer> cfg_type; 
<token> (id < 0 || id >= AFE_PORT_MAX) { <answer> if 
dev_err(dev, "AFE <token> token[%d] invalid!\n", id); <answer> port 
return <token> <answer> ERR_PTR(-EINVAL); 
void <token> q6afe_port *port) <answer> q6afe_port_put(struct 
kref_put(&port->refcount, <token> <answer> q6afe_port_free); 
int <token> device *dev, uint32_t hw_block_id, <answer> q6afe_unvote_lpass_core_hw(struct 
uint32_t <token> <answer> client_handle) 
struct q6afe *afe <token> dev_get_drvdata(dev->parent); <answer> = 
<token> afe_cmd_remote_lpass_core_hw_devote_request *vote_cfg; <answer> struct 
<token> apr_pkt *pkt; <answer> struct 
int ret = <token> <answer> 0; 
<token> pkt_size; <answer> int 
void <token> <answer> *p; 
pkt_size = <token> + sizeof(*vote_cfg); <answer> APR_HDR_SIZE 
<token> = kzalloc(pkt_size, GFP_KERNEL); <answer> p 
<token> (!p) <answer> if 
<token> -ENOMEM; <answer> return 
pkt <token> p; <answer> = 
vote_cfg = p <token> APR_HDR_SIZE; <answer> + 
pkt->hdr.hdr_field <token> APR_HDR_FIELD(APR_MSG_TYPE_SEQ_CMD, <answer> = 
pkt->hdr.pkt_size <token> pkt_size; <answer> = 
pkt->hdr.src_port = <token> <answer> 0; 
<token> = 0; <answer> pkt->hdr.dest_port 
pkt->hdr.token = <token> <answer> hw_block_id; 
<token> = AFE_CMD_REMOTE_LPASS_CORE_HW_DEVOTE_REQUEST; <answer> pkt->hdr.opcode 
vote_cfg->hw_block_id <token> hw_block_id; <answer> = 
vote_cfg->client_handle = <token> <answer> client_handle; 
ret = apr_send_pkt(afe->apr, <token> <answer> pkt); 
if (ret < <token> <answer> 0) 
dev_err(afe->dev, "AFE failed to unvote (%d)\n", <token> <answer> hw_block_id); 
return <token> <answer> ret; 
int q6afe_vote_lpass_core_hw(struct device <token> uint32_t hw_block_id, <answer> *dev, 
const char <token> uint32_t *client_handle) <answer> *client_name, 
<token> q6afe *afe = dev_get_drvdata(dev->parent); <answer> struct 
<token> afe_cmd_remote_lpass_core_hw_vote_request *vote_cfg; <answer> struct 
struct <token> *pkt; <answer> apr_pkt 
int ret = <token> <answer> 0; 
<token> pkt_size; <answer> int 
void <token> <answer> *p; 
pkt_size = APR_HDR_SIZE <token> sizeof(*vote_cfg); <answer> + 
p = kzalloc(pkt_size, <token> <answer> GFP_KERNEL); 
<token> (!p) <answer> if 
return <token> <answer> -ENOMEM; 
pkt = <token> <answer> p; 
vote_cfg = <token> + APR_HDR_SIZE; <answer> p 
pkt->hdr.hdr_field <token> APR_HDR_FIELD(APR_MSG_TYPE_SEQ_CMD, <answer> = 
pkt->hdr.pkt_size = <token> <answer> pkt_size; 
<token> = 0; <answer> pkt->hdr.src_port 
<token> = 0; <answer> pkt->hdr.dest_port 
pkt->hdr.token = <token> <answer> hw_block_id; 
pkt->hdr.opcode <token> AFE_CMD_REMOTE_LPASS_CORE_HW_VOTE_REQUEST; <answer> = 
vote_cfg->hw_block_id = <token> <answer> hw_block_id; 
<token> client_name, <answer> strscpy(vote_cfg->client_name, 
<token> = afe_apr_send_pkt(afe, pkt, NULL, <answer> ret 
if <token> <answer> (ret) 
dev_err(afe->dev, <token> failed to vote (%d)\n", hw_block_id); <answer> "AFE 
return <token> <answer> ret; 
static <token> q6afe_probe(struct apr_device *adev) <answer> int 
struct q6afe <token> <answer> *afe; 
struct device <token> = &adev->dev; <answer> *dev 
afe = <token> sizeof(*afe), GFP_KERNEL); <answer> devm_kzalloc(dev, 
if <token> <answer> (!afe) 
return <token> <answer> -ENOMEM; 
<token> &afe->ainfo); <answer> q6core_get_svc_api_info(adev->svc_id, 
<token> = adev; <answer> afe->apr 
afe->dev = <token> <answer> dev; 
dev_set_drvdata(dev, <token> <answer> afe); 
return <token> <answer> devm_of_platform_populate(dev); 
#ifdef <token> <answer> CONFIG_OF 
static const <token> of_device_id q6afe_device_id[] = { <answer> struct 
{ <token> = "qcom,q6afe" }, <answer> .compatible 
MODULE_DEVICE_TABLE(of, <token> <answer> q6afe_device_id); 
static struct apr_driver qcom_q6afe_driver = <token> <answer> { 
.probe <token> q6afe_probe, <answer> = 
<token> = q6afe_callback, <answer> .callback 
.driver = <token> <answer> { 
<token> = "qcom-q6afe", <answer> .name 
.of_match_table = <token> <answer> of_match_ptr(q6afe_device_id), 
MODULE_DESCRIPTION("Q6 <token> Front End"); <answer> Audio 
MODULE_LICENSE("GPL <token> <answer> v2"); 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/idr.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/vdpa.h> <answer> #include 
#include <token> <answer> <uapi/linux/vdpa.h> 
#include <token> <answer> <net/genetlink.h> 
#include <token> <answer> <linux/mod_devicetable.h> 
<token> <linux/virtio_ids.h> <answer> #include 
static <token> <answer> LIST_HEAD(mdev_head); 
<token> vdpa_device *__vdpa_alloc_device(struct device *parent, <answer> struct 
<token> struct vdpa_config_ops *config, <answer> const 
unsigned <token> ngroups, unsigned int nas, <answer> int 
size_t size, const <token> *name, <answer> char 
bool <token> <answer> use_va) 
struct <token> *vdev; <answer> vdpa_device 
<token> err = -EINVAL; <answer> int 
if <token> <answer> (!config) 
<token> err; <answer> goto 
if (!!config->dma_map <token> !!config->dma_unmap) <answer> != 
goto <token> <answer> err; 
int <token> vdpa_device *vdev, u32 nvqs) <answer> _vdpa_register_device(struct 
if <token> <answer> (!vdev->mdev) 
<token> -EINVAL; <answer> return 
return <token> nvqs); <answer> __vdpa_register_device(vdev, 
<token> vdpa_register_device(struct vdpa_device *vdev, u32 nvqs) <answer> int 
<token> err; <answer> int 
err = <token> nvqs); <answer> __vdpa_register_device(vdev, 
return <token> <answer> err; 
<token> _vdpa_unregister_device(struct vdpa_device *vdev) <answer> void 
<token> vdpa_unregister_device(struct vdpa_device *vdev) <answer> void 
int __vdpa_register_driver(struct <token> *drv, struct module *owner) <answer> vdpa_driver 
drv->driver.bus = <token> <answer> &vdpa_bus; 
drv->driver.owner = <token> <answer> owner; 
return <token> <answer> driver_register(&drv->driver); 
void <token> vdpa_driver *drv) <answer> vdpa_unregister_driver(struct 
int <token> vdpa_mgmt_dev *mdev) <answer> vdpa_mgmtdev_register(struct 
if (!mdev->device || !mdev->ops || !mdev->ops->dev_add <token> !mdev->ops->dev_del) <answer> || 
<token> -EINVAL; <answer> return 
list_add_tail(&mdev->list, <token> <answer> &mdev_head); 
return <token> <answer> 0; 
static int vdpa_match_remove(struct device *dev, void <token> <answer> *data) 
struct vdpa_device *vdev = <token> struct vdpa_device, dev); <answer> container_of(dev, 
<token> vdpa_mgmt_dev *mdev = vdev->mdev; <answer> struct 
<token> (mdev == data) <answer> if 
<token> vdev); <answer> mdev->ops->dev_del(mdev, 
return <token> <answer> 0; 
<token> vdpa_mgmtdev_unregister(struct vdpa_mgmt_dev *mdev) <answer> void 
<token> (!vdev->features_valid) <answer> if 
<token> 0); <answer> vdpa_set_features_unlocked(vdev, 
ops->get_config(vdev, offset, buf, <token> <answer> len); 
void vdpa_get_config(struct vdpa_device *vdev, <token> int offset, <answer> unsigned 
void <token> unsigned int len) <answer> *buf, 
vdpa_get_config_unlocked(vdev, <token> buf, len); <answer> offset, 
void <token> vdpa_device *vdev, unsigned int offset, <answer> vdpa_set_config(struct 
const void *buf, <token> int length) <answer> unsigned 
<token> offset, buf, length); <answer> vdev->config->set_config(vdev, 
static bool mgmtdev_handle_match(const struct vdpa_mgmt_dev <token> <answer> *mdev, 
const <token> *busname, const char *devname) <answer> char 
if ((busname && !mdev->device->bus) || <token> && mdev->device->bus)) <answer> (!busname 
<token> false; <answer> return 
if <token> && strcmp(dev_name(mdev->device), devname) == 0) <answer> (!busname 
return <token> <answer> true; 
if (busname && (strcmp(mdev->device->bus->name, busname) == 0) <token> <answer> && 
<token> devname) == 0)) <answer> (strcmp(dev_name(mdev->device), 
return <token> <answer> true; 
<token> false; <answer> return 
<token> struct vdpa_mgmt_dev *vdpa_mgmtdev_get_from_attr(struct nlattr **attrs) <answer> static 
struct <token> *mdev; <answer> vdpa_mgmt_dev 
const char <token> = NULL; <answer> *busname 
const char <token> <answer> *devname; 
if <token> <answer> (!attrs[VDPA_ATTR_MGMTDEV_DEV_NAME]) 
<token> ERR_PTR(-EINVAL); <answer> return 
<token> = nla_data(attrs[VDPA_ATTR_MGMTDEV_DEV_NAME]); <answer> devname 
<token> (attrs[VDPA_ATTR_MGMTDEV_BUS_NAME]) <answer> if 
busname <token> nla_data(attrs[VDPA_ATTR_MGMTDEV_BUS_NAME]); <answer> = 
list_for_each_entry(mdev, &mdev_head, list) <token> <answer> { 
if (mgmtdev_handle_match(mdev, <token> devname)) <answer> busname, 
<token> mdev; <answer> return 
return <token> <answer> ERR_PTR(-ENODEV); 
static int vdpa_nl_mgmtdev_handle_fill(struct sk_buff <token> const struct vdpa_mgmt_dev *mdev) <answer> *msg, 
if <token> && <answer> (mdev->device->bus 
<token> VDPA_ATTR_MGMTDEV_BUS_NAME, mdev->device->bus->name)) <answer> nla_put_string(msg, 
return <token> <answer> -EMSGSIZE; 
<token> (nla_put_string(msg, VDPA_ATTR_MGMTDEV_DEV_NAME, dev_name(mdev->device))) <answer> if 
return <token> <answer> -EMSGSIZE; 
<token> 0; <answer> return 
static u64 vdpa_mgmtdev_get_classes(const <token> vdpa_mgmt_dev *mdev, <answer> struct 
<token> int *nclasses) <answer> unsigned 
u64 <token> = 0; <answer> supported_classes 
unsigned int n <token> 0; <answer> = 
for (int i = <token> mdev->id_table[i].device; i++) { <answer> 0; 
<token> (mdev->id_table[i].device > 63) <answer> if 
supported_classes |= <token> <answer> BIT_ULL(mdev->id_table[i].device); 
if <token> <answer> (nclasses) 
<token> = n; <answer> *nclasses 
<token> supported_classes; <answer> return 
static int <token> struct vdpa_mgmt_dev *mdev, struct sk_buff *msg, <answer> vdpa_mgmtdev_fill(const 
u32 portid, u32 <token> int flags) <answer> seq, 
<token> *hdr; <answer> void 
<token> err; <answer> int 
hdr = genlmsg_put(msg, <token> seq, &vdpa_nl_family, flags, VDPA_CMD_MGMTDEV_NEW); <answer> portid, 
<token> (!hdr) <answer> if 
return <token> <answer> -EMSGSIZE; 
err <token> vdpa_nl_mgmtdev_handle_fill(msg, mdev); <answer> = 
if <token> <answer> (err) 
<token> msg_err; <answer> goto 
if (nla_put_u64_64bit(msg, <token> <answer> VDPA_ATTR_MGMTDEV_SUPPORTED_CLASSES, 
vdpa_mgmtdev_get_classes(mdev, <token> <answer> NULL), 
VDPA_ATTR_UNSPEC)) <token> <answer> { 
err <token> -EMSGSIZE; <answer> = 
goto <token> <answer> msg_err; 
<token> (nla_put_u32(msg, VDPA_ATTR_DEV_MGMTDEV_MAX_VQS, <answer> if 
mdev->max_supported_vqs)) <token> <answer> { 
<token> = -EMSGSIZE; <answer> err 
<token> msg_err; <answer> goto 
<token> (nla_put_u64_64bit(msg, VDPA_ATTR_DEV_SUPPORTED_FEATURES, <answer> if 
mdev->supported_features, VDPA_ATTR_PAD)) <token> <answer> { 
<token> = -EMSGSIZE; <answer> err 
goto <token> <answer> msg_err; 
<token> hdr); <answer> genlmsg_end(msg, 
return <token> <answer> 0; 
<token> hdr); <answer> genlmsg_cancel(msg, 
return <token> <answer> err; 
static int vdpa_nl_cmd_mgmtdev_get_doit(struct sk_buff *skb, struct genl_info <token> <answer> *info) 
<token> vdpa_mgmt_dev *mdev; <answer> struct 
<token> sk_buff *msg; <answer> struct 
int <token> <answer> err; 
msg = <token> GFP_KERNEL); <answer> nlmsg_new(NLMSG_DEFAULT_SIZE, 
<token> (!msg) <answer> if 
return <token> <answer> -ENOMEM; 
mdev <token> vdpa_mgmtdev_get_from_attr(info->attrs); <answer> = 
if <token> { <answer> (IS_ERR(mdev)) 
<token> "Fail to find the specified mgmt device"); <answer> NL_SET_ERR_MSG_MOD(info->extack, 
err <token> PTR_ERR(mdev); <answer> = 
goto <token> <answer> out; 
err = vdpa_mgmtdev_fill(mdev, <token> info->snd_portid, info->snd_seq, 0); <answer> msg, 
<token> (err) <answer> if 
<token> out; <answer> goto 
err = <token> info); <answer> genlmsg_reply(msg, 
<token> err; <answer> return 
return <token> <answer> err; 
<token> int <answer> static 
vdpa_nl_cmd_mgmtdev_get_dumpit(struct <token> *msg, struct netlink_callback *cb) <answer> sk_buff 
<token> vdpa_mgmt_dev *mdev; <answer> struct 
<token> start = cb->args[0]; <answer> int 
int idx <token> 0; <answer> = 
int <token> <answer> err; 
list_for_each_entry(mdev, &mdev_head, list) <token> <answer> { 
if (idx < <token> { <answer> start) 
err <token> vdpa_mgmtdev_fill(mdev, msg, NETLINK_CB(cb->skb).portid, <answer> = 
<token> NLM_F_MULTI); <answer> cb->nlh->nlmsg_seq, 
<token> (err) <answer> if 
goto <token> <answer> out; 
<token> = idx; <answer> cb->args[0] 
<token> msg->len; <answer> return 
#define VDPA_DEV_NET_ATTRS_MASK (BIT_ULL(VDPA_ATTR_DEV_NET_CFG_MACADDR) | <token> <answer> \ 
BIT_ULL(VDPA_ATTR_DEV_NET_CFG_MTU) <token> \ <answer> | 
#define VIRTIO_DEVICE_F_MASK (~0ULL << (VIRTIO_TRANSPORT_F_END + <token> | \ <answer> 1) 
((1ULL <token> VIRTIO_TRANSPORT_F_START) - 1)) <answer> << 
static int vdpa_nl_cmd_dev_add_set_doit(struct sk_buff <token> struct genl_info *info) <answer> *skb, 
struct <token> config = {}; <answer> vdpa_dev_set_config 
struct nlattr **nl_attrs = <token> <answer> info->attrs; 
struct <token> *mdev; <answer> vdpa_mgmt_dev 
unsigned int ncls <token> 0; <answer> = 
const <token> *macaddr; <answer> u8 
const char <token> <answer> *name; 
<token> classes; <answer> u64 
int err <token> 0; <answer> = 
if <token> <answer> (!info->attrs[VDPA_ATTR_DEV_NAME]) 
return <token> <answer> -EINVAL; 
name <token> nla_data(info->attrs[VDPA_ATTR_DEV_NAME]); <answer> = 
<token> (nl_attrs[VDPA_ATTR_DEV_NET_CFG_MACADDR]) { <answer> if 
macaddr = <token> <answer> nla_data(nl_attrs[VDPA_ATTR_DEV_NET_CFG_MACADDR]); 
memcpy(config.net.mac, macaddr, <token> <answer> sizeof(config.net.mac)); 
config.mask <token> BIT_ULL(VDPA_ATTR_DEV_NET_CFG_MACADDR); <answer> |= 
if <token> { <answer> (nl_attrs[VDPA_ATTR_DEV_NET_CFG_MTU]) 
config.net.mtu <token> <answer> = 
config.mask <token> BIT_ULL(VDPA_ATTR_DEV_NET_CFG_MTU); <answer> |= 
if <token> { <answer> (nl_attrs[VDPA_ATTR_DEV_NET_CFG_MAX_VQP]) 
config.net.max_vq_pairs <token> <answer> = 
if (!config.net.max_vq_pairs) <token> <answer> { 
"At <token> one pair of VQs is required"); <answer> least 
<token> -EINVAL; <answer> return 
config.mask <token> BIT_ULL(VDPA_ATTR_DEV_NET_CFG_MAX_VQP); <answer> |= 
if (nl_attrs[VDPA_ATTR_DEV_FEATURES]) <token> <answer> { 
<token> missing = 0x0ULL; <answer> u64 
<token> = <answer> config.device_features 
<token> (nl_attrs[VDPA_ATTR_DEV_NET_CFG_MACADDR] && <answer> if 
!(config.device_features & <token> <answer> BIT_ULL(VIRTIO_NET_F_MAC))) 
missing <token> BIT_ULL(VIRTIO_NET_F_MAC); <answer> |= 
<token> (nl_attrs[VDPA_ATTR_DEV_NET_CFG_MTU] && <answer> if 
!(config.device_features <token> BIT_ULL(VIRTIO_NET_F_MTU))) <answer> & 
<token> |= BIT_ULL(VIRTIO_NET_F_MTU); <answer> missing 
if <token> && <answer> (nl_attrs[VDPA_ATTR_DEV_NET_CFG_MAX_VQP] 
config.net.max_vq_pairs > <token> && <answer> 1 
<token> & BIT_ULL(VIRTIO_NET_F_MQ))) <answer> !(config.device_features 
<token> |= BIT_ULL(VIRTIO_NET_F_MQ); <answer> missing 
if (missing) <token> <answer> { 
"Missing features 0x%llx for provided <token> <answer> attributes", 
<token> -EINVAL; <answer> return 
config.mask <token> BIT_ULL(VDPA_ATTR_DEV_FEATURES); <answer> |= 
if ((config.mask & <token> && <answer> VDPA_DEV_NET_ATTRS_MASK) 
!netlink_capable(skb, <token> <answer> CAP_NET_ADMIN)) 
<token> -EPERM; <answer> return 
<token> = vdpa_mgmtdev_get_from_attr(info->attrs); <answer> mdev 
<token> (IS_ERR(mdev)) { <answer> if 
NL_SET_ERR_MSG_MOD(info->extack, <token> to find the specified management device"); <answer> "Fail 
err = <token> <answer> PTR_ERR(mdev); 
goto <token> <answer> err; 
if ((config.mask & <token> != config.mask) { <answer> mdev->config_attr_mask) 
"Some <token> attributes are not supported: 0x%llx", <answer> provided 
<token> & ~mdev->config_attr_mask); <answer> config.mask 
<token> = -EOPNOTSUPP; <answer> err 
<token> err; <answer> goto 
classes = <token> &ncls); <answer> vdpa_mgmtdev_get_classes(mdev, 
if (config.mask <token> VDPA_DEV_NET_ATTRS_MASK && <answer> & 
!(classes & <token> { <answer> BIT_ULL(VIRTIO_ID_NET))) 
"Network class attributes provided on <token> management device"); <answer> unsupported 
err = <token> <answer> -EINVAL; 
goto <token> <answer> err; 
if (!(config.mask & <token> && <answer> VDPA_DEV_NET_ATTRS_MASK) 
<token> & BIT_ULL(VDPA_ATTR_DEV_FEATURES) && <answer> config.mask 
classes & BIT_ULL(VIRTIO_ID_NET) && <token> > 1 && <answer> ncls 
config.device_features & VIRTIO_DEVICE_F_MASK) <token> <answer> { 
"Management device supports multi-class while <token> features specified are ambiguous"); <answer> device 
err <token> -EINVAL; <answer> = 
goto <token> <answer> err; 
err = mdev->ops->dev_add(mdev, name, <token> <answer> &config); 
return <token> <answer> err; 
static <token> vdpa_nl_cmd_dev_del_set_doit(struct sk_buff *skb, struct genl_info *info) <answer> int 
struct vdpa_mgmt_dev <token> <answer> *mdev; 
struct vdpa_device <token> <answer> *vdev; 
struct device <token> <answer> *dev; 
<token> char *name; <answer> const 
int <token> = 0; <answer> err 
if <token> <answer> (!info->attrs[VDPA_ATTR_DEV_NAME]) 
<token> -EINVAL; <answer> return 
name <token> nla_data(info->attrs[VDPA_ATTR_DEV_NAME]); <answer> = 
dev = <token> NULL, name, vdpa_name_match); <answer> bus_find_device(&vdpa_bus, 
if <token> { <answer> (!dev) 
NL_SET_ERR_MSG_MOD(info->extack, "device <token> found"); <answer> not 
err = <token> <answer> -ENODEV; 
<token> dev_err; <answer> goto 
vdev = container_of(dev, <token> vdpa_device, dev); <answer> struct 
if <token> { <answer> (!vdev->mdev) 
<token> "Only user created device can be deleted by user"); <answer> NL_SET_ERR_MSG_MOD(info->extack, 
err = <token> <answer> -EINVAL; 
<token> mdev_err; <answer> goto 
<token> = vdev->mdev; <answer> mdev 
mdev->ops->dev_del(mdev, <token> <answer> vdev); 
<token> err; <answer> return 
<token> int <answer> static 
vdpa_dev_fill(struct vdpa_device *vdev, struct sk_buff <token> u32 portid, u32 seq, <answer> *msg, 
int flags, <token> netlink_ext_ack *extack) <answer> struct 
<token> max_vq_size; <answer> u16 
<token> min_vq_size = 1; <answer> u16 
u32 <token> <answer> device_id; 
u32 <token> <answer> vendor_id; 
void <token> <answer> *hdr; 
int <token> <answer> err; 
hdr = genlmsg_put(msg, <token> seq, &vdpa_nl_family, flags, VDPA_CMD_DEV_NEW); <answer> portid, 
if <token> <answer> (!hdr) 
return <token> <answer> -EMSGSIZE; 
err = vdpa_nl_mgmtdev_handle_fill(msg, <token> <answer> vdev->mdev); 
<token> (err) <answer> if 
goto <token> <answer> msg_err; 
device_id <token> vdev->config->get_device_id(vdev); <answer> = 
<token> = vdev->config->get_vendor_id(vdev); <answer> vendor_id 
max_vq_size = <token> <answer> vdev->config->get_vq_num_max(vdev); 
if <token> <answer> (vdev->config->get_vq_num_min) 
<token> = vdev->config->get_vq_num_min(vdev); <answer> min_vq_size 
err <token> -EMSGSIZE; <answer> = 
if (nla_put_string(msg, VDPA_ATTR_DEV_NAME, <token> <answer> dev_name(&vdev->dev))) 
<token> msg_err; <answer> goto 
if <token> VDPA_ATTR_DEV_ID, device_id)) <answer> (nla_put_u32(msg, 
<token> msg_err; <answer> goto 
if (nla_put_u32(msg, VDPA_ATTR_DEV_VENDOR_ID, <token> <answer> vendor_id)) 
goto <token> <answer> msg_err; 
if <token> VDPA_ATTR_DEV_MAX_VQS, vdev->nvqs)) <answer> (nla_put_u32(msg, 
<token> msg_err; <answer> goto 
if <token> VDPA_ATTR_DEV_MAX_VQ_SIZE, max_vq_size)) <answer> (nla_put_u16(msg, 
goto <token> <answer> msg_err; 
if (nla_put_u16(msg, <token> min_vq_size)) <answer> VDPA_ATTR_DEV_MIN_VQ_SIZE, 
<token> msg_err; <answer> goto 
genlmsg_end(msg, <token> <answer> hdr); 
<token> 0; <answer> return 
genlmsg_cancel(msg, <token> <answer> hdr); 
<token> err; <answer> return 
<token> int vdpa_nl_cmd_dev_get_doit(struct sk_buff *skb, struct genl_info *info) <answer> static 
struct <token> *vdev; <answer> vdpa_device 
struct sk_buff <token> <answer> *msg; 
<token> char *devname; <answer> const 
<token> device *dev; <answer> struct 
int <token> <answer> err; 
<token> (!info->attrs[VDPA_ATTR_DEV_NAME]) <answer> if 
return <token> <answer> -EINVAL; 
devname <token> nla_data(info->attrs[VDPA_ATTR_DEV_NAME]); <answer> = 
msg = nlmsg_new(NLMSG_DEFAULT_SIZE, <token> <answer> GFP_KERNEL); 
<token> (!msg) <answer> if 
return <token> <answer> -ENOMEM; 
dev = bus_find_device(&vdpa_bus, <token> devname, vdpa_name_match); <answer> NULL, 
if (!dev) <token> <answer> { 
<token> "device not found"); <answer> NL_SET_ERR_MSG_MOD(info->extack, 
<token> = -ENODEV; <answer> err 
<token> err; <answer> goto 
vdev = container_of(dev, struct <token> dev); <answer> vdpa_device, 
if (!vdev->mdev) <token> <answer> { 
err <token> -EINVAL; <answer> = 
<token> mdev_err; <answer> goto 
err = vdpa_dev_fill(vdev, msg, <token> info->snd_seq, 0, info->extack); <answer> info->snd_portid, 
<token> (err) <answer> if 
goto <token> <answer> mdev_err; 
err = genlmsg_reply(msg, <token> <answer> info); 
return <token> <answer> err; 
<token> err; <answer> return 
struct vdpa_dev_dump_info <token> <answer> { 
struct <token> *msg; <answer> sk_buff 
struct netlink_callback <token> <answer> *cb; 
int <token> <answer> start_idx; 
int <token> <answer> idx; 
static int vdpa_dev_dump(struct device *dev, void <token> <answer> *data) 
struct <token> *vdev = container_of(dev, struct vdpa_device, dev); <answer> vdpa_device 
struct vdpa_dev_dump_info *info = <token> <answer> data; 
<token> err; <answer> int 
<token> (!vdev->mdev) <answer> if 
return <token> <answer> 0; 
if (info->idx < info->start_idx) <token> <answer> { 
<token> 0; <answer> return 
err = vdpa_dev_fill(vdev, <token> NETLINK_CB(info->cb->skb).portid, <answer> info->msg, 
<token> NLM_F_MULTI, info->cb->extack); <answer> info->cb->nlh->nlmsg_seq, 
if <token> <answer> (err) 
return <token> <answer> err; 
<token> 0; <answer> return 
static int vdpa_nl_cmd_dev_get_dumpit(struct sk_buff *msg, <token> netlink_callback *cb) <answer> struct 
<token> vdpa_dev_dump_info info; <answer> struct 
<token> = msg; <answer> info.msg 
<token> = cb; <answer> info.cb 
info.start_idx <token> cb->args[0]; <answer> = 
info.idx <token> 0; <answer> = 
bus_for_each_dev(&vdpa_bus, <token> &info, vdpa_dev_dump); <answer> NULL, 
cb->args[0] = <token> <answer> info.idx; 
return <token> <answer> msg->len; 
static int <token> sk_buff *msg, u64 features, <answer> vdpa_dev_net_mq_config_fill(struct 
const <token> virtio_net_config *config) <answer> struct 
u16 <token> <answer> val_u16; 
if ((features & BIT_ULL(VIRTIO_NET_F_MQ)) == 0 <token> <answer> && 
(features & BIT_ULL(VIRTIO_NET_F_RSS)) <token> 0) <answer> == 
return <token> <answer> 0; 
<token> = __virtio16_to_cpu(true, config->max_virtqueue_pairs); <answer> val_u16 
return nla_put_u16(msg, <token> val_u16); <answer> VDPA_ATTR_DEV_NET_CFG_MAX_VQP, 
static int vdpa_dev_net_mtu_config_fill(struct <token> *msg, u64 features, <answer> sk_buff 
const struct virtio_net_config <token> <answer> *config) 
u16 <token> <answer> val_u16; 
if <token> & BIT_ULL(VIRTIO_NET_F_MTU)) == 0) <answer> ((features 
<token> 0; <answer> return 
val_u16 = <token> config->mtu); <answer> __virtio16_to_cpu(true, 
<token> nla_put_u16(msg, VDPA_ATTR_DEV_NET_CFG_MTU, val_u16); <answer> return 
<token> int vdpa_dev_net_mac_config_fill(struct sk_buff *msg, u64 features, <answer> static 
const struct virtio_net_config <token> <answer> *config) 
if ((features & BIT_ULL(VIRTIO_NET_F_MAC)) == <token> <answer> 0) 
<token> 0; <answer> return 
return <token> VDPA_ATTR_DEV_NET_CFG_MACADDR, <answer> nla_put(msg, 
sizeof(config->mac), <token> <answer> config->mac); 
static int <token> sk_buff *msg, u64 features, <answer> vdpa_dev_net_status_config_fill(struct 
const struct <token> *config) <answer> virtio_net_config 
<token> val_u16; <answer> u16 
<token> ((features & BIT_ULL(VIRTIO_NET_F_STATUS)) == 0) <answer> if 
return <token> <answer> 0; 
val_u16 <token> __virtio16_to_cpu(true, config->status); <answer> = 
return nla_put_u16(msg, VDPA_ATTR_DEV_NET_STATUS, <token> <answer> val_u16); 
<token> int vdpa_dev_net_config_fill(struct vdpa_device *vdev, struct sk_buff *msg) <answer> static 
struct virtio_net_config config <token> {}; <answer> = 
<token> features_device; <answer> u64 
vdev->config->get_config(vdev, <token> &config, sizeof(config)); <answer> 0, 
features_device <token> vdev->config->get_device_features(vdev); <answer> = 
if <token> VDPA_ATTR_DEV_FEATURES, features_device, <answer> (nla_put_u64_64bit(msg, 
<token> -EMSGSIZE; <answer> return 
if (vdpa_dev_net_mtu_config_fill(msg, <token> &config)) <answer> features_device, 
return <token> <answer> -EMSGSIZE; 
if <token> features_device, &config)) <answer> (vdpa_dev_net_mac_config_fill(msg, 
return <token> <answer> -EMSGSIZE; 
<token> (vdpa_dev_net_status_config_fill(msg, features_device, &config)) <answer> if 
<token> -EMSGSIZE; <answer> return 
return vdpa_dev_net_mq_config_fill(msg, <token> &config); <answer> features_device, 
static <token> <answer> int 
vdpa_dev_blk_capacity_config_fill(struct sk_buff <token> <answer> *msg, 
<token> struct virtio_blk_config *config) <answer> const 
<token> val_u64; <answer> u64 
val_u64 = __virtio64_to_cpu(true, <token> <answer> config->capacity); 
return nla_put_u64_64bit(msg, <token> <answer> VDPA_ATTR_DEV_BLK_CFG_CAPACITY, 
<token> VDPA_ATTR_PAD); <answer> val_u64, 
<token> int <answer> static 
vdpa_dev_blk_seg_size_config_fill(struct sk_buff <token> u64 features, <answer> *msg, 
const <token> virtio_blk_config *config) <answer> struct 
<token> val_u32; <answer> u32 
if ((features & BIT_ULL(VIRTIO_BLK_F_SIZE_MAX)) == <token> <answer> 0) 
<token> 0; <answer> return 
val_u32 = __virtio32_to_cpu(true, <token> <answer> config->size_max); 
return <token> VDPA_ATTR_DEV_BLK_CFG_SIZE_MAX, val_u32); <answer> nla_put_u32(msg, 
<token> DEBUG <answer> #undef 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <linux/clk-provider.h> 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/clk/ti.h> 
#include <token> <answer> <asm/div64.h> 
#include <token> <answer> "clock.h" 
#define DPLL_SCALE_FACTOR <token> <answer> 64 
#define DPLL_SCALE_BASE <token> <answer> 2 
#define DPLL_ROUNDING_VAL ((DPLL_SCALE_BASE <token> 2) * \ <answer> / 
(DPLL_SCALE_FACTOR <token> DPLL_SCALE_BASE)) <answer> / 
#define <token> 500000 <answer> OMAP3PLUS_DPLL_FINT_JTYPE_MIN 
#define OMAP3PLUS_DPLL_FINT_JTYPE_MAX <token> <answer> 2500000 
static int _dpll_test_fint(struct clk_hw_omap *clk, unsigned int <token> <answer> n) 
struct <token> *dd; <answer> dpll_data 
long fint, <token> fint_max; <answer> fint_min, 
<token> ret = 0; <answer> int 
<token> = clk->dpll_data; <answer> dd 
<token> int _dpll_test_mult(int *m, int n, unsigned long *new_rate, <answer> static 
unsigned <token> target_rate, <answer> long 
unsigned <token> parent_rate) <answer> long 
int r = <token> carry = 0; <answer> 0, 
*new_rate = _dpll_compute_new_rate(parent_rate, *m, <token> <answer> n); 
if (*new_rate <token> target_rate) { <answer> > 
*new_rate = <token> <answer> 0; 
<token> int _omap2_dpll_is_in_bypass(u32 v) <answer> static 
u8 mask, <token> <answer> val; 
<token> = ti_clk_get_features()->dpll_bypass_vals; <answer> mask 
<token> (mask) { <answer> while 
<token> = __ffs(mask); <answer> val 
<token> ^= (1 << val); <answer> mask 
if (v == <token> <answer> val) 
return <token> <answer> 1; 
return <token> <answer> 0; 
unsigned long omap2_get_dpll_rate(struct clk_hw_omap <token> <answer> *clk) 
u64 <token> <answer> dpll_clk; 
u32 <token> dpll_div, v; <answer> dpll_mult, 
struct <token> *dd; <answer> dpll_data 
<token> = clk->dpll_data; <answer> dd 
if <token> <answer> (!dd) 
return <token> <answer> 0; 
long omap2_dpll_round_rate(struct clk_hw <token> unsigned long target_rate, <answer> *hw, 
unsigned <token> *parent_rate) <answer> long 
struct clk_hw_omap *clk = <token> <answer> to_clk_hw_omap(hw); 
int m, n, <token> scaled_max_m; <answer> r, 
int min_delta_m = INT_MAX, <token> = INT_MAX; <answer> min_delta_n 
<token> long scaled_rt_rp; <answer> unsigned 
unsigned long new_rate = <token> <answer> 0; 
struct dpll_data <token> <answer> *dd; 
<token> long ref_rate; <answer> unsigned 
long <token> <answer> delta; 
long <token> = LONG_MAX; <answer> prev_min_delta 
const char <token> <answer> *clk_name; 
if <token> || !clk->dpll_data) <answer> (!clk 
<token> ~0; <answer> return 
<token> = clk->dpll_data; <answer> dd 
<token> (dd->max_rate && target_rate > dd->max_rate) <answer> if 
<token> = dd->max_rate; <answer> target_rate 
<token> = clk_hw_get_rate(dd->clk_ref); <answer> ref_rate 
clk_name = <token> <answer> clk_hw_get_name(hw); 
<token> %s: starting DPLL round_rate, target rate %lu\n", <answer> pr_debug("clock: 
<token> target_rate); <answer> clk_name, 
scaled_rt_rp = target_rate / (ref_rate / <token> <answer> DPLL_SCALE_FACTOR); 
scaled_max_m = dd->max_multiplier <token> DPLL_SCALE_FACTOR; <answer> * 
dd->last_rounded_rate = <token> <answer> 0; 
for (n = dd->min_divider; n <token> dd->max_divider; n++) { <answer> <= 
if <token> > scaled_max_m) <answer> (m 
r <token> _dpll_test_mult(&m, n, &new_rate, target_rate, <answer> = 
<token> <misc/cxl.h> <answer> #include 
#include <token> <answer> "backend.h" 
static void __iomem *cxlflash_psa_map(void <token> <answer> *ctx_cookie) 
return <token> <answer> cxl_psa_map(ctx_cookie); 
static void cxlflash_psa_unmap(void __iomem <token> <answer> *addr) 
static <token> cxlflash_process_element(void *ctx_cookie) <answer> int 
return <token> <answer> cxl_process_element(ctx_cookie); 
static int cxlflash_map_afu_irq(void *ctx_cookie, int <token> <answer> num, 
irq_handler_t handler, void *cookie, char <token> <answer> *name) 
<token> cxl_map_afu_irq(ctx_cookie, num, handler, cookie, name); <answer> return 
static void cxlflash_unmap_afu_irq(void *ctx_cookie, int num, void <token> <answer> *cookie) 
<token> num, cookie); <answer> cxl_unmap_afu_irq(ctx_cookie, 
static u64 cxlflash_get_irq_objhndl(void *ctx_cookie, <token> irq) <answer> int 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/pci.h> <answer> #include 
<token> <linux/smp.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/dca.h> <answer> #include 
#define <token> 0x80 <answer> DCA_TAG_MAP_VALID 
<token> DCA3_TAG_MAP_BIT_TO_INV 0x80 <answer> #define 
#define DCA3_TAG_MAP_BIT_TO_SEL <token> <answer> 0x40 
<token> DCA3_TAG_MAP_LITERAL_VAL 0x1 <answer> #define 
#define <token> 0xDF <answer> DCA_TAG_MAP_MASK 
<token> APICID_BIT(x) (DCA_TAG_MAP_VALID | (x)) <answer> #define 
#define IOAT_TAG_MAP_LEN <token> <answer> 8 
return <token> == DCA_TAG_MAP_VALID) && <answer> ((tag_map[0] 
(tag_map[1] == DCA_TAG_MAP_VALID) <token> <answer> && 
(tag_map[2] <token> DCA_TAG_MAP_VALID) && <answer> == 
(tag_map[3] <token> DCA_TAG_MAP_VALID) && <answer> == 
<token> == DCA_TAG_MAP_VALID)); <answer> (tag_map[4] 
struct dca_provider *ioat_dca_init(struct pci_dev *pdev, void <token> *iobase) <answer> __iomem 
<token> dca_provider *dca; <answer> struct 
struct ioat_dca_priv <token> <answer> *ioatdca; 
<token> slots; <answer> int 
<token> i; <answer> int 
int <token> <answer> err; 
u16 <token> <answer> dca_offset; 
<token> csi_fsb_control; <answer> u16 
u16 <token> <answer> pcie_control; 
<token> bit; <answer> u8 
union <token> <answer> { 
<token> full; <answer> u64 
struct <token> <answer> { 
u32 <token> <answer> low; 
u32 <token> <answer> high; 
} <token> <answer> tag_map; 
if <token> <answer> (!system_has_dca_enabled(pdev)) 
return <token> <answer> NULL; 
dca_offset = <token> + IOAT_DCAOFFSET_OFFSET); <answer> readw(iobase 
if <token> == 0) <answer> (dca_offset 
<token> NULL; <answer> return 
slots = <token> dca_offset); <answer> ioat_dca_count_dca_slots(iobase, 
if <token> == 0) <answer> (slots 
<token> NULL; <answer> return 
dca = <token> <answer> alloc_dca_provider(&ioat_dca_ops, 
struct_size(ioatdca, <token> slots)); <answer> req_slots, 
if <token> <answer> (!dca) 
return <token> <answer> NULL; 
<token> = dca_priv(dca); <answer> ioatdca 
<token> = iobase; <answer> ioatdca->iobase 
ioatdca->dca_base = <token> + dca_offset; <answer> iobase 
ioatdca->max_requesters <token> slots; <answer> = 
<token> "dm_services.h" <answer> #include 
#include <token> <answer> "dm_services_types.h" 
<token> "virtual_link_encoder.h" <answer> #include 
static bool <token> <answer> virtual_link_encoder_validate_output_with_stream( 
struct <token> *enc, <answer> link_encoder 
const struct dc_stream_state *stream) { return true; <token> <answer> } 
static void virtual_link_encoder_hw_init(struct link_encoder <token> {} <answer> *enc) 
static void <token> <answer> virtual_link_encoder_setup( 
<token> link_encoder *enc, <answer> struct 
enum <token> signal) {} <answer> signal_type 
static <token> virtual_link_encoder_enable_tmds_output( <answer> void 
struct <token> *enc, <answer> link_encoder 
enum clock_source_id <token> <answer> clock_source, 
enum dc_color_depth <token> <answer> color_depth, 
<token> signal_type signal, <answer> enum 
uint32_t <token> {} <answer> pixel_clock) 
<token> void virtual_link_encoder_enable_dp_output( <answer> static 
struct link_encoder <token> <answer> *enc, 
const struct dc_link_settings <token> <answer> *link_settings, 
enum clock_source_id clock_source) <token> <answer> {} 
static void <token> <answer> virtual_link_encoder_enable_dp_mst_output( 
struct link_encoder <token> <answer> *enc, 
<token> struct dc_link_settings *link_settings, <answer> const 
enum <token> clock_source) {} <answer> clock_source_id 
<token> void virtual_link_encoder_disable_output( <answer> static 
struct <token> *link_enc, <answer> link_encoder 
enum signal_type <token> {} <answer> signal) 
static void <token> <answer> virtual_link_encoder_dp_set_lane_settings( 
<token> link_encoder *enc, <answer> struct 
<token> struct dc_link_settings *link_settings, <answer> const 
const struct dc_lane_settings <token> {} <answer> lane_settings[LANE_COUNT_DP_MAX]) 
static void <token> <answer> virtual_link_encoder_dp_set_phy_pattern( 
struct link_encoder <token> <answer> *enc, 
const struct <token> *param) {} <answer> encoder_set_dp_phy_pattern_param 
<token> void virtual_link_encoder_update_mst_stream_allocation_table( <answer> static 
struct link_encoder <token> <answer> *enc, 
<token> struct link_mst_stream_allocation_table *table) {} <answer> const 
static <token> virtual_link_encoder_connect_dig_be_to_fe( <answer> void 
<token> link_encoder *enc, <answer> struct 
enum engine_id <token> <answer> engine, 
<token> connect) {} <answer> bool 
static void <token> link_encoder **enc) <answer> virtual_link_encoder_destroy(struct 
*enc = <token> <answer> NULL; 
static void <token> link_encoder *enc, <answer> virtual_link_encoder_get_max_link_cap(struct 
struct dc_link_settings <token> <answer> *link_settings) 
#include <token> <answer> <linux/moduleparam.h> 
#include <token> <answer> "tfrc.h" 
#ifdef <token> <answer> CONFIG_IP_DCCP_TFRC_DEBUG 
<token> tfrc_debug; <answer> bool 
<token> bool, 0644); <answer> module_param(tfrc_debug, 
MODULE_PARM_DESC(tfrc_debug, <token> TFRC debug messages"); <answer> "Enable 
<token> __init tfrc_lib_init(void) <answer> int 
<token> rc = tfrc_li_init(); <answer> int 
<token> (rc) <answer> if 
<token> out; <answer> goto 
<token> = tfrc_tx_packet_history_init(); <answer> rc 
if <token> <answer> (rc) 
goto <token> <answer> out_free_loss_intervals; 
<token> = tfrc_rx_packet_history_init(); <answer> rc 
<token> (rc) <answer> if 
goto <token> <answer> out_free_tx_history; 
<token> 0; <answer> return 
<token> rc; <answer> return 
void <token> <answer> tfrc_lib_exit(void) 
#include <token> <answer> <linux/acpi.h> 
<token> <linux/completion.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/spi/spi.h> 
<token> <linux/tpm.h> <answer> #include 
#include <token> <answer> "tpm.h" 
#include <token> <answer> "tpm_tis_core.h" 
<token> "tpm_tis_spi.h" <answer> #include 
<token> MAX_SPI_FRAMESIZE 64 <answer> #define 
static int tpm_tis_spi_flow_control(struct tpm_tis_spi_phy <token> <answer> *phy, 
<token> spi_transfer *spi_xfer) <answer> struct 
struct <token> m; <answer> spi_message 
int <token> i; <answer> ret, 
if <token> & 0x01) == 0) { <answer> ((phy->iobuf[3] 
for (i = 0; <token> < TPM_RETRY; i++) { <answer> i 
spi_xfer->len <token> 1; <answer> = 
<token> &m); <answer> spi_message_add_tail(spi_xfer, 
ret = spi_sync_locked(phy->spi_device, <token> <answer> &m); 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
if (phy->iobuf[0] & <token> <answer> 0x01) 
<token> (i == TPM_RETRY) <answer> if 
<token> -ETIMEDOUT; <answer> return 
return <token> <answer> 0; 
<token> int tpm_tis_spi_transfer_half(struct tpm_tis_data *data, u32 addr, <answer> static 
u16 <token> u8 *in, const u8 *out) <answer> len, 
<token> tpm_tis_spi_phy *phy = to_tpm_tis_spi_phy(data); <answer> struct 
<token> spi_transfer spi_xfer[3]; <answer> struct 
<token> spi_message m; <answer> struct 
u8 <token> <answer> transfer_len; 
<token> ret; <answer> int 
while <token> { <answer> (len) 
<token> = min_t(u16, len, MAX_SPI_FRAMESIZE); <answer> transfer_len 
phy->iobuf[0] = (in ? <token> : 0) | (transfer_len - 1); <answer> 0x80 
<token> = 0xd4; <answer> phy->iobuf[1] 
phy->iobuf[2] = <token> >> 8; <answer> addr 
phy->iobuf[3] <token> addr; <answer> = 
<token> 0, sizeof(spi_xfer)); <answer> memset(&spi_xfer, 
spi_xfer[0].tx_buf <token> phy->iobuf; <answer> = 
spi_xfer[0].len = <token> <answer> 1; 
spi_message_add_tail(&spi_xfer[0], <token> <answer> &m); 
spi_xfer[1].tx_buf = <token> + 1; <answer> phy->iobuf 
<token> = 3; <answer> spi_xfer[1].len 
<token> &m); <answer> spi_message_add_tail(&spi_xfer[1], 
if <token> { <answer> (out) 
<token> = &phy->iobuf[4]; <answer> spi_xfer[2].tx_buf 
spi_xfer[2].rx_buf <token> NULL; <answer> = 
<token> out, transfer_len); <answer> memcpy(&phy->iobuf[4], 
<token> += transfer_len; <answer> out 
if <token> { <answer> (in) 
spi_xfer[2].tx_buf = <token> <answer> NULL; 
spi_xfer[2].rx_buf = <token> <answer> &phy->iobuf[4]; 
spi_xfer[2].len <token> transfer_len; <answer> = 
<token> &m); <answer> spi_message_add_tail(&spi_xfer[2], 
ret = <token> &m); <answer> spi_sync(phy->spi_device, 
if <token> < 0) <answer> (ret 
<token> ret; <answer> return 
if <token> { <answer> (in) 
memcpy(in, &phy->iobuf[4], <token> <answer> transfer_len); 
<token> += transfer_len; <answer> in 
len <token> transfer_len; <answer> -= 
return <token> <answer> ret; 
static int tpm_tis_spi_transfer_full(struct <token> *data, u32 addr, <answer> tpm_tis_data 
u16 len, u8 *in, const <token> *out) <answer> u8 
struct tpm_tis_spi_phy <token> = to_tpm_tis_spi_phy(data); <answer> *phy 
<token> ret = 0; <answer> int 
<token> spi_message m; <answer> struct 
struct spi_transfer <token> <answer> spi_xfer; 
u8 <token> <answer> transfer_len; 
while (len) <token> <answer> { 
<token> = min_t(u16, len, MAX_SPI_FRAMESIZE); <answer> transfer_len 
phy->iobuf[0] = (in ? 0x80 : 0) | <token> - 1); <answer> (transfer_len 
phy->iobuf[1] <token> 0xd4; <answer> = 
phy->iobuf[2] <token> addr >> 8; <answer> = 
