<token> <linux/anon_inodes.h> <answer> #include 
#include <token> <answer> <linux/dma-fence.h> 
#include <token> <answer> <linux/file.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/pci.h> <answer> #include 
#include <token> <answer> <linux/poll.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <drm/drm_client.h> 
#include <token> <answer> <drm/drm_drv.h> 
#include <token> <answer> <drm/drm_file.h> 
<token> <drm/drm_gem.h> <answer> #include 
<token> <drm/drm_print.h> <answer> #include 
<token> "drm_crtc_internal.h" <answer> #include 
#include <token> <answer> "drm_internal.h" 
if (dev->driver->load || <token> <answer> dev->driver->unload) 
<token> true; <answer> return 
if <token> <answer> (dev->driver->lastclose) 
return <token> <answer> true; 
return <token> <answer> false; 
struct drm_file *drm_file_alloc(struct drm_minor <token> <answer> *minor) 
<token> atomic64_t ident = ATOMIC_INIT(0); <answer> static 
struct <token> *dev = minor->dev; <answer> drm_device 
struct <token> *file; <answer> drm_file 
int <token> <answer> ret; 
file = kzalloc(sizeof(*file), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!file) 
return <token> <answer> ERR_PTR(-ENOMEM); 
void drm_file_free(struct <token> *file) <answer> drm_file 
struct <token> *dev; <answer> drm_device 
<token> (!file) <answer> if 
dev = <token> <answer> file->minor->dev; 
drm_dbg_core(dev, "comm=\"%s\", pid=%d, dev=0x%lx, <token> <answer> open_count=%d\n", 
<token> task_pid_nr(current), <answer> current->comm, 
if <token> DRIVER_MODESET)) { <answer> (drm_core_check_feature(dev, 
drm_property_destroy_user_blobs(dev, <token> <answer> file); 
if <token> DRIVER_SYNCOBJ)) <answer> (drm_core_check_feature(dev, 
if <token> DRIVER_GEM)) <answer> (drm_core_check_feature(dev, 
<token> file); <answer> drm_gem_release(dev, 
<token> (drm_is_primary_client(file)) <answer> if 
if <token> <answer> (dev->driver->postclose) 
dev->driver->postclose(dev, <token> <answer> file); 
static <token> drm_close_helper(struct file *filp) <answer> void 
struct <token> *file_priv = filp->private_data; <answer> drm_file 
struct drm_device <token> = file_priv->minor->dev; <answer> *dev 
<token> int drm_cpu_valid(void) <answer> static 
#if defined(__sparc__) <token> !defined(__sparc_v9__) <answer> && 
int drm_open_helper(struct file *filp, struct drm_minor <token> <answer> *minor) 
struct drm_device *dev = <token> <answer> minor->dev; 
<token> drm_file *priv; <answer> struct 
<token> ret; <answer> int 
if (filp->f_flags & <token> <answer> O_EXCL) 
int drm_open(struct inode *inode, struct file <token> <answer> *filp) 
<token> drm_device *dev; <answer> struct 
struct <token> *minor; <answer> drm_minor 
int <token> <answer> retcode; 
<token> = drm_minor_acquire(iminor(inode)); <answer> minor 
if <token> <answer> (IS_ERR(minor)) 
<token> PTR_ERR(minor); <answer> return 
<token> = minor->dev; <answer> dev 
<token> (drm_dev_needs_global_mutex(dev)) <answer> if 
int drm_release(struct <token> *inode, struct file *filp) <answer> inode 
struct drm_file *file_priv = <token> <answer> filp->private_data; 
struct <token> *minor = file_priv->minor; <answer> drm_minor 
<token> drm_device *dev = minor->dev; <answer> struct 
<token> (drm_dev_needs_global_mutex(dev)) <answer> if 
drm_dbg_core(dev, "open_count <token> %d\n", atomic_read(&dev->open_count)); <answer> = 
if <token> <answer> (atomic_dec_and_test(&dev->open_count)) 
if <token> <answer> (drm_dev_needs_global_mutex(dev)) 
return <token> <answer> 0; 
void <token> drm_file *filp) <answer> drm_file_update_pid(struct 
<token> drm_device *dev; <answer> struct 
struct pid <token> *old; <answer> *pid, 
<token> (filp->was_master) <answer> if 
<token> = task_tgid(current); <answer> pid 
if (pid == <token> <answer> rcu_access_pointer(filp->pid)) 
dev = <token> <answer> filp->minor->dev; 
old <token> rcu_replace_pointer(filp->pid, pid, 1); <answer> = 
if (pid != <token> { <answer> old) 
int drm_release_noglobal(struct inode <token> struct file *filp) <answer> *inode, 
struct drm_file *file_priv = <token> <answer> filp->private_data; 
struct drm_minor <token> = file_priv->minor; <answer> *minor 
struct <token> *dev = minor->dev; <answer> drm_device 
if <token> &drm_global_mutex)) { <answer> (atomic_dec_and_mutex_lock(&dev->open_count, 
<token> 0; <answer> return 
ssize_t drm_read(struct file *filp, char __user <token> <answer> *buffer, 
size_t <token> loff_t *offset) <answer> count, 
struct drm_file *file_priv = <token> <answer> filp->private_data; 
struct drm_device *dev = <token> <answer> file_priv->minor->dev; 
<token> ret; <answer> ssize_t 
ret <token> mutex_lock_interruptible(&file_priv->event_read_lock); <answer> = 
if <token> <answer> (ret) 
return <token> <answer> ret; 
for (;;) <token> <answer> { 
<token> drm_pending_event *e = NULL; <answer> struct 
if (!list_empty(&file_priv->event_list)) <token> <answer> { 
e = <token> <answer> list_first_entry(&file_priv->event_list, 
struct drm_pending_event, <token> <answer> link); 
file_priv->event_space += <token> <answer> e->event->length; 
if (e == <token> { <answer> NULL) 
<token> (ret) <answer> if 
<token> (filp->f_flags & O_NONBLOCK) { <answer> if 
<token> = -EAGAIN; <answer> ret 
ret <token> wait_event_interruptible(file_priv->event_wait, <answer> = 
if (ret <token> 0) <answer> >= 
ret <token> mutex_lock_interruptible(&file_priv->event_read_lock); <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> else { <answer> } 
unsigned length = <token> <answer> e->event->length; 
<token> (length > count - ret) { <answer> if 
file_priv->event_space <token> length; <answer> -= 
<token> &file_priv->event_list); <answer> list_add(&e->link, 
<token> | EPOLLRDNORM); <answer> EPOLLIN 
if (copy_to_user(buffer <token> ret, e->event, length)) { <answer> + 
if (ret == <token> <answer> 0) 
<token> = -EFAULT; <answer> ret 
<token> put_back_event; <answer> goto 
<token> += length; <answer> ret 
<token> ret; <answer> return 
__poll_t <token> file *filp, struct poll_table_struct *wait) <answer> drm_poll(struct 
struct drm_file *file_priv = <token> <answer> filp->private_data; 
__poll_t <token> = 0; <answer> mask 
poll_wait(filp, &file_priv->event_wait, <token> <answer> wait); 
if <token> <answer> (!list_empty(&file_priv->event_list)) 
mask <token> EPOLLIN | EPOLLRDNORM; <answer> |= 
<token> mask; <answer> return 
<token> drm_event_reserve_init_locked(struct drm_device *dev, <answer> int 
struct <token> *file_priv, <answer> drm_file 
struct drm_pending_event <token> <answer> *p, 
<token> drm_event *e) <answer> struct 
<token> (file_priv->event_space < e->length) <answer> if 
return <token> <answer> -ENOMEM; 
file_priv->event_space <token> e->length; <answer> -= 
<token> = e; <answer> p->event 
<token> &file_priv->pending_event_list); <answer> list_add(&p->pending_link, 
p->file_priv = <token> <answer> file_priv; 
return <token> <answer> 0; 
int drm_event_reserve_init(struct <token> *dev, <answer> drm_device 
<token> drm_file *file_priv, <answer> struct 
struct <token> *p, <answer> drm_pending_event 
struct <token> *e) <answer> drm_event 
unsigned long <token> <answer> flags; 
<token> ret; <answer> int 
<token> flags); <answer> spin_lock_irqsave(&dev->event_lock, 
ret = drm_event_reserve_init_locked(dev, file_priv, <token> e); <answer> p, 
<token> flags); <answer> spin_unlock_irqrestore(&dev->event_lock, 
<token> ret; <answer> return 
<token> drm_event_cancel_free(struct drm_device *dev, <answer> void 
struct <token> *p) <answer> drm_pending_event 
unsigned long <token> <answer> flags; 
<token> flags); <answer> spin_lock_irqsave(&dev->event_lock, 
<token> (p->file_priv) { <answer> if 
p->file_priv->event_space <token> p->event->length; <answer> += 
spin_unlock_irqrestore(&dev->event_lock, <token> <answer> flags); 
<token> (p->fence) <answer> if 
static void drm_send_event_helper(struct drm_device <token> <answer> *dev, 
struct drm_pending_event *e, <token> timestamp) <answer> ktime_t 
<token> (e->completion) { <answer> if 
e->completion = <token> <answer> NULL; 
if (e->fence) <token> <answer> { 
<token> (timestamp) <answer> if 
dma_fence_signal_timestamp(e->fence, <token> <answer> timestamp); 
if <token> { <answer> (!e->file_priv) 
EPOLLIN | <token> <answer> EPOLLRDNORM); 
void <token> drm_device *dev, <answer> drm_send_event_timestamp_locked(struct 
struct drm_pending_event <token> ktime_t timestamp) <answer> *e, 
drm_send_event_helper(dev, e, <token> <answer> timestamp); 
void drm_send_event_locked(struct drm_device *dev, <token> drm_pending_event *e) <answer> struct 
drm_send_event_helper(dev, e, <token> <answer> 0); 
void drm_send_event(struct drm_device *dev, struct <token> *e) <answer> drm_pending_event 
unsigned <token> irqflags; <answer> long 
<token> irqflags); <answer> spin_lock_irqsave(&dev->event_lock, 
<token> e, 0); <answer> drm_send_event_helper(dev, 
spin_unlock_irqrestore(&dev->event_lock, <token> <answer> irqflags); 
static void print_size(struct drm_printer *p, <token> char *stat, <answer> const 
const char *region, <token> sz) <answer> u64 
<token> char *units[] = {"", " KiB", " MiB"}; <answer> const 
unsigned <token> <answer> u; 
for <token> = 0; u < ARRAY_SIZE(units) - 1; u++) { <answer> (u 
<token> (sz == 0 || !IS_ALIGNED(sz, SZ_1K)) <answer> if 
sz = <token> SZ_1K); <answer> div_u64(sz, 
drm_printf(p, "drm-%s-%s:\t%llu%s\n", stat, region, <token> units[u]); <answer> sz, 
void <token> drm_printer *p, <answer> drm_print_memory_stats(struct 
<token> struct drm_memory_stats *stats, <answer> const 
<token> drm_gem_object_status supported_status, <answer> enum 
const char <token> <answer> *region) 
print_size(p, "total", region, stats->private + <token> <answer> stats->shared); 
print_size(p, "shared", region, <token> <answer> stats->shared); 
print_size(p, "active", region, <token> <answer> stats->active); 
if <token> & DRM_GEM_OBJECT_RESIDENT) <answer> (supported_status 
print_size(p, "resident", region, <token> <answer> stats->resident); 
<token> (supported_status & DRM_GEM_OBJECT_PURGEABLE) <answer> if 
<token> "purgeable", region, stats->purgeable); <answer> print_size(p, 
void drm_show_memory_stats(struct drm_printer <token> struct drm_file *file) <answer> *p, 
struct <token> *obj; <answer> drm_gem_object 
struct drm_memory_stats status = <token> <answer> {}; 
enum drm_gem_object_status <token> = 0; <answer> supported_status 
<token> id; <answer> int 
idr_for_each_entry (&file->object_idr, obj, id) <token> <answer> { 
enum drm_gem_object_status <token> = 0; <answer> s 
size_t add_size = (obj->funcs && <token> ? <answer> obj->funcs->rss) 
<token> : obj->size; <answer> obj->funcs->rss(obj) 
if (obj->funcs <token> obj->funcs->status) { <answer> && 
s = <token> <answer> obj->funcs->status(obj); 
supported_status <token> DRM_GEM_OBJECT_RESIDENT | <answer> = 
<token> (drm_gem_object_is_shared_for_memory_stats(obj)) { <answer> if 
status.shared += <token> <answer> obj->size; 
} <token> { <answer> else 
<token> += obj->size; <answer> status.private 
if (s & DRM_GEM_OBJECT_RESIDENT) <token> <answer> { 
status.resident += <token> <answer> add_size; 
} <token> { <answer> else 
<token> &= ~DRM_GEM_OBJECT_PURGEABLE; <answer> s 
if (!dma_resv_test_signaled(obj->resv, <token> { <answer> dma_resv_usage_rw(true))) 
status.active <token> add_size; <answer> += 
void <token> seq_file *m, struct file *f) <answer> drm_show_fdinfo(struct 
struct drm_file *file = <token> <answer> f->private_data; 
struct drm_device <token> = file->minor->dev; <answer> *dev 
struct drm_printer p <token> drm_seq_file_printer(m); <answer> = 
drm_printf(&p, "drm-driver:\t%s\n", <token> <answer> dev->driver->name); 
drm_printf(&p, <token> file->client_id); <answer> "drm-client-id:\t%llu\n", 
if <token> { <answer> (dev_is_pci(dev->dev)) 
struct pci_dev <token> = to_pci_dev(dev->dev); <answer> *pdev 
drm_printf(&p, <token> <answer> "drm-pdev:\t%04x:%02x:%02x.%d\n", 
<token> pdev->bus->number, <answer> pci_domain_nr(pdev->bus), 
PCI_SLOT(pdev->devfn), <token> <answer> PCI_FUNC(pdev->devfn)); 
<token> (dev->driver->show_fdinfo) <answer> if 
dev->driver->show_fdinfo(&p, <token> <answer> file); 
struct file <token> drm_minor *minor, unsigned int flags) <answer> *mock_drm_getfile(struct 
struct drm_device <token> = minor->dev; <answer> *dev 
<token> drm_file *priv; <answer> struct 
struct <token> *file; <answer> file 
<token> = drm_file_alloc(minor); <answer> priv 
if <token> <answer> (IS_ERR(priv)) 
return <token> <answer> ERR_CAST(priv); 
file = anon_inode_getfile("drm", dev->driver->fops, priv, <token> <answer> flags); 
if <token> { <answer> (IS_ERR(file)) 
<token> file; <answer> return 
<token> <linux/init.h> <answer> #include 
<token> <linux/mfd/max77620.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/regulator/driver.h> 
#include <token> <answer> <linux/regulator/machine.h> 
<token> <linux/regulator/of_regulator.h> <answer> #include 
#define <token> "max77620-"#_name <answer> max77620_rails(_name) 
<token> (rpdata->ramp_rate_setting) <answer> if 
<token> 0; <answer> return 
return max77620_set_slew_rate(pmic, <token> ramp_delay); <answer> id, 
static int max77620_of_parse_cb(struct device_node <token> <answer> *np, 
const <token> regulator_desc *desc, <answer> struct 
struct regulator_config <token> <answer> *config) 
struct max77620_regulator *pmic <token> config->driver_data; <answer> = 
struct max77620_regulator_pdata <token> = &pmic->reg_pdata[desc->id]; <answer> *rpdata 
u32 <token> <answer> pval; 
<token> ret; <answer> int 
ret = of_property_read_u32(np, "maxim,active-fps-source", <token> <answer> &pval); 
rpdata->active_fps_src = (!ret) <token> pval : MAX77620_FPS_SRC_DEF; <answer> ? 
ret <token> of_property_read_u32(np, "maxim,active-fps-power-up-slot", &pval); <answer> = 
rpdata->active_fps_pu_slot = <token> ? pval : -1; <answer> (!ret) 
<token> = of_property_read_u32( <answer> ret 
np, "maxim,active-fps-power-down-slot", <token> <answer> &pval); 
rpdata->active_fps_pd_slot = (!ret) ? pval <token> -1; <answer> : 
ret = of_property_read_u32(np, <token> &pval); <answer> "maxim,suspend-fps-source", 
rpdata->suspend_fps_src = <token> ? pval : -1; <answer> (!ret) 
ret = <token> <answer> of_property_read_u32( 
np, <token> &pval); <answer> "maxim,suspend-fps-power-up-slot", 
rpdata->suspend_fps_pu_slot = (!ret) <token> pval : -1; <answer> ? 
ret = <token> <answer> of_property_read_u32( 
np, "maxim,suspend-fps-power-down-slot", <token> <answer> &pval); 
rpdata->suspend_fps_pd_slot = (!ret) <token> pval : -1; <answer> ? 
ret = of_property_read_u32(np, "maxim,power-ok-control", <token> <answer> &pval); 
if <token> <answer> (!ret) 
rpdata->power_ok = <token> <answer> pval; 
rpdata->power_ok <token> -1; <answer> = 
ret = of_property_read_u32(np, <token> &pval); <answer> "maxim,ramp-rate-setting", 
rpdata->ramp_rate_setting = <token> ? pval : 0; <answer> (!ret) 
return <token> desc->id); <answer> max77620_init_pmic(pmic, 
static const struct regulator_ops max77620_regulator_ops <token> { <answer> = 
.is_enabled <token> max77620_regulator_is_enabled, <answer> = 
<token> = max77620_regulator_enable, <answer> .enable 
.disable <token> max77620_regulator_disable, <answer> = 
.list_voltage <token> regulator_list_voltage_linear, <answer> = 
.map_voltage = <token> <answer> regulator_map_voltage_linear, 
.get_voltage_sel <token> regulator_get_voltage_sel_regmap, <answer> = 
.set_voltage_sel <token> regulator_set_voltage_sel_regmap, <answer> = 
<token> = max77620_regulator_set_mode, <answer> .set_mode 
.get_mode = <token> <answer> max77620_regulator_get_mode, 
<token> = max77620_regulator_set_ramp_delay, <answer> .set_ramp_delay 
.set_voltage_time_sel <token> regulator_set_voltage_time_sel, <answer> = 
.set_active_discharge <token> regulator_set_active_discharge_regmap, <answer> = 
#define <token> 0 <answer> MAX77620_SD_CNF2_ROVS_EN_NONE 
#define RAIL_SD(_id, _name, _sname, <token> _min_uV, _max_uV, \ <answer> _volt_mask, 
<token> _rs_add, _rs_mask) \ <answer> _step_uV, 
[MAX77620_REGULATOR_ID_##_id] = { <token> <answer> \ 
.type <token> MAX77620_REGULATOR_TYPE_SD, \ <answer> = 
.volt_addr = <token> \ <answer> MAX77620_REG_##_id, 
.cfg_addr = <token> \ <answer> MAX77620_REG_##_id##_CFG, 
.fps_addr <token> MAX77620_REG_FPS_##_id, \ <answer> = 
.remote_sense_addr = <token> \ <answer> _rs_add, 
.remote_sense_mask = MAX77620_SD_CNF2_ROVS_EN_##_rs_mask, <token> <answer> \ 
.power_mode_mask <token> MAX77620_SD_POWER_MODE_MASK, \ <answer> = 
.power_mode_shift <token> MAX77620_SD_POWER_MODE_SHIFT, \ <answer> = 
.desc = <token> \ <answer> { 
.name = <token> \ <answer> max77620_rails(_name), 
.of_match = <token> \ <answer> of_match_ptr(#_name), 
.regulators_node = <token> \ <answer> of_match_ptr("regulators"), 
.of_parse_cb = max77620_of_parse_cb, <token> <answer> \ 
<token> = _sname, \ <answer> .supply_name 
.id <token> MAX77620_REGULATOR_ID_##_id, \ <answer> = 
.ops <token> &max77620_regulator_ops, \ <answer> = 
.n_voltages = ((_max_uV <token> _min_uV) / _step_uV) + 1, \ <answer> - 
.min_uV = <token> \ <answer> _min_uV, 
<token> = _step_uV, \ <answer> .uV_step 
<token> = 500, \ <answer> .enable_time 
.vsel_mask = MAX77620_##_volt_mask##_VOLT_MASK, <token> <answer> \ 
.vsel_reg = <token> \ <answer> MAX77620_REG_##_id, 
.active_discharge_off = <token> \ <answer> 0, 
.active_discharge_on <token> MAX77620_SD_CFG1_ADE_ENABLE, \ <answer> = 
.active_discharge_mask = <token> \ <answer> MAX77620_SD_CFG1_ADE_MASK, 
.active_discharge_reg <token> MAX77620_REG_##_id##_CFG, \ <answer> = 
.type = <token> \ <answer> REGULATOR_VOLTAGE, 
.owner <token> THIS_MODULE, \ <answer> = 
<token> \ <answer> }, 
#define RAIL_LDO(_id, _name, _sname, _type, _min_uV, _max_uV, <token> \ <answer> _step_uV) 
[MAX77620_REGULATOR_ID_##_id] = <token> \ <answer> { 
<token> = MAX77620_REGULATOR_TYPE_LDO_##_type, \ <answer> .type 
.volt_addr = MAX77620_REG_##_id##_CFG, <token> <answer> \ 
<token> = MAX77620_REG_##_id##_CFG2, \ <answer> .cfg_addr 
.fps_addr = MAX77620_REG_FPS_##_id, <token> <answer> \ 
.remote_sense_addr = <token> \ <answer> 0xFF, 
.power_mode_mask <token> MAX77620_LDO_POWER_MODE_MASK, \ <answer> = 
.power_mode_shift = MAX77620_LDO_POWER_MODE_SHIFT, <token> <answer> \ 
.desc = <token> \ <answer> { 
<token> = max77620_rails(_name), \ <answer> .name 
.of_match = of_match_ptr(#_name), <token> <answer> \ 
.regulators_node <token> of_match_ptr("regulators"), \ <answer> = 
.of_parse_cb = <token> \ <answer> max77620_of_parse_cb, 
.supply_name = <token> \ <answer> _sname, 
<token> = MAX77620_REGULATOR_ID_##_id, \ <answer> .id 
<token> = &max77620_regulator_ops, \ <answer> .ops 
.n_voltages = ((_max_uV - _min_uV) / _step_uV) <token> 1, \ <answer> + 
.min_uV <token> _min_uV, \ <answer> = 
.uV_step = <token> \ <answer> _step_uV, 
.enable_time = <token> \ <answer> 500, 
.vsel_mask <token> MAX77620_LDO_VOLT_MASK, \ <answer> = 
.vsel_reg <token> MAX77620_REG_##_id##_CFG, \ <answer> = 
<token> = 0, \ <answer> .active_discharge_off 
.active_discharge_on = <token> \ <answer> MAX77620_LDO_CFG2_ADE_ENABLE, 
.active_discharge_mask <token> MAX77620_LDO_CFG2_ADE_MASK, \ <answer> = 
<token> = MAX77620_REG_##_id##_CFG2, \ <answer> .active_discharge_reg 
<token> = REGULATOR_VOLTAGE, \ <answer> .type 
<token> = THIS_MODULE, \ <answer> .owner 
}, <token> <answer> \ 
static struct <token> max77620_regs_info[MAX77620_NUM_REGS] = { <answer> max77620_regulator_info 
RAIL_SD(SD0, sd0, <token> SD0, 600000, 1400000, 12500, 0x22, SD0), <answer> "in-sd0", 
<token> sd1, "in-sd1", SD1, 600000, 1550000, 12500, 0x22, SD1), <answer> RAIL_SD(SD1, 
RAIL_SD(SD2, sd2, "in-sd2", SDX, 600000, 3787500, 12500, <token> NONE), <answer> 0xFF, 
RAIL_SD(SD3, sd3, "in-sd3", SDX, 600000, 3787500, 12500, 0xFF, <token> <answer> NONE), 
RAIL_LDO(LDO0, ldo0, "in-ldo0-1", N, <token> 2375000, 25000), <answer> 800000, 
RAIL_LDO(LDO1, ldo1, "in-ldo0-1", N, <token> 2375000, 25000), <answer> 800000, 
RAIL_LDO(LDO2, ldo2, "in-ldo2", <token> 800000, 3950000, 50000), <answer> P, 
RAIL_LDO(LDO3, <token> "in-ldo3-5", P, 800000, 3950000, 50000), <answer> ldo3, 
RAIL_LDO(LDO4, ldo4, "in-ldo4-6", <token> 800000, 1587500, 12500), <answer> P, 
<token> ldo5, "in-ldo3-5", P, 800000, 3950000, 50000), <answer> RAIL_LDO(LDO5, 
RAIL_LDO(LDO6, ldo6, "in-ldo4-6", P, 800000, 3950000, <token> <answer> 50000), 
RAIL_LDO(LDO7, ldo7, "in-ldo7-8", N, 800000, 3950000, <token> <answer> 50000), 
RAIL_LDO(LDO8, ldo8, "in-ldo7-8", N, 800000, <token> 50000), <answer> 3950000, 
static struct max77620_regulator_info max20024_regs_info[MAX77620_NUM_REGS] = <token> <answer> { 
RAIL_SD(SD0, sd0, "in-sd0", SD0, <token> 1587500, 12500, 0x22, SD0), <answer> 800000, 
RAIL_SD(SD1, sd1, "in-sd1", <token> 600000, 3387500, 12500, 0x22, SD1), <answer> SD1, 
<token> sd2, "in-sd2", SDX, 600000, 3787500, 12500, 0xFF, NONE), <answer> RAIL_SD(SD2, 
RAIL_SD(SD3, sd3, <token> SDX, 600000, 3787500, 12500, 0xFF, NONE), <answer> "in-sd3", 
RAIL_SD(SD4, sd4, "in-sd4", SDX, 600000, 3787500, 12500, 0xFF, <token> <answer> NONE), 
RAIL_LDO(LDO0, ldo0, "in-ldo0-1", N, <token> 2375000, 25000), <answer> 800000, 
RAIL_LDO(LDO1, ldo1, <token> N, 800000, 2375000, 25000), <answer> "in-ldo0-1", 
RAIL_LDO(LDO2, ldo2, <token> P, 800000, 3950000, 50000), <answer> "in-ldo2", 
RAIL_LDO(LDO3, ldo3, "in-ldo3-5", P, 800000, 3950000, <token> <answer> 50000), 
RAIL_LDO(LDO4, ldo4, "in-ldo4-6", <token> 800000, 1587500, 12500), <answer> P, 
<token> ldo5, "in-ldo3-5", P, 800000, 3950000, 50000), <answer> RAIL_LDO(LDO5, 
RAIL_LDO(LDO6, ldo6, <token> P, 800000, 3950000, 50000), <answer> "in-ldo4-6", 
RAIL_LDO(LDO7, <token> "in-ldo7-8", N, 800000, 3950000, 50000), <answer> ldo7, 
RAIL_LDO(LDO8, ldo8, "in-ldo7-8", N, <token> 3950000, 50000), <answer> 800000, 
static struct max77620_regulator_info max77663_regs_info[MAX77620_NUM_REGS] = <token> <answer> { 
RAIL_SD(SD0, sd0, "in-sd0", SD0, 600000, 3387500, <token> 0xFF, NONE), <answer> 12500, 
RAIL_SD(SD1, sd1, "in-sd1", <token> 800000, 1587500, 12500, 0xFF, NONE), <answer> SD1, 
RAIL_SD(SD2, sd2, "in-sd2", SDX, 600000, 3787500, 12500, 0xFF, <token> <answer> NONE), 
RAIL_SD(SD3, <token> "in-sd3", SDX, 600000, 3787500, 12500, 0xFF, NONE), <answer> sd3, 
RAIL_SD(SD4, sd4, "in-sd4", <token> 600000, 3787500, 12500, 0xFF, NONE), <answer> SDX, 
RAIL_LDO(LDO0, ldo0, "in-ldo0-1", N, 800000, <token> 25000), <answer> 2375000, 
<token> ldo1, "in-ldo0-1", N, 800000, 2375000, 25000), <answer> RAIL_LDO(LDO1, 
RAIL_LDO(LDO2, ldo2, "in-ldo2", P, 800000, <token> 50000), <answer> 3950000, 
RAIL_LDO(LDO3, ldo3, "in-ldo3-5", P, <token> 3950000, 50000), <answer> 800000, 
RAIL_LDO(LDO4, ldo4, "in-ldo4-6", P, 800000, <token> 12500), <answer> 1587500, 
RAIL_LDO(LDO5, <token> "in-ldo3-5", P, 800000, 3950000, 50000), <answer> ldo5, 
RAIL_LDO(LDO6, ldo6, "in-ldo4-6", <token> 800000, 3950000, 50000), <answer> P, 
RAIL_LDO(LDO7, ldo7, "in-ldo7-8", N, <token> 3950000, 50000), <answer> 800000, 
<token> ldo8, "in-ldo7-8", N, 800000, 3950000, 50000), <answer> RAIL_LDO(LDO8, 
static int max77620_regulator_probe(struct <token> *pdev) <answer> platform_device 
<token> max77620_chip *max77620_chip = dev_get_drvdata(pdev->dev.parent); <answer> struct 
<token> max77620_regulator_info *rinfo; <answer> struct 
struct device <token> = &pdev->dev; <answer> *dev 
struct <token> config = { }; <answer> regulator_config 
struct max77620_regulator <token> <answer> *pmic; 
int ret <token> 0; <answer> = 
<token> id; <answer> int 
pmic = devm_kzalloc(dev, sizeof(*pmic), <token> <answer> GFP_KERNEL); 
<token> (!pmic) <answer> if 
<token> -ENOMEM; <answer> return 
<token> pmic); <answer> platform_set_drvdata(pdev, 
<token> = dev; <answer> pmic->dev 
pmic->rmap <token> max77620_chip->rmap; <answer> = 
<token> (!dev->of_node) <answer> if 
dev->of_node = <token> <answer> pdev->dev.parent->of_node; 
<token> (max77620_chip->chip_id) { <answer> switch 
<token> MAX77620: <answer> case 
rinfo = <token> <answer> max77620_regs_info; 
<token> MAX20024: <answer> case 
<token> = max20024_regs_info; <answer> rinfo 
case <token> <answer> MAX77663: 
rinfo = <token> <answer> max77663_regs_info; 
<token> -EINVAL; <answer> return 
config.regmap <token> pmic->rmap; <answer> = 
<token> = dev; <answer> config.dev 
<token> = pmic; <answer> config.driver_data 
device_set_of_node_from_dev(&pdev->dev, <token> <answer> pdev->dev.parent); 
for (id <token> 0; id < MAX77620_NUM_REGS; id++) { <answer> = 
struct <token> *rdev; <answer> regulator_dev 
struct <token> *rdesc; <answer> regulator_desc 
if ((max77620_chip->chip_id == <token> && <answer> MAX77620) 
<token> == MAX77620_REGULATOR_ID_SD4)) <answer> (id 
rdesc = <token> <answer> &rinfo[id].desc; 
pmic->rinfo[id] = <token> <answer> &rinfo[id]; 
pmic->enable_power_mode[id] = <token> <answer> MAX77620_POWER_MODE_NORMAL; 
<token> = -1; <answer> pmic->reg_pdata[id].active_fps_src 
pmic->reg_pdata[id].active_fps_pd_slot <token> -1; <answer> = 
pmic->reg_pdata[id].active_fps_pu_slot = <token> <answer> -1; 
pmic->reg_pdata[id].suspend_fps_src <token> -1; <answer> = 
pmic->reg_pdata[id].suspend_fps_pd_slot <token> -1; <answer> = 
pmic->reg_pdata[id].suspend_fps_pu_slot <token> -1; <answer> = 
pmic->reg_pdata[id].power_ok <token> -1; <answer> = 
<token> = -1; <answer> pmic->reg_pdata[id].ramp_rate_setting 
ret = max77620_read_slew_rate(pmic, <token> <answer> id); 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
rdev = devm_regulator_register(dev, rdesc, <token> <answer> &config); 
<token> (IS_ERR(rdev)) <answer> if 
return dev_err_probe(dev, <token> <answer> PTR_ERR(rdev), 
"Regulator registration %s <token> <answer> failed\n", 
return <token> <answer> 0; 
<token> CONFIG_PM_SLEEP <answer> #ifdef 
static int max77620_regulator_suspend(struct <token> *dev) <answer> device 
<token> max77620_regulator *pmic = dev_get_drvdata(dev); <answer> struct 
struct <token> *reg_pdata; <answer> max77620_regulator_pdata 
int <token> <answer> id; 
for (id = 0; id <token> MAX77620_NUM_REGS; id++) { <answer> < 
reg_pdata <token> &pmic->reg_pdata[id]; <answer> = 
max77620_regulator_set_fps_slots(pmic, id, <token> <answer> true); 
if (reg_pdata->suspend_fps_src < <token> <answer> 0) 
<token> reg_pdata->suspend_fps_src, <answer> max77620_regulator_set_fps_src(pmic, 
return <token> <answer> 0; 
static int <token> device *dev) <answer> max77620_regulator_resume(struct 
struct max77620_regulator <token> = dev_get_drvdata(dev); <answer> *pmic 
struct max77620_regulator_pdata <token> <answer> *reg_pdata; 
<token> id; <answer> int 
for (id <token> 0; id < MAX77620_NUM_REGS; id++) { <answer> = 
<token> = &pmic->reg_pdata[id]; <answer> reg_pdata 
max77620_config_power_ok(pmic, <token> <answer> id); 
max77620_regulator_set_fps_slots(pmic, <token> false); <answer> id, 
<token> (reg_pdata->active_fps_src < 0) <answer> if 
<token> reg_pdata->active_fps_src, <answer> max77620_regulator_set_fps_src(pmic, 
return <token> <answer> 0; 
static const struct dev_pm_ops max77620_regulator_pm_ops = <token> <answer> { 
static const <token> platform_device_id max77620_regulator_devtype[] = { <answer> struct 
{ <token> = "max77620-pmic", }, <answer> .name 
<token> .name = "max20024-pmic", }, <answer> { 
{ .name <token> "max77663-pmic", }, <answer> = 
MODULE_DEVICE_TABLE(platform, <token> <answer> max77620_regulator_devtype); 
<token> struct platform_driver max77620_regulator_driver = { <answer> static 
.probe <token> max77620_regulator_probe, <answer> = 
.id_table = <token> <answer> max77620_regulator_devtype, 
.driver = <token> <answer> { 
.name <token> "max77620-pmic", <answer> = 
.probe_type = <token> <answer> PROBE_PREFER_ASYNCHRONOUS, 
<token> = &max77620_regulator_pm_ops, <answer> .pm 
<token> regulator driver"); <answer> MODULE_DESCRIPTION("MAX77620/MAX20024 
MODULE_AUTHOR("Mallikarjun <token> <mkasoju@nvidia.com>"); <answer> Kasoju 
<token> Dewangan <ldewangan@nvidia.com>"); <answer> MODULE_AUTHOR("Laxman 
MODULE_LICENSE("GPL <token> <answer> v2"); 
<token> dev_fmt(fmt) "mtdoops-pstore: " fmt <answer> #define 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/pstore_blk.h> <answer> #include 
#include <token> <answer> <linux/mtd/mtd.h> 
#include <token> <answer> <linux/bitops.h> 
#include <token> <answer> <linux/slab.h> 
static struct mtdpstore_context <token> <answer> { 
<token> index; <answer> int 
struct pstore_blk_config <token> <answer> info; 
struct pstore_device_info <token> <answer> dev; 
<token> mtd_info *mtd; <answer> struct 
static <token> mtdpstore_erase(size_t size, loff_t off) <answer> ssize_t 
struct mtdpstore_context *cxt = <token> <answer> &oops_cxt; 
if <token> off)) <answer> (mtdpstore_block_isbad(cxt, 
<token> -EIO; <answer> return 
mtdpstore_mark_unused(cxt, <token> <answer> off); 
<token> int mtdpstore_security(struct mtdpstore_context *cxt, loff_t off) <answer> static 
<token> ret = 0, i; <answer> int 
struct mtd_info *mtd <token> cxt->mtd; <answer> = 
u32 zonenum = (u32)div_u64(off, <token> <answer> cxt->info.kmsg_size); 
u32 zonecnt = (u32)div_u64(cxt->mtd->size, <token> <answer> cxt->info.kmsg_size); 
u32 blkcnt = (u32)div_u64(cxt->mtd->size, <token> <answer> cxt->mtd->erasesize); 
u32 erasesize = <token> <answer> cxt->mtd->erasesize; 
for (i = 0; i < zonecnt; i++) <token> <answer> { 
u32 num = (zonenum <token> i) % zonecnt; <answer> + 
<token> ssize_t mtdpstore_read(char *buf, size_t size, loff_t off) <answer> static 
struct mtdpstore_context *cxt = <token> <answer> &oops_cxt; 
<token> mtd_info *mtd = cxt->mtd; <answer> struct 
size_t retlen, <token> <answer> done; 
int <token> <answer> ret; 
if (mtdpstore_block_isbad(cxt, <token> <answer> off)) 
<token> -ENOMSG; <answer> return 
dev_dbg(&mtd->dev, "try to read off 0x%llx <token> %zu\n", off, size); <answer> size 
for (done <token> 0, retlen = 0; done < size; done += retlen) { <answer> = 
retlen = <token> <answer> 0; 
ret = mtd_read(cxt->mtd, off + done, size <token> done, &retlen, <answer> - 
(u_char *)buf <token> done); <answer> + 
if <token> { <answer> (mtdpstore_is_io_error(ret)) 
dev_err(&mtd->dev, "read failure at <token> (%zu of %zu read), err %d\n", <answer> %lld 
off + done, retlen, size <token> done, ret); <answer> - 
if (mtd_is_eccerr(ret)) <token> <answer> { 
dev_err(&mtd->dev, "ecc error at %lld <token> of %zu read), err %d\n", <answer> (%zu 
off + done, retlen, size - done, <token> <answer> ret); 
if (mtd->erasesize < <token> { <answer> info->kmsg_size) 
dev_err(&mtd->dev, <token> size of MTD partition %d too small\n", <answer> "eraseblock 
<token> (unlikely(info->kmsg_size % mtd->writesize)) { <answer> if 
<token> "record size %lu KB must align to write size %d KB\n", <answer> dev_err(&mtd->dev, 
info->kmsg_size <token> 1024, <answer> / 
<token> / 1024); <answer> mtd->writesize 
longcnt <token> BITS_TO_LONGS(div_u64(mtd->size, info->kmsg_size)); <answer> = 
<token> = kcalloc(longcnt, sizeof(long), GFP_KERNEL); <answer> cxt->rmmap 
cxt->usedmap <token> kcalloc(longcnt, sizeof(long), GFP_KERNEL); <answer> = 
longcnt <token> BITS_TO_LONGS(div_u64(mtd->size, mtd->erasesize)); <answer> = 
cxt->badmap <token> kcalloc(longcnt, sizeof(long), GFP_KERNEL); <answer> = 
static int mtdpstore_flush_removed(struct mtdpstore_context <token> <answer> *cxt) 
struct mtd_info *mtd <token> cxt->mtd; <answer> = 
int <token> <answer> ret; 
loff_t <token> <answer> off; 
u32 blkcnt = (u32)div_u64(mtd->size, <token> <answer> mtd->erasesize); 
for (off = 0; blkcnt <token> 0; blkcnt--, off += mtd->erasesize) { <answer> > 
ret = mtdpstore_block_isbad(cxt, <token> <answer> off); 
if <token> <answer> (ret) 
ret = <token> off); <answer> mtdpstore_block_is_removed(cxt, 
if <token> <answer> (!ret) 
ret = <token> off, mtd->erasesize); <answer> mtdpstore_flush_removed_do(cxt, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
return <token> <answer> 0; 
<token> void mtdpstore_notify_remove(struct mtd_info *mtd) <answer> static 
struct <token> *cxt = &oops_cxt; <answer> mtdpstore_context 
if (mtd->index != cxt->index || <token> < 0) <answer> cxt->index 
cxt->mtd <token> NULL; <answer> = 
cxt->index = <token> <answer> -1; 
static struct mtd_notifier <token> = { <answer> mtdpstore_notifier 
.add = <token> <answer> mtdpstore_notify_add, 
.remove = <token> <answer> mtdpstore_notify_remove, 
<token> int __init mtdpstore_init(void) <answer> static 
int <token> <answer> ret; 
struct mtdpstore_context <token> = &oops_cxt; <answer> *cxt 
struct pstore_blk_config <token> = &cxt->info; <answer> *info 
ret = <token> <answer> pstore_blk_get_config(info); 
if <token> <answer> (unlikely(ret)) 
<token> ret; <answer> return 
<token> (strlen(info->device) == 0) { <answer> if 
pr_err("mtd <token> must be supplied (device name is empty)\n"); <answer> device 
<token> -EINVAL; <answer> return 
if <token> { <answer> (!info->kmsg_size) 
pr_err("no <token> enabled (kmsg_size is 0)\n"); <answer> backend 
return <token> <answer> -EINVAL; 
<token> "mt7603.h" <answer> #include 
static <token> <answer> int 
mt7603_reset_read(struct seq_file *s, void <token> <answer> *data) 
struct mt7603_dev <token> = dev_get_drvdata(s->private); <answer> *dev 
static const char * const <token> = { <answer> reset_cause_str[] 
[RESET_CAUSE_TX_HANG] = <token> hang", <answer> "TX 
[RESET_CAUSE_TX_BUSY] = <token> DMA busy stuck", <answer> "TX 
[RESET_CAUSE_RX_BUSY] = "RX DMA busy <token> <answer> stuck", 
<token> = "RX PSE busy stuck", <answer> [RESET_CAUSE_RX_PSE_BUSY] 
[RESET_CAUSE_BEACON_STUCK] = "Beacon <token> <answer> stuck", 
[RESET_CAUSE_MCU_HANG] = "MCU <token> <answer> hang", 
<token> = "PSE reset failed", <answer> [RESET_CAUSE_RESET_FAILED] 
int <token> <answer> i; 
for (i = <token> i < ARRAY_SIZE(reset_cause_str); i++) { <answer> 0; 
<token> (!reset_cause_str[i]) <answer> if 
seq_printf(s, <token> %u\n", reset_cause_str[i], <answer> "%20s: 
return <token> <answer> 0; 
<token> int <answer> static 
mt7603_radio_read(struct seq_file *s, <token> *data) <answer> void 
struct mt7603_dev *dev <token> dev_get_drvdata(s->private); <answer> = 
seq_printf(s, <token> %d\n", dev->sensitivity); <answer> "Sensitivity: 
seq_printf(s, <token> CCA: ofdm=%d cck=%d\n", <answer> "False 
<token> dev->false_cca_cck); <answer> dev->false_cca_ofdm, 
<token> 0; <answer> return 
static <token> <answer> int 
<token> *data, u64 val) <answer> mt7603_edcca_set(void 
struct mt7603_dev <token> = data; <answer> *dev 
<token> = !!val; <answer> dev->ed_monitor_enabled 
dev->ed_monitor = <token> && <answer> dev->ed_monitor_enabled 
dev->mt76.region <token> NL80211_DFS_ETSI; <answer> == 
return <token> <answer> 0; 
static <token> <answer> int 
mt7603_edcca_get(void *data, <token> *val) <answer> u64 
struct mt7603_dev *dev = <token> <answer> data; 
*val <token> dev->ed_monitor_enabled; <answer> = 
<token> 0; <answer> return 
DEFINE_DEBUGFS_ATTRIBUTE(fops_edcca, <token> <answer> mt7603_edcca_get, 
<token> "%lld\n"); <answer> mt7603_edcca_set, 
<token> int <answer> static 
mt7603_ampdu_stat_show(struct seq_file *file, void <token> <answer> *data) 
struct mt7603_dev *dev = <token> <answer> file->private; 
<token> bound[3], i, range; <answer> int 
range = mt76_rr(dev, <token> <answer> MT_AGG_ASRCR); 
for (i = 0; <token> < ARRAY_SIZE(bound); i++) <answer> i 
bound[i] = MT_AGG_ASRCR_RANGE(range, <token> + 1; <answer> i) 
seq_printf(file, "Length: %8d | ", <token> <answer> bound[0]); 
for <token> = 0; i < ARRAY_SIZE(bound) - 1; i++) <answer> (i 
seq_printf(file, <token> -%3d | ", <answer> "%3d 
bound[i], <token> + 1]); <answer> bound[i 
seq_puts(file, "\nCount: <token> <answer> "); 
for (i = 0; i < <token> i++) <answer> ARRAY_SIZE(bound); 
seq_printf(file, <token> | ", dev->mphy.aggr_stats[i]); <answer> "%8d 
<token> "\n"); <answer> seq_puts(file, 
<token> 0; <answer> return 
void <token> mt7603_dev *dev) <answer> mt7603_init_debugfs(struct 
struct dentry <token> <answer> *dir; 
dir = <token> <answer> mt76_register_debugfs(&dev->mt76); 
<token> (!dir) <answer> if 
debugfs_create_file("ampdu_stat", <token> dir, dev, <answer> 0400, 
debugfs_create_devm_seqfile(dev->mt76.dev, <token> dir, <answer> "xmit-queues", 
debugfs_create_file("edcca", 0600, dir, dev, <token> <answer> &fops_edcca); 
<token> 0600, dir, &dev->reset_test); <answer> debugfs_create_u32("reset_test", 
debugfs_create_devm_seqfile(dev->mt76.dev, <token> dir, <answer> "reset", 
debugfs_create_devm_seqfile(dev->mt76.dev, "radio", <token> <answer> dir, 
debugfs_create_u8("sensitivity_limit", <token> dir, <answer> 0600, 
debugfs_create_bool("dynamic_sensitivity", <token> dir, <answer> 0600, 
#define <token> "arm_dmc620" <answer> DMC620_PMUNAME 
#define DMC620_DRVNAME <token> "_pmu" <answer> DMC620_PMUNAME 
#define <token> DMC620_DRVNAME ": " fmt <answer> pr_fmt(fmt) 
#include <token> <answer> <linux/acpi.h> 
<token> <linux/bitfield.h> <answer> #include 
#include <token> <answer> <linux/bitops.h> 
<token> <linux/cpuhotplug.h> <answer> #include 
<token> <linux/cpumask.h> <answer> #include 
<token> <linux/device.h> <answer> #include 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/irq.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/list.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/mutex.h> 
<token> <linux/perf_event.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/printk.h> 
#include <token> <answer> <linux/rculist.h> 
#include <token> <answer> <linux/refcount.h> 
#define <token> 12 <answer> DMC620_PA_SHIFT 
#define <token> 0x80000000 <answer> DMC620_CNT_INIT 
#define DMC620_CNT_MAX_PERIOD <token> <answer> 0xffffffff 
#define <token> 8 <answer> DMC620_PMU_CLKDIV2_MAX_COUNTERS 
#define <token> 2 <answer> DMC620_PMU_CLK_MAX_COUNTERS 
<token> DMC620_PMU_MAX_COUNTERS \ <answer> #define 
(DMC620_PMU_CLKDIV2_MAX_COUNTERS <token> DMC620_PMU_CLK_MAX_COUNTERS) <answer> + 
<token> DMC620_PMU_OVERFLOW_STATUS_CLKDIV2 0x8 <answer> #define 
<token> DMC620_PMU_OVERFLOW_STATUS_CLKDIV2_MASK \ <answer> #define 
(DMC620_PMU_CLKDIV2_MAX_COUNTERS <token> 1) <answer> - 
#define <token> 0xC <answer> DMC620_PMU_OVERFLOW_STATUS_CLK 
<token> DMC620_PMU_OVERFLOW_STATUS_CLK_MASK \ <answer> #define 
(DMC620_PMU_CLK_MAX_COUNTERS <token> 1) <answer> - 
#define DMC620_PMU_COUNTERS_BASE <token> <answer> 0x10 
#define DMC620_PMU_COUNTERn_MASK_31_00 <token> <answer> 0x0 
#define <token> 0x4 <answer> DMC620_PMU_COUNTERn_MASK_63_32 
#define DMC620_PMU_COUNTERn_MATCH_31_00 <token> <answer> 0x8 
#define DMC620_PMU_COUNTERn_MATCH_63_32 <token> <answer> 0xC 
#define DMC620_PMU_COUNTERn_CONTROL <token> <answer> 0x10 
#define DMC620_PMU_COUNTERn_CONTROL_ENABLE <token> <answer> BIT(0) 
<token> DMC620_PMU_COUNTERn_CONTROL_INVERT BIT(1) <answer> #define 
#define DMC620_PMU_COUNTERn_CONTROL_EVENT_MUX <token> 2) <answer> GENMASK(6, 
#define DMC620_PMU_COUNTERn_CONTROL_INCR_MUX GENMASK(8, <token> <answer> 7) 
#define DMC620_PMU_COUNTERn_VALUE <token> <answer> 0x20 
static <token> <answer> DEFINE_MUTEX(dmc620_pmu_irqs_lock); 
static <token> <answer> DEFINE_MUTEX(dmc620_pmu_node_lock); 
<token> LIST_HEAD(dmc620_pmu_irqs); <answer> static 
<token> dmc620_pmu_irq { <answer> struct 
struct hlist_node <token> <answer> node; 
struct <token> pmus_node; <answer> list_head 
struct <token> irqs_node; <answer> list_head 
<token> refcount; <answer> refcount_t 
<token> int irq_num; <answer> unsigned 
unsigned <token> cpu; <answer> int 
struct <token> { <answer> dmc620_pmu 
struct pmu <token> <answer> pmu; 
void __iomem <token> <answer> *base; 
struct dmc620_pmu_irq <token> <answer> *irq; 
struct <token> pmus_node; <answer> list_head 
DECLARE_BITMAP(used_mask, <token> <answer> DMC620_PMU_MAX_COUNTERS); 
struct <token> *events[DMC620_PMU_MAX_COUNTERS]; <answer> perf_event 
<token> to_dmc620_pmu(p) (container_of(p, struct dmc620_pmu, pmu)) <answer> #define 
<token> int cpuhp_state_num; <answer> static 
struct <token> { <answer> dmc620_pmu_event_attr 
struct <token> attr; <answer> device_attribute 
<token> clkdiv2; <answer> u8 
<token> eventid; <answer> u8 
<token> ssize_t <answer> static 
<token> device *dev, <answer> dmc620_pmu_event_show(struct 
struct <token> *attr, char *page) <answer> device_attribute 
struct <token> *eattr; <answer> dmc620_pmu_event_attr 
eattr = container_of(attr, typeof(*eattr), <token> <answer> attr); 
return sysfs_emit(page, <token> eattr->eventid, eattr->clkdiv2); <answer> "event=0x%x,clkdiv2=0x%x\n", 
#define <token> _eventid, _clkdiv2) \ <answer> DMC620_PMU_EVENT_ATTR(_name, 
(&((struct dmc620_pmu_event_attr[]) {{ <token> <answer> \ 
.attr = __ATTR(_name, 0444, dmc620_pmu_event_show, NULL), <token> <answer> \ 
.clkdiv2 <token> _clkdiv2, \ <answer> = 
.eventid = <token> \ <answer> _eventid, 
static <token> attribute *dmc620_pmu_events_attrs[] = { <answer> struct 
for (idx = 0; idx < DMC620_PMU_MAX_COUNTERS; <token> { <answer> idx++) 
event = <token> <answer> dmc620_pmu->events[idx]; 
<token> (!event) <answer> if 
<token> = readl(dmc620_pmu->base + DMC620_PMU_OVERFLOW_STATUS_CLKDIV2); <answer> status 
status |= (readl(dmc620_pmu->base <token> DMC620_PMU_OVERFLOW_STATUS_CLK) << <answer> + 
if <token> { <answer> (status) 
for_each_set_bit(idx, <token> <answer> &status, 
DMC620_PMU_MAX_COUNTERS) <token> <answer> { 
event = <token> <answer> dmc620_pmu->events[idx]; 
<token> (WARN_ON_ONCE(!event)) <answer> if 
if <token> & DMC620_PMU_OVERFLOW_STATUS_CLKDIV2_MASK) <answer> (status 
writel(0, dmc620_pmu->base + <token> <answer> DMC620_PMU_OVERFLOW_STATUS_CLKDIV2); 
if ((status >> <token> & <answer> DMC620_PMU_CLKDIV2_MAX_COUNTERS) 
writel(0, dmc620_pmu->base <token> DMC620_PMU_OVERFLOW_STATUS_CLK); <answer> + 
<token> (idx = 0; idx < DMC620_PMU_MAX_COUNTERS; idx++) { <answer> for 
event <token> dmc620_pmu->events[idx]; <answer> = 
<token> (!event) <answer> if 
if (!(event->hw.state <token> PERF_HES_STOPPED)) <answer> & 
ret <token> IRQ_HANDLED; <answer> = 
<token> ret; <answer> return 
static struct dmc620_pmu_irq *__dmc620_pmu_get_irq(int <token> <answer> irq_num) 
struct <token> *irq; <answer> dmc620_pmu_irq 
<token> ret; <answer> int 
list_for_each_entry(irq, &dmc620_pmu_irqs, <token> <answer> irqs_node) 
if (irq->irq_num == irq_num <token> refcount_inc_not_zero(&irq->refcount)) <answer> && 
return <token> <answer> irq; 
<token> = kzalloc(sizeof(*irq), GFP_KERNEL); <answer> irq 
<token> (!irq) <answer> if 
return <token> <answer> ERR_PTR(-ENOMEM); 
<token> (is_sampling_event(event) || <answer> if 
<token> & PERF_ATTACH_TASK) { <answer> event->attach_state 
<token> support per-task counters\n"); <answer> "Can't 
<token> -EOPNOTSUPP; <answer> return 
event->cpu = <token> <answer> dmc620_pmu->irq->cpu; 
if <token> < 0) <answer> (event->cpu 
<token> -EINVAL; <answer> return 
if (event->group_leader != event <token> <answer> && 
return <token> <answer> -EINVAL; 
for_each_sibling_event(sibling, <token> { <answer> event->group_leader) 
if (sibling != <token> && <answer> event 
return <token> <answer> -EINVAL; 
hwc->idx <token> -1; <answer> = 
return <token> <answer> 0; 
static void <token> perf_event *event) <answer> dmc620_pmu_read(struct 
static <token> dmc620_pmu_start(struct perf_event *event, int flags) <answer> void 
event->hw.state <token> 0; <answer> = 
<token> void dmc620_pmu_stop(struct perf_event *event, int flags) <answer> static 
if (event->hw.state <token> PERF_HES_STOPPED) <answer> & 
event->hw.state |= <token> | PERF_HES_UPTODATE; <answer> PERF_HES_STOPPED 
static int dmc620_pmu_add(struct perf_event <token> int flags) <answer> *event, 
struct dmc620_pmu *dmc620_pmu = <token> <answer> to_dmc620_pmu(event->pmu); 
struct perf_event_attr <token> = &event->attr; <answer> *attr 
struct hw_perf_event *hwc <token> &event->hw; <answer> = 
int <token> <answer> idx; 
<token> reg; <answer> u64 
idx = <token> <answer> dmc620_get_event_idx(event); 
if (idx < <token> <answer> 0) 
<token> idx; <answer> return 
hwc->idx = <token> <answer> idx; 
<token> = event; <answer> dmc620_pmu->events[idx] 
hwc->state <token> PERF_HES_STOPPED | PERF_HES_UPTODATE; <answer> = 
<token> = ATTR_CFG_GET_FLD(attr, mask); <answer> reg 
idx, DMC620_PMU_COUNTERn_MASK_31_00, <token> <answer> lower_32_bits(reg)); 
<token> DMC620_PMU_COUNTERn_MASK_63_32, upper_32_bits(reg)); <answer> idx, 
reg = ATTR_CFG_GET_FLD(attr, <token> <answer> match); 
idx, DMC620_PMU_COUNTERn_MATCH_31_00, <token> <answer> lower_32_bits(reg)); 
<token> DMC620_PMU_COUNTERn_MATCH_63_32, upper_32_bits(reg)); <answer> idx, 
if (flags & <token> <answer> PERF_EF_START) 
dmc620_pmu_start(event, <token> <answer> PERF_EF_RELOAD); 
return <token> <answer> 0; 
static void <token> perf_event *event, int flags) <answer> dmc620_pmu_del(struct 
struct dmc620_pmu *dmc620_pmu <token> to_dmc620_pmu(event->pmu); <answer> = 
<token> hw_perf_event *hwc = &event->hw; <answer> struct 
int idx = <token> <answer> hwc->idx; 
dmc620_pmu_stop(event, <token> <answer> PERF_EF_UPDATE); 
dmc620_pmu->events[idx] <token> NULL; <answer> = 
clear_bit(idx, <token> <answer> dmc620_pmu->used_mask); 
<token> int dmc620_pmu_cpu_teardown(unsigned int cpu, <answer> static 
struct hlist_node <token> <answer> *node) 
struct dmc620_pmu_irq <token> <answer> *irq; 
<token> dmc620_pmu *dmc620_pmu; <answer> struct 
unsigned <token> target; <answer> int 
irq <token> hlist_entry_safe(node, struct dmc620_pmu_irq, node); <answer> = 
if <token> != irq->cpu) <answer> (cpu 
<token> 0; <answer> return 
target = cpumask_any_but(cpu_online_mask, <token> <answer> cpu); 
<token> (target >= nr_cpu_ids) <answer> if 
<token> 0; <answer> return 
#include <token> <answer> <linux/etherdevice.h> 
#include <token> <answer> <linux/skbuff.h> 
#include <token> <answer> "iwl-trans.h" 
<token> "mvm.h" <answer> #include 
#include <token> <answer> "fw-api.h" 
<token> "time-sync.h" <answer> #include 
static inline int iwl_mvm_check_pn(struct iwl_mvm *mvm, struct <token> *skb, <answer> sk_buff 
int <token> struct ieee80211_sta *sta) <answer> queue, 
<token> iwl_mvm_sta *mvmsta; <answer> struct 
<token> ieee80211_hdr *hdr = (void *)skb_mac_header(skb); <answer> struct 
<token> ieee80211_rx_status *stats = IEEE80211_SKB_RXCB(skb); <answer> struct 
<token> iwl_mvm_key_pn *ptk_pn; <answer> struct 
int <token> <answer> res; 
u8 <token> keyidx; <answer> tid, 
<token> pn[IEEE80211_CCMP_PN_LEN]; <answer> u8 
u8 <token> <answer> *extiv; 
if (queue == <token> <answer> 0) 
return <token> <answer> 0; 
if (len > mic_crc_len <token> !ieee80211_hw_check(mvm->hw, RX_INCLUDES_FCS)) <answer> && 
len -= <token> <answer> mic_crc_len; 
headlen <token> (len <= skb_tailroom(skb)) ? len : <answer> = 
hdrlen + crypt_len + <token> <answer> 8; 
hdrlen <token> crypt_len; <answer> += 
if <token> < hdrlen)) <answer> (unlikely(headlen 
return <token> <answer> -EINVAL; 
<token> skb->len); <answer> skb_set_mac_header(skb, 
<token> hdr, hdrlen); <answer> skb_put_data(skb, 
skb_put_data(skb, (u8 *)hdr + <token> + pad_len, headlen - hdrlen); <answer> hdrlen 
if (skb->ip_summed == CHECKSUM_COMPLETE) <token> <answer> { 
struct <token> <answer> { 
<token> hdr[6]; <answer> u8 
__be16 <token> <answer> type; 
} __packed *shdr = (void <token> *)hdr + hdrlen + pad_len); <answer> *)((u8 
if <token> - hdrlen < sizeof(*shdr) || <answer> (unlikely(headlen 
!ether_addr_equal(shdr->hdr, rfc1042_header) <token> <answer> || 
(shdr->type <token> htons(ETH_P_IP) && <answer> != 
shdr->type <token> htons(ETH_P_ARP) && <answer> != 
shdr->type != htons(ETH_P_IPV6) <token> <answer> && 
<token> != htons(ETH_P_8021Q) && <answer> shdr->type 
<token> != htons(ETH_P_PAE) && <answer> shdr->type 
shdr->type != <token> <answer> htons(ETH_P_TDLS)))) 
skb->ip_summed <token> CHECKSUM_NONE; <answer> = 
else if (mvm->trans->trans_cfg->device_family < <token> <answer> IWL_DEVICE_FAMILY_BZ) 
static void <token> <answer> * 
iwl_mvm_radiotap_put_tlv(struct sk_buff *skb, u16 type, <token> len) <answer> u16 
<token> ieee80211_radiotap_tlv *tlv; <answer> struct 
tlv = skb_put(skb, <token> <answer> sizeof(*tlv)); 
tlv->type <token> cpu_to_le16(type); <answer> = 
<token> = cpu_to_le16(len); <answer> tlv->len 
return skb_put_zero(skb, ALIGN(len, <token> <answer> 4)); 
static void iwl_mvm_add_rtap_sniffer_config(struct iwl_mvm <token> <answer> *mvm, 
struct sk_buff <token> <answer> *skb) 
struct ieee80211_rx_status <token> = IEEE80211_SKB_RXCB(skb); <answer> *rx_status 
struct <token> *radiotap; <answer> ieee80211_radiotap_vendor_content 
<token> u16 vendor_data_len = sizeof(mvm->cur_aid); <answer> const 
<token> (!mvm->cur_aid) <answer> if 
radiotap = <token> <answer> iwl_mvm_radiotap_put_tlv(skb, 
sizeof(*radiotap) <token> vendor_data_len); <answer> + 
<token> (!ieee80211_is_beacon(hdr->frame_control)) <answer> if 
return <token> <answer> 0; 
if <token> <answer> (!sta) 
<token> -1; <answer> return 
mvmsta <token> iwl_mvm_sta_from_mac80211(sta); <answer> = 
mvmvif = <token> <answer> iwl_mvm_vif_from_mac80211(mvmsta->vif); 
key = <token> <answer> rcu_dereference(mvmvif->bcn_prot.keys[0]); 
if (!key) <token> <answer> { 
key <token> rcu_dereference(mvmvif->bcn_prot.keys[1]); <answer> = 
<token> (!key) <answer> if 
<token> report; <answer> goto 
if (len < key->icv_len + IEEE80211_GMAC_PN_LEN + <token> <answer> 2) 
<token> report; <answer> goto 
if <token> != 6 && keyid != 7) <answer> (keyid 
<token> -1; <answer> return 
key = rcu_dereference(mvmvif->bcn_prot.keys[keyid <token> 6]); <answer> - 
if <token> <answer> (!key) 
goto <token> <answer> report; 
<token> (phy_info & IWL_RX_MPDU_PHY_AMPDU && <answer> if 
<token> & IWL_RX_MPDU_STATUS_SEC_MASK) == <answer> (status 
<token> && !mvm->monitor_on) { <answer> IWL_RX_MPDU_STATUS_SEC_UNKNOWN 
<token> "Dropping packets, bad enc status\n"); <answer> IWL_DEBUG_DROP(mvm, 
return <token> <answer> -1; 
if <token> && <answer> (unlikely(ieee80211_is_mgmt(hdr->frame_control) 
return iwl_mvm_rx_mgmt_prot(sta, hdr, desc, status, <token> <answer> stats); 
if (!ieee80211_has_protected(hdr->frame_control) <token> <answer> || 
(status & <token> == <answer> IWL_RX_MPDU_STATUS_SEC_MASK) 
return <token> <answer> 0; 
<token> (!is_multicast_ether_addr(hdr->addr1) && <answer> if 
!mvm->monitor_on && <token> <answer> net_ratelimit()) 
IWL_WARN(mvm, "Unhandled alg: 0x%x\n", <token> <answer> status); 
return <token> <answer> 0; 
static void <token> iwl_mvm *mvm, <answer> iwl_mvm_rx_csum(struct 
struct ieee80211_sta <token> <answer> *sta, 
struct <token> *skb, <answer> sk_buff 
<token> iwl_rx_packet *pkt) <answer> struct 
<token> iwl_rx_mpdu_desc *desc = (void *)pkt->data; <answer> struct 
<token> (mvm->trans->trans_cfg->device_family >= IWL_DEVICE_FAMILY_AX210) { <answer> if 
if <token> & cpu_to_le32(FH_RSCSR_RPA_EN)) { <answer> (pkt->len_n_flags 
u16 hwsum = <token> <answer> be16_to_cpu(desc->v3.raw_xsum); 
<token> = CHECKSUM_COMPLETE; <answer> skb->ip_summed 
skb->csum = <token> __sum16)hwsum); <answer> csum_unfold(~(__force 
} <token> { <answer> else 
struct iwl_mvm_sta <token> = iwl_mvm_sta_from_mac80211(sta); <answer> *mvmsta 
struct iwl_mvm_vif <token> <answer> *mvmvif; 
u16 flags = <token> <answer> le16_to_cpu(desc->l3l4_flags); 
u8 l3_prot <token> (u8)((flags & IWL_RX_L3L4_L3_PROTO_MASK) >> <answer> = 
<token> = iwl_mvm_vif_from_mac80211(mvmsta->vif); <answer> mvmvif 
if (mvmvif->features & NETIF_F_RXCSUM <token> <answer> && 
flags <token> IWL_RX_L3L4_TCP_UDP_CSUM_OK && <answer> & 
(flags <token> IWL_RX_L3L4_IP_HDR_CSUM_OK || <answer> & 
l3_prot == IWL_RX_L3_TYPE_IPV6 <token> <answer> || 
l3_prot == <token> <answer> IWL_RX_L3_TYPE_IPV6_FRAG)) 
skb->ip_summed <token> CHECKSUM_UNNECESSARY; <answer> = 
static bool iwl_mvm_is_dup(struct ieee80211_sta *sta, <token> queue, <answer> int 
struct ieee80211_rx_status <token> <answer> *rx_status, 
<token> ieee80211_hdr *hdr, <answer> struct 
<token> iwl_rx_mpdu_desc *desc) <answer> struct 
struct <token> *mvm_sta; <answer> iwl_mvm_sta 
<token> iwl_mvm_rxq_dup_data *dup_data; <answer> struct 
<token> tid, sub_frame_idx; <answer> u8 
if <token> <answer> (WARN_ON(IS_ERR_OR_NULL(sta))) 
<token> false; <answer> return 
<token> = iwl_mvm_sta_from_mac80211(sta); <answer> mvm_sta 
if <token> <answer> (WARN_ON_ONCE(!mvm_sta->dup_data)) 
return <token> <answer> false; 
dup_data = <token> <answer> &mvm_sta->dup_data[queue]; 
if (ieee80211_is_ctl(hdr->frame_control) <token> <answer> || 
ieee80211_is_any_nullfunc(hdr->frame_control) <token> <answer> || 
<token> false; <answer> return 
<token> (ieee80211_is_data_qos(hdr->frame_control)) { <answer> if 
while ((skb = __skb_dequeue(skb_list))) <token> <answer> { 
iwl_mvm_pass_packet_to_mac80211(mvm, <token> skb, <answer> napi, 
reorder_buf->head_sn <token> nssn; <answer> = 
static void iwl_mvm_del_ba(struct iwl_mvm <token> int queue, <answer> *mvm, 
struct iwl_mvm_delba_data <token> <answer> *data) 
struct iwl_mvm_baid_data <token> <answer> *ba_data; 
struct <token> *sta; <answer> ieee80211_sta 
<token> iwl_mvm_reorder_buffer *reorder_buf; <answer> struct 
u8 <token> = data->baid; <answer> baid 
u32 <token> <answer> sta_id; 
if (WARN_ONCE(baid >= IWL_MAX_BAID, "invalid BAID: <token> baid)) <answer> %x\n", 
<token> = rcu_dereference(mvm->baid_map[baid]); <answer> ba_data 
if <token> <answer> (WARN_ON_ONCE(!ba_data)) 
goto <token> <answer> out; 
static bool <token> iwl_mvm *mvm, <answer> iwl_mvm_reorder(struct 
struct napi_struct <token> <answer> *napi, 
<token> queue, <answer> int 
struct <token> *sta, <answer> ieee80211_sta 
<token> sk_buff *skb, <answer> struct 
struct <token> *desc) <answer> iwl_rx_mpdu_desc 
struct ieee80211_hdr *hdr <token> (void *)skb_mac_header(skb); <answer> = 
struct iwl_mvm_baid_data <token> <answer> *baid_data; 
struct iwl_mvm_reorder_buffer <token> <answer> *buffer; 
u32 reorder = <token> <answer> le32_to_cpu(desc->reorder_data); 
bool amsdu = <token> & IWL_RX_MPDU_MFLG2_AMSDU; <answer> desc->mac_flags2 
<token> last_subframe = <answer> bool 
desc->amsdu_info & <token> <answer> IWL_RX_MPDU_AMSDU_LAST_SUBFRAME; 
u8 tid = <token> <answer> ieee80211_get_tid(hdr); 
u8 sub_frame_idx = <token> & <answer> desc->amsdu_info 
struct iwl_mvm_reorder_buf_entry <token> <answer> *entries; 
u32 <token> <answer> sta_mask; 
<token> index; <answer> int 
u16 <token> sn; <answer> nssn, 
u8 <token> <answer> baid; 
baid = (reorder <token> IWL_RX_MPDU_REORDER_BAID_MASK) >> <answer> & 
<token> (mvm->trans->trans_cfg->device_family == IWL_DEVICE_FAMILY_9000) <answer> if 
<token> false; <answer> return 
if (baid <token> IWL_RX_REORDER_DATA_INVALID_BAID) <answer> == 
return <token> <answer> false; 
if (!buffer->num_stored <token> sn == buffer->head_sn) { <answer> && 
if (!amsdu || <token> <answer> last_subframe) 
buffer->head_sn = <token> <answer> ieee80211_sn_inc(buffer->head_sn); 
<token> (!amsdu || last_subframe) <answer> if 
iwl_mvm_release_frames(mvm, <token> napi, baid_data, <answer> sta, 
<token> nssn); <answer> buffer, 
return <token> <answer> true; 
return <token> <answer> true; 
static void iwl_mvm_agg_rx_received(struct <token> *mvm, <answer> iwl_mvm 
u32 reorder_data, <token> baid) <answer> u8 
unsigned long <token> = jiffies; <answer> now 
unsigned <token> timeout; <answer> long 
struct iwl_mvm_baid_data <token> <answer> *data; 
data = <token> <answer> rcu_dereference(mvm->baid_map[baid]); 
if (!data) <token> <answer> { 
"Got valid BAID but no baid allocated, bypass the <token> buffer. Baid %d reorder 0x%x\n", <answer> re-ordering 
baid, <token> <answer> reorder_data); 
<token> out; <answer> goto 
if <token> <answer> (!data->timeout) 
goto <token> <answer> out; 
<token> = data->timeout; <answer> timeout 
if (time_before(data->last_rx <token> TU_TO_JIFFIES(timeout), now)) <answer> + 
u8 ru = le32_get_bits(phy_data->d1, <token> <answer> IWL_RX_PHY_DATA1_HE_RU_ALLOC_MASK); 
u32 rate_n_flags = <token> <answer> phy_data->rate_n_flags; 
u32 he_type = rate_n_flags & <token> <answer> RATE_MCS_HE_TYPE_MSK_V1; 
u8 offs <token> 0; <answer> = 
rx_status->bw <token> RATE_INFO_BW_HE_RU; <answer> = 
he->data1 |= <token> <answer> cpu_to_le16(IEEE80211_RADIOTAP_HE_DATA1_BW_RU_ALLOC_KNOWN); 
switch <token> { <answer> (ru) 
case <token> ... 36: <answer> 0 
<token> = NL80211_RATE_INFO_HE_RU_ALLOC_26; <answer> rx_status->he_ru 
offs <token> ru; <answer> = 
<token> 37 ... 52: <answer> case 
rx_status->he_ru <token> NL80211_RATE_INFO_HE_RU_ALLOC_52; <answer> = 
<token> = ru - 37; <answer> offs 
case <token> ... 60: <answer> 53 
rx_status->he_ru = <token> <answer> NL80211_RATE_INFO_HE_RU_ALLOC_106; 
<token> = ru - 53; <answer> offs 
case <token> ... 64: <answer> 61 
rx_status->he_ru = <token> <answer> NL80211_RATE_INFO_HE_RU_ALLOC_242; 
offs = ru <token> 61; <answer> - 
case 65 <token> 66: <answer> ... 
rx_status->he_ru = <token> <answer> NL80211_RATE_INFO_HE_RU_ALLOC_484; 
<token> = ru - 65; <answer> offs 
case <token> <answer> 67: 
rx_status->he_ru <token> NL80211_RATE_INFO_HE_RU_ALLOC_996; <answer> = 
case <token> <answer> 68: 
rx_status->he_ru <token> NL80211_RATE_INFO_HE_RU_ALLOC_2x996; <answer> = 
<token> |= le16_encode_bits(offs, <answer> he->data2 
<token> |= cpu_to_le16(IEEE80211_RADIOTAP_HE_DATA2_PRISEC_80_KNOWN | <answer> he->data2 
if (phy_data->d1 <token> cpu_to_le32(IWL_RX_PHY_DATA1_HE_RU_ALLOC_SEC80)) <answer> & 
he->data2 <token> <answer> |= 
#define <token> \ <answer> CHECK_BW(bw) 
BUILD_BUG_ON(IEEE80211_RADIOTAP_HE_MU_FLAGS2_BW_FROM_SIG_A_BW_ <token> bw ## MHZ != \ <answer> ## 
RATE_MCS_CHAN_WIDTH_##bw <token> RATE_MCS_CHAN_WIDTH_POS); \ <answer> >> 
BUILD_BUG_ON(IEEE80211_RADIOTAP_HE_DATA6_TB_PPDU_BW_ ## bw ## <token> != \ <answer> MHZ 
RATE_MCS_CHAN_WIDTH_##bw <token> RATE_MCS_CHAN_WIDTH_POS) <answer> >> 
if <token> <answer> (he_mu) 
<token> |= <answer> he_mu->flags2 
else if (he_type <token> RATE_MCS_HE_TYPE_TRIG_V1) <answer> == 
<token> |= <answer> he->data6 
<token> | <answer> cpu_to_le16(IEEE80211_RADIOTAP_HE_DATA6_TB_PPDU_BW_KNOWN) 
static void <token> iwl_mvm *mvm, <answer> iwl_mvm_decode_he_phy_data(struct 
struct iwl_mvm_rx_phy_data <token> <answer> *phy_data, 
struct <token> *he, <answer> ieee80211_radiotap_he 
struct ieee80211_radiotap_he_mu <token> <answer> *he_mu, 
struct <token> *rx_status, <answer> ieee80211_rx_status 
<token> queue) <answer> int 
switch <token> { <answer> (phy_data->info_type) 
case <token> <answer> IWL_RX_PHY_INFO_TYPE_NONE: 
<token> IWL_RX_PHY_INFO_TYPE_CCK: <answer> case 
<token> IWL_RX_PHY_INFO_TYPE_OFDM_LGCY: <answer> case 
case <token> <answer> IWL_RX_PHY_INFO_TYPE_HT: 
<token> IWL_RX_PHY_INFO_TYPE_VHT_SU: <answer> case 
<token> IWL_RX_PHY_INFO_TYPE_VHT_MU: <answer> case 
<token> IWL_RX_PHY_INFO_TYPE_EHT_MU: <answer> case 
<token> IWL_RX_PHY_INFO_TYPE_EHT_TB: <answer> case 
case <token> <answer> IWL_RX_PHY_INFO_TYPE_EHT_MU_EXT: 
<token> IWL_RX_PHY_INFO_TYPE_EHT_TB_EXT: <answer> case 
<token> IWL_RX_PHY_INFO_TYPE_HE_TB_EXT: <answer> case 
<token> |= cpu_to_le16(IEEE80211_RADIOTAP_HE_DATA1_SPTL_REUSE_KNOWN | <answer> he->data1 
<token> | <answer> IEEE80211_RADIOTAP_HE_DATA1_SPTL_REUSE2_KNOWN 
IEEE80211_RADIOTAP_HE_DATA1_SPTL_REUSE3_KNOWN <token> <answer> | 
he->data4 |= <token> <answer> le16_encode_bits(le32_get_bits(phy_data->d2, 
he->data4 <token> le16_encode_bits(le32_get_bits(phy_data->d2, <answer> |= 
<token> |= le16_encode_bits(le32_get_bits(phy_data->d2, <answer> he->data4 
<token> |= le16_encode_bits(le32_get_bits(phy_data->d2, <answer> he->data4 
case <token> <answer> IWL_RX_PHY_INFO_TYPE_HE_SU: 
<token> IWL_RX_PHY_INFO_TYPE_HE_MU: <answer> case 
<token> IWL_RX_PHY_INFO_TYPE_HE_MU_EXT: <answer> case 
case <token> <answer> IWL_RX_PHY_INFO_TYPE_HE_TB: 
switch (phy_bw) <token> <answer> { 
<token> RATE_MCS_CHAN_WIDTH_320: <answer> case 
<token> (ru) { <answer> switch 
case <token> ... 36: <answer> 0 
<token> = NL80211_RATE_INFO_EHT_RU_ALLOC_26; <answer> nl_ru 
case <token> ... 52: <answer> 37 
nl_ru = <token> <answer> NL80211_RATE_INFO_EHT_RU_ALLOC_52; 
case <token> ... 60: <answer> 53 
nl_ru = <token> <answer> NL80211_RATE_INFO_EHT_RU_ALLOC_106; 
case 61 <token> 64: <answer> ... 
nl_ru = <token> <answer> NL80211_RATE_INFO_EHT_RU_ALLOC_242; 
case 65 <token> 66: <answer> ... 
nl_ru = <token> <answer> NL80211_RATE_INFO_EHT_RU_ALLOC_484; 
<token> 67: <answer> case 
<token> = NL80211_RATE_INFO_EHT_RU_ALLOC_996; <answer> nl_ru 
<token> 68: <answer> case 
nl_ru = <token> <answer> NL80211_RATE_INFO_EHT_RU_ALLOC_2x996; 
case <token> <answer> 69: 
nl_ru = <token> <answer> NL80211_RATE_INFO_EHT_RU_ALLOC_4x996; 
case <token> ... 81: <answer> 70 
nl_ru = <token> <answer> NL80211_RATE_INFO_EHT_RU_ALLOC_52P26; 
case 82 <token> 89: <answer> ... 
nl_ru <token> NL80211_RATE_INFO_EHT_RU_ALLOC_106P26; <answer> = 
case 90 ... <token> <answer> 93: 
<token> = NL80211_RATE_INFO_EHT_RU_ALLOC_484P242; <answer> nl_ru 
case <token> ... 95: <answer> 94 
nl_ru <token> NL80211_RATE_INFO_EHT_RU_ALLOC_996P484; <answer> = 
<token> 96 ... 99: <answer> case 
nl_ru <token> NL80211_RATE_INFO_EHT_RU_ALLOC_996P484P242; <answer> = 
case 100 <token> 103: <answer> ... 
nl_ru = <token> <answer> NL80211_RATE_INFO_EHT_RU_ALLOC_2x996P484; 
case <token> <answer> 104: 
<token> = NL80211_RATE_INFO_EHT_RU_ALLOC_3x996; <answer> nl_ru 
<token> 105 ... 106: <answer> case 
nl_ru = <token> <answer> NL80211_RATE_INFO_EHT_RU_ALLOC_3x996P484; 
rx_status->bw = <token> <answer> RATE_INFO_BW_EHT_RU; 
rx_status->eht.ru = <token> <answer> nl_ru; 
static void iwl_mvm_decode_eht_phy_data(struct <token> *mvm, <answer> iwl_mvm 
struct <token> *phy_data, <answer> iwl_mvm_rx_phy_data 
struct ieee80211_rx_status <token> <answer> *rx_status, 
struct ieee80211_radiotap_eht <token> <answer> *eht, 
struct <token> *usig) <answer> ieee80211_radiotap_eht_usig 
<token> data0 = phy_data->d0; <answer> __le32 
__le32 <token> = phy_data->d1; <answer> data1 
__le32 usig_a1 <token> phy_data->rx_vec[0]; <answer> = 
<token> info_type = phy_data->info_type; <answer> u8 
eht->known |= <token> <answer> cpu_to_le32(IEEE80211_RADIOTAP_EHT_KNOWN_PRIMARY_80); 
eht->data[1] <token> <answer> |= 
usig->common |= <token> <answer> cpu_to_le32(IEEE80211_RADIOTAP_EHT_USIG_COMMON_TXOP_KNOWN); 
if <token> <answer> (phy_data->with_data) 
usig->common |= LE32_DEC_ENC(data0, <token> <answer> IWL_RX_PHY_DATA0_EHT_TXOP_DUR_MASK, 
usig->common |= <token> IWL_RX_USIG_A1_TXOP_DURATION, <answer> LE32_DEC_ENC(usig_a1, 
<token> |= cpu_to_le32(IEEE80211_RADIOTAP_EHT_KNOWN_LDPC_EXTRA_SYM_OM); <answer> eht->known 
eht->data[0] |= LE32_DEC_ENC(data0, <token> <answer> IWL_RX_PHY_DATA0_EHT_LDPC_EXT_SYM, 
eht->known <token> cpu_to_le32(IEEE80211_RADIOTAP_EHT_KNOWN_PRE_PADD_FACOR_OM); <answer> |= 
eht->data[0] |= LE32_DEC_ENC(data0, <token> <answer> IWL_RX_PHY_DATA0_EHT_PRE_FEC_PAD_MASK, 
eht->known |= <token> <answer> cpu_to_le32(IEEE80211_RADIOTAP_EHT_KNOWN_PE_DISAMBIGUITY_OM); 
eht->data[0] |= LE32_DEC_ENC(data0, <token> <answer> IWL_RX_PHY_DATA0_EHT_PE_DISAMBIG, 
eht->known |= <token> <answer> cpu_to_le32(IEEE80211_RADIOTAP_EHT_KNOWN_EHT_LTF); 
<token> |= LE32_DEC_ENC(data1, IWL_RX_PHY_DATA1_EHT_SIG_LTF_NUM, <answer> eht->data[0] 
if (info_type <token> IWL_RX_PHY_INFO_TYPE_EHT_TB_EXT || <answer> == 
info_type <token> IWL_RX_PHY_INFO_TYPE_EHT_TB) <answer> == 
iwl_mvm_decode_eht_ext_tb(mvm, phy_data, <token> eht, usig); <answer> rx_status, 
if <token> == IWL_RX_PHY_INFO_TYPE_EHT_MU_EXT || <answer> (info_type 
info_type == <token> <answer> IWL_RX_PHY_INFO_TYPE_EHT_MU) 
<token> phy_data, rx_status, eht, usig); <answer> iwl_mvm_decode_eht_ext_mu(mvm, 
static void iwl_mvm_rx_eht(struct iwl_mvm *mvm, struct sk_buff <token> <answer> *skb, 
<token> iwl_mvm_rx_phy_data *phy_data, <answer> struct 
int <token> <answer> queue) 
struct ieee80211_rx_status *rx_status = <token> <answer> IEEE80211_SKB_RXCB(skb); 
struct ieee80211_radiotap_eht <token> <answer> *eht; 
struct ieee80211_radiotap_eht_usig <token> <answer> *usig; 
size_t <token> = sizeof(*eht); <answer> eht_len 
u32 rate_n_flags = <token> <answer> phy_data->rate_n_flags; 
u32 <token> = rate_n_flags & RATE_MCS_HE_TYPE_MSK; <answer> he_type 
static void iwl_mvm_rx_fill_status(struct <token> *mvm, <answer> iwl_mvm 
struct <token> *skb, <answer> sk_buff 
<token> iwl_mvm_rx_phy_data *phy_data, <answer> struct 
int <token> <answer> queue) 
struct <token> *rx_status = IEEE80211_SKB_RXCB(skb); <answer> ieee80211_rx_status 
u32 rate_n_flags = <token> <answer> phy_data->rate_n_flags; 
u8 stbc = <token> RATE_MCS_STBC_MSK); <answer> u32_get_bits(rate_n_flags, 
<token> format = rate_n_flags & RATE_MCS_MOD_TYPE_MSK; <answer> u32 
<token> is_sgi; <answer> bool 
phy_data->info_type = <token> <answer> IWL_RX_PHY_INFO_TYPE_NONE; 
if (phy_data->phy_info <token> IWL_RX_MPDU_PHY_TSF_OVERLOAD) <answer> & 
phy_data->info_type <token> <answer> = 
skb = alloc_skb(128, <token> <answer> GFP_ATOMIC); 
<token> (!skb) { <answer> if 
IWL_ERR(mvm, <token> failed\n"); <answer> "alloc_skb 
<token> (desc->mac_flags2 & IWL_RX_MPDU_MFLG2_PAD) { <answer> if 
<token> 2); <answer> skb_reserve(skb, 
rx_status <token> IEEE80211_SKB_RXCB(skb); <answer> = 
<token> (!(desc->status & cpu_to_le32(IWL_RX_MPDU_STATUS_CRC_OK)) || <answer> if 
!(desc->status & <token> { <answer> cpu_to_le32(IWL_RX_MPDU_STATUS_OVERRUN_OK))) 
IWL_DEBUG_RX(mvm, "Bad <token> or FIFO: 0x%08X.\n", <answer> CRC 
rx_status->flag |= <token> <answer> RX_FLAG_FAILED_FCS_CRC; 
<token> (toggle_bit != mvm->ampdu_toggle) { <answer> if 
<token> (mvm->ampdu_ref == 0) <answer> if 
mvm->ampdu_toggle <token> toggle_bit; <answer> = 
<token> = true; <answer> phy_data.first_subframe 
<token> = mvm->ampdu_ref; <answer> rx_status->ampdu_reference 
if (desc->status & <token> { <answer> cpu_to_le32(IWL_RX_MPDU_STATUS_SRC_STA_FOUND)) 
u8 id = <token> IWL_RX_MPDU_STATUS_STA_ID); <answer> le32_get_bits(desc->status, 
if (!WARN_ON_ONCE(id <token> mvm->fw->ucode_capa.num_stations)) { <answer> >= 
sta <token> rcu_dereference(mvm->fw_id_to_mac_id[id]); <answer> = 
<token> (IS_ERR(sta)) <answer> if 
sta <token> NULL; <answer> = 
<token> = rcu_dereference(mvm->fw_id_to_link_sta[id]); <answer> link_sta 
if <token> && sta->valid_links && link_sta) { <answer> (sta 
<token> = 1; <answer> rx_status->link_valid 
rx_status->link_id <token> link_sta->link_id; <answer> = 
} else <token> (!is_multicast_ether_addr(hdr->addr2)) { <answer> if 
sta = ieee80211_find_sta_by_ifaddr(mvm->hw, hdr->addr2, <token> <answer> NULL); 
if (iwl_mvm_rx_crypto(mvm, sta, hdr, rx_status, <token> desc, <answer> phy_data.phy_info, 
le32_to_cpu(pkt->len_n_flags), <token> <answer> queue, 
<token> { <answer> &crypt_len)) 
<token> out; <answer> goto 
iwl_mvm_rx_fill_status(mvm, <token> &phy_data, queue); <answer> skb, 
if (sta) <token> <answer> { 
struct <token> *mvmsta = iwl_mvm_sta_from_mac80211(sta); <answer> iwl_mvm_sta 
<token> ieee80211_vif *tx_blocked_vif = <answer> struct 
u8 <token> = (u8)((le32_to_cpu(desc->reorder_data) & <answer> baid 
IWL_RX_MPDU_REORDER_BAID_MASK) <token> <answer> >> 
struct <token> *trig; <answer> iwl_fw_dbg_trigger_tlv 
struct ieee80211_vif *vif <token> mvmsta->vif; <answer> = 
if <token> && len >= sizeof(*hdr) && <answer> (!mvm->tcm.paused 
!is_multicast_ether_addr(hdr->addr1) <token> <answer> && 
ieee80211_is_data(hdr->frame_control) <token> <answer> && 
time_after(jiffies, mvm->tcm.ts + <token> <answer> MVM_TCM_PERIOD)) 
<token> 0); <answer> schedule_delayed_work(&mvm->tcm.work, 
if (unlikely(tx_blocked_vif) && tx_blocked_vif <token> vif) { <answer> == 
struct <token> *mvmvif = <answer> iwl_mvm_vif 
<token> iwl_rx_sta_csa rx_sta_csa = { <answer> struct 
.all_sta_unblocked = <token> <answer> true, 
.vif = <token> <answer> tx_blocked_vif, 
if (mvmvif->csa_target_freq == <token> <answer> rx_status->freq) 
<token> sta, <answer> iwl_mvm_sta_modify_disable_tx_ap(mvm, 
if (rx_sta_csa.all_sta_unblocked) <token> <answer> { 
RCU_INIT_POINTER(mvm->csa_tx_blocked_vif, <token> <answer> NULL); 
<token> ((desc->mac_flags2 & IWL_RX_MPDU_MFLG2_AMSDU) && <answer> if 
<token> { <answer> !WARN_ON(!ieee80211_is_data_qos(hdr->frame_control))) 
u8 *qc <token> ieee80211_get_qos_ctl(hdr); <answer> = 
<token> &= ~IEEE80211_QOS_CTL_A_MSDU_PRESENT; <answer> *qc 
<token> (mvm->trans->trans_cfg->device_family == <answer> if 
IWL_DEVICE_FAMILY_9000) <token> <answer> { 
if <token> <answer> (ieee80211_has_a4(hdr->frame_control)) 
if (baid <token> IWL_RX_REORDER_DATA_INVALID_BAID) { <answer> != 
u32 reorder_data <token> le32_to_cpu(desc->reorder_data); <answer> = 
iwl_mvm_agg_rx_received(mvm, reorder_data, <token> <answer> baid); 
skb = <token> GFP_ATOMIC); <answer> alloc_skb(128, 
<token> (!skb) { <answer> if 
IWL_ERR(mvm, "alloc_skb <token> <answer> failed\n"); 
<token> = IEEE80211_SKB_RXCB(skb); <answer> rx_status 
switch <token> { <answer> (format) 
<token> RATE_MCS_VHT_MSK: <answer> case 
rx_status->nss <token> <answer> = 
RX_NO_DATA_RX_VEC0_VHT_NSTS_MSK) <token> 1; <answer> + 
case <token> <answer> RATE_MCS_HE_MSK: 
<token> = <answer> rx_status->nss 
<token> + 1; <answer> RX_NO_DATA_RX_VEC0_HE_NSTS_MSK) 
<token> RATE_MCS_EHT_MSK: <answer> case 
<token> = <answer> rx_status->nss 
RX_NO_DATA_RX_VEC2_EHT_NSTS_MSK) <token> 1; <answer> + 
<token> sta, skb, napi); <answer> ieee80211_rx_napi(mvm->hw, 
void <token> iwl_mvm *mvm, struct napi_struct *napi, <answer> iwl_mvm_rx_frame_release(struct 
<token> iwl_rx_cmd_buffer *rxb, int queue) <answer> struct 
struct <token> *pkt = rxb_addr(rxb); <answer> iwl_rx_packet 
struct iwl_frame_release *release <token> (void *)pkt->data; <answer> = 
if (unlikely(iwl_rx_packet_payload_len(pkt) < <token> <answer> sizeof(*release))) 
iwl_mvm_release_frames_from_notif(mvm, napi, <token> <answer> release->baid, 
void iwl_mvm_rx_bar_frame_release(struct iwl_mvm <token> struct napi_struct *napi, <answer> *mvm, 
<token> iwl_rx_cmd_buffer *rxb, int queue) <answer> struct 
struct iwl_rx_packet *pkt <token> rxb_addr(rxb); <answer> = 
<token> iwl_bar_frame_release *release = (void *)pkt->data; <answer> struct 
unsigned <token> baid = le32_get_bits(release->ba_info, <answer> int 
unsigned <token> nssn = le32_get_bits(release->ba_info, <answer> int 
unsigned <token> sta_id = le32_get_bits(release->sta_tid, <answer> int 
unsigned int <token> = le32_get_bits(release->sta_tid, <answer> tid 
<token> iwl_mvm_baid_data *baid_data; <answer> struct 
if (unlikely(iwl_rx_packet_payload_len(pkt) <token> sizeof(*release))) <answer> < 
if (WARN_ON_ONCE(baid == <token> || <answer> IWL_RX_REORDER_DATA_INVALID_BAID 
<token> >= ARRAY_SIZE(mvm->baid_map))) <answer> baid 
<token> = rcu_dereference(mvm->baid_map[baid]); <answer> baid_data 
if (!baid_data) <token> <answer> { 
"Got <token> BAID %d but not allocated, invalid BAR release!\n", <answer> valid 
<token> out; <answer> goto 
if (WARN(tid != <token> || sta_id > IWL_MVM_STATION_COUNT_MAX || <answer> baid_data->tid 
<token> & BIT(sta_id)), <answer> !(baid_data->sta_mask 
"baid 0x%x is mapped to sta_mask:0x%x tid:%d, but BAR release received <token> sta:%d tid:%d\n", <answer> for 
baid, baid_data->sta_mask, baid_data->tid, <token> <answer> sta_id, 
goto <token> <answer> out; 
IWL_DEBUG_DROP(mvm, "Received a BAR, expect packet <token> nssn %d\n", <answer> loss: 
iwl_mvm_release_frames_from_notif(mvm, <token> baid, nssn, queue); <answer> napi, 
#include <token> <answer> "dml1_display_rq_dlg_calc.h" 
#include <token> <answer> "display_mode_lib.h" 
<token> "dml_inline_defs.h" <answer> #include 
static unsigned int get_bytes_per_element(enum source_format_class source_format, bool <token> <answer> is_chroma) 
unsigned int <token> = 0; <answer> ret_val 
if (source_format == <token> { <answer> dm_444_16) 
if <token> <answer> (!is_chroma) 
ret_val <token> 2; <answer> = 
} else if (source_format == <token> { <answer> dm_444_32) 
<token> (!is_chroma) <answer> if 
ret_val <token> 4; <answer> = 
} else <token> (source_format == dm_444_64) { <answer> if 
if <token> <answer> (!is_chroma) 
ret_val = <token> <answer> 8; 
} else <token> (source_format == dm_420_8) { <answer> if 
<token> (is_chroma) <answer> if 
ret_val <token> 2; <answer> = 
ret_val = <token> <answer> 1; 
} else <token> (source_format == dm_420_10) { <answer> if 
<token> (is_chroma) <answer> if 
ret_val <token> 4; <answer> = 
<token> = 2; <answer> ret_val 
<token> ret_val; <answer> return 
static bool <token> source_format_class source_format) <answer> is_dual_plane(enum 
<token> ret_val = 0; <answer> bool 
if ((source_format == dm_420_8) <token> (source_format == dm_420_10)) <answer> || 
ret_val <token> 1; <answer> = 
<token> ret_val; <answer> return 
static void <token> <answer> get_blk256_size( 
unsigned int <token> <answer> *blk256_width, 
unsigned <token> *blk256_height, <answer> int 
<token> int bytes_per_element) <answer> unsigned 
if <token> == 1) { <answer> (bytes_per_element 
*blk256_width <token> 16; <answer> = 
*blk256_height = <token> <answer> 16; 
} else if (bytes_per_element == <token> { <answer> 2) 
*blk256_width <token> 16; <answer> = 
*blk256_height = <token> <answer> 8; 
} else <token> (bytes_per_element == 4) { <answer> if 
*blk256_width <token> 8; <answer> = 
*blk256_height = <token> <answer> 8; 
} else if (bytes_per_element == 8) <token> <answer> { 
*blk256_width = <token> <answer> 8; 
*blk256_height = <token> <answer> 4; 
static double <token> <answer> get_refcyc_per_delivery( 
<token> display_mode_lib *mode_lib, <answer> struct 
double <token> <answer> refclk_freq_in_mhz, 
<token> pclk_freq_in_mhz, <answer> double 
<token> int recout_width, <answer> unsigned 
double <token> <answer> vratio, 
double <token> <answer> hscale_pixel_rate, 
<token> int delivery_width, <answer> unsigned 
unsigned int <token> <answer> req_per_swath_ub) 
double refcyc_per_delivery <token> 0.0; <answer> = 
if (vratio <= <token> { <answer> 1.0) 
refcyc_per_delivery = (double) refclk_freq_in_mhz * (double) <token> <answer> recout_width 
/ pclk_freq_in_mhz / (double) <token> <answer> req_per_swath_ub; 
} <token> { <answer> else 
refcyc_per_delivery = (double) refclk_freq_in_mhz * (double) <token> <answer> delivery_width 
/ (double) hscale_pixel_rate <token> (double) req_per_swath_ub; <answer> / 
DTRACE("DLG: %s: refclk_freq_in_mhz = %3.2f", <token> refclk_freq_in_mhz); <answer> __func__, 
DTRACE("DLG: %s: pclk_freq_in_mhz <token> %3.2f", __func__, pclk_freq_in_mhz); <answer> = 
DTRACE("DLG: <token> recout_width = %d", __func__, recout_width); <answer> %s: 
DTRACE("DLG: %s: vratio <token> %3.2f", __func__, vratio); <answer> = 
DTRACE("DLG: <token> req_per_swath_ub = %d", __func__, req_per_swath_ub); <answer> %s: 
<token> %s: refcyc_per_delivery= %3.2f", __func__, refcyc_per_delivery); <answer> DTRACE("DLG: 
<token> refcyc_per_delivery; <answer> return 
static <token> get_vratio_pre( <answer> double 
struct <token> *mode_lib, <answer> display_mode_lib 
unsigned <token> max_num_sw, <answer> int 
unsigned int <token> <answer> max_partial_sw, 
<token> int swath_height, <answer> unsigned 
double <token> <answer> vinit, 
double <token> <answer> l_sw) 
<token> prefill = dml_floor(vinit, 1); <answer> double 
<token> vratio_pre = 1.0; <answer> double 
vratio_pre = <token> * swath_height + max_partial_sw) / l_sw; <answer> (max_num_sw 
if <token> > 4) { <answer> (swath_height 
<token> tmp0 = (max_num_sw * swath_height) / (l_sw - (prefill - 3.0) / 2.0); <answer> double 
if <token> > vratio_pre) <answer> (tmp0 
vratio_pre <token> tmp0; <answer> = 
DTRACE("DLG: %s: max_num_sw = %0d", <token> max_num_sw); <answer> __func__, 
DTRACE("DLG: %s: max_partial_sw = <token> __func__, max_partial_sw); <answer> %0d", 
<token> %s: swath_height = %0d", __func__, swath_height); <answer> DTRACE("DLG: 
<token> %s: vinit = %3.2f", __func__, vinit); <answer> DTRACE("DLG: 
DTRACE("DLG: <token> vratio_pre = %3.2f", __func__, vratio_pre); <answer> %s: 
if (vratio_pre < <token> { <answer> 1.0) 
DTRACE("WARNING_DLG: <token> vratio_pre=%3.2f < 1.0, set to 1.0", __func__, vratio_pre); <answer> %s: 
vratio_pre <token> 1.0; <answer> = 
if (vratio_pre <token> 4.0) { <answer> > 
"WARNING_DLG: <token> vratio_pre=%3.2f > 4.0 (max scaling ratio). set to 4.0", <answer> %s: 
<token> = 4.0; <answer> vratio_pre 
return <token> <answer> vratio_pre; 
static <token> get_swath_need( <answer> void 
struct display_mode_lib <token> <answer> *mode_lib, 
unsigned int <token> <answer> *max_num_sw, 
unsigned <token> *max_partial_sw, <answer> int 
<token> int swath_height, <answer> unsigned 
<token> vinit) <answer> double 
<token> prefill = dml_floor(vinit, 1); <answer> double 
unsigned <token> max_partial_sw_int; <answer> int 
DTRACE("DLG: %s: swath_height = %0d", <token> swath_height); <answer> __func__, 
<token> %s: vinit = %3.2f", __func__, vinit); <answer> DTRACE("DLG: 
<token> > 0.0 && prefill <= 8.0); <answer> ASSERT(prefill 
if (req128_l <token> 1) { <answer> == 
<token> = 1; <answer> req128_c 
<token> %s: bug workaround DEGVIDCN10-137", __func__); <answer> DTRACE("DLG: 
} else <token> <answer> { 
total_swath_bytes = 2 <token> full_swath_bytes_packed_l; <answer> * 
if (total_swath_bytes <= <token> <answer> detile_buf_size_in_bytes) 
req128_l <token> 0; <answer> = 
req128_l <token> 1; <answer> = 
swath_bytes_l = <token> <answer> total_swath_bytes; 
<token> = 0; <answer> swath_bytes_c 
<token> = swath_bytes_l; <answer> rq_param->misc.rq_l.stored_swath_bytes 
<token> = swath_bytes_c; <answer> rq_param->misc.rq_c.stored_swath_bytes 
<token> (surf_linear) { <answer> if 
<token> = 0; <answer> log2_swath_height_l 
log2_swath_height_c = <token> <answer> 0; 
} <token> { <answer> else 
<token> int swath_height_l; <answer> unsigned 
<token> int swath_height_c; <answer> unsigned 
<token> (!surf_vert) { <answer> if 
swath_height_l = <token> <answer> rq_param->misc.rq_l.blk256_height; 
swath_height_c <token> rq_param->misc.rq_c.blk256_height; <answer> = 
<token> else { <answer> } 
<token> = rq_param->misc.rq_l.blk256_width; <answer> swath_height_l 
swath_height_c = <token> <answer> rq_param->misc.rq_c.blk256_width; 
if (swath_height_l > <token> <answer> 0) 
<token> = dml_log2(swath_height_l); <answer> log2_swath_height_l 
if <token> && log2_swath_height_l > 0) <answer> (req128_l 
log2_swath_height_l <token> 1; <answer> -= 
if <token> > 0) <answer> (swath_height_c 
<token> = dml_log2(swath_height_c); <answer> log2_swath_height_c 
if <token> && log2_swath_height_c > 0) <answer> (req128_c 
log2_swath_height_c -= <token> <answer> 1; 
rq_param->dlg.rq_l.swath_height = 1 << <token> <answer> log2_swath_height_l; 
rq_param->dlg.rq_c.swath_height = <token> << log2_swath_height_c; <answer> 1 
DTRACE("DLG: %s: req128_l = %0d", __func__, <token> <answer> req128_l); 
DTRACE("DLG: %s: req128_c = %0d", <token> req128_c); <answer> __func__, 
DTRACE("DLG: %s: full_swath_bytes_packed_l <token> %0d", __func__, full_swath_bytes_packed_l); <answer> = 
DTRACE("DLG: %s: <token> = %0d", __func__, full_swath_bytes_packed_c); <answer> full_swath_bytes_packed_c 
if <token> != dm_sw_linear) <answer> (tiling 
log2_blk_height <token> log2_blk256_height <answer> = 
+ dml_ceil((double) (log2_blk_bytes - 8) / 2.0, <token> <answer> 1); 
<token> (!surf_vert) <answer> if 
log2_meta_row_height <token> log2_meta_req_height; <answer> = 
log2_meta_row_height <token> log2_meta_req_width; <answer> = 
*o_meta_row_height = 1 << <token> <answer> log2_meta_row_height; 
log2_dpte_req_height <token> log2_vmpg_height + log2_dpte_req_height_ptes; <answer> = 
log2_dpte_req_width <token> log2_vmpg_width + log2_dpte_req_width_ptes; <answer> = 
dpte_req_width = 1 << <token> <answer> log2_dpte_req_width; 
<token> (surf_linear) { <answer> if 
log2_dpte_row_height_linear = <token> <answer> dml_floor( 
dml_log2(dpte_buf_in_pte_reqs <token> dpte_req_width / data_pitch), <answer> * 
<token> >= 3); <answer> ASSERT(log2_dpte_row_height_linear 
if (log2_dpte_row_height_linear <token> 7) <answer> > 
log2_dpte_row_height_linear <token> 7; <answer> = 
<token> = log2_dpte_row_height_linear; <answer> log2_dpte_row_height 
<token> else { <answer> } 
if (!surf_vert && vp_width > (2560 + 16) && bytes_per_element >= 4 && log2_vmpg_bytes <token> 12 <answer> == 
&& log2_blk_bytes <token> 16) <answer> >= 
if (pipe_src_param->sw_mode != <token> <answer> dm_sw_linear) 
log2_blk_height <token> log2_blk256_height <answer> = 
+ dml_ceil((double) (log2_blk_bytes - 8) <token> 2.0, 1); <answer> / 
if (!surf_vert) <token> <answer> { 
log2_meta_row_height <token> log2_meta_req_height; <answer> = 
meta_row_width_ub = <token> - 1, meta_req_width, 1) <answer> dml_round_to_multiple(vp_width 
+ <token> <answer> meta_req_width; 
rq_dlg_param->meta_req_per_row_ub = <token> / meta_req_width; <answer> meta_row_width_ub 
} <token> { <answer> else 
<token> = log2_meta_req_width; <answer> log2_meta_row_height 
meta_row_width_ub = <token> - 1, meta_req_height, 1) <answer> dml_round_to_multiple(vp_height 
+ <token> <answer> meta_req_height; 
rq_dlg_param->meta_req_per_row_ub <token> meta_row_width_ub / meta_req_height; <answer> = 
rq_dlg_param->meta_bytes_per_row_ub = rq_dlg_param->meta_req_per_row_ub * <token> <answer> 64; 
log2_meta_chunk_bytes = <token> <answer> dml_log2(rq_sizing_param->meta_chunk_bytes); 
<token> = log2_meta_row_height; <answer> log2_meta_chunk_height 
log2_dpte_req_height = log2_vmpg_height <token> log2_dpte_req_height_ptes; <answer> + 
log2_dpte_req_width = <token> + log2_dpte_req_width_ptes; <answer> log2_vmpg_width 
dpte_req_height <token> 1 << log2_dpte_req_height; <answer> = 
dpte_req_width = 1 << <token> <answer> log2_dpte_req_width; 
if <token> { <answer> (surf_linear) 
<token> = dml_floor( <answer> log2_dpte_row_height_linear 
<token> * dpte_req_width / data_pitch), <answer> dml_log2(dpte_buf_in_pte_reqs 
ASSERT(log2_dpte_row_height_linear <token> 3); <answer> >= 
if (log2_dpte_row_height_linear > <token> <answer> 7) 
<token> = 7; <answer> log2_dpte_row_height_linear 
log2_dpte_row_height <token> log2_dpte_row_height_linear; <answer> = 
rq_dlg_param->dpte_row_height = 1 <token> log2_dpte_row_height; <answer> << 
dpte_row_width_ub <token> dml_round_to_multiple( <answer> = 
data_pitch <token> dpte_row_height - 1, <answer> * 
1) <token> dpte_req_width; <answer> + 
rq_dlg_param->dpte_req_per_row_ub = dpte_row_width_ub <token> dpte_req_width; <answer> / 
} else <token> <answer> { 
if (!surf_vert && vp_width > (2560 + <token> && bytes_per_element >= 4 && log2_vmpg_bytes == 12 <answer> 16) 
&& log2_blk_bytes >= <token> { <answer> 16) 
rq_dlg_param->dpte_groups_per_row_ub = <token> <answer> dml_ceil( 
(double) dpte_row_width_ub / <token> <answer> dpte_group_width, 
if (rq_dlg_param->meta_row_height != <token> { <answer> func_meta_row_height) 
"MISMATCH: rq_dlg_param->meta_row_height <token> %d", <answer> = 
DTRACE("MISMATCH: <token> = %d", func_meta_row_height); <answer> func_meta_row_height 
<token> (rq_dlg_param->dpte_row_height != func_dpte_row_height) { <answer> if 
"MISMATCH: rq_dlg_param->dpte_row_height = <token> <answer> %d", 
<token> func_dpte_row_height = %d", func_dpte_row_height); <answer> DTRACE("MISMATCH: 
void <token> <answer> dml1_rq_dlg_get_rq_params( 
struct <token> *mode_lib, <answer> display_mode_lib 
struct <token> *rq_param, <answer> _vcs_dpi_display_rq_params_st 
const struct <token> *pipe_src_param) <answer> _vcs_dpi_display_pipe_source_params_st 
void <token> <answer> dml1_rq_dlg_get_dlg_params( 
<token> display_mode_lib *mode_lib, <answer> struct 
struct _vcs_dpi_display_dlg_regs_st <token> <answer> *disp_dlg_regs, 
<token> _vcs_dpi_display_ttu_regs_st *disp_ttu_regs, <answer> struct 
<token> struct _vcs_dpi_display_rq_dlg_params_st *rq_dlg_param, <answer> const 
const struct <token> *dlg_sys_param, <answer> _vcs_dpi_display_dlg_sys_params_st 
const <token> _vcs_dpi_display_e2e_pipe_params_st *e2e_pipe_param, <answer> struct 
<token> bool cstate_en, <answer> const 
const <token> pstate_en, <answer> bool 
<token> bool vm_en, <answer> const 
<token> bool iflip_en) <answer> const 
<token> pr_fmt(fmt) KBUILD_MODNAME ": " fmt <answer> #define 
<token> <linux/crc32.h> <answer> #include 
#include <token> <answer> <linux/ethtool.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/list.h> <answer> #include 
#include <token> <answer> <linux/mii.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/net_tstamp.h> <answer> #include 
<token> <linux/netdevice.h> <answer> #include 
<token> <linux/if_vlan.h> <answer> #include 
<token> <linux/phy.h> <answer> #include 
<token> <linux/ptp_classify.h> <answer> #include 
#include <token> <answer> <linux/ptp_clock_kernel.h> 
<token> "dp83640_reg.h" <answer> #include 
#define DP83640_PHY_ID <token> <answer> 0x20005ce1 
#define <token> 0x13 <answer> PAGESEL 
<token> MAX_RXTS 64 <answer> #define 
#define <token> 6 <answer> N_EXT_TS 
<token> N_PER_OUT 7 <answer> #define 
#define PSF_PTPVER <token> <answer> 2 
#define PSF_EVNT <token> <answer> 0x4000 
<token> PSF_RX 0x2000 <answer> #define 
#define <token> 0x1000 <answer> PSF_TX 
#define EXT_EVENT <token> <answer> 1 
#define CAL_EVENT <token> <answer> 7 
#define CAL_TRIGGER <token> <answer> 1 
#define <token> 12 <answer> DP83640_N_PINS 
#define <token> 0x11 <answer> MII_DP83640_MICR 
#define <token> 0x12 <answer> MII_DP83640_MISR 
#define <token> 0x1 <answer> MII_DP83640_MICR_OE 
#define <token> 0x2 <answer> MII_DP83640_MICR_IE 
#define MII_DP83640_MISR_RHF_INT_EN <token> <answer> 0x01 
#define <token> 0x02 <answer> MII_DP83640_MISR_FHF_INT_EN 
#define <token> 0x04 <answer> MII_DP83640_MISR_ANC_INT_EN 
<token> MII_DP83640_MISR_DUP_INT_EN 0x08 <answer> #define 
#define MII_DP83640_MISR_SPD_INT_EN <token> <answer> 0x10 
<token> MII_DP83640_MISR_LINK_INT_EN 0x20 <answer> #define 
<token> MII_DP83640_MISR_ED_INT_EN 0x40 <answer> #define 
#define <token> 0x80 <answer> MII_DP83640_MISR_LQ_INT_EN 
#define MII_DP83640_MISR_ANC_INT <token> <answer> 0x400 
<token> MII_DP83640_MISR_DUP_INT 0x800 <answer> #define 
<token> MII_DP83640_MISR_SPD_INT 0x1000 <answer> #define 
#define <token> 0x2000 <answer> MII_DP83640_MISR_LINK_INT 
<token> MII_DP83640_MISR_INT_MASK (MII_DP83640_MISR_ANC_INT |\ <answer> #define 
MII_DP83640_MISR_DUP_INT <token> <answer> |\ 
MII_DP83640_MISR_SPD_INT <token> <answer> |\ 
<token> &clock->phylist, list) { <answer> list_for_each_entry(tmp, 
<token> clock->page, 1); <answer> enable_broadcast(tmp->phydev, 
tmp->cfg0 <token> ext_read(tmp->phydev, PAGE5, PSF_CFG0); <answer> = 
ext_write(0, tmp->phydev, <token> PSF_CFG0, 0); <answer> PAGE5, 
ext_write(0, tmp->phydev, <token> PTP_CTL, PTP_ENABLE); <answer> PAGE4, 
<token> clock->page, 1); <answer> enable_broadcast(master, 
cfg0 = ext_read(master, PAGE5, <token> <answer> PSF_CFG0); 
ext_write(0, master, PAGE5, <token> 0); <answer> PSF_CFG0, 
ext_write(0, <token> PAGE4, PTP_CTL, PTP_ENABLE); <answer> master, 
evnt = <token> | EVNT_RISE | EVNT_SINGLE; <answer> EVNT_WR 
evnt |= (CAL_EVENT & EVNT_SEL_MASK) <token> EVNT_SEL_SHIFT; <answer> << 
<token> |= (cal_gpio & EVNT_GPIO_MASK) << EVNT_GPIO_SHIFT; <answer> evnt 
list_for_each_entry(tmp, <token> list) <answer> &clock->phylist, 
ext_write(0, tmp->phydev, PAGE5, PTP_EVNT, <token> <answer> evnt); 
ext_write(0, master, <token> PTP_EVNT, evnt); <answer> PAGE5, 
ptp_trig <token> TRIG_WR | TRIG_IF_LATE | TRIG_PULSE; <answer> = 
<token> |= (trigger & TRIG_CSEL_MASK) << TRIG_CSEL_SHIFT; <answer> ptp_trig 
<token> |= (cal_gpio & TRIG_GPIO_MASK) << TRIG_GPIO_SHIFT; <answer> ptp_trig 
<token> master, PAGE5, PTP_TRIG, ptp_trig); <answer> ext_write(0, 
val = ext_read(master, <token> PTP_STS); <answer> PAGE4, 
phydev_info(master, "master PTP_STS <token> val); <answer> 0x%04hx\n", 
val = ext_read(master, <token> PTP_ESTS); <answer> PAGE4, 
phydev_info(master, <token> PTP_ESTS 0x%04hx\n", val); <answer> "master 
<token> = ext_read(master, PAGE4, PTP_EDATA); <answer> event_ts.ns_lo 
<token> = ext_read(master, PAGE4, PTP_EDATA); <answer> event_ts.ns_hi 
event_ts.sec_lo = ext_read(master, <token> PTP_EDATA); <answer> PAGE4, 
event_ts.sec_hi = <token> PAGE4, PTP_EDATA); <answer> ext_read(master, 
now <token> phy2txts(&event_ts); <answer> = 
<token> &clock->phylist, list) { <answer> list_for_each_entry(tmp, 
val <token> ext_read(tmp->phydev, PAGE4, PTP_STS); <answer> = 
phydev_info(tmp->phydev, "slave PTP_STS <token> val); <answer> 0x%04hx\n", 
val <token> ext_read(tmp->phydev, PAGE4, PTP_ESTS); <answer> = 
phydev_info(tmp->phydev, "slave PTP_ESTS 0x%04hx\n", <token> <answer> val); 
event_ts.ns_lo = <token> PAGE4, PTP_EDATA); <answer> ext_read(tmp->phydev, 
event_ts.ns_hi <token> ext_read(tmp->phydev, PAGE4, PTP_EDATA); <answer> = 
event_ts.sec_lo = ext_read(tmp->phydev, <token> PTP_EDATA); <answer> PAGE4, 
event_ts.sec_hi <token> ext_read(tmp->phydev, PAGE4, PTP_EDATA); <answer> = 
diff = <token> - (s64) phy2txts(&event_ts); <answer> now 
<token> "slave offset %lld nanoseconds\n", <answer> phydev_info(tmp->phydev, 
<token> += ADJTIME_FIX; <answer> diff 
ts <token> ns_to_timespec64(diff); <answer> = 
tdr_write(0, tmp->phydev, <token> PTP_STEP_CLK); <answer> &ts, 
list_for_each_entry(tmp, &clock->phylist, <token> <answer> list) 
ext_write(0, <token> PAGE5, PSF_CFG0, tmp->cfg0); <answer> tmp->phydev, 
ext_write(0, <token> PAGE5, PSF_CFG0, cfg0); <answer> master, 
<token> int choose_this_phy(struct dp83640_clock *clock, <answer> static 
struct <token> *phydev) <answer> phy_device 
<token> (chosen_phy == -1 && !clock->chosen) <answer> if 
<token> 1; <answer> return 
if <token> == phydev->mdio.addr) <answer> (chosen_phy 
return <token> <answer> 1; 
<token> 0; <answer> return 
static struct dp83640_clock *dp83640_clock_get(struct dp83640_clock <token> <answer> *clock) 
<token> (clock) <answer> if 
return <token> <answer> clock; 
static <token> dp83640_clock *dp83640_clock_get_bus(struct mii_bus *bus) <answer> struct 
struct dp83640_clock <token> = NULL, *tmp; <answer> *clock 
struct list_head <token> <answer> *this; 
list_for_each(this, <token> { <answer> &phyter_clocks) 
tmp = list_entry(this, <token> dp83640_clock, list); <answer> struct 
if (tmp->bus == bus) <token> <answer> { 
clock = <token> <answer> tmp; 
<token> (clock) <answer> if 
goto <token> <answer> out; 
clock = kzalloc(sizeof(struct <token> GFP_KERNEL); <answer> dp83640_clock), 
<token> (!clock) <answer> if 
<token> out; <answer> goto 
<token> = kcalloc(DP83640_N_PINS, <answer> clock->caps.pin_config 
<token> ptp_pin_desc), <answer> sizeof(struct 
if (!clock->caps.pin_config) <token> <answer> { 
clock = <token> <answer> NULL; 
goto <token> <answer> out; 
<token> bus); <answer> dp83640_clock_init(clock, 
list_add_tail(&clock->list, <token> <answer> &phyter_clocks); 
return <token> <answer> dp83640_clock_get(clock); 
static void <token> dp83640_clock *clock) <answer> dp83640_clock_put(struct 
static int dp83640_soft_reset(struct phy_device <token> <answer> *phydev) 
<token> ret; <answer> int 
ret = <token> <answer> genphy_soft_reset(phydev); 
if <token> < 0) <answer> (ret 
return <token> <answer> ret; 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/gpio/consumer.h> 
#include <token> <answer> <linux/i2c.h> 
<token> <linux/init.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/irq.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/regmap.h> 
<token> <linux/regulator/driver.h> <answer> #include 
#include <token> <answer> <linux/regulator/machine.h> 
#include <token> <answer> <linux/regulator/of_regulator.h> 
<token> "slg51000-regulator.h" <answer> #include 
#define <token> 7 <answer> SLG51000_SCTL_EVT 
<token> SLG51000_MAX_EVT_REGISTER 8 <answer> #define 
<token> SLG51000_LDOHP_LV_MIN 1200000 <answer> #define 
#define SLG51000_LDOHP_HV_MIN <token> <answer> 2400000 
<token> slg51000_regulators { <answer> enum 
SLG51000_REGULATOR_LDO1 <token> 0, <answer> = 
<token> slg51000 { <answer> struct 
struct device <token> <answer> *dev; 
<token> regmap *regmap; <answer> struct 
struct regulator_desc <token> <answer> *rdesc[SLG51000_MAX_REGULATORS]; 
struct regulator_dev <token> <answer> *rdev[SLG51000_MAX_REGULATORS]; 
struct gpio_desc <token> <answer> *cs_gpiod; 
<token> chip_irq; <answer> int 
struct <token> { <answer> slg51000_evt_sta 
unsigned int <token> <answer> ereg; 
<token> int sreg; <answer> unsigned 
static const struct slg51000_evt_sta es_reg[SLG51000_MAX_EVT_REGISTER] = <token> <answer> { 
{SLG51000_LDO1_EVENT, <token> <answer> SLG51000_LDO1_STATUS}, 
<token> SLG51000_LDO2_STATUS}, <answer> {SLG51000_LDO2_EVENT, 
{SLG51000_LDO3_EVENT, <token> <answer> SLG51000_LDO3_STATUS}, 
<token> SLG51000_LDO4_STATUS}, <answer> {SLG51000_LDO4_EVENT, 
<token> SLG51000_LDO5_STATUS}, <answer> {SLG51000_LDO5_EVENT, 
<token> SLG51000_LDO6_STATUS}, <answer> {SLG51000_LDO6_EVENT, 
<token> SLG51000_LDO7_STATUS}, <answer> {SLG51000_LDO7_EVENT, 
{SLG51000_SYSCTL_EVENT, <token> <answer> SLG51000_SYSCTL_STATUS}, 
static const struct regmap_range slg51000_writeable_ranges[] = <token> <answer> { 
<token> SLG51000_LDO1_VSEL), <answer> regmap_reg_range(SLG51000_LDO1_VSEL, 
regmap_reg_range(SLG51000_LDO1_MINV, <token> <answer> SLG51000_LDO1_MAXV), 
regmap_reg_range(SLG51000_LDO1_IRQ_MASK, <token> <answer> SLG51000_LDO1_IRQ_MASK), 
regmap_reg_range(SLG51000_LDO2_VSEL, <token> <answer> SLG51000_LDO2_VSEL), 
<token> SLG51000_LDO2_MAXV), <answer> regmap_reg_range(SLG51000_LDO2_MINV, 
<token> SLG51000_LDO2_IRQ_MASK), <answer> regmap_reg_range(SLG51000_LDO2_IRQ_MASK, 
<token> SLG51000_LDO3_VSEL), <answer> regmap_reg_range(SLG51000_LDO3_VSEL, 
regmap_reg_range(SLG51000_LDO3_MINV, <token> <answer> SLG51000_LDO3_MAXV), 
regmap_reg_range(SLG51000_LDO3_IRQ_MASK, <token> <answer> SLG51000_LDO3_IRQ_MASK), 
<token> SLG51000_LDO4_VSEL), <answer> regmap_reg_range(SLG51000_LDO4_VSEL, 
regmap_reg_range(SLG51000_LDO4_MINV, <token> <answer> SLG51000_LDO4_MAXV), 
regmap_reg_range(SLG51000_LDO4_IRQ_MASK, <token> <answer> SLG51000_LDO4_IRQ_MASK), 
<token> SLG51000_LDO5_VSEL), <answer> regmap_reg_range(SLG51000_LDO5_VSEL, 
<token> SLG51000_LDO5_MAXV), <answer> regmap_reg_range(SLG51000_LDO5_MINV, 
<token> SLG51000_LDO5_IRQ_MASK), <answer> regmap_reg_range(SLG51000_LDO5_IRQ_MASK, 
regmap_reg_range(SLG51000_LDO6_VSEL, <token> <answer> SLG51000_LDO6_VSEL), 
<token> SLG51000_LDO6_MAXV), <answer> regmap_reg_range(SLG51000_LDO6_MINV, 
<token> SLG51000_LDO6_IRQ_MASK), <answer> regmap_reg_range(SLG51000_LDO6_IRQ_MASK, 
<token> SLG51000_LDO7_VSEL), <answer> regmap_reg_range(SLG51000_LDO7_VSEL, 
<token> SLG51000_LDO7_MAXV), <answer> regmap_reg_range(SLG51000_LDO7_MINV, 
regmap_reg_range(SLG51000_LDO7_IRQ_MASK, <token> <answer> SLG51000_LDO7_IRQ_MASK), 
<token> SLG51000_OTP_IRQ_MASK), <answer> regmap_reg_range(SLG51000_OTP_IRQ_MASK, 
static const struct regmap_range slg51000_readable_ranges[] <token> { <answer> = 
<token> SLG51000_SYSCTL_IRQ_MASK), <answer> regmap_reg_range(SLG51000_SYSCTL_FAULT_LOG1, 
regmap_reg_range(SLG51000_IO_GPIO1_CONF, <token> <answer> SLG51000_IO_GPIO_STATUS), 
regmap_reg_range(SLG51000_LDO1_VSEL, <token> <answer> SLG51000_LDO1_VSEL), 
regmap_reg_range(SLG51000_LDO1_MINV, <token> <answer> SLG51000_LDO1_MAXV), 
<token> SLG51000_LDO1_VSEL_ACTUAL), <answer> regmap_reg_range(SLG51000_LDO1_MISC1, 
regmap_reg_range(SLG51000_LDO1_EVENT, <token> <answer> SLG51000_LDO1_IRQ_MASK), 
regmap_reg_range(SLG51000_LDO2_VSEL, <token> <answer> SLG51000_LDO2_VSEL), 
<token> SLG51000_LDO2_MAXV), <answer> regmap_reg_range(SLG51000_LDO2_MINV, 
regmap_reg_range(SLG51000_LDO2_MISC1, <token> <answer> SLG51000_LDO2_VSEL_ACTUAL), 
regmap_reg_range(SLG51000_LDO2_EVENT, <token> <answer> SLG51000_LDO2_IRQ_MASK), 
<token> SLG51000_LDO3_VSEL), <answer> regmap_reg_range(SLG51000_LDO3_VSEL, 
<token> SLG51000_LDO3_MAXV), <answer> regmap_reg_range(SLG51000_LDO3_MINV, 
<token> SLG51000_LDO3_VSEL_ACTUAL), <answer> regmap_reg_range(SLG51000_LDO3_CONF1, 
<token> SLG51000_LDO3_IRQ_MASK), <answer> regmap_reg_range(SLG51000_LDO3_EVENT, 
<token> SLG51000_LDO4_VSEL), <answer> regmap_reg_range(SLG51000_LDO4_VSEL, 
regmap_reg_range(SLG51000_LDO4_MINV, <token> <answer> SLG51000_LDO4_MAXV), 
<token> SLG51000_LDO4_VSEL_ACTUAL), <answer> regmap_reg_range(SLG51000_LDO4_CONF1, 
regmap_reg_range(SLG51000_LDO4_EVENT, <token> <answer> SLG51000_LDO4_IRQ_MASK), 
regmap_reg_range(SLG51000_LDO5_VSEL, <token> <answer> SLG51000_LDO5_VSEL), 
regmap_reg_range(SLG51000_LDO5_MINV, <token> <answer> SLG51000_LDO5_MAXV), 
<token> SLG51000_LDO5_TRIM2), <answer> regmap_reg_range(SLG51000_LDO5_TRIM2, 
<token> SLG51000_LDO5_VSEL_ACTUAL), <answer> regmap_reg_range(SLG51000_LDO5_CONF1, 
<token> SLG51000_LDO5_IRQ_MASK), <answer> regmap_reg_range(SLG51000_LDO5_EVENT, 
regmap_reg_range(SLG51000_LDO6_VSEL, <token> <answer> SLG51000_LDO6_VSEL), 
<token> SLG51000_LDO6_MAXV), <answer> regmap_reg_range(SLG51000_LDO6_MINV, 
<token> SLG51000_LDO6_TRIM2), <answer> regmap_reg_range(SLG51000_LDO6_TRIM2, 
<token> SLG51000_LDO6_VSEL_ACTUAL), <answer> regmap_reg_range(SLG51000_LDO6_CONF1, 
regmap_reg_range(SLG51000_LDO6_EVENT, <token> <answer> SLG51000_LDO6_IRQ_MASK), 
<token> SLG51000_LDO7_VSEL), <answer> regmap_reg_range(SLG51000_LDO7_VSEL, 
<token> SLG51000_LDO7_MAXV), <answer> regmap_reg_range(SLG51000_LDO7_MINV, 
<token> SLG51000_LDO7_VSEL_ACTUAL), <answer> regmap_reg_range(SLG51000_LDO7_CONF1, 
<token> SLG51000_LDO7_IRQ_MASK), <answer> regmap_reg_range(SLG51000_LDO7_EVENT, 
<token> SLG51000_OTP_EVENT), <answer> regmap_reg_range(SLG51000_OTP_EVENT, 
regmap_reg_range(SLG51000_OTP_IRQ_MASK, <token> <answer> SLG51000_OTP_IRQ_MASK), 
regmap_reg_range(SLG51000_OTP_LOCK_OTP_PROG, <token> <answer> SLG51000_OTP_LOCK_CTRL), 
<token> const struct regmap_range slg51000_volatile_ranges[] = { <answer> static 
regmap_reg_range(SLG51000_SYSCTL_FAULT_LOG1, <token> <answer> SLG51000_SYSCTL_STATUS), 
regmap_reg_range(SLG51000_IO_GPIO_STATUS, <token> <answer> SLG51000_IO_GPIO_STATUS), 
regmap_reg_range(SLG51000_LDO1_EVENT, <token> <answer> SLG51000_LDO1_STATUS), 
regmap_reg_range(SLG51000_LDO2_EVENT, <token> <answer> SLG51000_LDO2_STATUS), 
regmap_reg_range(SLG51000_LDO3_EVENT, <token> <answer> SLG51000_LDO3_STATUS), 
<token> SLG51000_LDO4_STATUS), <answer> regmap_reg_range(SLG51000_LDO4_EVENT, 
<token> SLG51000_LDO5_STATUS), <answer> regmap_reg_range(SLG51000_LDO5_EVENT, 
<token> SLG51000_LDO6_STATUS), <answer> regmap_reg_range(SLG51000_LDO6_EVENT, 
<token> SLG51000_LDO7_STATUS), <answer> regmap_reg_range(SLG51000_LDO7_EVENT, 
<token> SLG51000_OTP_EVENT), <answer> regmap_reg_range(SLG51000_OTP_EVENT, 
static const struct regmap_access_table <token> = { <answer> slg51000_writeable_table 
.yes_ranges <token> slg51000_writeable_ranges, <answer> = 
.n_yes_ranges <token> ARRAY_SIZE(slg51000_writeable_ranges), <answer> = 
<token> const struct regmap_access_table slg51000_readable_table = { <answer> static 
<token> = slg51000_readable_ranges, <answer> .yes_ranges 
<token> = ARRAY_SIZE(slg51000_readable_ranges), <answer> .n_yes_ranges 
static const struct <token> slg51000_volatile_table = { <answer> regmap_access_table 
<token> = slg51000_volatile_ranges, <answer> .yes_ranges 
.n_yes_ranges <token> ARRAY_SIZE(slg51000_volatile_ranges), <answer> = 
<token> const struct regmap_config slg51000_regmap_config = { <answer> static 
.reg_bits <token> 16, <answer> = 
.val_bits <token> 8, <answer> = 
<token> = 0x8000, <answer> .max_register 
.wr_table <token> &slg51000_writeable_table, <answer> = 
<token> = &slg51000_readable_table, <answer> .rd_table 
.volatile_table <token> &slg51000_volatile_table, <answer> = 
static const struct <token> slg51000_regl_ops = { <answer> regulator_ops 
<token> = regulator_enable_regmap, <answer> .enable 
.disable = <token> <answer> regulator_disable_regmap, 
<token> = regulator_is_enabled_regmap, <answer> .is_enabled 
.list_voltage <token> regulator_list_voltage_linear, <answer> = 
.map_voltage = <token> <answer> regulator_map_voltage_linear, 
<token> = regulator_get_voltage_sel_regmap, <answer> .get_voltage_sel 
.set_voltage_sel = <token> <answer> regulator_set_voltage_sel_regmap, 
static const struct regulator_ops slg51000_switch_ops = <token> <answer> { 
.enable <token> regulator_enable_regmap, <answer> = 
<token> = regulator_disable_regmap, <answer> .disable 
.is_enabled = <token> <answer> regulator_is_enabled_regmap, 
static int slg51000_of_parse_cb(struct device_node <token> <answer> *np, 
<token> struct regulator_desc *desc, <answer> const 
struct regulator_config <token> <answer> *config) 
struct <token> *ena_gpiod; <answer> gpio_desc 
ena_gpiod = <token> "enable", 0, <answer> fwnode_gpiod_get_index(of_fwnode_handle(np), 
GPIOD_OUT_LOW <token> <answer> | 
<token> (!IS_ERR(ena_gpiod)) <answer> if 
config->ena_gpiod = <token> <answer> ena_gpiod; 
return <token> <answer> 0; 
#define SLG51000_REGL_DESC(_id, _name, <token> _min, _step) \ <answer> _s_name, 
[SLG51000_REGULATOR_##_id] = <token> \ <answer> { 
.name = <token> \ <answer> #_name, 
.supply_name = _s_name, <token> <answer> \ 
.id = SLG51000_REGULATOR_##_id, <token> <answer> \ 
.of_match = of_match_ptr(#_name), <token> <answer> \ 
.of_parse_cb = slg51000_of_parse_cb, <token> <answer> \ 
.ops = <token> \ <answer> &slg51000_regl_ops, 
.regulators_node = <token> \ <answer> of_match_ptr("regulators"), 
.n_voltages = 256, <token> <answer> \ 
.min_uV = <token> \ <answer> _min, 
.uV_step <token> _step, \ <answer> = 
<token> = 0, \ <answer> .linear_min_sel 
.vsel_mask <token> SLG51000_VSEL_MASK, \ <answer> = 
<token> = SLG51000_##_id##_VSEL, \ <answer> .vsel_reg 
<token> = SLG51000_SYSCTL_MATRIX_CONF_A, \ <answer> .enable_reg 
<token> = BIT(SLG51000_REGULATOR_##_id), \ <answer> .enable_mask 
.type = REGULATOR_VOLTAGE, <token> <answer> \ 
.owner <token> THIS_MODULE, \ <answer> = 
static <token> regulator_desc regls_desc[SLG51000_MAX_REGULATORS] = { <answer> struct 
SLG51000_REGL_DESC(LDO1, ldo1, <token> 2400000, 5000), <answer> NULL, 
SLG51000_REGL_DESC(LDO2, <token> NULL, 2400000, 5000), <answer> ldo2, 
SLG51000_REGL_DESC(LDO3, <token> "vin3", 1200000, 10000), <answer> ldo3, 
<token> ldo4, "vin4", 1200000, 10000), <answer> SLG51000_REGL_DESC(LDO4, 
SLG51000_REGL_DESC(LDO5, <token> "vin5", 400000, 5000), <answer> ldo5, 
<token> ldo6, "vin6", 400000, 5000), <answer> SLG51000_REGL_DESC(LDO6, 
SLG51000_REGL_DESC(LDO7, ldo7, "vin7", <token> 10000), <answer> 1200000, 
static int slg51000_regulator_init(struct <token> *chip) <answer> slg51000 
struct regulator_config config = <token> }; <answer> { 
struct <token> *rdesc; <answer> regulator_desc 
<token> int reg, val; <answer> unsigned 
u8 <token> <answer> vsel_range[2]; 
int id, ret = <token> <answer> 0; 
const unsigned <token> min_regs[SLG51000_MAX_REGULATORS] = { <answer> int 
<token> SLG51000_LDO2_MINV, SLG51000_LDO3_MINV, <answer> SLG51000_LDO1_MINV, 
SLG51000_LDO4_MINV, SLG51000_LDO5_MINV, <token> <answer> SLG51000_LDO6_MINV, 
for (id = 0; id <token> SLG51000_MAX_REGULATORS; id++) { <answer> < 
chip->rdesc[id] <token> &regls_desc[id]; <answer> = 
<token> = chip->rdesc[id]; <answer> rdesc 
config.regmap = <token> <answer> chip->regmap; 
<token> = chip->dev; <answer> config.dev 
<token> = chip; <answer> config.driver_data 
ret = <token> min_regs[id], <answer> regmap_bulk_read(chip->regmap, 
<token> 2); <answer> vsel_range, 
if (ret <token> 0) { <answer> < 
"Failed to read <token> MIN register\n"); <answer> the 
<token> ret; <answer> return 
switch <token> { <answer> (id) 
<token> SLG51000_REGULATOR_LDO1: <answer> case 
<token> SLG51000_REGULATOR_LDO2: <answer> case 
if (id == <token> <answer> SLG51000_REGULATOR_LDO1) 
reg = <token> <answer> SLG51000_LDO1_MISC1; 
reg <token> SLG51000_LDO2_MISC1; <answer> = 
ret <token> regmap_read(chip->regmap, reg, &val); <answer> = 
<token> (ret < 0) { <answer> if 
"Failed to <token> voltage range of ldo%d\n", <answer> read 
id + <token> <answer> 1); 
<token> ret; <answer> return 
rdesc->linear_min_sel = <token> <answer> vsel_range[0]; 
<token> = vsel_range[1] + 1; <answer> rdesc->n_voltages 
<token> (val & SLG51000_SEL_VRANGE_MASK) <answer> if 
rdesc->min_uV <token> SLG51000_LDOHP_HV_MIN <answer> = 
+ <token> <answer> (vsel_range[0] 
<token> rdesc->uV_step); <answer> * 
rdesc->min_uV <token> SLG51000_LDOHP_LV_MIN <answer> = 
+ <token> <answer> (vsel_range[0] 
<token> rdesc->uV_step); <answer> * 
<token> SLG51000_REGULATOR_LDO5: <answer> case 
<token> SLG51000_REGULATOR_LDO6: <answer> case 
if <token> == SLG51000_REGULATOR_LDO5) <answer> (id 
reg = <token> <answer> SLG51000_LDO5_TRIM2; 
<token> = SLG51000_LDO6_TRIM2; <answer> reg 
ret = regmap_read(chip->regmap, reg, <token> <answer> &val); 
if (ret < <token> { <answer> 0) 
"Failed to read LDO <token> register\n"); <answer> mode 
return <token> <answer> ret; 
if (val & SLG51000_SEL_BYP_MODE_MASK) <token> <answer> { 
rdesc->ops = <token> <answer> &slg51000_switch_ops; 
<token> = 0; <answer> rdesc->n_voltages 
rdesc->min_uV = <token> <answer> 0; 
<token> = 0; <answer> rdesc->uV_step 
<token> = 0; <answer> rdesc->linear_min_sel 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/types.h> 
<token> <linux/mm.h> <answer> #include 
#include <token> <answer> <linux/sched.h> 
#include <token> <answer> <linux/pci.h> 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/reboot.h> 
<token> <linux/memblock.h> <answer> #include 
#include <token> <answer> <linux/bitops.h> 
<token> <asm/ptrace.h> <answer> #include 
<token> <asm/dma.h> <answer> #include 
<token> <asm/irq.h> <answer> #include 
#include <token> <answer> <asm/mmu_context.h> 
<token> <asm/io.h> <answer> #include 
<token> <asm/core_irongate.h> <answer> #include 
#include <token> <answer> <asm/hwrpb.h> 
#include <token> <answer> <asm/tlbflush.h> 
<token> "proto.h" <answer> #include 
<token> "err_impl.h" <answer> #include 
#include <token> <answer> "irq_impl.h" 
<token> "pci_impl.h" <answer> #include 
<token> "machvec_impl.h" <answer> #include 
static <token> __init <answer> void 
<token> (alpha_using_srm) { <answer> if 
alpha_mv.device_interrupt = <token> <answer> srm_device_interrupt; 
<token> int <answer> static 
nautilus_map_irq(const <token> pci_dev *dev, u8 slot, u8 pin) <answer> struct 
if (slot == 1 && pin == <token> && <answer> 2 
dev->bus->self && <token> == 0x700f) <answer> dev->bus->self->device 
return <token> <answer> 5; 
pci_read_config_byte(dev, <token> &irq); <answer> PCI_INTERRUPT_LINE, 
return <token> <answer> irq; 
<token> mode) <answer> nautilus_kill_arch(int 
struct pci_bus *bus = <token> <answer> pci_isa_hose->bus; 
<token> pmuport; <answer> u32 
<token> off; <answer> int 
switch <token> { <answer> (mode) 
<token> LINUX_REBOOT_CMD_RESTART: <answer> case 
if <token> alpha_using_srm) { <answer> (! 
<token> t8; <answer> u8 
<token> 0x38, 0x43, &t8); <answer> pci_bus_read_config_byte(bus, 
<token> 0x38, 0x43, t8 | 0x80); <answer> pci_bus_write_config_byte(bus, 
<token> 0x92); <answer> outb(1, 
<token> 0x92); <answer> outb(0, 
nautilus_machine_check(unsigned long vector, unsigned long <token> <answer> la_ptr) 
<token> *mchk_class; <answer> char 
<token> (vector == SCB_Q_SYSMCHK <answer> if 
&& ((IRONGATE0->dramms & 0x300) == 0x300)) <token> <answer> { 
unsigned <token> nmi_ctl; <answer> long 
<token> &irongate_mem); <answer> pci_add_resource(&bridge->windows, 
pci_add_resource(&bridge->windows, <token> <answer> &busn_resource); 
bridge->dev.parent <token> NULL; <answer> = 
bridge->sysdata <token> hose; <answer> = 
bridge->busnr = <token> <answer> 0; 
<token> = alpha_mv.pci_ops; <answer> bridge->ops 
bridge->swizzle_irq = <token> <answer> alpha_mv.pci_swizzle; 
bridge->map_irq <token> alpha_mv.pci_map_irq; <answer> = 
bridge->size_windows <token> 1; <answer> = 
bus_align <token> irongate_mem.start; <answer> = 
<token> = irongate_mem.end + 1 - bus_align; <answer> bus_size 
<token> (bus_align < 0x1000000UL) <answer> if 
<token> = 0x1000000UL; <answer> bus_align 
pci_mem = (0x100000000UL - bus_size) & <token> <answer> -bus_align; 
irongate_mem.start <token> pci_mem; <answer> = 
irongate_mem.end = <token> <answer> 0xffffffffUL; 
<token> (request_resource(&iomem_resource, &irongate_mem) < 0) <answer> if 
printk(KERN_ERR <token> to request MEM on hose 0\n"); <answer> "Failed 
printk(KERN_INFO "Irongate pci_mem %pR\n", <token> <answer> &irongate_mem); 
if <token> < memtop) <answer> (pci_mem 
<token> = pci_mem; <answer> memtop 
if (memtop <token> alpha_mv.min_mem_address) { <answer> > 
<token> -1, NULL); <answer> __va(memtop), 
<token> "nautilus_init_pci: %ldk freed\n", <answer> printk(KERN_INFO 
(memtop - alpha_mv.min_mem_address) >> <token> <answer> 10); 
struct alpha_machine_vector nautilus_mv __initmv = <token> <answer> { 
.vector_name <token> "Nautilus", <answer> = 
<token> = nautilus_machine_check, <answer> .machine_check 
<token> = ALPHA_MAX_ISA_DMA_ADDRESS, <answer> .max_isa_dma_address 
.min_io_address <token> DEFAULT_IO_BASE, <answer> = 
<token> = IRONGATE_DEFAULT_MEM_BASE, <answer> .min_mem_address 
.nr_irqs = <token> <answer> 16, 
.device_interrupt = <token> <answer> isa_device_interrupt, 
.init_arch <token> irongate_init_arch, <answer> = 
.init_irq = <token> <answer> nautilus_init_irq, 
<token> = common_init_rtc, <answer> .init_rtc 
<token> = nautilus_init_pci, <answer> .init_pci 
.kill_arch = <token> <answer> nautilus_kill_arch, 
.pci_map_irq = <token> <answer> nautilus_map_irq, 
<token> = common_swizzle, <answer> .pci_swizzle 
#include <token> <answer> "i915_selftest.h" 
#include <token> <answer> "selftest_engine.h" 
int intel_engine_live_selftests(struct drm_i915_private <token> <answer> *i915) 
static int (* const tests[])(struct intel_gt *) <token> { <answer> = 
struct <token> *gt = to_gt(i915); <answer> intel_gt 
<token> *fn; <answer> typeof(*tests) 
for <token> = tests; *fn; fn++) { <answer> (fn 
<token> err; <answer> int 
err <token> (*fn)(gt); <answer> = 
if <token> <answer> (err) 
return <token> <answer> err; 
<token> 0; <answer> return 
<token> "xe_guc_debugfs.h" <answer> #include 
#include <token> <answer> <drm/drm_debugfs.h> 
<token> <drm/drm_managed.h> <answer> #include 
#include <token> <answer> "xe_device.h" 
#include <token> <answer> "xe_gt.h" 
<token> "xe_guc.h" <answer> #include 
<token> "xe_guc_ct.h" <answer> #include 
#include <token> <answer> "xe_guc_log.h" 
#include <token> <answer> "xe_macros.h" 
static struct xe_guc *node_to_guc(struct drm_info_node <token> <answer> *node) 
<token> node->info_ent->data; <answer> return 
<token> int guc_info(struct seq_file *m, void *data) <answer> static 
struct <token> *guc = node_to_guc(m->private); <answer> xe_guc 
struct xe_device <token> = guc_to_xe(guc); <answer> *xe 
<token> drm_printer p = drm_seq_file_printer(m); <answer> struct 
xe_guc_print_info(guc, <token> <answer> &p); 
<token> 0; <answer> return 
static int guc_log(struct seq_file *m, void <token> <answer> *data) 
struct xe_guc *guc <token> node_to_guc(m->private); <answer> = 
struct xe_device <token> = guc_to_xe(guc); <answer> *xe 
struct drm_printer <token> = drm_seq_file_printer(m); <answer> p 
xe_guc_log_print(&guc->log, <token> <answer> &p); 
return <token> <answer> 0; 
static const struct drm_info_list debugfs_list[] <token> { <answer> = 
{"guc_info", guc_info, <token> <answer> 0}, 
{"guc_log", <token> 0}, <answer> guc_log, 
void xe_guc_debugfs_register(struct <token> *guc, struct dentry *parent) <answer> xe_guc 
<token> drm_minor *minor = guc_to_xe(guc)->drm.primary; <answer> struct 
struct <token> *local; <answer> drm_info_list 
int <token> <answer> i; 
<token> DEBUGFS_SIZE (ARRAY_SIZE(debugfs_list) * sizeof(struct drm_info_list)) <answer> #define 
local = drmm_kmalloc(&guc_to_xe(guc)->drm, DEBUGFS_SIZE, <token> <answer> GFP_KERNEL); 
<token> (!local) <answer> if 
memcpy(local, debugfs_list, <token> <answer> DEBUGFS_SIZE); 
#undef <token> <answer> DEBUGFS_SIZE 
for (i <token> 0; i < ARRAY_SIZE(debugfs_list); ++i) <answer> = 
local[i].data = <token> <answer> guc; 
parent, <token> <answer> minor); 
<token> "i915_drv.h" <answer> #include 
#include <token> <answer> "i915_pvinfo.h" 
<token> "i915_vgpu.h" <answer> #include 
void intel_vgpu_detect(struct drm_i915_private <token> <answer> *dev_priv) 
struct pci_dev <token> = to_pci_dev(dev_priv->drm.dev); <answer> *pdev 
u64 <token> <answer> magic; 
<token> version_major; <answer> u16 
void __iomem <token> <answer> *shared_area; 
BUILD_BUG_ON(sizeof(struct vgt_if) <token> VGT_PVINFO_SIZE); <answer> != 
if <token> < 6) <answer> (GRAPHICS_VER(dev_priv) 
shared_area <token> pci_iomap_range(pdev, 0, VGT_PVINFO_PAGE, VGT_PVINFO_SIZE); <answer> = 
if <token> { <answer> (!shared_area) 
"failed to map MMIO bar <token> check for VGT\n"); <answer> to 
magic = readq(shared_area + <token> <answer> vgtif_offset(magic)); 
<token> (magic != VGT_MAGIC) <answer> if 
<token> out; <answer> goto 
version_major = readw(shared_area <token> vgtif_offset(version_major)); <answer> + 
if (version_major < VGT_VERSION_MAJOR) <token> <answer> { 
drm_info(&dev_priv->drm, "VGT interface version <token> <answer> mismatch!\n"); 
<token> out; <answer> goto 
dev_priv->vgpu.caps <token> readl(shared_area + vgtif_offset(vgt_caps)); <answer> = 
dev_priv->vgpu.active = <token> <answer> true; 
<token> "Virtual GPU for Intel GVT-g detected.\n"); <answer> drm_info(&dev_priv->drm, 
<token> shared_area); <answer> pci_iounmap(pdev, 
void intel_vgpu_register(struct drm_i915_private <token> <answer> *i915) 
if <token> <answer> (intel_vgpu_active(i915)) 
intel_uncore_write(&i915->uncore, <token> <answer> vgtif_reg(display_ready), 
<token> intel_vgpu_active(struct drm_i915_private *dev_priv) <answer> bool 
return <token> <answer> dev_priv->vgpu.active; 
<token> intel_vgpu_has_full_ppgtt(struct drm_i915_private *dev_priv) <answer> bool 
return dev_priv->vgpu.caps & <token> <answer> VGT_CAPS_FULL_PPGTT; 
<token> intel_vgpu_has_hwsp_emulation(struct drm_i915_private *dev_priv) <answer> bool 
return <token> & VGT_CAPS_HWSP_EMULATION; <answer> dev_priv->vgpu.caps 
<token> intel_vgpu_has_huge_gtt(struct drm_i915_private *dev_priv) <answer> bool 
return dev_priv->vgpu.caps & <token> <answer> VGT_CAPS_HUGE_GTT; 
struct _balloon_info_ <token> <answer> { 
struct drm_mm_node <token> <answer> space[4]; 
static struct <token> bl_info; <answer> _balloon_info_ 
static void vgt_deballoon_space(struct <token> *ggtt, <answer> i915_ggtt 
struct <token> *node) <answer> drm_mm_node 
struct drm_i915_private *dev_priv = <token> <answer> ggtt->vm.i915; 
<token> (!drm_mm_node_allocated(node)) <answer> if 
"deballoon space: range <token> - 0x%llx] %llu KiB.\n", <answer> [0x%llx 
node->start <token> node->size, <answer> + 
node->size / <token> <answer> 1024); 
<token> -= node->size; <answer> ggtt->vm.reserved 
void intel_vgt_deballoon(struct i915_ggtt <token> <answer> *ggtt) 
<token> drm_i915_private *dev_priv = ggtt->vm.i915; <answer> struct 
<token> i; <answer> int 
<token> (!intel_vgpu_active(ggtt->vm.i915)) <answer> if 
drm_dbg(&dev_priv->drm, <token> deballoon.\n"); <answer> "VGT 
for (i = 0; i < 4; <token> <answer> i++) 
vgt_deballoon_space(ggtt, <token> <answer> &bl_info.space[i]); 
<token> int vgt_balloon_space(struct i915_ggtt *ggtt, <answer> static 
struct <token> *node, <answer> drm_mm_node 
unsigned long start, unsigned long <token> <answer> end) 
<token> drm_i915_private *dev_priv = ggtt->vm.i915; <answer> struct 
unsigned long size = end <token> start; <answer> - 
<token> ret; <answer> int 
if (start >= <token> <answer> end) 
return <token> <answer> -EINVAL; 
"balloon space: range [ 0x%lx - 0x%lx <token> %lu KiB.\n", <answer> ] 
start, <token> size / 1024); <answer> end, 
ret = i915_gem_gtt_reserve(&ggtt->vm, <token> node, <answer> NULL, 
<token> start, I915_COLOR_UNEVICTABLE, <answer> size, 
<token> (!ret) <answer> if 
ggtt->vm.reserved <token> size; <answer> += 
return <token> <answer> ret; 
int intel_vgt_balloon(struct i915_ggtt <token> <answer> *ggtt) 
struct <token> *dev_priv = ggtt->vm.i915; <answer> drm_i915_private 
struct intel_uncore *uncore = <token> <answer> &dev_priv->uncore; 
unsigned <token> ggtt_end = ggtt->vm.total; <answer> long 
unsigned long mappable_base, mappable_size, <token> <answer> mappable_end; 
unsigned long <token> unmappable_size, unmappable_end; <answer> unmappable_base, 
int <token> <answer> ret; 
if <token> <answer> (!intel_vgpu_active(ggtt->vm.i915)) 
<token> 0; <answer> return 
<token> = <answer> mappable_base 
<token> vgtif_reg(avail_rs.mappable_gmadr.base)); <answer> intel_uncore_read(uncore, 
<token> = <answer> mappable_size 
intel_uncore_read(uncore, <token> <answer> vgtif_reg(avail_rs.mappable_gmadr.size)); 
unmappable_base <token> <answer> = 
intel_uncore_read(uncore, <token> <answer> vgtif_reg(avail_rs.nonmappable_gmadr.base)); 
<token> = <answer> unmappable_size 
<token> vgtif_reg(avail_rs.nonmappable_gmadr.size)); <answer> intel_uncore_read(uncore, 
mappable_end = mappable_base <token> mappable_size; <answer> + 
unmappable_end <token> unmappable_base + unmappable_size; <answer> = 
<token> "VGT ballooning configuration:\n"); <answer> drm_info(&dev_priv->drm, 
<token> graphic memory: base 0x%lx size %ldKiB\n", <answer> "Mappable 
mappable_base, mappable_size / <token> <answer> 1024); 
<token> graphic memory: base 0x%lx size %ldKiB\n", <answer> "Unmappable 
unmappable_base, unmappable_size / <token> <answer> 1024); 
if (mappable_end > <token> || <answer> ggtt->mappable_end 
unmappable_base <token> ggtt->mappable_end || <answer> < 
<token> > ggtt_end) { <answer> unmappable_end 
<token> "Invalid ballooning configuration!\n"); <answer> drm_err(&dev_priv->drm, 
<token> -EINVAL; <answer> return 
#include <token> <answer> <linux/bitfield.h> 
<token> <linux/export.h> <answer> #include 
#include <token> <answer> <linux/pci-ats.h> 
<token> <linux/pci.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> "pci.h" <answer> #include 
void pci_ats_init(struct pci_dev <token> <answer> *dev) 
<token> pos; <answer> int 
<token> (pci_ats_disabled()) <answer> if 
pos = pci_find_ext_capability(dev, <token> <answer> PCI_EXT_CAP_ID_ATS); 
if <token> <answer> (!pos) 
dev->ats_cap = <token> <answer> pos; 
bool pci_ats_supported(struct <token> *dev) <answer> pci_dev 
if <token> <answer> (!dev->ats_cap) 
<token> false; <answer> return 
return <token> == 0); <answer> (dev->untrusted 
<token> pci_enable_ats(struct pci_dev *dev, int ps) <answer> int 
<token> ctrl; <answer> u16 
struct pci_dev <token> <answer> *pdev; 
<token> (!pci_ats_supported(dev)) <answer> if 
<token> -EINVAL; <answer> return 
if <token> <answer> (WARN_ON(dev->ats_enabled)) 
<token> -EBUSY; <answer> return 
if (ps < <token> <answer> PCI_ATS_MIN_STU) 
return <token> <answer> -EINVAL; 
<token> = PCI_ATS_CTRL_ENABLE; <answer> ctrl 
if (dev->is_virtfn) <token> <answer> { 
pdev <token> pci_physfn(dev); <answer> = 
if (pdev->ats_stu <token> ps) <answer> != 
return <token> <answer> -EINVAL; 
<token> else { <answer> } 
<token> = ps; <answer> dev->ats_stu 
<token> |= PCI_ATS_CTRL_STU(dev->ats_stu - PCI_ATS_MIN_STU); <answer> ctrl 
<token> dev->ats_cap + PCI_ATS_CTRL, ctrl); <answer> pci_write_config_word(dev, 
<token> = 1; <answer> dev->ats_enabled 
<token> 0; <answer> return 
void <token> pci_dev *dev) <answer> pci_disable_ats(struct 
u16 <token> <answer> ctrl; 
<token> (WARN_ON(!dev->ats_enabled)) <answer> if 
pci_read_config_word(dev, dev->ats_cap + <token> &ctrl); <answer> PCI_ATS_CTRL, 
ctrl <token> ~PCI_ATS_CTRL_ENABLE; <answer> &= 
pci_write_config_word(dev, dev->ats_cap <token> PCI_ATS_CTRL, ctrl); <answer> + 
<token> = 0; <answer> dev->ats_enabled 
void <token> pci_dev *dev) <answer> pci_restore_ats_state(struct 
u16 <token> <answer> ctrl; 
if <token> <answer> (!dev->ats_enabled) 
ctrl = <token> <answer> PCI_ATS_CTRL_ENABLE; 
<token> (!dev->is_virtfn) <answer> if 
ctrl <token> PCI_ATS_CTRL_STU(dev->ats_stu - PCI_ATS_MIN_STU); <answer> |= 
pci_write_config_word(dev, <token> + PCI_ATS_CTRL, ctrl); <answer> dev->ats_cap 
<token> pci_ats_queue_depth(struct pci_dev *dev) <answer> int 
u16 <token> <answer> cap; 
if <token> <answer> (!dev->ats_cap) 
<token> -EINVAL; <answer> return 
<token> (dev->is_virtfn) <answer> if 
return <token> <answer> 0; 
pci_read_config_word(dev, dev->ats_cap + <token> &cap); <answer> PCI_ATS_CAP, 
return PCI_ATS_CAP_QDEP(cap) ? <token> : PCI_ATS_MAX_QDEP; <answer> PCI_ATS_CAP_QDEP(cap) 
int pci_ats_page_aligned(struct pci_dev <token> <answer> *pdev) 
<token> cap; <answer> u16 
if <token> <answer> (!pdev->ats_cap) 
<token> 0; <answer> return 
pci_read_config_word(pdev, <token> + PCI_ATS_CAP, &cap); <answer> pdev->ats_cap 
if <token> & PCI_ATS_CAP_PAGE_ALIGNED) <answer> (cap 
<token> 1; <answer> return 
<token> 0; <answer> return 
<token> CONFIG_PCI_PRI <answer> #ifdef 
<token> pci_pri_init(struct pci_dev *pdev) <answer> void 
u16 <token> <answer> status; 
pdev->pri_cap <token> pci_find_ext_capability(pdev, PCI_EXT_CAP_ID_PRI); <answer> = 
<token> (!pdev->pri_cap) <answer> if 
<token> pdev->pri_cap + PCI_PRI_STATUS, &status); <answer> pci_read_config_word(pdev, 
if (status & <token> <answer> PCI_PRI_STATUS_PASID) 
pdev->pasid_required = <token> <answer> 1; 
int pci_enable_pri(struct pci_dev *pdev, <token> reqs) <answer> u32 
u16 <token> status; <answer> control, 
<token> max_requests; <answer> u32 
int pri = <token> <answer> pdev->pri_cap; 
if (pdev->is_virtfn) <token> <answer> { 
<token> (pci_physfn(pdev)->pri_enabled) <answer> if 
<token> 0; <answer> return 
return <token> <answer> -EINVAL; 
if <token> <answer> (WARN_ON(pdev->pri_enabled)) 
return <token> <answer> -EBUSY; 
<token> (!pri) <answer> if 
<token> -EINVAL; <answer> return 
pci_read_config_word(pdev, <token> + PCI_PRI_STATUS, &status); <answer> pri 
if (!(status <token> PCI_PRI_STATUS_STOPPED)) <answer> & 
<token> -EBUSY; <answer> return 
pci_read_config_dword(pdev, pri + <token> &max_requests); <answer> PCI_PRI_MAX_REQ, 
reqs = min(max_requests, <token> <answer> reqs); 
<token> = reqs; <answer> pdev->pri_reqs_alloc 
pci_write_config_dword(pdev, <token> + PCI_PRI_ALLOC_REQ, reqs); <answer> pri 
control <token> PCI_PRI_CTRL_ENABLE; <answer> = 
pci_write_config_word(pdev, pri <token> PCI_PRI_CTRL, control); <answer> + 
pdev->pri_enabled <token> 1; <answer> = 
<token> 0; <answer> return 
void pci_disable_pri(struct <token> *pdev) <answer> pci_dev 
u16 <token> <answer> control; 
int <token> = pdev->pri_cap; <answer> pri 
<token> pci_restore_pri_state(struct pci_dev *pdev) <answer> void 
u16 control <token> PCI_PRI_CTRL_ENABLE; <answer> = 
u32 reqs <token> pdev->pri_reqs_alloc; <answer> = 
int <token> = pdev->pri_cap; <answer> pri 
<token> (pdev->is_virtfn) <answer> if 
if <token> <answer> (!pdev->pri_enabled) 
<token> (!pri) <answer> if 
pci_write_config_dword(pdev, <token> + PCI_PRI_ALLOC_REQ, reqs); <answer> pri 
pci_write_config_word(pdev, pri + PCI_PRI_CTRL, <token> <answer> control); 
int pci_reset_pri(struct <token> *pdev) <answer> pci_dev 
u16 <token> <answer> control; 
<token> pri = pdev->pri_cap; <answer> int 
<token> (pdev->is_virtfn) <answer> if 
return <token> <answer> 0; 
<token> (WARN_ON(pdev->pri_enabled)) <answer> if 
return <token> <answer> -EBUSY; 
if <token> <answer> (!pri) 
<token> -EINVAL; <answer> return 
control = <token> <answer> PCI_PRI_CTRL_RESET; 
pci_write_config_word(pdev, pri <token> PCI_PRI_CTRL, control); <answer> + 
<token> 0; <answer> return 
int <token> pci_dev *pdev) <answer> pci_prg_resp_pasid_required(struct 
<token> (pdev->is_virtfn) <answer> if 
pdev = <token> <answer> pci_physfn(pdev); 
<token> pdev->pasid_required; <answer> return 
bool pci_pri_supported(struct <token> *pdev) <answer> pci_dev 
int pci_enable_pasid(struct pci_dev *pdev, int <token> <answer> features) 
<token> control, supported; <answer> u16 
int pasid <token> pdev->pasid_cap; <answer> = 
<token> (pdev->is_virtfn) { <answer> if 
<token> (pci_physfn(pdev)->pasid_enabled) <answer> if 
<token> 0; <answer> return 
<token> -EINVAL; <answer> return 
if <token> <answer> (WARN_ON(pdev->pasid_enabled)) 
<token> -EBUSY; <answer> return 
if <token> && !pdev->pasid_no_tlp) <answer> (!pdev->eetlp_prefix_path 
return <token> <answer> -EINVAL; 
<token> (!pasid) <answer> if 
return <token> <answer> -EINVAL; 
if <token> NULL, PCI_ACS_RR | PCI_ACS_UF)) <answer> (!pci_acs_path_enabled(pdev, 
<token> -EINVAL; <answer> return 
pci_read_config_word(pdev, pasid + PCI_PASID_CAP, <token> <answer> &supported); 
supported &= <token> | PCI_PASID_CAP_PRIV; <answer> PCI_PASID_CAP_EXEC 
void pci_disable_pasid(struct <token> *pdev) <answer> pci_dev 
u16 <token> = 0; <answer> control 
int pasid = <token> <answer> pdev->pasid_cap; 
<token> pci_restore_pasid_state(struct pci_dev *pdev) <answer> void 
u16 <token> <answer> control; 
int <token> = pdev->pasid_cap; <answer> pasid 
if <token> <answer> (pdev->is_virtfn) 
if <token> <answer> (!pdev->pasid_enabled) 
if <token> <answer> (!pasid) 
control = PCI_PASID_CTRL_ENABLE <token> pdev->pasid_features; <answer> | 
pci_write_config_word(pdev, pasid + <token> control); <answer> PCI_PASID_CTRL, 
<token> pci_pasid_features(struct pci_dev *pdev) <answer> int 
u16 <token> <answer> supported; 
<token> pasid; <answer> int 
if <token> <answer> (pdev->is_virtfn) 
pdev = <token> <answer> pci_physfn(pdev); 
pasid <token> pdev->pasid_cap; <answer> = 
if <token> <answer> (!pasid) 
return <token> <answer> -EINVAL; 
pci_read_config_word(pdev, pasid + PCI_PASID_CAP, <token> <answer> &supported); 
supported &= PCI_PASID_CAP_EXEC <token> PCI_PASID_CAP_PRIV; <answer> | 
<token> supported; <answer> return 
int pci_max_pasids(struct pci_dev <token> <answer> *pdev) 
<token> supported; <answer> u16 
int <token> <answer> pasid; 
if <token> <answer> (pdev->is_virtfn) 
pdev = <token> <answer> pci_physfn(pdev); 
pasid = <token> <answer> pdev->pasid_cap; 
<token> (!pasid) <answer> if 
return <token> <answer> -EINVAL; 
pci_read_config_word(pdev, pasid + <token> &supported); <answer> PCI_PASID_CAP, 
return (1 <token> FIELD_GET(PCI_PASID_CAP_WIDTH, supported)); <answer> << 
#define pr_fmt(fmt) "arcnet:" KBUILD_MODNAME ": <token> fmt <answer> " 
<token> <linux/module.h> <answer> #include 
<token> <linux/gfp.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
<token> <linux/if_arp.h> <answer> #include 
<token> <net/arp.h> <answer> #include 
#include <token> <answer> <linux/netdevice.h> 
<token> <linux/skbuff.h> <answer> #include 
<token> "arcdevice.h" <answer> #include 
static <token> build_header(struct sk_buff *skb, struct net_device *dev, <answer> int 
unsigned <token> type, uint8_t daddr) <answer> short 
int hdr_size = <token> <answer> ARC_HDR_SIZE; 
struct <token> *pkt = skb_push(skb, hdr_size); <answer> archdr 
pkt->hard.source = <token> <answer> *dev->dev_addr; 
pkt->hard.dest <token> 0; <answer> = 
<token> hdr_size; <answer> return 
<token> <linux/export.h> <answer> #include 
<token> <linux/mm.h> <answer> #include 
#include <token> <answer> <linux/string.h> 
<token> <asm/pgalloc.h> <answer> #include 
<token> *pgd_alloc(struct mm_struct *mm) <answer> pgd_t 
<token> *init, *ret = NULL; <answer> pgd_t 
struct ptdesc *ptdesc <token> pagetable_alloc(GFP_KERNEL & ~__GFP_HIGHMEM, <answer> = 
if (ptdesc) <token> <answer> { 
ret = <token> <answer> ptdesc_address(ptdesc); 
init <token> pgd_offset(&init_mm, 0UL); <answer> = 
<token> + USER_PTRS_PER_PGD, init + USER_PTRS_PER_PGD, <answer> memcpy(ret 
(PTRS_PER_PGD <token> USER_PTRS_PER_PGD) * sizeof(pgd_t)); <answer> - 
return <token> <answer> ret; 
<token> "kfd_priv.h" <answer> #include 
#include <token> <answer> "kfd_events.h" 
<token> "soc15_int.h" <answer> #include 
#include <token> <answer> "kfd_device_queue_manager.h" 
#include <token> <answer> "ivsrcid/vmc/irqsrcs_vmc_1_0.h" 
<token> "kfd_smi_events.h" <answer> #include 
#include <token> <answer> "kfd_debug.h" 
<token> SQ_INTERRUPT_WORD_ENCODING { <answer> enum 
SQ_INTERRUPT_WORD_ENCODING_AUTO <token> 0x0, <answer> = 
enum SQ_INTERRUPT_ERROR_TYPE <token> <answer> { 
SQ_INTERRUPT_ERROR_TYPE_EDC_FUE = <token> <answer> 0x0, 
#define KFD_CTXID0_TRAP_CODE_SHIFT <token> <answer> 10 
<token> KFD_CTXID0_TRAP_CODE_MASK 0xfffc00 <answer> #define 
#define <token> 0x3ffffff <answer> KFD_CTXID0_CP_BAD_OP_ECODE_MASK 
<token> KFD_CTXID0_DOORBELL_ID_MASK 0x0003ff <answer> #define 
#define KFD_CTXID0_TRAP_CODE(ctxid0) (((ctxid0) <token> \ <answer> & 
KFD_CTXID0_TRAP_CODE_MASK) <token> \ <answer> >> 
#define <token> (((ctxid0) & \ <answer> KFD_CTXID0_CP_BAD_OP_ECODE(ctxid0) 
KFD_CTXID0_CP_BAD_OP_ECODE_MASK) <token> \ <answer> >> 
#define KFD_CTXID0_DOORBELL_ID(ctxid0) ((ctxid0) <token> \ <answer> & 
static void <token> context_id0, uint32_t context_id1) <answer> print_sq_intr_info_auto(uint32_t 
"sq_intr: auto, ttrace %d, wlt %d, ttrace_buf_full %d, reg_tms %d, cmd_tms %d, host_cmd_ovf %d, host_reg_ovf <token> immed_ovf %d, ttrace_utc_err %d\n", <answer> %d, 
REG_GET_FIELD(context_id0, <token> THREAD_TRACE), <answer> SQ_INTERRUPT_WORD_AUTO_CTXID0, 
REG_GET_FIELD(context_id0, SQ_INTERRUPT_WORD_AUTO_CTXID0, <token> <answer> WLT), 
REG_GET_FIELD(context_id0, <token> THREAD_TRACE_BUF_FULL), <answer> SQ_INTERRUPT_WORD_AUTO_CTXID0, 
REG_GET_FIELD(context_id0, <token> REG_TIMESTAMP), <answer> SQ_INTERRUPT_WORD_AUTO_CTXID0, 
REG_GET_FIELD(context_id0, <token> CMD_TIMESTAMP), <answer> SQ_INTERRUPT_WORD_AUTO_CTXID0, 
REG_GET_FIELD(context_id0, SQ_INTERRUPT_WORD_AUTO_CTXID0, <token> <answer> HOST_CMD_OVERFLOW), 
<token> SQ_INTERRUPT_WORD_AUTO_CTXID0, HOST_REG_OVERFLOW), <answer> REG_GET_FIELD(context_id0, 
REG_GET_FIELD(context_id0, <token> IMMED_OVERFLOW), <answer> SQ_INTERRUPT_WORD_AUTO_CTXID0, 
<token> SQ_INTERRUPT_WORD_AUTO_CTXID0, THREAD_TRACE_UTC_ERROR)); <answer> REG_GET_FIELD(context_id0, 
<token> void print_sq_intr_info_inst(uint32_t context_id0, uint32_t context_id1) <answer> static 
"sq_intr: inst, data 0x%08x, sh %d, priv %d, wave_id %d, <token> %d, wgp_id %d\n", <answer> simd_id 
REG_GET_FIELD(context_id0, SQ_INTERRUPT_WORD_WAVE_CTXID0, <token> <answer> DATA), 
<token> SQ_INTERRUPT_WORD_WAVE_CTXID0, SH_ID), <answer> REG_GET_FIELD(context_id0, 
<token> SQ_INTERRUPT_WORD_WAVE_CTXID0, PRIV), <answer> REG_GET_FIELD(context_id0, 
REG_GET_FIELD(context_id0, SQ_INTERRUPT_WORD_WAVE_CTXID0, <token> <answer> WAVE_ID), 
REG_GET_FIELD(context_id1, SQ_INTERRUPT_WORD_WAVE_CTXID1, <token> <answer> SIMD_ID), 
REG_GET_FIELD(context_id1, SQ_INTERRUPT_WORD_WAVE_CTXID1, <token> <answer> WGP_ID)); 
static <token> print_sq_intr_info_error(uint32_t context_id0, uint32_t context_id1) <answer> void 
"sq_intr: error, detail 0x%08x, type %d, sh <token> priv %d, wave_id %d, simd_id %d, wgp_id %d\n", <answer> %d, 
<token> SQ_INTERRUPT_WORD_ERROR_CTXID0, DETAIL), <answer> REG_GET_FIELD(context_id0, 
REG_GET_FIELD(context_id0, <token> TYPE), <answer> SQ_INTERRUPT_WORD_ERROR_CTXID0, 
REG_GET_FIELD(context_id0, <token> SH_ID), <answer> SQ_INTERRUPT_WORD_ERROR_CTXID0, 
<token> SQ_INTERRUPT_WORD_ERROR_CTXID0, PRIV), <answer> REG_GET_FIELD(context_id0, 
<token> SQ_INTERRUPT_WORD_ERROR_CTXID0, WAVE_ID), <answer> REG_GET_FIELD(context_id0, 
REG_GET_FIELD(context_id0, SQ_INTERRUPT_WORD_ERROR_CTXID1, <token> <answer> SIMD_ID), 
<token> SQ_INTERRUPT_WORD_ERROR_CTXID1, WGP_ID)); <answer> REG_GET_FIELD(context_id0, 
static void <token> kfd_node *dev, <answer> event_interrupt_poison_consumption_v11(struct 
<token> pasid, uint16_t source_id) <answer> uint16_t 
enum <token> block = 0; <answer> amdgpu_ras_block 
int <token> = -EINVAL; <answer> ret 
<token> kfd_process *p = kfd_lookup_process_by_pasid(pasid); <answer> struct 
if <token> <answer> (!p) 
<token> (!ret) <answer> if 
amdgpu_amdkfd_ras_poison_consumption_handler(dev->adev, block, <token> <answer> false); 
amdgpu_amdkfd_ras_poison_consumption_handler(dev->adev, block, <token> <answer> true); 
static bool <token> kfd_node *dev, <answer> event_interrupt_isr_v11(struct 
const uint32_t <token> <answer> *ih_ring_entry, 
<token> *patched_ihre, <answer> uint32_t 
<token> *patched_flag) <answer> bool 
uint16_t source_id, client_id, pasid, <token> <answer> vmid; 
const uint32_t *data <token> ih_ring_entry; <answer> = 
<token> context_id0; <answer> uint32_t 
source_id <token> SOC15_SOURCE_ID_FROM_IH_ENTRY(ih_ring_entry); <answer> = 
<token> = SOC15_CLIENT_ID_FROM_IH_ENTRY(ih_ring_entry); <answer> client_id 
return source_id == <token> || <answer> SOC15_INTSRC_CP_END_OF_PIPE 
source_id == SOC15_INTSRC_SQ_INTERRUPT_MSG <token> <answer> || 
source_id <token> SOC15_INTSRC_CP_BAD_OPCODE || <answer> == 
source_id <token> SOC21_INTSRC_SDMA_TRAP || <answer> == 
KFD_IRQ_IS_FENCE(client_id, <token> || <answer> source_id) 
(((client_id == SOC21_IH_CLIENTID_VMC) <token> <answer> || 
<token> == SOC21_IH_CLIENTID_GFX) && <answer> ((client_id 
(source_id <token> UTCL2_1_0__SRCID__FAULT))) && <answer> == 
static void event_interrupt_wq_v11(struct <token> *dev, <answer> kfd_node 
<token> uint32_t *ih_ring_entry) <answer> const 
uint16_t <token> client_id, ring_id, pasid, vmid; <answer> source_id, 
<token> context_id0, context_id1; <answer> uint32_t 
uint8_t <token> sq_int_priv, sq_int_errtype; <answer> sq_int_enc, 
struct <token> info = {0}; <answer> kfd_vm_fault_info 
struct <token> exception_data; <answer> kfd_hsa_memory_exception_data 
source_id <token> SOC15_SOURCE_ID_FROM_IH_ENTRY(ih_ring_entry); <answer> = 
client_id <token> SOC15_CLIENT_ID_FROM_IH_ENTRY(ih_ring_entry); <answer> = 
<token> = SOC15_RING_ID_FROM_IH_ENTRY(ih_ring_entry); <answer> ring_id 
<token> = SOC15_PASID_FROM_IH_ENTRY(ih_ring_entry); <answer> pasid 
vmid <token> SOC15_VMID_FROM_IH_ENTRY(ih_ring_entry); <answer> = 
context_id0 <token> SOC15_CONTEXT_ID0_FROM_IH_ENTRY(ih_ring_entry); <answer> = 
context_id1 = <token> <answer> SOC15_CONTEXT_ID1_FROM_IH_ENTRY(ih_ring_entry); 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/ptrace.h> 
<token> <linux/seq_file.h> <answer> #include 
<token> <linux/string.h> <answer> #include 
<token> <linux/timer.h> <answer> #include 
<token> <linux/major.h> <answer> #include 
#include <token> <answer> <linux/fs.h> 
#include <token> <answer> <linux/err.h> 
<token> <linux/ioctl.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/proc_fs.h> 
#include <token> <answer> <linux/idr.h> 
#include <token> <answer> <linux/backing-dev.h> 
#include <token> <answer> <linux/gfp.h> 
<token> <linux/random.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/reboot.h> 
<token> <linux/leds.h> <answer> #include 
#include <token> <answer> <linux/debugfs.h> 
<token> <linux/nvmem-provider.h> <answer> #include 
#include <token> <answer> <linux/root_dev.h> 
#include <token> <answer> <linux/error-injection.h> 
<token> <linux/mtd/mtd.h> <answer> #include 
<token> <linux/mtd/partitions.h> <answer> #include 
#include <token> <answer> "mtdcore.h" 
struct backing_dev_info <token> <answer> *mtd_bdi; 
#ifdef <token> <answer> CONFIG_PM_SLEEP 
static <token> mtd_cls_suspend(struct device *dev) <answer> int 
struct mtd_info *mtd <token> dev_get_drvdata(dev); <answer> = 
return <token> ? mtd_suspend(mtd) : 0; <answer> mtd 
static <token> mtd_cls_resume(struct device *dev) <answer> int 
struct mtd_info *mtd <token> dev_get_drvdata(dev); <answer> = 
if <token> <answer> (mtd) 
<token> 0; <answer> return 
static SIMPLE_DEV_PM_OPS(mtd_cls_pm_ops, mtd_cls_suspend, <token> <answer> mtd_cls_resume); 
<token> MTD_CLS_PM_OPS (&mtd_cls_pm_ops) <answer> #define 
#define MTD_CLS_PM_OPS <token> <answer> NULL 
<token> struct class mtd_class = { <answer> static 
.name <token> "mtd", <answer> = 
.pm <token> MTD_CLS_PM_OPS, <answer> = 
static <token> <answer> DEFINE_IDR(mtd_idr); 
struct mtd_info <token> i) <answer> *__mtd_next_device(int 
return <token> &i); <answer> idr_get_next(&mtd_idr, 
static <token> <answer> LIST_HEAD(mtd_notifiers); 
#define <token> MKDEV(MTD_CHAR_MAJOR, (index)*2) <answer> MTD_DEVT(index) 
static void mtd_release(struct device <token> <answer> *dev) 
<token> mtd_info *mtd = dev_get_drvdata(dev); <answer> struct 
<token> index = MTD_DEVT(mtd->index); <answer> dev_t 
<token> mtd->index); <answer> idr_remove(&mtd_idr, 
if <token> <answer> (mtd_is_partition(mtd)) 
<token> (!is_partition) <answer> if 
<token> 0, sizeof(mtd->dev)); <answer> memset(&mtd->dev, 
#define MTD_DEVICE_ATTR_RO(name) <token> <answer> \ 
static DEVICE_ATTR(name, 0444, mtd_##name##_show, <token> <answer> NULL) 
#define <token> \ <answer> MTD_DEVICE_ATTR_RW(name) 
static DEVICE_ATTR(name, 0644, <token> mtd_##name##_store) <answer> mtd_##name##_show, 
static ssize_t mtd_type_show(struct <token> *dev, <answer> device 
struct device_attribute *attr, <token> *buf) <answer> char 
struct <token> *mtd = dev_get_drvdata(dev); <answer> mtd_info 
char <token> <answer> *type; 
<token> (mtd->type) { <answer> switch 
case <token> <answer> MTD_ABSENT: 
type = <token> <answer> "absent"; 
case <token> <answer> MTD_RAM: 
type <token> "ram"; <answer> = 
<token> MTD_ROM: <answer> case 
type <token> "rom"; <answer> = 
case <token> <answer> MTD_NORFLASH: 
type <token> "nor"; <answer> = 
<token> MTD_NANDFLASH: <answer> case 
type = <token> <answer> "nand"; 
case <token> <answer> MTD_DATAFLASH: 
type <token> "dataflash"; <answer> = 
<token> MTD_UBIVOLUME: <answer> case 
type <token> "ubi"; <answer> = 
case <token> <answer> MTD_MLCNANDFLASH: 
type = <token> <answer> "mlc-nand"; 
type <token> "unknown"; <answer> = 
return sysfs_emit(buf, <token> type); <answer> "%s\n", 
static ssize_t <token> device *dev, <answer> mtd_flags_show(struct 
struct <token> *attr, char *buf) <answer> device_attribute 
struct mtd_info <token> = dev_get_drvdata(dev); <answer> *mtd 
return <token> "0x%lx\n", (unsigned long)mtd->flags); <answer> sysfs_emit(buf, 
static ssize_t mtd_size_show(struct device <token> <answer> *dev, 
struct device_attribute *attr, char <token> <answer> *buf) 
struct <token> *mtd = dev_get_drvdata(dev); <answer> mtd_info 
return sysfs_emit(buf, "%llu\n", (unsigned <token> long)mtd->size); <answer> long 
static ssize_t <token> device *dev, <answer> mtd_erasesize_show(struct 
struct device_attribute *attr, <token> *buf) <answer> char 
<token> mtd_info *mtd = dev_get_drvdata(dev); <answer> struct 
return sysfs_emit(buf, "%lu\n", <token> long)mtd->erasesize); <answer> (unsigned 
static ssize_t mtd_writesize_show(struct device <token> <answer> *dev, 
struct <token> *attr, char *buf) <answer> device_attribute 
<token> mtd_info *mtd = dev_get_drvdata(dev); <answer> struct 
<token> sysfs_emit(buf, "%lu\n", (unsigned long)mtd->writesize); <answer> return 
static ssize_t mtd_subpagesize_show(struct device <token> <answer> *dev, 
<token> device_attribute *attr, char *buf) <answer> struct 
struct mtd_info *mtd = <token> <answer> dev_get_drvdata(dev); 
unsigned int subpagesize <token> mtd->writesize >> mtd->subpage_sft; <answer> = 
return sysfs_emit(buf, <token> subpagesize); <answer> "%u\n", 
static ssize_t <token> device *dev, <answer> mtd_oobsize_show(struct 
<token> device_attribute *attr, char *buf) <answer> struct 
struct mtd_info <token> = dev_get_drvdata(dev); <answer> *mtd 
return <token> "%lu\n", (unsigned long)mtd->oobsize); <answer> sysfs_emit(buf, 
static <token> mtd_oobavail_show(struct device *dev, <answer> ssize_t 
struct device_attribute *attr, char <token> <answer> *buf) 
struct <token> *mtd = dev_get_drvdata(dev); <answer> mtd_info 
<token> sysfs_emit(buf, "%u\n", mtd->oobavail); <answer> return 
static ssize_t mtd_numeraseregions_show(struct <token> *dev, <answer> device 
struct device_attribute *attr, <token> *buf) <answer> char 
struct mtd_info *mtd <token> dev_get_drvdata(dev); <answer> = 
return sysfs_emit(buf, "%u\n", <token> <answer> mtd->numeraseregions); 
<token> ssize_t mtd_name_show(struct device *dev, <answer> static 
struct device_attribute *attr, char <token> <answer> *buf) 
struct mtd_info *mtd <token> dev_get_drvdata(dev); <answer> = 
return sysfs_emit(buf, <token> mtd->name); <answer> "%s\n", 
static <token> mtd_ecc_strength_show(struct device *dev, <answer> ssize_t 
struct <token> *attr, char *buf) <answer> device_attribute 
struct <token> *mtd = dev_get_drvdata(dev); <answer> mtd_info 
return sysfs_emit(buf, "%u\n", <token> <answer> mtd->ecc_strength); 
<token> ssize_t mtd_bitflip_threshold_show(struct device *dev, <answer> static 
struct device_attribute <token> <answer> *attr, 
char <token> <answer> *buf) 
struct mtd_info *mtd <token> dev_get_drvdata(dev); <answer> = 
return <token> "%u\n", mtd->bitflip_threshold); <answer> sysfs_emit(buf, 
<token> ssize_t mtd_bitflip_threshold_store(struct device *dev, <answer> static 
struct <token> *attr, <answer> device_attribute 
const <token> *buf, size_t count) <answer> char 
struct mtd_info <token> = dev_get_drvdata(dev); <answer> *mtd 
unsigned <token> bitflip_threshold; <answer> int 
<token> retval; <answer> int 
retval <token> kstrtouint(buf, 0, &bitflip_threshold); <answer> = 
if <token> <answer> (retval) 
<token> retval; <answer> return 
mtd->bitflip_threshold = <token> <answer> bitflip_threshold; 
<token> count; <answer> return 
static ssize_t <token> device *dev, <answer> mtd_ecc_step_size_show(struct 
struct device_attribute *attr, char <token> <answer> *buf) 
struct mtd_info <token> = dev_get_drvdata(dev); <answer> *mtd 
<token> sysfs_emit(buf, "%u\n", mtd->ecc_step_size); <answer> return 
static ssize_t mtd_corrected_bits_show(struct <token> *dev, <answer> device 
struct device_attribute *attr, <token> *buf) <answer> char 
struct <token> *mtd = dev_get_drvdata(dev); <answer> mtd_info 
struct mtd_ecc_stats *ecc_stats <token> &mtd->ecc_stats; <answer> = 
return sysfs_emit(buf, <token> ecc_stats->corrected); <answer> "%u\n", 
int mtd_wunit_to_pairing_info(struct <token> *mtd, int wunit, <answer> mtd_info 
struct mtd_pairing_info <token> <answer> *info) 
struct <token> *master = mtd_get_master(mtd); <answer> mtd_info 
int npairs = mtd_wunit_per_eb(master) <token> mtd_pairing_groups(master); <answer> / 
if (wunit <token> 0 || wunit >= npairs) <answer> < 
<token> -EINVAL; <answer> return 
if (master->pairing && <token> <answer> master->pairing->get_info) 
<token> master->pairing->get_info(master, wunit, info); <answer> return 
info->group = <token> <answer> 0; 
info->pair = <token> <answer> wunit; 
return <token> <answer> 0; 
int mtd_pairing_info_to_wunit(struct mtd_info <token> <answer> *mtd, 
const struct mtd_pairing_info <token> <answer> *info) 
<token> mtd_info *master = mtd_get_master(mtd); <answer> struct 
<token> ngroups = mtd_pairing_groups(master); <answer> int 
int npairs <token> mtd_wunit_per_eb(master) / ngroups; <answer> = 
if (!info || <token> < 0 || info->pair >= npairs || <answer> info->pair 
info->group < 0 <token> info->group >= ngroups) <answer> || 
return <token> <answer> -EINVAL; 
if <token> && master->pairing->get_wunit) <answer> (master->pairing 
return <token> info); <answer> mtd->pairing->get_wunit(master, 
return <token> <answer> info->pair; 
<token> mtd_pairing_groups(struct mtd_info *mtd) <answer> int 
struct mtd_info *master <token> mtd_get_master(mtd); <answer> = 
if (!master->pairing <token> !master->pairing->ngroups) <answer> || 
<token> 1; <answer> return 
<token> master->pairing->ngroups; <answer> return 
<token> int mtd_nvmem_reg_read(void *priv, unsigned int offset, <answer> static 
void *val, size_t <token> <answer> bytes) 
struct mtd_info *mtd <token> priv; <answer> = 
<token> retlen; <answer> size_t 
<token> err; <answer> int 
<token> = mtd_read(mtd, offset, bytes, &retlen, val); <answer> err 
if (err && err != <token> <answer> -EUCLEAN) 
return <token> <answer> err; 
return <token> == bytes ? 0 : -EIO; <answer> retlen 
static int mtd_nvmem_add(struct <token> *mtd) <answer> mtd_info 
<token> device_node *node = mtd_get_of_node(mtd); <answer> struct 
<token> nvmem_config config = {}; <answer> struct 
config.id <token> NVMEM_DEVID_NONE; <answer> = 
config.dev <token> &mtd->dev; <answer> = 
<token> = dev_name(&mtd->dev); <answer> config.name 
config.owner <token> THIS_MODULE; <answer> = 
config.add_legacy_fixed_of_cells = of_device_is_compatible(node, <token> <answer> "nvmem-cells"); 
config.reg_read = <token> <answer> mtd_nvmem_reg_read; 
config.size <token> mtd->size; <answer> = 
<token> = 1; <answer> config.word_size 
config.stride <token> 1; <answer> = 
config.read_only = <token> <answer> true; 
config.root_only <token> true; <answer> = 
config.ignore_wp <token> true; <answer> = 
<token> = mtd; <answer> config.priv 
<token> = nvmem_register(&config); <answer> mtd->nvmem 
if <token> { <answer> (IS_ERR(mtd->nvmem)) 
int add_mtd_device(struct <token> *mtd) <answer> mtd_info 
struct device_node <token> = mtd_get_of_node(mtd); <answer> *np 
struct mtd_info *master <token> mtd_get_master(mtd); <answer> = 
<token> mtd_notifier *not; <answer> struct 
<token> i, error, ofidx; <answer> int 
if (WARN_ONCE(mtd->dev.type, "MTD already <token> <answer> registered\n")) 
return <token> <answer> -EEXIST; 
BUG_ON(mtd->writesize <token> 0); <answer> == 
if (WARN_ON((mtd->_write && mtd->_write_oob) <token> <answer> || 
(mtd->_read && <token> <answer> mtd->_read_oob))) 
<token> -EINVAL; <answer> return 
if (WARN_ON((!mtd->erasesize || !master->_erase) <token> <answer> && 
!(mtd->flags & <token> <answer> MTD_NO_ERASE))) 
return <token> <answer> -EINVAL; 
if (mtd->flags <token> MTD_SLC_ON_MLC_EMULATION && <answer> & 
(!mtd_is_partition(mtd) || master->type <token> MTD_MLCNANDFLASH || <answer> != 
<token> || master->_writev)) <answer> !master->pairing 
<token> -EINVAL; <answer> return 
ofidx <token> -1; <answer> = 
if <token> <answer> (np) 
ofidx = of_alias_get_id(np, <token> <answer> "mtd"); 
if (ofidx >= <token> <answer> 0) 
<token> = idr_alloc(&mtd_idr, mtd, ofidx, ofidx + 1, GFP_KERNEL); <answer> i 
i = <token> mtd, 0, 0, GFP_KERNEL); <answer> idr_alloc(&mtd_idr, 
if (i < <token> { <answer> 0) 
error = <token> <answer> i; 
goto <token> <answer> fail_locked; 
mtd->index = <token> <answer> i; 
<token> = &mtd_devtype; <answer> mtd->dev.type 
mtd->dev.class <token> &mtd_class; <answer> = 
<token> = MTD_DEVT(i); <answer> mtd->dev.devt 
<token> "mtd%d", i); <answer> dev_set_name(&mtd->dev, 
<token> mtd); <answer> dev_set_drvdata(&mtd->dev, 
<token> = device_register(&mtd->dev); <answer> error 
if (error) <token> <answer> { 
<token> fail_added; <answer> goto 
list_for_each_entry(not, &mtd_notifiers, <token> <answer> list) 
if (of_property_read_bool(mtd_get_of_node(mtd), "linux,rootfs")) <token> <answer> { 
<token> (IS_BUILTIN(CONFIG_MTD)) { <answer> if 
pr_info("mtd: setting mtd%d (%s) as root device\n", <token> mtd->name); <answer> mtd->index, 
ROOT_DEV <token> MKDEV(MTD_BLOCK_MAJOR, mtd->index); <answer> = 
} <token> { <answer> else 
pr_warn("mtd: can't set mtd%d <token> as root device - mtd must be builtin\n", <answer> (%s) 
<token> mtd->name); <answer> mtd->index, 
return <token> <answer> 0; 
idr_remove(&mtd_idr, <token> <answer> i); 
<token> error; <answer> return 
int del_mtd_device(struct mtd_info <token> <answer> *mtd) 
int <token> <answer> ret; 
struct <token> *not; <answer> mtd_notifier 
if (idr_find(&mtd_idr, <token> != mtd) { <answer> mtd->index) 
ret <token> -ENODEV; <answer> = 
<token> out_error; <answer> goto 
list_for_each_entry(not, <token> list) <answer> &mtd_notifiers, 
kref_put(&mtd->refcnt, <token> <answer> mtd_device_release); 
ret = <token> <answer> 0; 
<token> ret; <answer> return 
static void mtd_set_dev_defaults(struct <token> *mtd) <answer> mtd_info 
if <token> { <answer> (mtd->dev.parent) 
<token> (!mtd->owner && mtd->dev.parent->driver) <answer> if 
mtd->owner <token> mtd->dev.parent->driver->owner; <answer> = 
<token> (!mtd->name) <answer> if 
mtd->name = <token> <answer> dev_name(mtd->dev.parent); 
} else <token> <answer> { 
pr_debug("mtd device won't show a device <token> in sysfs\n"); <answer> symlink 
<token> ssize_t mtd_otp_size(struct mtd_info *mtd, bool is_user) <answer> static 
<token> otp_info *info; <answer> struct 
ssize_t <token> = 0; <answer> size 
unsigned <token> i; <answer> int 
size_t <token> <answer> retlen; 
int <token> <answer> ret; 
info = <token> GFP_KERNEL); <answer> kmalloc(PAGE_SIZE, 
if <token> <answer> (!info) 
<token> -ENOMEM; <answer> return 
if <token> <answer> (is_user) 
ret = mtd_get_user_prot_info(mtd, <token> &retlen, info); <answer> PAGE_SIZE, 
ret = <token> PAGE_SIZE, &retlen, info); <answer> mtd_get_fact_prot_info(mtd, 
if <token> <answer> (ret) 
goto <token> <answer> err; 
for (i = <token> i < retlen / sizeof(*info); i++) <answer> 0; 
size += <token> <answer> info[i].length; 
<token> size; <answer> return 
<token> *otp; <answer> void 
otp = kmalloc(size, <token> <answer> GFP_KERNEL); 
if <token> { <answer> (!otp) 
err <token> -ENOMEM; <answer> = 
<token> err; <answer> goto 
err = <token> 0, otp, size); <answer> mtd_nvmem_fact_otp_reg_read(mtd, 
if (err < <token> { <answer> 0) 
<token> err; <answer> goto 
<token> err); <answer> add_device_randomness(otp, 
nvmem = <token> "factory-otp", size, <answer> mtd_otp_nvmem_register(mtd, 
if (IS_ERR(nvmem)) <token> <answer> { 
err <token> PTR_ERR(nvmem); <answer> = 
goto <token> <answer> err; 
mtd->otp_factory_nvmem = <token> <answer> nvmem; 
return <token> <answer> 0; 
return dev_err_probe(dev, <token> "Failed to register OTP NVMEM device\n"); <answer> err, 
<token> mtd_device_parse_register(struct mtd_info *mtd, const char * const *types, <answer> int 
<token> mtd_part_parser_data *parser_data, <answer> struct 
<token> struct mtd_partition *parts, <answer> const 
int <token> <answer> nr_parts) 
<token> ret; <answer> int 
ret = <token> <answer> mtd_otp_nvmem_add(mtd); 
<token> (ret) <answer> if 
<token> out; <answer> goto 
if <token> { <answer> (IS_ENABLED(CONFIG_MTD_PARTITIONED_MASTER)) 
ret = <token> <answer> add_mtd_device(mtd); 
<token> (ret) <answer> if 
<token> out; <answer> goto 
WARN_ONCE(mtd->_reboot <token> mtd->reboot_notifier.notifier_call, <answer> && 
<token> already registered\n"); <answer> "MTD 
if (mtd->_reboot && <token> { <answer> !mtd->reboot_notifier.notifier_call) 
<token> = mtd_reboot_notifier; <answer> mtd->reboot_notifier.notifier_call 
if (ret) <token> <answer> { 
<token> (ret && device_is_registered(&mtd->dev)) <answer> if 
return <token> <answer> ret; 
int mtd_device_unregister(struct mtd_info <token> <answer> *master) 
int <token> <answer> err; 
<token> (master->_reboot) { <answer> if 
memset(&master->reboot_notifier, <token> sizeof(master->reboot_notifier)); <answer> 0, 
err <token> del_mtd_partitions(master); <answer> = 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> (!device_is_registered(&master->dev)) <answer> if 
return <token> <answer> 0; 
<token> del_mtd_device(master); <answer> return 
void register_mtd_user <token> mtd_notifier *new) <answer> (struct 
struct mtd_info <token> <answer> *mtd; 
<token> &mtd_notifiers); <answer> list_add(&new->list, 
<token> unregister_mtd_user (struct mtd_notifier *old) <answer> int 
struct <token> *mtd; <answer> mtd_info 
<token> 0; <answer> return 
struct mtd_info *get_mtd_device(struct <token> *mtd, int num) <answer> mtd_info 
struct <token> *ret = NULL, *other; <answer> mtd_info 
int err = <token> <answer> -ENODEV; 
<token> (num == -1) { <answer> if 
mtd_for_each_device(other) <token> <answer> { 
if (other == mtd) <token> <answer> { 
<token> = mtd; <answer> ret 
} else <token> (num >= 0) { <answer> if 
ret = idr_find(&mtd_idr, <token> <answer> num); 
if (mtd && <token> != ret) <answer> mtd 
ret = <token> <answer> NULL; 
<token> (!ret) { <answer> if 
ret <token> ERR_PTR(err); <answer> = 
goto <token> <answer> out; 
err = <token> <answer> __get_mtd_device(ret); 
if <token> <answer> (err) 
ret = <token> <answer> ERR_PTR(err); 
<token> ret; <answer> return 
<token> __get_mtd_device(struct mtd_info *mtd) <answer> int 
struct mtd_info *master = <token> <answer> mtd_get_master(mtd); 
<token> err; <answer> int 
<token> (master->_get_device) { <answer> if 
<token> = master->_get_device(mtd); <answer> err 
<token> (err) <answer> if 
return <token> <answer> err; 
if (!try_module_get(master->owner)) <token> <answer> { 
<token> (master->_put_device) <answer> if 
<token> -ENODEV; <answer> return 
while <token> { <answer> (mtd) 
if <token> != master) <answer> (mtd 
mtd <token> mtd->parent; <answer> = 
<token> (IS_ENABLED(CONFIG_MTD_PARTITIONED_MASTER)) <answer> if 
<token> 0; <answer> return 
struct mtd_info *of_get_mtd_device_by_node(struct device_node <token> <answer> *np) 
struct mtd_info *mtd <token> NULL; <answer> = 
<token> mtd_info *tmp; <answer> struct 
<token> err; <answer> int 
<token> = -EPROBE_DEFER; <answer> err 
mtd_for_each_device(tmp) <token> <answer> { 
if <token> == np) { <answer> (mtd_get_of_node(tmp) 
mtd <token> tmp; <answer> = 
err = <token> <answer> __get_mtd_device(mtd); 
return err ? ERR_PTR(err) <token> mtd; <answer> : 
struct <token> *get_mtd_device_nm(const char *name) <answer> mtd_info 
<token> err = -ENODEV; <answer> int 
struct mtd_info <token> = NULL, *other; <answer> *mtd 
<token> { <answer> mtd_for_each_device(other) 
if (!strcmp(name, <token> { <answer> other->name)) 
mtd <token> other; <answer> = 
if <token> <answer> (!mtd) 
goto <token> <answer> out_unlock; 
err = <token> <answer> __get_mtd_device(mtd); 
<token> (err) <answer> if 
goto <token> <answer> out_unlock; 
return <token> <answer> mtd; 
return <token> <answer> ERR_PTR(err); 
<token> put_mtd_device(struct mtd_info *mtd) <answer> void 
void __put_mtd_device(struct <token> *mtd) <answer> mtd_info 
struct mtd_info <token> = mtd_get_master(mtd); <answer> *master 
while (mtd) <token> <answer> { 
int <token> mtd_info *mtd, struct erase_info *instr) <answer> mtd_erase(struct 
struct <token> *master = mtd_get_master(mtd); <answer> mtd_info 
u64 mst_ofs = <token> 0); <answer> mtd_get_master_ofs(mtd, 
struct erase_info <token> <answer> adjinstr; 
int <token> <answer> ret; 
instr->fail_addr <token> MTD_FAIL_ADDR_UNKNOWN; <answer> = 
adjinstr = <token> <answer> *instr; 
if (!mtd->erasesize || <token> <answer> !master->_erase) 
return <token> <answer> -ENOTSUPP; 
if (instr->addr >= mtd->size || instr->len > mtd->size - <token> <answer> instr->addr) 
return <token> <answer> -EINVAL; 
<token> (!(mtd->flags & MTD_WRITEABLE)) <answer> if 
return <token> <answer> -EROFS; 
<token> (!instr->len) <answer> if 
<token> 0; <answer> return 
if (mtd->flags & MTD_SLC_ON_MLC_EMULATION) <token> <answer> { 
adjinstr.addr = (loff_t)mtd_div_by_eb(instr->addr, <token> * <answer> mtd) 
adjinstr.len = ((u64)mtd_div_by_eb(instr->addr <token> instr->len, mtd) * <answer> + 
<token> - <answer> master->erasesize) 
adjinstr.addr <token> mst_ofs; <answer> += 
ret = master->_erase(master, <token> <answer> &adjinstr); 
if (adjinstr.fail_addr <token> MTD_FAIL_ADDR_UNKNOWN) { <answer> != 
instr->fail_addr = <token> - mst_ofs; <answer> adjinstr.fail_addr 
if <token> & MTD_SLC_ON_MLC_EMULATION) { <answer> (mtd->flags 
instr->fail_addr <token> mtd_div_by_eb(instr->fail_addr, <answer> = 
instr->fail_addr <token> mtd->erasesize; <answer> *= 
return <token> <answer> ret; 
ALLOW_ERROR_INJECTION(mtd_erase, <token> <answer> ERRNO); 
int mtd_point(struct mtd_info *mtd, loff_t from, size_t len, size_t <token> <answer> *retlen, 
void <token> resource_size_t *phys) <answer> **virt, 
struct mtd_info *master <token> mtd_get_master(mtd); <answer> = 
*retlen <token> 0; <answer> = 
*virt = <token> <answer> NULL; 
if <token> <answer> (phys) 
<token> = 0; <answer> *phys 
if <token> <answer> (!master->_point) 
<token> -EOPNOTSUPP; <answer> return 
if (from < 0 || <token> >= mtd->size || len > mtd->size - from) <answer> from 
<token> -EINVAL; <answer> return 
<token> (!len) <answer> if 
<token> 0; <answer> return 
<token> = mtd_get_master_ofs(mtd, from); <answer> from 
return master->_point(master, from, <token> retlen, virt, phys); <answer> len, 
unsigned long mtd_get_unmapped_area(struct mtd_info *mtd, unsigned long <token> <answer> len, 
unsigned long offset, unsigned long <token> <answer> flags) 
size_t <token> <answer> retlen; 
<token> *virt; <answer> void 
int <token> <answer> ret; 
<token> = mtd_point(mtd, offset, len, &retlen, &virt, NULL); <answer> ret 
<token> (ret) <answer> if 
return <token> <answer> ret; 
if <token> != len) { <answer> (retlen 
mtd_unpoint(mtd, <token> retlen); <answer> offset, 
<token> -ENOSYS; <answer> return 
return <token> long)virt; <answer> (unsigned 
static void <token> mtd_info *mtd, struct mtd_info *master, <answer> mtd_update_ecc_stats(struct 
const struct <token> *old_stats) <answer> mtd_ecc_stats 
<token> mtd_ecc_stats diff; <answer> struct 
if (master == <token> <answer> mtd) 
diff <token> master->ecc_stats; <answer> = 
diff.failed <token> old_stats->failed; <answer> -= 
diff.corrected <token> old_stats->corrected; <answer> -= 
while <token> { <answer> (mtd->parent) 
<token> += diff.failed; <answer> mtd->ecc_stats.failed 
<token> += diff.corrected; <answer> mtd->ecc_stats.corrected 
<token> = mtd->parent; <answer> mtd 
int mtd_read(struct <token> *mtd, loff_t from, size_t len, size_t *retlen, <answer> mtd_info 
u_char <token> <answer> *buf) 
<token> mtd_oob_ops ops = { <answer> struct 
.len = <token> <answer> len, 
.datbuf = <token> <answer> buf, 
int <token> <answer> ret; 
ret <token> mtd_read_oob(mtd, from, &ops); <answer> = 
*retlen <token> ops.retlen; <answer> = 
WARN_ON_ONCE(*retlen != len <token> mtd_is_bitflip_or_eccerr(ret)); <answer> && 
<token> ret; <answer> return 
<token> ERRNO); <answer> ALLOW_ERROR_INJECTION(mtd_read, 
int <token> mtd_info *mtd, loff_t to, size_t len, size_t *retlen, <answer> mtd_write(struct 
const u_char <token> <answer> *buf) 
struct mtd_oob_ops ops <token> { <answer> = 
.len = <token> <answer> len, 
.datbuf = <token> *)buf, <answer> (u8 
<token> ret; <answer> int 
ret = <token> to, &ops); <answer> mtd_write_oob(mtd, 
<token> = ops.retlen; <answer> *retlen 
return <token> <answer> ret; 
ALLOW_ERROR_INJECTION(mtd_write, <token> <answer> ERRNO); 
int <token> mtd_info *mtd, loff_t to, size_t len, size_t *retlen, <answer> mtd_panic_write(struct 
const u_char <token> <answer> *buf) 
struct mtd_info *master = <token> <answer> mtd_get_master(mtd); 
*retlen <token> 0; <answer> = 
if <token> <answer> (!master->_panic_write) 
<token> -EOPNOTSUPP; <answer> return 
if (to < 0 || to <token> mtd->size || len > mtd->size - to) <answer> >= 
<token> -EINVAL; <answer> return 
if (!(mtd->flags <token> MTD_WRITEABLE)) <answer> & 
<token> -EROFS; <answer> return 
if <token> <answer> (!len) 
<token> 0; <answer> return 
if <token> <answer> (!master->oops_panic_write) 
master->oops_panic_write <token> true; <answer> = 
return master->_panic_write(master, <token> to), len, <answer> mtd_get_master_ofs(mtd, 
retlen, <token> <answer> buf); 
static int mtd_check_oob_ops(struct mtd_info *mtd, loff_t <token> <answer> offs, 
<token> mtd_oob_ops *ops) <answer> struct 
<token> (!ops->datbuf) <answer> if 
ops->len <token> 0; <answer> = 
if <token> <answer> (!ops->oobbuf) 
<token> = 0; <answer> ops->ooblen 
if (offs <token> 0 || offs + ops->len > mtd->size) <answer> < 
<token> -EINVAL; <answer> return 
if (ops->ooblen) <token> <answer> { 
size_t <token> <answer> maxooblen; 
if <token> >= mtd_oobavail(mtd, ops)) <answer> (ops->ooboffs 
<token> -EINVAL; <answer> return 
maxooblen = <token> mtd) - <answer> ((size_t)(mtd_div_by_ws(mtd->size, 
mtd_div_by_ws(offs, mtd)) <token> <answer> * 
mtd_oobavail(mtd, <token> - ops->ooboffs; <answer> ops)) 
if <token> > maxooblen) <answer> (ops->ooblen 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
<token> int mtd_read_oob_std(struct mtd_info *mtd, loff_t from, <answer> static 
<token> mtd_oob_ops *ops) <answer> struct 
<token> mtd_info *master = mtd_get_master(mtd); <answer> struct 
int <token> <answer> ret; 
from = <token> from); <answer> mtd_get_master_ofs(mtd, 
<token> (master->_read_oob) <answer> if 
<token> = master->_read_oob(master, from, ops); <answer> ret 
ret = master->_read(master, from, ops->len, <token> <answer> &ops->retlen, 
return <token> <answer> ret; 
<token> int mtd_write_oob_std(struct mtd_info *mtd, loff_t to, <answer> static 
struct <token> *ops) <answer> mtd_oob_ops 
struct mtd_info <token> = mtd_get_master(mtd); <answer> *master 
<token> ret; <answer> int 
to = <token> to); <answer> mtd_get_master_ofs(mtd, 
<token> (master->_write_oob) <answer> if 
ret <token> master->_write_oob(master, to, ops); <answer> = 
ret = master->_write(master, <token> ops->len, &ops->retlen, <answer> to, 
<token> ret; <answer> return 
static int <token> mtd_info *mtd, loff_t start, bool read, <answer> mtd_io_emulated_slc(struct 
struct <token> *ops) <answer> mtd_oob_ops 
struct <token> *master = mtd_get_master(mtd); <answer> mtd_info 
<token> ngroups = mtd_pairing_groups(master); <answer> int 
<token> npairs = mtd_wunit_per_eb(master) / ngroups; <answer> int 
struct mtd_oob_ops <token> = *ops; <answer> adjops 
unsigned int wunit, <token> <answer> oobavail; 
struct <token> info; <answer> mtd_pairing_info 
<token> max_bitflips = 0; <answer> int 
u32 ebofs, <token> <answer> pageofs; 
<token> base, pos; <answer> loff_t 
ebofs = mtd_mod_by_eb(start, <token> <answer> mtd); 
base = (loff_t)mtd_div_by_eb(start, mtd) <token> master->erasesize; <answer> * 
info.group = <token> <answer> 0; 
<token> = mtd_div_by_ws(ebofs, mtd); <answer> info.pair 
<token> = mtd_mod_by_ws(ebofs, mtd); <answer> pageofs 
oobavail = mtd_oobavail(mtd, <token> <answer> ops); 
while (ops->retlen < <token> || ops->oobretlen < ops->ooblen) { <answer> ops->len 
int <token> <answer> ret; 
if <token> >= npairs) { <answer> (info.pair 
info.pair <token> 0; <answer> = 
<token> += master->erasesize; <answer> base 
wunit <token> mtd_pairing_info_to_wunit(master, &info); <answer> = 
pos <token> mtd_wunit_to_offset(mtd, base, wunit); <answer> = 
adjops.len <token> ops->len - ops->retlen; <answer> = 
if (adjops.len > mtd->writesize - <token> <answer> pageofs) 
<token> = mtd->writesize - pageofs; <answer> adjops.len 
<token> = ops->ooblen - ops->oobretlen; <answer> adjops.ooblen 
if <token> > oobavail - adjops.ooboffs) <answer> (adjops.ooblen 
adjops.ooblen = oobavail - <token> <answer> adjops.ooboffs; 
<token> (read) { <answer> if 
<token> = mtd_read_oob_std(mtd, pos + pageofs, &adjops); <answer> ret 
<token> (ret > 0) <answer> if 
<token> = max(max_bitflips, ret); <answer> max_bitflips 
<token> else { <answer> } 
ret = mtd_write_oob_std(mtd, pos + <token> &adjops); <answer> pageofs, 
if (ret <token> 0) <answer> < 
return <token> <answer> ret; 
max_bitflips = <token> ret); <answer> max(max_bitflips, 
ops->retlen <token> adjops.retlen; <answer> += 
ops->oobretlen <token> adjops.oobretlen; <answer> += 
<token> += adjops.retlen; <answer> adjops.datbuf 
adjops.oobbuf += <token> <answer> adjops.oobretlen; 
adjops.ooboffs <token> 0; <answer> = 
pageofs <token> 0; <answer> = 
return <token> <answer> max_bitflips; 
int mtd_read_oob(struct <token> *mtd, loff_t from, struct mtd_oob_ops *ops) <answer> mtd_info 
struct mtd_info <token> = mtd_get_master(mtd); <answer> *master 
struct mtd_ecc_stats old_stats <token> master->ecc_stats; <answer> = 
<token> ret_code; <answer> int 
ops->retlen = <token> = 0; <answer> ops->oobretlen 
ret_code <token> mtd_check_oob_ops(mtd, from, ops); <answer> = 
<token> (ret_code) <answer> if 
return <token> <answer> ret_code; 
if <token> < 0)) <answer> (unlikely(ret_code 
return <token> <answer> ret_code; 
if <token> == 0) <answer> (mtd->ecc_strength 
int mtd_ooblayout_ecc(struct mtd_info <token> int section, <answer> *mtd, 
struct <token> *oobecc) <answer> mtd_oob_region 
struct mtd_info *master = <token> <answer> mtd_get_master(mtd); 
<token> 0, sizeof(*oobecc)); <answer> memset(oobecc, 
if (!master || section < <token> <answer> 0) 
<token> -EINVAL; <answer> return 
if (!master->ooblayout || <token> <answer> !master->ooblayout->ecc) 
return <token> <answer> -ENOTSUPP; 
return master->ooblayout->ecc(master, section, <token> <answer> oobecc); 
int mtd_ooblayout_free(struct mtd_info *mtd, int <token> <answer> section, 
<token> mtd_oob_region *oobfree) <answer> struct 
struct <token> *master = mtd_get_master(mtd); <answer> mtd_info 
memset(oobfree, 0, <token> <answer> sizeof(*oobfree)); 
if (!master || section < <token> <answer> 0) 
return <token> <answer> -EINVAL; 
<token> (!master->ooblayout || !master->ooblayout->free) <answer> if 
return <token> <answer> -ENOTSUPP; 
return <token> section, oobfree); <answer> master->ooblayout->free(master, 
static int mtd_ooblayout_find_region(struct mtd_info *mtd, <token> byte, <answer> int 
int *sectionp, struct mtd_oob_region <token> <answer> *oobregion, 
int (*iter)(struct mtd_info <token> <answer> *, 
int <token> <answer> section, 
struct mtd_oob_region <token> <answer> *oobregion)) 
int pos = <token> ret, section = 0; <answer> 0, 
memset(oobregion, 0, <token> <answer> sizeof(*oobregion)); 
<token> (1) { <answer> while 
ret = iter(mtd, <token> oobregion); <answer> section, 
if <token> <answer> (ret) 
return <token> <answer> ret; 
if (pos + oobregion->length > <token> <answer> byte) 
pos += <token> <answer> oobregion->length; 
oobregion->offset += byte - <token> <answer> pos; 
oobregion->length -= byte - <token> <answer> pos; 
*sectionp = <token> <answer> section; 
<token> 0; <answer> return 
<token> mtd_ooblayout_find_eccregion(struct mtd_info *mtd, int eccbyte, <answer> int 
<token> *section, <answer> int 
<token> mtd_oob_region *oobregion) <answer> struct 
return <token> eccbyte, section, oobregion, <answer> mtd_ooblayout_find_region(mtd, 
static int mtd_ooblayout_get_bytes(struct <token> *mtd, u8 *buf, <answer> mtd_info 
const u8 *oobbuf, <token> start, int nbytes, <answer> int 
int (*iter)(struct mtd_info <token> <answer> *, 
int <token> <answer> section, 
struct mtd_oob_region <token> <answer> *oobregion)) 
struct <token> oobregion; <answer> mtd_oob_region 
int section, <token> <answer> ret; 
ret = mtd_ooblayout_find_region(mtd, <token> &section, <answer> start, 
<token> iter); <answer> &oobregion, 
while (!ret) <token> <answer> { 
<token> cnt; <answer> int 
<token> = min_t(int, nbytes, oobregion.length); <answer> cnt 
memcpy(buf, oobbuf + oobregion.offset, <token> <answer> cnt); 
<token> += cnt; <answer> buf 
nbytes <token> cnt; <answer> -= 
if <token> <answer> (!nbytes) 
<token> = iter(mtd, ++section, &oobregion); <answer> ret 
return <token> <answer> ret; 
static int mtd_ooblayout_set_bytes(struct <token> *mtd, const u8 *buf, <answer> mtd_info 
u8 *oobbuf, int start, <token> nbytes, <answer> int 
<token> (*iter)(struct mtd_info *, <answer> int 
int <token> <answer> section, 
<token> mtd_oob_region *oobregion)) <answer> struct 
struct <token> oobregion; <answer> mtd_oob_region 
<token> section, ret; <answer> int 
ret = mtd_ooblayout_find_region(mtd, <token> &section, <answer> start, 
&oobregion, <token> <answer> iter); 
while <token> { <answer> (!ret) 
int <token> <answer> cnt; 
cnt = <token> nbytes, oobregion.length); <answer> min_t(int, 
memcpy(oobbuf + <token> buf, cnt); <answer> oobregion.offset, 
buf += <token> <answer> cnt; 
nbytes -= <token> <answer> cnt; 
<token> (!nbytes) <answer> if 
ret = iter(mtd, <token> &oobregion); <answer> ++section, 
<token> ret; <answer> return 
static int <token> mtd_info *mtd, <answer> mtd_ooblayout_count_bytes(struct 
int (*iter)(struct <token> *, <answer> mtd_info 
int <token> <answer> section, 
struct <token> *oobregion)) <answer> mtd_oob_region 
struct mtd_oob_region <token> <answer> oobregion; 
int section = 0, ret, nbytes = <token> <answer> 0; 
while (1) <token> <answer> { 
ret = iter(mtd, <token> &oobregion); <answer> section++, 
<token> (ret) { <answer> if 
if (ret <token> -ERANGE) <answer> == 
ret <token> nbytes; <answer> = 
<token> += oobregion.length; <answer> nbytes 
return <token> <answer> ret; 
int mtd_ooblayout_get_eccbytes(struct mtd_info *mtd, <token> *eccbuf, <answer> u8 
const u8 *oobbuf, int start, <token> nbytes) <answer> int 
return <token> eccbuf, oobbuf, start, nbytes, <answer> mtd_ooblayout_get_bytes(mtd, 
int mtd_ooblayout_set_eccbytes(struct <token> *mtd, const u8 *eccbuf, <answer> mtd_info 
u8 *oobbuf, int <token> int nbytes) <answer> start, 
return <token> eccbuf, oobbuf, start, nbytes, <answer> mtd_ooblayout_set_bytes(mtd, 
<token> mtd_ooblayout_get_databytes(struct mtd_info *mtd, u8 *databuf, <answer> int 
const u8 *oobbuf, int <token> int nbytes) <answer> start, 
return <token> databuf, oobbuf, start, nbytes, <answer> mtd_ooblayout_get_bytes(mtd, 
int mtd_ooblayout_set_databytes(struct <token> *mtd, const u8 *databuf, <answer> mtd_info 
u8 *oobbuf, int start, int <token> <answer> nbytes) 
return mtd_ooblayout_set_bytes(mtd, <token> oobbuf, start, nbytes, <answer> databuf, 
int mtd_ooblayout_count_freebytes(struct <token> *mtd) <answer> mtd_info 
return mtd_ooblayout_count_bytes(mtd, <token> <answer> mtd_ooblayout_free); 
int mtd_ooblayout_count_eccbytes(struct <token> *mtd) <answer> mtd_info 
<token> mtd_ooblayout_count_bytes(mtd, mtd_ooblayout_ecc); <answer> return 
int mtd_get_fact_prot_info(struct mtd_info *mtd, size_t len, <token> *retlen, <answer> size_t 
struct <token> *buf) <answer> otp_info 
struct mtd_info *master <token> mtd_get_master(mtd); <answer> = 
if <token> <answer> (!master->_get_fact_prot_info) 
<token> -EOPNOTSUPP; <answer> return 
<token> (!len) <answer> if 
<token> 0; <answer> return 
return master->_get_fact_prot_info(master, len, <token> buf); <answer> retlen, 
int mtd_read_fact_prot_reg(struct mtd_info *mtd, loff_t <token> size_t len, <answer> from, 
size_t *retlen, <token> *buf) <answer> u_char 
struct mtd_info <token> = mtd_get_master(mtd); <answer> *master 
<token> = 0; <answer> *retlen 
if <token> <answer> (!master->_read_fact_prot_reg) 
return <token> <answer> -EOPNOTSUPP; 
<token> (!len) <answer> if 
<token> 0; <answer> return 
return master->_read_fact_prot_reg(master, from, len, <token> buf); <answer> retlen, 
int mtd_get_user_prot_info(struct <token> *mtd, size_t len, size_t *retlen, <answer> mtd_info 
<token> otp_info *buf) <answer> struct 
struct mtd_info *master <token> mtd_get_master(mtd); <answer> = 
<token> (!master->_get_user_prot_info) <answer> if 
<token> -EOPNOTSUPP; <answer> return 
<token> (!len) <answer> if 
<token> 0; <answer> return 
<token> master->_get_user_prot_info(master, len, retlen, buf); <answer> return 
<token> mtd_read_user_prot_reg(struct mtd_info *mtd, loff_t from, size_t len, <answer> int 
size_t *retlen, <token> *buf) <answer> u_char 
<token> mtd_info *master = mtd_get_master(mtd); <answer> struct 
<token> = 0; <answer> *retlen 
<token> (!master->_read_user_prot_reg) <answer> if 
return <token> <answer> -EOPNOTSUPP; 
<token> (!len) <answer> if 
<token> 0; <answer> return 
return master->_read_user_prot_reg(master, <token> len, retlen, buf); <answer> from, 
int mtd_write_user_prot_reg(struct mtd_info *mtd, loff_t to, <token> len, <answer> size_t 
size_t <token> const u_char *buf) <answer> *retlen, 
struct <token> *master = mtd_get_master(mtd); <answer> mtd_info 
int <token> <answer> ret; 
*retlen = <token> <answer> 0; 
<token> (!master->_write_user_prot_reg) <answer> if 
<token> -EOPNOTSUPP; <answer> return 
<token> (!len) <answer> if 
<token> 0; <answer> return 
ret = master->_write_user_prot_reg(master, to, len, retlen, <token> <answer> buf); 
<token> (ret) <answer> if 
return <token> <answer> ret; 
return (*retlen) <token> 0 : -ENOSPC; <answer> ? 
int mtd_lock_user_prot_reg(struct <token> *mtd, loff_t from, size_t len) <answer> mtd_info 
struct mtd_info *master = <token> <answer> mtd_get_master(mtd); 
<token> (!master->_lock_user_prot_reg) <answer> if 
return <token> <answer> -EOPNOTSUPP; 
<token> (!len) <answer> if 
<token> 0; <answer> return 
return master->_lock_user_prot_reg(master, <token> len); <answer> from, 
int mtd_erase_user_prot_reg(struct mtd_info *mtd, <token> from, size_t len) <answer> loff_t 
struct <token> *master = mtd_get_master(mtd); <answer> mtd_info 
if <token> <answer> (!master->_erase_user_prot_reg) 
return <token> <answer> -EOPNOTSUPP; 
<token> (!len) <answer> if 
return <token> <answer> 0; 
return master->_erase_user_prot_reg(master, from, <token> <answer> len); 
static int default_mtd_writev(struct mtd_info *mtd, const struct kvec <token> <answer> *vecs, 
unsigned long count, loff_t to, size_t <token> <answer> *retlen) 
unsigned long <token> <answer> i; 
size_t <token> = 0, thislen; <answer> totlen 
int <token> = 0; <answer> ret 
for (i = 0; <token> < count; i++) { <answer> i 
if <token> <answer> (!vecs[i].iov_len) 
ret = mtd_write(mtd, to, vecs[i].iov_len, <token> <answer> &thislen, 
totlen <token> thislen; <answer> += 
if (ret || <token> != vecs[i].iov_len) <answer> thislen 
<token> += vecs[i].iov_len; <answer> to 
*retlen <token> totlen; <answer> = 
<token> ret; <answer> return 
int <token> mtd_info *mtd, const struct kvec *vecs, <answer> mtd_writev(struct 
<token> long count, loff_t to, size_t *retlen) <answer> unsigned 
struct mtd_info <token> = mtd_get_master(mtd); <answer> *master 
<token> = 0; <answer> *retlen 
<token> (!(mtd->flags & MTD_WRITEABLE)) <answer> if 
return <token> <answer> -EROFS; 
if <token> <answer> (!master->_writev) 
return <token> vecs, count, to, retlen); <answer> default_mtd_writev(mtd, 
<token> master->_writev(master, vecs, count, <answer> return 
mtd_get_master_ofs(mtd, <token> retlen); <answer> to), 
void *mtd_kmalloc_up_to(const struct mtd_info *mtd, <token> *size) <answer> size_t 
<token> flags = __GFP_NOWARN | __GFP_DIRECT_RECLAIM | __GFP_NORETRY; <answer> gfp_t 
size_t min_alloc = max_t(size_t, mtd->writesize, <token> <answer> PAGE_SIZE); 
<token> *kbuf; <answer> void 
*size <token> min_t(size_t, *size, KMALLOC_MAX_SIZE); <answer> = 
while (*size > <token> { <answer> min_alloc) 
kbuf = <token> flags); <answer> kmalloc(*size, 
if <token> <answer> (kbuf) 
return <token> <answer> kbuf; 
*size <token> 1; <answer> >>= 
<token> = ALIGN(*size, mtd->writesize); <answer> *size 
return <token> GFP_KERNEL); <answer> kmalloc(*size, 
#ifdef <token> <answer> CONFIG_PROC_FS 
ret = bdi_register(bdi, "%.28s-0", <token> <answer> name); 
if <token> <answer> (ret) 
return ret ? <token> : bdi; <answer> ERR_PTR(ret) 
<token> struct proc_dir_entry *proc_mtd; <answer> static 
static int <token> init_mtd(void) <answer> __init 
int <token> <answer> ret; 
ret <token> class_register(&mtd_class); <answer> = 
if <token> <answer> (ret) 
goto <token> <answer> err_reg; 
mtd_bdi = <token> <answer> mtd_bdi_init("mtd"); 
if (IS_ERR(mtd_bdi)) <token> <answer> { 
ret <token> PTR_ERR(mtd_bdi); <answer> = 
goto <token> <answer> err_bdi; 
<token> = proc_create_single("mtd", 0, NULL, mtd_proc_show); <answer> proc_mtd 
ret = <token> <answer> init_mtdchar(); 
<token> (ret) <answer> if 
goto <token> <answer> out_procfs; 
dfs_dir_mtd = debugfs_create_dir("mtd", <token> <answer> NULL); 
debugfs_create_bool("expert_analysis_mode", 0600, <token> <answer> dfs_dir_mtd, 
return <token> <answer> 0; 
if <token> <answer> (proc_mtd) 
remove_proc_entry("mtd", <token> <answer> NULL); 
pr_err("Error registering mtd class or <token> %d\n", ret); <answer> bdi: 
<token> ret; <answer> return 
<token> void __exit cleanup_mtd(void) <answer> static 
if <token> <answer> (proc_mtd) 
remove_proc_entry("mtd", <token> <answer> NULL); 
MODULE_AUTHOR("David Woodhouse <token> <answer> <dwmw2@infradead.org>"); 
MODULE_DESCRIPTION("Core MTD registration <token> access routines"); <answer> and 
<token> <linux/delay.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
<token> <linux/hwmon.h> <answer> #include 
<token> <linux/hwmon-sysfs.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/completion.h> 
<token> <linux/mfd/da9055/core.h> <answer> #include 
#include <token> <answer> <linux/mfd/da9055/reg.h> 
#define <token> 102 <answer> DA9055_ADCIN_DIV 
<token> DA9055_VSYS_DIV 85 <answer> #define 
#define <token> 0 <answer> DA9055_ADC_VSYS 
#define DA9055_ADC_ADCIN1 <token> <answer> 1 
<token> DA9055_ADC_ADCIN2 2 <answer> #define 
#define DA9055_ADC_ADCIN3 <token> <answer> 3 
#define DA9055_ADC_TJUNC <token> <answer> 4 
struct da9055_hwmon <token> <answer> { 
<token> da9055 *da9055; <answer> struct 
<token> mutex hwmon_lock; <answer> struct 
struct mutex <token> <answer> irq_lock; 
struct <token> done; <answer> completion 
static const char * const <token> = { <answer> input_names[] 
[DA9055_ADC_VSYS] = <token> <answer> "VSYS", 
<token> = "ADC IN1", <answer> [DA9055_ADC_ADCIN1] 
[DA9055_ADC_ADCIN2] = "ADC <token> <answer> IN2", 
[DA9055_ADC_ADCIN3] = <token> IN3", <answer> "ADC 
[DA9055_ADC_TJUNC] = <token> TEMP", <answer> "CHIP 
static <token> u8 chan_mux[DA9055_ADC_TJUNC + 1] = { <answer> const 
<token> = DA9055_ADC_MUX_VSYS, <answer> [DA9055_ADC_VSYS] 
<token> = DA9055_ADC_MUX_ADCIN1, <answer> [DA9055_ADC_ADCIN1] 
[DA9055_ADC_ADCIN2] <token> DA9055_ADC_MUX_ADCIN2, <answer> = 
[DA9055_ADC_ADCIN3] = <token> <answer> DA9055_ADC_MUX_ADCIN3, 
[DA9055_ADC_TJUNC] <token> DA9055_ADC_MUX_T_SENSE, <answer> = 
<token> int da9055_adc_manual_read(struct da9055_hwmon *hwmon, <answer> static 
unsigned <token> channel) <answer> char 
int <token> <answer> ret; 
<token> short calc_data; <answer> unsigned 
unsigned short <token> <answer> data; 
unsigned <token> mux_sel; <answer> char 
struct <token> *da9055 = hwmon->da9055; <answer> da9055 
if (channel > <token> <answer> DA9055_ADC_TJUNC) 
return <token> <answer> -EINVAL; 
return sprintf(buf, <token> DIV_ROUND_CLOSEST(-4084 * (tjunc - toffset) <answer> "%d\n", 
+ 3076332, <token> <answer> 10000)); 
static <token> label_show(struct device *dev, <answer> ssize_t 
struct device_attribute *devattr, char <token> <answer> *buf) 
return <token> "%s\n", <answer> sprintf(buf, 
static SENSOR_DEVICE_ATTR_RO(in0_input, <token> DA9055_ADC_VSYS); <answer> da9055_auto_ch, 
<token> SENSOR_DEVICE_ATTR_RO(in0_label, label, DA9055_ADC_VSYS); <answer> static 
<token> SENSOR_DEVICE_ATTR_RO(in1_input, da9055_auto_ch, DA9055_ADC_ADCIN1); <answer> static 
static SENSOR_DEVICE_ATTR_RO(in1_label, <token> DA9055_ADC_ADCIN1); <answer> label, 
static SENSOR_DEVICE_ATTR_RO(in2_input, <token> DA9055_ADC_ADCIN2); <answer> da9055_auto_ch, 
static SENSOR_DEVICE_ATTR_RO(in2_label, label, <token> <answer> DA9055_ADC_ADCIN2); 
static SENSOR_DEVICE_ATTR_RO(in3_input, da9055_auto_ch, <token> <answer> DA9055_ADC_ADCIN3); 
<token> SENSOR_DEVICE_ATTR_RO(in3_label, label, DA9055_ADC_ADCIN3); <answer> static 
static SENSOR_DEVICE_ATTR_RO(temp1_input, da9055_tjunc, <token> <answer> DA9055_ADC_TJUNC); 
static <token> label, DA9055_ADC_TJUNC); <answer> SENSOR_DEVICE_ATTR_RO(temp1_label, 
static struct <token> *da9055_attrs[] = { <answer> attribute 
static <token> da9055_hwmon_probe(struct platform_device *pdev) <answer> int 
struct device *dev <token> &pdev->dev; <answer> = 
<token> da9055_hwmon *hwmon; <answer> struct 
struct device <token> <answer> *hwmon_dev; 
int hwmon_irq, <token> <answer> ret; 
hwmon = devm_kzalloc(dev, <token> da9055_hwmon), GFP_KERNEL); <answer> sizeof(struct 
<token> (!hwmon) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = dev_get_drvdata(pdev->dev.parent); <answer> hwmon->da9055 
hwmon_irq = <token> "HWMON"); <answer> platform_get_irq_byname(pdev, 
if (hwmon_irq < <token> <answer> 0) 
<token> hwmon_irq; <answer> return 
<token> = devm_request_threaded_irq(&pdev->dev, hwmon_irq, <answer> ret 
NULL, <token> <answer> da9055_auxadc_irq, 
IRQF_TRIGGER_HIGH | <token> <answer> IRQF_ONESHOT, 
<token> hwmon); <answer> "adc-irq", 
if (ret != 0) <token> <answer> { 
dev_err(hwmon->da9055->dev, "DA9055 ADC IRQ failed <token> <answer> ret=%d\n", 
<token> ret; <answer> return 
hwmon_dev = devm_hwmon_device_register_with_groups(dev, <token> <answer> "da9055", 
<token> PTR_ERR_OR_ZERO(hwmon_dev); <answer> return 
<token> struct platform_driver da9055_hwmon_driver = { <answer> static 
<token> = da9055_hwmon_probe, <answer> .probe 
.driver = <token> <answer> { 
<token> = "da9055-hwmon", <answer> .name 
MODULE_AUTHOR("David <token> Chen <dchen@diasemi.com>"); <answer> Dajun 
MODULE_DESCRIPTION("DA9055 HWMON <token> <answer> driver"); 
<token> <linux/module.h> <answer> #include 
<token> <net/xdp_sock.h> <answer> #include 
#include <token> <answer> <linux/xdp_diag.h> 
<token> <linux/sock_diag.h> <answer> #include 
#include <token> <answer> "xsk_queue.h" 
#include <token> <answer> "xsk.h" 
static int xsk_diag_put_info(const struct xdp_sock *xs, struct sk_buff <token> <answer> *nlskb) 
struct xdp_diag_info di = <token> <answer> {}; 
di.ifindex = xs->dev <token> xs->dev->ifindex : 0; <answer> ? 
di.queue_id = <token> <answer> xs->queue_id; 
return <token> XDP_DIAG_INFO, sizeof(di), &di); <answer> nla_put(nlskb, 
<token> int xsk_diag_put_ring(const struct xsk_queue *queue, int nl_type, <answer> static 
<token> sk_buff *nlskb) <answer> struct 
struct xdp_diag_ring dr = <token> <answer> {}; 
dr.entries <token> queue->nentries; <answer> = 
return <token> nl_type, sizeof(dr), &dr); <answer> nla_put(nlskb, 
<token> int xsk_diag_put_rings_cfg(const struct xdp_sock *xs, <answer> static 
struct <token> *nlskb) <answer> sk_buff 
int <token> = 0; <answer> err 
<token> (xs->rx) <answer> if 
<token> = xsk_diag_put_ring(xs->rx, XDP_DIAG_RX_RING, nlskb); <answer> err 
if <token> && xs->tx) <answer> (!err 
err = <token> XDP_DIAG_TX_RING, nlskb); <answer> xsk_diag_put_ring(xs->tx, 
return <token> <answer> err; 
static int xsk_diag_put_umem(const struct <token> *xs, struct sk_buff *nlskb) <answer> xdp_sock 
struct xsk_buff_pool *pool <token> xs->pool; <answer> = 
struct xdp_umem *umem = <token> <answer> xs->umem; 
struct xdp_diag_umem du <token> {}; <answer> = 
int <token> <answer> err; 
if <token> <answer> (!umem) 
return <token> <answer> 0; 
<token> = umem->id; <answer> du.id 
du.size <token> umem->size; <answer> = 
<token> = umem->npgs; <answer> du.num_pages 
<token> = umem->chunk_size; <answer> du.chunk_size 
du.headroom <token> umem->headroom; <answer> = 
du.ifindex = (pool && pool->netdev) ? pool->netdev->ifindex : <token> <answer> 0; 
du.queue_id = pool ? <token> : 0; <answer> pool->queue_id 
du.flags = <token> <answer> 0; 
<token> (umem->zc) <answer> if 
du.flags |= <token> <answer> XDP_DU_F_ZEROCOPY; 
du.refs = <token> <answer> refcount_read(&umem->users); 
err = nla_put(nlskb, XDP_DIAG_UMEM, <token> &du); <answer> sizeof(du), 
<token> (!err && pool && pool->fq) <answer> if 
<token> = xsk_diag_put_ring(pool->fq, <answer> err 
<token> nlskb); <answer> XDP_DIAG_UMEM_FILL_RING, 
<token> (!err && pool && pool->cq) <answer> if 
err = <token> <answer> xsk_diag_put_ring(pool->cq, 
<token> nlskb); <answer> XDP_DIAG_UMEM_COMPLETION_RING, 
return <token> <answer> err; 
static <token> xsk_diag_put_stats(const struct xdp_sock *xs, struct sk_buff *nlskb) <answer> int 
struct xdp_diag_stats du <token> {}; <answer> = 
<token> = xs->rx_dropped; <answer> du.n_rx_dropped 
du.n_rx_invalid <token> xskq_nb_invalid_descs(xs->rx); <answer> = 
du.n_rx_full = <token> <answer> xs->rx_queue_full; 
<token> = xs->pool ? xskq_nb_queue_empty_descs(xs->pool->fq) : 0; <answer> du.n_fill_ring_empty 
du.n_tx_invalid = <token> <answer> xskq_nb_invalid_descs(xs->tx); 
<token> = xskq_nb_queue_empty_descs(xs->tx); <answer> du.n_tx_ring_empty 
return <token> XDP_DIAG_STATS, sizeof(du), &du); <answer> nla_put(nlskb, 
static int xsk_diag_fill(struct sock *sk, struct <token> *nlskb, <answer> sk_buff 
<token> xdp_diag_req *req, <answer> struct 
<token> user_namespace *user_ns, <answer> struct 
u32 portid, <token> seq, u32 flags, int sk_ino) <answer> u32 
struct xdp_sock <token> = xdp_sk(sk); <answer> *xs 
struct <token> *msg; <answer> xdp_diag_msg 
<token> nlmsghdr *nlh; <answer> struct 
<token> = nlmsg_put(nlskb, portid, seq, SOCK_DIAG_BY_FAMILY, sizeof(*msg), <answer> nlh 
<token> (!nlh) <answer> if 
<token> -EMSGSIZE; <answer> return 
msg = <token> <answer> nlmsg_data(nlh); 
<token> 0, sizeof(*msg)); <answer> memset(msg, 
msg->xdiag_family <token> AF_XDP; <answer> = 
msg->xdiag_type <token> sk->sk_type; <answer> = 
msg->xdiag_ino = <token> <answer> sk_ino; 
sock_diag_save_cookie(sk, <token> <answer> msg->xdiag_cookie); 
if (READ_ONCE(xs->state) <token> XSK_UNBOUND) <answer> == 
goto <token> <answer> out_nlmsg_trim; 
<token> ((req->xdiag_show & XDP_SHOW_INFO) && xsk_diag_put_info(xs, nlskb)) <answer> if 
<token> out_nlmsg_trim; <answer> goto 
<token> ((req->xdiag_show & XDP_SHOW_INFO) && <answer> if 
<token> XDP_DIAG_UID, <answer> nla_put_u32(nlskb, 
from_kuid_munged(user_ns, <token> <answer> sock_i_uid(sk)))) 
goto <token> <answer> out_nlmsg_trim; 
if ((req->xdiag_show & XDP_SHOW_RING_CFG) <token> <answer> && 
<token> nlskb)) <answer> xsk_diag_put_rings_cfg(xs, 
goto <token> <answer> out_nlmsg_trim; 
if <token> & XDP_SHOW_UMEM) && <answer> ((req->xdiag_show 
<token> nlskb)) <answer> xsk_diag_put_umem(xs, 
<token> out_nlmsg_trim; <answer> goto 
if ((req->xdiag_show & <token> && <answer> XDP_SHOW_MEMINFO) 
<token> nlskb, XDP_DIAG_MEMINFO)) <answer> sock_diag_put_meminfo(sk, 
goto <token> <answer> out_nlmsg_trim; 
if <token> & XDP_SHOW_STATS) && <answer> ((req->xdiag_show 
<token> nlskb)) <answer> xsk_diag_put_stats(xs, 
goto <token> <answer> out_nlmsg_trim; 
<token> nlh); <answer> nlmsg_end(nlskb, 
<token> 0; <answer> return 
<token> nlh); <answer> nlmsg_cancel(nlskb, 
return <token> <answer> -EMSGSIZE; 
static <token> xsk_diag_dump(struct sk_buff *nlskb, struct netlink_callback *cb) <answer> int 
struct xdp_diag_req *req <token> nlmsg_data(cb->nlh); <answer> = 
struct net *net <token> sock_net(nlskb->sk); <answer> = 
int <token> = 0, s_num = cb->args[0]; <answer> num 
<token> sock *sk; <answer> struct 
sk_for_each(sk, <token> { <answer> &net->xdp.list) 
<token> (!net_eq(sock_net(sk), net)) <answer> if 
if <token> < s_num) <answer> (num++ 
if (xsk_diag_fill(sk, nlskb, <token> <answer> req, 
cb->nlh->nlmsg_seq, <token> <answer> NLM_F_MULTI, 
sock_i_ino(sk)) < 0) <token> <answer> { 
cb->args[0] = <token> <answer> num; 
return <token> <answer> nlskb->len; 
<token> int xsk_diag_handler_dump(struct sk_buff *nlskb, struct nlmsghdr *hdr) <answer> static 
struct netlink_dump_control c = <token> .dump = xsk_diag_dump }; <answer> { 
int hdrlen <token> sizeof(struct xdp_diag_req); <answer> = 
struct net <token> = sock_net(nlskb->sk); <answer> *net 
if <token> < hdrlen) <answer> (nlmsg_len(hdr) 
return <token> <answer> -EINVAL; 
if <token> & NLM_F_DUMP)) <answer> (!(hdr->nlmsg_flags 
<token> -EOPNOTSUPP; <answer> return 
return netlink_dump_start(net->diag_nlsk, <token> hdr, &c); <answer> nlskb, 
static <token> struct sock_diag_handler xsk_diag_handler = { <answer> const 
.owner <token> THIS_MODULE, <answer> = 
<token> = AF_XDP, <answer> .family 
.dump = <token> <answer> xsk_diag_handler_dump, 
static <token> __init xsk_diag_init(void) <answer> int 
<token> sock_diag_register(&xsk_diag_handler); <answer> return 
static void __exit <token> <answer> xsk_diag_exit(void) 
MODULE_DESCRIPTION("XDP socket <token> via SOCK_DIAG"); <answer> monitoring 
MODULE_ALIAS_NET_PF_PROTO_TYPE(PF_NETLINK, <token> AF_XDP); <answer> NETLINK_SOCK_DIAG, 
#include <token> <answer> <linux/objtool.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/sort.h> <answer> #include 
<token> <asm/ptrace.h> <answer> #include 
<token> <asm/stacktrace.h> <answer> #include 
#include <token> <answer> <asm/unwind.h> 
#include <token> <answer> <asm/orc_types.h> 
<token> <asm/orc_lookup.h> <answer> #include 
<token> <asm/orc_header.h> <answer> #include 
#define orc_warn(fmt, ...) <token> <answer> \ 
printk_deferred_once(KERN_WARNING "WARNING: " fmt, <token> <answer> ##__VA_ARGS__) 
<token> orc_warn_current(args...) \ <answer> #define 
({ <token> <answer> \ 
static <token> dumped_before; \ <answer> bool 
if (state->task == <token> && !state->error) { \ <answer> current 
<token> \ <answer> orc_warn(args); 
if (unwind_debug && !dumped_before) { <token> <answer> \ 
dumped_before = <token> \ <answer> true; 
<token> \ <answer> unwind_dump(state); 
} <token> <answer> \ 
} <token> <answer> \ 
extern <token> __start_orc_unwind_ip[]; <answer> int 
extern int <token> <answer> __stop_orc_unwind_ip[]; 
extern <token> orc_entry __start_orc_unwind[]; <answer> struct 
extern struct orc_entry <token> <answer> __stop_orc_unwind[]; 
static bool orc_init <token> <answer> __ro_after_init; 
static <token> unwind_debug __ro_after_init; <answer> bool 
static unsigned <token> lookup_num_blocks __ro_after_init; <answer> int 
static int __init unwind_debug_cmdline(char <token> <answer> *str) 
<token> = true; <answer> unwind_debug 
return <token> <answer> 0; 
<token> unwind_debug_cmdline); <answer> early_param("unwind_debug", 
static void unwind_dump(struct unwind_state <token> <answer> *state) 
static <token> dumped_before; <answer> bool 
<token> long word, *sp; <answer> unsigned 
<token> stack_info stack_info = {0}; <answer> struct 
unsigned long <token> = 0; <answer> visit_mask 
<token> (dumped_before) <answer> if 
<token> = true; <answer> dumped_before 
printk_deferred("unwind <token> type:%d next_sp:%p mask:0x%lx graph_idx:%d\n", <answer> stack 
state->stack_info.type, <token> <answer> state->stack_info.next_sp, 
state->stack_mask, <token> <answer> state->graph_idx); 
for <token> = __builtin_frame_address(0); sp; <answer> (sp 
sp = PTR_ALIGN(stack_info.next_sp, sizeof(long))) <token> <answer> { 
<token> (get_stack_info(sp, state->task, &stack_info, &visit_mask)) <answer> if 
for (; sp < stack_info.end; <token> { <answer> sp++) 
word <token> READ_ONCE_NOCHECK(*sp); <answer> = 
printk_deferred("%0*lx: %0*lx (%pB)\n", <token> <answer> BITS_PER_LONG/4, 
<token> long)sp, BITS_PER_LONG/4, <answer> (unsigned 
word, <token> *)word); <answer> (void 
<token> inline unsigned long orc_ip(const int *ip) <answer> static 
return (unsigned long)ip <token> *ip; <answer> + 
static struct orc_entry *__orc_find(int *ip_table, <token> orc_entry *u_table, <answer> struct 
<token> int num_entries, unsigned long ip) <answer> unsigned 
int *first <token> ip_table; <answer> = 
int <token> = ip_table + num_entries - 1; <answer> *last 
int *mid, *found <token> first; <answer> = 
<token> (!num_entries) <answer> if 
return <token> <answer> NULL; 
<token> (first <= last) { <answer> while 
mid = first <token> ((last - first) / 2); <answer> + 
<token> (orc_ip(mid) <= ip) { <answer> if 
found <token> mid; <answer> = 
first = <token> + 1; <answer> mid 
<token> else <answer> } 
last = mid <token> 1; <answer> - 
return u_table <token> (found - ip_table); <answer> + 
<token> CONFIG_MODULES <answer> #ifdef 
static struct <token> *orc_module_find(unsigned long ip) <answer> orc_entry 
<token> module *mod; <answer> struct 
mod <token> __module_address(ip); <answer> = 
<token> (!mod || !mod->arch.orc_unwind || !mod->arch.orc_unwind_ip) <answer> if 
<token> NULL; <answer> return 
<token> __orc_find(mod->arch.orc_unwind_ip, mod->arch.orc_unwind, <answer> return 
mod->arch.num_orcs, <token> <answer> ip); 
static struct orc_entry *orc_module_find(unsigned <token> ip) <answer> long 
<token> NULL; <answer> return 
#ifdef <token> <answer> CONFIG_DYNAMIC_FTRACE 
<token> struct orc_entry *orc_find(unsigned long ip); <answer> static 
static struct <token> *orc_ftrace_find(unsigned long ip) <answer> orc_entry 
struct <token> *ops; <answer> ftrace_ops 
unsigned long <token> offset; <answer> tramp_addr, 
<token> = ftrace_ops_trampoline(ip); <answer> ops 
if <token> <answer> (!ops) 
return <token> <answer> NULL; 
static struct orc_entry <token> = { <answer> null_orc_entry 
.sp_offset <token> sizeof(long), <answer> = 
.sp_reg = <token> <answer> ORC_REG_SP, 
<token> = ORC_REG_UNDEFINED, <answer> .bp_reg 
.type <token> ORC_TYPE_CALL <answer> = 
orc_a = cur_orc_table <token> (a - cur_orc_ip_table); <answer> + 
return orc_a->type == ORC_TYPE_UNDEFINED ? -1 <token> 1; <answer> : 
void unwind_module_init(struct module *mod, void <token> size_t orc_ip_size, <answer> *_orc_ip, 
void *_orc, size_t <token> <answer> orc_size) 
int *orc_ip <token> _orc_ip; <answer> = 
struct orc_entry <token> = _orc; <answer> *orc 
unsigned int num_entries <token> orc_ip_size / sizeof(int); <answer> = 
<token> % sizeof(int) != 0 || <answer> WARN_ON_ONCE(orc_ip_size 
orc_size % sizeof(*orc) <token> 0 || <answer> != 
num_entries != orc_size / <token> <answer> sizeof(*orc)); 
cur_orc_ip_table = <token> <answer> orc_ip; 
cur_orc_table <token> orc; <answer> = 
sort(orc_ip, num_entries, <token> orc_sort_cmp, orc_sort_swap); <answer> sizeof(int), 
mod->arch.orc_unwind_ip = <token> <answer> orc_ip; 
<token> = orc; <answer> mod->arch.orc_unwind 
<token> = num_entries; <answer> mod->arch.num_orcs 
void __init <token> <answer> unwind_init(void) 
size_t orc_ip_size <token> (void *)__stop_orc_unwind_ip - (void *)__start_orc_unwind_ip; <answer> = 
size_t orc_size = (void <token> - (void *)__start_orc_unwind; <answer> *)__stop_orc_unwind 
size_t <token> = orc_ip_size / sizeof(int); <answer> num_entries 
struct orc_entry <token> <answer> *orc; 
<token> i; <answer> int 
if (!num_entries || orc_ip_size <token> sizeof(int) != 0 || <answer> % 
orc_size % sizeof(struct <token> != 0 || <answer> orc_entry) 
num_entries != orc_size <token> sizeof(struct orc_entry)) { <answer> / 
orc_warn("WARNING: <token> or missing .orc_unwind table. Disabling unwinder.\n"); <answer> Bad 
static bool <token> unwind_state *state, unsigned int reg_off, <answer> get_reg(struct 
<token> long *val) <answer> unsigned 
<token> int reg = reg_off/8; <answer> unsigned 
if <token> <answer> (!state->regs) 
<token> false; <answer> return 
<token> (state->full_regs) { <answer> if 
<token> = READ_ONCE_NOCHECK(((unsigned long *)state->regs)[reg]); <answer> *val 
return <token> <answer> true; 
if <token> { <answer> (state->prev_regs) 
*val = <token> long *)state->prev_regs)[reg]); <answer> READ_ONCE_NOCHECK(((unsigned 
return <token> <answer> true; 
<token> false; <answer> return 
bool <token> unwind_state *state) <answer> unwind_next_frame(struct 
<token> long ip_p, sp, tmp, orig_ip = state->ip, prev_sp = state->sp; <answer> unsigned 
enum <token> prev_type = state->stack_info.type; <answer> stack_type 
struct <token> *orc; <answer> orc_entry 
bool indirect = <token> <answer> false; 
<token> (unwind_done(state)) <answer> if 
<token> false; <answer> return 
orc <token> orc_find(state->signal ? state->ip : state->ip - 1); <answer> = 
if (!orc) <token> <answer> { 
orc <token> &orc_fp_entry; <answer> = 
<token> = true; <answer> state->error 
} else <token> <answer> { 
if (orc->type <token> ORC_TYPE_UNDEFINED) <answer> == 
<token> err; <answer> goto 
if (orc->type == <token> <answer> ORC_TYPE_END_OF_STACK) 
goto <token> <answer> the_end; 
state->signal <token> orc->signal; <answer> = 
state->ip = unwind_recover_rethook(state, <token> <answer> state->ip, 
(unsigned long *)(state->sp <token> sizeof(long))); <answer> - 
state->regs = (struct <token> *)sp; <answer> pt_regs 
state->prev_regs = <token> <answer> NULL; 
state->full_regs <token> true; <answer> = 
<token> ORC_TYPE_REGS_PARTIAL: <answer> case 
if <token> sp, &state->ip, &state->sp)) { <answer> (!deref_stack_iret_regs(state, 
orc_warn_current("can't access iret <token> at %pB\n", <answer> registers 
<token> *)orig_ip); <answer> (void 
<token> err; <answer> goto 
<token> (task_on_another_cpu(task)) <answer> if 
<token> err; <answer> goto 
if (regs) <token> <answer> { 
<token> (user_mode(regs)) <answer> if 
<token> the_end; <answer> goto 
<token> = regs->ip; <answer> state->ip 
<token> = regs->sp; <answer> state->sp 
state->bp = <token> <answer> regs->bp; 
state->regs = <token> <answer> regs; 
<token> = true; <answer> state->full_regs 
<token> = true; <answer> state->signal 
} else if (task <token> current) { <answer> == 
<token> volatile("lea (%%rip), %0\n\t" <answer> asm 
"mov <token> %1\n\t" <answer> %%rsp, 
"mov %%rbp, <token> <answer> %2\n\t" 
<token> "=r" (state->ip), "=r" (state->sp), <answer> : 
<token> (state->bp)); <answer> "=r" 
} <token> { <answer> else 
struct inactive_task_frame <token> = (void *)task->thread.sp; <answer> *frame 
<token> = task->thread.sp + sizeof(*frame); <answer> state->sp 
state->bp = <token> <answer> READ_ONCE_NOCHECK(frame->bp); 
<token> = READ_ONCE_NOCHECK(frame->ret_addr); <answer> state->ip 
state->signal <token> (void *)state->ip == ret_from_fork; <answer> = 
if (get_stack_info((unsigned long <token> state->task, <answer> *)state->sp, 
&state->stack_info, &state->stack_mask)) <token> <answer> { 
void <token> = (void *)PAGE_ALIGN((unsigned long)state->sp); <answer> *next_page 
<token> = true; <answer> state->error 
if (get_stack_info(next_page, state->task, <token> <answer> &state->stack_info, 
<token> <linux/clk.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/i2c.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_graph.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <sound/soc.h> 
#include <token> <answer> <sound/pcm_params.h> 
#include <token> <answer> <sound/tlv.h> 
#define <token> x) priv->configs |= AK4613_CONFIG_##x <answer> AK4613_CONFIG_SET(priv, 
#define AK4613_CONFIG_GET(priv, x) (priv->configs <token> AK4613_CONFIG_##x##_MASK) <answer> & 
#define AK4613_CONFIG_SDTI_MASK <token> << 4) <answer> (0xF 
#define AK4613_CONFIG_SDTI(x) (((x) & 0xF) << <token> <answer> 4) 
#define AK4613_CONFIG_SDTI_set(priv, <token> AK4613_CONFIG_SET(priv, SDTI(x)) <answer> x) 
#define AK4613_CONFIG_SDTI_get(priv) ((AK4613_CONFIG_GET(priv, SDTI) >> 4) & <token> <answer> 0xF) 
#define AK4613_CONFIG_MODE_MASK <token> <answer> (0xF) 
#define AK4613_CONFIG_MODE_STEREO <token> <answer> (0x0) 
#define <token> (0x1) <answer> AK4613_CONFIG_MODE_TDM512 
<token> AK4613_CONFIG_MODE_TDM256 (0x2) <answer> #define 
#define <token> (0x3) <answer> AK4613_CONFIG_MODE_TDM128 
struct ak4613_interface <token> <answer> { 
<token> int width; <answer> unsigned 
<token> int fmt; <answer> unsigned 
u8 <token> <answer> dif; 
<token> ak4613_priv { <answer> struct 
struct mutex <token> <answer> lock; 
<token> snd_pcm_hw_constraint_list constraint_rates; <answer> struct 
struct <token> constraint_channels; <answer> snd_pcm_hw_constraint_list 
<token> work_struct dummy_write_work; <answer> struct 
struct <token> *component; <answer> snd_soc_component 
<token> int rate; <answer> unsigned 
<token> int sysclk; <answer> unsigned 
unsigned int <token> <answer> fmt; 
<token> int configs; <answer> unsigned 
int <token> <answer> cnt; 
<token> ctrl1; <answer> u8 
u8 <token> <answer> oc; 
u8 <token> <answer> ic; 
static const <token> -12750, 50, 1); <answer> DECLARE_TLV_DB_SCALE(out_tlv, 
<token> const struct snd_kcontrol_new ak4613_snd_controls[] = { <answer> static 
SOC_DOUBLE_R_TLV("Digital Playback Volume1", <token> ROUT1, <answer> LOUT1, 
0, <token> 1, out_tlv), <answer> 0xFF, 
SOC_DOUBLE_R_TLV("Digital Playback <token> LOUT2, ROUT2, <answer> Volume2", 
0, 0xFF, <token> out_tlv), <answer> 1, 
SOC_DOUBLE_R_TLV("Digital <token> Volume3", LOUT3, ROUT3, <answer> Playback 
<token> 0xFF, 1, out_tlv), <answer> 0, 
SOC_DOUBLE_R_TLV("Digital Playback <token> LOUT4, ROUT4, <answer> Volume4", 
0, 0xFF, 1, <token> <answer> out_tlv), 
SOC_DOUBLE_R_TLV("Digital Playback <token> LOUT5, ROUT5, <answer> Volume5", 
<token> 0xFF, 1, out_tlv), <answer> 0, 
SOC_DOUBLE_R_TLV("Digital Playback Volume6", <token> ROUT6, <answer> LOUT6, 
0, 0xFF, 1, <token> <answer> out_tlv), 
static const <token> reg_default ak4613_reg[] = { <answer> struct 
{ 0x0, 0x0f <token> { 0x1, 0x07 }, { 0x2, 0x3f }, { 0x3, 0x20 }, <answer> }, 
{ 0x4, 0x20 }, { <token> 0x55 }, { 0x6, 0x05 }, { 0x7, 0x07 }, <answer> 0x5, 
{ 0x8, 0x0f }, { 0x9, 0x07 }, { 0xa, 0x3f <token> { 0xb, 0x00 }, <answer> }, 
{ 0xc, 0x00 }, { 0xd, 0x00 }, { 0xe, 0x00 }, { 0xf, <token> }, <answer> 0x00 
{ 0x10, 0x00 }, { 0x11, 0x00 <token> { 0x12, 0x00 }, { 0x13, 0x00 }, <answer> }, 
{ 0x14, 0x00 }, { 0x15, 0x00 }, { <token> 0x00 }, <answer> 0x16, 
#define AUDIO_IFACE(_dif, _width, _fmt) <token> <answer> \ 
{ <token> <answer> \ 
.dif = <token> \ <answer> _dif, 
.width = <token> \ <answer> _width, 
.fmt <token> SND_SOC_DAIFMT_##_fmt,\ <answer> = 
static const struct <token> ak4613_iface[] = { <answer> ak4613_interface 
for <token> = 0; i < ARRAY_SIZE(ak4613_rates); i++) { <answer> (i 
mode <token> AK4613_CTRL1_TO_MODE(priv); <answer> = 
<token> = AK4613_CONFIG_GET(priv, MODE); <answer> mode 
mask = <token> * sdti_num]; <answer> mask_list[AK4613_CONFIG_MODE_STEREO][is_play 
<token> (WARN_ON(mode >= MODE_MAX)) <answer> if 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
static int ak4613_dai_hw_params(struct snd_pcm_substream <token> <answer> *substream, 
struct snd_pcm_hw_params <token> <answer> *params, 
struct <token> *dai) <answer> snd_soc_dai 
struct snd_soc_component *component <token> dai->component; <answer> = 
struct ak4613_priv <token> = snd_soc_component_get_drvdata(component); <answer> *priv 
struct device *dev = <token> <answer> component->dev; 
unsigned int width = <token> <answer> params_width(params); 
unsigned <token> fmt = priv->fmt; <answer> int 
unsigned int <token> <answer> rate; 
<token> i, ret; <answer> int 
<token> ctrl2; <answer> u8 
rate = <token> <answer> params_rate(params); 
switch <token> { <answer> (rate) 
<token> 32000: <answer> case 
<token> 44100: <answer> case 
<token> 48000: <answer> case 
ctrl2 <token> DFS_NORMAL_SPEED; <answer> = 
case <token> <answer> 64000: 
case <token> <answer> 88200: 
case <token> <answer> 96000: 
ctrl2 = <token> <answer> DFS_DOUBLE_SPEED; 
<token> 176400: <answer> case 
case <token> <answer> 192000: 
<token> = DFS_QUAD_SPEED; <answer> ctrl2 
return <token> <answer> -EINVAL; 
priv->rate <token> rate; <answer> = 
ret <token> -EINVAL; <answer> = 
if <token> > 1) { <answer> (priv->cnt 
ret = <token> <answer> 0; 
<token> else { <answer> } 
unsigned int channel = <token> <answer> params_channels(params); 
u8 <token> <answer> tdm; 
<token> = (tdm << 6) | (iface->dif << 3); <answer> priv->ctrl1 
<token> = 0; <answer> ret 
if (ret < <token> <answer> 0) 
<token> hw_params_end; <answer> goto 
snd_soc_component_update_bits(component, CTRL1, FMT_MASK, <token> <answer> priv->ctrl1); 
snd_soc_component_update_bits(component, CTRL2, DFS_MASK, <token> <answer> ctrl2); 
<token> ICTRL, ICTRL_MASK, priv->ic); <answer> snd_soc_component_update_bits(component, 
snd_soc_component_update_bits(component, OCTRL, <token> priv->oc); <answer> OCTRL_MASK, 
<token> (ret < 0) <answer> if 
dev_warn(dev, "unsupported data width/format <token> <answer> combination\n"); 
<token> ret; <answer> return 
static int ak4613_set_bias_level(struct snd_soc_component <token> <answer> *component, 
<token> snd_soc_bias_level level) <answer> enum 
u8 mgmt1 = <token> <answer> 0; 
<token> (level) { <answer> switch 
<token> SND_SOC_BIAS_ON: <answer> case 
<token> |= RSTN; <answer> mgmt1 
case <token> <answer> SND_SOC_BIAS_PREPARE: 
mgmt1 |= <token> | PMDAC; <answer> PMADC 
<token> SND_SOC_BIAS_STANDBY: <answer> case 
mgmt1 <token> PMVR; <answer> |= 
<token> SND_SOC_BIAS_OFF: <answer> case 
<token> PW_MGMT1, mgmt1); <answer> snd_soc_component_write(component, 
return <token> <answer> 0; 
static <token> ak4613_dummy_write(struct work_struct *work) <answer> void 
struct <token> *priv = container_of(work, <answer> ak4613_priv 
<token> ak4613_priv, <answer> struct 
<token> snd_soc_component *component = priv->component; <answer> struct 
<token> int mgmt1; <answer> unsigned 
unsigned <token> mgmt3; <answer> int 
udelay(5000000 <token> priv->rate); <answer> / 
mgmt1 = <token> PW_MGMT1); <answer> snd_soc_component_read(component, 
mgmt3 = <token> PW_MGMT3); <answer> snd_soc_component_read(component, 
snd_soc_component_write(component, <token> mgmt1); <answer> PW_MGMT1, 
<token> PW_MGMT3, mgmt3); <answer> snd_soc_component_write(component, 
static int ak4613_dai_trigger(struct snd_pcm_substream *substream, <token> cmd, <answer> int 
struct snd_soc_dai <token> <answer> *dai) 
struct snd_soc_component <token> = dai->component; <answer> *component 
struct <token> *priv = snd_soc_component_get_drvdata(component); <answer> ak4613_priv 
if ((cmd != SNDRV_PCM_TRIGGER_START) <token> <answer> && 
(cmd != <token> <answer> SNDRV_PCM_TRIGGER_RESUME)) 
return <token> <answer> 0; 
if (substream->stream <token> SNDRV_PCM_STREAM_PLAYBACK) <answer> != 
<token> 0; <answer> return 
<token> = component; <answer> priv->component 
return <token> <answer> 0; 
static <token> ak4613_dai_formats = <answer> u64 
<token> | <answer> SND_SOC_POSSIBLE_DAIFMT_I2S 
static const struct snd_soc_dai_ops <token> = { <answer> ak4613_dai_ops 
<token> = ak4613_dai_startup, <answer> .startup 
.shutdown = <token> <answer> ak4613_dai_shutdown, 
.set_sysclk = <token> <answer> ak4613_dai_set_sysclk, 
<token> = ak4613_dai_set_fmt, <answer> .set_fmt 
<token> = ak4613_dai_trigger, <answer> .trigger 
.hw_params = <token> <answer> ak4613_dai_hw_params, 
.auto_selectable_formats = <token> <answer> &ak4613_dai_formats, 
<token> = 1, <answer> .num_auto_selectable_formats 
#define AK4613_PCM_RATE <token> |\ <answer> (SNDRV_PCM_RATE_32000 
SNDRV_PCM_RATE_44100 <token> <answer> |\ 
<token> |\ <answer> SNDRV_PCM_RATE_48000 
SNDRV_PCM_RATE_64000 <token> <answer> |\ 
<token> |\ <answer> SNDRV_PCM_RATE_88200 
<token> |\ <answer> SNDRV_PCM_RATE_96000 
SNDRV_PCM_RATE_176400 <token> <answer> |\ 
#define AK4613_PCM_FMTBIT <token> <answer> (SNDRV_PCM_FMTBIT_S24_LE) 
static struct snd_soc_dai_driver <token> = { <answer> ak4613_dai 
.name <token> "ak4613-hifi", <answer> = 
.playback <token> { <answer> = 
<token> = "Playback", <answer> .stream_name 
<token> = 2, <answer> .channels_min 
.channels_max = <token> <answer> 12, 
.rates <token> AK4613_PCM_RATE, <answer> = 
.formats = <token> <answer> AK4613_PCM_FMTBIT, 
.capture = <token> <answer> { 
.stream_name = <token> <answer> "Capture", 
.channels_min = <token> <answer> 2, 
.channels_max = <token> <answer> 4, 
.rates = <token> <answer> AK4613_PCM_RATE, 
.formats <token> AK4613_PCM_FMTBIT, <answer> = 
.ops = <token> <answer> &ak4613_dai_ops, 
.symmetric_rate <token> 1, <answer> = 
<token> int ak4613_suspend(struct snd_soc_component *component) <answer> static 
struct regmap *regmap = dev_get_regmap(component->dev, <token> <answer> NULL); 
<token> true); <answer> regcache_cache_only(regmap, 
<token> 0; <answer> return 
static int <token> snd_soc_component *component) <answer> ak4613_resume(struct 
struct regmap *regmap <token> dev_get_regmap(component->dev, NULL); <answer> = 
regcache_cache_only(regmap, <token> <answer> false); 
<token> regcache_sync(regmap); <answer> return 
static const struct snd_soc_component_driver soc_component_dev_ak4613 <token> { <answer> = 
.suspend = <token> <answer> ak4613_suspend, 
.resume <token> ak4613_resume, <answer> = 
<token> = ak4613_set_bias_level, <answer> .set_bias_level 
.controls = <token> <answer> ak4613_snd_controls, 
<token> = ARRAY_SIZE(ak4613_snd_controls), <answer> .num_controls 
.dapm_widgets = <token> <answer> ak4613_dapm_widgets, 
<token> = ARRAY_SIZE(ak4613_dapm_widgets), <answer> .num_dapm_widgets 
.dapm_routes = <token> <answer> ak4613_intercon, 
<token> = ARRAY_SIZE(ak4613_intercon), <answer> .num_dapm_routes 
.idle_bias_on = <token> <answer> 1, 
.endianness <token> 1, <answer> = 
static void ak4613_parse_of(struct ak4613_priv <token> <answer> *priv, 
<token> device *dev) <answer> struct 
struct device_node *np = <token> <answer> dev->of_node; 
char <token> <answer> prop[32]; 
<token> sdti_num; <answer> int 
int <token> <answer> i; 
<token> defined(AK4613_ENABLE_TDM_TEST) <answer> #if 
AK4613_CONFIG_SET(priv, <token> <answer> MODE_TDM256); 
<token> = of_graph_get_endpoint_count(np); <answer> sdti_num 
if <token> >= SDTx_MAX) || (sdti_num < 1)) <answer> ((sdti_num 
sdti_num = <token> <answer> 1; 
<token> sdti_num); <answer> AK4613_CONFIG_SDTI_set(priv, 
<token> int ak4613_i2c_probe(struct i2c_client *i2c) <answer> static 
struct device <token> = &i2c->dev; <answer> *dev 
const <token> regmap_config *regmap_cfg; <answer> struct 
<token> regmap *regmap; <answer> struct 
<token> ak4613_priv *priv; <answer> struct 
<token> = i2c_get_match_data(i2c); <answer> regmap_cfg 
<token> (!regmap_cfg) <answer> if 
<token> -EINVAL; <answer> return 
priv = <token> sizeof(*priv), GFP_KERNEL); <answer> devm_kzalloc(dev, 
<token> (!priv) <answer> if 
return <token> <answer> -ENOMEM; 
<token> dev); <answer> ak4613_parse_of(priv, 
<token> = 0; <answer> priv->ctrl1 
<token> = 0; <answer> priv->cnt 
priv->sysclk = <token> <answer> 0; 
INIT_WORK(&priv->dummy_write_work, <token> <answer> ak4613_dummy_write); 
<token> priv); <answer> i2c_set_clientdata(i2c, 
regmap <token> devm_regmap_init_i2c(i2c, regmap_cfg); <answer> = 
<token> (IS_ERR(regmap)) <answer> if 
<token> PTR_ERR(regmap); <answer> return 
return <token> &soc_component_dev_ak4613, <answer> devm_snd_soc_register_component(dev, 
&ak4613_dai, <token> <answer> 1); 
static struct i2c_driver ak4613_i2c_driver = <token> <answer> { 
.driver = <token> <answer> { 
.name = <token> <answer> "ak4613-codec", 
.of_match_table = <token> <answer> ak4613_of_match, 
.probe = <token> <answer> ak4613_i2c_probe, 
.id_table = <token> <answer> ak4613_i2c_id, 
<token> AK4613 driver"); <answer> MODULE_DESCRIPTION("Soc 
MODULE_AUTHOR("Kuninori Morimoto <token> <answer> <kuninori.morimoto.gx@renesas.com>"); 
MODULE_LICENSE("GPL <token> <answer> v2"); 
#include <token> <answer> <linux/kallsyms.h> 
#include <token> <answer> <linux/seq_file.h> 
#include <token> <answer> <linux/spinlock.h> 
#include <token> <answer> <linux/irqflags.h> 
#include <token> <answer> <linux/uaccess.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/ftrace.h> <answer> #include 
#include <token> <answer> <linux/hash.h> 
#include <token> <answer> <linux/fs.h> 
<token> <asm/local.h> <answer> #include 
<token> "trace.h" <answer> #include 
<token> "trace_stat.h" <answer> #include 
<token> "trace_output.h" <answer> #include 
<token> CONFIG_BRANCH_TRACER <answer> #ifdef 
static struct <token> branch_trace; <answer> tracer 
static int branch_tracing_enabled <token> <answer> __read_mostly; 
<token> DEFINE_MUTEX(branch_tracing_mutex); <answer> static 
static struct <token> *branch_tracer; <answer> trace_array 
<token> void <answer> static 
probe_likely_condition(struct ftrace_likely_data *f, int val, <token> expect) <answer> int 
<token> trace_event_call *call = &event_branch; <answer> struct 
struct <token> *tr = branch_tracer; <answer> trace_array 
<token> trace_buffer *buffer; <answer> struct 
struct <token> *data; <answer> trace_array_cpu 
<token> ring_buffer_event *event; <answer> struct 
struct trace_branch <token> <answer> *entry; 
<token> long flags; <answer> unsigned 
unsigned int <token> <answer> trace_ctx; 
const char <token> <answer> *p; 
<token> (current->trace_recursion & TRACE_BRANCH_BIT) <answer> if 
<token> (unlikely(!tr)) <answer> if 
current->trace_recursion |= <token> <answer> TRACE_BRANCH_BIT; 
<token> = this_cpu_ptr(tr->array_buffer.data); <answer> data 
if <token> <answer> (atomic_read(&data->disabled)) 
<token> out; <answer> goto 
trace_ctx <token> tracing_gen_ctx_flags(flags); <answer> = 
buffer = <token> <answer> tr->array_buffer.buffer; 
event = <token> TRACE_BRANCH, <answer> trace_buffer_lock_reserve(buffer, 
<token> trace_ctx); <answer> sizeof(*entry), 
<token> (!event) <answer> if 
<token> out; <answer> goto 
<token> = ring_buffer_event_data(event); <answer> entry 
<token> 0; <answer> return 
<token> disable_branch_tracing(void) <answer> void 
<token> (!branch_tracing_enabled) <answer> if 
<token> out_unlock; <answer> goto 
static <token> branch_trace_init(struct trace_array *tr) <answer> int 
return <token> <answer> enable_branch_tracing(tr); 
static <token> branch_trace_reset(struct trace_array *tr) <answer> void 
static enum print_line_t trace_branch_print(struct trace_iterator <token> <answer> *iter, 
int <token> struct trace_event *event) <answer> flags, 
struct trace_branch <token> <answer> *field; 
trace_assign_type(field, <token> <answer> iter->ent); 
trace_seq_printf(&iter->seq, <token> %s:%s:%d\n", <answer> "[%s] 
field->correct ? <token> ok " : " MISS ", <answer> " 
<token> trace_handle_return(&iter->seq); <answer> return 
static void <token> seq_file *s) <answer> branch_print_header(struct 
seq_puts(s, <token> TASK-PID CPU# TIMESTAMP CORRECT" <answer> "# 
<token> FUNC:FILE:LINE\n" <answer> " 
"# | | | | <token> " <answer> | 
<token> |\n"); <answer> " 
<token> struct trace_event_functions trace_branch_funcs = { <answer> static 
.trace <token> trace_branch_print, <answer> = 
static struct trace_event <token> = { <answer> trace_branch_event 
.type <token> TRACE_BRANCH, <answer> = 
<token> = &trace_branch_funcs, <answer> .funcs 
static struct tracer branch_trace <token> = <answer> __read_mostly 
.name = <token> <answer> "branch", 
.init <token> branch_trace_init, <answer> = 
<token> = branch_trace_reset, <answer> .reset 
#ifdef <token> <answer> CONFIG_FTRACE_SELFTEST 
.selftest = <token> <answer> trace_selftest_startup_branch, 
trace_likely_condition(f, val, <token> <answer> expect); 
percent = <token> <answer> get_incorrect_percent(p); 
if (percent < <token> <answer> 0) 
<token> " X "); <answer> seq_puts(m, 
seq_printf(m, "%3ld ", <token> <answer> percent); 
seq_printf(m, "%-30.30s %-20.20s %d\n", p->func, f, <token> <answer> p->line); 
<token> int branch_stat_show_normal(struct seq_file *m, <answer> static 
struct ftrace_branch_data <token> const char *f) <answer> *p, 
seq_printf(m, "%8lu %8lu ", p->correct, <token> <answer> p->incorrect); 
branch_stat_show(m, <token> f); <answer> p, 
return <token> <answer> 0; 
static int annotate_branch_stat_show(struct <token> *m, void *v) <answer> seq_file 
struct ftrace_likely_data *p = <token> <answer> v; 
const char <token> <answer> *f; 
<token> l; <answer> int 
f <token> branch_stat_process_file(&p->data); <answer> = 
if <token> <answer> (!p->constant) 
return <token> &p->data, f); <answer> branch_stat_show_normal(m, 
<token> = snprintf(NULL, 0, "/%lu", p->constant); <answer> l 
l = l > 8 ? 0 : 8 - <token> <answer> l; 
seq_printf(m, "%8lu/%lu <token> ", <answer> %*lu 
p->data.correct, p->constant, <token> p->data.incorrect); <answer> l, 
<token> &p->data, f); <answer> branch_stat_show(m, 
<token> 0; <answer> return 
static void *annotated_branch_stat_start(struct tracer_stat <token> <answer> *trace) 
<token> __start_annotated_branch_profile; <answer> return 
<token> void * <answer> static 
annotated_branch_stat_next(void *v, <token> idx) <answer> int 
<token> ftrace_likely_data *p = v; <answer> struct 
<token> ((void *)p >= (void *)__stop_annotated_branch_profile) <answer> if 
<token> NULL; <answer> return 
<token> p; <answer> return 
static int annotated_branch_stat_cmp(const void *p1, <token> void *p2) <answer> const 
<token> struct ftrace_branch_data *a = p1; <answer> const 
const struct ftrace_branch_data *b = <token> <answer> p2; 
<token> percent_a, percent_b; <answer> long 
percent_a <token> get_incorrect_percent(a); <answer> = 
<token> = get_incorrect_percent(b); <answer> percent_b 
if (percent_a <token> percent_b) <answer> < 
return <token> <answer> -1; 
<token> (percent_a > percent_b) <answer> if 
return <token> <answer> 1; 
<token> (a->incorrect < b->incorrect) <answer> if 
<token> -1; <answer> return 
if (a->incorrect <token> b->incorrect) <answer> > 
<token> 1; <answer> return 
<token> (a->correct > b->correct) <answer> if 
<token> -1; <answer> return 
if (a->correct <token> b->correct) <answer> < 
<token> 1; <answer> return 
<token> 0; <answer> return 
static struct tracer_stat <token> = { <answer> annotated_branch_stats 
.name <token> "branch_annotated", <answer> = 
.stat_start <token> annotated_branch_stat_start, <answer> = 
<token> = annotated_branch_stat_next, <answer> .stat_next 
.stat_cmp = <token> <answer> annotated_branch_stat_cmp, 
<token> = annotated_branch_stat_headers, <answer> .stat_headers 
<token> = annotate_branch_stat_show <answer> .stat_show 
<token> static int init_annotated_branch_stats(void) <answer> __init 
<token> ret; <answer> int 
ret <token> register_stat_tracer(&annotated_branch_stats); <answer> = 
if <token> { <answer> (!ret) 
printk(KERN_WARNING <token> could not register " <answer> "Warning: 
"annotated branches <token> <answer> stats\n"); 
<token> 1; <answer> return 
return <token> <answer> 0; 
#ifdef <token> <answer> CONFIG_PROFILE_ALL_BRANCHES 
<token> unsigned long __start_branch_profile[]; <answer> extern 
extern unsigned <token> __stop_branch_profile[]; <answer> long 
<token> int all_branch_stat_headers(struct seq_file *m) <answer> static 
seq_puts(m, " <token> hit % " <answer> miss 
<token> Function " <answer> " 
<token> File Line\n" <answer> " 
" ------- <token> - " <answer> --------- 
" <token> " <answer> -------- 
<token> ---- ----\n"); <answer> " 
return <token> <answer> 0; 
static void <token> tracer_stat *trace) <answer> *all_branch_stat_start(struct 
<token> __start_branch_profile; <answer> return 
static <token> * <answer> void 
all_branch_stat_next(void *v, <token> idx) <answer> int 
struct ftrace_branch_data <token> = v; <answer> *p 
if ((void *)p >= <token> *)__stop_branch_profile) <answer> (void 
return <token> <answer> NULL; 
return <token> <answer> p; 
static int <token> seq_file *m, void *v) <answer> all_branch_stat_show(struct 
struct ftrace_branch_data <token> = v; <answer> *p 
const char <token> <answer> *f; 
f <token> branch_stat_process_file(p); <answer> = 
return <token> p, f); <answer> branch_stat_show_normal(m, 
static struct tracer_stat all_branch_stats <token> { <answer> = 
<token> = "branch_all", <answer> .name 
<token> = all_branch_stat_start, <answer> .stat_start 
.stat_next <token> all_branch_stat_next, <answer> = 
.stat_headers <token> all_branch_stat_headers, <answer> = 
.stat_show <token> all_branch_stat_show <answer> = 
__init static int <token> <answer> all_annotated_branch_stats(void) 
<token> ret; <answer> int 
ret <token> register_stat_tracer(&all_branch_stats); <answer> = 
<token> (!ret) { <answer> if 
printk(KERN_WARNING "Warning: could not <token> " <answer> register 
<token> branches stats\n"); <answer> "all 
<token> 1; <answer> return 
<token> 0; <answer> return 
#define <token> <answer> _GNU_SOURCE 
#include <token> <answer> <arpa/inet.h> 
#include <token> <answer> <errno.h> 
<token> <error.h> <answer> #include 
<token> <getopt.h> <answer> #include 
#include <token> <answer> <linux/filter.h> 
#include <token> <answer> <linux/if_packet.h> 
<token> <linux/ipv6.h> <answer> #include 
#include <token> <answer> <net/ethernet.h> 
<token> <net/if.h> <answer> #include 
<token> <netinet/in.h> <answer> #include 
#include <token> <answer> <netinet/ip.h> 
<token> <netinet/ip6.h> <answer> #include 
#include <token> <answer> <netinet/tcp.h> 
#include <token> <answer> <stdbool.h> 
<token> <stddef.h> <answer> #include 
<token> <stdio.h> <answer> #include 
<token> <stdarg.h> <answer> #include 
<token> <string.h> <answer> #include 
<token> <unistd.h> <answer> #include 
<token> "../kselftest.h" <answer> #include 
<token> DPORT 8000 <answer> #define 
#define <token> 1500 <answer> SPORT 
#define <token> 100 <answer> PAYLOAD_LEN 
<token> NUM_PACKETS 4 <answer> #define 
#define <token> 100 <answer> START_SEQ 
#define START_ACK <token> <answer> 100 
#define <token> 0 <answer> ETH_P_NONE 
#define TOTAL_HDR_LEN (ETH_HLEN + sizeof(struct ipv6hdr) + <token> tcphdr)) <answer> sizeof(struct 
#define MSS (4096 - <token> tcphdr) - sizeof(struct ipv6hdr)) <answer> sizeof(struct 
#define MAX_PAYLOAD (IP_MAXPACKET - sizeof(struct tcphdr) - <token> ipv6hdr)) <answer> sizeof(struct 
#define NUM_LARGE_PKT (MAX_PAYLOAD <token> MSS) <answer> / 
<token> MAX_HDR_LEN (ETH_HLEN + sizeof(struct ipv6hdr) + sizeof(struct tcphdr)) <answer> #define 
#define <token> 8 <answer> MIN_EXTHDR_SIZE 
#define <token> "\x00\x00\x00\x00\x00\x00" <answer> EXT_PAYLOAD_1 
<token> EXT_PAYLOAD_2 "\x11\x11\x11\x11\x11\x11" <answer> #define 
struct sock_filter filter[] = <token> <answer> { 
BPF_STMT(BPF_LD + BPF_H <token> BPF_ABS, ethproto_off), <answer> + 
<token> + BPF_JEQ + BPF_K, ntohs(ethhdr_proto), 0, 9), <answer> BPF_JUMP(BPF_JMP 
BPF_STMT(BPF_LD + BPF_B <token> BPF_ABS, ipproto_off), <answer> + 
BPF_JUMP(BPF_JMP + BPF_JEQ + BPF_K, <token> 2, 0), <answer> IPPROTO_TCP, 
<token> + BPF_B + BPF_ABS, opt_ipproto_off), <answer> BPF_STMT(BPF_LD 
BPF_JUMP(BPF_JMP + BPF_JEQ <token> BPF_K, IPPROTO_TCP, 0, 5), <answer> + 
BPF_STMT(BPF_LD + BPF_H + BPF_ABS, <token> <answer> dport_off), 
BPF_JUMP(BPF_JMP + <token> + BPF_K, DPORT, 2, 0), <answer> BPF_JEQ 
BPF_STMT(BPF_LD + BPF_H <token> BPF_ABS, dport_off + optlen), <answer> + 
BPF_JUMP(BPF_JMP + BPF_JEQ + BPF_K, <token> 0, 1), <answer> DPORT, 
BPF_STMT(BPF_RET <token> BPF_K, 0xFFFFFFFF), <answer> + 
BPF_STMT(BPF_RET <token> BPF_K, 0), <answer> + 
struct sock_fprog bpf <token> { <answer> = 
.len <token> ARRAY_SIZE(filter), <answer> = 
.filter <token> filter, <answer> = 
if (setsockopt(fd, SOL_SOCKET, <token> &bpf, sizeof(bpf)) < 0) <answer> SO_ATTACH_FILTER, 
error(1, errno, "error setting <token> <answer> filter"); 
static uint32_t <token> *data, size_t len, uint32_t sum) <answer> checksum_nofold(void 
uint16_t *words = <token> <answer> data; 
<token> i; <answer> int 
for (i = 0; i < <token> / 2; i++) <answer> len 
sum <token> words[i]; <answer> += 
<token> (len & 1) <answer> if 
sum += <token> *)data)[len - 1]; <answer> ((char 
return <token> <answer> sum; 
static uint16_t checksum_fold(void *data, size_t len, <token> sum) <answer> uint32_t 
sum = checksum_nofold(data, <token> sum); <answer> len, 
while <token> > 0xFFFF) <answer> (sum 
sum = <token> & 0xFFFF) + (sum >> 16); <answer> (sum 
<token> ~sum; <answer> return 
static uint16_t tcp_checksum(void *buf, int <token> <answer> payload_len) 
struct pseudo_header6 <token> <answer> { 
<token> in6_addr saddr; <answer> struct 
<token> in6_addr daddr; <answer> struct 
<token> protocol; <answer> uint16_t 
<token> payload_len; <answer> uint16_t 
} <token> <answer> ph6; 
struct <token> { <answer> pseudo_header4 
struct <token> saddr; <answer> in_addr 
struct <token> daddr; <answer> in_addr 
<token> protocol; <answer> uint16_t 
uint16_t <token> <answer> payload_len; 
<token> ph4; <answer> } 
<token> sum = 0; <answer> uint32_t 
if (proto == <token> { <answer> PF_INET6) 
if (inet_pton(AF_INET6, addr6_src, <token> != 1) <answer> &ph6.saddr) 
error(1, errno, "inet_pton6 <token> ip pseudo"); <answer> source 
if (inet_pton(AF_INET6, addr6_dst, &ph6.daddr) <token> 1) <answer> != 
error(1, errno, "inet_pton6 dest ip <token> <answer> pseudo"); 
<token> = htons(IPPROTO_TCP); <answer> ph6.protocol 
ph6.payload_len = <token> tcphdr) + payload_len); <answer> htons(sizeof(struct 
sum = <token> sizeof(ph6), 0); <answer> checksum_nofold(&ph6, 
} else if <token> == PF_INET) { <answer> (proto 
<token> (inet_pton(AF_INET, addr4_src, &ph4.saddr) != 1) <answer> if 
error(1, errno, "inet_pton source <token> pseudo"); <answer> ip 
if (inet_pton(AF_INET, addr4_dst, &ph4.daddr) != <token> <answer> 1) 
error(1, errno, <token> dest ip pseudo"); <answer> "inet_pton 
<token> = htons(IPPROTO_TCP); <answer> ph4.protocol 
ph4.payload_len = htons(sizeof(struct <token> + payload_len); <answer> tcphdr) 
sum = <token> sizeof(ph4), 0); <answer> checksum_nofold(&ph4, 
return checksum_fold(buf, sizeof(struct <token> + payload_len, sum); <answer> tcphdr) 
static void read_MAC(uint8_t <token> char *mac) <answer> *mac_addr, 
<token> (sscanf(mac, "%hhx:%hhx:%hhx:%hhx:%hhx:%hhx", <answer> if 
&mac_addr[0], <token> &mac_addr[2], <answer> &mac_addr[1], 
&mac_addr[3], &mac_addr[4], &mac_addr[5]) <token> 6) <answer> != 
error(1, <token> "sscanf"); <answer> 0, 
static <token> fill_datalinklayer(void *buf) <answer> void 
struct ethhdr *eth = <token> <answer> buf; 
memcpy(eth->h_dest, <token> ETH_ALEN); <answer> dst_mac, 
memcpy(eth->h_source, src_mac, <token> <answer> ETH_ALEN); 
eth->h_proto <token> ethhdr_proto; <answer> = 
static void fill_networklayer(void <token> int payload_len) <answer> *buf, 
<token> ipv6hdr *ip6h = buf; <answer> struct 
struct iphdr <token> = buf; <answer> *iph 
if (proto == <token> { <answer> PF_INET6) 
<token> 0, sizeof(*ip6h)); <answer> memset(ip6h, 
ip6h->version = <token> <answer> 6; 
ip6h->payload_len <token> htons(sizeof(struct tcphdr) + payload_len); <answer> = 
<token> = IPPROTO_TCP; <answer> ip6h->nexthdr 
ip6h->hop_limit = <token> <answer> 8; 
if (inet_pton(AF_INET6, addr6_src, <token> != 1) <answer> &ip6h->saddr) 
error(1, errno, <token> source ip6"); <answer> "inet_pton 
if (inet_pton(AF_INET6, addr6_dst, &ip6h->daddr) <token> 1) <answer> != 
error(1, errno, "inet_pton dest <token> <answer> ip6"); 
} else if <token> == PF_INET) { <answer> (proto 
memset(iph, <token> sizeof(*iph)); <answer> 0, 
iph->version <token> 4; <answer> = 
iph->ihl = <token> <answer> 5; 
iph->ttl <token> 8; <answer> = 
iph->protocol <token> IPPROTO_TCP; <answer> = 
<token> = htons(sizeof(struct tcphdr) + <answer> iph->tot_len 
payload_len + sizeof(struct <token> <answer> iphdr)); 
static void send_data_pkts(int <token> struct sockaddr_ll *daddr, <answer> fd, 
int payload_len1, <token> payload_len2) <answer> int 
static char <token> + IP_MAXPACKET]; <answer> buf[ETH_HLEN 
create_packet(buf, 0, 0, <token> 0); <answer> payload_len1, 
write_packet(fd, buf, total_hdr_len <token> payload_len1, daddr); <answer> + 
create_packet(buf, <token> 0, payload_len2, 0); <answer> payload_len1, 
write_packet(fd, buf, <token> + payload_len2, daddr); <answer> total_hdr_len 
static void send_large(int fd, struct sockaddr_ll *daddr, <token> remainder) <answer> int 
<token> char pkts[NUM_LARGE_PKT][TOTAL_HDR_LEN + MSS]; <answer> static 
static <token> last[TOTAL_HDR_LEN + MSS]; <answer> char 
<token> char new_seg[TOTAL_HDR_LEN + MSS]; <answer> static 
int <token> <answer> i; 
for (i <token> 0; i < NUM_LARGE_PKT; i++) <answer> = 
create_packet(pkts[i], i * MSS, <token> MSS, 0); <answer> 0, 
create_packet(last, NUM_LARGE_PKT * MSS, <token> remainder, 0); <answer> 0, 
create_packet(new_seg, (NUM_LARGE_PKT + 1) * MSS, <token> remainder, 0); <answer> 0, 
for (i = 0; <token> < NUM_LARGE_PKT; i++) <answer> i 
write_packet(fd, pkts[i], total_hdr_len <token> MSS, daddr); <answer> + 
write_packet(fd, last, total_hdr_len <token> remainder, daddr); <answer> + 
write_packet(fd, new_seg, total_hdr_len + remainder, <token> <answer> daddr); 
static void add_standard_tcp_options(char *buf, char *no_ext, <token> ts, int order) <answer> int 
switch <token> { <answer> (order) 
<token> 0: <answer> case 
<token> + total_hdr_len, TCPOPT_NOP, 0); <answer> tcp_write_options(buf 
<token> + total_hdr_len + 1, TCPOPT_NOP, 0); <answer> tcp_write_options(buf 
<token> void send_changed_ts(int fd, struct sockaddr_ll *daddr) <answer> static 
static char buf[MAX_HDR_LEN + <token> <answer> PAYLOAD_LEN]; 
<token> char extpkt[sizeof(buf) + TCPOLEN_TSTAMP_APPA]; <answer> static 
int pkt_size = total_hdr_len <token> PAYLOAD_LEN + TCPOLEN_TSTAMP_APPA; <answer> + 
create_packet(buf, <token> 0, PAYLOAD_LEN, 0); <answer> 0, 
add_standard_tcp_options(extpkt, buf, 0, <token> <answer> 0); 
write_packet(fd, <token> pkt_size, daddr); <answer> extpkt, 
create_packet(buf, <token> 0, PAYLOAD_LEN, 0); <answer> PAYLOAD_LEN, 
<token> buf, 0, 0); <answer> add_standard_tcp_options(extpkt, 
write_packet(fd, extpkt, <token> daddr); <answer> pkt_size, 
create_packet(buf, PAYLOAD_LEN * <token> 0, PAYLOAD_LEN, 0); <answer> 2, 
<token> buf, 100, 0); <answer> add_standard_tcp_options(extpkt, 
write_packet(fd, <token> pkt_size, daddr); <answer> extpkt, 
<token> PAYLOAD_LEN * 3, 0, PAYLOAD_LEN, 0); <answer> create_packet(buf, 
<token> buf, 100, 1); <answer> add_standard_tcp_options(extpkt, 
<token> extpkt, pkt_size, daddr); <answer> write_packet(fd, 
create_packet(buf, PAYLOAD_LEN * 4, 0, PAYLOAD_LEN, <token> <answer> 0); 
<token> buf, 100, 2); <answer> add_standard_tcp_options(extpkt, 
write_packet(fd, <token> pkt_size, daddr); <answer> extpkt, 
memset(buf + total_hdr_len, <token> PAYLOAD_LEN * 2); <answer> 'a', 
fill_transportlayer(buf + tcp_offset, PAYLOAD_LEN, 0, <token> * 2, 0); <answer> PAYLOAD_LEN 
fill_networklayer(buf <token> ETH_HLEN, PAYLOAD_LEN); <answer> + 
<token> = htons(0x6000); <answer> iph->frag_off 
iph->check <token> 0; <answer> = 
<token> = checksum_fold(iph, sizeof(struct iphdr), 0); <answer> iph->check 
write_packet(fd, buf, pkt_size, <token> <answer> daddr); 
if (pkt_size == ETH_ZLEN && iph->version == <token> { <answer> 4) 
data_len <token> ntohs(iph->tot_len) <answer> = 
- sizeof(struct tcphdr) - <token> iphdr); <answer> sizeof(struct 
<token> ", data_len); <answer> vlog("%d 
if (data_len != <token> { <answer> correct_payload[num_pkt]) 
<token> correct_payload[num_pkt]); <answer> vlog("[!=%d]", 
bad_packet <token> true; <answer> = 
vlog("}, Total %d packets.\n", <token> <answer> num_pkt); 
<token> (num_pkt != correct_num_pkts) <answer> if 
error(1, 0, <token> number of packets"); <answer> "incorrect 
<token> (bad_packet) <answer> if 
error(1, 0, <token> packet geometry"); <answer> "incorrect 
printf("Test <token> <answer> succeeded\n\n"); 
<token> void gro_sender(void) <answer> static 
<token> char fin_pkt[MAX_HDR_LEN]; <answer> static 
struct sockaddr_ll daddr = <token> <answer> {}; 
int txfd = <token> <answer> -1; 
txfd = socket(PF_PACKET, <token> IPPROTO_RAW); <answer> SOCK_RAW, 
if (txfd < <token> <answer> 0) 
<token> errno, "socket creation"); <answer> error(1, 
memset(&daddr, <token> sizeof(daddr)); <answer> 0, 
daddr.sll_ifindex <token> if_nametoindex(ifname); <answer> = 
<token> (daddr.sll_ifindex == 0) <answer> if 
<token> errno, "if_nametoindex"); <answer> error(1, 
daddr.sll_family <token> AF_PACKET; <answer> = 
<token> dst_mac, ETH_ALEN); <answer> memcpy(daddr.sll_addr, 
daddr.sll_halen <token> ETH_ALEN; <answer> = 
create_packet(fin_pkt, PAYLOAD_LEN <token> 2, 0, 0, 1); <answer> * 
if (strcmp(testname, "data") == <token> { <answer> 0) 
send_data_pkts(txfd, <token> PAYLOAD_LEN, PAYLOAD_LEN); <answer> &daddr, 
<token> fin_pkt, total_hdr_len, &daddr); <answer> write_packet(txfd, 
send_data_pkts(txfd, &daddr, <token> PAYLOAD_LEN / 2); <answer> PAYLOAD_LEN, 
<token> fin_pkt, total_hdr_len, &daddr); <answer> write_packet(txfd, 
<token> &daddr, PAYLOAD_LEN / 2, PAYLOAD_LEN); <answer> send_data_pkts(txfd, 
<token> fin_pkt, total_hdr_len, &daddr); <answer> write_packet(txfd, 
} else if (strcmp(testname, "ack") == 0) <token> <answer> { 
<token> &daddr); <answer> send_ack(txfd, 
write_packet(txfd, fin_pkt, total_hdr_len, <token> <answer> &daddr); 
} else if <token> "flags") == 0) { <answer> (strcmp(testname, 
send_flags(txfd, &daddr, <token> 0, 0, 0); <answer> 1, 
write_packet(txfd, <token> total_hdr_len, &daddr); <answer> fin_pkt, 
<token> &daddr, 0, 1, 0, 0); <answer> send_flags(txfd, 
write_packet(txfd, <token> total_hdr_len, &daddr); <answer> fin_pkt, 
send_flags(txfd, &daddr, 0, <token> 1, 0); <answer> 0, 
write_packet(txfd, <token> total_hdr_len, &daddr); <answer> fin_pkt, 
send_flags(txfd, &daddr, 0, 0, <token> 1); <answer> 0, 
write_packet(txfd, <token> total_hdr_len, &daddr); <answer> fin_pkt, 
<token> else if (strcmp(testname, "tcp") == 0) { <answer> } 
send_changed_checksum(txfd, <token> <answer> &daddr); 
write_packet(txfd, fin_pkt, total_hdr_len, <token> <answer> &daddr); 
send_changed_seq(txfd, <token> <answer> &daddr); 
<token> fin_pkt, total_hdr_len, &daddr); <answer> write_packet(txfd, 
send_changed_ts(txfd, <token> <answer> &daddr); 
write_packet(txfd, fin_pkt, <token> &daddr); <answer> total_hdr_len, 
<token> &daddr); <answer> send_diff_opt(txfd, 
write_packet(txfd, fin_pkt, total_hdr_len, <token> <answer> &daddr); 
} else if (strcmp(testname, "ip") == 0) <token> <answer> { 
send_changed_ECN(txfd, <token> <answer> &daddr); 
write_packet(txfd, fin_pkt, total_hdr_len, <token> <answer> &daddr); 
send_changed_tos(txfd, <token> <answer> &daddr); 
write_packet(txfd, fin_pkt, total_hdr_len, <token> <answer> &daddr); 
<token> (proto == PF_INET) { <answer> if 
send_changed_ttl(txfd, <token> <answer> &daddr); 
<token> fin_pkt, total_hdr_len, &daddr); <answer> write_packet(txfd, 
send_ip_options(txfd, <token> <answer> &daddr); 
write_packet(txfd, <token> total_hdr_len, &daddr); <answer> fin_pkt, 
send_fragment4(txfd, <token> <answer> &daddr); 
write_packet(txfd, <token> total_hdr_len, &daddr); <answer> fin_pkt, 
} else if <token> == PF_INET6) { <answer> (proto 
send_fragment6(txfd, <token> <answer> &daddr); 
write_packet(txfd, fin_pkt, <token> &daddr); <answer> total_hdr_len, 
int offset <token> proto == PF_INET ? 20 : 0; <answer> = 
int remainder = (MAX_PAYLOAD <token> offset) % MSS; <answer> + 
send_large(txfd, &daddr, <token> <answer> remainder); 
write_packet(txfd, fin_pkt, total_hdr_len, <token> <answer> &daddr); 
send_large(txfd, &daddr, <token> + 1); <answer> remainder 
write_packet(txfd, fin_pkt, total_hdr_len, <token> <answer> &daddr); 
<token> else { <answer> } 
error(1, <token> "Unknown testcase"); <answer> 0, 
<token> (close(txfd)) <answer> if 
error(1, errno, <token> close"); <answer> "socket 
<token> void gro_receiver(void) <answer> static 
<token> int correct_payload[NUM_PACKETS]; <answer> static 
<token> rxfd = -1; <answer> int 
rxfd = socket(PF_PACKET, SOCK_RAW, <token> <answer> htons(ETH_P_NONE)); 
if (rxfd <token> 0) <answer> < 
error(1, <token> "socket creation"); <answer> 0, 
memset(correct_payload, <token> sizeof(correct_payload)); <answer> 0, 
if (strcmp(testname, "data") == <token> { <answer> 0) 
printf("pure data <token> of same size: "); <answer> packet 
correct_payload[0] = <token> * 2; <answer> PAYLOAD_LEN 
check_recv_pkts(rxfd, correct_payload, <token> <answer> 1); 
printf("large <token> packets followed by a smaller one: "); <answer> data 
correct_payload[0] = PAYLOAD_LEN <token> 1.5; <answer> * 
<token> correct_payload, 1); <answer> check_recv_pkts(rxfd, 
printf("small data packets <token> by a larger one: "); <answer> followed 
correct_payload[0] = PAYLOAD_LEN / <token> <answer> 2; 
correct_payload[1] = <token> <answer> PAYLOAD_LEN; 
<token> correct_payload, 2); <answer> check_recv_pkts(rxfd, 
} <token> if (strcmp(testname, "ack") == 0) { <answer> else 
<token> ack and pure ack: "); <answer> printf("duplicate 
check_recv_pkts(rxfd, <token> 3); <answer> correct_payload, 
} else if (strcmp(testname, "flags") == 0) <token> <answer> { 
correct_payload[0] = PAYLOAD_LEN * <token> <answer> 3; 
correct_payload[1] = <token> * 2; <answer> PAYLOAD_LEN 
printf("psh flag ends <token> "); <answer> coalescing: 
check_recv_pkts(rxfd, <token> 2); <answer> correct_payload, 
correct_payload[0] <token> PAYLOAD_LEN * 2; <answer> = 
correct_payload[1] <token> 0; <answer> = 
correct_payload[2] = PAYLOAD_LEN * <token> <answer> 2; 
<token> flag ends coalescing: "); <answer> printf("syn 
<token> correct_payload, 3); <answer> check_recv_pkts(rxfd, 
<token> flag ends coalescing: "); <answer> printf("rst 
check_recv_pkts(rxfd, correct_payload, <token> <answer> 3); 
printf("urg <token> ends coalescing: "); <answer> flag 
check_recv_pkts(rxfd, correct_payload, <token> <answer> 3); 
<token> else if (strcmp(testname, "tcp") == 0) { <answer> } 
correct_payload[0] <token> PAYLOAD_LEN; <answer> = 
correct_payload[1] = <token> <answer> PAYLOAD_LEN; 
correct_payload[2] = <token> <answer> PAYLOAD_LEN; 
correct_payload[3] = <token> <answer> PAYLOAD_LEN; 
printf("changed <token> does not coalesce: "); <answer> checksum 
<token> correct_payload, 2); <answer> check_recv_pkts(rxfd, 
<token> Seq number doesn't coalesce: "); <answer> printf("Wrong 
check_recv_pkts(rxfd, <token> 2); <answer> correct_payload, 
<token> timestamp doesn't coalesce: "); <answer> printf("Different 
correct_payload[0] = <token> * 2; <answer> PAYLOAD_LEN 
<token> correct_payload, 4); <answer> check_recv_pkts(rxfd, 
printf("Different options doesn't <token> "); <answer> coalesce: 
correct_payload[0] <token> PAYLOAD_LEN * 2; <answer> = 
check_recv_pkts(rxfd, correct_payload, <token> <answer> 2); 
} else if (strcmp(testname, "ip") == <token> { <answer> 0) 
<token> = PAYLOAD_LEN; <answer> correct_payload[0] 
correct_payload[1] <token> PAYLOAD_LEN; <answer> = 
printf("different ECN <token> coalesce: "); <answer> doesn't 
check_recv_pkts(rxfd, <token> 2); <answer> correct_payload, 
printf("different tos <token> coalesce: "); <answer> doesn't 
<token> correct_payload, 2); <answer> check_recv_pkts(rxfd, 
if <token> == PF_INET) { <answer> (proto 
printf("different ttl doesn't coalesce: <token> <answer> "); 
<token> correct_payload, 2); <answer> check_recv_pkts(rxfd, 
<token> options doesn't coalesce: "); <answer> printf("ip 
correct_payload[2] <token> PAYLOAD_LEN; <answer> = 
check_recv_pkts(rxfd, correct_payload, <token> <answer> 3); 
printf("fragmented ip4 doesn't <token> "); <answer> coalesce: 
<token> correct_payload, 2); <answer> check_recv_pkts(rxfd, 
} else <token> (proto == PF_INET6) { <answer> if 
printf("fragmented <token> doesn't coalesce: "); <answer> ip6 
<token> = PAYLOAD_LEN * 2; <answer> correct_payload[0] 
<token> = PAYLOAD_LEN; <answer> correct_payload[1] 
<token> = PAYLOAD_LEN; <answer> correct_payload[2] 
<token> correct_payload, 3); <answer> check_recv_pkts(rxfd, 
printf("ipv6 with ext header does <token> "); <answer> coalesce: 
<token> = PAYLOAD_LEN * 2; <answer> correct_payload[0] 
check_recv_pkts(rxfd, <token> 1); <answer> correct_payload, 
printf("ipv6 with ext header <token> different payloads doesn't coalesce: "); <answer> with 
correct_payload[0] = <token> <answer> PAYLOAD_LEN; 
<token> = PAYLOAD_LEN; <answer> correct_payload[1] 
check_recv_pkts(rxfd, <token> 2); <answer> correct_payload, 
} else if (strcmp(testname, <token> == 0) { <answer> "large") 
int offset = proto == PF_INET ? <token> : 0; <answer> 20 
int remainder <token> (MAX_PAYLOAD + offset) % MSS; <answer> = 
<token> = (MAX_PAYLOAD + offset); <answer> correct_payload[0] 
correct_payload[1] = <token> <answer> remainder; 
printf("Shouldn't coalesce <token> exceed IP max pkt size: "); <answer> if 
check_recv_pkts(rxfd, correct_payload, <token> <answer> 2); 
<token> <inttypes.h> <answer> #include 
<token> "aolib.h" <answer> #include 
const unsigned int nr_packets <token> 1000; <answer> = 
<token> unsigned int msg_len = 1000; <answer> const 
const unsigned int quota <token> nr_packets * msg_len; <answer> = 
<token> int client_new_port; <answer> unsigned 
#include <token> <answer> <linux/packing.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/bitops.h> <answer> #include 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/types.h> 
<token> <linux/bitrev.h> <answer> #include 
static int get_le_offset(int <token> <answer> offset) 
int <token> <answer> closest_multiple_of_4; 
closest_multiple_of_4 = (offset / 4) * <token> <answer> 4; 
<token> -= closest_multiple_of_4; <answer> offset 
<token> closest_multiple_of_4 + (3 - offset); <answer> return 
<token> int get_reverse_lsw32_offset(int offset, size_t len) <answer> static 
int <token> <answer> closest_multiple_of_4; 
<token> word_index; <answer> int 
word_index = offset / <token> <answer> 4; 
closest_multiple_of_4 = word_index <token> 4; <answer> * 
offset -= <token> <answer> closest_multiple_of_4; 
word_index = (len / 4) <token> word_index - 1; <answer> - 
return <token> * 4 + offset; <answer> word_index 
static void adjust_for_msb_right_quirk(u64 *to_write, int <token> <answer> *box_start_bit, 
int *box_end_bit, u8 <token> <answer> *box_mask) 
int box_bit_width = *box_start_bit - <token> + 1; <answer> *box_end_bit 
<token> new_box_start_bit, new_box_end_bit; <answer> int 
*to_write >>= <token> <answer> *box_end_bit; 
<token> = bitrev8(*to_write) >> (8 - box_bit_width); <answer> *to_write 
*to_write <token> *box_end_bit; <answer> <<= 
new_box_end_bit = box_bit_width - <token> - 1; <answer> *box_start_bit 
new_box_start_bit = <token> - *box_end_bit - 1; <answer> box_bit_width 
*box_mask = GENMASK_ULL(new_box_start_bit, <token> <answer> new_box_end_bit); 
<token> = new_box_start_bit; <answer> *box_start_bit 
*box_end_bit = <token> <answer> new_box_end_bit; 
<token> packing(void *pbuf, u64 *uval, int startbit, int endbit, size_t pbuflen, <answer> int 
enum packing_op op, <token> quirks) <answer> u8 
u64 <token> <answer> value_width; 
<token> plogical_first_u8, plogical_last_u8, box; <answer> int 
if (op == PACK && value_width < 64 && (*uval >= (1ull << <token> <answer> value_width))) 
return <token> <answer> -ERANGE; 
plogical_first_u8 = <token> / 8; <answer> startbit 
<token> = endbit / 8; <answer> plogical_last_u8 
for (box = plogical_first_u8; <token> >= plogical_last_u8; box--) { <answer> box 
if <token> == plogical_first_u8) <answer> (box 
<token> = startbit % 8; <answer> box_start_bit 
box_start_bit = <token> <answer> 7; 
if (box <token> plogical_last_u8) <answer> == 
box_end_bit = endbit <token> 8; <answer> % 
box_end_bit = <token> <answer> 0; 
<token> = ((box * 8) + box_start_bit) - endbit; <answer> proj_start_bit 
proj_end_bit = ((box * 8) + box_end_bit) - <token> <answer> endbit; 
<token> = GENMASK_ULL(proj_start_bit, proj_end_bit); <answer> proj_mask 
box_mask <token> GENMASK_ULL(box_start_bit, box_end_bit); <answer> = 
box_addr <token> pbuflen - box - 1; <answer> = 
if (quirks & <token> <answer> QUIRK_LITTLE_ENDIAN) 
<token> = get_le_offset(box_addr); <answer> box_addr 
if (quirks <token> QUIRK_LSW32_IS_FIRST) <answer> & 
box_addr <token> get_reverse_lsw32_offset(box_addr, <answer> = 
if (op <token> UNPACK) { <answer> == 
<token> pval; <answer> u64 
#include <token> <answer> <asm/cacheflush.h> 
#include <token> <answer> <linux/cache.h> 
#include <token> <answer> <asm/cpuinfo.h> 
<token> <asm/pvr.h> <answer> #include 
static <token> void __enable_icache_msr(void) <answer> inline 
__asm__ __volatile__ <token> msrset r0, %0;" \ <answer> (" 
<token> \ <answer> "nop;" 
: : <token> (MSR_ICE) : "memory"); <answer> "i" 
static <token> void __disable_icache_msr(void) <answer> inline 
__asm__ __volatile__ <token> msrclr r0, %0;" \ <answer> (" 
<token> \ <answer> "nop;" 
: : "i" (MSR_ICE) <token> "memory"); <answer> : 
<token> inline void __enable_dcache_msr(void) <answer> static 
__asm__ __volatile__ (" msrset r0, <token> \ <answer> %0;" 
"nop;" <token> <answer> \ 
: : "i" <token> : "memory"); <answer> (MSR_DCE) 
static inline void <token> <answer> __disable_dcache_msr(void) 
__asm__ __volatile__ (" msrclr r0, %0;" <token> <answer> \ 
"nop; " <token> <answer> \ 
: : "i" (MSR_DCE) : <token> <answer> "memory"); 
<token> inline void __enable_icache_nomsr(void) <answer> static 
__asm__ __volatile__ (" mfs r12, rmsr;" <token> <answer> \ 
"nop;" <token> <answer> \ 
<token> r12, r12, %0;" \ <answer> "ori 
"mts rmsr, <token> \ <answer> r12;" 
<token> \ <answer> "nop;" 
: <token> "i" (MSR_ICE) : "memory", "r12"); <answer> : 
static <token> void __disable_icache_nomsr(void) <answer> inline 
__asm__ <token> (" mfs r12, rmsr;" \ <answer> __volatile__ 
"nop;" <token> <answer> \ 
"andi <token> r12, ~%0;" \ <answer> r12, 
<token> rmsr, r12;" \ <answer> "mts 
"nop;" <token> <answer> \ 
: <token> "i" (MSR_ICE) : "memory", "r12"); <answer> : 
static inline void <token> <answer> __enable_dcache_nomsr(void) 
__asm__ <token> (" mfs r12, rmsr;" \ <answer> __volatile__ 
"nop;" <token> <answer> \ 
"ori r12, r12, %0;" <token> <answer> \ 
"mts <token> r12;" \ <answer> rmsr, 
"nop;" <token> <answer> \ 
: : "i" <token> : "memory", "r12"); <answer> (MSR_DCE) 
static inline void <token> <answer> __disable_dcache_nomsr(void) 
__asm__ __volatile__ (" <token> r12, rmsr;" \ <answer> mfs 
<token> \ <answer> "nop;" 
"andi <token> r12, ~%0;" \ <answer> r12, 
<token> rmsr, r12;" \ <answer> "mts 
"nop;" <token> <answer> \ 
: <token> "i" (MSR_DCE) : "memory", "r12"); <answer> : 
#define <token> end, cache_line_length, cache_size) \ <answer> CACHE_LOOP_LIMITS(start, 
do { <token> <answer> \ 
int align = ~(cache_line_length - <token> \ <answer> 1); 
if <token> < UINT_MAX - cache_size) \ <answer> (start 
<token> = min(start + cache_size, end); \ <answer> end 
start &= <token> \ <answer> align; 
} while <token> <answer> (0) 
#define CACHE_ALL_LOOP(cache_size, line_length, op) <token> <answer> \ 
<token> { \ <answer> do 
unsigned int len = cache_size <token> line_length; \ <answer> - 
int <token> = -line_length; \ <answer> step 
WARN_ON(step <token> 0); \ <answer> >= 
__asm__ __volatile__ (" 1: " #op " %0, <token> \ <answer> r0;" 
"bgtid %0, <token> \ <answer> 1b;" 
<token> %0, %0, %1;" \ <answer> "addk 
: : "r" (len), <token> (step) \ <answer> "r" 
: <token> \ <answer> "memory"); 
<token> while (0) <answer> } 
<token> CACHE_RANGE_LOOP_2(start, end, line_length, op) \ <answer> #define 
do <token> \ <answer> { 
int step = -line_length; <token> <answer> \ 
int align = ~(line_length - 1); <token> <answer> \ 
<token> count; \ <answer> int 
end = ((end & align) <token> end) ? end - line_length : end & align; \ <answer> == 
count = <token> - start; \ <answer> end 
<token> < 0); \ <answer> WARN_ON(count 
__asm__ __volatile__ (" <token> " #op " %0, %1;" \ <answer> 1: 
"bgtid %1, 1b;" <token> <answer> \ 
<token> %1, %1, %2;" \ <answer> "addk 
: : <token> (start), "r" (count), \ <answer> "r" 
"r" (step) <token> "memory"); \ <answer> : 
} while <token> <answer> (0) 
static void <token> <answer> __invalidate_dcache_all_wb(void) 
#ifndef <token> <answer> ASM_LOOP 
<token> i; <answer> int 
pr_debug("%s\n", <token> <answer> __func__); 
<token> ASM_LOOP <answer> #ifdef 
CACHE_ALL_LOOP(cpuinfo.dcache_size, <token> <answer> cpuinfo.dcache_line_length, 
<token> (i = 0; i < cpuinfo.dcache_size; <answer> for 
i += <token> <answer> cpuinfo.dcache_line_length) 
__asm__ __volatile__ ("wdc <token> r0;" \ <answer> %0, 
: : "r" <token> <answer> (i)); 
static void __invalidate_dcache_range_wb(unsigned long <token> <answer> start, 
unsigned <token> end) <answer> long 
<token> ASM_LOOP <answer> #ifndef 
int <token> <answer> i; 
pr_debug("%s: start 0x%x, end 0x%x\n", <token> <answer> __func__, 
(unsigned <token> (unsigned int) end); <answer> int)start, 
CACHE_LOOP_LIMITS(start, <token> <answer> end, 
<token> cpuinfo.dcache_size); <answer> cpuinfo.dcache_line_length, 
#ifdef <token> <answer> ASM_LOOP 
CACHE_RANGE_LOOP_2(start, <token> cpuinfo.dcache_line_length, wdc.clear); <answer> end, 
for (i = <token> i < end; i += cpuinfo.dcache_line_length) <answer> start; 
__asm__ __volatile__ ("wdc.clear %0, <token> \ <answer> r0;" 
: : <token> (i)); <answer> "r" 
static void __invalidate_dcache_range_nomsr_wt(unsigned <token> start, <answer> long 
<token> long end) <answer> unsigned 
<token> ASM_LOOP <answer> #ifndef 
<token> i; <answer> int 
pr_debug("%s: start 0x%x, <token> 0x%x\n", __func__, <answer> end 
(unsigned <token> (unsigned int) end); <answer> int)start, 
CACHE_LOOP_LIMITS(start, <token> <answer> end, 
<token> cpuinfo.dcache_size); <answer> cpuinfo.dcache_line_length, 
#ifdef <token> <answer> ASM_LOOP 
CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, <token> <answer> wdc); 
for (i = start; i < <token> i += cpuinfo.dcache_line_length) <answer> end; 
__asm__ <token> ("wdc %0, r0;" \ <answer> __volatile__ 
: <token> "r" (i)); <answer> : 
<token> void __invalidate_dcache_range_msr_irq_wt(unsigned long start, <answer> static 
<token> long end) <answer> unsigned 
unsigned <token> flags; <answer> long 
<token> ASM_LOOP <answer> #ifndef 
int <token> <answer> i; 
pr_debug("%s: start 0x%x, <token> 0x%x\n", __func__, <answer> end 
(unsigned <token> (unsigned int) end); <answer> int)start, 
CACHE_LOOP_LIMITS(start, <token> <answer> end, 
cpuinfo.dcache_line_length, <token> <answer> cpuinfo.dcache_size); 
#ifdef <token> <answer> ASM_LOOP 
CACHE_RANGE_LOOP_1(start, end, <token> wdc); <answer> cpuinfo.dcache_line_length, 
for (i <token> start; i < end; i += cpuinfo.dcache_line_length) <answer> = 
__asm__ <token> ("wdc %0, r0;" \ <answer> __volatile__ 
: : "r" <token> <answer> (i)); 
static void <token> long start, <answer> __invalidate_dcache_range_nomsr_irq(unsigned 
<token> long end) <answer> unsigned 
<token> long flags; <answer> unsigned 
#ifndef <token> <answer> ASM_LOOP 
int <token> <answer> i; 
pr_debug("%s: start <token> end 0x%x\n", __func__, <answer> 0x%x, 
(unsigned int)start, <token> int) end); <answer> (unsigned 
CACHE_LOOP_LIMITS(start, <token> <answer> end, 
<token> cpuinfo.dcache_size); <answer> cpuinfo.dcache_line_length, 
<token> ASM_LOOP <answer> #ifdef 
<token> end, cpuinfo.dcache_line_length, wdc); <answer> CACHE_RANGE_LOOP_1(start, 
for (i = start; <token> < end; i += cpuinfo.dcache_line_length) <answer> i 
__asm__ __volatile__ <token> %0, r0;" \ <answer> ("wdc 
: : "r" <token> <answer> (i)); 
<token> void __flush_dcache_all_wb(void) <answer> static 
#ifndef <token> <answer> ASM_LOOP 
int <token> <answer> i; 
pr_debug("%s\n", <token> <answer> __func__); 
#ifdef <token> <answer> ASM_LOOP 
CACHE_ALL_LOOP(cpuinfo.dcache_size, <token> <answer> cpuinfo.dcache_line_length, 
for (i = 0; i <token> cpuinfo.dcache_size; <answer> < 
i <token> cpuinfo.dcache_line_length) <answer> += 
__asm__ <token> ("wdc.flush %0, r0;" \ <answer> __volatile__ 
: : "r" <token> <answer> (i)); 
static void <token> long start, unsigned long end) <answer> __flush_dcache_range_wb(unsigned 
#ifndef <token> <answer> ASM_LOOP 
<token> i; <answer> int 
pr_debug("%s: start <token> end 0x%x\n", __func__, <answer> 0x%x, 
(unsigned <token> (unsigned int) end); <answer> int)start, 
CACHE_LOOP_LIMITS(start, <token> <answer> end, 
<token> cpuinfo.dcache_size); <answer> cpuinfo.dcache_line_length, 
#ifdef <token> <answer> ASM_LOOP 
CACHE_RANGE_LOOP_2(start, <token> cpuinfo.dcache_line_length, wdc.flush); <answer> end, 
for (i = <token> i < end; i += cpuinfo.dcache_line_length) <answer> start; 
__asm__ __volatile__ ("wdc.flush <token> r0;" \ <answer> %0, 
<token> : "r" (i)); <answer> : 
<token> <linux/reboot.h> <answer> #include 
#include <token> <answer> <linux/smp.h> 
#include <token> <answer> <asm/hexagon_vm.h> 
void <token> <answer> machine_power_off(void) 
<token> machine_halt(void) <answer> void 
void <token> *cmd) <answer> machine_restart(char 
void <token> = NULL; <answer> (*pm_power_off)(void) 
#define pr_fmt(fmt) <token> " fmt <answer> "nvdimm_pmu: 
#include <token> <answer> <linux/nd.h> 
#include <token> <answer> <linux/platform_device.h> 
#define EVENT(_name, _code) enum{_name = <token> <answer> _code} 
<token> (cpu != nd_pmu->cpu) <answer> if 
return <token> <answer> 0; 
if <token> >= nr_cpu_ids) { <answer> (target 
<token> = cpu_to_node(cpu); <answer> nodeid 
cpumask = <token> <answer> cpumask_of_node(nodeid); 
target <token> cpumask_any_but(cpumask, cpu); <answer> = 
nd_pmu->cpu = <token> <answer> target; 
if (!cpumask_empty(&nd_pmu->arch_cpumask)) <token> <answer> { 
<token> = cpumask_any(&nd_pmu->arch_cpumask); <answer> nd_pmu->cpu 
} else <token> <answer> { 
nd_pmu->dev <token> &pdev->dev; <answer> = 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/sched.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/input.h> <answer> #include 
#include <token> <answer> <linux/serio.h> 
#include <token> <answer> <linux/workqueue.h> 
#define DRIVER_DESC "Sun keyboard <token> <answer> driver" 
MODULE_AUTHOR("Vojtech <token> <vojtech@ucw.cz>"); <answer> Pavlik 
<token> unsigned char sunkbd_keycode[128] = { <answer> static 
0,128,114,129,115, 59, <token> 68, 61, 87, 62, 88, 63,100, 64,112, <answer> 60, 
65, 66, 67, 56,103,119, 99, 70,105,130,131,108,106, 1, <token> 3, <answer> 2, 
4, 5, 6, 7, <token> 9, 10, 11, 12, 13, 41, 14,110,113, 98, 55, <answer> 8, 
116,132, 83,133,102, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, <token> <answer> 25, 
26, 27,111,127, 71, <token> 73, 74,134,135,107, 0, 29, 30, 31, 32, <answer> 72, 
<token> 34, 35, 36, 37, 38, 39, 40, 43, 28, 96, 75, 76, 77, 82,136, <answer> 33, 
104,137, 69, 42, 44, <token> 46, 47, 48, 49, 50, 51, 52, 53, 54,101, <answer> 45, 
79, 80, 81, 0, 0, 0,138, <token> 57,126,109, 86, 78 <answer> 58,125, 
<token> SUNKBD_CMD_RESET 0x1 <answer> #define 
#define SUNKBD_CMD_BELLON <token> <answer> 0x2 
#define <token> 0x3 <answer> SUNKBD_CMD_BELLOFF 
#define SUNKBD_CMD_CLICK <token> <answer> 0xa 
#define SUNKBD_CMD_NOCLICK <token> <answer> 0xb 
#define <token> 0xe <answer> SUNKBD_CMD_SETLED 
#define SUNKBD_CMD_LAYOUT <token> <answer> 0xf 
<token> SUNKBD_RET_RESET 0xff <answer> #define 
<token> SUNKBD_RET_ALLUP 0x7f <answer> #define 
#define SUNKBD_RET_LAYOUT <token> <answer> 0xfe 
#define <token> 0x20 <answer> SUNKBD_LAYOUT_5_MASK 
<token> SUNKBD_RELEASE 0x80 <answer> #define 
<token> SUNKBD_KEY 0x7f <answer> #define 
struct sunkbd <token> <answer> { 
<token> char keycode[ARRAY_SIZE(sunkbd_keycode)]; <answer> unsigned 
struct input_dev <token> <answer> *dev; 
<token> serio *serio; <answer> struct 
<token> work_struct tq; <answer> struct 
wait_queue_head_t <token> <answer> wait; 
char <token> <answer> name[64]; 
char <token> <answer> phys[32]; 
<token> type; <answer> char 
<token> enabled; <answer> bool 
volatile <token> reset; <answer> s8 
volatile <token> layout; <answer> s8 
static irqreturn_t sunkbd_interrupt(struct serio <token> <answer> *serio, 
unsigned <token> data, unsigned int flags) <answer> char 
struct sunkbd *sunkbd <token> serio_get_drvdata(serio); <answer> = 
if <token> <= -1) { <answer> (sunkbd->reset 
sunkbd->reset <token> data; <answer> = 
<token> out; <answer> goto 
if (sunkbd->layout == <token> { <answer> -1) 
sunkbd->layout <token> data; <answer> = 
goto <token> <answer> out; 
<token> (data) { <answer> switch 
case <token> <answer> SUNKBD_RET_RESET: 
<token> (sunkbd->enabled) <answer> if 
sunkbd->reset <token> -1; <answer> = 
case <token> <answer> SUNKBD_RET_LAYOUT: 
sunkbd->layout = <token> <answer> -1; 
static int sunkbd_event(struct input_dev <token> <answer> *dev, 
unsigned int type, <token> int code, int value) <answer> unsigned 
struct sunkbd <token> = input_get_drvdata(dev); <answer> *sunkbd 
<token> (type) { <answer> switch 
case <token> <answer> EV_LED: 
<token> SUNKBD_CMD_SETLED); <answer> serio_write(sunkbd->serio, 
(!!test_bit(LED_CAPSL, dev->led) << 3) <token> <answer> | 
(!!test_bit(LED_SCROLLL, <token> << 2) | <answer> dev->led) 
(!!test_bit(LED_COMPOSE, dev->led) << <token> | <answer> 1) 
!!test_bit(LED_NUML, <token> <answer> dev->led)); 
<token> 0; <answer> return 
<token> EV_SND: <answer> case 
switch (code) <token> <answer> { 
<token> SND_CLICK: <answer> case 
serio_write(sunkbd->serio, SUNKBD_CMD_NOCLICK <token> value); <answer> - 
return <token> <answer> 0; 
case <token> <answer> SND_BELL: 
<token> SUNKBD_CMD_BELLOFF - value); <answer> serio_write(sunkbd->serio, 
<token> 0; <answer> return 
return <token> <answer> -1; 
<token> int sunkbd_initialize(struct sunkbd *sunkbd) <answer> static 
sunkbd->reset <token> -2; <answer> = 
<token> SUNKBD_CMD_RESET); <answer> serio_write(sunkbd->serio, 
<token> sunkbd->reset >= 0, HZ); <answer> wait_event_interruptible_timeout(sunkbd->wait, 
<token> (sunkbd->reset < 0) <answer> if 
<token> -1; <answer> return 
sunkbd->type <token> sunkbd->reset; <answer> = 
static <token> sunkbd_set_leds_beeps(struct sunkbd *sunkbd) <answer> void 
serio_write(sunkbd->serio, <token> <answer> SUNKBD_CMD_SETLED); 
(!!test_bit(LED_CAPSL, sunkbd->dev->led) <token> 3) | <answer> << 
(!!test_bit(LED_SCROLLL, sunkbd->dev->led) <token> 2) | <answer> << 
<token> sunkbd->dev->led) << 1) | <answer> (!!test_bit(LED_COMPOSE, 
<token> sunkbd->dev->led)); <answer> !!test_bit(LED_NUML, 
SUNKBD_CMD_NOCLICK <token> !!test_bit(SND_CLICK, sunkbd->dev->snd)); <answer> - 
SUNKBD_CMD_BELLOFF - !!test_bit(SND_BELL, <token> <answer> sunkbd->dev->snd)); 
static void sunkbd_reinit(struct work_struct <token> <answer> *work) 
struct <token> *sunkbd = container_of(work, struct sunkbd, tq); <answer> sunkbd 
<token> >= 0 || !sunkbd->enabled, <answer> sunkbd->reset 
if (sunkbd->reset <token> 0 && sunkbd->enabled) <answer> >= 
static void sunkbd_enable(struct sunkbd *sunkbd, <token> enable) <answer> bool 
sunkbd->enabled = <token> <answer> enable; 
if (!enable) <token> <answer> { 
static int <token> serio *serio, struct serio_driver *drv) <answer> sunkbd_connect(struct 
struct <token> *sunkbd; <answer> sunkbd 
struct <token> *input_dev; <answer> input_dev 
int <token> = -ENOMEM; <answer> err 
<token> i; <answer> int 
sunkbd = <token> sunkbd), GFP_KERNEL); <answer> kzalloc(sizeof(struct 
input_dev = <token> <answer> input_allocate_device(); 
if <token> || !input_dev) <answer> (!sunkbd 
goto <token> <answer> fail1; 
<token> = serio; <answer> sunkbd->serio 
sunkbd->dev <token> input_dev; <answer> = 
<token> sunkbd_reinit); <answer> INIT_WORK(&sunkbd->tq, 
snprintf(sunkbd->phys, sizeof(sunkbd->phys), <token> serio->phys); <answer> "%s/input0", 
serio_set_drvdata(serio, <token> <answer> sunkbd); 
<token> = serio_open(serio, drv); <answer> err 
if <token> <answer> (err) 
<token> fail2; <answer> goto 
if (sunkbd_initialize(sunkbd) < <token> { <answer> 0) 
err = <token> <answer> -ENODEV; 
goto <token> <answer> fail3; 
<token> sizeof(sunkbd->name), <answer> snprintf(sunkbd->name, 
"Sun Type <token> keyboard", sunkbd->type); <answer> %d 
<token> sunkbd_keycode, sizeof(sunkbd->keycode)); <answer> memcpy(sunkbd->keycode, 
input_dev->name = <token> <answer> sunkbd->name; 
input_dev->phys = <token> <answer> sunkbd->phys; 
<token> = BUS_RS232; <answer> input_dev->id.bustype 
<token> = SERIO_SUNKBD; <answer> input_dev->id.vendor 
input_dev->id.product = <token> <answer> sunkbd->type; 
input_dev->id.version = <token> <answer> 0x0100; 
<token> = &serio->dev; <answer> input_dev->dev.parent 
<token> sunkbd); <answer> input_set_drvdata(input_dev, 
input_dev->event = <token> <answer> sunkbd_event; 
input_dev->evbit[0] = <token> | BIT_MASK(EV_LED) | <answer> BIT_MASK(EV_KEY) 
BIT_MASK(EV_SND) | <token> <answer> BIT_MASK(EV_REP); 
input_dev->ledbit[0] = <token> | BIT_MASK(LED_COMPOSE) | <answer> BIT_MASK(LED_CAPSL) 
BIT_MASK(LED_SCROLLL) <token> BIT_MASK(LED_NUML); <answer> | 
input_dev->sndbit[0] = BIT_MASK(SND_CLICK) <token> BIT_MASK(SND_BELL); <answer> | 
input_dev->keycode <token> sunkbd->keycode; <answer> = 
<token> = sizeof(unsigned char); <answer> input_dev->keycodesize 
input_dev->keycodemax = <token> <answer> ARRAY_SIZE(sunkbd_keycode); 
for (i = 0; i < <token> i++) <answer> ARRAY_SIZE(sunkbd_keycode); 
<token> input_dev->keybit); <answer> __set_bit(sunkbd->keycode[i], 
<token> input_dev->keybit); <answer> __clear_bit(KEY_RESERVED, 
sunkbd_enable(sunkbd, <token> <answer> true); 
<token> = input_register_device(sunkbd->dev); <answer> err 
<token> (err) <answer> if 
<token> fail4; <answer> goto 
<token> 0; <answer> return 
fail4: <token> false); <answer> sunkbd_enable(sunkbd, 
fail3: <token> <answer> serio_close(serio); 
<token> serio_set_drvdata(serio, NULL); <answer> fail2: 
<token> input_free_device(input_dev); <answer> fail1: 
return <token> <answer> err; 
static void sunkbd_disconnect(struct serio <token> <answer> *serio) 
struct sunkbd *sunkbd <token> serio_get_drvdata(serio); <answer> = 
<token> false); <answer> sunkbd_enable(sunkbd, 
serio_set_drvdata(serio, <token> <answer> NULL); 
static const struct serio_device_id <token> = { <answer> sunkbd_serio_ids[] 
.type = <token> <answer> SERIO_RS232, 
.proto <token> SERIO_SUNKBD, <answer> = 
.id = <token> <answer> SERIO_ANY, 
.extra <token> SERIO_ANY, <answer> = 
.type <token> SERIO_RS232, <answer> = 
#include <token> <answer> <linux/debugfs.h> 
<token> <linux/ethtool.h> <answer> #include 
<token> <linux/random.h> <answer> #include 
<token> "netdevsim.h" <answer> #include 
static <token> <answer> void 
<token> net_device *dev, <answer> nsim_get_pause_stats(struct 
<token> ethtool_pause_stats *pause_stats) <answer> struct 
struct netdevsim <token> = netdev_priv(dev); <answer> *ns 
if <token> <answer> (ns->ethtool.pauseparam.report_stats_rx) 
<token> = 1; <answer> pause_stats->rx_pause_frames 
<token> (ns->ethtool.pauseparam.report_stats_tx) <answer> if 
<token> = 2; <answer> pause_stats->tx_pause_frames 
<token> void <answer> static 
nsim_get_pauseparam(struct net_device *dev, struct ethtool_pauseparam <token> <answer> *pause) 
struct <token> *ns = netdev_priv(dev); <answer> netdevsim 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/sched.h> 
<token> <linux/perf_event.h> <answer> #include 
#include <token> <answer> <linux/percpu.h> 
<token> <linux/uaccess.h> <answer> #include 
#include <token> <answer> <linux/mm.h> 
#include <token> <answer> <asm/ptrace.h> 
#include <token> <answer> <asm/sigcontext.h> 
<token> <asm/ucontext.h> <answer> #include 
#include <token> <answer> <asm/vdso.h> 
<token> <asm/pte-walk.h> <answer> #include 
#include <token> <answer> "callchain.h" 
#ifdef <token> <answer> CONFIG_PPC64 
#include <token> <answer> <asm/syscalls_32.h> 
struct signal_frame_32 <token> <answer> { 
<token> dummy[__SIGNAL_FRAMESIZE32]; <answer> char 
struct sigcontext32 <token> <answer> sctx; 
struct <token> mctx; <answer> mcontext32 
<token> abigap[56]; <answer> int 
<token> rt_signal_frame_32 { <answer> struct 
char dummy[__SIGNAL_FRAMESIZE32 <token> 16]; <answer> + 
<token> info; <answer> compat_siginfo_t 
struct ucontext32 <token> <answer> uc; 
<token> abigap[56]; <answer> int 
static int is_sigreturn_32_address(unsigned <token> nip, unsigned int fp) <answer> int 
if (nip == <token> + offsetof(struct signal_frame_32, mctx.mc_pad)) <answer> fp 
<token> 1; <answer> return 
if <token> && <answer> (current->mm->context.vdso 
nip <token> VDSO32_SYMBOL(current->mm->context.vdso, sigtramp32)) <answer> == 
<token> 1; <answer> return 
return <token> <answer> 0; 
static int is_rt_sigreturn_32_address(unsigned int <token> unsigned int fp) <answer> nip, 
if (nip == fp + offsetof(struct <token> <answer> rt_signal_frame_32, 
return <token> <answer> 1; 
if (current->mm->context.vdso <token> <answer> && 
<token> == VDSO32_SYMBOL(current->mm->context.vdso, sigtramp_rt32)) <answer> nip 
<token> 1; <answer> return 
return <token> <answer> 0; 
static int <token> int sp) <answer> sane_signal_32_frame(unsigned 
struct signal_frame_32 <token> *sf; <answer> __user 
<token> int regs; <answer> unsigned 
sf = (struct <token> __user *) (unsigned long) sp; <answer> signal_frame_32 
if (read_user_stack_32((unsigned <token> __user *) &sf->sctx.regs, &regs)) <answer> int 
<token> 0; <answer> return 
return regs == <token> long) &sf->mctx; <answer> (unsigned 
static <token> sane_rt_signal_32_frame(unsigned int sp) <answer> int 
struct <token> __user *sf; <answer> rt_signal_frame_32 
unsigned int <token> <answer> regs; 
sf = <token> rt_signal_frame_32 __user *) (unsigned long) sp; <answer> (struct 
if (read_user_stack_32((unsigned int __user *) &sf->uc.uc_regs, <token> <answer> &regs)) 
return <token> <answer> 0; 
<token> regs == (unsigned long) &sf->uc.uc_mcontext; <answer> return 
static unsigned int __user <token> int sp, <answer> *signal_frame_32_regs(unsigned 
unsigned int next_sp, <token> int next_ip) <answer> unsigned 
struct mcontext32 __user *mctx <token> NULL; <answer> = 
struct signal_frame_32 <token> *sf; <answer> __user 
<token> rt_signal_frame_32 __user *rt_sf; <answer> struct 
if (next_sp - sp >= sizeof(struct <token> && <answer> signal_frame_32) 
<token> sp) && <answer> is_sigreturn_32_address(next_ip, 
<token> { <answer> sane_signal_32_frame(sp)) 
sf = (struct <token> __user *) (unsigned long) sp; <answer> signal_frame_32 
mctx = <token> <answer> &sf->mctx; 
if (!mctx && next_sp - sp <token> sizeof(struct rt_signal_frame_32) && <answer> >= 
<token> sp) && <answer> is_rt_sigreturn_32_address(next_ip, 
sane_rt_signal_32_frame(sp)) <token> <answer> { 
rt_sf = (struct rt_signal_frame_32 __user *) (unsigned long) <token> <answer> sp; 
mctx <token> &rt_sf->uc.uc_mcontext; <answer> = 
<token> (!mctx) <answer> if 
return <token> <answer> NULL; 
<token> mctx->mc_gregs; <answer> return 
void perf_callchain_user_32(struct <token> *entry, <answer> perf_callchain_entry_ctx 
<token> pt_regs *regs) <answer> struct 
unsigned int sp, <token> <answer> next_sp; 
unsigned <token> next_ip; <answer> int 
unsigned <token> lr; <answer> int 
<token> level = 0; <answer> long 
<token> int __user *fp, *uregs; <answer> unsigned 
<token> = perf_instruction_pointer(regs); <answer> next_ip 
lr = <token> <answer> regs->link; 
sp = <token> <answer> regs->gpr[1]; 
<token> next_ip); <answer> perf_callchain_store(entry, 
while (entry->nr <token> entry->max_stack) { <answer> < 
fp = (unsigned int __user *) (unsigned long) <token> <answer> sp; 
if (invalid_user_sp(sp) <token> read_user_stack_32(fp, &next_sp)) <answer> || 
if (level > 0 <token> read_user_stack_32(&fp[1], &next_ip)) <answer> && 
uregs <token> signal_frame_32_regs(sp, next_sp, next_ip); <answer> = 
if (!uregs && level <token> 1) <answer> <= 
uregs = signal_frame_32_regs(sp, next_sp, <token> <answer> lr); 
if (uregs) <token> <answer> { 
if (read_user_stack_32(&uregs[PT_NIP], &next_ip) <token> <answer> || 
read_user_stack_32(&uregs[PT_LNK], &lr) <token> <answer> || 
<token> &sp)) <answer> read_user_stack_32(&uregs[PT_R1], 
level <token> 0; <answer> = 
<token> PERF_CONTEXT_USER); <answer> perf_callchain_store_context(entry, 
<token> next_ip); <answer> perf_callchain_store(entry, 
<token> (level == 0) <answer> if 
next_ip = <token> <answer> lr; 
perf_callchain_store(entry, <token> <answer> next_ip); 
sp = <token> <answer> next_sp; 
#include <token> <answer> <linux/module.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
<token> <linux/err.h> <answer> #include 
<token> <linux/atomic.h> <answer> #include 
<token> <linux/uaccess.h> <answer> #include 
#include <token> <answer> <linux/mod_devicetable.h> 
<token> "ap_bus.h" <answer> #include 
#include <token> <answer> "zcrypt_api.h" 
#include <token> <answer> "zcrypt_msgtype6.h" 
#include <token> <answer> "zcrypt_msgtype50.h" 
<token> "zcrypt_error.h" <answer> #include 
#include <token> <answer> "zcrypt_cex4.h" 
<token> "zcrypt_ccamisc.h" <answer> #include 
<token> "zcrypt_ep11misc.h" <answer> #include 
#define <token> (900 * HZ) <answer> CEX4_CLEANUP_TIME 
MODULE_AUTHOR("IBM <token> <answer> Corporation"); 
MODULE_DESCRIPTION("CEX[45678] Cryptographic Card device <token> " \ <answer> driver, 
"Copyright <token> Corp. 2022"); <answer> IBM 
static struct ap_device_id <token> = { <answer> zcrypt_cex4_card_ids[] 
{ .dev_type = <token> <answer> AP_DEVICE_TYPE_CEX4, 
.match_flags <token> AP_DEVICE_ID_MATCH_CARD_TYPE }, <answer> = 
<token> .dev_type = AP_DEVICE_TYPE_CEX5, <answer> { 
.match_flags = <token> }, <answer> AP_DEVICE_ID_MATCH_CARD_TYPE 
{ .dev_type = <token> <answer> AP_DEVICE_TYPE_CEX6, 
.match_flags <token> AP_DEVICE_ID_MATCH_CARD_TYPE }, <answer> = 
{ .dev_type <token> AP_DEVICE_TYPE_CEX7, <answer> = 
.match_flags = AP_DEVICE_ID_MATCH_CARD_TYPE <token> <answer> }, 
{ <token> = AP_DEVICE_TYPE_CEX8, <answer> .dev_type 
<token> = AP_DEVICE_ID_MATCH_CARD_TYPE }, <answer> .match_flags 
static <token> cca_serialnr_show(struct device *dev, <answer> ssize_t 
struct <token> *attr, <answer> device_attribute 
char <token> <answer> *buf) 
struct zcrypt_card *zc <token> dev_get_drvdata(dev); <answer> = 
<token> cca_info ci; <answer> struct 
struct <token> *ac = to_ap_card(dev); <answer> ap_card 
<token> 0, sizeof(ci)); <answer> memset(&ci, 
if <token> >= 0) <answer> (ap_domain_index 
<token> ap_domain_index, &ci, zc->online); <answer> cca_get_info(ac->id, 
return sysfs_emit(buf, <token> ci.serial); <answer> "%s\n", 
<token> struct device_attribute dev_attr_cca_serialnr = <answer> static 
<token> 0444, cca_serialnr_show, NULL); <answer> __ATTR(serialnr, 
static struct attribute *cca_card_attrs[] <token> { <answer> = 
static const struct <token> cca_card_attr_grp = { <answer> attribute_group 
.attrs <token> cca_card_attrs, <answer> = 
static ssize_t cca_mkvps_show(struct device <token> <answer> *dev, 
struct <token> *attr, <answer> device_attribute 
<token> *buf) <answer> char 
<token> zcrypt_queue *zq = dev_get_drvdata(dev); <answer> struct 
int <token> = 0; <answer> n 
<token> cca_info ci; <answer> struct 
static const char * const cao_state[] = { "invalid", "valid" <token> <answer> }; 
<token> const char * const new_state[] = { "empty", "partial", "full" }; <answer> static 
memset(&ci, <token> sizeof(ci)); <answer> 0, 
<token> zq->online); <answer> &ci, 
if (ci.new_aes_mk_state >= '1' && ci.new_aes_mk_state <token> '3') <answer> <= 
<token> += sysfs_emit_at(buf, n, "AES NEW: %s 0x%016llx\n", <answer> n 
new_state[ci.new_aes_mk_state <token> '1'], <answer> - 
n += sysfs_emit_at(buf, n, <token> NEW: - -\n"); <answer> "AES 
if (ci.cur_aes_mk_state >= '1' && ci.cur_aes_mk_state <= <token> <answer> '2') 
<token> += sysfs_emit_at(buf, n, "AES CUR: %s 0x%016llx\n", <answer> n 
cao_state[ci.cur_aes_mk_state - <token> <answer> '1'], 
n += sysfs_emit_at(buf, n, "AES <token> - -\n"); <answer> CUR: 
if <token> >= '1' && ci.old_aes_mk_state <= '2') <answer> (ci.old_aes_mk_state 
n += sysfs_emit_at(buf, n, "AES <token> %s 0x%016llx\n", <answer> OLD: 
<token> - '1'], <answer> cao_state[ci.old_aes_mk_state 
<token> += sysfs_emit_at(buf, n, "AES OLD: - -\n"); <answer> n 
if (ci.new_apka_mk_state >= '1' <token> ci.new_apka_mk_state <= '3') <answer> && 
n += <token> n, "APKA NEW: %s 0x%016llx\n", <answer> sysfs_emit_at(buf, 
new_state[ci.new_apka_mk_state <token> '1'], <answer> - 
n += sysfs_emit_at(buf, <token> "APKA NEW: - -\n"); <answer> n, 
if (ci.cur_apka_mk_state >= '1' && ci.cur_apka_mk_state <token> '2') <answer> <= 
n += <token> n, "APKA CUR: %s 0x%016llx\n", <answer> sysfs_emit_at(buf, 
cao_state[ci.cur_apka_mk_state - <token> <answer> '1'], 
n += sysfs_emit_at(buf, n, "APKA CUR: <token> -\n"); <answer> - 
if (ci.old_apka_mk_state >= '1' <token> ci.old_apka_mk_state <= '2') <answer> && 
<token> += sysfs_emit_at(buf, n, "APKA OLD: %s 0x%016llx\n", <answer> n 
<token> - '1'], <answer> cao_state[ci.old_apka_mk_state 
n += sysfs_emit_at(buf, n, "APKA OLD: - <token> <answer> -\n"); 
if (ci.new_asym_mk_state >= '1' && <token> <= '3') <answer> ci.new_asym_mk_state 
n += sysfs_emit_at(buf, <token> "ASYM NEW: %s 0x%016llx%016llx\n", <answer> n, 
<token> - '1'], <answer> new_state[ci.new_asym_mk_state 
<token> *)(ci.new_asym_mkvp)), <answer> *((u64 
*((u64 *)(ci.new_asym_mkvp + <token> <answer> sizeof(u64)))); 
n += sysfs_emit_at(buf, n, <token> NEW: - -\n"); <answer> "ASYM 
if (ci.cur_asym_mk_state <token> '1' && ci.cur_asym_mk_state <= '2') <answer> >= 
n += <token> n, "ASYM CUR: %s 0x%016llx%016llx\n", <answer> sysfs_emit_at(buf, 
cao_state[ci.cur_asym_mk_state <token> '1'], <answer> - 
<token> *)(ci.cur_asym_mkvp)), <answer> *((u64 
<token> *)(ci.cur_asym_mkvp + sizeof(u64)))); <answer> *((u64 
n += sysfs_emit_at(buf, <token> "ASYM CUR: - -\n"); <answer> n, 
if (ci.old_asym_mk_state <token> '1' && ci.old_asym_mk_state <= '2') <answer> >= 
n += sysfs_emit_at(buf, n, "ASYM OLD: %s <token> <answer> 0x%016llx%016llx\n", 
<token> - '1'], <answer> cao_state[ci.old_asym_mk_state 
*((u64 <token> <answer> *)(ci.old_asym_mkvp)), 
<token> *)(ci.old_asym_mkvp + sizeof(u64)))); <answer> *((u64 
n += sysfs_emit_at(buf, n, <token> OLD: - -\n"); <answer> "ASYM 
<token> n; <answer> return 
<token> struct device_attribute dev_attr_cca_mkvps = <answer> static 
__ATTR(mkvps, 0444, cca_mkvps_show, <token> <answer> NULL); 
<token> struct attribute *cca_queue_attrs[] = { <answer> static 
static <token> struct attribute_group cca_queue_attr_grp = { <answer> const 
<token> = cca_queue_attrs, <answer> .attrs 
static ssize_t ep11_api_ordinalnr_show(struct <token> *dev, <answer> device 
<token> device_attribute *attr, <answer> struct 
<token> *buf) <answer> char 
struct <token> *zc = dev_get_drvdata(dev); <answer> zcrypt_card 
<token> ep11_card_info ci; <answer> struct 
struct ap_card *ac <token> to_ap_card(dev); <answer> = 
memset(&ci, 0, <token> <answer> sizeof(ci)); 
<token> &ci, zc->online); <answer> ep11_get_card_info(ac->id, 
if (ci.API_ord_nr <token> 0) <answer> > 
return sysfs_emit(buf, <token> ci.API_ord_nr); <answer> "%u\n", 
<token> sysfs_emit(buf, "\n"); <answer> return 
static struct <token> dev_attr_ep11_api_ordinalnr = <answer> device_attribute 
__ATTR(API_ordinalnr, <token> ep11_api_ordinalnr_show, NULL); <answer> 0444, 
static ssize_t ep11_fw_version_show(struct <token> *dev, <answer> device 
<token> device_attribute *attr, <answer> struct 
char <token> <answer> *buf) 
<token> zcrypt_card *zc = dev_get_drvdata(dev); <answer> struct 
struct <token> ci; <answer> ep11_card_info 
struct <token> *ac = to_ap_card(dev); <answer> ap_card 
memset(&ci, <token> sizeof(ci)); <answer> 0, 
ep11_get_card_info(ac->id, &ci, <token> <answer> zc->online); 
<token> (ci.FW_version > 0) <answer> if 
<token> sysfs_emit(buf, "%d.%d\n", <answer> return 
<token> >> 8), <answer> (int)(ci.FW_version 
(int)(ci.FW_version <token> 0xFF)); <answer> & 
<token> sysfs_emit(buf, "\n"); <answer> return 
static struct device_attribute dev_attr_ep11_fw_version <token> <answer> = 
__ATTR(FW_version, 0444, <token> NULL); <answer> ep11_fw_version_show, 
<token> ssize_t ep11_serialnr_show(struct device *dev, <answer> static 
struct <token> *attr, <answer> device_attribute 
<token> *buf) <answer> char 
struct zcrypt_card *zc = <token> <answer> dev_get_drvdata(dev); 
<token> ep11_card_info ci; <answer> struct 
struct <token> *ac = to_ap_card(dev); <answer> ap_card 
<token> 0, sizeof(ci)); <answer> memset(&ci, 
ep11_get_card_info(ac->id, &ci, <token> <answer> zc->online); 
if <token> <answer> (ci.serial[0]) 
return sysfs_emit(buf, <token> ci.serial); <answer> "%16.16s\n", 
<token> sysfs_emit(buf, "\n"); <answer> return 
static <token> device_attribute dev_attr_ep11_serialnr = <answer> struct 
__ATTR(serialnr, 0444, ep11_serialnr_show, <token> <answer> NULL); 
static const struct <token> <answer> { 
int <token> <answer> mode_bit; 
<token> char *mode_txt; <answer> const 
} ep11_op_modes[] = <token> <answer> { 
{ <token> "FIPS2009" }, <answer> 0, 
{ <token> "BSI2009" }, <answer> 1, 
{ 2, <token> }, <answer> "FIPS2011" 
{ 3, <token> }, <answer> "BSI2011" 
{ 4, "SIGG-IMPORT" <token> <answer> }, 
<token> 5, "SIGG" }, <answer> { 
<token> 6, "BSICC2017" }, <answer> { 
{ 7, "FIPS2021" <token> <answer> }, 
{ 8, <token> }, <answer> "FIPS2024" 
{ <token> NULL } <answer> 0, 
static ssize_t ep11_card_op_modes_show(struct <token> *dev, <answer> device 
struct <token> *attr, <answer> device_attribute 
<token> *buf) <answer> char 
struct zcrypt_card *zc <token> dev_get_drvdata(dev); <answer> = 
int i, n <token> 0; <answer> = 
<token> ep11_card_info ci; <answer> struct 
struct ap_card *ac <token> to_ap_card(dev); <answer> = 
memset(&ci, 0, <token> <answer> sizeof(ci)); 
ep11_get_card_info(ac->id, <token> zc->online); <answer> &ci, 
for (i = <token> ep11_op_modes[i].mode_txt; i++) { <answer> 0; 
<token> (ci.op_mode & (1ULL << ep11_op_modes[i].mode_bit)) { <answer> if 
if (n <token> 0) <answer> > 
buf[n++] = <token> '; <answer> ' 
n += <token> n, "%s", <answer> sysfs_emit_at(buf, 
<token> += sysfs_emit_at(buf, n, "\n"); <answer> n 
<token> n; <answer> return 
static struct <token> dev_attr_ep11_card_op_modes = <answer> device_attribute 
__ATTR(op_modes, <token> ep11_card_op_modes_show, NULL); <answer> 0444, 
static struct attribute *ep11_card_attrs[] = <token> <answer> { 
static const <token> attribute_group ep11_card_attr_grp = { <answer> struct 
.attrs = <token> <answer> ep11_card_attrs, 
<token> ssize_t ep11_mkvps_show(struct device *dev, <answer> static 
struct device_attribute <token> <answer> *attr, 
char <token> <answer> *buf) 
struct <token> *zq = dev_get_drvdata(dev); <answer> zcrypt_queue 
<token> n = 0; <answer> int 
struct <token> di; <answer> ep11_domain_info 
static const char * <token> cwk_state[] = { "invalid", "valid" }; <answer> const 
static const char <token> const nwk_state[] = { "empty", "uncommitted", <answer> * 
<token> }; <answer> "committed" 
memset(&di, 0, <token> <answer> sizeof(di)); 
<token> (zq->online) <answer> if 
if (di.cur_wk_state == <token> { <answer> '0') 
n <token> sysfs_emit(buf, "WK CUR: %s -\n", <answer> = 
cwk_state[di.cur_wk_state <token> '0']); <answer> - 
} else <token> (di.cur_wk_state == '1') { <answer> if 
n = sysfs_emit(buf, <token> CUR: %s 0x", <answer> "WK 
cwk_state[di.cur_wk_state <token> '0']); <answer> - 
bin2hex(buf + <token> di.cur_wkvp, sizeof(di.cur_wkvp)); <answer> n, 
n += <token> * sizeof(di.cur_wkvp); <answer> 2 
n += sysfs_emit_at(buf, <token> "\n"); <answer> n, 
<token> else { <answer> } 
n = <token> "WK CUR: - -\n"); <answer> sysfs_emit(buf, 
if (di.new_wk_state <token> '0') { <answer> == 
n <token> sysfs_emit_at(buf, n, "WK NEW: %s -\n", <answer> += 
<token> - '0']); <answer> nwk_state[di.new_wk_state 
} else if (di.new_wk_state <token> '1' && di.new_wk_state <= '2') { <answer> >= 
<token> += sysfs_emit_at(buf, n, "WK NEW: %s 0x", <answer> n 
<token> - '0']); <answer> nwk_state[di.new_wk_state 
<token> + n, di.new_wkvp, sizeof(di.new_wkvp)); <answer> bin2hex(buf 
n += 2 <token> sizeof(di.new_wkvp); <answer> * 
n += sysfs_emit_at(buf, n, <token> <answer> "\n"); 
} else <token> <answer> { 
<token> += sysfs_emit_at(buf, n, "WK NEW: - -\n"); <answer> n 
<token> n; <answer> return 
static struct <token> dev_attr_ep11_mkvps = <answer> device_attribute 
__ATTR(mkvps, <token> ep11_mkvps_show, NULL); <answer> 0444, 
static ssize_t ep11_queue_op_modes_show(struct <token> *dev, <answer> device 
struct <token> *attr, <answer> device_attribute 
<token> *buf) <answer> char 
struct <token> *zq = dev_get_drvdata(dev); <answer> zcrypt_queue 
int <token> n = 0; <answer> i, 
<token> ep11_domain_info di; <answer> struct 
<token> 0, sizeof(di)); <answer> memset(&di, 
<token> (zq->online) <answer> if 
for (i <token> 0; ep11_op_modes[i].mode_txt; i++) { <answer> = 
if (di.op_mode & (1ULL << ep11_op_modes[i].mode_bit)) <token> <answer> { 
if (n > <token> <answer> 0) 
buf[n++] = ' <token> <answer> '; 
n += <token> n, "%s", <answer> sysfs_emit_at(buf, 
<token> += sysfs_emit_at(buf, n, "\n"); <answer> n 
<token> n; <answer> return 
<token> struct device_attribute dev_attr_ep11_queue_op_modes = <answer> static 
__ATTR(op_modes, 0444, ep11_queue_op_modes_show, <token> <answer> NULL); 
static struct attribute <token> = { <answer> *ep11_queue_attrs[] 
static const struct attribute_group <token> = { <answer> ep11_queue_attr_grp 
.attrs = <token> <answer> ep11_queue_attrs, 
<token> int zcrypt_cex4_card_probe(struct ap_device *ap_dev) <answer> static 
static const int <token> = { <answer> CEX4A_SPEED_IDX[NUM_OPS] 
14, 19, 249, <token> 228, 1458, 0, 0}; <answer> 42, 
<token> const int CEX5A_SPEED_IDX[NUM_OPS] = { <answer> static 
8, 9, <token> 18, 66, 458, 0, 0}; <answer> 20, 
static <token> int CEX6A_SPEED_IDX[NUM_OPS] = { <answer> const 
<token> 9, 20, 17, 65, 438, 0, 0}; <answer> 6, 
<token> const int CEX7A_SPEED_IDX[NUM_OPS] = { <answer> static 
6, 8, 17, 15, 54, 362, <token> 0}; <answer> 0, 
static const <token> CEX8A_SPEED_IDX[NUM_OPS] = { <answer> int 
6, 8, 17, 15, 54, <token> 0, 0}; <answer> 362, 
static const int CEX4C_SPEED_IDX[NUM_OPS] <token> { <answer> = 
59, 69, <token> 83, 278, 2204, 209, 40}; <answer> 308, 
static <token> int CEX5C_SPEED_IDX[] = { <answer> const 
24, 31, 50, 37, <token> 479, 27, 10}; <answer> 90, 
static const int <token> = { <answer> CEX6C_SPEED_IDX[NUM_OPS] 
16, 20, 32, 27, <token> 455, 24, 9}; <answer> 77, 
static <token> int CEX7C_SPEED_IDX[NUM_OPS] = { <answer> const 
14, 16, 26, <token> 64, 376, 23, 8}; <answer> 23, 
<token> const int CEX8C_SPEED_IDX[NUM_OPS] = { <answer> static 
14, <token> 26, 23, 64, 376, 23, 8}; <answer> 16, 
static const int CEX4P_SPEED_IDX[NUM_OPS] = <token> <answer> { 
0, 0, 0, <token> 0, 0, 0, 50}; <answer> 0, 
static const int <token> = { <answer> CEX5P_SPEED_IDX[NUM_OPS] 
0, 0, 0, 0, 0, 0, <token> 10}; <answer> 0, 
static const int <token> = { <answer> CEX6P_SPEED_IDX[NUM_OPS] 
0, 0, 0, 0, <token> 0, 0, 9}; <answer> 0, 
static const int <token> = { <answer> CEX7P_SPEED_IDX[NUM_OPS] 
0, 0, 0, 0, 0, 0, <token> 8}; <answer> 0, 
static <token> int CEX8P_SPEED_IDX[NUM_OPS] = { <answer> const 
<token> 0, 0, 0, 0, 0, 0, 8}; <answer> 0, 
struct <token> *ac = to_ap_card(&ap_dev->device); <answer> ap_card 
<token> zcrypt_card *zc; <answer> struct 
<token> rc = 0; <answer> int 
<token> = zcrypt_card_alloc(); <answer> zc 
if <token> <answer> (!zc) 
return <token> <answer> -ENOMEM; 
<token> = ac; <answer> zc->card 
dev_set_drvdata(&ap_dev->device, <token> <answer> zc); 
<token> (ac->hwinfo.accel) { <answer> if 
if (ac->ap_dev.device_type <token> AP_DEVICE_TYPE_CEX4) { <answer> == 
<token> = "CEX4A"; <answer> zc->type_string 
zc->user_space_type = <token> <answer> ZCRYPT_CEX4; 
zc->speed_rating = <token> <answer> CEX4A_SPEED_IDX; 
} else if (ac->ap_dev.device_type <token> AP_DEVICE_TYPE_CEX5) { <answer> == 
zc->type_string = <token> <answer> "CEX5A"; 
zc->user_space_type = <token> <answer> ZCRYPT_CEX5; 
<token> = CEX5A_SPEED_IDX; <answer> zc->speed_rating 
} else if (ac->ap_dev.device_type == <token> { <answer> AP_DEVICE_TYPE_CEX6) 
<token> = "CEX6A"; <answer> zc->type_string 
zc->user_space_type = <token> <answer> ZCRYPT_CEX6; 
zc->speed_rating = <token> <answer> CEX6A_SPEED_IDX; 
} else if <token> == AP_DEVICE_TYPE_CEX7) { <answer> (ac->ap_dev.device_type 
zc->type_string = <token> <answer> "CEX7A"; 
<token> = CEX7A_SPEED_IDX; <answer> zc->speed_rating 
<token> = ZCRYPT_CEX6; <answer> zc->user_space_type 
} else <token> <answer> { 
<token> = "CEX8A"; <answer> zc->type_string 
zc->speed_rating = <token> <answer> CEX8A_SPEED_IDX; 
zc->user_space_type <token> ZCRYPT_CEX6; <answer> = 
<token> = CEX4A_MIN_MOD_SIZE; <answer> zc->min_mod_size 
if (ac->hwinfo.mex4k <token> ac->hwinfo.crt4k) { <answer> && 
zc->max_mod_size = <token> <answer> CEX4A_MAX_MOD_SIZE_4K; 
zc->max_exp_bit_length <token> <answer> = 
} else <token> <answer> { 
zc->max_mod_size = <token> <answer> CEX4A_MAX_MOD_SIZE_2K; 
zc->max_exp_bit_length <token> <answer> = 
} <token> if (ac->hwinfo.cca) { <answer> else 
if <token> == AP_DEVICE_TYPE_CEX4) { <answer> (ac->ap_dev.device_type 
<token> = "CEX4C"; <answer> zc->type_string 
zc->speed_rating <token> CEX4C_SPEED_IDX; <answer> = 
<token> = ZCRYPT_CEX3C; <answer> zc->user_space_type 
} else <token> (ac->ap_dev.device_type == AP_DEVICE_TYPE_CEX5) { <answer> if 
zc->type_string = <token> <answer> "CEX5C"; 
<token> = CEX5C_SPEED_IDX; <answer> zc->speed_rating 
zc->user_space_type <token> ZCRYPT_CEX3C; <answer> = 
} else if (ac->ap_dev.device_type == <token> { <answer> AP_DEVICE_TYPE_CEX6) 
zc->type_string <token> "CEX6C"; <answer> = 
zc->speed_rating = <token> <answer> CEX6C_SPEED_IDX; 
<token> = ZCRYPT_CEX3C; <answer> zc->user_space_type 
} else if (ac->ap_dev.device_type == AP_DEVICE_TYPE_CEX7) <token> <answer> { 
zc->type_string = <token> <answer> "CEX7C"; 
<token> = CEX7C_SPEED_IDX; <answer> zc->speed_rating 
zc->user_space_type <token> ZCRYPT_CEX3C; <answer> = 
} <token> { <answer> else 
<token> = "CEX8C"; <answer> zc->type_string 
<token> = CEX8C_SPEED_IDX; <answer> zc->speed_rating 
zc->user_space_type = <token> <answer> ZCRYPT_CEX3C; 
zc->min_mod_size = <token> <answer> CEX4C_MIN_MOD_SIZE; 
<token> = CEX4C_MAX_MOD_SIZE; <answer> zc->max_mod_size 
<token> = CEX4C_MAX_MOD_SIZE; <answer> zc->max_exp_bit_length 
} else if <token> { <answer> (ac->hwinfo.ep11) 
<token> (ac->ap_dev.device_type == AP_DEVICE_TYPE_CEX4) { <answer> if 
<token> = "CEX4P"; <answer> zc->type_string 
<token> = ZCRYPT_CEX4; <answer> zc->user_space_type 
zc->speed_rating = <token> <answer> CEX4P_SPEED_IDX; 
<token> else if (ac->ap_dev.device_type == AP_DEVICE_TYPE_CEX5) { <answer> } 
<token> = "CEX5P"; <answer> zc->type_string 
zc->user_space_type = <token> <answer> ZCRYPT_CEX5; 
<token> = CEX5P_SPEED_IDX; <answer> zc->speed_rating 
} else if <token> == AP_DEVICE_TYPE_CEX6) { <answer> (ac->ap_dev.device_type 
<token> = "CEX6P"; <answer> zc->type_string 
<token> = ZCRYPT_CEX6; <answer> zc->user_space_type 
zc->speed_rating <token> CEX6P_SPEED_IDX; <answer> = 
} else if (ac->ap_dev.device_type <token> AP_DEVICE_TYPE_CEX7) { <answer> == 
<token> = "CEX7P"; <answer> zc->type_string 
<token> = CEX7P_SPEED_IDX; <answer> zc->speed_rating 
<token> = ZCRYPT_CEX6; <answer> zc->user_space_type 
} <token> { <answer> else 
<token> = "CEX8P"; <answer> zc->type_string 
zc->speed_rating <token> CEX8P_SPEED_IDX; <answer> = 
<token> = ZCRYPT_CEX6; <answer> zc->user_space_type 
<token> = CEX4C_MIN_MOD_SIZE; <answer> zc->min_mod_size 
zc->max_mod_size <token> CEX4C_MAX_MOD_SIZE; <answer> = 
zc->max_exp_bit_length <token> CEX4C_MAX_MOD_SIZE; <answer> = 
} else <token> <answer> { 
return <token> <answer> -ENODEV; 
<token> = 1; <answer> zc->online 
<token> = zcrypt_card_register(zc); <answer> rc 
if (rc) <token> <answer> { 
return <token> <answer> rc; 
if <token> { <answer> (ac->hwinfo.cca) 
rc = <token> <answer> sysfs_create_group(&ap_dev->device.kobj, 
if (rc) <token> <answer> { 
} <token> if (ac->hwinfo.ep11) { <answer> else 
<token> = sysfs_create_group(&ap_dev->device.kobj, <answer> rc 
<token> (rc) { <answer> if 
return <token> <answer> rc; 
static void zcrypt_cex4_card_remove(struct <token> *ap_dev) <answer> ap_device 
struct zcrypt_card *zc <token> dev_get_drvdata(&ap_dev->device); <answer> = 
struct ap_card *ac = <token> <answer> to_ap_card(&ap_dev->device); 
<token> (ac->hwinfo.cca) <answer> if 
<token> &cca_card_attr_grp); <answer> sysfs_remove_group(&ap_dev->device.kobj, 
else <token> (ac->hwinfo.ep11) <answer> if 
sysfs_remove_group(&ap_dev->device.kobj, <token> <answer> &ep11_card_attr_grp); 
static struct ap_driver zcrypt_cex4_card_driver <token> { <answer> = 
.probe = <token> <answer> zcrypt_cex4_card_probe, 
.remove = <token> <answer> zcrypt_cex4_card_remove, 
<token> = zcrypt_cex4_card_ids, <answer> .ids 
.flags <token> AP_DRIVER_FLAG_DEFAULT, <answer> = 
static int <token> ap_device *ap_dev) <answer> zcrypt_cex4_queue_probe(struct 
<token> ap_queue *aq = to_ap_queue(&ap_dev->device); <answer> struct 
struct <token> *zq; <answer> zcrypt_queue 
int <token> <answer> rc; 
<token> (aq->card->hwinfo.accel) { <answer> if 
zq = <token> <answer> zcrypt_queue_alloc(aq->card->maxmsgsize); 
if <token> <answer> (!zq) 
<token> -ENOMEM; <answer> return 
zq->ops <token> zcrypt_msgtype(MSGTYPE50_NAME, <answer> = 
} else if (aq->card->hwinfo.cca) <token> <answer> { 
zq <token> zcrypt_queue_alloc(aq->card->maxmsgsize); <answer> = 
<token> (!zq) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = zcrypt_msgtype(MSGTYPE06_NAME, <answer> zq->ops 
} <token> if (aq->card->hwinfo.ep11) { <answer> else 
zq = <token> <answer> zcrypt_queue_alloc(aq->card->maxmsgsize); 
<token> (!zq) <answer> if 
return <token> <answer> -ENOMEM; 
zq->ops = <token> <answer> zcrypt_msgtype(MSGTYPE06_NAME, 
} <token> { <answer> else 
return <token> <answer> -ENODEV; 
zq->queue = <token> <answer> aq; 
<token> = 1; <answer> zq->online 
atomic_set(&zq->load, <token> <answer> 0); 
<token> &zq->reply); <answer> ap_queue_init_reply(aq, 
<token> = CEX4_CLEANUP_TIME; <answer> aq->request_timeout 
<token> zq); <answer> dev_set_drvdata(&ap_dev->device, 
<token> = zcrypt_queue_register(zq); <answer> rc 
<token> (rc) { <answer> if 
return <token> <answer> rc; 
if <token> { <answer> (aq->card->hwinfo.cca) 
rc <token> sysfs_create_group(&ap_dev->device.kobj, <answer> = 
<token> (rc) { <answer> if 
} else if <token> { <answer> (aq->card->hwinfo.ep11) 
rc <token> sysfs_create_group(&ap_dev->device.kobj, <answer> = 
<token> (rc) { <answer> if 
<token> rc; <answer> return 
static void zcrypt_cex4_queue_remove(struct <token> *ap_dev) <answer> ap_device 
struct zcrypt_queue *zq <token> dev_get_drvdata(&ap_dev->device); <answer> = 
<token> ap_queue *aq = to_ap_queue(&ap_dev->device); <answer> struct 
<token> (aq->card->hwinfo.cca) <answer> if 
<token> &cca_queue_attr_grp); <answer> sysfs_remove_group(&ap_dev->device.kobj, 
<token> if (aq->card->hwinfo.ep11) <answer> else 
sysfs_remove_group(&ap_dev->device.kobj, <token> <answer> &ep11_queue_attr_grp); 
static struct ap_driver zcrypt_cex4_queue_driver = <token> <answer> { 
.probe <token> zcrypt_cex4_queue_probe, <answer> = 
.remove = <token> <answer> zcrypt_cex4_queue_remove, 
.ids = <token> <answer> zcrypt_cex4_queue_ids, 
<token> = AP_DRIVER_FLAG_DEFAULT, <answer> .flags 
int __init <token> <answer> zcrypt_cex4_init(void) 
int <token> <answer> rc; 
rc <token> ap_driver_register(&zcrypt_cex4_card_driver, <answer> = 
<token> "cex4card"); <answer> THIS_MODULE, 
<token> (rc) <answer> if 
return <token> <answer> rc; 
rc <token> ap_driver_register(&zcrypt_cex4_queue_driver, <answer> = 
<token> "cex4queue"); <answer> THIS_MODULE, 
<token> (rc) <answer> if 
return <token> <answer> rc; 
void <token> zcrypt_cex4_exit(void) <answer> __exit 
#include <token> <answer> <linux/module.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
<token> <linux/input.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/workqueue.h> <answer> #include 
<token> <linux/spi/spi.h> <answer> #include 
<token> <linux/pm.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_platform.h> 
#include <token> <answer> <linux/of_device.h> 
#include <token> <answer> "lis3lv02d.h" 
#define <token> "lis3lv02d_spi" <answer> DRV_NAME 
<token> LIS3_SPI_READ 0x80 <answer> #define 
static int lis3_spi_read(struct lis3lv02d *lis3, int reg, u8 <token> <answer> *v) 
struct spi_device *spi <token> lis3->bus_priv; <answer> = 
<token> ret = spi_w8r8(spi, reg | LIS3_SPI_READ); <answer> int 
if <token> < 0) <answer> (ret 
return <token> <answer> -EINVAL; 
*v <token> (u8) ret; <answer> = 
<token> 0; <answer> return 
static <token> lis3_spi_write(struct lis3lv02d *lis3, int reg, u8 val) <answer> int 
u8 tmp[2] = { reg, <token> }; <answer> val 
struct spi_device *spi <token> lis3->bus_priv; <answer> = 
return spi_write(spi, <token> sizeof(tmp)); <answer> tmp, 
static int lis3_spi_init(struct <token> *lis3) <answer> lis3lv02d 
u8 <token> <answer> reg; 
int <token> <answer> ret; 
<token> "amdgpu.h" <answer> #include 
#include <token> <answer> "mmhub_v3_3.h" 
#include <token> <answer> "mmhub/mmhub_3_3_0_offset.h" 
#include <token> <answer> "mmhub/mmhub_3_3_0_sh_mask.h" 
<token> "navi10_enum.h" <answer> #include 
<token> "soc15_common.h" <answer> #include 
#define regMMVM_L2_CNTL3_DEFAULT <token> <answer> 0x80100007 
<token> regMMVM_L2_CNTL4_DEFAULT 0x000000c1 <answer> #define 
#define <token> 0x00003fe0 <answer> regMMVM_L2_CNTL5_DEFAULT 
static const char <token> = { <answer> *mmhub_client_ids_v3_3[][2] 
[0][0] = <token> <answer> "VMC", 
<token> = "DCEDMC", <answer> [4][0] 
[6][0] = <token> <answer> "MP0", 
[7][0] <token> "MP1", <answer> = 
[8][0] <token> "MPM", <answer> = 
<token> = "HDP", <answer> [24][0] 
[25][0] = <token> <answer> "LSDMA", 
[26][0] = <token> <answer> "JPEG", 
<token> = "VPE", <answer> [27][0] 
[29][0] <token> "VCNU", <answer> = 
<token> = "VCN", <answer> [30][0] 
[3][1] = <token> <answer> "DCEDWB", 
<token> = "DCEDMC", <answer> [4][1] 
[6][1] <token> "MP0", <answer> = 
[7][1] <token> "MP1", <answer> = 
<token> = "MPM", <answer> [8][1] 
[21][1] = <token> <answer> "OSSSYS", 
[24][1] = <token> <answer> "HDP", 
[25][1] <token> "LSDMA", <answer> = 
[26][1] = <token> <answer> "JPEG", 
[27][1] = <token> <answer> "VPE", 
[29][1] <token> "VCNU", <answer> = 
[30][1] = <token> <answer> "VCN", 
static <token> mmhub_v3_3_get_invalidate_req(unsigned int vmid, <answer> uint32_t 
uint32_t <token> <answer> flush_type) 
u32 <token> = 0; <answer> req 
<token> void mmhub_v3_3_set_fault_enable_default(struct amdgpu_device *adev, <answer> static 
<token> value) <answer> bool 
u32 <token> <answer> tmp; 
<token> = RREG32_SOC15(MMHUB, 0, regMMVM_L2_PROTECTION_FAULT_CNTL); <answer> tmp 
<token> = REG_SET_FIELD(tmp, MMVM_L2_PROTECTION_FAULT_CNTL, <answer> tmp 
<token> value); <answer> RANGE_PROTECTION_FAULT_ENABLE_DEFAULT, 
tmp = REG_SET_FIELD(tmp, <token> <answer> MMVM_L2_PROTECTION_FAULT_CNTL, 
PDE0_PROTECTION_FAULT_ENABLE_DEFAULT, <token> <answer> value); 
tmp = REG_SET_FIELD(tmp, <token> <answer> MMVM_L2_PROTECTION_FAULT_CNTL, 
<token> value); <answer> PDE1_PROTECTION_FAULT_ENABLE_DEFAULT, 
<token> = REG_SET_FIELD(tmp, MMVM_L2_PROTECTION_FAULT_CNTL, <answer> tmp 
<token> value); <answer> PDE2_PROTECTION_FAULT_ENABLE_DEFAULT, 
tmp = REG_SET_FIELD(tmp, <token> <answer> MMVM_L2_PROTECTION_FAULT_CNTL, 
tmp <token> REG_SET_FIELD(tmp, MMVM_L2_PROTECTION_FAULT_CNTL, <answer> = 
<token> value); <answer> NACK_PROTECTION_FAULT_ENABLE_DEFAULT, 
tmp = <token> MMVM_L2_PROTECTION_FAULT_CNTL, <answer> REG_SET_FIELD(tmp, 
<token> value); <answer> DUMMY_PAGE_PROTECTION_FAULT_ENABLE_DEFAULT, 
tmp <token> REG_SET_FIELD(tmp, MMVM_L2_PROTECTION_FAULT_CNTL, <answer> = 
VALID_PROTECTION_FAULT_ENABLE_DEFAULT, <token> <answer> value); 
<token> = REG_SET_FIELD(tmp, MMVM_L2_PROTECTION_FAULT_CNTL, <answer> tmp 
READ_PROTECTION_FAULT_ENABLE_DEFAULT, <token> <answer> value); 
<token> = REG_SET_FIELD(tmp, MMVM_L2_PROTECTION_FAULT_CNTL, <answer> tmp 
WRITE_PROTECTION_FAULT_ENABLE_DEFAULT, <token> <answer> value); 
tmp = <token> MMVM_L2_PROTECTION_FAULT_CNTL, <answer> REG_SET_FIELD(tmp, 
<token> value); <answer> EXECUTE_PROTECTION_FAULT_ENABLE_DEFAULT, 
<token> (!value) { <answer> if 
tmp <token> REG_SET_FIELD(tmp, MMVM_L2_PROTECTION_FAULT_CNTL, <answer> = 
<token> 1); <answer> CRASH_ON_NO_RETRY_FAULT, 
tmp = <token> MMVM_L2_PROTECTION_FAULT_CNTL, <answer> REG_SET_FIELD(tmp, 
CRASH_ON_RETRY_FAULT, <token> <answer> 1); 
WREG32_SOC15(MMHUB, 0, regMMVM_L2_PROTECTION_FAULT_CNTL, <token> <answer> tmp); 
static const struct <token> mmhub_v3_3_vmhub_funcs = { <answer> amdgpu_vmhub_funcs 
.print_l2_protection_fault_status <token> mmhub_v3_3_print_l2_protection_fault_status, <answer> = 
.get_invalidate_req = <token> <answer> mmhub_v3_3_get_invalidate_req, 
static void <token> amdgpu_device *adev) <answer> mmhub_v3_3_init(struct 
struct amdgpu_vmhub <token> = &adev->vmhub[AMDGPU_MMHUB0(0)]; <answer> *hub 
<token> = <answer> hub->ctx0_ptb_addr_lo32 
SOC15_REG_OFFSET(MMHUB, <token> <answer> 0, 
<token> = <answer> hub->ctx0_ptb_addr_hi32 
SOC15_REG_OFFSET(MMHUB, <token> <answer> 0, 
hub->vm_inv_eng0_sem <token> <answer> = 
SOC15_REG_OFFSET(MMHUB, <token> regMMVM_INVALIDATE_ENG0_SEM); <answer> 0, 
<token> = <answer> hub->vm_inv_eng0_req 
SOC15_REG_OFFSET(MMHUB, <token> regMMVM_INVALIDATE_ENG0_REQ); <answer> 0, 
hub->vm_inv_eng0_ack <token> <answer> = 
SOC15_REG_OFFSET(MMHUB, 0, <token> <answer> regMMVM_INVALIDATE_ENG0_ACK); 
<token> = <answer> hub->vm_context0_cntl 
<token> 0, regMMVM_CONTEXT0_CNTL); <answer> SOC15_REG_OFFSET(MMHUB, 
<token> = <answer> hub->vm_l2_pro_fault_status 
SOC15_REG_OFFSET(MMHUB, <token> regMMVM_L2_PROTECTION_FAULT_STATUS); <answer> 0, 
hub->vm_l2_pro_fault_cntl <token> <answer> = 
<token> 0, regMMVM_L2_PROTECTION_FAULT_CNTL); <answer> SOC15_REG_OFFSET(MMHUB, 
<token> = regMMVM_CONTEXT1_CNTL - regMMVM_CONTEXT0_CNTL; <answer> hub->ctx_distance 
hub->ctx_addr_distance <token> regMMVM_CONTEXT1_PAGE_TABLE_BASE_ADDR_LO32 - <answer> = 
hub->eng_distance = <token> - <answer> regMMVM_INVALIDATE_ENG1_REQ 
hub->eng_addr_distance = <token> - <answer> regMMVM_INVALIDATE_ENG1_ADDR_RANGE_LO32 
hub->vm_cntx_cntl_vm_fault <token> MMVM_CONTEXT1_CNTL__RANGE_PROTECTION_FAULT_ENABLE_INTERRUPT_MASK | <answer> = 
<token> | <answer> MMVM_CONTEXT1_CNTL__DUMMY_PAGE_PROTECTION_FAULT_ENABLE_INTERRUPT_MASK 
MMVM_CONTEXT1_CNTL__PDE0_PROTECTION_FAULT_ENABLE_INTERRUPT_MASK <token> <answer> | 
<token> | <answer> MMVM_CONTEXT1_CNTL__VALID_PROTECTION_FAULT_ENABLE_INTERRUPT_MASK 
<token> | <answer> MMVM_CONTEXT1_CNTL__READ_PROTECTION_FAULT_ENABLE_INTERRUPT_MASK 
<token> | <answer> MMVM_CONTEXT1_CNTL__WRITE_PROTECTION_FAULT_ENABLE_INTERRUPT_MASK 
hub->vmhub_funcs = <token> <answer> &mmhub_v3_3_vmhub_funcs; 
static u64 mmhub_v3_3_get_fb_location(struct <token> *adev) <answer> amdgpu_device 
<token> base; <answer> u64 
base = <token> 0, regMMMC_VM_FB_LOCATION_BASE); <answer> RREG32_SOC15(MMHUB, 
base <token> MMMC_VM_FB_LOCATION_BASE__FB_BASE_MASK; <answer> &= 
base <<= <token> <answer> 24; 
<token> base; <answer> return 
static u64 <token> amdgpu_device *adev) <answer> mmhub_v3_3_get_mc_fb_offset(struct 
<token> offset; <answer> u64 
offset = <token> 0, regMMMC_VM_FB_OFFSET); <answer> RREG32_SOC15(MMHUB, 
<token> &= MMMC_VM_FB_OFFSET__FB_OFFSET_MASK; <answer> offset 
offset <token> 24; <answer> <<= 
return <token> <answer> offset; 
static void <token> amdgpu_device *adev, <answer> mmhub_v3_3_update_medium_grain_clock_gating(struct 
bool <token> <answer> enable) 
<token> def, data; <answer> uint32_t 
def = data = <token> 0, regMM_ATC_L2_MISC_CG); <answer> RREG32_SOC15(MMHUB, 
<token> (enable) <answer> if 
data |= <token> <answer> MM_ATC_L2_MISC_CG__ENABLE_MASK; 
data &= <token> <answer> ~MM_ATC_L2_MISC_CG__ENABLE_MASK; 
if <token> != data) <answer> (def 
<token> 0, regMM_ATC_L2_MISC_CG, data); <answer> WREG32_SOC15(MMHUB, 
static void <token> amdgpu_device *adev, <answer> mmhub_v3_3_update_medium_grain_light_sleep(struct 
<token> enable) <answer> bool 
uint32_t <token> data; <answer> def, 
def = data = RREG32_SOC15(MMHUB, <token> regMM_ATC_L2_MISC_CG); <answer> 0, 
<token> (enable) <answer> if 
<token> |= MM_ATC_L2_MISC_CG__MEM_LS_ENABLE_MASK; <answer> data 
data <token> ~MM_ATC_L2_MISC_CG__MEM_LS_ENABLE_MASK; <answer> &= 
if (def <token> data) <answer> != 
WREG32_SOC15(MMHUB, 0, regMM_ATC_L2_MISC_CG, <token> <answer> data); 
static int mmhub_v3_3_set_clockgating(struct amdgpu_device <token> <answer> *adev, 
<token> amd_clockgating_state state) <answer> enum 
<token> (amdgpu_sriov_vf(adev)) <answer> if 
<token> 0; <answer> return 
state <token> AMD_CG_STATE_GATE); <answer> == 
state <token> AMD_CG_STATE_GATE); <answer> == 
return <token> <answer> 0; 
static void <token> amdgpu_device *adev, u64 *flags) <answer> mmhub_v3_3_get_clockgating(struct 
int <token> <answer> data; 
if <token> <answer> (amdgpu_sriov_vf(adev)) 
*flags = <token> <answer> 0; 
data = RREG32_SOC15(MMHUB, 0, <token> <answer> regMM_ATC_L2_MISC_CG); 
<token> <drv_types.h> <answer> #include 
<token> <rtw_debug.h> <answer> #include 
<token> <hal_btcoex.h> <answer> #include 
<token> <linux/jiffies.h> <answer> #include 
#ifndef <token> <answer> dev_to_sdio_func 
#define dev_to_sdio_func(d) container_of(d, struct sdio_func, <token> <answer> dev) 
static const struct sdio_device_id <token> = { <answer> sdio_ids[] 
<token> SDIO_DEVICE(0x024c, 0x0523), }, <answer> { 
{ SDIO_DEVICE(0x024c, 0x0525), <token> <answer> }, 
{ SDIO_DEVICE(0x024c, <token> }, <answer> 0x0623), 
{ <token> 0x0626), }, <answer> SDIO_DEVICE(0x024c, 
{ SDIO_DEVICE(0x024c, 0x0627), <token> <answer> }, 
{ SDIO_DEVICE(0x024c, <token> }, <answer> 0xb723), 
static <token> rtw_drv_init( <answer> int 
struct <token> *func, <answer> sdio_func 
const struct <token> *id) <answer> sdio_device_id 
int <token> = _FAIL; <answer> status 
struct adapter *if1 = <token> <answer> NULL; 
struct <token> *dvobj; <answer> dvobj_priv 
<token> = sdio_dvobj_init(func); <answer> dvobj 
<token> (!dvobj) <answer> if 
goto <token> <answer> exit; 
if1 = <token> id); <answer> rtw_sdio_if1_init(dvobj, 
<token> (!if1) <answer> if 
goto <token> <answer> free_dvobj; 
#include <token> <answer> <linux/acpi.h> 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/i2c.h> 
#include <token> <answer> <linux/miscdevice.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/mutex.h> 
<token> <linux/poll.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/semaphore.h> <answer> #include 
<token> <linux/kthread.h> <answer> #include 
#include <token> <answer> <linux/wait.h> 
<token> <linux/ipmi_msgdefs.h> <answer> #include 
<token> <linux/ipmi_smi.h> <answer> #include 
<token> DEVICE_NAME "ipmi-ipmb" <answer> #define 
static int bmcaddr = <token> <answer> 0x20; 
module_param(bmcaddr, int, <token> <answer> 0644); 
MODULE_PARM_DESC(bmcaddr, "Address <token> use for BMC."); <answer> to 
static unsigned int retry_time_ms <token> 250; <answer> = 
<token> uint, 0644); <answer> module_param(retry_time_ms, 
<token> "Timeout time between retries, in milliseconds."); <answer> MODULE_PARM_DESC(retry_time_ms, 
static unsigned int max_retries <token> 1; <answer> = 
<token> uint, 0644); <answer> module_param(max_retries, 
MODULE_PARM_DESC(max_retries, "Max resends of a <token> before timing out."); <answer> command 
if (!xmit_rsp && seq <token> iidev->curr_seq) { <answer> == 
iidev->curr_seq <token> (iidev->curr_seq + 1) & 0x3f; <answer> = 
imsg = <token> <answer> iidev->working_msg; 
<token> = NULL; <answer> iidev->working_msg 
<token> flags); <answer> spin_unlock_irqrestore(&iidev->lock, 
if <token> <answer> (!imsg) 
<token> done; <answer> goto 
if (imsg->type == <token> { <answer> IPMI_SMI_MSG_TYPE_IPMB_DIRECT) 
memcpy(imsg->rsp + 1, msg + 3, iidev->rcvlen - <token> <answer> 4); 
imsg->rsp_size = iidev->rcvlen - <token> <answer> 3; 
} <token> { <answer> else 
memcpy(imsg->rsp + 1, <token> + 5, iidev->rcvlen - 6); <answer> msg 
imsg->rsp_size <token> iidev->rcvlen - 5; <answer> = 
ipmi_smi_msg_received(iidev->intf, <token> <answer> imsg); 
if <token> <answer> (!is_cmd) 
<token> = false; <answer> iidev->overrun 
iidev->rcvlen <token> 0; <answer> = 
<token> int ipmi_ipmb_slave_cb(struct i2c_client *client, <answer> static 
enum <token> event, u8 *val) <answer> i2c_slave_event 
struct ipmi_ipmb_dev *iidev <token> i2c_get_clientdata(client); <answer> = 
switch <token> { <answer> (event) 
case <token> <answer> I2C_SLAVE_WRITE_REQUESTED: 
iidev->rcvmsg[0] <token> client->addr << 1; <answer> = 
iidev->rcvlen = <token> <answer> 1; 
<token> I2C_SLAVE_WRITE_RECEIVED: <answer> case 
if (iidev->rcvlen <token> sizeof(iidev->rcvmsg)) <answer> >= 
<token> = true; <answer> iidev->overrun 
iidev->rcvmsg[iidev->rcvlen++] <token> *val; <answer> = 
<token> I2C_SLAVE_READ_REQUESTED: <answer> case 
case <token> <answer> I2C_SLAVE_STOP: 
case <token> <answer> I2C_SLAVE_READ_PROCESSED: 
<token> 0; <answer> return 
static void ipmi_ipmb_send_response(struct <token> *iidev, <answer> ipmi_ipmb_dev 
struct <token> *msg, u8 cc) <answer> ipmi_smi_msg 
if ((msg->data[0] >> 2) & <token> { <answer> 1) 
msg->data[0] <token> (IPMI_NETFN_APP_REQUEST | 1) << 2; <answer> = 
<token> = IPMI_SEND_MSG_CMD; <answer> msg->data[3] 
msg->data[4] <token> cc; <answer> = 
msg->data_size = <token> <answer> 5; 
msg->rsp[0] = <token> | (1 << 2); <answer> msg->data[0] 
if (msg->type <token> IPMI_SMI_MSG_TYPE_IPMB_DIRECT) { <answer> == 
<token> = msg->data[1]; <answer> msg->rsp[1] 
msg->rsp[2] <token> msg->data[2]; <answer> = 
<token> = msg->data[3]; <answer> msg->rsp[3] 
<token> = cc; <answer> msg->rsp[4] 
<token> = 5; <answer> msg->rsp_size 
} else <token> <answer> { 
<token> = msg->data[1]; <answer> msg->rsp[1] 
<token> = cc; <answer> msg->rsp[2] 
msg->rsp_size <token> 3; <answer> = 
<token> msg); <answer> ipmi_smi_msg_received(iidev->intf, 
static <token> ipmi_ipmb_format_for_xmit(struct ipmi_ipmb_dev *iidev, <answer> void 
struct ipmi_smi_msg <token> <answer> *msg) 
if (msg->type <token> IPMI_SMI_MSG_TYPE_IPMB_DIRECT) { <answer> == 
iidev->xmitmsg[0] <token> msg->data[1]; <answer> = 
iidev->xmitmsg[1] <token> msg->data[0]; <answer> = 
memcpy(iidev->xmitmsg + 4, msg->data + 2, msg->data_size - <token> <answer> 2); 
<token> = msg->data_size + 2; <answer> iidev->xmitlen 
} else <token> <answer> { 
iidev->xmitmsg[0] = <token> <answer> iidev->bmcaddr; 
iidev->xmitmsg[1] <token> msg->data[0]; <answer> = 
iidev->xmitmsg[4] <token> 0; <answer> = 
memcpy(iidev->xmitmsg + 5, <token> + 1, msg->data_size - 1); <answer> msg->data 
iidev->xmitlen = <token> + 4; <answer> msg->data_size 
iidev->xmitmsg[3] = iidev->slave->addr <token> 1; <answer> << 
if (((msg->data[0] >> 2) & 1) <token> 0) <answer> == 
iidev->working_msg = <token> <answer> NULL; 
<token> msg, <answer> ipmi_ipmb_send_response(iidev, 
ret < <token> ? IPMI_BUS_ERR : 0); <answer> 0 
if (ret < <token> { <answer> 0) 
<token> = NULL; <answer> iidev->working_msg 
<token> msg, IPMI_BUS_ERR); <answer> ipmi_ipmb_send_response(iidev, 
spin_lock_irqsave(&iidev->lock, <token> <answer> flags); 
<token> = iidev->working_msg; <answer> msg 
iidev->working_msg = <token> <answer> NULL; 
spin_unlock_irqrestore(&iidev->lock, <token> <answer> flags); 
if (!msg && ret) <token> <answer> { 
} else if <token> && ++retries <= iidev->max_retries) { <answer> (msg 
<token> flags); <answer> spin_lock_irqsave(&iidev->lock, 
<token> = msg; <answer> iidev->working_msg 
spin_unlock_irqrestore(&iidev->lock, <token> <answer> flags); 
<token> retry; <answer> goto 
<token> (msg) <answer> if 
ipmi_ipmb_send_response(iidev, <token> IPMI_TIMEOUT_ERR); <answer> msg, 
if <token> <answer> (iidev->next_msg) 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/err.h> 
<token> <linux/random.h> <answer> #include 
#include <token> <answer> <linux/spinlock.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/dma-mapping.h> 
#include <token> <answer> <linux/kref.h> 
#include <token> <answer> <linux/xarray.h> 
<token> <linux/workqueue.h> <answer> #include 
#include <token> <answer> <uapi/linux/if_ether.h> 
<token> <rdma/ib_pack.h> <answer> #include 
<token> <rdma/ib_cache.h> <answer> #include 
#include <token> <answer> <rdma/rdma_netlink.h> 
<token> <net/netlink.h> <answer> #include 
#include <token> <answer> <uapi/rdma/ib_user_sa.h> 
#include <token> <answer> <rdma/ib_marshall.h> 
<token> <rdma/ib_addr.h> <answer> #include 
<token> <rdma/opa_addr.h> <answer> #include 
<token> <rdma/rdma_cm.h> <answer> #include 
#include <token> <answer> "sa.h" 
#include <token> <answer> "core_priv.h" 
#define IB_SA_LOCAL_SVC_TIMEOUT_MIN <token> <answer> 100 
<token> IB_SA_LOCAL_SVC_TIMEOUT_DEFAULT 2000 <answer> #define 
#define IB_SA_LOCAL_SVC_TIMEOUT_MAX <token> <answer> 200000 
<token> IB_SA_CPI_MAX_RETRY_CNT 3 <answer> #define 
<token> (WARN_ON(len == 0)) <answer> if 
return <token> <answer> len; 
if (nlh->nlmsg_seq == iter->seq) <token> <answer> { 
if <token> { <answer> (!ib_sa_query_cancelled(iter)) 
query <token> iter; <answer> = 
if (!query) <token> <answer> { 
spin_unlock_irqrestore(&ib_nl_request_lock, <token> <answer> flags); 
goto <token> <answer> resp_out; 
<token> = query->mad_buf; <answer> send_buf 
<token> (!ib_nl_is_good_resolve_resp(nlh)) { <answer> if 
<token> ib_sa_cancel_query(int id, struct ib_sa_query *query) <answer> void 
unsigned long <token> <answer> flags; 
struct <token> *mad_buf; <answer> ib_mad_send_buf 
xa_lock_irqsave(&queries, <token> <answer> flags); 
if <token> id) != query) { <answer> (xa_load(&queries, 
<token> flags); <answer> xa_unlock_irqrestore(&queries, 
<token> = query->mad_buf; <answer> mad_buf 
<token> flags); <answer> xa_unlock_irqrestore(&queries, 
<token> (!ib_nl_cancel_request(query)) <answer> if 
static u8 get_src_path_mask(struct <token> *device, u32 port_num) <answer> ib_device 
struct <token> *sa_dev; <answer> ib_sa_device 
struct ib_sa_port <token> <answer> *port; 
<token> long flags; <answer> unsigned 
u8 <token> <answer> src_path_mask; 
<token> = ib_get_client_data(device, &sa_client); <answer> sa_dev 
if <token> <answer> (!sa_dev) 
return <token> <answer> 0x7f; 
port = <token> - sa_dev->start_port]; <answer> &sa_dev->port[port_num 
spin_lock_irqsave(&port->ah_lock, <token> <answer> flags); 
src_path_mask <token> port->sm_ah ? port->sm_ah->src_path_mask : 0x7f; <answer> = 
<token> flags); <answer> spin_unlock_irqrestore(&port->ah_lock, 
return <token> <answer> src_path_mask; 
static int init_ah_attr_grh_fields(struct ib_device *device, <token> port_num, <answer> u32 
<token> sa_path_rec *rec, <answer> struct 
struct <token> *ah_attr, <answer> rdma_ah_attr 
const struct <token> *gid_attr) <answer> ib_gid_attr 
<token> ib_gid_type type = sa_conv_pathrec_to_gid_type(rec); <answer> enum 
if <token> { <answer> (!gid_attr) 
gid_attr <token> rdma_find_gid_by_port(device, &rec->sgid, type, <answer> = 
port_num, <token> <answer> NULL); 
<token> (IS_ERR(gid_attr)) <answer> if 
<token> PTR_ERR(gid_attr); <answer> return 
} <token> <answer> else 
<token> &rec->dgid, <answer> rdma_move_grh_sgid_attr(ah_attr, 
<token> rec->traffic_class, <answer> rec->hop_limit, 
<token> 0; <answer> return 
<token> ib_init_ah_attr_from_path(struct ib_device *device, u32 port_num, <answer> int 
<token> sa_path_rec *rec, <answer> struct 
struct rdma_ah_attr <token> <answer> *ah_attr, 
<token> struct ib_gid_attr *gid_attr) <answer> const 
int ret <token> 0; <answer> = 
<token> 0, sizeof(*ah_attr)); <answer> memset(ah_attr, 
ah_attr->type = <token> port_num); <answer> rdma_ah_find_type(device, 
rdma_ah_set_sl(ah_attr, <token> <answer> rec->sl); 
<token> port_num); <answer> rdma_ah_set_port_num(ah_attr, 
<token> rec->rate); <answer> rdma_ah_set_static_rate(ah_attr, 
<token> (sa_path_is_roce(rec)) { <answer> if 
ret = <token> gid_attr); <answer> roce_resolve_route_from_path(rec, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
memcpy(ah_attr->roce.dmac, sa_path_get_dmac(rec), <token> <answer> ETH_ALEN); 
} <token> { <answer> else 
<token> be32_to_cpu(sa_path_get_dlid(rec))); <answer> rdma_ah_set_dlid(ah_attr, 
if (sa_path_is_opa(rec) <token> <answer> && 
rdma_ah_get_dlid(ah_attr) == <token> <answer> be16_to_cpu(IB_LID_PERMISSIVE)) 
rdma_ah_set_make_grd(ah_attr, <token> <answer> true); 
be32_to_cpu(sa_path_get_slid(rec)) <token> <answer> & 
<token> port_num)); <answer> get_src_path_mask(device, 
if (rec->hop_limit <token> 0 || sa_path_is_roce(rec)) <answer> > 
ret <token> init_ah_attr_grh_fields(device, port_num, <answer> = 
rec, <token> gid_attr); <answer> ah_attr, 
<token> ret; <answer> return 
<token> int alloc_mad(struct ib_sa_query *query, gfp_t gfp_mask) <answer> static 
<token> rdma_ah_attr ah_attr; <answer> struct 
unsigned long <token> <answer> flags; 
<token> flags); <answer> spin_lock_irqsave(&query->port->ah_lock, 
if <token> { <answer> (!query->port->sm_ah) 
spin_unlock_irqrestore(&query->port->ah_lock, <token> <answer> flags); 
return <token> <answer> -EAGAIN; 
query->sm_ah = <token> <answer> query->port->sm_ah; 
<token> flags); <answer> spin_unlock_irqrestore(&query->port->ah_lock, 
if ((rdma_query_ah(query->sm_ah->ah, &ah_attr) <token> 0) || <answer> < 
!rdma_is_valid_unicast_lid(&ah_attr)) <token> <answer> { 
kref_put(&query->sm_ah->ref, <token> <answer> free_sm_ah); 
<token> -EAGAIN; <answer> return 
query->mad_buf = ib_create_send_mad(query->port->agent, <token> <answer> 1, 
<token> IB_MGMT_SA_HDR, IB_MGMT_SA_DATA, <answer> 0, 
((query->flags & <token> ? <answer> IB_SA_QUERY_OPA) 
OPA_MGMT_BASE_VERSION <token> <answer> : 
<token> (IS_ERR(query->mad_buf)) { <answer> if 
kref_put(&query->sm_ah->ref, <token> <answer> free_sm_ah); 
<token> -ENOMEM; <answer> return 
<token> = query->sm_ah->ah; <answer> query->mad_buf->ah 
<token> 0; <answer> return 
static void <token> ib_sa_query *query) <answer> free_mad(struct 
<token> free_sm_ah); <answer> kref_put(&query->sm_ah->ref, 
<token> void init_mad(struct ib_sa_query *query, struct ib_mad_agent *agent) <answer> static 
struct ib_sa_mad *mad <token> query->mad_buf->mad; <answer> = 
<token> long flags; <answer> unsigned 
memset(mad, <token> sizeof *mad); <answer> 0, 
if (query->flags <token> IB_SA_QUERY_OPA) { <answer> & 
mad->mad_hdr.base_version = <token> <answer> OPA_MGMT_BASE_VERSION; 
mad->mad_hdr.class_version = <token> <answer> OPA_SA_CLASS_VERSION; 
} <token> { <answer> else 
mad->mad_hdr.base_version = <token> <answer> IB_MGMT_BASE_VERSION; 
<token> = IB_SA_CLASS_VERSION; <answer> mad->mad_hdr.class_version 
<token> = IB_MGMT_CLASS_SUBN_ADM; <answer> mad->mad_hdr.mgmt_class 
spin_lock_irqsave(&tid_lock, <token> <answer> flags); 
mad->mad_hdr.tid <token> <answer> = 
<token> agent->hi_tid) << 32 | tid++); <answer> cpu_to_be64(((u64) 
<token> flags); <answer> spin_unlock_irqrestore(&tid_lock, 
static int send_mad(struct ib_sa_query <token> unsigned long timeout_ms, <answer> *query, 
gfp_t <token> <answer> gfp_mask) 
unsigned <token> flags; <answer> long 
<token> ret, id; <answer> int 
<token> int nmbr_sa_query_retries = 10; <answer> const 
<token> flags); <answer> xa_lock_irqsave(&queries, 
ret = <token> &id, query, xa_limit_32b, gfp_mask); <answer> __xa_alloc(&queries, 
xa_unlock_irqrestore(&queries, <token> <answer> flags); 
if <token> < 0) <answer> (ret 
<token> ret; <answer> return 
query->mad_buf->timeout_ms = <token> / nmbr_sa_query_retries; <answer> timeout_ms 
query->mad_buf->retries <token> nmbr_sa_query_retries; <answer> = 
if <token> { <answer> (!query->mad_buf->timeout_ms) 
return ret ? ret <token> id; <answer> : 
void ib_sa_unpack_path(void <token> struct sa_path_rec *rec) <answer> *attribute, 
ib_unpack(path_rec_table, ARRAY_SIZE(path_rec_table), <token> rec); <answer> attribute, 
void ib_sa_pack_path(struct sa_path_rec <token> void *attribute) <answer> *rec, 
ib_pack(path_rec_table, <token> rec, attribute); <answer> ARRAY_SIZE(path_rec_table), 
static bool ib_sa_opa_pathrecord_support(struct ib_sa_client <token> <answer> *client, 
struct <token> *sa_dev, <answer> ib_sa_device 
u32 <token> <answer> port_num) 
struct ib_sa_port <token> <answer> *port; 
unsigned <token> flags; <answer> long 
bool ret <token> false; <answer> = 
port = <token> - sa_dev->start_port]; <answer> &sa_dev->port[port_num 
<token> flags); <answer> spin_lock_irqsave(&port->classport_lock, 
if <token> <answer> (!port->classport_info.valid) 
goto <token> <answer> ret; 
if (port->classport_info.data.type == <token> <answer> RDMA_CLASS_PORT_INFO_OPA) 
ret = opa_get_cpi_capmask2(&port->classport_info.data.opa) <token> <answer> & 
<token> flags); <answer> spin_unlock_irqrestore(&port->classport_lock, 
<token> ret; <answer> return 
enum opa_pr_supported <token> <answer> { 
static int <token> ib_sa_client *client, <answer> opa_pr_query_possible(struct 
struct <token> *sa_dev, <answer> ib_sa_device 
<token> ib_device *device, u32 port_num) <answer> struct 
<token> ib_port_attr port_attr; <answer> struct 
if (ib_query_port(device, port_num, <token> <answer> &port_attr)) 
<token> PR_NOT_SUPPORTED; <answer> return 
if <token> sa_dev, port_num)) <answer> (ib_sa_opa_pathrecord_support(client, 
return <token> <answer> PR_OPA_SUPPORTED; 
if (port_attr.lid <token> be16_to_cpu(IB_MULTICAST_LID_BASE)) <answer> >= 
<token> PR_NOT_SUPPORTED; <answer> return 
return <token> <answer> PR_IB_SUPPORTED; 
<token> void ib_sa_path_rec_callback(struct ib_sa_query *sa_query, <answer> static 
int status, <token> ib_sa_mad *mad) <answer> struct 
struct ib_sa_path_query <token> = <answer> *query 
container_of(sa_query, struct ib_sa_path_query, <token> <answer> sa_query); 
struct sa_path_rec <token> = {}; <answer> rec 
if (!mad) <token> <answer> { 
query->callback(status, NULL, <token> query->context); <answer> 0, 
if (sa_query->flags <token> IB_SA_QUERY_OPA) { <answer> & 
ib_unpack(opa_path_rec_table, <token> <answer> ARRAY_SIZE(opa_path_rec_table), 
mad->data, <token> <answer> &rec); 
rec.rec_type <token> SA_PATH_REC_TYPE_OPA; <answer> = 
query->callback(status, &rec, 1, <token> <answer> query->context); 
ib_unpack(path_rec_table, <token> <answer> ARRAY_SIZE(path_rec_table), 
<token> &rec); <answer> mad->data, 
rec.rec_type = <token> <answer> SA_PATH_REC_TYPE_IB; 
if (query->conv_pr) <token> <answer> { 
struct <token> opa; <answer> sa_path_rec 
memset(&opa, 0, sizeof(struct <token> <answer> sa_path_rec)); 
sa_convert_path_ib_to_opa(&opa, <token> <answer> &rec); 
query->callback(status, <token> 1, query->context); <answer> &opa, 
} else <token> <answer> { 
query->callback(status, &rec, 1, <token> <answer> query->context); 
static void <token> ib_sa_query *sa_query) <answer> ib_sa_path_rec_release(struct 
struct ib_sa_path_query <token> = <answer> *query 
container_of(sa_query, struct ib_sa_path_query, <token> <answer> sa_query); 
int ib_sa_path_rec_get(struct <token> *client, <answer> ib_sa_client 
struct ib_device *device, u32 <token> <answer> port_num, 
<token> sa_path_rec *rec, <answer> struct 
ib_sa_comp_mask <token> <answer> comp_mask, 
<token> long timeout_ms, gfp_t gfp_mask, <answer> unsigned 
<token> (*callback)(int status, <answer> void 
<token> sa_path_rec *resp, <answer> struct 
unsigned int <token> void *context), <answer> num_paths, 
void <token> <answer> *context, 
<token> ib_sa_query **sa_query) <answer> struct 
struct ib_sa_path_query <token> <answer> *query; 
struct <token> *sa_dev = ib_get_client_data(device, &sa_client); <answer> ib_sa_device 
struct <token> *port; <answer> ib_sa_port 
struct ib_mad_agent <token> <answer> *agent; 
<token> ib_sa_mad *mad; <answer> struct 
enum opa_pr_supported <token> <answer> status; 
<token> ret; <answer> int 
<token> (!sa_dev) <answer> if 
<token> -ENODEV; <answer> return 
if ((rec->rec_type != SA_PATH_REC_TYPE_IB) <token> <answer> && 
(rec->rec_type <token> SA_PATH_REC_TYPE_OPA)) <answer> != 
return <token> <answer> -EINVAL; 
port = &sa_dev->port[port_num - <token> <answer> sa_dev->start_port]; 
agent <token> port->agent; <answer> = 
query <token> kzalloc(sizeof(*query), gfp_mask); <answer> = 
<token> (!query) <answer> if 
return <token> <answer> -ENOMEM; 
query->sa_query.port <token> port; <answer> = 
if (rec->rec_type == <token> { <answer> SA_PATH_REC_TYPE_OPA) 
status = opa_pr_query_possible(client, sa_dev, device, <token> <answer> port_num); 
<token> (status == PR_NOT_SUPPORTED) { <answer> if 
ret <token> -EINVAL; <answer> = 
goto <token> <answer> err1; 
} else <token> (status == PR_OPA_SUPPORTED) { <answer> if 
query->sa_query.flags |= <token> <answer> IB_SA_QUERY_OPA; 
<token> else { <answer> } 
<token> = <answer> query->conv_pr 
kmalloc(sizeof(*query->conv_pr), <token> <answer> gfp_mask); 
if (!query->conv_pr) <token> <answer> { 
ret <token> -ENOMEM; <answer> = 
goto <token> <answer> err1; 
<token> = alloc_mad(&query->sa_query, gfp_mask); <answer> ret 
<token> (ret) <answer> if 
goto <token> <answer> err2; 
query->sa_query.client = <token> <answer> client; 
query->callback = <token> <answer> callback; 
<token> = context; <answer> query->context 
<token> = query->sa_query.mad_buf->mad; <answer> mad 
<token> agent); <answer> init_mad(&query->sa_query, 
query->sa_query.callback <token> callback ? ib_sa_path_rec_callback : NULL; <answer> = 
query->sa_query.release = <token> <answer> ib_sa_path_rec_release; 
mad->mad_hdr.method <token> IB_MGMT_METHOD_GET; <answer> = 
<token> = cpu_to_be16(IB_SA_ATTR_PATH_REC); <answer> mad->mad_hdr.attr_id 
<token> = comp_mask; <answer> mad->sa_hdr.comp_mask 
<token> (query->sa_query.flags & IB_SA_QUERY_OPA) { <answer> if 
ib_pack(opa_path_rec_table, <token> <answer> ARRAY_SIZE(opa_path_rec_table), 
rec, <token> <answer> mad->data); 
} else if (query->conv_pr) <token> <answer> { 
<token> rec); <answer> sa_convert_path_opa_to_ib(query->conv_pr, 
ib_pack(path_rec_table, <token> <answer> ARRAY_SIZE(path_rec_table), 
query->conv_pr, <token> <answer> mad->data); 
} else <token> <answer> { 
ib_pack(path_rec_table, <token> <answer> ARRAY_SIZE(path_rec_table), 
<token> mad->data); <answer> rec, 
<token> = &query->sa_query; <answer> *sa_query 
query->sa_query.flags <token> IB_SA_ENABLE_LOCAL_SERVICE; <answer> |= 
<token> = (query->conv_pr) ? <answer> query->sa_query.mad_buf->context[1] 
<token> : rec; <answer> query->conv_pr 
ret <token> send_mad(&query->sa_query, timeout_ms, gfp_mask); <answer> = 
if <token> < 0) <answer> (ret 
<token> err3; <answer> goto 
return <token> <answer> ret; 
<token> = NULL; <answer> *sa_query 
<token> ret; <answer> return 
static void ib_sa_mcmember_rec_callback(struct <token> *sa_query, <answer> ib_sa_query 
int <token> struct ib_sa_mad *mad) <answer> status, 
struct ib_sa_mcmember_query <token> = <answer> *query 
container_of(sa_query, <token> ib_sa_mcmember_query, sa_query); <answer> struct 
if (mad) <token> <answer> { 
struct <token> rec; <answer> ib_sa_mcmember_rec 
ib_unpack(mcmember_rec_table, <token> <answer> ARRAY_SIZE(mcmember_rec_table), 
<token> &rec); <answer> mad->data, 
query->callback(status, <token> query->context); <answer> &rec, 
} <token> <answer> else 
query->callback(status, NULL, <token> <answer> query->context); 
static void <token> ib_sa_query *sa_query) <answer> ib_sa_mcmember_rec_release(struct 
<token> struct ib_sa_mcmember_query, sa_query)); <answer> kfree(container_of(sa_query, 
int ib_sa_mcmember_rec_query(struct <token> *client, <answer> ib_sa_client 
<token> ib_device *device, u32 port_num, <answer> struct 
u8 <token> <answer> method, 
struct <token> *rec, <answer> ib_sa_mcmember_rec 
<token> comp_mask, <answer> ib_sa_comp_mask 
unsigned <token> timeout_ms, gfp_t gfp_mask, <answer> long 
void <token> status, <answer> (*callback)(int 
struct <token> *resp, <answer> ib_sa_mcmember_rec 
void <token> <answer> *context), 
void <token> <answer> *context, 
struct ib_sa_query <token> <answer> **sa_query) 
<token> ib_sa_mcmember_query *query; <answer> struct 
<token> ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client); <answer> struct 
struct ib_sa_port <token> <answer> *port; 
<token> ib_mad_agent *agent; <answer> struct 
<token> ib_sa_mad *mad; <answer> struct 
int <token> <answer> ret; 
if <token> <answer> (!sa_dev) 
<token> -ENODEV; <answer> return 
port = <token> - sa_dev->start_port]; <answer> &sa_dev->port[port_num 
agent = <token> <answer> port->agent; 
query <token> kzalloc(sizeof(*query), gfp_mask); <answer> = 
<token> (!query) <answer> if 
return <token> <answer> -ENOMEM; 
query->sa_query.port = <token> <answer> port; 
ret = <token> gfp_mask); <answer> alloc_mad(&query->sa_query, 
<token> (ret) <answer> if 
goto <token> <answer> err1; 
<token> = client; <answer> query->sa_query.client 
query->callback <token> callback; <answer> = 
<token> = context; <answer> query->context 
<token> = query->sa_query.mad_buf->mad; <answer> mad 
<token> agent); <answer> init_mad(&query->sa_query, 
query->sa_query.callback = <token> ? ib_sa_mcmember_rec_callback : NULL; <answer> callback 
query->sa_query.release <token> ib_sa_mcmember_rec_release; <answer> = 
mad->mad_hdr.method = <token> <answer> method; 
mad->mad_hdr.attr_id <token> cpu_to_be16(IB_SA_ATTR_MC_MEMBER_REC); <answer> = 
mad->sa_hdr.comp_mask <token> comp_mask; <answer> = 
<token> ARRAY_SIZE(mcmember_rec_table), <answer> ib_pack(mcmember_rec_table, 
<token> mad->data); <answer> rec, 
<token> = &query->sa_query; <answer> *sa_query 
ret = send_mad(&query->sa_query, <token> gfp_mask); <answer> timeout_ms, 
<token> (ret < 0) <answer> if 
goto <token> <answer> err2; 
return <token> <answer> ret; 
*sa_query = <token> <answer> NULL; 
<token> ret; <answer> return 
spin_lock_irqsave(&port->classport_lock, <token> <answer> flags); 
if (port->classport_info.valid) <token> <answer> { 
spin_unlock_irqrestore(&port->classport_lock, <token> <answer> flags); 
spin_unlock_irqrestore(&port->classport_lock, <token> <answer> flags); 
cb_context = <token> GFP_KERNEL); <answer> kmalloc(sizeof(*cb_context), 
if <token> <answer> (!cb_context) 
goto <token> <answer> err_nomem; 
<token> = ib_sa_classport_info_rec_query(port, 3000, <answer> ret 
<token> cb_context, <answer> ib_classportinfo_cb, 
if (ret < <token> <answer> 0) 
<token> free_cb_err; <answer> goto 
<token> flags); <answer> spin_lock_irqsave(&port->classport_lock, 
<token> (!port->classport_info.valid) { <answer> if 
<token> (port->classport_info.retry_cnt <= <answer> if 
IB_SA_CPI_MAX_RETRY_CNT) <token> <answer> { 
unsigned long <token> = <answer> delay 
<token> &port->ib_cpi_work, delay); <answer> queue_delayed_work(ib_wq, 
spin_unlock_irqrestore(&port->classport_lock, <token> <answer> flags); 
static void send_handler(struct <token> *agent, <answer> ib_mad_agent 
struct ib_mad_send_wc <token> <answer> *mad_send_wc) 
struct ib_sa_query <token> = mad_send_wc->send_buf->context[0]; <answer> *query 
<token> long flags; <answer> unsigned 
<token> (query->callback) <answer> if 
switch (mad_send_wc->status) <token> <answer> { 
<token> IB_WC_SUCCESS: <answer> case 
if (ah_attr.type == <token> && <answer> RDMA_AH_ATTR_TYPE_OPA 
<token> || <answer> (grh_required 
port_attr.sm_lid <token> be16_to_cpu(IB_LID_PERMISSIVE))) <answer> == 
<token> true); <answer> rdma_ah_set_make_grd(&ah_attr, 
if (ah_attr.type == <token> && grh_required) { <answer> RDMA_AH_ATTR_TYPE_IB 
<token> IB_AH_GRH); <answer> rdma_ah_set_ah_flags(&ah_attr, 
new_ah->ah = <token> &ah_attr, <answer> rdma_create_ah(port->agent->qp->pd, 
<token> (IS_ERR(new_ah->ah)) { <answer> if 
pr_warn("Couldn't create new SM <token> <answer> AH\n"); 
<token> (port->sm_ah) <answer> if 
kref_put(&port->sm_ah->ref, <token> <answer> free_sm_ah); 
port->sm_ah = <token> <answer> new_ah; 
static void <token> ib_event_handler *handler, <answer> ib_sa_event(struct 
struct ib_event <token> <answer> *event) 
<token> (event->event == IB_EVENT_PORT_ERR || <answer> if 
event->event <token> IB_EVENT_PORT_ACTIVE || <answer> == 
event->event == IB_EVENT_LID_CHANGE <token> <answer> || 
<token> == IB_EVENT_PKEY_CHANGE || <answer> event->event 
<token> == IB_EVENT_SM_CHANGE || <answer> event->event 
event->event == <token> { <answer> IB_EVENT_CLIENT_REREGISTER) 
unsigned <token> flags; <answer> long 
struct <token> *sa_dev = <answer> ib_sa_device 
container_of(handler, typeof(*sa_dev), <token> <answer> event_handler); 
u32 port_num = <token> - sa_dev->start_port; <answer> event->element.port_num 
<token> ib_sa_port *port = &sa_dev->port[port_num]; <answer> struct 
if (!rdma_cap_ib_sa(handler->device, <token> <answer> port->port_num)) 
spin_lock_irqsave(&port->ah_lock, <token> <answer> flags); 
<token> (port->sm_ah) <answer> if 
kref_put(&port->sm_ah->ref, <token> <answer> free_sm_ah); 
<token> = NULL; <answer> port->sm_ah 
<token> flags); <answer> spin_unlock_irqrestore(&port->ah_lock, 
<token> (event->event == IB_EVENT_SM_CHANGE || <answer> if 
<token> == IB_EVENT_CLIENT_REREGISTER || <answer> event->event 
event->event == <token> || <answer> IB_EVENT_LID_CHANGE 
event->event <token> IB_EVENT_PORT_ACTIVE) { <answer> == 
unsigned long <token> = <answer> delay 
spin_lock_irqsave(&port->classport_lock, <token> <answer> flags); 
port->classport_info.valid = <token> <answer> false; 
port->classport_info.retry_cnt <token> 0; <answer> = 
<token> flags); <answer> spin_unlock_irqrestore(&port->classport_lock, 
<token> delay); <answer> &port->ib_cpi_work, 
queue_work(ib_wq, <token> <answer> &sa_dev->port[port_num].update_task); 
static int ib_sa_add_one(struct ib_device <token> <answer> *device) 
struct <token> *sa_dev; <answer> ib_sa_device 
int s, e, <token> <answer> i; 
int <token> = 0; <answer> count 
<token> ret; <answer> int 
<token> = rdma_start_port(device); <answer> s 
e = <token> <answer> rdma_end_port(device); 
<token> = kzalloc(struct_size(sa_dev, port, <answer> sa_dev 
size_add(size_sub(e, <token> 1)), <answer> s), 
<token> (!sa_dev) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = s; <answer> sa_dev->start_port 
sa_dev->end_port <token> e; <answer> = 
for (i = 0; i <= e - <token> ++i) { <answer> s; 
if <token> i + 1)) <answer> (!rdma_cap_ib_sa(device, 
<token> = NULL; <answer> sa_dev->port[i].sm_ah 
sa_dev->port[i].port_num <token> i + s; <answer> = 
sa_dev->port[i].classport_info.valid <token> false; <answer> = 
sa_dev->port[i].agent <token> <answer> = 
ib_register_mad_agent(device, i + <token> IB_QPT_GSI, <answer> s, 
NULL, 0, <token> <answer> send_handler, 
recv_handler, <token> 0); <answer> sa_dev, 
if (IS_ERR(sa_dev->port[i].agent)) <token> <answer> { 
ret = <token> <answer> PTR_ERR(sa_dev->port[i].agent); 
goto <token> <answer> err; 
<token> update_sm_ah); <answer> INIT_WORK(&sa_dev->port[i].update_task, 
if (!count) <token> <answer> { 
ret <token> -EOPNOTSUPP; <answer> = 
goto <token> <answer> free; 
<token> &sa_client, sa_dev); <answer> ib_set_client_data(device, 
<token> device, ib_sa_event); <answer> INIT_IB_EVENT_HANDLER(&sa_dev->event_handler, 
for (i = 0; i <= e - s; <token> { <answer> ++i) 
<token> (rdma_cap_ib_sa(device, i + 1)) <answer> if 
<token> 0; <answer> return 
while (--i >= <token> { <answer> 0) 
if <token> i + 1)) <answer> (rdma_cap_ib_sa(device, 
<token> ret; <answer> return 
static void ib_sa_remove_one(struct ib_device <token> void *client_data) <answer> *device, 
struct <token> *sa_dev = client_data; <answer> ib_sa_device 
<token> i; <answer> int 
for <token> = 0; i <= sa_dev->end_port - sa_dev->start_port; ++i) { <answer> (i 
if (rdma_cap_ib_sa(device, i + 1)) <token> <answer> { 
<token> (sa_dev->port[i].sm_ah) <answer> if 
<token> free_sm_ah); <answer> kref_put(&sa_dev->port[i].sm_ah->ref, 
<token> ib_sa_init(void) <answer> int 
int <token> <answer> ret; 
get_random_bytes(&tid, sizeof <token> <answer> tid); 
<token> 0); <answer> atomic_set(&ib_nl_sa_request_seq, 
ret <token> ib_register_client(&sa_client); <answer> = 
if <token> { <answer> (ret) 
pr_err("Couldn't register <token> client\n"); <answer> ib_sa 
<token> err1; <answer> goto 
ret <token> mcast_init(); <answer> = 
if <token> { <answer> (ret) 
pr_err("Couldn't initialize multicast <token> <answer> handling\n"); 
<token> err2; <answer> goto 
ib_nl_wq = alloc_ordered_workqueue("ib_nl_sa_wq", <token> <answer> WQ_MEM_RECLAIM); 
<token> (!ib_nl_wq) { <answer> if 
<token> = -ENOMEM; <answer> ret 
<token> err3; <answer> goto 
<token> ib_nl_request_timeout); <answer> INIT_DELAYED_WORK(&ib_nl_timed_work, 
<token> 0; <answer> return 
return <token> <answer> ret; 
<token> ib_sa_cleanup(void) <answer> void 
static inline void tdcall(u64 fn, <token> tdx_module_args *args) <answer> struct 
<token> (__tdcall_ret(fn, args)) <answer> if 
panic("TDCALL %lld failed <token> TDX module!)\n", fn); <answer> (Buggy 
int tdx_mcall_get_report0(u8 *reportdata, <token> *tdreport) <answer> u8 
struct <token> args = { <answer> tdx_module_args 
.rcx = <token> <answer> virt_to_phys(tdreport), 
.rdx <token> virt_to_phys(reportdata), <answer> = 
.r8 <token> TDREPORT_SUBTYPE_0, <answer> = 
<token> ret; <answer> u64 
ret = <token> &args); <answer> __tdcall(TDG_MR_REPORT, 
if <token> { <answer> (ret) 
<token> (TDCALL_RETURN_CODE(ret) == TDCALL_INVALID_OPERAND) <answer> if 
return <token> <answer> -EINVAL; 
<token> -EIO; <answer> return 
return <token> <answer> 0; 
u64 <token> *buf, size_t size) <answer> tdx_hcall_get_quote(u8 
<token> (1) <answer> while 
static void <token> *cc_mask) <answer> tdx_parse_tdinfo(u64 
struct tdx_module_args <token> = {}; <answer> args 
unsigned <token> gpa_width; <answer> int 
u64 <token> <answer> td_attr; 
tdcall(TDG_VP_INFO, <token> <answer> &args); 
gpa_width <token> args.rcx & GENMASK(5, 0); <answer> = 
*cc_mask = BIT_ULL(gpa_width - <token> <answer> 1); 
<token> = args.rdx; <answer> td_attr 
if (!(td_attr & <token> { <answer> ATTR_SEPT_VE_DISABLE)) 
const char *msg = "TD misconfiguration: <token> attribute must be set."; <answer> SEPT_VE_DISABLE 
static int <token> ve_info *ve) <answer> ve_instr_len(struct 
switch <token> { <answer> (ve->exit_reason) 
case <token> <answer> EXIT_REASON_HLT: 
<token> EXIT_REASON_MSR_READ: <answer> case 
case <token> <answer> EXIT_REASON_MSR_WRITE: 
case <token> <answer> EXIT_REASON_CPUID: 
case <token> <answer> EXIT_REASON_IO_INSTRUCTION: 
WARN_ONCE(1, "ve->instr_len is <token> defined for EPT violations"); <answer> not 
return <token> <answer> 0; 
<token> "Unexpected #VE-type: %lld\n", ve->exit_reason); <answer> WARN_ONCE(1, 
<token> ve->instr_len; <answer> return 
static u64 __cpuidle <token> bool irq_disabled) <answer> __halt(const 
struct tdx_module_args <token> = { <answer> args 
<token> = TDX_HYPERCALL_STANDARD, <answer> .r10 
.r11 <token> hcall_func(EXIT_REASON_HLT), <answer> = 
.r12 = <token> <answer> irq_disabled, 
<token> __tdx_hypercall(&args); <answer> return 
static <token> handle_halt(struct ve_info *ve) <answer> int 
<token> bool irq_disabled = irqs_disabled(); <answer> const 
<token> (__halt(irq_disabled)) <answer> if 
return <token> <answer> -EIO; 
<token> ve_instr_len(ve); <answer> return 
void <token> tdx_safe_halt(void) <answer> __cpuidle 
const <token> irq_disabled = false; <answer> bool 
if <token> <answer> (__halt(irq_disabled)) 
WARN_ONCE(1, "HLT instruction emulation <token> <answer> failed\n"); 
static int <token> pt_regs *regs, struct ve_info *ve) <answer> read_msr(struct 
struct <token> args = { <answer> tdx_module_args 
.r10 <token> TDX_HYPERCALL_STANDARD, <answer> = 
.r11 <token> hcall_func(EXIT_REASON_MSR_READ), <answer> = 
.r12 = <token> <answer> regs->cx, 
<token> (__tdx_hypercall(&args)) <answer> if 
<token> -EIO; <answer> return 
regs->ax <token> lower_32_bits(args.r11); <answer> = 
regs->dx = <token> <answer> upper_32_bits(args.r11); 
return <token> <answer> ve_instr_len(ve); 
static int write_msr(struct pt_regs <token> struct ve_info *ve) <answer> *regs, 
struct tdx_module_args args = <token> <answer> { 
.r10 = <token> <answer> TDX_HYPERCALL_STANDARD, 
.r11 = <token> <answer> hcall_func(EXIT_REASON_MSR_WRITE), 
<token> = regs->cx, <answer> .r12 
.r13 <token> (u64)regs->dx << 32 | regs->ax, <answer> = 
if <token> <answer> (__tdx_hypercall(&args)) 
<token> -EIO; <answer> return 
return <token> <answer> ve_instr_len(ve); 
static int handle_cpuid(struct pt_regs *regs, struct <token> *ve) <answer> ve_info 
struct tdx_module_args args = <token> <answer> { 
<token> = TDX_HYPERCALL_STANDARD, <answer> .r10 
.r11 <token> hcall_func(EXIT_REASON_CPUID), <answer> = 
.r12 <token> regs->ax, <answer> = 
.r13 <token> regs->cx, <answer> = 
if (regs->ax < 0x40000000 || regs->ax > <token> { <answer> 0x4FFFFFFF) 
regs->ax = regs->bx <token> regs->cx = regs->dx = 0; <answer> = 
return <token> <answer> ve_instr_len(ve); 
if <token> <answer> (__tdx_hypercall(&args)) 
return <token> <answer> -EIO; 
regs->ax <token> args.r12; <answer> = 
regs->bx = <token> <answer> args.r13; 
regs->cx <token> args.r14; <answer> = 
regs->dx = <token> <answer> args.r15; 
<token> ve_instr_len(ve); <answer> return 
static <token> mmio_read(int size, unsigned long addr, unsigned long *val) <answer> bool 
struct <token> args = { <answer> tdx_module_args 
.r10 = <token> <answer> TDX_HYPERCALL_STANDARD, 
.r11 <token> hcall_func(EXIT_REASON_EPT_VIOLATION), <answer> = 
.r12 = <token> <answer> size, 
<token> = EPT_READ, <answer> .r13 
.r14 <token> addr, <answer> = 
.r15 <token> *val, <answer> = 
if <token> <answer> (__tdx_hypercall(&args)) 
return <token> <answer> false; 
<token> = args.r11; <answer> *val 
return <token> <answer> true; 
static bool mmio_write(int size, unsigned long addr, <token> long val) <answer> unsigned 
return !_tdx_hypercall(hcall_func(EXIT_REASON_EPT_VIOLATION), <token> <answer> size, 
<token> addr, val); <answer> EPT_WRITE, 
static int handle_mmio(struct pt_regs *regs, struct <token> *ve) <answer> ve_info 
unsigned long *reg, val, <token> <answer> vaddr; 
<token> buffer[MAX_INSN_SIZE]; <answer> char 
enum <token> mmio; <answer> insn_mmio_type 
<token> insn insn = {}; <answer> struct 
int size, <token> <answer> extend_size; 
u8 extend_val = <token> <answer> 0; 
vaddr <token> (unsigned long)insn_get_addr_ref(&insn, regs); <answer> = 
if <token> / PAGE_SIZE != (vaddr + size - 1) / PAGE_SIZE) <answer> (vaddr 
<token> -EFAULT; <answer> return 
<token> -EINVAL; <answer> return 
WARN_ONCE(1, <token> insn_decode_mmio() decode value?"); <answer> "Unknown 
<token> -EINVAL; <answer> return 
success = <token> <answer> !__tdx_hypercall(&args); 
return <token> size, <answer> !_tdx_hypercall(hcall_func(EXIT_REASON_IO_INSTRUCTION), 
PORT_WRITE, <token> regs->ax & mask); <answer> port, 
static int handle_io(struct pt_regs *regs, struct ve_info <token> <answer> *ve) 
u32 <token> = ve->exit_qual; <answer> exit_qual 
int size, <token> <answer> port; 
<token> in, ret; <answer> bool 
<token> (VE_IS_IO_STRING(exit_qual)) <answer> if 
return <token> <answer> -EIO; 
in = <token> <answer> VE_IS_IO_IN(exit_qual); 
<token> = VE_GET_IO_SIZE(exit_qual); <answer> size 
port <token> VE_GET_PORT_NUM(exit_qual); <answer> = 
<token> (in) <answer> if 
ret <token> handle_in(regs, size, port); <answer> = 
ret = handle_out(regs, <token> port); <answer> size, 
<token> (!ret) <answer> if 
<token> -EIO; <answer> return 
<token> ve_instr_len(ve); <answer> return 
__init bool tdx_early_handle_ve(struct pt_regs <token> <answer> *regs) 
struct ve_info <token> <answer> ve; 
<token> insn_len; <answer> int 
if (ve.exit_reason != <token> <answer> EXIT_REASON_IO_INSTRUCTION) 
return <token> <answer> false; 
insn_len = handle_io(regs, <token> <answer> &ve); 
if <token> < 0) <answer> (insn_len 
<token> false; <answer> return 
<token> += insn_len; <answer> regs->ip 
<token> true; <answer> return 
<token> tdx_get_ve_info(struct ve_info *ve) <answer> void 
struct <token> args = {}; <answer> tdx_module_args 
<token> &args); <answer> tdcall(TDG_VP_VEINFO_GET, 
static int virt_exception_user(struct pt_regs *regs, <token> ve_info *ve) <answer> struct 
switch (ve->exit_reason) <token> <answer> { 
<token> EXIT_REASON_CPUID: <answer> case 
return handle_cpuid(regs, <token> <answer> ve); 
pr_warn("Unexpected #VE: <token> ve->exit_reason); <answer> %lld\n", 
return <token> <answer> -EIO; 
<token> inline bool is_private_gpa(u64 gpa) <answer> static 
return gpa <token> cc_mkenc(gpa); <answer> == 
static int virt_exception_kernel(struct pt_regs *regs, <token> ve_info *ve) <answer> struct 
switch <token> { <answer> (ve->exit_reason) 
case <token> <answer> EXIT_REASON_HLT: 
return <token> <answer> handle_halt(ve); 
<token> EXIT_REASON_MSR_READ: <answer> case 
<token> read_msr(regs, ve); <answer> return 
case <token> <answer> EXIT_REASON_MSR_WRITE: 
return <token> ve); <answer> write_msr(regs, 
<token> EXIT_REASON_CPUID: <answer> case 
<token> handle_cpuid(regs, ve); <answer> return 
case <token> <answer> EXIT_REASON_EPT_VIOLATION: 
<token> (is_private_gpa(ve->gpa)) <answer> if 
panic("Unexpected EPT-violation <token> private memory."); <answer> on 
return <token> ve); <answer> handle_mmio(regs, 
case <token> <answer> EXIT_REASON_IO_INSTRUCTION: 
return handle_io(regs, <token> <answer> ve); 
<token> #VE: %lld\n", ve->exit_reason); <answer> pr_warn("Unexpected 
<token> -EIO; <answer> return 
bool tdx_handle_virt_exception(struct <token> *regs, struct ve_info *ve) <answer> pt_regs 
<token> insn_len; <answer> int 
<token> (user_mode(regs)) <answer> if 
insn_len = <token> ve); <answer> virt_exception_user(regs, 
insn_len = virt_exception_kernel(regs, <token> <answer> ve); 
if (insn_len < <token> <answer> 0) 
return <token> <answer> false; 
return <token> <answer> !private; 
<token> bool tdx_cache_flush_required(void) <answer> static 
return <token> <answer> true; 
static bool <token> start, phys_addr_t end, bool enc) <answer> tdx_map_gpa(phys_addr_t 
<token> = args.r11; <answer> map_fail_paddr 
if (map_fail_paddr < <token> || map_fail_paddr >= end) <answer> start 
return <token> <answer> false; 
static bool tdx_enc_status_changed(unsigned <token> vaddr, int numpages, bool enc) <answer> long 
phys_addr_t start <token> __pa(vaddr); <answer> = 
phys_addr_t end = __pa(vaddr <token> numpages * PAGE_SIZE); <answer> + 
if (!tdx_map_gpa(start, <token> enc)) <answer> end, 
<token> false; <answer> return 
if <token> <answer> (enc) 
return <token> numpages, enc); <answer> tdx_enc_status_changed(vaddr, 
return <token> <answer> true; 
static <token> tdx_enc_status_change_finish(unsigned long vaddr, int numpages, <answer> bool 
<token> enc) <answer> bool 
if <token> <answer> (!enc) 
return tdx_enc_status_changed(vaddr, numpages, <token> <answer> enc); 
<token> true; <answer> return 
<token> __init tdx_early_init(void) <answer> void 
<token> tdx_module_args args = { <answer> struct 
<token> = TDCS_NOTIFY_ENABLES, <answer> .rdx 
.r9 <token> -1ULL, <answer> = 
u64 <token> <answer> cc_mask; 
u32 <token> sig[3]; <answer> eax, 
cpuid_count(TDX_CPUID_LEAF_ID, 0, &eax, &sig[0], <token> &sig[1]); <answer> &sig[2], 
if (memcmp(TDX_IDENT, <token> sizeof(sig))) <answer> sig, 
physical_mask &= cc_mask - <token> <answer> 1; 
<token> = tdx_enc_status_change_prepare; <answer> x86_platform.guest.enc_status_change_prepare 
x86_platform.guest.enc_status_change_finish = <token> <answer> tdx_enc_status_change_finish; 
<token> = tdx_cache_flush_required; <answer> x86_platform.guest.enc_cache_flush_required 
x86_platform.guest.enc_tlb_flush_required = <token> <answer> tdx_tlb_flush_required; 
x86_cpuinit.parallel_bringup <token> false; <answer> = 
<token> detected\n"); <answer> pr_info("Guest 
#include <token> <answer> "dm_services.h" 
#include <token> <answer> "include/logger_interface.h" 
#include <token> <answer> "../dce110/irq_service_dce110.h" 
<token> "dcn/dcn_1_0_offset.h" <answer> #include 
#include <token> <answer> "dcn/dcn_1_0_sh_mask.h" 
#include <token> <answer> "soc15_hw_ip.h" 
#include <token> <answer> "vega10_ip_offset.h" 
<token> "irq_service_dcn10.h" <answer> #include 
#include <token> <answer> "ivsrcid/dcn/irqsrcs_dcn_1_0.h" 
<token> enum dc_irq_source to_dal_irq_source_dcn10(struct irq_service *irq_service, <answer> static 
uint32_t <token> <answer> src_id, 
uint32_t <token> <answer> ext_id) 
switch <token> { <answer> (src_id) 
<token> DCN_1_0__SRCID__DC_D1_OTG_VSTARTUP: <answer> case 
<token> DC_IRQ_SOURCE_VBLANK1; <answer> return 
<token> DCN_1_0__SRCID__DC_D2_OTG_VSTARTUP: <answer> case 
<token> DC_IRQ_SOURCE_VBLANK2; <answer> return 
case <token> <answer> DCN_1_0__SRCID__DC_D3_OTG_VSTARTUP: 
<token> DC_IRQ_SOURCE_VBLANK3; <answer> return 
<token> DCN_1_0__SRCID__DC_D4_OTG_VSTARTUP: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_VBLANK4; 
<token> DCN_1_0__SRCID__DC_D5_OTG_VSTARTUP: <answer> case 
<token> DC_IRQ_SOURCE_VBLANK5; <answer> return 
case <token> <answer> DCN_1_0__SRCID__DC_D6_OTG_VSTARTUP: 
<token> DC_IRQ_SOURCE_VBLANK6; <answer> return 
case <token> <answer> DCN_1_0__SRCID__OTG1_VERTICAL_INTERRUPT0_CONTROL: 
<token> DC_IRQ_SOURCE_DC1_VLINE0; <answer> return 
<token> DCN_1_0__SRCID__OTG2_VERTICAL_INTERRUPT0_CONTROL: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_DC2_VLINE0; 
case <token> <answer> DCN_1_0__SRCID__OTG3_VERTICAL_INTERRUPT0_CONTROL: 
<token> DC_IRQ_SOURCE_DC3_VLINE0; <answer> return 
case <token> <answer> DCN_1_0__SRCID__OTG4_VERTICAL_INTERRUPT0_CONTROL: 
<token> DC_IRQ_SOURCE_DC4_VLINE0; <answer> return 
<token> DCN_1_0__SRCID__OTG5_VERTICAL_INTERRUPT0_CONTROL: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_DC5_VLINE0; 
<token> DCN_1_0__SRCID__OTG6_VERTICAL_INTERRUPT0_CONTROL: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_DC6_VLINE0; 
<token> DCN_1_0__SRCID__OTG0_IHC_V_UPDATE_NO_LOCK_INTERRUPT: <answer> case 
<token> DC_IRQ_SOURCE_VUPDATE1; <answer> return 
<token> DCN_1_0__SRCID__OTG1_IHC_V_UPDATE_NO_LOCK_INTERRUPT: <answer> case 
<token> DC_IRQ_SOURCE_VUPDATE2; <answer> return 
case <token> <answer> DCN_1_0__SRCID__OTG2_IHC_V_UPDATE_NO_LOCK_INTERRUPT: 
<token> DC_IRQ_SOURCE_VUPDATE3; <answer> return 
case <token> <answer> DCN_1_0__SRCID__OTG3_IHC_V_UPDATE_NO_LOCK_INTERRUPT: 
return <token> <answer> DC_IRQ_SOURCE_VUPDATE4; 
<token> DCN_1_0__SRCID__OTG4_IHC_V_UPDATE_NO_LOCK_INTERRUPT: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_VUPDATE5; 
case <token> <answer> DCN_1_0__SRCID__OTG5_IHC_V_UPDATE_NO_LOCK_INTERRUPT: 
<token> DC_IRQ_SOURCE_VUPDATE6; <answer> return 
<token> DCN_1_0__SRCID__HUBP0_FLIP_INTERRUPT: <answer> case 
<token> DC_IRQ_SOURCE_PFLIP1; <answer> return 
<token> DCN_1_0__SRCID__HUBP1_FLIP_INTERRUPT: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_PFLIP2; 
<token> DCN_1_0__SRCID__HUBP2_FLIP_INTERRUPT: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_PFLIP3; 
<token> DCN_1_0__SRCID__HUBP3_FLIP_INTERRUPT: <answer> case 
<token> DC_IRQ_SOURCE_PFLIP4; <answer> return 
case <token> <answer> DCN_1_0__SRCID__HUBP4_FLIP_INTERRUPT: 
return <token> <answer> DC_IRQ_SOURCE_PFLIP5; 
<token> DCN_1_0__SRCID__HUBP5_FLIP_INTERRUPT: <answer> case 
<token> DC_IRQ_SOURCE_PFLIP6; <answer> return 
<token> DCN_1_0__SRCID__DC_HPD1_INT: <answer> case 
#define <token> <answer> vupdate_no_lock_int_entry(reg_num)\ 
[DC_IRQ_SOURCE_VUPDATE1 + reg_num] = <token> <answer> {\ 
IRQ_REG_ENTRY(OTG, <token> <answer> reg_num,\ 
OTG_GLOBAL_SYNC_STATUS, <token> <answer> VUPDATE_NO_LOCK_INT_EN,\ 
OTG_GLOBAL_SYNC_STATUS, <token> <answer> VUPDATE_NO_LOCK_EVENT_CLEAR),\ 
.funcs <token> &vupdate_no_lock_irq_info_funcs\ <answer> = 
<token> vblank_int_entry(reg_num)\ <answer> #define 
[DC_IRQ_SOURCE_VBLANK1 + reg_num] = <token> <answer> {\ 
<token> reg_num,\ <answer> IRQ_REG_ENTRY(OTG, 
OTG_GLOBAL_SYNC_STATUS, <token> <answer> VSTARTUP_INT_EN,\ 
<token> VSTARTUP_EVENT_CLEAR),\ <answer> OTG_GLOBAL_SYNC_STATUS, 
.funcs = <token> <answer> &vblank_irq_info_funcs\ 
#define <token> <answer> vline0_int_entry(reg_num)\ 
[DC_IRQ_SOURCE_DC1_VLINE0 + reg_num] = <token> <answer> {\ 
IRQ_REG_ENTRY(OTG, <token> <answer> reg_num,\ 
<token> OTG_VERTICAL_INTERRUPT0_INT_ENABLE,\ <answer> OTG_VERTICAL_INTERRUPT0_CONTROL, 
OTG_VERTICAL_INTERRUPT0_CONTROL, <token> <answer> OTG_VERTICAL_INTERRUPT0_CLEAR),\ 
.funcs <token> &vline0_irq_info_funcs\ <answer> = 
<token> dummy_irq_entry() \ <answer> #define 
.funcs = <token> <answer> &dummy_irq_info_funcs\ 
#define <token> \ <answer> i2c_int_entry(reg_num) 
[DC_IRQ_SOURCE_I2C_DDC ## <token> = dummy_irq_entry() <answer> reg_num] 
#define dp_sink_int_entry(reg_num) <token> <answer> \ 
[DC_IRQ_SOURCE_DPSINK <token> reg_num] = dummy_irq_entry() <answer> ## 
#define gpio_pad_int_entry(reg_num) <token> <answer> \ 
[DC_IRQ_SOURCE_GPIOPAD ## reg_num] = <token> <answer> dummy_irq_entry() 
#define dc_underflow_int_entry(reg_num) <token> <answer> \ 
[DC_IRQ_SOURCE_DC ## reg_num ## <token> = dummy_irq_entry() <answer> UNDERFLOW] 
static struct irq_source_info_funcs dummy_irq_info_funcs = <token> <answer> { 
.set <token> dal_irq_service_dummy_set, <answer> = 
.ack <token> dal_irq_service_dummy_ack <answer> = 
<token> const struct irq_source_info <answer> static 
<token> = { <answer> irq_source_info_dcn10[DAL_IRQ_SOURCES_NUMBER] 
[DC_IRQ_SOURCE_INVALID] = <token> <answer> dummy_irq_entry(), 
<token> = dummy_irq_entry(), <answer> [DC_IRQ_SOURCE_TIMER] 
<token> = dummy_irq_entry(), <answer> [DC_IRQ_SOURCE_PFLIP5] 
<token> = dummy_irq_entry(), <answer> [DC_IRQ_SOURCE_PFLIP6] 
[DC_IRQ_SOURCE_PFLIP_UNDERLAY0] = <token> <answer> dummy_irq_entry(), 
[DC_IRQ_SOURCE_DMCU_SCP] = <token> <answer> dummy_irq_entry(), 
[DC_IRQ_SOURCE_VBIOS_SW] <token> dummy_irq_entry(), <answer> = 
<token> const struct irq_service_funcs irq_service_funcs_dcn10 = { <answer> static 
.to_dal_irq_source <token> to_dal_irq_source_dcn10 <answer> = 
static void <token> <answer> dcn10_irq_construct( 
struct irq_service <token> <answer> *irq_service, 
struct <token> *init_data) <answer> irq_service_init_data 
<token> init_data); <answer> dal_irq_service_construct(irq_service, 
irq_service->info = <token> <answer> irq_source_info_dcn10; 
irq_service->funcs = <token> <answer> &irq_service_funcs_dcn10; 
struct <token> *dal_irq_service_dcn10_create( <answer> irq_service 
<token> irq_service_init_data *init_data) <answer> struct 
struct <token> *irq_service = kzalloc(sizeof(*irq_service), <answer> irq_service 
if <token> <answer> (!irq_service) 
<token> NULL; <answer> return 
<token> init_data); <answer> dcn10_irq_construct(irq_service, 
return <token> <answer> irq_service; 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/initrd.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/fs.h> 
#include <token> <answer> <linux/root_dev.h> 
#include <token> <answer> <linux/screen_info.h> 
#include <token> <answer> <linux/memblock.h> 
<token> <uapi/linux/mount.h> <answer> #include 
<token> <asm/setup.h> <answer> #include 
<token> <asm/system_info.h> <answer> #include 
#include <token> <answer> <asm/page.h> 
#include <token> <answer> <asm/mach/arch.h> 
#include <token> <answer> "atags.h" 
static char default_command_line[COMMAND_LINE_SIZE] __initdata <token> CONFIG_CMDLINE; <answer> = 
#ifndef <token> <answer> MEM_SIZE 
<token> MEM_SIZE (16*1024*1024) <answer> #define 
static <token> { <answer> struct 
<token> tag_header hdr1; <answer> struct 
<token> tag_core core; <answer> struct 
struct <token> hdr2; <answer> tag_header 
struct <token> mem; <answer> tag_mem32 
struct <token> hdr3; <answer> tag_header 
<token> default_tags __initdata = { <answer> } 
<token> tag_size(tag_core), ATAG_CORE }, <answer> { 
{ 1, <token> 0xff }, <answer> PAGE_SIZE, 
{ tag_size(tag_mem32), <token> }, <answer> ATAG_MEM 
{ MEM_SIZE <token> <answer> }, 
<token> 0, ATAG_NONE } <answer> { 
static int __init <token> struct tag *tag) <answer> parse_tag_core(const 
if (tag->hdr.size <token> 2) { <answer> > 
if ((tag->u.core.flags & 1) <token> 0) <answer> == 
<token> &= ~MS_RDONLY; <answer> root_mountflags 
ROOT_DEV = <token> <answer> old_decode_dev(tag->u.core.rootdev); 
<token> 0; <answer> return 
<token> parse_tag_core); <answer> __tagtable(ATAG_CORE, 
static int __init <token> struct tag *tag) <answer> parse_tag_mem32(const 
return arm_add_memory(tag->u.mem.start, <token> <answer> tag->u.mem.size); 
__tagtable(ATAG_MEM, <token> <answer> parse_tag_mem32); 
#if defined(CONFIG_ARCH_FOOTBRIDGE) && <token> <answer> defined(CONFIG_VGA_CONSOLE) 
static <token> __init parse_tag_videotext(const struct tag *tag) <answer> int 
<token> = tag->u.videotext.x; <answer> vgacon_screen_info.orig_x 
vgacon_screen_info.orig_y = <token> <answer> tag->u.videotext.y; 
<token> = tag->u.videotext.video_page; <answer> vgacon_screen_info.orig_video_page 
vgacon_screen_info.orig_video_mode = <token> <answer> tag->u.videotext.video_mode; 
<token> = tag->u.videotext.video_cols; <answer> vgacon_screen_info.orig_video_cols 
vgacon_screen_info.orig_video_ega_bx = <token> <answer> tag->u.videotext.video_ega_bx; 
vgacon_screen_info.orig_video_lines <token> tag->u.videotext.video_lines; <answer> = 
<token> = tag->u.videotext.video_isvga; <answer> vgacon_screen_info.orig_video_isVGA 
<token> = tag->u.videotext.video_points; <answer> vgacon_screen_info.orig_video_points 
return <token> <answer> 0; 
__tagtable(ATAG_VIDEOTEXT, <token> <answer> parse_tag_videotext); 
<token> CONFIG_BLK_DEV_RAM <answer> #ifdef 
static int __init <token> struct tag *tag) <answer> parse_tag_ramdisk(const 
rd_image_start = <token> <answer> tag->u.ramdisk.start; 
<token> (tag->u.ramdisk.size) <answer> if 
rd_size = <token> <answer> tag->u.ramdisk.size; 
return <token> <answer> 0; 
<token> parse_tag_ramdisk); <answer> __tagtable(ATAG_RAMDISK, 
static int __init parse_tag_serialnr(const <token> tag *tag) <answer> struct 
system_serial_low <token> tag->u.serialnr.low; <answer> = 
<token> = tag->u.serialnr.high; <answer> system_serial_high 
return <token> <answer> 0; 
<token> parse_tag_serialnr); <answer> __tagtable(ATAG_SERIAL, 
static int __init <token> struct tag *tag) <answer> parse_tag_revision(const 
<token> = tag->u.revision.rev; <answer> system_rev 
return <token> <answer> 0; 
__tagtable(ATAG_REVISION, <token> <answer> parse_tag_revision); 
static int __init parse_tag_cmdline(const struct <token> *tag) <answer> tag 
#if <token> <answer> defined(CONFIG_CMDLINE_EXTEND) 
strlcat(default_command_line, " ", <token> <answer> COMMAND_LINE_SIZE); 
<token> tag->u.cmdline.cmdline, <answer> strlcat(default_command_line, 
<token> defined(CONFIG_CMDLINE_FORCE) <answer> #elif 
pr_warn("Ignoring tag cmdline (using <token> default kernel command line)\n"); <answer> the 
strscpy(default_command_line, <token> <answer> tag->u.cmdline.cmdline, 
<token> 0; <answer> return 
<token> parse_tag_cmdline); <answer> __tagtable(ATAG_CMDLINE, 
static <token> __init parse_tag(const struct tag *tag) <answer> int 
extern struct tagtable <token> __tagtable_end; <answer> __tagtable_begin, 
<token> tagtable *t; <answer> struct 
<token> (t = &__tagtable_begin; t < &__tagtable_end; t++) <answer> for 
<token> (tag->hdr.tag == t->tag) { <answer> if 
return t <token> &__tagtable_end; <answer> < 
<token> void __init parse_tags(const struct tag *t) <answer> static 
for <token> t->hdr.size; t = tag_next(t)) <answer> (; 
if <token> <answer> (!parse_tag(t)) 
<token> unrecognised tag 0x%08x\n", <answer> pr_warn("Ignoring 
<token> void __init squash_mem_tags(struct tag *tag) <answer> static 
for <token> tag->hdr.size; tag = tag_next(tag)) <answer> (; 
if (tag->hdr.tag <token> ATAG_MEM) <answer> == 
<token> = ATAG_NONE; <answer> tag->hdr.tag 
const struct machine_desc * <token> <answer> __init 
<token> *atags_vaddr, unsigned int machine_nr) <answer> setup_machine_tags(void 
struct <token> *tags = (struct tag *)&default_tags; <answer> tag 
const struct <token> *mdesc = NULL, *p; <answer> machine_desc 
char *from <token> default_command_line; <answer> = 
default_tags.mem.start <token> PHYS_OFFSET; <answer> = 
if (machine_nr == p->nr) <token> <answer> { 
<token> %s\n", p->name); <answer> pr_info("Machine: 
mdesc = <token> <answer> p; 
<token> (!mdesc) <answer> if 
return <token> <answer> NULL; 
<token> (atags_vaddr) <answer> if 
<token> = atags_vaddr; <answer> tags 
else if <token> <answer> (mdesc->atag_offset) 
tags = (void *)(PAGE_OFFSET <token> mdesc->atag_offset); <answer> + 
#if <token> <answer> defined(CONFIG_DEPRECATED_PARAM_STRUCT) 
<token> (tags->hdr.tag != ATAG_CORE) <answer> if 
if (tags->hdr.tag <token> ATAG_CORE) { <answer> != 
early_print("Warning: <token> atags nor dtb found\n"); <answer> Neither 
tags <token> (struct tag *)&default_tags; <answer> = 
<token> (mdesc->fixup) <answer> if 
mdesc->fixup(tags, <token> <answer> &from); 
if (tags->hdr.tag == <token> { <answer> ATAG_CORE) 
<token> (memblock_phys_mem_size()) <answer> if 
#include <token> <answer> <linux/acpi.h> 
#include <token> <answer> <linux/gpio/consumer.h> 
<token> <linux/string.h> <answer> #include 
<token> "cs35l41_hda_property.h" <answer> #include 
#include <token> <answer> <linux/spi/spi.h> 
<token> MAX_AMPS 4 <answer> #define 
struct cs35l41_config <token> <answer> { 
const char <token> <answer> *ssid; 
<token> num_amps; <answer> int 
<token> { <answer> enum 
} <token> <answer> boost_type; 
<token> channel[MAX_AMPS]; <answer> u8 
{ "103C89C6", 2, INTERNAL, { CS35L41_RIGHT, CS35L41_LEFT, 0, 0 <token> -1, -1, -1, 1000, 4500, 24 }, <answer> }, 
{ "103C8A28", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, 24 <token> <answer> }, 
{ "103C8A29", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, <token> 0 }, 0, 1, -1, 1000, 4100, 24 }, <answer> 0, 
{ "103C8A2A", 2, <token> { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, 24 }, <answer> INTERNAL, 
{ "103C8A2B", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, <token> }, <answer> 24 
{ "103C8A2C", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, 24 <token> <answer> }, 
{ "103C8A2D", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, <token> 24 }, <answer> 4100, 
{ "103C8A2E", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 <token> 0, 1, -1, 1000, 4100, 24 }, <answer> }, 
{ "103C8A30", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, 24 <token> <answer> }, 
{ "103C8A31", 2, <token> { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, 24 }, <answer> INTERNAL, 
{ "103C8A6E", 4, <token> { CS35L41_LEFT, CS35L41_LEFT, CS35L41_RIGHT, CS35L41_RIGHT }, 0, -1, -1, 0, 0, 0 }, <answer> EXTERNAL, 
{ "103C8BB3", 2, INTERNAL, { CS35L41_LEFT, <token> 0, 0 }, 0, 1, -1, 1000, 4100, 24 }, <answer> CS35L41_RIGHT, 
{ "103C8BB4", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, <token> }, 0, 1, -1, 1000, 4100, 24 }, <answer> 0 
{ "103C8BDD", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, <token> }, 0, 1, -1, 1000, 4100, 24 }, <answer> 0 
{ "103C8BDE", <token> INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, 24 }, <answer> 2, 
{ "103C8BDF", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 <token> 0, 1, -1, 1000, 4100, 24 }, <answer> }, 
{ "103C8BE0", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, <token> 24 }, <answer> 4100, 
{ "103C8BE1", 2, <token> { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, 24 }, <answer> INTERNAL, 
{ "103C8BE2", 2, INTERNAL, { CS35L41_LEFT, <token> 0, 0 }, 0, 1, -1, 1000, 4100, 24 }, <answer> CS35L41_RIGHT, 
{ "103C8BE3", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, <token> 1, -1, 1000, 4100, 24 }, <answer> 0, 
{ "103C8BE5", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, <token> 24 }, <answer> 4100, 
{ "103C8BE6", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, <token> -1, 1000, 4100, 24 }, <answer> 1, 
<token> "103C8BE7", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, 24 }, <answer> { 
{ "103C8BE8", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, <token> -1, 1000, 4100, 24 }, <answer> 1, 
{ "103C8BE9", 2, INTERNAL, { CS35L41_LEFT, <token> 0, 0 }, 0, 1, -1, 1000, 4100, 24 }, <answer> CS35L41_RIGHT, 
{ "103C8B3A", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, 24 <token> <answer> }, 
{ "103C8C15", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 <token> 0, 1, -1, 1000, 4000, 24 }, <answer> }, 
{ "103C8C16", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, <token> 1, -1, 1000, 4000, 24 }, <answer> 0, 
{ "103C8C17", <token> INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4000, 24 }, <answer> 2, 
{ "103C8C4F", 2, INTERNAL, { <token> CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, 24 }, <answer> CS35L41_LEFT, 
{ "103C8C50", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, <token> 1000, 4100, 24 }, <answer> -1, 
{ "103C8C51", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 <token> 0, 1, -1, 1000, 4100, 24 }, <answer> }, 
{ "103C8CDD", 2, INTERNAL, { <token> CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4100, 24 }, <answer> CS35L41_LEFT, 
{ "103C8CDE", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, <token> 3900, 24 }, <answer> 1000, 
{ "104312AF", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, <token> 0, 1000, 4500, 24 }, <answer> 2, 
{ "10431433", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4500, 24 <token> <answer> }, 
{ "10431463", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, <token> }, 0, 1, -1, 1000, 4500, 24 }, <answer> 0 
{ "10431473", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, <token> 0, 1000, 4500, 24 }, <answer> -1, 
{ "10431483", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, -1, 0, 1000, 4500, 24 <token> <answer> }, 
{ "10431493", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, <token> 2, 0, 1000, 4500, 24 }, <answer> 1, 
{ "104314D3", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, 2, 0, 1000, 4500, <token> }, <answer> 24 
{ "104314E3", 2, <token> { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4500, 24 }, <answer> INTERNAL, 
{ "10431503", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, <token> 1, -1, 1000, 4500, 24 }, <answer> 0, 
<token> "10431533", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4500, 24 }, <answer> { 
{ "10431573", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, <token> 2, 0, 1000, 4500, 24 }, <answer> 1, 
{ "10431663", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, -1, 0, 1000, 4500, <token> }, <answer> 24 
{ "10431683", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 0, 0, <token> }, <answer> 0 
{ <token> 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, 2, 0, 0, 0, 0 }, <answer> "104316A3", 
{ <token> 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, 2, 0, 0, 0, 0 }, <answer> "104316D3", 
{ "104316F3", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, 2, 0, <token> 0, 0 }, <answer> 0, 
{ "104317F3", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4500, <token> }, <answer> 24 
{ "10431863", 2, INTERNAL, { <token> CS35L41_RIGHT, 0, 0 }, 1, 2, 0, 1000, 4500, 24 }, <answer> CS35L41_LEFT, 
{ "104318D3", 2, EXTERNAL, <token> CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 0, 0, 0 }, <answer> { 
{ "10431A83", 2, INTERNAL, <token> CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4500, 24 }, <answer> { 
{ "10431C9F", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, <token> 2, 0, 1000, 4500, 24 }, <answer> 1, 
{ "10431CAF", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, <token> 2, 0, 1000, 4500, 24 }, <answer> 1, 
{ "10431CCF", 2, INTERNAL, <token> CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, 2, 0, 1000, 4500, 24 }, <answer> { 
{ "10431CDF", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, 2, 0, <token> 4500, 24 }, <answer> 1000, 
{ "10431CEF", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, 2, <token> 1000, 4500, 24 }, <answer> 0, 
<token> "10431D1F", 2, INTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4500, 24 }, <answer> { 
{ "10431DA2", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, 2, 0, 0, 0, 0 <token> <answer> }, 
{ "10431E02", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, <token> 2, 0, 0, 0, 0 }, <answer> 1, 
{ "10431E12", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 0, <token> 0 }, <answer> 0, 
<token> "10431EE2", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, -1, -1, 0, 0, 0 }, <answer> { 
{ "10431F12", 2, <token> { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 1000, 4500, 24 }, <answer> INTERNAL, 
{ "10431F1F", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 <token> 1, -1, 0, 0, 0, 0 }, <answer> }, 
{ "10431F62", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 1, 2, 0, 0, 0, <token> }, <answer> 0 
{ "10433A60", 2, INTERNAL, { CS35L41_LEFT, <token> 0, 0 }, 1, 2, 0, 1000, 4500, 24 }, <answer> CS35L41_RIGHT, 
{ "17AA386F", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, <token> -1, 0, 0, 0 }, <answer> -1, 
{ "17AA3877", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, <token> 0, 0, 0 }, <answer> -1, 
{ "17AA3878", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, <token> 0, 0 }, <answer> 0, 
{ "17AA38A9", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, <token> }, 0, 2, -1, 0, 0, 0 }, <answer> 0 
{ <token> 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 2, -1, 0, 0, 0 }, <answer> "17AA38AB", 
{ "17AA38B4", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 0, 0, 0 <token> <answer> }, 
{ "17AA38B5", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, <token> -1, 0, 0, 0 }, <answer> 1, 
{ "17AA38B6", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, 0 }, 0, 1, -1, 0, 0, <token> }, <answer> 0 
{ "17AA38B7", 2, EXTERNAL, { CS35L41_LEFT, CS35L41_RIGHT, 0, <token> }, 0, 1, -1, 0, 0, 0 }, <answer> 0 
static int cs35l41_add_gpios(struct cs35l41_hda *cs35l41, struct device <token> int reset_gpio, <answer> *physdev, 
int spkid_gpio, int <token> int num_amps) <answer> cs_gpio_index, 
struct acpi_gpio_mapping *gpio_mapping = <token> <answer> NULL; 
struct acpi_gpio_params *reset_gpio_params <token> NULL; <answer> = 
struct acpi_gpio_params <token> = NULL; <answer> *spkid_gpio_params 
<token> acpi_gpio_params *cs_gpio_params = NULL; <answer> struct 
unsigned int <token> = 0; <answer> num_entries 
unsigned int reset_index, spkid_index, <token> <answer> csgpio_index; 
<token> i; <answer> int 
<token> (cs35l41->dacpi->driver_gpios) <answer> if 
<token> 0; <answer> return 
if (reset_gpio >= <token> { <answer> 0) 
reset_index = <token> <answer> num_entries; 
if (spkid_gpio <token> 0) { <answer> >= 
<token> = num_entries; <answer> spkid_index 
if ((cs_gpio_index <token> 0) && (num_amps == 2)) { <answer> >= 
csgpio_index = <token> <answer> num_entries; 
if <token> <answer> (!num_entries) 
return <token> <answer> 0; 
if (IS_ENABLED(CONFIG_SPI) && <token> >= 0) { <answer> cfg->cs_gpio_index 
<token> = to_spi_device(cs35l41->dev); <answer> spi 
if <token> != 2) { <answer> (cfg->num_amps 
"Cannot update SPI CS, <token> of Amps (%d) != 2\n", <answer> Number 
<token> else if (dsd_found) { <answer> } 
"Cannot update SPI CS, <token> already exists.\n"); <answer> _DSD 
} <token> { <answer> else 
cs_gpiod = gpiod_get_index(physdev, "cs", <token> GPIOD_OUT_LOW); <answer> 0, 
if <token> { <answer> (IS_ERR(cs_gpiod)) 
"Unable to get Chip Select <token> descriptor\n"); <answer> GPIO 
return <token> <answer> PTR_ERR(cs_gpiod); 
if (id == 1) <token> <answer> { 
spi_set_csgpiod(spi, <token> cs_gpiod); <answer> 0, 
cs35l41->cs_gpio <token> cs_gpiod; <answer> = 
<token> else { <answer> } 
<token> true); <answer> gpiod_set_value_cansleep(cs_gpiod, 
<token> else { <answer> } 
if <token> > 2) <answer> (cfg->num_amps 
cs35l41->index = <token> - 0x40; <answer> id 
static int hp_i2c_int_2amp_dual_spkid(struct cs35l41_hda *cs35l41, struct device <token> int id, <answer> *physdev, 
const char <token> <answer> *hid) 
struct cs35l41_hw_cfg <token> = &cs35l41->hw_cfg; <answer> *hw_cfg 
<token> int lenovo_legion_no_acpi(struct cs35l41_hda *cs35l41, struct device *physdev, int id, <answer> static 
<token> char *hid) <answer> const 
struct cs35l41_hw_cfg *hw_cfg <token> &cs35l41->hw_cfg; <answer> = 
<token> <linux/module.h> <answer> #include 
<token> <linux/types.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/sched.h> <answer> #include 
<token> <asm/io.h> <answer> #include 
#include <token> <answer> <asm/byteorder.h> 
<token> <linux/errno.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/mtd/map.h> <answer> #include 
<token> <linux/mtd/cfi.h> <answer> #include 
<token> <linux/mtd/mtd.h> <answer> #include 
static int cfi_staa_read(struct mtd_info *, loff_t, size_t, <token> *, u_char *); <answer> size_t 
static int cfi_staa_write_buffers(struct <token> *, loff_t, size_t, size_t *, const u_char *); <answer> mtd_info 
static int cfi_staa_writev(struct mtd_info *mtd, const struct <token> *vecs, <answer> kvec 
<token> long count, loff_t to, size_t *retlen); <answer> unsigned 
static int cfi_staa_erase_varsize(struct <token> *, struct erase_info *); <answer> mtd_info 
static void <token> (struct mtd_info *); <answer> cfi_staa_sync 
static int cfi_staa_lock(struct <token> *mtd, loff_t ofs, uint64_t len); <answer> mtd_info 
static int cfi_staa_unlock(struct mtd_info *mtd, loff_t ofs, <token> len); <answer> uint64_t 
static int cfi_staa_suspend (struct mtd_info <token> <answer> *); 
static <token> cfi_staa_resume (struct mtd_info *); <answer> void 
static void cfi_staa_destroy(struct <token> *); <answer> mtd_info 
struct mtd_info *cfi_cmdset_0020(struct <token> *, int); <answer> map_info 
static <token> mtd_info *cfi_staa_setup (struct map_info *); <answer> struct 
static struct <token> cfi_staa_chipdrv = { <answer> mtd_chip_driver 
struct mtd_info <token> map_info *map, int primary) <answer> *cfi_cmdset_0020(struct 
struct cfi_private *cfi <token> map->fldrv_priv; <answer> = 
int <token> <answer> i; 
if <token> { <answer> (cfi->cfi_mode) 
__u16 adr = <token> <answer> primary?cfi->cfiq->P_ADR:cfi->cfiq->A_ADR; 
struct cfi_pri_intelext <token> <answer> *extp; 
extp = (struct <token> adr, sizeof(*extp), "ST Microelectronics"); <answer> cfi_pri_intelext*)cfi_read_pri(map, 
<token> (!extp) <answer> if 
<token> NULL; <answer> return 
if (extp->MajorVersion != '1' <token> <answer> || 
(extp->MinorVersion < <token> || extp->MinorVersion > '3')) { <answer> '0' 
printk(KERN_ERR " <token> ST Microelectronics" <answer> Unknown 
" Extended Query version <token> <answer> %c.%c.\n", 
extp->MajorVersion, <token> <answer> extp->MinorVersion); 
return <token> <answer> NULL; 
<token> (chip->state) { <answer> switch 
case <token> <answer> FL_ERASING: 
<token> (!(((struct cfi_pri_intelext *)cfi->cmdset_priv)->FeatureSupport & 2)) <answer> if 
map_write(map, CMD(0x70), <token> <answer> cmd_addr); 
chip->oldstate = <token> <answer> FL_ERASING; 
<token> = FL_ERASE_SUSPENDING; <answer> chip->state 
for <token> { <answer> (;;) 
status <token> map_read(map, cmd_addr); <answer> = 
<token> (map_word_andequal(map, status, status_OK, status_OK)) <answer> if 
<token> (time_after(jiffies, timeo)) { <answer> if 
<token> &wait); <answer> add_wait_queue(&chip->wq, 
<token> &wait); <answer> remove_wait_queue(&chip->wq, 
timeo = <token> + HZ; <answer> jiffies 
goto <token> <answer> retry; 
map_copy_from(map, <token> adr, len); <answer> buf, 
if (suspended) <token> <answer> { 
chip->state = <token> <answer> chip->oldstate; 
map_write(map, <token> cmd_addr); <answer> CMD(0xd0), 
<token> CMD(0x70), cmd_addr); <answer> map_write(map, 
<token> 0; <answer> return 
static int cfi_staa_read (struct mtd_info *mtd, loff_t from, size_t len, <token> *retlen, u_char *buf) <answer> size_t 
struct map_info *map <token> mtd->priv; <answer> = 
struct cfi_private *cfi <token> map->fldrv_priv; <answer> = 
<token> long ofs; <answer> unsigned 
<token> chipnum; <answer> int 
<token> ret = 0; <answer> int 
switch <token> { <answer> (chip->state) 
<token> FL_READY: <answer> case 
<token> FL_CFI_QUERY: <answer> case 
case <token> <answer> FL_JEDEC_QUERY: 
map_write(map, CMD(0x70), <token> <answer> cmd_adr); 
chip->state <token> FL_STATUS; <answer> = 
#ifdef <token> <answer> DEBUG_CFI_FEATURES 
printk("%s: 1 status[%x]\n", __func__, <token> cmd_adr)); <answer> map_read(map, 
<token> FL_STATUS: <answer> case 
<token> = map_read(map, cmd_adr); <answer> status 
if (map_word_andequal(map, status, <token> status_OK)) <answer> status_OK, 
add_wait_queue(&chip->wq, <token> <answer> &wait); 
remove_wait_queue(&chip->wq, <token> <answer> &wait); 
<token> = jiffies + HZ; <answer> timeo 
goto <token> <answer> retry; 
map_write(map, <token> cmd_adr); <answer> CMD(0xe8), 
<token> = FL_WRITING_TO_BUFFER; <answer> chip->state 
z = <token> <answer> 0; 
<token> (;;) { <answer> for 
status = map_read(map, <token> <answer> cmd_adr); 
<token> (map_word_andequal(map, status, status_OK, status_OK)) <answer> if 
if (++z <token> 100) { <answer> > 
#define <token> (mtd->writesize) <answer> ECCBUF_SIZE 
<token> ECCBUF_DIV(x) ((x) & ~(ECCBUF_SIZE - 1)) <answer> #define 
#define ECCBUF_MOD(x) ((x) & <token> - 1)) <answer> (ECCBUF_SIZE 
static <token> <answer> int 
cfi_staa_writev(struct mtd_info <token> const struct kvec *vecs, <answer> *mtd, 
unsigned long count, <token> to, size_t *retlen) <answer> loff_t 
unsigned <token> i; <answer> long 
<token> totlen = 0, thislen; <answer> size_t 
int ret <token> 0; <answer> = 
size_t <token> = 0; <answer> buflen 
char <token> <answer> *buffer; 
if (!ECCBUF_SIZE) <token> <answer> { 
<token> -EIO; <answer> return 
<token> = kmalloc(ECCBUF_SIZE, GFP_KERNEL); <answer> buffer 
<token> (!buffer) <answer> if 
<token> -ENOMEM; <answer> return 
for (i=0; <token> i++) { <answer> i<count; 
size_t <token> = vecs[i].iov_len; <answer> elem_len 
void *elem_base = <token> <answer> vecs[i].iov_base; 
<token> &wait); <answer> add_wait_queue(&chip->wq, 
<token> &wait); <answer> remove_wait_queue(&chip->wq, 
timeo = jiffies + <token> <answer> HZ; 
<token> retry; <answer> goto 
i <token> 0; <answer> = 
while (i < mtd->numeraseregions <token> instr->addr >= regions[i].offset) <answer> && 
if (instr->addr & <token> <answer> (regions[i].erasesize-1)) 
<token> -EINVAL; <answer> return 
while (i<mtd->numeraseregions && (instr->addr + instr->len) >= <token> <answer> regions[i].offset) 
<token> ((instr->addr + instr->len) & (regions[i].erasesize-1)) <answer> if 
return <token> <answer> -EINVAL; 
chipnum = instr->addr >> <token> <answer> cfi->chipshift; 
adr = instr->addr - <token> << cfi->chipshift); <answer> (chipnum 
<token> = instr->len; <answer> len 
<token> { <answer> while(len) 
<token> = do_erase_oneblock(map, &cfi->chips[chipnum], adr); <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ret; 
<token> += regions[i].erasesize; <answer> adr 
len <token> regions[i].erasesize; <answer> -= 
if (adr % (1<< cfi->chipshift) == (((unsigned <token> + (regions[i].erasesize * regions[i].numblocks)) %( 1<< cfi->chipshift))) <answer> long)regions[i].offset 
<token> (adr >> cfi->chipshift) { <answer> if 
adr = <token> <answer> 0; 
if (chipnum >= <token> <answer> cfi->numchips) 
<token> 0; <answer> return 
static void <token> (struct mtd_info *mtd) <answer> cfi_staa_sync 
struct map_info <token> = mtd->priv; <answer> *map 
struct cfi_private *cfi = <token> <answer> map->fldrv_priv; 
<token> i; <answer> int 
struct flchip <token> <answer> *chip; 
<token> ret = 0; <answer> int 
<token> current); <answer> DECLARE_WAITQUEUE(wait, 
<token> (i=0; !ret && i<cfi->numchips; i++) { <answer> for 
chip <token> &cfi->chips[i]; <answer> = 
switch(chip->state) <token> <answer> { 
<token> FL_READY: <answer> case 
<token> FL_STATUS: <answer> case 
<token> FL_CFI_QUERY: <answer> case 
case <token> <answer> FL_JEDEC_QUERY: 
<token> = chip->state; <answer> chip->oldstate 
chip->state <token> FL_SYNCING; <answer> = 
case <token> <answer> FL_SYNCING: 
<token> &wait); <answer> add_wait_queue(&chip->wq, 
remove_wait_queue(&chip->wq, <token> <answer> &wait); 
timeo = jiffies + <token> <answer> HZ; 
<token> retry; <answer> goto 
map_write(map, <token> adr); <answer> CMD(0x60), 
map_write(map, CMD(0x01), <token> <answer> adr); 
chip->state <token> FL_LOCKING; <answer> = 
add_wait_queue(&chip->wq, <token> <answer> &wait); 
<token> &wait); <answer> remove_wait_queue(&chip->wq, 
timeo = jiffies + <token> <answer> HZ; 
goto <token> <answer> retry; 
map_write(map, CMD(0x60), <token> <answer> adr); 
map_write(map, <token> adr); <answer> CMD(0xD0), 
chip->state <token> FL_UNLOCKING; <answer> = 
<token> FL_PM_SUSPENDED: <answer> case 
ret <token> -EAGAIN; <answer> = 
chip->state <token> chip->oldstate; <answer> = 
return <token> <answer> ret; 
static void cfi_staa_resume(struct <token> *mtd) <answer> mtd_info 
struct map_info <token> = mtd->priv; <answer> *map 
struct <token> *cfi = map->fldrv_priv; <answer> cfi_private 
int <token> <answer> i; 
struct flchip <token> <answer> *chip; 
for <token> i<cfi->numchips; i++) { <answer> (i=0; 
chip = <token> <answer> &cfi->chips[i]; 
#include <token> <answer> "core.h" 
<token> "dp_tx.h" <answer> #include 
<token> "debug.h" <answer> #include 
<token> "hw.h" <answer> #include 
static <token> hal_tcl_encap_type <answer> enum 
ath12k_dp_tx_get_encap_type(struct ath12k_vif <token> struct sk_buff *skb) <answer> *arvif, 
struct ieee80211_tx_info <token> = IEEE80211_SKB_CB(skb); <answer> *tx_info 
struct <token> *ab = arvif->ar->ab; <answer> ath12k_base 
<token> (test_bit(ATH12K_FLAG_RAW_MODE, &ab->dev_flags)) <answer> if 
<token> HAL_TCL_ENCAP_TYPE_RAW; <answer> return 
if (tx_info->flags <token> IEEE80211_TX_CTL_HW_80211_ENCAP) <answer> & 
return <token> <answer> HAL_TCL_ENCAP_TYPE_ETHERNET; 
return <token> <answer> HAL_TCL_ENCAP_TYPE_NATIVE_WIFI; 
<token> void ath12k_dp_tx_encap_nwifi(struct sk_buff *skb) <answer> static 
struct ieee80211_hdr <token> = (void *)skb->data; <answer> *hdr 
u8 <token> <answer> *qos_ctl; 
<token> (!ieee80211_is_data_qos(hdr->frame_control)) <answer> if 
<token> = ieee80211_get_qos_ctl(hdr); <answer> qos_ctl 
memmove(skb->data + <token> <answer> IEEE80211_QOS_CTL_LEN, 
skb->data, (void *)qos_ctl - (void <token> <answer> *)skb->data); 
<token> IEEE80211_QOS_CTL_LEN); <answer> skb_pull(skb, 
hdr = (void <token> <answer> *)skb->data; 
<token> &= ~__cpu_to_le16(IEEE80211_STYPE_QOS_DATA); <answer> hdr->frame_control 
<token> u8 ath12k_dp_tx_get_tid(struct sk_buff *skb) <answer> static 
struct ieee80211_hdr *hdr = <token> *)skb->data; <answer> (void 
struct ath12k_skb_cb <token> = ATH12K_SKB_CB(skb); <answer> *cb 
if (cb->flags <token> ATH12K_SKB_HW_80211_ENCAP) <answer> & 
return skb->priority & <token> <answer> IEEE80211_QOS_CTL_TID_MASK; 
else if <token> <answer> (!ieee80211_is_data_qos(hdr->frame_control)) 
<token> HAL_DESC_REO_NON_QOS_TID; <answer> return 
<token> skb->priority & IEEE80211_QOS_CTL_TID_MASK; <answer> return 
enum hal_encrypt_type <token> cipher) <answer> ath12k_dp_tx_get_encrypt_type(u32 
switch (cipher) <token> <answer> { 
<token> WLAN_CIPHER_SUITE_WEP40: <answer> case 
return <token> <answer> HAL_ENCRYPT_TYPE_WEP_40; 
case <token> <answer> WLAN_CIPHER_SUITE_WEP104: 
<token> HAL_ENCRYPT_TYPE_WEP_104; <answer> return 
<token> WLAN_CIPHER_SUITE_TKIP: <answer> case 
<token> HAL_ENCRYPT_TYPE_TKIP_MIC; <answer> return 
<token> WLAN_CIPHER_SUITE_CCMP: <answer> case 
<token> HAL_ENCRYPT_TYPE_CCMP_128; <answer> return 
case <token> <answer> WLAN_CIPHER_SUITE_CCMP_256: 
return <token> <answer> HAL_ENCRYPT_TYPE_CCMP_256; 
<token> WLAN_CIPHER_SUITE_GCMP: <answer> case 
<token> HAL_ENCRYPT_TYPE_GCMP_128; <answer> return 
case <token> <answer> WLAN_CIPHER_SUITE_GCMP_256: 
return <token> <answer> HAL_ENCRYPT_TYPE_AES_GCMP_256; 
return <token> <answer> HAL_ENCRYPT_TYPE_OPEN; 
static void ath12k_dp_tx_release_txbuf(struct <token> *dp, <answer> ath12k_dp 
<token> ath12k_tx_desc_info *tx_desc, <answer> struct 
<token> pool_id) <answer> u8 
<token> &dp->tx_desc_free_list[pool_id]); <answer> list_move_tail(&tx_desc->list, 
<token> struct ath12k_tx_desc_info *ath12k_dp_tx_assign_buffer(struct ath12k_dp *dp, <answer> static 
<token> pool_id) <answer> u8 
struct <token> *desc; <answer> ath12k_tx_desc_info 
<token> = list_first_entry_or_null(&dp->tx_desc_free_list[pool_id], <answer> desc 
struct <token> <answer> ath12k_tx_desc_info, 
if <token> { <answer> (!desc) 
ath12k_warn(dp->ab, "failed to <token> data Tx buffer\n"); <answer> allocate 
<token> NULL; <answer> return 
list_move_tail(&desc->list, <token> <answer> &dp->tx_desc_used_list[pool_id]); 
return <token> <answer> desc; 
static void ath12k_hal_tx_cmd_ext_desc_setup(struct <token> *ab, <answer> ath12k_base 
struct <token> *tcl_ext_cmd, <answer> hal_tx_msdu_ext_desc 
struct <token> *ti) <answer> hal_tx_info 
tcl_ext_cmd->info0 <token> le32_encode_bits(ti->paddr, <answer> = 
<token> = le32_encode_bits(0x0, <answer> tcl_ext_cmd->info1 
HAL_TX_MSDU_EXT_INFO1_BUF_PTR_HI) <token> <answer> | 
tcl_ext_cmd->info1 = le32_encode_bits(1, HAL_TX_MSDU_EXT_INFO1_EXTN_OVERRIDE) <token> <answer> | 
<token> | <answer> HAL_TX_MSDU_EXT_INFO1_ENCAP_TYPE) 
<token> ath12k_dp_tx(struct ath12k *ar, struct ath12k_vif *arvif, <answer> int 
<token> sk_buff *skb) <answer> struct 
struct ath12k_base <token> = ar->ab; <answer> *ab 
struct ath12k_dp <token> = &ab->dp; <answer> *dp 
<token> hal_tx_info ti = {0}; <answer> struct 
struct ath12k_tx_desc_info <token> <answer> *tx_desc; 
struct ieee80211_tx_info <token> = IEEE80211_SKB_CB(skb); <answer> *info 
struct ath12k_skb_cb <token> = ATH12K_SKB_CB(skb); <answer> *skb_cb 
struct <token> *hal_tcl_desc; <answer> hal_tcl_data_cmd 
<token> hal_tx_msdu_ext_desc *msg; <answer> struct 
struct sk_buff <token> <answer> *skb_ext_desc; 
<token> hal_srng *tcl_ring; <answer> struct 
struct ieee80211_hdr *hdr = <token> *)skb->data; <answer> (void 
struct <token> *tx_ring; <answer> dp_tx_ring 
u8 <token> <answer> pool_id; 
u8 <token> <answer> hal_ring_id; 
int <token> <answer> ret; 
u8 <token> ring_map = 0; <answer> ring_selector, 
<token> tcl_ring_retry; <answer> bool 
bool msdu_ext_desc <token> false; <answer> = 
if (test_bit(ATH12K_FLAG_CRASH_FLUSH, <token> <answer> &ar->ab->dev_flags)) 
<token> -ESHUTDOWN; <answer> return 
if <token> & IEEE80211_TX_CTL_HW_80211_ENCAP) && <answer> (!(info->flags 
return <token> <answer> -EOPNOTSUPP; 
pool_id = skb_get_queue_mapping(skb) <token> (ATH12K_HW_MAX_QUEUES - 1); <answer> & 
<token> = ab->hw_params->hw_ops->get_ring_selector(skb); <answer> ring_selector 
<token> = false; <answer> tcl_ring_retry 
ti.ring_id = <token> % ab->hw_params->max_tx_ring; <answer> ring_selector 
ring_map |= <token> <answer> BIT(ti.ring_id); 
ti.rbm_id <token> ab->hw_params->hal_ops->tcl_to_wbm_rbm_map[ti.ring_id].rbm_id; <answer> = 
tx_ring <token> &dp->tx_ring[ti.ring_id]; <answer> = 
<token> = ath12k_dp_tx_assign_buffer(dp, pool_id); <answer> tx_desc 
if <token> <answer> (!tx_desc) 
return <token> <answer> -ENOMEM; 
ti.bank_id <token> arvif->bank_id; <answer> = 
<token> = arvif->tcl_metadata; <answer> ti.meta_data_flags 
if (arvif->tx_encap_type == <token> && <answer> HAL_TCL_ENCAP_TYPE_RAW 
test_bit(ATH12K_FLAG_HW_CRYPTO_DISABLED, &ar->ab->dev_flags)) <token> <answer> { 
<token> (skb_cb->flags & ATH12K_SKB_CIPHER_SET) { <answer> if 
ti.encrypt_type <token> <answer> = 
<token> (ieee80211_has_protected(hdr->frame_control)) <answer> if 
<token> IEEE80211_CCMP_MIC_LEN); <answer> skb_put(skb, 
<token> else { <answer> } 
ti.encrypt_type = <token> <answer> HAL_ENCRYPT_TYPE_OPEN; 
msdu_ext_desc = <token> <answer> true; 
ti.encap_type = <token> skb); <answer> ath12k_dp_tx_get_encap_type(arvif, 
ti.addr_search_flags <token> arvif->hal_addr_search_flags; <answer> = 
ti.search_type = <token> <answer> arvif->search_type; 
ti.type = <token> <answer> HAL_TCL_DESC_TYPE_BUFFER; 
ti.pkt_offset = <token> <answer> 0; 
ti.lmac_id = <token> <answer> ar->lmac_id; 
<token> = arvif->vdev_id; <answer> ti.vdev_id 
ti.bss_ast_hash = <token> <answer> arvif->ast_hash; 
ti.bss_ast_idx = <token> <answer> arvif->ast_idx; 
ti.dscp_tid_tbl_idx = <token> <answer> 0; 
if (skb->ip_summed == CHECKSUM_PARTIAL <token> <answer> && 
ti.encap_type <token> HAL_TCL_ENCAP_TYPE_RAW) { <answer> != 
ti.flags0 |= u32_encode_bits(1, <token> | <answer> HAL_TCL_DATA_CMD_INFO2_IP4_CKSUM_EN) 
u32_encode_bits(1, <token> | <answer> HAL_TCL_DATA_CMD_INFO2_UDP4_CKSUM_EN) 
u32_encode_bits(1, HAL_TCL_DATA_CMD_INFO2_UDP6_CKSUM_EN) <token> <answer> | 
<token> HAL_TCL_DATA_CMD_INFO2_TCP4_CKSUM_EN) | <answer> u32_encode_bits(1, 
<token> HAL_TCL_DATA_CMD_INFO2_TCP6_CKSUM_EN); <answer> u32_encode_bits(1, 
ti.flags1 |= u32_encode_bits(1, <token> <answer> HAL_TCL_DATA_CMD_INFO3_TID_OVERWRITE); 
ti.tid <token> ath12k_dp_tx_get_tid(skb); <answer> = 
switch <token> { <answer> (ti.encap_type) 
case <token> <answer> HAL_TCL_ENCAP_TYPE_NATIVE_WIFI: 
<token> HAL_TCL_ENCAP_TYPE_RAW: <answer> case 
if <token> &ab->dev_flags)) { <answer> (!test_bit(ATH12K_FLAG_RAW_MODE, 
ret <token> -EINVAL; <answer> = 
<token> fail_remove_tx_buf; <answer> goto 
case <token> <answer> HAL_TCL_ENCAP_TYPE_ETHERNET: 
<token> tcl_ring); <answer> ath12k_hal_srng_access_end(ab, 
ret <token> -ENOMEM; <answer> = 
if (ring_map != <token> - 1) && <answer> (BIT(ab->hw_params->max_tx_ring) 
ab->hw_params->tcl_ring_retry) <token> <answer> { 
<token> = true; <answer> tcl_ring_retry 
<token> fail_unmap_dma; <answer> goto 
ath12k_hal_tx_cmd_desc_setup(ab, hal_tcl_desc, <token> <answer> &ti); 
<token> tcl_ring); <answer> ath12k_hal_srng_access_end(ab, 
ath12k_dbg_dump(ab, ATH12K_DBG_DP_TX, NULL, "dp <token> msdu: ", <answer> tx 
<token> skb->len); <answer> skb->data, 
return <token> <answer> 0; 
dma_unmap_single(ab->dev, ti.paddr, ti.data_len, <token> <answer> DMA_TO_DEVICE); 
<token> (skb_cb->paddr_ext_desc) <answer> if 
<token> skb_cb->paddr_ext_desc, <answer> dma_unmap_single(ab->dev, 
sizeof(struct <token> <answer> hal_tx_msdu_ext_desc), 
<token> tx_desc, pool_id); <answer> ath12k_dp_tx_release_txbuf(dp, 
if <token> <answer> (tcl_ring_retry) 
<token> tcl_ring_sel; <answer> goto 
<token> ret; <answer> return 
<token> void ath12k_dp_tx_free_txbuf(struct ath12k_base *ab, <answer> static 
<token> sk_buff *msdu, u8 mac_id, <answer> struct 
<token> dp_tx_ring *tx_ring) <answer> struct 
struct ath12k <token> <answer> *ar; 
struct <token> *skb_cb; <answer> ath12k_skb_cb 
u8 pdev_id <token> ath12k_hw_mac_id_to_pdev_id(ab->hw_params, mac_id); <answer> = 
skb_cb = <token> <answer> ATH12K_SKB_CB(msdu); 
dma_unmap_single(ab->dev, skb_cb->paddr, <token> DMA_TO_DEVICE); <answer> msdu->len, 
if <token> <answer> (skb_cb->paddr_ext_desc) 
dma_unmap_single(ab->dev, <token> <answer> skb_cb->paddr_ext_desc, 
<token> hal_tx_msdu_ext_desc), DMA_TO_DEVICE); <answer> sizeof(struct 
ar <token> ab->pdevs[pdev_id].ar; <answer> = 
<token> (atomic_dec_and_test(&ar->dp.num_tx_pending)) <answer> if 
static <token> <answer> void 
<token> ath12k_base *ab, <answer> ath12k_dp_tx_htt_tx_complete_buf(struct 
<token> sk_buff *msdu, <answer> struct 
struct <token> *tx_ring, <answer> dp_tx_ring 
<token> ath12k_dp_htt_wbm_tx_status *ts) <answer> struct 
<token> ieee80211_tx_info *info; <answer> struct 
<token> ath12k_skb_cb *skb_cb; <answer> struct 
struct <token> *ar; <answer> ath12k 
skb_cb = <token> <answer> ATH12K_SKB_CB(msdu); 
<token> = IEEE80211_SKB_CB(msdu); <answer> info 
ar <token> skb_cb->ar; <answer> = 
<token> (atomic_dec_and_test(&ar->dp.num_tx_pending)) <answer> if 
dma_unmap_single(ab->dev, <token> msdu->len, DMA_TO_DEVICE); <answer> skb_cb->paddr, 
if <token> <answer> (skb_cb->paddr_ext_desc) 
dma_unmap_single(ab->dev, <token> <answer> skb_cb->paddr_ext_desc, 
<token> hal_tx_msdu_ext_desc), DMA_TO_DEVICE); <answer> sizeof(struct 
memset(&info->status, 0, <token> <answer> sizeof(info->status)); 
<token> (ts->acked) { <answer> if 
<token> (!(info->flags & IEEE80211_TX_CTL_NO_ACK)) { <answer> if 
info->flags |= <token> <answer> IEEE80211_TX_STAT_ACK; 
info->status.ack_signal = <token> + <answer> ATH12K_DEFAULT_NOISE_FLOOR 
info->status.flags = <token> <answer> IEEE80211_TX_STATUS_ACK_SIGNAL_VALID; 
} else <token> <answer> { 
info->flags <token> IEEE80211_TX_STAT_NOACK_TRANSMITTED; <answer> |= 
<token> msdu); <answer> ieee80211_tx_status_skb(ath12k_ar_to_hw(ar), 
<token> void <answer> static 
<token> ath12k_base *ab, <answer> ath12k_dp_tx_process_htt_tx_complete(struct 
void <token> u8 mac_id, <answer> *desc, 
struct sk_buff <token> <answer> *msdu, 
<token> dp_tx_ring *tx_ring) <answer> struct 
struct <token> *status_desc; <answer> htt_tx_wbm_completion 
struct <token> ts = {0}; <answer> ath12k_dp_htt_wbm_tx_status 
enum <token> wbm_status; <answer> hal_wbm_htt_tx_comp_status 
<token> = desc + HTT_TX_WBM_COMP_STATUS_OFFSET; <answer> status_desc 
wbm_status = <token> <answer> le32_get_bits(status_desc->info0, 
<token> (wbm_status) { <answer> switch 
case <token> <answer> HAL_WBM_REL_HTT_TX_COMP_STATUS_OK: 
<token> HAL_WBM_REL_HTT_TX_COMP_STATUS_DROP: <answer> case 
<token> HAL_WBM_REL_HTT_TX_COMP_STATUS_TTL: <answer> case 
ts.acked <token> (wbm_status == HAL_WBM_REL_HTT_TX_COMP_STATUS_OK); <answer> = 
ts.ack_rssi <token> le32_get_bits(status_desc->info2, <answer> = 
ath12k_dp_tx_htt_tx_complete_buf(ab, msdu, tx_ring, <token> <answer> &ts); 
case <token> <answer> HAL_WBM_REL_HTT_TX_COMP_STATUS_REINJ: 
<token> HAL_WBM_REL_HTT_TX_COMP_STATUS_INSPECT: <answer> case 
<token> msdu, mac_id, tx_ring); <answer> ath12k_dp_tx_free_txbuf(ab, 
case <token> <answer> HAL_WBM_REL_HTT_TX_COMP_STATUS_MEC_NOTIFY: 
ath12k_warn(ab, "Unknown htt tx status %d\n", <token> <answer> wbm_status); 
static void ath12k_dp_tx_complete_msdu(struct <token> *ar, <answer> ath12k 
struct sk_buff <token> <answer> *msdu, 
<token> hal_tx_status *ts) <answer> struct 
struct ath12k_base *ab <token> ar->ab; <answer> = 
<token> ieee80211_tx_info *info; <answer> struct 
struct <token> *skb_cb; <answer> ath12k_skb_cb 
<token> (WARN_ON_ONCE(ts->buf_rel_source != HAL_WBM_REL_SRC_MODULE_TQM)) { <answer> if 
<token> msdu); <answer> ieee80211_tx_status_skb(ath12k_ar_to_hw(ar), 
static <token> ath12k_dp_tx_status_parse(struct ath12k_base *ab, <answer> void 
struct <token> *desc, <answer> hal_wbm_completion_ring_tx 
<token> hal_tx_status *ts) <answer> struct 
ts->buf_rel_source <token> <answer> = 
<token> HAL_WBM_COMPL_TX_INFO0_REL_SRC_MODULE); <answer> le32_get_bits(desc->info0, 
if (ts->buf_rel_source <token> HAL_WBM_REL_SRC_MODULE_FW && <answer> != 
<token> != HAL_WBM_REL_SRC_MODULE_TQM) <answer> ts->buf_rel_source 
if (ts->buf_rel_source == <token> <answer> HAL_WBM_REL_SRC_MODULE_FW) 
<token> = le32_get_bits(desc->info0, <answer> ts->status 
<token> = le32_get_bits(desc->info1, <answer> ts->ppdu_id 
if (le32_to_cpu(desc->rate_stats.info0) <token> HAL_TX_RATE_STATS_INFO0_VALID) <answer> & 
ts->rate_stats = <token> <answer> le32_to_cpu(desc->rate_stats.info0); 
<token> = 0; <answer> ts->rate_stats 
void ath12k_dp_tx_completion_handler(struct <token> *ab, int ring_id) <answer> ath12k_base 
struct ath12k <token> <answer> *ar; 
<token> ath12k_dp *dp = &ab->dp; <answer> struct 
int hal_ring_id = <token> <answer> dp->tx_ring[ring_id].tcl_comp_ring.ring_id; 
struct hal_srng *status_ring <token> &ab->hal.srng_list[hal_ring_id]; <answer> = 
struct ath12k_tx_desc_info *tx_desc = <token> <answer> NULL; 
<token> sk_buff *msdu; <answer> struct 
struct hal_tx_status <token> = { 0 }; <answer> ts 
struct dp_tx_ring *tx_ring <token> &dp->tx_ring[ring_id]; <answer> = 
struct hal_wbm_release_ring <token> <answer> *desc; 
<token> mac_id, pdev_id; <answer> u8 
<token> desc_va; <answer> u64 
<token> status_ring); <answer> ath12k_hal_srng_access_begin(ab, 
while (ATH12K_TX_COMPL_NEXT(tx_ring->tx_status_head) <token> tx_ring->tx_status_tail) { <answer> != 
<token> = ath12k_hal_srng_dst_get_next_entry(ab, status_ring); <answer> desc 
if <token> <answer> (!desc) 
<token> sizeof(*desc)); <answer> desc, 
tx_ring->tx_status_head <token> <answer> = 
if (ath12k_hal_srng_dst_peek(ab, <token> && <answer> status_ring) 
(ATH12K_TX_COMPL_NEXT(tx_ring->tx_status_head) == <token> { <answer> tx_ring->tx_status_tail)) 
<token> tx_desc, tx_desc->pool_id); <answer> ath12k_dp_tx_release_txbuf(dp, 
if <token> == HAL_WBM_REL_SRC_MODULE_FW) { <answer> (ts.buf_rel_source 
<token> *)tx_status, <answer> (void 
mac_id, <token> <answer> msdu, 
pdev_id = <token> mac_id); <answer> ath12k_hw_mac_id_to_pdev_id(ab->hw_params, 
<token> = ab->pdevs[pdev_id].ar; <answer> ar 
if <token> <answer> (atomic_dec_and_test(&ar->dp.num_tx_pending)) 
ath12k_dp_tx_complete_msdu(ar, <token> &ts); <answer> msdu, 
static <token> <answer> int 
ath12k_dp_tx_get_ring_id_type(struct <token> *ab, <answer> ath12k_base 
int mac_id, <token> ring_id, <answer> u32 
enum hal_ring_type <token> <answer> ring_type, 
enum htt_srng_ring_type <token> <answer> *htt_ring_type, 
enum htt_srng_ring_id <token> <answer> *htt_ring_id) 
int ret = <token> <answer> 0; 
<token> (ring_type) { <answer> switch 
case <token> <answer> HAL_RXDMA_BUF: 
<token> (!ab->hw_params->rx_mac_buf_ring) { <answer> if 
if (!(ring_id == HAL_SRNG_SW2RXDMA_BUF0 <token> <answer> || 
ring_id == <token> { <answer> HAL_SRNG_SW2RXDMA_BUF1)) 
<token> = -EINVAL; <answer> ret 
*htt_ring_id <token> HTT_RXDMA_HOST_BUF_RING; <answer> = 
<token> = HTT_SW_TO_HW_RING; <answer> *htt_ring_type 
} else <token> <answer> { 
<token> (ring_id == HAL_SRNG_SW2RXDMA_BUF0) { <answer> if 
*htt_ring_id <token> HTT_HOST1_TO_FW_RXBUF_RING; <answer> = 
*htt_ring_type <token> HTT_SW_TO_SW_RING; <answer> = 
} <token> { <answer> else 
*htt_ring_id <token> HTT_RXDMA_HOST_BUF_RING; <answer> = 
*htt_ring_type = <token> <answer> HTT_SW_TO_HW_RING; 
<token> HAL_RXDMA_DST: <answer> case 
*htt_ring_id = <token> <answer> HTT_RXDMA_NON_MONITOR_DEST_RING; 
*htt_ring_type = <token> <answer> HTT_HW_TO_SW_RING; 
case <token> <answer> HAL_RXDMA_MONITOR_BUF: 
<token> = HTT_RXDMA_MONITOR_BUF_RING; <answer> *htt_ring_id 
<token> = HTT_SW_TO_HW_RING; <answer> *htt_ring_type 
case <token> <answer> HAL_RXDMA_MONITOR_STATUS: 
*htt_ring_id = <token> <answer> HTT_RXDMA_MONITOR_STATUS_RING; 
<token> = HTT_SW_TO_HW_RING; <answer> *htt_ring_type 
<token> HAL_RXDMA_MONITOR_DST: <answer> case 
*htt_ring_id = <token> <answer> HTT_RXDMA_MONITOR_DEST_RING; 
<token> = HTT_HW_TO_SW_RING; <answer> *htt_ring_type 
case <token> <answer> HAL_RXDMA_MONITOR_DESC: 
<token> = HTT_RXDMA_MONITOR_DESC_RING; <answer> *htt_ring_id 
*htt_ring_type <token> HTT_SW_TO_HW_RING; <answer> = 
case <token> <answer> HAL_TX_MONITOR_BUF: 
*htt_ring_id = <token> <answer> HTT_TX_MON_HOST2MON_BUF_RING; 
<token> = HTT_SW_TO_HW_RING; <answer> *htt_ring_type 
<token> HAL_TX_MONITOR_DST: <answer> case 
<token> = HTT_TX_MON_MON2HOST_DEST_RING; <answer> *htt_ring_id 
*htt_ring_type <token> HTT_HW_TO_SW_RING; <answer> = 
ath12k_warn(ab, "Unsupported ring type <token> DP :%d\n", ring_type); <answer> in 
ret = <token> <answer> -EINVAL; 
<token> ret; <answer> return 
<token> ath12k_dp_tx_htt_srng_setup(struct ath12k_base *ab, u32 ring_id, <answer> int 
int <token> enum hal_ring_type ring_type) <answer> mac_id, 
struct htt_srng_setup_cmd <token> <answer> *cmd; 
<token> hal_srng *srng = &ab->hal.srng_list[ring_id]; <answer> struct 
struct hal_srng_params <token> <answer> params; 
struct sk_buff <token> <answer> *skb; 
<token> ring_entry_sz; <answer> u32 
int len = <token> <answer> sizeof(*cmd); 
dma_addr_t hp_addr, <token> <answer> tp_addr; 
enum <token> htt_ring_type; <answer> htt_srng_ring_type 
enum htt_srng_ring_id <token> <answer> htt_ring_id; 
<token> ret; <answer> int 
skb = <token> len); <answer> ath12k_htc_alloc_skb(ab, 
if <token> <answer> (!skb) 
<token> -ENOMEM; <answer> return 
memset(&params, 0, <token> <answer> sizeof(params)); 
<token> srng, &params); <answer> ath12k_hal_srng_get_params(ab, 
hp_addr = <token> srng); <answer> ath12k_hal_srng_get_hp_addr(ab, 
tp_addr <token> ath12k_hal_srng_get_tp_addr(ab, srng); <answer> = 
ret = <token> mac_id, ring_id, <answer> ath12k_dp_tx_get_ring_id_type(ab, 
ring_type, <token> <answer> &htt_ring_type, 
<token> (ret) <answer> if 
<token> err_free; <answer> goto 
skb_put(skb, <token> <answer> len); 
cmd = <token> htt_srng_setup_cmd *)skb->data; <answer> (struct 
cmd->info0 = <token> <answer> le32_encode_bits(HTT_H2T_MSG_TYPE_SRING_SETUP, 
if (htt_ring_type <token> HTT_SW_TO_HW_RING || <answer> == 
<token> == HTT_HW_TO_SW_RING) <answer> htt_ring_type 
cmd->info0 <token> le32_encode_bits(DP_SW2HW_MACID(mac_id), <answer> |= 
cmd->info0 |= <token> <answer> le32_encode_bits(mac_id, 
cmd->info0 |= <token> <answer> le32_encode_bits(htt_ring_type, 
<token> |= le32_encode_bits(htt_ring_id, <answer> cmd->info0 
<token> = cpu_to_le32(params.ring_base_paddr & <answer> cmd->ring_base_addr_lo 
cmd->ring_base_addr_hi <token> cpu_to_le32((u64)params.ring_base_paddr >> <answer> = 
<token> = ath12k_hal_srng_get_entrysize(ab, ring_type); <answer> ret 
<token> (ret < 0) <answer> if 
goto <token> <answer> err_free; 
<token> = ret; <answer> ring_entry_sz 
ring_entry_sz >>= <token> <answer> 2; 
cmd->info1 = <token> <answer> le32_encode_bits(ring_entry_sz, 
cmd->info1 |= le32_encode_bits(params.num_entries <token> ring_entry_sz, <answer> * 
cmd->info1 <token> le32_encode_bits(!!(params.flags & HAL_SRNG_FLAGS_MSI_SWAP), <answer> |= 
cmd->info1 |= <token> & HAL_SRNG_FLAGS_DATA_TLV_SWAP), <answer> le32_encode_bits(!!(params.flags 
cmd->info1 |= le32_encode_bits(!!(params.flags & <token> <answer> HAL_SRNG_FLAGS_RING_PTR_SWAP), 
if (htt_ring_type <token> HTT_SW_TO_HW_RING) <answer> == 
cmd->info1 <token> cpu_to_le32(HTT_SRNG_SETUP_CMD_INFO1_RING_LOOP_CNT_DIS); <answer> |= 
cmd->ring_head_off32_remote_addr_lo <token> cpu_to_le32(lower_32_bits(hp_addr)); <answer> = 
<token> = cpu_to_le32(upper_32_bits(hp_addr)); <answer> cmd->ring_head_off32_remote_addr_hi 
cmd->ring_tail_off32_remote_addr_lo = <token> <answer> cpu_to_le32(lower_32_bits(tp_addr)); 
cmd->ring_tail_off32_remote_addr_hi <token> cpu_to_le32(upper_32_bits(tp_addr)); <answer> = 
cmd->ring_msi_addr_lo = <token> <answer> cpu_to_le32(lower_32_bits(params.msi_addr)); 
cmd->ring_msi_addr_hi <token> cpu_to_le32(upper_32_bits(params.msi_addr)); <answer> = 
cmd->msi_data = <token> <answer> cpu_to_le32(params.msi_data); 
<token> = <answer> cmd->intr_info 
le32_encode_bits(params.intr_batch_cntr_thres_entries * <token> <answer> ring_entry_sz, 
<token> |= <answer> cmd->intr_info 
le32_encode_bits(params.intr_timer_thres_us >> <token> <answer> 3, 
<token> = 0; <answer> cmd->info2 
if (params.flags & HAL_SRNG_FLAGS_LOW_THRESH_INTR_EN) <token> <answer> { 
cmd->info2 = <token> <answer> le32_encode_bits(params.low_threshold, 
ath12k_dbg(ab, <token> <answer> ATH12K_DBG_HAL, 
"%s <token> msi_addr_hi:0x%x, msi_data:0x%x\n", <answer> msi_addr_lo:0x%x, 
__func__, cmd->ring_msi_addr_lo, <token> <answer> cmd->ring_msi_addr_hi, 
ath12k_dbg(ab, <token> <answer> ATH12K_DBG_HAL, 
<token> ring_type:%d, intr_info:0x%x, flags:0x%x\n", <answer> "ring_id:%d, 
ring_id, <token> cmd->intr_info, cmd->info2); <answer> ring_type, 
ret = ath12k_htc_send(&ab->htc, <token> skb); <answer> ab->dp.eid, 
<token> (ret) <answer> if 
goto <token> <answer> err_free; 
return <token> <answer> 0; 
<token> ret; <answer> return 
#define HTT_TARGET_VERSION_TIMEOUT_HZ (3 * <token> <answer> HZ) 
int ath12k_dp_tx_htt_h2t_ver_req_msg(struct <token> *ab) <answer> ath12k_base 
struct ath12k_dp *dp = <token> <answer> &ab->dp; 
struct <token> *skb; <answer> sk_buff 
<token> htt_ver_req_cmd *cmd; <answer> struct 
int len = <token> <answer> sizeof(*cmd); 
int <token> <answer> ret; 
skb <token> ath12k_htc_alloc_skb(ab, len); <answer> = 
if <token> <answer> (!skb) 
<token> -ENOMEM; <answer> return 
skb_put(skb, <token> <answer> len); 
<token> = (struct htt_ver_req_cmd *)skb->data; <answer> cmd 
<token> = le32_encode_bits(HTT_H2T_MSG_TYPE_VERSION_REQ, <answer> cmd->ver_reg_info 
ret = ath12k_htc_send(&ab->htc, dp->eid, <token> <answer> skb); 
if <token> { <answer> (ret) 
return <token> <answer> ret; 
<token> = wait_for_completion_timeout(&dp->htt_tgt_version_received, <answer> ret 
<token> (ret == 0) { <answer> if 
ath12k_warn(ab, "htt target version request <token> out\n"); <answer> timed 
return <token> <answer> -ETIMEDOUT; 
if (dp->htt_tgt_ver_major <token> HTT_TARGET_VERSION_MAJOR) { <answer> != 
ath12k_err(ab, "unsupported <token> major version %d supported version is %d\n", <answer> htt 
dp->htt_tgt_ver_major, <token> <answer> HTT_TARGET_VERSION_MAJOR); 
return <token> <answer> -EOPNOTSUPP; 
return <token> <answer> 0; 
int ath12k_dp_tx_htt_h2t_ppdu_stats_req(struct ath12k <token> u32 mask) <answer> *ar, 
struct ath12k_base *ab <token> ar->ab; <answer> = 
struct ath12k_dp <token> = &ab->dp; <answer> *dp 
struct sk_buff <token> <answer> *skb; 
struct htt_ppdu_stats_cfg_cmd <token> <answer> *cmd; 
int len <token> sizeof(*cmd); <answer> = 
<token> pdev_mask; <answer> u8 
<token> ret; <answer> int 
<token> i; <answer> int 
for (i = 0; i <token> ab->hw_params->num_rxmda_per_pdev; i++) { <answer> < 
skb <token> ath12k_htc_alloc_skb(ab, len); <answer> = 
if <token> <answer> (!skb) 
return <token> <answer> -ENOMEM; 
<token> len); <answer> skb_put(skb, 
<token> = (struct htt_ppdu_stats_cfg_cmd *)skb->data; <answer> cmd 
cmd->msg <token> le32_encode_bits(HTT_H2T_MSG_TYPE_PPDU_STATS_CFG, <answer> = 
pdev_mask <token> 1 << (i + 1); <answer> = 
<token> |= le32_encode_bits(pdev_mask, HTT_PPDU_STATS_CFG_PDEV_ID); <answer> cmd->msg 
cmd->msg <token> le32_encode_bits(mask, HTT_PPDU_STATS_CFG_TLV_TYPE_BITMASK); <answer> |= 
ret = <token> dp->eid, skb); <answer> ath12k_htc_send(&ab->htc, 
if (ret) <token> <answer> { 
<token> ret; <answer> return 
<token> 0; <answer> return 
int ath12k_dp_tx_htt_rx_filter_setup(struct ath12k_base *ab, u32 <token> <answer> ring_id, 
<token> mac_id, enum hal_ring_type ring_type, <answer> int 
<token> rx_buf_size, <answer> int 
struct <token> *tlv_filter) <answer> htt_rx_ring_tlv_filter 
struct htt_rx_ring_selection_cfg_cmd <token> <answer> *cmd; 
struct <token> *srng = &ab->hal.srng_list[ring_id]; <answer> hal_srng 
struct <token> params; <answer> hal_srng_params 
<token> sk_buff *skb; <answer> struct 
<token> len = sizeof(*cmd); <answer> int 
<token> htt_srng_ring_type htt_ring_type; <answer> enum 
enum htt_srng_ring_id <token> <answer> htt_ring_id; 
<token> ret; <answer> int 
skb <token> ath12k_htc_alloc_skb(ab, len); <answer> = 
<token> (!skb) <answer> if 
return <token> <answer> -ENOMEM; 
memset(&params, 0, <token> <answer> sizeof(params)); 
ath12k_hal_srng_get_params(ab, <token> &params); <answer> srng, 
ret = ath12k_dp_tx_get_ring_id_type(ab, <token> ring_id, <answer> mac_id, 
ring_type, <token> <answer> &htt_ring_type, 
if <token> <answer> (ret) 
<token> err_free; <answer> goto 
<token> len); <answer> skb_put(skb, 
cmd = <token> htt_rx_ring_selection_cfg_cmd *)skb->data; <answer> (struct 
cmd->info0 = <token> <answer> le32_encode_bits(HTT_H2T_MSG_TYPE_RX_RING_SELECTION_CFG, 
if (htt_ring_type <token> HTT_SW_TO_HW_RING || <answer> == 
htt_ring_type == <token> <answer> HTT_HW_TO_SW_RING) 
<token> |= <answer> cmd->info0 
<token> |= <answer> cmd->info0 
cmd->info0 <token> le32_encode_bits(htt_ring_id, <answer> |= 
<token> |= le32_encode_bits(!!(params.flags & HAL_SRNG_FLAGS_MSI_SWAP), <answer> cmd->info0 
cmd->info0 |= <token> & HAL_SRNG_FLAGS_DATA_TLV_SWAP), <answer> le32_encode_bits(!!(params.flags 
cmd->info0 <token> le32_encode_bits(tlv_filter->offset_valid, <answer> |= 
cmd->info1 <token> le32_encode_bits(rx_buf_size, <answer> = 
<token> = cpu_to_le32(tlv_filter->pkt_filter_flags0); <answer> cmd->pkt_type_en_flags0 
<token> = cpu_to_le32(tlv_filter->pkt_filter_flags1); <answer> cmd->pkt_type_en_flags1 
cmd->pkt_type_en_flags2 <token> cpu_to_le32(tlv_filter->pkt_filter_flags2); <answer> = 
cmd->pkt_type_en_flags3 = <token> <answer> cpu_to_le32(tlv_filter->pkt_filter_flags3); 
cmd->rx_filter_tlv <token> cpu_to_le32(tlv_filter->rx_filter); <answer> = 
if (tlv_filter->offset_valid) <token> <answer> { 
cmd->rx_packet_offset <token> <answer> = 
<token> |= <answer> cmd->rx_packet_offset 
cmd->rx_mpdu_offset <token> <answer> = 
cmd->rx_mpdu_offset <token> <answer> |= 
<token> = <answer> cmd->rx_msdu_offset 
<token> |= <answer> cmd->rx_msdu_offset 
cmd->rx_attn_offset <token> <answer> = 
if (tlv_filter->rx_mpdu_start_wmask > <token> && <answer> 0 
tlv_filter->rx_msdu_end_wmask <token> 0) { <answer> > 
cmd->info2 <token> <answer> |= 
<token> = <answer> cmd->rx_mpdu_start_end_mask 
<token> |= <answer> cmd->rx_mpdu_start_end_mask 
cmd->rx_msdu_end_word_mask <token> <answer> = 
ret <token> ath12k_htc_send(&ab->htc, ab->dp.eid, skb); <answer> = 
if <token> <answer> (ret) 
goto <token> <answer> err_free; 
return <token> <answer> 0; 
<token> ret; <answer> return 
ath12k_dp_tx_htt_h2t_ext_stats_req(struct ath12k *ar, <token> type, <answer> u8 
<token> htt_ext_stats_cfg_params *cfg_params, <answer> struct 
<token> cookie) <answer> u64 
struct ath12k_base *ab = <token> <answer> ar->ab; 
struct ath12k_dp <token> = &ab->dp; <answer> *dp 
struct <token> *skb; <answer> sk_buff 
struct htt_ext_stats_cfg_cmd <token> <answer> *cmd; 
int len <token> sizeof(*cmd); <answer> = 
<token> ret; <answer> int 
<token> = ath12k_htc_alloc_skb(ab, len); <answer> skb 
<token> (!skb) <answer> if 
return <token> <answer> -ENOMEM; 
<token> len); <answer> skb_put(skb, 
cmd = <token> htt_ext_stats_cfg_cmd *)skb->data; <answer> (struct 
memset(cmd, <token> sizeof(*cmd)); <answer> 0, 
cmd->hdr.msg_type <token> HTT_H2T_MSG_TYPE_EXT_STATS_CFG; <answer> = 
cmd->hdr.pdev_mask <token> 1 << ar->pdev->pdev_id; <answer> = 
<token> = type; <answer> cmd->hdr.stats_type 
<token> = cpu_to_le32(cfg_params->cfg0); <answer> cmd->cfg_param0 
cmd->cfg_param1 = <token> <answer> cpu_to_le32(cfg_params->cfg1); 
cmd->cfg_param2 = <token> <answer> cpu_to_le32(cfg_params->cfg2); 
<token> = cpu_to_le32(cfg_params->cfg3); <answer> cmd->cfg_param3 
cmd->cookie_lsb <token> cpu_to_le32(lower_32_bits(cookie)); <answer> = 
<token> = cpu_to_le32(upper_32_bits(cookie)); <answer> cmd->cookie_msb 
ret = ath12k_htc_send(&ab->htc, <token> skb); <answer> dp->eid, 
<token> (ret) { <answer> if 
ath12k_warn(ab, "failed to send htt type stats <token> %d", <answer> request: 
return <token> <answer> ret; 
return <token> <answer> 0; 
int ath12k_dp_tx_htt_monitor_mode_ring_config(struct ath12k <token> bool reset) <answer> *ar, 
struct ath12k_base *ab <token> ar->ab; <answer> = 
<token> ret; <answer> int 
ret <token> ath12k_dp_tx_htt_tx_monitor_mode_ring_config(ar, reset); <answer> = 
<token> (ret) { <answer> if 
ath12k_err(ab, "failed <token> setup tx monitor filter %d\n", ret); <answer> to 
<token> ret; <answer> return 
<token> = ath12k_dp_tx_htt_tx_monitor_mode_ring_config(ar, reset); <answer> ret 
if (ret) <token> <answer> { 
<token> "failed to setup rx monitor filter %d\n", ret); <answer> ath12k_err(ab, 
<token> ret; <answer> return 
return <token> <answer> 0; 
int ath12k_dp_tx_htt_rx_monitor_mode_ring_config(struct <token> *ar, bool reset) <answer> ath12k 
struct <token> *ab = ar->ab; <answer> ath12k_base 
struct <token> *dp = &ab->dp; <answer> ath12k_dp 
struct htt_rx_ring_tlv_filter tlv_filter = <token> <answer> {0}; 
int <token> ring_id; <answer> ret, 
ring_id = <token> <answer> dp->rxdma_mon_buf_ring.refill_buf_ring.ring_id; 
<token> = false; <answer> tlv_filter.offset_valid 
if (!reset) <token> <answer> { 
<token> = HTT_RX_MON_FILTER_TLV_FLAGS_MON_BUF_RING; <answer> tlv_filter.rx_filter 
tlv_filter.pkt_filter_flags0 <token> <answer> = 
<token> | <answer> HTT_RX_MON_FP_MGMT_FILTER_FLAGS0 
<token> = <answer> tlv_filter.pkt_filter_flags1 
<token> | <answer> HTT_RX_MON_FP_MGMT_FILTER_FLAGS1 
tlv_filter.pkt_filter_flags2 <token> <answer> = 
<token> | <answer> HTT_RX_MON_FP_CTRL_FILTER_FLASG2 
tlv_filter.pkt_filter_flags3 <token> <answer> = 
<token> | <answer> HTT_RX_MON_FP_CTRL_FILTER_FLASG3 
<token> | <answer> HTT_RX_MON_MO_CTRL_FILTER_FLASG3 
HTT_RX_MON_FP_DATA_FILTER_FLASG3 <token> <answer> | 
if <token> { <answer> (ab->hw_params->rxdma1_enable) 
ret = ath12k_dp_tx_htt_rx_filter_setup(ar->ab, <token> 0, <answer> ring_id, 
<token> (ret) { <answer> if 
"failed to setup filter for monitor buf %d\n", <token> <answer> ret); 
<token> ret; <answer> return 
return <token> <answer> 0; 
int ath12k_dp_tx_htt_tx_filter_setup(struct ath12k_base <token> u32 ring_id, <answer> *ab, 
int mac_id, enum hal_ring_type <token> <answer> ring_type, 
<token> tx_buf_size, <answer> int 
struct htt_tx_ring_tlv_filter <token> <answer> *htt_tlv_filter) 
struct htt_tx_ring_selection_cfg_cmd <token> <answer> *cmd; 
struct <token> *srng = &ab->hal.srng_list[ring_id]; <answer> hal_srng 
struct <token> params; <answer> hal_srng_params 
struct <token> *skb; <answer> sk_buff 
int len <token> sizeof(*cmd); <answer> = 
<token> htt_srng_ring_type htt_ring_type; <answer> enum 
enum <token> htt_ring_id; <answer> htt_srng_ring_id 
int <token> <answer> ret; 
<token> = ath12k_htc_alloc_skb(ab, len); <answer> skb 
if <token> <answer> (!skb) 
<token> -ENOMEM; <answer> return 
memset(&params, <token> sizeof(params)); <answer> 0, 
ath12k_hal_srng_get_params(ab, srng, <token> <answer> &params); 
<token> = ath12k_dp_tx_get_ring_id_type(ab, mac_id, ring_id, <answer> ret 
<token> &htt_ring_type, <answer> ring_type, 
<token> (ret) <answer> if 
<token> err_free; <answer> goto 
skb_put(skb, <token> <answer> len); 
cmd = <token> htt_tx_ring_selection_cfg_cmd *)skb->data; <answer> (struct 
<token> = le32_encode_bits(HTT_H2T_MSG_TYPE_TX_MONITOR_CFG, <answer> cmd->info0 
<token> (htt_ring_type == HTT_SW_TO_HW_RING || <answer> if 
<token> == HTT_HW_TO_SW_RING) <answer> htt_ring_type 
cmd->info0 <token> <answer> |= 
cmd->info0 <token> <answer> |= 
<token> |= le32_encode_bits(htt_ring_id, <answer> cmd->info0 
cmd->info0 <token> le32_encode_bits(!!(params.flags & HAL_SRNG_FLAGS_MSI_SWAP), <answer> |= 
cmd->info0 |= le32_encode_bits(!!(params.flags & <token> <answer> HAL_SRNG_FLAGS_DATA_TLV_SWAP), 
cmd->info1 <token> <answer> |= 
<token> (htt_tlv_filter->tx_mon_mgmt_filter) { <answer> if 
cmd->info1 <token> <answer> |= 
cmd->info1 <token> <answer> |= 
cmd->info2 <token> <answer> |= 
if <token> { <answer> (htt_tlv_filter->tx_mon_data_filter) 
cmd->info1 <token> <answer> |= 
<token> |= <answer> cmd->info1 
cmd->info2 <token> <answer> |= 
if <token> { <answer> (htt_tlv_filter->tx_mon_ctrl_filter) 
cmd->info1 <token> <answer> |= 
<token> |= <answer> cmd->info1 
cmd->info2 <token> <answer> |= 
<token> = <answer> cmd->tlv_filter_mask_in0 
cmd->tlv_filter_mask_in1 <token> <answer> = 
cmd->tlv_filter_mask_in2 <token> <answer> = 
<token> = <answer> cmd->tlv_filter_mask_in3 
ret = <token> ab->dp.eid, skb); <answer> ath12k_htc_send(&ab->htc, 
<token> (ret) <answer> if 
goto <token> <answer> err_free; 
<token> 0; <answer> return 
<token> ret; <answer> return 
int ath12k_dp_tx_htt_tx_monitor_mode_ring_config(struct ath12k *ar, bool <token> <answer> reset) 
struct ath12k_base <token> = ar->ab; <answer> *ab 
struct ath12k_dp <token> = &ab->dp; <answer> *dp 
struct <token> tlv_filter = {0}; <answer> htt_tx_ring_tlv_filter 
int <token> ring_id; <answer> ret, 
<token> = dp->tx_mon_buf_ring.refill_buf_ring.ring_id; <answer> ring_id 
<token> (ab->hw_params->rxdma1_enable) { <answer> if 
ret = ath12k_dp_tx_htt_tx_filter_setup(ar->ab, ring_id, <token> <answer> 0, 
<token> (ret) { <answer> if 
"failed to setup <token> for monitor buf %d\n", ret); <answer> filter 
return <token> <answer> ret; 
return <token> <answer> 0; 
<token> <linux/hyperv.h> <answer> #include 
<token> <linux/debugfs.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> "hyperv_vmbus.h" 
static struct <token> *hv_debug_root; <answer> dentry 
static int <token> *data, u64 *val) <answer> hv_debugfs_delay_get(void 
*val = <token> *)data; <answer> *(u32 
<token> 0; <answer> return 
<token> int hv_debugfs_delay_set(void *data, u64 val) <answer> static 
<token> (val > 1000) <answer> if 
return <token> <answer> -EINVAL; 
*(u32 <token> = val; <answer> *)data 
<token> 0; <answer> return 
<token> hv_debugfs_delay_get, <answer> DEFINE_DEBUGFS_ATTRIBUTE(hv_debugfs_delay_fops, 
hv_debugfs_delay_set, <token> <answer> "%llu\n"); 
static int hv_debugfs_state_get(void <token> u64 *val) <answer> *data, 
*val = <token> *)data; <answer> *(bool 
<token> 0; <answer> return 
static int hv_debugfs_state_set(void *data, <token> val) <answer> u64 
if (val <token> 1) <answer> == 
*(bool <token> = true; <answer> *)data 
else if <token> == 0) <answer> (val 
*(bool *)data = <token> <answer> false; 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
<token> hv_debugfs_state_get, <answer> DEFINE_DEBUGFS_ATTRIBUTE(hv_debugfs_state_fops, 
<token> "%llu\n"); <answer> hv_debugfs_state_set, 
<token> <linux/dmaengine.h> <answer> #include 
#include <token> <answer> <linux/dma-mapping.h> 
<token> <linux/bitmap.h> <answer> #include 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/list.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/of_dma.h> 
<token> <linux/of_irq.h> <answer> #include 
#include <token> <answer> <linux/of_address.h> 
<token> <linux/pm_runtime.h> <answer> #include 
<token> <linux/platform_data/edma.h> <answer> #include 
<token> "../dmaengine.h" <answer> #include 
#include <token> <answer> "../virt-dma.h" 
#define <token> 20 <answer> MAX_NR_SG 
#define EDMA_MAX_SLOTS <token> <answer> MAX_NR_SG 
#define EDMA_DESCRIPTORS <token> <answer> 16 
#define EDMA_REG_ARRAY_INDEX(channel) <token> >> 5) <answer> ((channel) 
#define EDMA_CHANNEL_BIT(channel) (BIT((channel) <token> 0x1f)) <answer> & 
<token> processed_stat; <answer> int 
<token> sg_len; <answer> u32 
<token> residue; <answer> u32 
u32 <token> <answer> residue_stat; 
<token> edma_pset pset[] __counted_by(pset_nr); <answer> struct 
<token> edma_cc; <answer> struct 
struct <token> { <answer> edma_tc 
<token> device_node *node; <answer> struct 
<token> id; <answer> u16 
struct edma_chan <token> <answer> { 
struct virt_dma_chan <token> <answer> vchan; 
struct list_head <token> <answer> node; 
struct <token> *edesc; <answer> edma_desc 
<token> edma_cc *ecc; <answer> struct 
struct edma_tc <token> <answer> *tc; 
int <token> <answer> ch_num; 
<token> alloced; <answer> bool 
<token> hw_triggered; <answer> bool 
int <token> <answer> slot[EDMA_MAX_SLOTS]; 
int <token> <answer> missed; 
<token> dma_slave_config cfg; <answer> struct 
struct <token> { <answer> edma_cc 
struct <token> *dev; <answer> device 
struct edma_soc_info <token> <answer> *info; 
<token> __iomem *base; <answer> void 
<token> id; <answer> int 
bool <token> <answer> legacy_mode; 
unsigned <token> *slot_inuse; <answer> long 
unsigned <token> *channels_mask; <answer> long 
struct <token> dma_slave; <answer> dma_device 
struct dma_device <token> <answer> *dma_memcpy; 
struct <token> *slave_chans; <answer> edma_chan 
struct <token> *tc_list; <answer> edma_tc 
int <token> <answer> dummy_slot; 
static void edma_write_slot(struct edma_cc *ecc, unsigned <token> <answer> slot, 
const struct edmacc_param <token> <answer> *param) 
<token> = EDMA_CHAN_SLOT(slot); <answer> slot 
if (slot <token> ecc->num_slots) <answer> >= 
memcpy_toio(ecc->base + PARM_OFFSET(slot), param, <token> <answer> PARM_SIZE); 
static int <token> edma_cc *ecc, unsigned slot, <answer> edma_read_slot(struct 
struct edmacc_param <token> <answer> *param) 
slot <token> EDMA_CHAN_SLOT(slot); <answer> = 
<token> (slot >= ecc->num_slots) <answer> if 
<token> -EINVAL; <answer> return 
memcpy_fromio(param, ecc->base + <token> PARM_SIZE); <answer> PARM_OFFSET(slot), 
<token> 0; <answer> return 
static <token> edma_alloc_slot(struct edma_cc *ecc, int slot) <answer> int 
if (slot >= 0) <token> <answer> { 
<token> = EDMA_CHAN_SLOT(slot); <answer> slot 
static void <token> edma_cc *ecc, unsigned from, unsigned to) <answer> edma_link(struct 
if <token> != EDMA_CTLR(to))) <answer> (unlikely(EDMA_CTLR(from) 
dev_warn(ecc->dev, "Ignoring eDMA instance <token> linking\n"); <answer> for 
from <token> EDMA_CHAN_SLOT(from); <answer> = 
to <token> EDMA_CHAN_SLOT(to); <answer> = 
if (from >= <token> || to >= ecc->num_slots) <answer> ecc->num_slots 
edma_param_modify(ecc, PARM_LINK_BCNTRLD, from, <token> <answer> 0xffff0000, 
<token> dma_addr_t edma_get_position(struct edma_cc *ecc, unsigned slot, <answer> static 
<token> dst) <answer> bool 
<token> offs; <answer> u32 
<token> = EDMA_CHAN_SLOT(slot); <answer> slot 
offs <token> PARM_OFFSET(slot); <answer> = 
<token> += dst ? PARM_DST : PARM_SRC; <answer> offs 
<token> edma_read(ecc, offs); <answer> return 
static void edma_start(struct <token> *echan) <answer> edma_chan 
struct <token> *ecc = echan->ecc; <answer> edma_cc 
int channel = <token> <answer> EDMA_CHAN_SLOT(echan->ch_num); 
int idx = <token> <answer> EDMA_REG_ARRAY_INDEX(channel); 
<token> ch_bit = EDMA_CHANNEL_BIT(channel); <answer> int 
if <token> { <answer> (!echan->hw_triggered) 
static <token> edma_pause(struct edma_chan *echan) <answer> void 
int channel <token> EDMA_CHAN_SLOT(echan->ch_num); <answer> = 
edma_shadow0_write_array(echan->ecc, <token> <answer> SH_EECR, 
<token> (edesc->processed == edesc->pset_nr) { <answer> if 
if <token> <answer> (edesc->cyclic) 
edma_link(ecc, echan->slot[nslots <token> 1], echan->slot[1]); <answer> - 
edma_link(ecc, echan->slot[nslots <token> 1], <answer> - 
if <token> { <answer> (echan->missed) 
dev_dbg(dev, "missed event <token> channel %d\n", echan->ch_num); <answer> on 
echan->missed <token> 0; <answer> = 
} <token> if (edesc->processed <= MAX_NR_SG) { <answer> else 
<token> "first transfer starting on channel %d\n", <answer> dev_dbg(dev, 
<token> else { <answer> } 
dev_dbg(dev, "chan: <token> completed %d elements, resuming\n", <answer> %d: 
echan->ch_num, <token> <answer> edesc->processed); 
static int <token> dma_chan *chan) <answer> edma_terminate_all(struct 
<token> edma_chan *echan = to_edma_chan(chan); <answer> struct 
unsigned <token> flags; <answer> long 
spin_lock_irqsave(&echan->vchan.lock, <token> <answer> flags); 
if <token> { <answer> (echan->edesc) 
static int edma_config_pset(struct dma_chan <token> struct edma_pset *epset, <answer> *chan, 
dma_addr_t src_addr, dma_addr_t dst_addr, u32 <token> <answer> burst, 
unsigned int acnt, <token> int dma_length, <answer> unsigned 
<token> dma_transfer_direction direction) <answer> enum 
struct edma_chan <token> = to_edma_chan(chan); <answer> *echan 
<token> device *dev = chan->device->dev; <answer> struct 
struct <token> *param = &epset->param; <answer> edmacc_param 
int bcnt, ccnt, <token> <answer> cidx; 
int src_bidx, dst_bidx, src_cidx, <token> <answer> dst_cidx; 
<token> absync; <answer> int 
<token> (burst == 1) { <answer> if 
absync <token> false; <answer> = 
ccnt = dma_length <token> acnt / (SZ_64K - 1); <answer> / 
bcnt <token> dma_length / acnt - ccnt * (SZ_64K - 1); <answer> = 
<token> (bcnt) <answer> if 
bcnt = <token> - 1; <answer> SZ_64K 
cidx = <token> <answer> acnt; 
} else <token> <answer> { 
absync <token> true; <answer> = 
bcnt <token> burst; <answer> = 
ccnt = dma_length / (acnt * <token> <answer> bcnt); 
if <token> > (SZ_64K - 1)) { <answer> (ccnt 
dev_err(dev, "Exceeded max SG <token> size\n"); <answer> segment 
return <token> <answer> -EINVAL; 
cidx <token> acnt * bcnt; <answer> = 
epset->len = <token> <answer> dma_length; 
if (direction <token> DMA_MEM_TO_DEV) { <answer> == 
<token> = acnt; <answer> src_bidx 
<token> = cidx; <answer> src_cidx 
dst_bidx <token> 0; <answer> = 
<token> = 0; <answer> dst_cidx 
<token> = src_addr; <answer> epset->addr 
} else if (direction == DMA_DEV_TO_MEM) <token> <answer> { 
<token> = 0; <answer> src_bidx 
src_cidx <token> 0; <answer> = 
dst_bidx <token> acnt; <answer> = 
dst_cidx = <token> <answer> cidx; 
epset->addr <token> dst_addr; <answer> = 
} <token> if (direction == DMA_MEM_TO_MEM) { <answer> else 
<token> = acnt; <answer> src_bidx 
<token> = cidx; <answer> src_cidx 
<token> = acnt; <answer> dst_bidx 
<token> = cidx; <answer> dst_cidx 
<token> = src_addr; <answer> epset->addr 
} <token> { <answer> else 
dev_err(dev, "%s: direction not implemented yet\n", <token> <answer> __func__); 
<token> -EINVAL; <answer> return 
param->opt = <token> <answer> EDMA_TCC(EDMA_CHAN_SLOT(echan->ch_num)); 
<token> = 0xffffffff; <answer> param->link_bcntrld 
return <token> <answer> absync; 
<token> struct dma_async_tx_descriptor *edma_prep_slave_sg( <answer> static 
<token> dma_chan *chan, struct scatterlist *sgl, <answer> struct 
unsigned int <token> enum dma_transfer_direction direction, <answer> sg_len, 
<token> long tx_flags, void *context) <answer> unsigned 
struct edma_chan *echan <token> to_edma_chan(chan); <answer> = 
struct <token> *dev = chan->device->dev; <answer> device 
struct edma_desc <token> <answer> *edesc; 
dma_addr_t src_addr <token> 0, dst_addr = 0; <answer> = 
enum dma_slave_buswidth <token> <answer> dev_width; 
<token> burst; <answer> u32 
struct <token> *sg; <answer> scatterlist 
<token> i, nslots, ret; <answer> int 
if (unlikely(!echan || <token> || !sg_len)) <answer> !sgl 
return <token> <answer> NULL; 
<token> (direction == DMA_DEV_TO_MEM) { <answer> if 
src_addr <token> echan->cfg.src_addr; <answer> = 
dev_width <token> echan->cfg.src_addr_width; <answer> = 
burst = <token> <answer> echan->cfg.src_maxburst; 
<token> else if (direction == DMA_MEM_TO_DEV) { <answer> } 
<token> = echan->cfg.dst_addr; <answer> dst_addr 
dev_width = <token> <answer> echan->cfg.dst_addr_width; 
burst = <token> <answer> echan->cfg.dst_maxburst; 
} <token> { <answer> else 
<token> "%s: bad direction: %d\n", __func__, direction); <answer> dev_err(dev, 
<token> NULL; <answer> return 
if (dev_width == DMA_SLAVE_BUSWIDTH_UNDEFINED) <token> <answer> { 
dev_err(dev, "%s: <token> slave buswidth\n", __func__); <answer> Undefined 
return <token> <answer> NULL; 
edesc = kzalloc(struct_size(edesc, <token> sg_len), GFP_ATOMIC); <answer> pset, 
if <token> <answer> (!edesc) 
<token> NULL; <answer> return 
edesc->pset_nr <token> sg_len; <answer> = 
<token> = 0; <answer> edesc->residue 
edesc->direction = <token> <answer> direction; 
edesc->echan <token> echan; <answer> = 
edesc->pset[i].param.opt |= <token> | TCCMODE); <answer> (TCINTEN 
edesc->residue_stat <token> edesc->residue; <answer> = 
return vchan_tx_prep(&echan->vchan, &edesc->vdesc, <token> <answer> tx_flags); 
<token> struct dma_async_tx_descriptor *edma_prep_dma_memcpy( <answer> static 
struct dma_chan *chan, <token> dest, dma_addr_t src, <answer> dma_addr_t 
size_t len, <token> long tx_flags) <answer> unsigned 
int ret, <token> <answer> nslots; 
struct <token> *edesc; <answer> edma_desc 
struct device *dev <token> chan->device->dev; <answer> = 
struct edma_chan *echan <token> to_edma_chan(chan); <answer> = 
unsigned <token> width, pset_len, array_size; <answer> int 
if <token> || !len)) <answer> (unlikely(!echan 
return <token> <answer> NULL; 
width = <token> <answer> len; 
<token> = len; <answer> pset_len 
nslots = <token> <answer> 1; 
<token> else { <answer> } 
width <token> array_size; <answer> = 
pset_len <token> rounddown(len, width); <answer> = 
<token> (nslots > MAX_NR_SG) { <answer> if 
if (burst == period_len) <token> <answer> { 
period_len = <token> <answer> buf_len; 
<token> = 2; <answer> nslots 
use_intermediate <token> true; <answer> = 
} <token> { <answer> else 
return <token> <answer> NULL; 
<token> = kzalloc(struct_size(edesc, pset, nslots), GFP_ATOMIC); <answer> edesc 
if <token> <answer> (!edesc) 
return <token> <answer> NULL; 
edesc->cyclic = <token> <answer> 1; 
edesc->pset_nr <token> nslots; <answer> = 
edesc->residue = <token> = buf_len; <answer> edesc->residue_stat 
edesc->direction <token> direction; <answer> = 
edesc->echan = <token> <answer> echan; 
<token> "%s: channel=%d nslots=%d period_len=%zu buf_len=%zu\n", <answer> dev_dbg(dev, 
__func__, echan->ch_num, nslots, period_len, <token> <answer> buf_len); 
for (i <token> 0; i < nslots; i++) { <answer> = 
if (tx_flags & DMA_PREP_INTERRUPT) <token> <answer> { 
edesc->pset[i].param.opt |= <token> <answer> TCINTEN; 
if (err || (p.a_b_cnt == 0 <token> p.ccnt == 0)) { <answer> && 
dev_dbg(dev, "Error on <token> slot, setting miss\n"); <answer> null 
echan->missed = <token> <answer> 1; 
} else <token> <answer> { 
<token> "Missed event, TRIGGERING\n"); <answer> dev_dbg(dev, 
<token> inline bool edma_error_pending(struct edma_cc *ecc) <answer> static 
<token> (edma_read_array(ecc, EDMA_EMR, 0) || <answer> if 
edma_read_array(ecc, <token> 1) || <answer> EDMA_EMR, 
edma_read(ecc, EDMA_QEMR) <token> edma_read(ecc, EDMA_CCERR)) <answer> || 
<token> true; <answer> return 
return <token> <answer> false; 
dev_err(ecc->dev, "%s: Error interrupt without error <token> <answer> event!\n", 
edma_write(ecc, <token> 1); <answer> EDMA_EEVAL, 
return <token> <answer> IRQ_NONE; 
<token> (1) { <answer> while 
<token> EDMA_MAX_TR_WAIT_LOOPS 1000 <answer> #define 
<token> u32 edma_residue(struct edma_desc *edesc) <answer> static 
bool dst <token> edesc->direction == DMA_DEV_TO_MEM; <answer> = 
int <token> = EDMA_MAX_TR_WAIT_LOOPS; <answer> loop_count 
struct edma_chan *echan <token> edesc->echan; <answer> = 
struct edma_pset *pset <token> edesc->pset; <answer> = 
dma_addr_t <token> pos, pos_old; <answer> done, 
int channel = <token> <answer> EDMA_CHAN_SLOT(echan->ch_num); 
int <token> = EDMA_REG_ARRAY_INDEX(channel); <answer> idx 
<token> ch_bit = EDMA_CHANNEL_BIT(channel); <answer> int 
int <token> <answer> event_reg; 
int <token> <answer> i; 
pos = edma_get_position(echan->ecc, echan->slot[0], <token> <answer> dst); 
<token> (is_slave_direction(edesc->direction)) <answer> if 
event_reg = <token> <answer> SH_ER; 
event_reg = <token> <answer> SH_ESR; 
pos_old = <token> <answer> pos; 
while (edma_shadow0_read_array(echan->ecc, event_reg, idx) <token> ch_bit) { <answer> & 
pos <token> edma_get_position(echan->ecc, echan->slot[0], dst); <answer> = 
if <token> != pos_old) <answer> (pos 
if <token> { <answer> (!--loop_count) 
"%s: timeout waiting for <token> update\n", <answer> PaRAM 
<token> (edesc->cyclic) { <answer> if 
done = pos - <token> <answer> pset->addr; 
<token> = edesc->residue - done; <answer> edesc->residue_stat 
return <token> <answer> edesc->residue_stat; 
if <token> <answer> (!pos) 
return <token> <answer> 0; 
pset <token> edesc->processed_stat; <answer> += 
for <token> = edesc->processed_stat; i < edesc->processed; i++, pset++) { <answer> (i 
if (pos >= <token> && pos < pset->addr + pset->len) <answer> pset->addr 
return edesc->residue_stat - <token> - pset->addr); <answer> (pos 
if (ret != DMA_COMPLETE && <token> && <answer> !txstate->residue 
<token> && echan->edesc->polled && <answer> echan->edesc 
echan->edesc->vdesc.tx.cookie <token> cookie) { <answer> == 
<token> = NULL; <answer> echan->edesc 
ret = <token> <answer> DMA_COMPLETE; 
spin_unlock_irqrestore(&echan->vchan.lock, <token> <answer> flags); 
<token> ret; <answer> return 
static bool edma_is_memcpy_channel(int ch_num, s32 <token> <answer> *memcpy_channels) 
if <token> <answer> (!memcpy_channels) 
<token> false; <answer> return 
while (*memcpy_channels != <token> { <answer> -1) 
<token> (*memcpy_channels == ch_num) <answer> if 
return <token> <answer> true; 
<token> false; <answer> return 
#define <token> (BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) | \ <answer> EDMA_DMA_BUSWIDTHS 
<token> | \ <answer> BIT(DMA_SLAVE_BUSWIDTH_2_BYTES) 
BIT(DMA_SLAVE_BUSWIDTH_3_BYTES) | <token> <answer> \ 
static void edma_dma_init(struct edma_cc *ecc, bool <token> <answer> legacy_mode) 
struct dma_device *s_ddev <token> &ecc->dma_slave; <answer> = 
struct dma_device *m_ddev = <token> <answer> NULL; 
s32 *memcpy_channels = <token> <answer> ecc->info->memcpy_channels; 
<token> i, j; <answer> int 
<token> s_ddev->cap_mask); <answer> dma_cap_set(DMA_SLAVE, 
<token> s_ddev->cap_mask); <answer> dma_cap_set(DMA_CYCLIC, 
if (ecc->legacy_mode <token> !memcpy_channels) { <answer> && 
"Legacy memcpy is enabled, <token> might not work\n"); <answer> things 
<token> s_ddev->cap_mask); <answer> dma_cap_set(DMA_MEMCPY, 
dma_cap_set(DMA_INTERLEAVE, <token> <answer> s_ddev->cap_mask); 
<token> = edma_prep_dma_memcpy; <answer> s_ddev->device_prep_dma_memcpy 
<token> = edma_prep_dma_interleaved; <answer> s_ddev->device_prep_interleaved_dma 
s_ddev->directions = <token> <answer> BIT(DMA_MEM_TO_MEM); 
s_ddev->device_prep_slave_sg <token> edma_prep_slave_sg; <answer> = 
s_ddev->device_prep_dma_cyclic = <token> <answer> edma_prep_dma_cyclic; 
s_ddev->device_alloc_chan_resources = <token> <answer> edma_alloc_chan_resources; 
s_ddev->device_free_chan_resources <token> edma_free_chan_resources; <answer> = 
s_ddev->device_issue_pending <token> edma_issue_pending; <answer> = 
s_ddev->device_tx_status <token> edma_tx_status; <answer> = 
s_ddev->device_config <token> edma_slave_config; <answer> = 
s_ddev->device_pause = <token> <answer> edma_dma_pause; 
s_ddev->device_resume <token> edma_dma_resume; <answer> = 
s_ddev->device_terminate_all <token> edma_terminate_all; <answer> = 
<token> = edma_synchronize; <answer> s_ddev->device_synchronize 
<token> = EDMA_DMA_BUSWIDTHS; <answer> s_ddev->src_addr_widths 
s_ddev->dst_addr_widths <token> EDMA_DMA_BUSWIDTHS; <answer> = 
s_ddev->directions <token> (BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV)); <answer> |= 
s_ddev->residue_granularity = <token> <answer> DMA_RESIDUE_GRANULARITY_BURST; 
<token> = devm_kcalloc(dev, ecc->num_tc + 1, sizeof(s8), <answer> queue_priority_map 
<token> (!queue_priority_map) <answer> if 
<token> -ENOMEM; <answer> return 
for <token> = 0; i < ecc->num_tc; i++) { <answer> (i 
<token> = i; <answer> queue_priority_map[i][0] 
queue_priority_map[i][1] = <token> <answer> i; 
queue_priority_map[i][0] <token> -1; <answer> = 
queue_priority_map[i][1] <token> -1; <answer> = 
<token> = queue_priority_map; <answer> pdata->queue_priority_mapping 
#include <token> <answer> <stdarg.h> 
<token> <stddef.h> <answer> #include 
#include <token> <answer> "types.h" 
#include <token> <answer> "elf.h" 
<token> "string.h" <answer> #include 
<token> "stdio.h" <answer> #include 
#include <token> <answer> "page.h" 
#include <token> <answer> "ops.h" 
#include <token> <answer> "reg.h" 
#include <token> <answer> "io.h" 
#include <token> <answer> "dcr.h" 
#include <token> <answer> "4xx.h" 
#include <token> <answer> "44x.h" 
#include <token> <answer> "libfdt.h" 
static <token> ibm4xx_memstart; <answer> u32 
<token> void iss_4xx_fixups(void) <answer> static 
void <token> <answer> *memory; 
<token> reg[3]; <answer> u32 
memory = <token> <answer> finddevice("/memory"); 
if <token> <answer> (!memory) 
fatal("Can't <token> memory node\n"); <answer> find 
#include <token> <answer> <linux/device.h> 
#include <token> <answer> <linux/mod_devicetable.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/sysfs.h> <answer> #include 
<token> <linux/soundwire/sdw.h> <answer> #include 
#include <token> <answer> <linux/soundwire/sdw_type.h> 
#include <token> <answer> "bus.h" 
<token> "sysfs_local.h" <answer> #include 
struct <token> { <answer> dpn_attribute 
struct <token> dev_attr; <answer> device_attribute 
<token> N; <answer> int 
int <token> <answer> dir; 
const <token> *format_string; <answer> char 
#define <token> 15 <answer> SDW_DPN_ATTRIBUTES 
<token> sdw_dpn_attribute_alloc(field) \ <answer> #define 
static int field##_attribute_alloc(struct device *dev, <token> <answer> \ 
struct attribute <token> \ <answer> **res, 
int N, int dir, <token> <answer> \ 
<token> char *format_string) \ <answer> const 
<token> \ <answer> { 
struct dpn_attribute *dpn_attr; <token> <answer> \ 
dpn_attr = <token> sizeof(*dpn_attr), GFP_KERNEL); \ <answer> devm_kzalloc(dev, 
<token> (!dpn_attr) \ <answer> if 
<token> -ENOMEM; \ <answer> return 
dpn_attr->N <token> N; \ <answer> = 
<token> = dir; \ <answer> dpn_attr->dir 
<token> \ <answer> sysfs_attr_init(&dpn_attr->dev_attr.attr); 
dpn_attr->format_string <token> format_string; \ <answer> = 
dpn_attr->dev_attr.attr.name <token> __stringify(field); \ <answer> = 
<token> = 0444; \ <answer> dpn_attr->dev_attr.attr.mode 
<token> = field##_show; \ <answer> dpn_attr->dev_attr.show 
*res = <token> \ <answer> &dpn_attr->dev_attr.attr; 
<token> 0; \ <answer> return 
#define sdw_dpn_attr(field) <token> <answer> \ 
static ssize_t field##_dpn_show(struct <token> *slave, \ <answer> sdw_slave 
int <token> \ <answer> N, 
int <token> \ <answer> dir, 
const char <token> \ <answer> *format_string, 
char *buf) <token> <answer> \ 
{ <token> <answer> \ 
<token> sdw_dpn_prop *dpn; \ <answer> struct 
unsigned <token> mask; \ <answer> long 
int bit; <token> <answer> \ 
int i; <token> <answer> \ 
if (dir) { <token> <answer> \ 
dpn = <token> \ <answer> slave->prop.src_dpn_prop; 
mask = <token> \ <answer> slave->prop.source_ports; 
} else <token> \ <answer> { 
<token> = slave->prop.sink_dpn_prop; \ <answer> dpn 
mask = slave->prop.sink_ports; <token> <answer> \ 
<token> \ <answer> } 
i = 0; <token> <answer> \ 
for_each_set_bit(bit, &mask, 32) <token> \ <answer> { 
if (bit == <token> { \ <answer> N) 
return sprintf(buf, format_string, <token> <answer> \ 
dpn[i].field); <token> <answer> \ 
} <token> <answer> \ 
i++; <token> <answer> \ 
<token> \ <answer> } 
return <token> \ <answer> -EINVAL; 
<token> \ <answer> } 
static ssize_t field##_show(struct device *dev, <token> <answer> \ 
struct device_attribute <token> \ <answer> *attr, 
<token> *buf) \ <answer> char 
{ <token> <answer> \ 
struct sdw_slave <token> = dev_to_sdw_dev(dev); \ <answer> *slave 
struct dpn_attribute *dpn_attr <token> \ <answer> = 
container_of(attr, struct dpn_attribute, <token> \ <answer> dev_attr); 
return field##_dpn_show(slave, <token> <answer> \ 
<token> dpn_attr->dir, \ <answer> dpn_attr->N, 
<token> \ <answer> dpn_attr->format_string, 
buf); <token> <answer> \ 
} <token> <answer> \ 
#define <token> \ <answer> sdw_dpn_array_attr(field) 
static ssize_t field##_dpn_show(struct sdw_slave *slave, <token> <answer> \ 
int <token> \ <answer> N, 
int dir, <token> <answer> \ 
const char <token> \ <answer> *format_string, 
<token> *buf) \ <answer> char 
<token> \ <answer> { 
struct sdw_dpn_prop <token> \ <answer> *dpn; 
<token> long mask; \ <answer> unsigned 
ssize_t <token> = 0; \ <answer> size 
int <token> \ <answer> bit; 
int <token> \ <answer> i; 
<token> j; \ <answer> int 
if <token> { \ <answer> (dir) 
dpn = <token> \ <answer> slave->prop.src_dpn_prop; 
mask = <token> \ <answer> slave->prop.source_ports; 
} else { <token> <answer> \ 
dpn = slave->prop.sink_dpn_prop; <token> <answer> \ 
<token> = slave->prop.sink_ports; \ <answer> mask 
} <token> <answer> \ 
i <token> 0; \ <answer> = 
for_each_set_bit(bit, <token> 32) { \ <answer> &mask, 
if (bit == N) { <token> <answer> \ 
for (j = 0; j < dpn[i].num_##field; <token> \ <answer> j++) 
size <token> sprintf(buf + size, \ <answer> += 
format_string, <token> <answer> \ 
dpn[i].field[j]); <token> <answer> \ 
size += sprintf(buf + size, <token> \ <answer> "\n"); 
return <token> \ <answer> size; 
<token> \ <answer> } 
<token> \ <answer> i++; 
} <token> <answer> \ 
return <token> \ <answer> -EINVAL; 
} <token> <answer> \ 
static ssize_t field##_show(struct device *dev, <token> <answer> \ 
struct device_attribute *attr, <token> <answer> \ 
<token> *buf) \ <answer> char 
{ <token> <answer> \ 
struct <token> *slave = dev_to_sdw_dev(dev); \ <answer> sdw_slave 
struct dpn_attribute *dpn_attr <token> \ <answer> = 
container_of(attr, struct dpn_attribute, <token> \ <answer> dev_attr); 
return field##_dpn_show(slave, <token> <answer> \ 
dpn_attr->N, dpn_attr->dir, <token> <answer> \ 
dpn_attr->format_string, <token> <answer> \ 
<token> \ <answer> buf); 
} <token> <answer> \ 
static int add_all_attributes(struct device <token> int N, int dir) <answer> *dev, 
<token> attribute **dpn_attrs; <answer> struct 
struct attribute_group <token> <answer> *dpn_group; 
int i <token> 0; <answer> = 
int <token> <answer> ret; 
#include <token> <answer> "archinsn.h" 
<token> "event.h" <answer> #include 
#include <token> <answer> "machine.h" 
<token> "thread.h" <answer> #include 
#include <token> <answer> "symbol.h" 
<token> "../../../../arch/x86/include/asm/insn.h" <answer> #include 
void <token> perf_sample *sample, <answer> arch_fetch_insn(struct 
struct thread <token> <answer> *thread, 
struct <token> *machine) <answer> machine 
struct <token> insn; <answer> insn 
int <token> ret; <answer> len, 
<token> is64bit = false; <answer> bool 
if <token> <answer> (!sample->ip) 
len = thread__memcpy(thread, machine, sample->insn, <token> sizeof(sample->insn), &is64bit); <answer> sample->ip, 
if <token> <= 0) <answer> (len 
ret <token> insn_decode(&insn, sample->insn, len, <answer> = 
is64bit ? INSN_MODE_64 <token> INSN_MODE_32); <answer> : 
if (ret >= <token> && insn.length <= len) <answer> 0 
<token> = insn.length; <answer> sample->insn_len 
#include <token> <answer> <linux/pm_runtime.h> 
#include <token> <answer> <linux/math.h> 
#include <token> <answer> <linux/time.h> 
<token> <linux/units.h> <answer> #include 
<token> <net/pkt_cls.h> <answer> #include 
#include <token> <answer> "am65-cpsw-nuss.h" 
<token> "am65-cpsw-qos.h" <answer> #include 
<token> "am65-cpts.h" <answer> #include 
#include <token> <answer> "cpsw_ale.h" 
#define TO_MBPS(x) <token> BYTES_PER_MBIT) <answer> DIV_ROUND_UP((x), 
enum timer_act <token> <answer> { 
for (tc = 0; <token> < mqprio->qopt.num_tc; tc++) { <answer> tc 
prio = <token> <answer> tc; 
rate_mbps = <token> <answer> TO_MBPS(mqprio->min_rate[tc]); 
rate_mbps <token> am65_cpsw_qos_tx_rate_calc(rate_mbps, <answer> = 
<token> + AM65_CPSW_PN_REG_PRI_CIR(prio)); <answer> port->port_base 
rate_mbps <token> 0; <answer> = 
<token> (mqprio->max_rate[tc]) { <answer> if 
rate_mbps = <token> - mqprio->min_rate[tc]; <answer> mqprio->max_rate[tc] 
<token> = TO_MBPS(rate_mbps); <answer> rate_mbps 
rate_mbps <token> am65_cpsw_qos_tx_rate_calc(rate_mbps, <answer> = 
port->port_base <token> AM65_CPSW_PN_REG_PRI_EIR(prio)); <answer> + 
static int <token> am65_cpsw_port *port, <answer> am65_cpsw_mqprio_verify_shaper(struct 
struct tc_mqprio_qopt_offload <token> <answer> *mqprio) 
struct am65_cpsw_mqprio *p_mqprio = <token> <answer> &port->qos.mqprio; 
struct netlink_ext_ack <token> = mqprio->extack; <answer> *extack 
u64 min_rate_total = 0, max_rate_total <token> 0; <answer> = 
u32 min_rate_msk = 0, <token> = 0; <answer> max_rate_msk 
bool <token> has_max_rate; <answer> has_min_rate, 
<token> num_tc, i; <answer> int 
if <token> & TC_MQPRIO_F_SHAPER)) <answer> (!(mqprio->flags 
return <token> <answer> 0; 
if <token> != TC_MQPRIO_SHAPER_BW_RATE) <answer> (mqprio->shaper 
return <token> <answer> 0; 
has_min_rate = <token> & TC_MQPRIO_F_MIN_RATE); <answer> !!(mqprio->flags 
has_max_rate = !!(mqprio->flags <token> TC_MQPRIO_F_MAX_RATE); <answer> & 
<token> (!has_min_rate && has_max_rate) { <answer> if 
NL_SET_ERR_MSG_MOD(extack, "min_rate <token> required with max_rate"); <answer> is 
<token> -EOPNOTSUPP; <answer> return 
<token> (!has_min_rate) <answer> if 
return <token> <answer> 0; 
num_tc = <token> <answer> mqprio->qopt.num_tc; 
for (i = num_tc - 1; i >= 0; <token> { <answer> i--) 
<token> ch_msk; <answer> u32 
<token> (mqprio->min_rate[i]) <answer> if 
min_rate_msk |= <token> <answer> BIT(i); 
<token> += mqprio->min_rate[i]; <answer> min_rate_total 
<token> (has_max_rate) { <answer> if 
<token> (mqprio->max_rate[i]) <answer> if 
max_rate_msk <token> BIT(i); <answer> |= 
max_rate_total <token> mqprio->max_rate[i]; <answer> += 
if <token> && mqprio->max_rate[i]) { <answer> (!mqprio->min_rate[i] 
"TX <token> rate max>0 but min=0", <answer> tc%d 
return <token> <answer> -EINVAL; 
if (mqprio->max_rate[i] <token> <answer> && 
<token> < mqprio->min_rate[i]) { <answer> mqprio->max_rate[i] 
"TX <token> rate min(%llu)>max(%llu)", <answer> tc%d 
i, <token> <answer> mqprio->min_rate[i], 
return <token> <answer> -EINVAL; 
<token> = GENMASK(num_tc - 1, i); <answer> ch_msk 
if ((min_rate_msk & BIT(i)) && (min_rate_msk ^ ch_msk)) <token> <answer> { 
"Min rate <token> be set sequentially hi->lo tx_rate_msk%x", <answer> must 
return <token> <answer> -EINVAL; 
if ((max_rate_msk & <token> && (max_rate_msk ^ ch_msk)) { <answer> BIT(i)) 
"Max rate must be set sequentially <token> tx_rate_msk%x", <answer> hi->lo 
return <token> <answer> -EINVAL; 
min_rate_total = <token> <answer> TO_MBPS(min_rate_total); 
max_rate_total <token> TO_MBPS(max_rate_total); <answer> = 
<token> = true; <answer> p_mqprio->shaper_en 
p_mqprio->max_rate_total = max_t(u64, <token> max_rate_total); <answer> min_rate_total, 
<token> 0; <answer> return 
<token> void am65_cpsw_reset_tc_mqprio(struct net_device *ndev) <answer> static 
struct <token> *port = am65_ndev_to_port(ndev); <answer> am65_cpsw_port 
struct <token> *p_mqprio = &port->qos.mqprio; <answer> am65_cpsw_mqprio 
p_mqprio->shaper_en <token> false; <answer> = 
p_mqprio->max_rate_total = <token> <answer> 0; 
for (tc = 0; tc <token> num_tc; tc++) { <answer> < 
prio = <token> <answer> tc; 
for (i = qopt->offset[tc]; i <token> qopt->offset[tc] + qopt->count[tc]; i++) <answer> < 
tx_prio_map |= prio << (4 * <token> <answer> i); 
count <token> qopt->count[tc]; <answer> = 
offset <token> qopt->offset[tc]; <answer> = 
netdev_set_tc_queue(ndev, tc, count, <token> <answer> offset); 
writel(tx_prio_map, port->port_base <token> AM65_CPSW_PN_REG_TX_PRI_MAP); <answer> + 
<token> mqprio->preemptible_tcs); <answer> am65_cpsw_iet_change_preemptible_tcs(port, 
<token> ret; <answer> return 
<token> int am65_cpsw_iet_set_verify_timeout_count(struct am65_cpsw_port *port) <answer> static 
<token> verify_time_ms = port->qos.iet.verify_time_ms; <answer> int 
<token> val; <answer> u32 
ctrl = <token> + AM65_CPSW_PN_REG_IET_CTRL); <answer> readl(port->port_base 
<token> |= AM65_CPSW_PN_IET_MAC_LINKFAIL; <answer> ctrl 
writel(ctrl, <token> + AM65_CPSW_PN_REG_IET_CTRL); <answer> port->port_base 
void am65_cpsw_iet_common_enable(struct am65_cpsw_common <token> <answer> *common) 
struct <token> *port; <answer> am65_cpsw_port 
bool <token> = false; <answer> rx_enable 
<token> val; <answer> u32 
int <token> <answer> i; 
for (i <token> 0; i < common->port_num; i++) { <answer> = 
port <token> &common->ports[i]; <answer> = 
val = readl(port->port_base <token> AM65_CPSW_PN_REG_CTL); <answer> + 
rx_enable <token> !!(val & AM65_CPSW_PN_CTL_IET_PORT_EN); <answer> = 
if <token> <answer> (rx_enable) 
<token> = readl(common->cpsw_base + AM65_CPSW_REG_CTL); <answer> val 
if <token> <answer> (rx_enable) 
val |= <token> <answer> AM65_CPSW_CTL_IET_EN; 
<token> &= ~AM65_CPSW_CTL_IET_EN; <answer> val 
writel(val, common->cpsw_base + <token> <answer> AM65_CPSW_REG_CTL); 
common->iet_enabled = <token> <answer> rx_enable; 
void am65_cpsw_iet_commit_preemptible_tcs(struct <token> *port) <answer> am65_cpsw_port 
u8 <token> <answer> preemptible_tcs; 
int <token> <answer> err; 
u32 <token> <answer> val; 
if (port->qos.link_speed == <token> <answer> SPEED_UNKNOWN) 
<token> = readl(port->port_base + AM65_CPSW_PN_REG_CTL); <answer> val 
if (!(val <token> AM65_CPSW_PN_CTL_IET_PORT_EN)) <answer> & 
static int am65_cpsw_port_est_is_swapped(struct net_device <token> int *oper, <answer> *ndev, 
int <token> <answer> *admin) 
struct am65_cpsw_port *port <token> am65_ndev_to_port(ndev); <answer> = 
<token> val; <answer> u32 
val = readl(port->port_base + <token> <answer> AM65_CPSW_PN_REG_FIFO_STATUS); 
*oper <token> !!(val & AM65_CPSW_PN_FST_EST_BUFACT); <answer> = 
val = <token> + AM65_CPSW_PN_REG_EST_CTL); <answer> readl(port->port_base 
*admin = !!(val & <token> <answer> AM65_CPSW_PN_EST_BUFSEL); 
return *admin <token> *oper; <answer> == 
static int am65_cpsw_port_est_get_free_buf_num(struct net_device <token> <answer> *ndev) 
int <token> admin; <answer> oper, 
int roll = <token> <answer> 2; 
while (roll--) <token> <answer> { 
if (am65_cpsw_port_est_is_swapped(ndev, <token> &admin)) <answer> &oper, 
return <token> <answer> !oper; 
<token> oper); <answer> am65_cpsw_port_est_assign_buf_num(ndev, 
"Prev. EST <token> cycle is in transit %d -> %d\n", <answer> admin 
oper, <token> <answer> admin); 
return <token> <answer> admin; 
static void am65_cpsw_admin_to_oper(struct net_device <token> <answer> *ndev) 
struct am65_cpsw_port *port = <token> <answer> am65_ndev_to_port(ndev); 
devm_kfree(&ndev->dev, <token> <answer> port->qos.est_oper); 
<token> = port->qos.est_admin; <answer> port->qos.est_oper 
port->qos.est_admin <token> NULL; <answer> = 
static <token> am65_cpsw_port_est_get_buf_num(struct net_device *ndev, <answer> void 
struct <token> *est_new) <answer> am65_cpsw_est 
struct am65_cpsw_port *port <token> am65_ndev_to_port(ndev); <answer> = 
u32 <token> <answer> val; 
val = <token> + AM65_CPSW_PN_REG_EST_CTL); <answer> readl(port->port_base 
val <token> ~AM65_CPSW_PN_EST_ONEBUF; <answer> &= 
writel(val, port->port_base + <token> <answer> AM65_CPSW_PN_REG_EST_CTL); 
est_new->buf = <token> <answer> am65_cpsw_port_est_get_free_buf_num(ndev); 
static void am65_cpsw_est_update_state(struct net_device <token> <answer> *ndev) 
struct am65_cpsw_port *port = <token> <answer> am65_ndev_to_port(ndev); 
int <token> admin; <answer> oper, 
if <token> <answer> (!port->qos.est_admin) 
if <token> &oper, &admin)) <answer> (!am65_cpsw_port_est_is_swapped(ndev, 
static int am65_est_cmd_ns_to_cnt(u64 ns, int <token> <answer> link_speed) 
<token> temp; <answer> u64 
temp <token> ns * link_speed; <answer> = 
<token> (link_speed < SPEED_1000) <answer> if 
temp <<= <token> <answer> 1; 
return DIV_ROUND_UP(temp, <token> * 1000); <answer> 8 
static void __iomem <token> __iomem *addr, <answer> *am65_cpsw_est_set_sched_cmds(void 
<token> fetch_cnt, <answer> int 
<token> fetch_allow) <answer> int 
u32 prio_mask, cmd_fetch_cnt, <token> <answer> cmd; 
<token> { <answer> do 
if (fetch_cnt <token> AM65_CPSW_FETCH_CNT_MAX) { <answer> > 
<token> -= AM65_CPSW_FETCH_CNT_MAX; <answer> fetch_cnt 
<token> = AM65_CPSW_FETCH_CNT_MAX; <answer> cmd_fetch_cnt 
<token> else { <answer> } 
<token> = fetch_cnt; <answer> cmd_fetch_cnt 
static int am65_cpsw_timer_set(struct net_device <token> <answer> *ndev, 
struct am65_cpsw_est <token> <answer> *est_new) 
<token> am65_cpsw_port *port = am65_ndev_to_port(ndev); <answer> struct 
struct am65_cpsw_common *common = <token> <answer> port->common; 
<token> am65_cpts *cpts = common->cpts; <answer> struct 
struct am65_cpts_estf_cfg <token> <answer> cfg; 
cfg.ns_period = <token> <answer> est_new->taprio.cycle_time; 
cfg.ns_start <token> est_new->taprio.base_time; <answer> = 
return <token> port->port_id - 1, &cfg); <answer> am65_cpts_estf_enable(cpts, 
static <token> am65_cpsw_timer_stop(struct net_device *ndev) <answer> void 
struct am65_cpsw_port <token> = am65_ndev_to_port(ndev); <answer> *port 
<token> am65_cpts *cpts = port->common->cpts; <answer> struct 
am65_cpts_estf_disable(cpts, port->port_id <token> 1); <answer> - 
static enum timer_act am65_cpsw_timer_act(struct <token> *ndev, <answer> net_device 
<token> am65_cpsw_est *est_new) <answer> struct 
struct <token> *taprio_oper, *taprio_new; <answer> tc_taprio_qopt_offload 
struct <token> *port = am65_ndev_to_port(ndev); <answer> am65_cpsw_port 
struct <token> *cpts = port->common->cpts; <answer> am65_cpts 
<token> cur_time; <answer> u64 
s64 <token> <answer> diff; 
if <token> <answer> (!port->qos.est_oper) 
<token> TACT_PROG; <answer> return 
<token> = &est_new->taprio; <answer> taprio_new 
<token> = &port->qos.est_oper->taprio; <answer> taprio_oper 
if (taprio_new->cycle_time <token> taprio_oper->cycle_time) <answer> != 
return <token> <answer> TACT_NEED_STOP; 
#include <token> <answer> "priv.h" 
<token> <nvif/class.h> <answer> #include 
static const <token> nvkm_falcon_func <answer> struct 
gk104_mspdec = <token> <answer> { 
.init <token> gf100_mspdec_init, <answer> = 
.sclass = <token> <answer> { 
{ <token> -1, GK104_MSPDEC }, <answer> -1, 
gk104_mspdec_new(struct nvkm_device *device, <token> nvkm_subdev_type type, int inst, <answer> enum 
<token> nvkm_engine **pengine) <answer> struct 
return <token> device, type, inst, pengine); <answer> nvkm_mspdec_new_(&gk104_mspdec, 
<token> <linux/pci.h> <answer> #include 
<token> <pci.h> <answer> #include 
<token> <loongson.h> <answer> #include 
static struct resource loongson_pci_mem_resource <token> { <answer> = 
<token> = "pci memory space", <answer> .name 
<token> = LOONGSON_PCI_MEM_START, <answer> .start 
<token> = LOONGSON_PCI_MEM_END, <answer> .end 
.flags <token> IORESOURCE_MEM, <answer> = 
<token> struct resource loongson_pci_io_resource = { <answer> static 
.name = <token> io space", <answer> "pci 
.start <token> LOONGSON_PCI_IO_START, <answer> = 
.end <token> IO_SPACE_LIMIT, <answer> = 
<token> = IORESOURCE_IO, <answer> .flags 
static <token> pci_controller loongson_pci_controller = { <answer> struct 
<token> = &loongson_pci_ops, <answer> .pci_ops 
<token> = &loongson_pci_io_resource, <answer> .io_resource 
.mem_resource <token> &loongson_pci_mem_resource, <answer> = 
.mem_offset = <token> <answer> 0x00000000UL, 
<token> = 0x00000000UL, <answer> .io_offset 
static void <token> setup_pcimap(void) <answer> __init 
<token> = LOONGSON_PCIMAP_PCIMAP_2 | <answer> LOONGSON_PCIMAP 
<token> LOONGSON_PCILO2_BASE) | <answer> LOONGSON_PCIMAP_WIN(2, 
LOONGSON_PCIMAP_WIN(1, <token> | <answer> LOONGSON_PCILO1_BASE) 
LOONGSON_PCIMAP_WIN(0, <token> <answer> 0); 
LOONGSON_PXARB_CFG <token> 0x00fe0105ul; <answer> = 
#ifdef <token> <answer> CONFIG_CPU_SUPPORTS_ADDRWINCFG 
<token> LOONGSON_CPU_MEM_SRC, <answer> LOONGSON_ADDRWIN_CPUTOPCI(ADDRWIN_WIN2, 
<token> MMAP_CPUTOPCI_SIZE); <answer> LOONGSON_PCI_MEM_DST, 
<token> int __init pcibios_init(void) <answer> static 
<token> = mips_io_port_base; <answer> loongson_pci_controller.io_map_base 
return <token> <answer> 0; 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/pci.h> <answer> #include 
#include <token> <answer> <linux/blkdev.h> 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/device.h> 
<token> <scsi/scsi_host.h> <answer> #include 
<token> <linux/libata.h> <answer> #include 
#include <token> <answer> <linux/ata.h> 
<token> DRV_NAME "pata_artop" <answer> #define 
<token> DRV_VERSION "0.4.8" <answer> #define 
static int clock <token> 0; <answer> = 
static int artop62x0_pre_reset(struct ata_link <token> unsigned long deadline) <answer> *link, 
static const struct pci_bits artop_enable_bits[] <token> { <answer> = 
<token> int artop6260_cable_detect(struct ata_port *ap) <answer> static 
struct <token> *pdev = to_pci_dev(ap->host->dev); <answer> pci_dev 
<token> tmp; <answer> u8 
pci_read_config_byte(pdev, <token> &tmp); <answer> 0x49, 
if <token> & (1 << ap->port_no)) <answer> (tmp 
return <token> <answer> ATA_CBL_PATA40; 
<token> ATA_CBL_PATA80; <answer> return 
static void artop6210_load_piomode(struct ata_port *ap, struct ata_device <token> unsigned int pio) <answer> *adev, 
struct pci_dev <token> = to_pci_dev(ap->host->dev); <answer> *pdev 
int dn = adev->devno + 2 * <token> <answer> ap->port_no; 
static const <token> timing[2][5] = { <answer> u16 
{ <token> 0x000A, 0x0008, 0x0303, 0x0301 }, <answer> 0x0000, 
{ 0x0700, 0x070A, 0x0708, <token> 0x0401 } <answer> 0x0403, 
static void artop6210_set_piomode(struct <token> *ap, struct ata_device *adev) <answer> ata_port 
struct pci_dev *pdev = <token> <answer> to_pci_dev(ap->host->dev); 
int dn = <token> + 2 * ap->port_no; <answer> adev->devno 
u8 <token> <answer> ultra; 
artop6210_load_piomode(ap, adev, <token> - XFER_PIO_0); <answer> adev->pio_mode 
static void artop6260_load_piomode (struct ata_port <token> struct ata_device *adev, unsigned int pio) <answer> *ap, 
struct pci_dev <token> = to_pci_dev(ap->host->dev); <answer> *pdev 
int dn = <token> + 2 * ap->port_no; <answer> adev->devno 
static const u8 <token> = { <answer> timing[2][5] 
{ <token> 0x0A, 0x08, 0x33, 0x31 }, <answer> 0x00, 
{ 0x70, 0x7A, <token> 0x43, 0x41 } <answer> 0x78, 
static void artop6260_set_piomode(struct ata_port *ap, struct <token> *adev) <answer> ata_device 
struct <token> *pdev = to_pci_dev(ap->host->dev); <answer> pci_dev 
u8 <token> <answer> ultra; 
artop6260_load_piomode(ap, adev, adev->pio_mode - <token> <answer> XFER_PIO_0); 
static void artop6210_set_dmamode (struct ata_port <token> struct ata_device *adev) <answer> *ap, 
unsigned int <token> <answer> pio; 
struct pci_dev *pdev <token> to_pci_dev(ap->host->dev); <answer> = 
int dn = adev->devno + 2 <token> ap->port_no; <answer> * 
<token> ultra; <answer> u8 
if (adev->dma_mode == <token> <answer> XFER_MW_DMA_0) 
pio = <token> <answer> 1; 
pio <token> 4; <answer> = 
static void artop6260_set_dmamode (struct ata_port <token> struct ata_device *adev) <answer> *ap, 
unsigned <token> pio; <answer> int 
<token> pci_dev *pdev = to_pci_dev(ap->host->dev); <answer> struct 
<token> ultra; <answer> u8 
if (adev->dma_mode <token> XFER_MW_DMA_0) <answer> == 
pio <token> 1; <answer> = 
<token> = 4; <answer> pio 
<token> int artop6210_qc_defer(struct ata_queued_cmd *qc) <answer> static 
struct ata_host *host = <token> <answer> qc->ap->host; 
struct ata_port *alt <token> host->ports[1 ^ qc->ap->port_no]; <answer> = 
<token> rc; <answer> int 
<token> (alt && alt->qc_active) <answer> if 
return <token> <answer> ATA_DEFER_PORT; 
<token> 0; <answer> return 
static const <token> scsi_host_template artop_sht = { <answer> struct 
static <token> ata_port_operations artop6210_ops = { <answer> struct 
.inherits = <token> <answer> &ata_bmdma_port_ops, 
<token> = ata_cable_40wire, <answer> .cable_detect 
<token> = artop6210_set_piomode, <answer> .set_piomode 
<token> = artop6210_set_dmamode, <answer> .set_dmamode 
.prereset = <token> <answer> artop62x0_pre_reset, 
.qc_defer <token> artop6210_qc_defer, <answer> = 
static struct <token> artop6260_ops = { <answer> ata_port_operations 
.inherits = <token> <answer> &ata_bmdma_port_ops, 
.cable_detect <token> artop6260_cable_detect, <answer> = 
.set_piomode <token> artop6260_set_piomode, <answer> = 
<token> = artop6260_set_dmamode, <answer> .set_dmamode 
.prereset = <token> <answer> artop62x0_pre_reset, 
static <token> atp8xx_fixup(struct pci_dev *pdev) <answer> void 
<token> reg; <answer> u8 
switch <token> { <answer> (pdev->device) 
<token> 0x0005: <answer> case 
pci_read_config_byte(pdev, PCI_LATENCY_TIMER, <token> <answer> &reg); 
if (reg <= <token> <answer> 0x80) 
pci_write_config_byte(pdev, PCI_LATENCY_TIMER, <token> <answer> 0x90); 
static int artop_init_one (struct pci_dev <token> const struct pci_device_id *id) <answer> *pdev, 
static const struct ata_port_info info_6210 = <token> <answer> { 
.flags <token> ATA_FLAG_SLAVE_POSS, <answer> = 
<token> = ATA_PIO4, <answer> .pio_mask 
<token> = ATA_MWDMA2, <answer> .mwdma_mask 
.udma_mask = <token> <answer> ATA_UDMA2, 
<token> = &artop6210_ops, <answer> .port_ops 
static const <token> ata_port_info info_626x = { <answer> struct 
.flags = <token> <answer> ATA_FLAG_SLAVE_POSS, 
.pio_mask <token> ATA_PIO4, <answer> = 
<token> = ATA_MWDMA2, <answer> .mwdma_mask 
.udma_mask <token> ATA_UDMA4, <answer> = 
<token> = &artop6260_ops, <answer> .port_ops 
static const struct ata_port_info <token> = { <answer> info_628x 
<token> = ATA_FLAG_SLAVE_POSS, <answer> .flags 
<token> = ATA_PIO4, <answer> .pio_mask 
.mwdma_mask <token> ATA_MWDMA2, <answer> = 
.udma_mask <token> ATA_UDMA5, <answer> = 
.port_ops = <token> <answer> &artop6260_ops, 
static const struct ata_port_info <token> = { <answer> info_628x_fast 
.flags <token> ATA_FLAG_SLAVE_POSS, <answer> = 
.pio_mask = <token> <answer> ATA_PIO4, 
.mwdma_mask <token> ATA_MWDMA2, <answer> = 
.udma_mask = <token> <answer> ATA_UDMA6, 
<token> = &artop6260_ops, <answer> .port_ops 
<token> struct ata_port_info *ppi[] = { NULL, NULL }; <answer> const 
int <token> <answer> rc; 
<token> DRV_VERSION); <answer> ata_print_version_once(&pdev->dev, 
rc <token> pcim_enable_device(pdev); <answer> = 
if <token> <answer> (rc) 
return <token> <answer> rc; 
switch <token> { <answer> (id->driver_data) 
<token> <linux/list.h> <answer> #include 
#include <token> <answer> <net/sctp/sctp.h> 
#include <token> <answer> <net/sctp/sm.h> 
<token> <net/sctp/stream_sched.h> <answer> #include 
static int <token> sctp_stream *stream, __u16 sid, <answer> sctp_sched_fcfs_set(struct 
<token> value, gfp_t gfp) <answer> __u16 
<token> 0; <answer> return 
static int sctp_sched_fcfs_get(struct sctp_stream <token> __u16 sid, <answer> *stream, 
__u16 <token> <answer> *value) 
<token> = 0; <answer> *value 
return <token> <answer> 0; 
static int sctp_sched_fcfs_init(struct <token> *stream) <answer> sctp_stream 
<token> 0; <answer> return 
static int sctp_sched_fcfs_init_sid(struct sctp_stream *stream, __u16 <token> <answer> sid, 
gfp_t <token> <answer> gfp) 
<token> 0; <answer> return 
static void <token> sctp_stream *stream, __u16 sid) <answer> sctp_sched_fcfs_free_sid(struct 
static void <token> sctp_outq *q, <answer> sctp_sched_fcfs_enqueue(struct 
<token> sctp_datamsg *msg) <answer> struct 
static <token> sctp_chunk *sctp_sched_fcfs_dequeue(struct sctp_outq *q) <answer> struct 
struct sctp_stream *stream = <token> <answer> &q->asoc->stream; 
<token> sctp_chunk *ch = NULL; <answer> struct 
struct list_head <token> <answer> *entry; 
if <token> <answer> (list_empty(&q->out_chunk_list)) 
goto <token> <answer> out; 
<token> (stream->out_curr) { <answer> if 
ch = <token> <answer> list_entry(stream->out_curr->ext->outq.next, 
struct sctp_chunk, <token> <answer> stream_list); 
<token> else { <answer> } 
entry = <token> <answer> q->out_chunk_list.next; 
ch = <token> struct sctp_chunk, list); <answer> list_entry(entry, 
<token> ch); <answer> sctp_sched_dequeue_common(q, 
<token> ch; <answer> return 
static void sctp_sched_fcfs_dequeue_done(struct <token> *q, <answer> sctp_outq 
struct <token> *chunk) <answer> sctp_chunk 
static void sctp_sched_fcfs_sched_all(struct sctp_stream <token> <answer> *stream) 
static void <token> sctp_stream *stream) <answer> sctp_sched_fcfs_unsched_all(struct 
static struct sctp_sched_ops sctp_sched_fcfs <token> { <answer> = 
.set <token> sctp_sched_fcfs_set, <answer> = 
.get <token> sctp_sched_fcfs_get, <answer> = 
.init <token> sctp_sched_fcfs_init, <answer> = 
<token> = sctp_sched_fcfs_init_sid, <answer> .init_sid 
.free_sid <token> sctp_sched_fcfs_free_sid, <answer> = 
.enqueue = <token> <answer> sctp_sched_fcfs_enqueue, 
.dequeue <token> sctp_sched_fcfs_dequeue, <answer> = 
.dequeue_done <token> sctp_sched_fcfs_dequeue_done, <answer> = 
.sched_all = <token> <answer> sctp_sched_fcfs_sched_all, 
.unsched_all = <token> <answer> sctp_sched_fcfs_unsched_all, 
static <token> sctp_sched_ops_fcfs_init(void) <answer> void 
sctp_sched_ops_register(SCTP_SS_FCFS, <token> <answer> &sctp_sched_fcfs); 
sid <token> sctp_chunk_stream_no(ch); <answer> = 
<token> = SCTP_SO(&q->asoc->stream, sid); <answer> sout 
<token> = sout; <answer> q->asoc->stream.out_curr 
q->asoc->stream.out_curr <token> NULL; <answer> = 
<token> ch); <answer> q->sched->dequeue_done(q, 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_irq.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/power_supply.h> 
<token> <linux/regmap.h> <answer> #include 
<token> <linux/gpio/consumer.h> <answer> #include 
static const <token> *act8945a_charger_model = "ACT8945A"; <answer> char 
<token> const char *act8945a_charger_manufacturer = "Active-semi"; <answer> static 
<token> MAX_CURRENT_AC_HIGH 886527 <answer> #define 
#define <token> 117305 <answer> MAX_CURRENT_AC_LOW 
#define MAX_CURRENT_AC_HIGH_PRE <token> <answer> 88653 
#define MAX_CURRENT_AC_LOW_PRE <token> <answer> 11731 
static int <token> act8945a_charger *charger, <answer> act8945a_get_current_max(struct 
struct regmap *regmap, <token> *val) <answer> int 
<token> ret; <answer> int 
unsigned int status, <token> <answer> state; 
<token> int acin_state; <answer> unsigned 
int <token> = gpiod_get_value(charger->chglev_gpio); <answer> chgin_level 
ret = <token> ACT8945A_APCH_STATUS, &status); <answer> regmap_read(regmap, 
<token> (ret < 0) <answer> if 
<token> ret; <answer> return 
ret = <token> ACT8945A_APCH_STATE, &state); <answer> regmap_read(regmap, 
if <token> < 0) <answer> (ret 
return <token> <answer> ret; 
acin_state <token> (state & APCH_STATE_ACINSTAT) >> 1; <answer> = 
state &= <token> <answer> APCH_STATE_CSTATE; 
state <token> APCH_STATE_CSTATE_SHIFT; <answer> >>= 
switch <token> { <answer> (state) 
<token> APCH_STATE_CSTATE_PRE: <answer> case 
if <token> { <answer> (acin_state) 
if <token> <answer> (chgin_level) 
*val <token> MAX_CURRENT_AC_HIGH_PRE; <answer> = 
*val <token> MAX_CURRENT_AC_LOW_PRE; <answer> = 
} <token> { <answer> else 
<token> = MAX_CURRENT_USB_PRE; <answer> *val 
<token> APCH_STATE_CSTATE_FAST: <answer> case 
if (acin_state) <token> <answer> { 
<token> (chgin_level) <answer> if 
<token> = MAX_CURRENT_AC_HIGH; <answer> *val 
*val = <token> <answer> MAX_CURRENT_AC_LOW; 
} else <token> <answer> { 
if <token> <answer> (chgin_level) 
*val = <token> <answer> MAX_CURRENT_USB_HIGH; 
<token> = MAX_CURRENT_USB_LOW; <answer> *val 
case <token> <answer> APCH_STATE_CSTATE_EOC: 
<token> APCH_STATE_CSTATE_DISABLED: <answer> case 
*val <token> 0; <answer> = 
return <token> <answer> 0; 
static enum power_supply_property act8945a_charger_props[] <token> { <answer> = 
static int act8945a_charger_get_property(struct <token> *psy, <answer> power_supply 
enum power_supply_property <token> <answer> prop, 
<token> power_supply_propval *val) <answer> union 
struct act8945a_charger <token> = power_supply_get_drvdata(psy); <answer> *charger 
struct regmap *regmap <token> charger->regmap; <answer> = 
int <token> = 0; <answer> ret 
<token> (prop) { <answer> switch 
case <token> <answer> POWER_SUPPLY_PROP_STATUS: 
ret = act8945a_get_charger_state(regmap, <token> <answer> &val->intval); 
case <token> <answer> POWER_SUPPLY_PROP_CHARGE_TYPE: 
ret = <token> &val->intval); <answer> act8945a_get_charge_type(regmap, 
<token> POWER_SUPPLY_PROP_TECHNOLOGY: <answer> case 
<token> = POWER_SUPPLY_TECHNOLOGY_LION; <answer> val->intval 
case <token> <answer> POWER_SUPPLY_PROP_HEALTH: 
ret <token> act8945a_get_battery_health(regmap, &val->intval); <answer> = 
<token> POWER_SUPPLY_PROP_CAPACITY_LEVEL: <answer> case 
ret <token> act8945a_get_capacity_level(charger, <answer> = 
regmap, <token> <answer> &val->intval); 
case <token> <answer> POWER_SUPPLY_PROP_CURRENT_MAX: 
ret = <token> <answer> act8945a_get_current_max(charger, 
<token> &val->intval); <answer> regmap, 
case <token> <answer> POWER_SUPPLY_PROP_MODEL_NAME: 
val->strval = <token> <answer> act8945a_charger_model; 
case <token> <answer> POWER_SUPPLY_PROP_MANUFACTURER: 
val->strval <token> act8945a_charger_manufacturer; <answer> = 
return <token> <answer> -EINVAL; 
<token> ret; <answer> return 
<token> int act8945a_enable_interrupt(struct act8945a_charger *charger) <answer> static 
struct <token> *regmap = charger->regmap; <answer> regmap 
unsigned char <token> <answer> ctrl; 
<token> ret; <answer> int 
<token> = APCH_CTRL_CHGEOCOUT | APCH_CTRL_CHGEOCIN | <answer> ctrl 
APCH_CTRL_INDIS <token> APCH_CTRL_INCON | <answer> | 
<token> | APCH_CTRL_TEMPIN | <answer> APCH_CTRL_TEMPOUT 
APCH_CTRL_TIMRPRE <token> APCH_CTRL_TIMRTOT; <answer> | 
ret <token> regmap_write(regmap, ACT8945A_APCH_CTRL, ctrl); <answer> = 
if <token> <answer> (ret) 
return <token> <answer> ret; 
ctrl = APCH_STATUS_CHGSTAT | APCH_STATUS_INSTAT <token> <answer> | 
APCH_STATUS_TEMPSTAT <token> APCH_STATUS_TIMRSTAT; <answer> | 
ret = <token> ACT8945A_APCH_STATUS, ctrl); <answer> regmap_write(regmap, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> 0; <answer> return 
<token> unsigned int act8945a_set_supply_type(struct act8945a_charger *charger, <answer> static 
<token> int *type) <answer> unsigned 
unsigned <token> status, state; <answer> int 
<token> ret; <answer> int 
ret = regmap_read(charger->regmap, <token> &status); <answer> ACT8945A_APCH_STATUS, 
<token> (ret < 0) <answer> if 
<token> ret; <answer> return 
ret = regmap_read(charger->regmap, ACT8945A_APCH_STATE, <token> <answer> &state); 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
<token> (status & APCH_STATUS_INDAT) { <answer> if 
if (state & <token> <answer> APCH_STATE_ACINSTAT) 
*type = <token> <answer> POWER_SUPPLY_TYPE_MAINS; 
*type <token> POWER_SUPPLY_TYPE_USB; <answer> = 
<token> else { <answer> } 
<token> = POWER_SUPPLY_TYPE_BATTERY; <answer> *type 
<token> 0; <answer> return 
static void <token> work_struct *work) <answer> act8945a_work(struct 
struct act8945a_charger <token> = <answer> *charger 
container_of(work, <token> act8945a_charger, work); <answer> struct 
act8945a_set_supply_type(charger, <token> <answer> &charger->desc.type); 
static irqreturn_t act8945a_status_changed(int <token> void *dev_id) <answer> irq, 
struct act8945a_charger *charger = <token> <answer> dev_id; 
<token> (charger->init_done) <answer> if 
return <token> <answer> IRQ_HANDLED; 
#define DEFAULT_TOTAL_TIME_OUT <token> <answer> 3 
<token> DEFAULT_PRE_TIME_OUT 40 <answer> #define 
#define <token> 6600 <answer> DEFAULT_INPUT_OVP_THRESHOLD 
<token> int act8945a_charger_config(struct device *dev, <answer> static 
struct <token> *charger) <answer> act8945a_charger 
<token> device_node *np = dev->of_node; <answer> struct 
struct regmap *regmap = <token> <answer> charger->regmap; 
u32 <token> <answer> total_time_out; 
<token> pre_time_out; <answer> u32 
<token> input_voltage_threshold; <answer> u32 
<token> err, ret; <answer> int 
unsigned <token> tmp; <answer> int 
<token> int value = 0; <answer> unsigned 
if <token> { <answer> (!np) 
dev_err(dev, "no charger <token> node\n"); <answer> of 
return <token> <answer> -EINVAL; 
ret <token> regmap_read(regmap, ACT8945A_APCH_CFG, &tmp); <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if <token> & APCH_CFG_SUSCHG) { <answer> (tmp 
value |= <token> <answer> APCH_CFG_SUSCHG; 
<token> "have been suspended\n"); <answer> dev_info(dev, 
charger->lbo_gpio = <token> "active-semi,lbo", <answer> devm_gpiod_get_optional(dev, 
if (IS_ERR(charger->lbo_gpio)) <token> <answer> { 
<token> = PTR_ERR(charger->lbo_gpio); <answer> err 
dev_err(dev, "unable <token> claim gpio \"lbo\": %d\n", err); <answer> to 
return <token> <answer> err; 
ret = devm_request_irq(dev, <token> <answer> gpiod_to_irq(charger->lbo_gpio), 
<token> | IRQF_TRIGGER_RISING), <answer> (IRQF_TRIGGER_FALLING 
"act8945a_lbo_detect", <token> <answer> charger); 
if <token> <answer> (ret) 
dev_info(dev, "failed to request gpio <token> IRQ\n"); <answer> \"lbo\" 
charger->chglev_gpio = <token> <answer> devm_gpiod_get_optional(dev, 
<token> (IS_ERR(charger->chglev_gpio)) { <answer> if 
err = <token> <answer> PTR_ERR(charger->chglev_gpio); 
dev_err(dev, "unable to claim gpio \"chglev\": %d\n", <token> <answer> err); 
return <token> <answer> err; 
if <token> <answer> (of_property_read_u32(np, 
input_voltage_threshold <token> DEFAULT_INPUT_OVP_THRESHOLD; <answer> = 
if <token> <answer> (of_property_read_u32(np, 
pre_time_out <token> DEFAULT_PRE_TIME_OUT; <answer> = 
<token> (of_property_read_u32(np, "active-semi,total-timeout", <answer> if 
total_time_out <token> DEFAULT_TOTAL_TIME_OUT; <answer> = 
<token> (input_voltage_threshold) { <answer> switch 
case <token> <answer> 8000: 
value <token> APCH_CFG_OVPSET_8V; <answer> |= 
<token> 7500: <answer> case 
<token> |= APCH_CFG_OVPSET_7V5; <answer> value 
case <token> <answer> 7000: 
value |= <token> <answer> APCH_CFG_OVPSET_7V; 
case <token> <answer> 6600: 
<token> |= APCH_CFG_OVPSET_6V6; <answer> value 
switch <token> { <answer> (pre_time_out) 
case <token> <answer> 60: 
value |= <token> <answer> APCH_CFG_PRETIMO_60_MIN; 
case <token> <answer> 80: 
<token> |= APCH_CFG_PRETIMO_80_MIN; <answer> value 
case <token> <answer> 0: 
value <token> APCH_CFG_PRETIMO_DISABLED; <answer> |= 
case <token> <answer> 40: 
value |= <token> <answer> APCH_CFG_PRETIMO_40_MIN; 
<token> (total_time_out) { <answer> switch 
<token> 4: <answer> case 
value |= <token> <answer> APCH_CFG_TOTTIMO_4_HOUR; 
case <token> <answer> 5: 
<token> |= APCH_CFG_TOTTIMO_5_HOUR; <answer> value 
<token> 0: <answer> case 
value <token> APCH_CFG_TOTTIMO_DISABLED; <answer> |= 
<token> 3: <answer> case 
<token> |= APCH_CFG_TOTTIMO_3_HOUR; <answer> value 
return regmap_write(regmap, ACT8945A_APCH_CFG, <token> <answer> value); 
<token> int act8945a_charger_probe(struct platform_device *pdev) <answer> static 
<token> act8945a_charger *charger; <answer> struct 
struct power_supply_config <token> = {}; <answer> psy_cfg 
int irq, <token> <answer> ret; 
charger = <token> sizeof(*charger), GFP_KERNEL); <answer> devm_kzalloc(&pdev->dev, 
<token> (!charger) <answer> if 
return <token> <answer> -ENOMEM; 
charger->regmap = dev_get_regmap(pdev->dev.parent, <token> <answer> NULL); 
if <token> { <answer> (!charger->regmap) 
dev_err(&pdev->dev, "Parent did not <token> regmap\n"); <answer> provide 
<token> -EINVAL; <answer> return 
ret <token> act8945a_charger_config(&pdev->dev, charger); <answer> = 
<token> (ret) <answer> if 
return <token> <answer> ret; 
irq = <token> 0); <answer> of_irq_get(pdev->dev.of_node, 
if (irq <token> 0) { <answer> <= 
dev_err(&pdev->dev, "failed to <token> IRQ number\n"); <answer> find 
<token> irq ?: -ENXIO; <answer> return 
ret = devm_request_irq(&pdev->dev, irq, <token> <answer> act8945a_status_changed, 
<token> "act8945a_interrupt", <answer> IRQF_TRIGGER_FALLING, 
if <token> { <answer> (ret) 
dev_err(&pdev->dev, "failed to request nIRQ <token> IRQ\n"); <answer> pin 
return <token> <answer> ret; 
charger->desc.name <token> "act8945a-charger"; <answer> = 
<token> = act8945a_charger_get_property; <answer> charger->desc.get_property 
charger->desc.properties <token> act8945a_charger_props; <answer> = 
charger->desc.num_properties <token> ARRAY_SIZE(act8945a_charger_props); <answer> = 
ret <token> act8945a_set_supply_type(charger, &charger->desc.type); <answer> = 
<token> (ret) <answer> if 
return <token> <answer> -EINVAL; 
psy_cfg.of_node <token> pdev->dev.of_node; <answer> = 
psy_cfg.drv_data = <token> <answer> charger; 
charger->psy <token> devm_power_supply_register(&pdev->dev, <answer> = 
<token> (IS_ERR(charger->psy)) { <answer> if 
dev_err(&pdev->dev, "failed to register power <token> <answer> supply\n"); 
<token> PTR_ERR(charger->psy); <answer> return 
<token> charger); <answer> platform_set_drvdata(pdev, 
INIT_WORK(&charger->work, <token> <answer> act8945a_work); 
ret <token> act8945a_enable_interrupt(charger); <answer> = 
if <token> <answer> (ret) 
return <token> <answer> -EIO; 
<token> = true; <answer> charger->init_done 
return <token> <answer> 0; 
static void act8945a_charger_remove(struct platform_device <token> <answer> *pdev) 
struct act8945a_charger *charger <token> platform_get_drvdata(pdev); <answer> = 
<token> = false; <answer> charger->init_done 
static struct <token> act8945a_charger_driver = { <answer> platform_driver 
<token> = { <answer> .driver 
.name = <token> <answer> "act8945a-charger", 
<token> = act8945a_charger_probe, <answer> .probe 
.remove_new = <token> <answer> act8945a_charger_remove, 
MODULE_DESCRIPTION("Active-semi ACT8945A ActivePath charger <token> <answer> driver"); 
MODULE_AUTHOR("Wenyou <token> <wenyou.yang@atmel.com>"); <answer> Yang 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/string.h> <answer> #include 
<token> <linux/ratelimit.h> <answer> #include 
#include <token> <answer> <linux/mmu_context.h> 
#include <token> <answer> <asm/desc_defs.h> 
<token> <asm/desc.h> <answer> #include 
<token> <asm/inat.h> <answer> #include 
#include <token> <answer> <asm/insn.h> 
<token> <asm/insn-eval.h> <answer> #include 
<token> <asm/ldt.h> <answer> #include 
<token> <asm/vm86.h> <answer> #include 
#undef <token> <answer> pr_fmt 
<token> pr_fmt(fmt) "insn: " fmt <answer> #define 
enum reg_type <token> <answer> { 
REG_TYPE_RM = <token> <answer> 0, 
static bool is_string_insn(struct insn <token> <answer> *insn) 
bool insn_has_rep_prefix(struct insn <token> <answer> *insn) 
insn_byte_t <token> <answer> p; 
int <token> <answer> i; 
for_each_insn_prefix(insn, i, <token> { <answer> p) 
<token> (p == 0xf2 || p == 0xf3) <answer> if 
return <token> <answer> true; 
return <token> <answer> false; 
static int <token> insn *insn) <answer> get_seg_reg_override_idx(struct 
int <token> = INAT_SEG_REG_DEFAULT; <answer> idx 
int num_overrides = 0, <token> <answer> i; 
<token> p; <answer> insn_byte_t 
static <token> check_seg_overrides(struct insn *insn, int regoff) <answer> bool 
if (regoff == offsetof(struct pt_regs, di) <token> is_string_insn(insn)) <answer> && 
<token> false; <answer> return 
<token> true; <answer> return 
static int resolve_default_seg(struct insn *insn, struct pt_regs *regs, <token> off) <answer> int 
<token> (any_64bit_mode(regs)) <answer> if 
return <token> <answer> INAT_SEG_REG_IGNORE; 
<token> (off) { <answer> switch 
<token> offsetof(struct pt_regs, ax): <answer> case 
case <token> pt_regs, cx): <answer> offsetof(struct 
case <token> pt_regs, dx): <answer> offsetof(struct 
static int resolve_seg_reg(struct <token> *insn, struct pt_regs *regs, int regoff) <answer> insn 
<token> idx; <answer> int 
if (regoff == <token> pt_regs, ip)) { <answer> offsetof(struct 
<token> (any_64bit_mode(regs)) <answer> if 
<token> INAT_SEG_REG_IGNORE; <answer> return 
return <token> <answer> INAT_SEG_REG_CS; 
if <token> <answer> (!insn) 
<token> -EINVAL; <answer> return 
if (!check_seg_overrides(insn, <token> <answer> regoff)) 
return resolve_default_seg(insn, regs, <token> <answer> regoff); 
<token> = get_seg_reg_override_idx(insn); <answer> idx 
<token> (idx < 0) <answer> if 
return <token> <answer> idx; 
if (idx <token> INAT_SEG_REG_DEFAULT) <answer> == 
return resolve_default_seg(insn, regs, <token> <answer> regoff); 
<token> (any_64bit_mode(regs)) { <answer> if 
if <token> != INAT_SEG_REG_FS && <answer> (idx 
<token> != INAT_SEG_REG_GS) <answer> idx 
<token> = INAT_SEG_REG_IGNORE; <answer> idx 
return <token> <answer> idx; 
static short <token> pt_regs *regs, int seg_reg_idx) <answer> get_segment_selector(struct 
<token> short sel; <answer> unsigned 
<token> CONFIG_X86_64 <answer> #ifdef 
<token> (seg_reg_idx) { <answer> switch 
<token> INAT_SEG_REG_IGNORE: <answer> case 
<token> 0; <answer> return 
case <token> <answer> INAT_SEG_REG_CS: 
return (unsigned short)(regs->cs <token> 0xffff); <answer> & 
<token> INAT_SEG_REG_SS: <answer> case 
return (unsigned short)(regs->ss & <token> <answer> 0xffff); 
case <token> <answer> INAT_SEG_REG_DS: 
savesegment(ds, <token> <answer> sel); 
return <token> <answer> sel; 
<token> INAT_SEG_REG_ES: <answer> case 
<token> sel); <answer> savesegment(es, 
<token> sel; <answer> return 
case <token> <answer> INAT_SEG_REG_FS: 
<token> sel); <answer> savesegment(fs, 
<token> sel; <answer> return 
case <token> <answer> INAT_SEG_REG_GS: 
savesegment(gs, <token> <answer> sel); 
return <token> <answer> sel; 
<token> -EINVAL; <answer> return 
<token> (IS_ENABLED(CONFIG_X86_64) && !insn->x86_64) <answer> if 
nr_registers -= <token> <answer> 8; 
switch <token> { <answer> (type) 
<token> REG_TYPE_RM: <answer> case 
regno <token> X86_MODRM_RM(insn->modrm.value); <answer> = 
if (!X86_MODRM_MOD(insn->modrm.value) <token> regno == 5) <answer> && 
<token> -EDOM; <answer> return 
if <token> <answer> (X86_REX_B(insn->rex_prefix.value)) 
regno += <token> <answer> 8; 
case <token> <answer> REG_TYPE_REG: 
regno <token> X86_MODRM_REG(insn->modrm.value); <answer> = 
<token> (X86_REX_R(insn->rex_prefix.value)) <answer> if 
regno <token> 8; <answer> += 
case <token> <answer> REG_TYPE_INDEX: 
regno = <token> <answer> X86_SIB_INDEX(insn->sib.value); 
if <token> <answer> (X86_REX_X(insn->rex_prefix.value)) 
regno += <token> <answer> 8; 
if (X86_MODRM_MOD(insn->modrm.value) != 3 && regno <token> 4) <answer> == 
return <token> <answer> -EDOM; 
<token> REG_TYPE_BASE: <answer> case 
<token> = X86_SIB_BASE(insn->sib.value); <answer> regno 
if (!X86_MODRM_MOD(insn->modrm.value) && <token> == 5) <answer> regno 
<token> -EDOM; <answer> return 
<token> (X86_REX_B(insn->rex_prefix.value)) <answer> if 
regno <token> 8; <answer> += 
pr_err_ratelimited("invalid <token> type: %d\n", type); <answer> register 
<token> -EINVAL; <answer> return 
if (regno >= <token> { <answer> nr_registers) 
<token> "decoded an instruction with an invalid register"); <answer> WARN_ONCE(1, 
<token> -EINVAL; <answer> return 
return <token> <answer> regno; 
static int <token> insn *insn, struct pt_regs *regs, <answer> get_reg_offset(struct 
enum reg_type <token> <answer> type) 
int regno = get_regno(insn, <token> <answer> type); 
if (regno <token> 0) <answer> < 
return <token> <answer> regno; 
<token> pt_regs_offset(regs, regno); <answer> return 
static int get_reg_offset_16(struct insn *insn, struct <token> *regs, <answer> pt_regs 
int *offs1, <token> *offs2) <answer> int 
static const int <token> = { <answer> regoff1[] 
<token> pt_regs, bx), <answer> offsetof(struct 
<token> pt_regs, bx), <answer> offsetof(struct 
offsetof(struct <token> bp), <answer> pt_regs, 
offsetof(struct <token> bp), <answer> pt_regs, 
<token> pt_regs, si), <answer> offsetof(struct 
offsetof(struct pt_regs, <token> <answer> di), 
offsetof(struct <token> bp), <answer> pt_regs, 
offsetof(struct <token> bx), <answer> pt_regs, 
<token> const int regoff2[] = { <answer> static 
offsetof(struct <token> si), <answer> pt_regs, 
offsetof(struct <token> di), <answer> pt_regs, 
offsetof(struct pt_regs, <token> <answer> si), 
offsetof(struct pt_regs, <token> <answer> di), 
<token> (!offs1 || !offs2) <answer> if 
<token> -EINVAL; <answer> return 
if ((X86_MODRM_MOD(insn->modrm.value) == <token> && <answer> 0) 
(X86_MODRM_RM(insn->modrm.value) <token> 6)) <answer> == 
*offs1 = <token> <answer> -EDOM; 
return <token> <answer> 0; 
<token> bool get_desc(struct desc_struct *out, unsigned short sel) <answer> static 
struct desc_ptr gdt_desc = <token> 0}; <answer> {0, 
unsigned long <token> <answer> desc_base; 
#ifdef <token> <answer> CONFIG_MODIFY_LDT_SYSCALL 
<token> ((sel & SEGMENT_TI_MASK) == SEGMENT_LDT) { <answer> if 
bool success = <token> <answer> false; 
<token> ldt_struct *ldt; <answer> struct 
desc_base = sel <token> ~(SEGMENT_RPL_MASK | SEGMENT_TI_MASK); <answer> & 
if <token> > gdt_desc.size) <answer> (desc_base 
return <token> <answer> false; 
*out = *(struct desc_struct *)(gdt_desc.address <token> desc_base); <answer> + 
<token> true; <answer> return 
unsigned long insn_get_seg_base(struct pt_regs <token> int seg_reg_idx) <answer> *regs, 
struct desc_struct <token> <answer> desc; 
<token> sel; <answer> short 
sel <token> get_segment_selector(regs, seg_reg_idx); <answer> = 
if (sel <token> 0) <answer> < 
<token> -1L; <answer> return 
if <token> <answer> (v8086_mode(regs)) 
return (unsigned long)(sel <token> 4); <answer> << 
if <token> { <answer> (any_64bit_mode(regs)) 
<token> long base; <answer> unsigned 
if (seg_reg_idx == INAT_SEG_REG_FS) <token> <answer> { 
rdmsrl(MSR_FS_BASE, <token> <answer> base); 
<token> else if (seg_reg_idx == INAT_SEG_REG_GS) { <answer> } 
if <token> <answer> (user_mode(regs)) 
<token> base); <answer> rdmsrl(MSR_KERNEL_GS_BASE, 
<token> base); <answer> rdmsrl(MSR_GS_BASE, 
<token> else { <answer> } 
base = <token> <answer> 0; 
<token> base; <answer> return 
static unsigned long get_seg_limit(struct pt_regs <token> int seg_reg_idx) <answer> *regs, 
struct desc_struct <token> <answer> desc; 
<token> long limit; <answer> unsigned 
short <token> <answer> sel; 
sel = <token> seg_reg_idx); <answer> get_segment_selector(regs, 
if (sel < <token> <answer> 0) 
<token> 0; <answer> return 
if (any_64bit_mode(regs) <token> v8086_mode(regs)) <answer> || 
return <token> <answer> -1L; 
<token> (!sel) <answer> if 
return <token> <answer> 0; 
if (!get_desc(&desc, <token> <answer> sel)) 
return <token> <answer> 0; 
limit = <token> <answer> get_desc_limit(&desc); 
<token> (desc.g) <answer> if 
limit = <token> << 12) + 0xfff; <answer> (limit 
<token> limit; <answer> return 
<token> insn_get_code_seg_params(struct pt_regs *regs) <answer> int 
<token> desc_struct desc; <answer> struct 
<token> sel; <answer> short 
if <token> <answer> (v8086_mode(regs)) 
if (!(desc.type <token> BIT(3))) <answer> & 
return <token> <answer> -EINVAL; 
switch ((desc.l << 1) | <token> { <answer> desc.d) 
<token> INSN_CODE_SEG_PARAMS(2, 2); <answer> return 
return <token> 4); <answer> INSN_CODE_SEG_PARAMS(4, 
return INSN_CODE_SEG_PARAMS(4, <token> <answer> 8); 
<token> insn_get_modrm_rm_off(struct insn *insn, struct pt_regs *regs) <answer> int 
<token> get_reg_offset(insn, regs, REG_TYPE_RM); <answer> return 
int insn_get_modrm_reg_off(struct <token> *insn, struct pt_regs *regs) <answer> insn 
return get_reg_offset(insn, <token> REG_TYPE_REG); <answer> regs, 
unsigned long *insn_get_modrm_reg_ptr(struct insn *insn, <token> pt_regs *regs) <answer> struct 
<token> offset; <answer> int 
offset = <token> regs); <answer> insn_get_modrm_reg_off(insn, 
if (offset < <token> <answer> 0) 
return <token> <answer> NULL; 
<token> (void *)regs + offset; <answer> return 
<token> int get_seg_base_limit(struct insn *insn, struct pt_regs *regs, <answer> static 
int regoff, <token> long *base, <answer> unsigned 
unsigned <token> *limit) <answer> long 
<token> seg_reg_idx; <answer> int 
<token> (!base) <answer> if 
return <token> <answer> -EINVAL; 
seg_reg_idx = resolve_seg_reg(insn, <token> regoff); <answer> regs, 
if (seg_reg_idx <token> 0) <answer> < 
return <token> <answer> seg_reg_idx; 
*base = insn_get_seg_base(regs, <token> <answer> seg_reg_idx); 
if (*base == <token> <answer> -1L) 
return <token> <answer> -EINVAL; 
if <token> <answer> (!limit) 
return <token> <answer> 0; 
*limit = <token> seg_reg_idx); <answer> get_seg_limit(regs, 
if <token> <answer> (!(*limit)) 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
static int get_eff_addr_reg(struct insn <token> struct pt_regs *regs, <answer> *insn, 
int *regoff, long <token> <answer> *eff_addr) 
<token> ret; <answer> int 
ret <token> insn_get_modrm(insn); <answer> = 
if <token> <answer> (ret) 
return <token> <answer> ret; 
if <token> != 3) <answer> (X86_MODRM_MOD(insn->modrm.value) 
<token> -EINVAL; <answer> return 
*regoff = <token> regs, REG_TYPE_RM); <answer> get_reg_offset(insn, 
if <token> < 0) <answer> (*regoff 
<token> -EINVAL; <answer> return 
static int get_eff_addr_modrm(struct insn *insn, <token> pt_regs *regs, <answer> struct 
<token> *regoff, long *eff_addr) <answer> int 
long <token> <answer> tmp; 
int <token> <answer> ret; 
if (insn->addr_bytes != 8 <token> insn->addr_bytes != 4) <answer> && 
<token> -EINVAL; <answer> return 
<token> = insn_get_modrm(insn); <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ret; 
if (X86_MODRM_MOD(insn->modrm.value) <token> 2) <answer> > 
return <token> <answer> -EINVAL; 
*regoff = get_reg_offset(insn, regs, <token> <answer> REG_TYPE_RM); 
if <token> == -EDOM) { <answer> (*regoff 
if <token> <answer> (any_64bit_mode(regs)) 
tmp = regs->ip + <token> <answer> insn->length; 
<token> = 0; <answer> tmp 
<token> else if (*regoff < 0) { <answer> } 
<token> -EINVAL; <answer> return 
<token> else { <answer> } 
<token> = regs_get_register(regs, *regoff); <answer> tmp 
if (insn->addr_bytes == <token> { <answer> 4) 
int <token> = (int)(tmp & 0xffffffff) + insn->displacement.value; <answer> addr32 
<token> = addr32 & 0xffffffff; <answer> *eff_addr 
} <token> { <answer> else 
*eff_addr <token> tmp + insn->displacement.value; <answer> = 
<token> 0; <answer> return 
static int get_eff_addr_modrm_16(struct insn *insn, struct <token> *regs, <answer> pt_regs 
int <token> short *eff_addr) <answer> *regoff, 
<token> addr_offset1, addr_offset2, ret; <answer> int 
short addr1 = 0, addr2 = 0, <token> <answer> displacement; 
if (insn->addr_bytes <token> 2) <answer> != 
<token> -EINVAL; <answer> return 
if <token> <answer> (!insn->modrm.nbytes) 
<token> -EINVAL; <answer> return 
if (X86_MODRM_MOD(insn->modrm.value) > <token> <answer> 2) 
return <token> <answer> -EINVAL; 
ret = get_reg_offset_16(insn, regs, &addr_offset1, <token> <answer> &addr_offset2); 
<token> (ret < 0) <answer> if 
<token> -EINVAL; <answer> return 
if (addr_offset1 <token> -EDOM) <answer> != 
addr1 = regs_get_register(regs, addr_offset1) <token> 0xffff; <answer> & 
if (addr_offset2 != <token> <answer> -EDOM) 
addr2 = regs_get_register(regs, addr_offset2) & <token> <answer> 0xffff; 
displacement = insn->displacement.value <token> 0xffff; <answer> & 
*eff_addr = addr1 + addr2 <token> displacement; <answer> + 
*regoff = <token> <answer> addr_offset1; 
return <token> <answer> 0; 
static int <token> insn *insn, struct pt_regs *regs, <answer> get_eff_addr_sib(struct 
int *base_offset, <token> *eff_addr) <answer> long 
<token> base, indx; <answer> long 
int <token> <answer> indx_offset; 
int <token> <answer> ret; 
if (insn->addr_bytes != 8 && insn->addr_bytes != <token> <answer> 4) 
return <token> <answer> -EINVAL; 
ret = <token> <answer> insn_get_modrm(insn); 
if <token> <answer> (ret) 
<token> ret; <answer> return 
if <token> <answer> (!insn->modrm.nbytes) 
<token> -EINVAL; <answer> return 
if (X86_MODRM_MOD(insn->modrm.value) > <token> <answer> 2) 
<token> -EINVAL; <answer> return 
<token> = insn_get_sib(insn); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if <token> <answer> (!insn->sib.nbytes) 
return <token> <answer> -EINVAL; 
<token> = get_reg_offset(insn, regs, REG_TYPE_BASE); <answer> *base_offset 
indx_offset = get_reg_offset(insn, regs, <token> <answer> REG_TYPE_INDEX); 
if <token> == -EDOM) <answer> (*base_offset 
base <token> 0; <answer> = 
else <token> (*base_offset < 0) <answer> if 
<token> -EINVAL; <answer> return 
base = regs_get_register(regs, <token> <answer> *base_offset); 
if <token> == -EDOM) <answer> (indx_offset 
<token> = 0; <answer> indx 
else if (indx_offset < <token> <answer> 0) 
return <token> <answer> -EINVAL; 
indx = <token> indx_offset); <answer> regs_get_register(regs, 
if (insn->addr_bytes == 4) <token> <answer> { 
<token> addr32, base32, idx32; <answer> int 
base32 = base & <token> <answer> 0xffffffff; 
idx32 <token> indx & 0xffffffff; <answer> = 
addr32 = <token> + idx32 * (1 << X86_SIB_SCALE(insn->sib.value)); <answer> base32 
addr32 += <token> <answer> insn->displacement.value; 
<token> = addr32 & 0xffffffff; <answer> *eff_addr 
} <token> { <answer> else 
<token> = base + indx * (1 << X86_SIB_SCALE(insn->sib.value)); <answer> *eff_addr 
*eff_addr <token> insn->displacement.value; <answer> += 
<token> 0; <answer> return 
static void __user <token> insn *insn, struct pt_regs *regs) <answer> *get_addr_ref_16(struct 
unsigned long linear_addr = -1L, seg_base, <token> <answer> seg_limit; 
int ret, <token> <answer> regoff; 
short <token> <answer> eff_addr; 
long <token> <answer> tmp; 
if <token> <answer> (insn_get_displacement(insn)) 
<token> out; <answer> goto 
if (insn->addr_bytes <token> 2) <answer> != 
<token> out; <answer> goto 
if (X86_MODRM_MOD(insn->modrm.value) == 3) <token> <answer> { 
ret = get_eff_addr_reg(insn, <token> &regoff, &tmp); <answer> regs, 
<token> (ret) <answer> if 
<token> out; <answer> goto 
<token> = tmp; <answer> eff_addr 
<token> else { <answer> } 
ret = get_eff_addr_modrm_16(insn, regs, <token> &eff_addr); <answer> &regoff, 
<token> (ret) <answer> if 
<token> out; <answer> goto 
ret = <token> regs, regoff, &seg_base, &seg_limit); <answer> get_seg_base_limit(insn, 
<token> (ret) <answer> if 
goto <token> <answer> out; 
<token> ((unsigned long)(eff_addr & 0xffff) > seg_limit) <answer> if 
goto <token> <answer> out; 
linear_addr = (unsigned long)(eff_addr & 0xffff) <token> seg_base; <answer> + 
static void <token> *get_addr_ref_32(struct insn *insn, struct pt_regs *regs) <answer> __user 
<token> long linear_addr = -1L, seg_base, seg_limit; <answer> unsigned 
<token> eff_addr, regoff; <answer> int 
long <token> <answer> tmp; 
int <token> <answer> ret; 
if <token> != 4) <answer> (insn->addr_bytes 
<token> out; <answer> goto 
if <token> == 3) { <answer> (X86_MODRM_MOD(insn->modrm.value) 
ret = <token> regs, &regoff, &tmp); <answer> get_eff_addr_reg(insn, 
<token> (ret) <answer> if 
goto <token> <answer> out; 
eff_addr <token> tmp; <answer> = 
<token> else { <answer> } 
<token> (insn->sib.nbytes) { <answer> if 
ret = get_eff_addr_sib(insn, regs, &regoff, <token> <answer> &tmp); 
if <token> <answer> (ret) 
goto <token> <answer> out; 
<token> = tmp; <answer> eff_addr 
} else <token> <answer> { 
<token> = get_eff_addr_modrm(insn, regs, &regoff, &tmp); <answer> ret 
if <token> <answer> (ret) 
goto <token> <answer> out; 
<token> = tmp; <answer> eff_addr 
ret <token> get_seg_base_limit(insn, regs, regoff, &seg_base, &seg_limit); <answer> = 
<token> (ret) <answer> if 
<token> out; <answer> goto 
if (!any_64bit_mode(regs) && ((unsigned <token> > seg_limit)) <answer> int)eff_addr 
goto <token> <answer> out; 
if (v8086_mode(regs) <token> (eff_addr & ~0xffff)) <answer> && 
<token> out; <answer> goto 
linear_addr = (unsigned long)(eff_addr & 0xffffffff) <token> seg_base; <answer> + 
<token> CONFIG_X86_64 <answer> #ifndef 
<token> void __user *get_addr_ref_64(struct insn *insn, struct pt_regs *regs) <answer> static 
return (void __user <token> <answer> *)-1L; 
static void __user *get_addr_ref_64(struct insn *insn, <token> pt_regs *regs) <answer> struct 
unsigned <token> linear_addr = -1L, seg_base; <answer> long 
<token> regoff, ret; <answer> int 
<token> eff_addr; <answer> long 
<token> (insn->addr_bytes != 8) <answer> if 
<token> out; <answer> goto 
if (X86_MODRM_MOD(insn->modrm.value) <token> 3) { <answer> == 
ret = get_eff_addr_reg(insn, regs, <token> &eff_addr); <answer> &regoff, 
if <token> <answer> (ret) 
<token> out; <answer> goto 
} <token> { <answer> else 
if (insn->sib.nbytes) <token> <answer> { 
<token> = get_eff_addr_sib(insn, regs, &regoff, &eff_addr); <answer> ret 
<token> (ret) <answer> if 
<token> out; <answer> goto 
} else <token> <answer> { 
ret = <token> regs, &regoff, &eff_addr); <answer> get_eff_addr_modrm(insn, 
if <token> <answer> (ret) 
<token> out; <answer> goto 
ret = get_seg_base_limit(insn, regs, regoff, &seg_base, <token> <answer> NULL); 
if <token> <answer> (ret) 
<token> out; <answer> goto 
linear_addr = (unsigned long)eff_addr <token> seg_base; <answer> + 
return (void __user <token> <answer> *)linear_addr; 
void __user *insn_get_addr_ref(struct insn <token> struct pt_regs *regs) <answer> *insn, 
<token> (!insn || !regs) <answer> if 
return (void <token> *)-1L; <answer> __user 
<token> (insn_get_opcode(insn)) <answer> if 
<token> (void __user *)-1L; <answer> return 
switch <token> { <answer> (insn->addr_bytes) 
<token> 2: <answer> case 
return <token> regs); <answer> get_addr_ref_16(insn, 
<token> 4: <answer> case 
return <token> regs); <answer> get_addr_ref_32(insn, 
<token> 8: <answer> case 
<token> get_addr_ref_64(insn, regs); <answer> return 
<token> (void __user *)-1L; <answer> return 
int insn_get_effective_ip(struct pt_regs *regs, <token> long *ip) <answer> unsigned 
unsigned long <token> = 0; <answer> seg_base 
<token> (!user_64bit_mode(regs)) { <answer> if 
<token> = insn_get_seg_base(regs, INAT_SEG_REG_CS); <answer> seg_base 
<token> (seg_base == -1L) <answer> if 
<token> -EINVAL; <answer> return 
*ip <token> seg_base + regs->ip; <answer> = 
<token> 0; <answer> return 
int insn_fetch_from_user(struct pt_regs *regs, unsigned char <token> <answer> buf[MAX_INSN_SIZE]) 
<token> long ip; <answer> unsigned 
<token> not_copied; <answer> int 
<token> (insn_get_effective_ip(regs, &ip)) <answer> if 
<token> -EINVAL; <answer> return 
not_copied <token> copy_from_user(buf, (void __user *)ip, MAX_INSN_SIZE); <answer> = 
return MAX_INSN_SIZE - <token> <answer> not_copied; 
int insn_fetch_from_user_inatomic(struct pt_regs *regs, <token> char buf[MAX_INSN_SIZE]) <answer> unsigned 
unsigned <token> ip; <answer> long 
int <token> <answer> not_copied; 
if <token> &ip)) <answer> (insn_get_effective_ip(regs, 
<token> -EINVAL; <answer> return 
not_copied <token> __copy_from_user_inatomic(buf, (void __user *)ip, MAX_INSN_SIZE); <answer> = 
return MAX_INSN_SIZE <token> not_copied; <answer> - 
bool insn_decode_from_regs(struct insn *insn, struct <token> *regs, <answer> pt_regs 
unsigned <token> buf[MAX_INSN_SIZE], int buf_size) <answer> char 
int <token> <answer> seg_defs; 
insn_init(insn, <token> buf_size, user_64bit_mode(regs)); <answer> buf, 
<token> = insn_get_code_seg_params(regs); <answer> seg_defs 
<token> (seg_defs == -EINVAL) <answer> if 
return <token> <answer> false; 
insn->addr_bytes <token> INSN_CODE_SEG_ADDR_SZ(seg_defs); <answer> = 
<token> = INSN_CODE_SEG_OPND_SZ(seg_defs); <answer> insn->opnd_bytes 
<token> (insn_get_length(insn)) <answer> if 
return <token> <answer> false; 
if (buf_size < <token> <answer> insn->length) 
return <token> <answer> false; 
<token> true; <answer> return 
enum insn_mmio_type insn_decode_mmio(struct <token> *insn, int *bytes) <answer> insn 
enum insn_mmio_type type = <token> <answer> INSN_MMIO_DECODE_FAILED; 
*bytes = <token> <answer> 0; 
if <token> <answer> (insn_get_opcode(insn)) 
return <token> <answer> INSN_MMIO_DECODE_FAILED; 
switch (insn->opcode.bytes[0]) <token> <answer> { 
<token> <linux/pci.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/spi/spi.h> <answer> #include 
#include <token> <answer> <linux/spi/mmc_spi.h> 
<token> <linux/mmc/host.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_address.h> 
#include <token> <answer> <linux/of_irq.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/fsl_devices.h> 
<token> <asm/time.h> <answer> #include 
<token> <asm/ipic.h> <answer> #include 
<token> <asm/udbg.h> <answer> #include 
<token> <soc/fsl/qe/qe.h> <answer> #include 
<token> <sysdev/fsl_soc.h> <answer> #include 
#include <token> <answer> <sysdev/fsl_pci.h> 
<token> "mpc83xx.h" <answer> #include 
#undef <token> <answer> DEBUG 
#ifdef <token> <answer> DEBUG 
<token> DBG(fmt...) udbg_printf(fmt) <answer> #define 
#define <token> <answer> DBG(fmt...) 
<token> CONFIG_QUICC_ENGINE <answer> #ifdef 
static int __init of_fsl_spi_probe(char *type, <token> *compatible, u32 sysclk, <answer> char 
<token> spi_board_info *board_infos, <answer> struct 
unsigned <token> num_board_infos, <answer> int 
void (*cs_control)(struct <token> *dev, <answer> spi_device 
bool <token> <answer> on)) 
<token> device_node *np; <answer> struct 
unsigned int i <token> 0; <answer> = 
<token> type, compatible) { <answer> for_each_compatible_node(np, 
<token> ret; <answer> int 
unsigned <token> j; <answer> int 
<token> void *prop; <answer> const 
<token> resource res[2]; <answer> struct 
struct <token> *pdev; <answer> platform_device 
<token> fsl_spi_platform_data pdata = { <answer> struct 
<token> = cs_control, <answer> .cs_control 
memset(res, <token> sizeof(res)); <answer> 0, 
pdata.sysclk <token> sysclk; <answer> = 
prop = of_get_property(np, <token> NULL); <answer> "reg", 
if <token> <answer> (!prop) 
<token> err; <answer> goto 
pdata.bus_num = <token> *)prop; <answer> *(u32 
<token> = of_get_property(np, "cell-index", NULL); <answer> prop 
if <token> <answer> (prop) 
i <token> *(u32 *)prop; <answer> = 
prop = <token> "mode", NULL); <answer> of_get_property(np, 
<token> (prop && !strcmp(prop, "cpu-qe")) <answer> if 
pdata.flags <token> SPI_QE_CPU_MODE; <answer> = 
for (j = 0; j < num_board_infos; <token> { <answer> j++) 
if (board_infos[j].bus_num <token> pdata.bus_num) <answer> == 
if <token> <answer> (!pdata.max_chipselect) 
ret = of_address_to_resource(np, <token> &res[0]); <answer> 0, 
if <token> <answer> (ret) 
<token> err; <answer> goto 
ret = <token> 0, &res[1]); <answer> of_irq_to_resource(np, 
if (ret <= <token> <answer> 0) 
<token> err; <answer> goto 
pdev <token> platform_device_alloc("mpc83xx_spi", i); <answer> = 
if <token> <answer> (!pdev) 
<token> err; <answer> goto 
ret <token> platform_device_add_data(pdev, &pdata, sizeof(pdata)); <answer> = 
if <token> <answer> (ret) 
<token> unreg; <answer> goto 
ret = platform_device_add_resources(pdev, <token> <answer> res, 
if <token> <answer> (ret) 
goto <token> <answer> unreg; 
ret <token> platform_device_add(pdev); <answer> = 
if <token> <answer> (ret) 
goto <token> <answer> unreg; 
goto <token> <answer> next; 
pr_err("%pOF: <token> failed\n", np); <answer> registration 
<token> i; <answer> return 
static int <token> fsl_spi_init(struct spi_board_info *board_infos, <answer> __init 
unsigned <token> num_board_infos, <answer> int 
void <token> spi_device *spi, <answer> (*cs_control)(struct 
<token> on)) <answer> bool 
u32 <token> = -1; <answer> sysclk 
int <token> <answer> ret; 
<token> = of_find_compatible_node(NULL, NULL, "mmc-spi-slot"); <answer> np 
if <token> <answer> (np) 
return <token> <answer> 0; 
return fsl_spi_init(&mpc832x_spi_boardinfo, <token> mpc83xx_spi_cs_control); <answer> 1, 
<token> mpc832x_spi_init); <answer> machine_device_initcall(mpc832x_rdb, 
static void __init <token> <answer> mpc832x_rdb_setup_arch(void) 
<token> defined(CONFIG_QUICC_ENGINE) <answer> #if 
struct device_node <token> <answer> *np; 
#ifdef <token> <answer> CONFIG_QUICC_ENGINE 
if ((np = of_find_node_by_name(NULL, "par_io")) != <token> { <answer> NULL) 
for_each_node_by_name(np, <token> <answer> "ucc") 
<token> "odm_precomp.h" <answer> #include 
<token> odm_DynamicTxPowerInit(void *pDM_VOID) <answer> void 
struct dm_odm_t *pDM_Odm <token> (struct dm_odm_t *)pDM_VOID; <answer> = 
<token> adapter *Adapter = pDM_Odm->Adapter; <answer> struct 
struct hal_com_data <token> = GET_HAL_DATA(Adapter); <answer> *pHalData 
struct dm_priv *pdmpriv = <token> <answer> &pHalData->dmpriv; 
pdmpriv->bDynamicTxPowerEnable <token> false; <answer> = 
<token> = TxHighPwrLevel_Normal; <answer> pdmpriv->LastDTPLvl 
<token> = TxHighPwrLevel_Normal; <answer> pdmpriv->DynamicTxHighPowerLvl 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/tty.h> <answer> #include 
<token> <linux/errno.h> <answer> #include 
<token> <linux/ioctl.h> <answer> #include 
#include <token> <answer> <linux/skbuff.h> 
#include <token> <answer> <net/bluetooth/bluetooth.h> 
#include <token> <answer> <net/bluetooth/hci_core.h> 
<token> "hci_uart.h" <answer> #include 
<token> ath_struct { <answer> struct 
struct hci_uart <token> <answer> *hu; 
unsigned <token> cur_sleep; <answer> int 
struct <token> *rx_skb; <answer> sk_buff 
<token> sk_buff_head txq; <answer> struct 
struct work_struct <token> <answer> ctxtsw; 
<token> OP_WRITE_TAG 0x01 <answer> #define 
#define <token> 0x01 <answer> INDEX_BDADDR 
<token> ath_vendor_cmd { <answer> struct 
__u8 <token> <answer> opcode; 
__le16 <token> <answer> index; 
__u8 <token> <answer> len; 
__u8 <token> <answer> data[251]; 
} <token> <answer> __packed; 
static int <token> tty_struct *tty) <answer> ath_wakeup_ar3k(struct 
int status = <token> <answer> tty->driver->ops->tiocmget(tty); 
<token> (status & TIOCM_CTS) <answer> if 
return <token> <answer> status; 
if (hci_skb_pkt_type(skb) <token> HCI_COMMAND_PKT) { <answer> == 
struct hci_command_hdr *hdr <token> (void *)skb->data; <answer> = 
if <token> == HCI_OP_ATH_SLEEP) <answer> (__le16_to_cpu(hdr->opcode) 
ath->cur_sleep <token> skb->data[HCI_COMMAND_HDR_SIZE]; <answer> = 
BT_DBG("hu %p skb %p", hu, <token> <answer> skb); 
#include <token> <answer> <linux/dma-mapping.h> 
#include <token> <answer> <linux/pm_runtime.h> 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/property.h> <answer> #include 
<token> <linux/dmapool.h> <answer> #include 
#include <token> <answer> <linux/iopoll.h> 
#include <token> <answer> "cdns2-gadget.h" 
#include <token> <answer> "cdns2-trace.h" 
static void set_reg_bit_32(void __iomem <token> u32 mask) <answer> *ptr, 
mask = <token> | mask; <answer> readl(ptr) 
<token> ptr); <answer> writel(mask, 
static void clear_reg_bit_32(void __iomem *ptr, <token> mask) <answer> u32 
mask = readl(ptr) <token> ~mask; <answer> & 
writel(mask, <token> <answer> ptr); 
static <token> cdns2_ep_stall_flush(struct cdns2_endpoint *pep) <answer> void 
struct cdns2_device *pdev <token> pep->pdev; <answer> = 
<token> val; <answer> int 
trace_cdns2_ep_halt(pep, <token> 1); <answer> 1, 
<token> &pdev->adma_regs->ep_cmd); <answer> writel(DMA_EP_CMD_DFLUSH, 
static <token> cdns2_ep_inc_trb(int *index, u8 *cs, int trb_in_seg) <answer> void 
if (*index == (trb_in_seg - <token> { <answer> 1)) 
*index = <token> <answer> 0; 
<token> ^= 1; <answer> *cs 
static void cdns2_ep_inc_enq(struct cdns2_ring <token> <answer> *ring) 
cdns2_ep_inc_trb(&ring->enqueue, &ring->pcs, <token> <answer> TRBS_PER_SEGMENT); 
<token> void cdns2_ep_inc_deq(struct cdns2_ring *ring) <answer> static 
cdns2_ep_inc_trb(&ring->dequeue, <token> TRBS_PER_SEGMENT); <answer> &ring->ccs, 
<token> void cdns2_enable_l1(struct cdns2_device *pdev, int enable) <answer> static 
if (enable) <token> <answer> { 
<token> USBCS_LPMNYET); <answer> clear_reg_bit_8(&pdev->usb_regs->usbcs, 
<token> &pdev->usb_regs->lpmclock); <answer> writeb(LPMCLOCK_SLEEP_ENTRY, 
} else <token> <answer> { 
set_reg_bit_8(&pdev->usb_regs->usbcs, <token> <answer> USBCS_LPMNYET); 
<token> enum usb_device_speed cdns2_get_speed(struct cdns2_device *pdev) <answer> static 
u8 <token> = readb(&pdev->usb_regs->speedctrl); <answer> speed 
if (speed <token> SPEEDCTRL_HS) <answer> & 
return <token> <answer> USB_SPEED_HIGH; 
else <token> (speed & SPEEDCTRL_FS) <answer> if 
<token> USB_SPEED_FULL; <answer> return 
return <token> <answer> USB_SPEED_UNKNOWN; 
static <token> cdns2_trb *cdns2_next_trb(struct cdns2_endpoint *pep, <answer> struct 
struct cdns2_trb <token> <answer> *trb) 
if <token> == (pep->ring.trbs + (TRBS_PER_SEGMENT - 1))) <answer> (trb 
return <token> <answer> pep->ring.trbs; 
<token> ++trb; <answer> return 
<token> cdns2_gadget_giveback(struct cdns2_endpoint *pep, <answer> void 
struct cdns2_request <token> <answer> *preq, 
int <token> <answer> status) 
<token> usb_request *request = &preq->request; <answer> struct 
<token> cdns2_device *pdev = pep->pdev; <answer> struct 
if <token> == -EINPROGRESS) <answer> (request->status 
<token> = status; <answer> request->status 
<token> request, pep->dir); <answer> usb_gadget_unmap_request_by_dev(pdev->dev, 
if (pep->type == USB_ENDPOINT_XFER_ISOC || <token> > 2) <answer> TRBS_PER_SEGMENT 
<token> = TRB_CHAIN; <answer> ch_bit 
link_trb->control = <token> ? TRB_CYCLE : 0) | <answer> cpu_to_le32(((ring->pcs) 
<token> | TRB_TOGGLE | ch_bit); <answer> TRB_TYPE(TRB_LINK) 
<token> 0; <answer> return 
<token> void cdns2_dbg_request_trbs(struct cdns2_endpoint *pep, <answer> static 
struct <token> *preq) <answer> cdns2_request 
struct cdns2_trb *link_trb = <token> + (TRBS_PER_SEGMENT - 1); <answer> pep->ring.trbs 
struct <token> *trb = preq->trb; <answer> cdns2_trb 
int num_trbs = <token> <answer> preq->num_of_trb; 
int <token> = 0; <answer> i 
while <token> < num_trbs) { <answer> (i 
trace_cdns2_queue_trb(pep, trb + <token> <answer> i); 
if (trb + i == link_trb) <token> <answer> { 
trb = <token> <answer> pep->ring.trbs; 
<token> = num_trbs - i; <answer> num_trbs 
i <token> 0; <answer> = 
<token> else { <answer> } 
<token> unsigned int cdns2_count_trbs(struct cdns2_endpoint *pep, <answer> static 
u64 addr, <token> len) <answer> u64 
unsigned int <token> = 1; <answer> num_trbs 
if <token> == USB_ENDPOINT_XFER_ISOC) { <answer> (pep->type 
<token> = DIV_ROUND_UP(len + <answer> num_trbs 
(addr <token> (TRB_MAX_ISO_BUFF_SIZE - 1)), <answer> & 
if (pep->interval > <token> <answer> 1) 
num_trbs = pep->dir ? num_trbs * pep->interval <token> 1; <answer> : 
} else if (pep->dir) <token> <answer> { 
<token> num_trbs; <answer> return 
static <token> int cdns2_count_sg_trbs(struct cdns2_endpoint *pep, <answer> unsigned 
struct <token> *req) <answer> usb_request 
unsigned int i, len, full_len, <token> = 0; <answer> num_trbs 
struct <token> *sg; <answer> scatterlist 
<token> trb_len = 0; <answer> int 
full_len <token> req->length; <answer> = 
for_each_sg(req->sg, sg, req->num_sgs, i) <token> <answer> { 
len <token> sg_dma_len(sg); <answer> = 
num_trbs <token> cdns2_count_trbs(pep, sg_dma_address(sg), len); <answer> += 
len = min(len, <token> <answer> full_len); 
if (pep->type == <token> { <answer> USB_ENDPOINT_XFER_ISOC) 
<token> temp; <answer> u8 
<token> += len; <answer> trb_len 
temp = <token> >> 10; <answer> trb_len 
if <token> { <answer> (temp) 
if (trb_len <token> 1024) <answer> % 
num_trbs = <token> + temp; <answer> num_trbs 
<token> = num_trbs + temp - 1; <answer> num_trbs 
<token> = trb_len - (temp << 10); <answer> trb_len 
<token> -= len; <answer> full_len 
if (full_len == <token> <answer> 0) 
return <token> <answer> num_trbs; 
static void <token> cdns2_device *pdev) <answer> cdsn2_isoc_burst_opt(struct 
int axi_burst_option[] <token> {1, 2, 4, 8, 16, 32, 64, 128}; <answer> = 
int <token> <answer> best_burst; 
<token> array_size; <answer> int 
int <token> <answer> opt_burst; 
int <token> <answer> trb_size; 
int i, <token> <answer> j; 
<token> = ARRAY_SIZE(axi_burst_option); <answer> array_size 
for (i = <token> i <= MAX_ISO_SIZE; i++) { <answer> 0; 
<token> = i / 4; <answer> trb_size 
best_burst = trb_size <token> trb_size : 1; <answer> ? 
for (j = <token> j < array_size; j++) { <answer> 0; 
opt_burst <token> trb_size / axi_burst_option[j]; <answer> = 
opt_burst <token> trb_size % axi_burst_option[j]; <answer> += 
if (opt_burst <token> best_burst) { <answer> < 
best_burst <token> opt_burst; <answer> = 
pdev->burst_opt[i] <token> axi_burst_option[j]; <answer> = 
<token> void cdns2_ep_tx_isoc(struct cdns2_endpoint *pep, <answer> static 
struct cdns2_request <token> <answer> *preq, 
int <token> <answer> num_trbs) 
<token> scatterlist *sg = NULL; <answer> struct 
<token> remaining_packet_size = 0; <answer> u32 
<token> cdns2_trb *trb; <answer> struct 
bool first_trb = <token> <answer> true; 
dma_addr_t <token> <answer> trb_dma; 
u32 <token> <answer> trb_buff_len; 
<token> block_length; <answer> u32 
<token> td_idx = 0; <answer> int 
<token> split_size; <answer> int 
<token> full_len; <answer> u32 
<token> enqd_len; <answer> int 
int <token> <answer> sent_len; 
<token> sg_iter; <answer> int 
u32 <token> <answer> control; 
<token> num_tds; <answer> int 
u32 <token> <answer> length; 
num_tds = pep->dir <token> pep->interval : 1; <answer> ? 
split_size <token> preq->request.num_sgs ? 1024 : 3072; <answer> = 
for (td_idx = 0; td_idx < num_tds; <token> { <answer> td_idx++) 
if <token> { <answer> (preq->request.num_sgs) 
sg = <token> <answer> preq->request.sg; 
<token> = sg_dma_address(sg); <answer> trb_dma 
block_length <token> sg_dma_len(sg); <answer> = 
} <token> { <answer> else 
trb_dma <token> preq->request.dma; <answer> = 
block_length = <token> <answer> preq->request.length; 
<token> = preq->request.length; <answer> full_len 
sg_iter = preq->request.num_sgs <token> preq->request.num_sgs : 1; <answer> ? 
remaining_packet_size = <token> <answer> split_size; 
for (enqd_len = 0; enqd_len <token> full_len; <answer> < 
<token> += trb_buff_len) { <answer> enqd_len 
<token> (remaining_packet_size == 0) <answer> if 
remaining_packet_size <token> split_size; <answer> = 
<token> = TRB_BUFF_LEN_UP_TO_BOUNDARY(trb_dma); <answer> trb_buff_len 
trb_buff_len <token> min(trb_buff_len, remaining_packet_size); <answer> = 
trb_buff_len = min(trb_buff_len, <token> <answer> block_length); 
<token> (trb_buff_len > full_len - enqd_len) <answer> if 
trb_buff_len <token> full_len - enqd_len; <answer> = 
control = <token> <answer> TRB_TYPE(TRB_NORMAL); 
if <token> + trb_buff_len >= full_len || !pep->dir) <answer> (enqd_len 
control |= TRB_IOC | <token> <answer> TRB_ISP; 
if <token> { <answer> (first_trb) 
first_trb = <token> <answer> false; 
if <token> == 0) <answer> (pep->ring.pcs 
control <token> TRB_CYCLE; <answer> |= 
} else <token> <answer> { 
control <token> pep->ring.pcs; <answer> |= 
if (enqd_len + trb_buff_len < <token> <answer> full_len) 
<token> |= TRB_CHAIN; <answer> control 
<token> = TRB_LEN(trb_buff_len) | <answer> length 
trb = <token> + pep->ring.enqueue; <answer> pep->ring.trbs 
trb->buffer = <token> <answer> cpu_to_le32(TRB_BUFFER(trb_dma)); 
<token> = cpu_to_le32(length); <answer> trb->length 
trb->control <token> cpu_to_le32(control); <answer> = 
<token> += trb_buff_len; <answer> trb_dma 
sent_len = <token> <answer> trb_buff_len; 
if (sg && <token> >= block_length) { <answer> sent_len 
if <token> == 0) <answer> (sg_iter 
control = control <token> TRB_CYCLE; <answer> ^ 
buffer = pep->ring.dma + <token> * TRB_SIZE; <answer> pep->ring.dequeue 
hw_ccs = <token> <answer> !!DMA_EP_STS_CCS(readl(&pdev->adma_regs->ep_sts)); 
trb = <token> <answer> &pep->ring.trbs[TRBS_PER_SEGMENT]; 
trb->length = <token> <answer> 0; 
trb->buffer <token> cpu_to_le32(TRB_BUFFER(buffer)); <answer> = 
trb->control = <token> ? TRB_CYCLE : 0) | TRB_TYPE(TRB_NORMAL)); <answer> cpu_to_le32((hw_ccs 
trb->length = <token> <answer> 0; 
<token> = cpu_to_le32(TRB_BUFFER(buffer)); <answer> trb->buffer 
trb->control = cpu_to_le32((hw_ccs ? TRB_CYCLE : <token> | <answer> 0) 
<token> | TRB_CHAIN); <answer> TRB_TYPE(TRB_LINK) 
if <token> != pep->ring.ccs) <answer> (hw_ccs 
trb->control <token> cpu_to_le32(TRB_TOGGLE); <answer> |= 
<token> DMA_EP_CFG_ENABLE); <answer> set_reg_bit_32(&pdev->adma_regs->ep_cfg, 
writel(pep->ring.dma + (TRBS_PER_SEGMENT * <token> <answer> TRB_SIZE), 
<token> 0; <answer> return 
static bool <token> cdns2_endpoint *pep, <answer> cdns2_trb_handled(struct 
struct cdns2_request <token> <answer> *preq) 
<token> cdns2_device *pdev = pep->pdev; <answer> struct 
<token> cdns2_ring *ring; <answer> struct 
struct cdns2_trb <token> <answer> *trb; 
int current_index = <token> <answer> 0; 
int handled = <token> <answer> 0; 
<token> doorbell; <answer> int 
ring <token> &pep->ring; <answer> = 
current_index = <token> pep); <answer> cdns2_get_dma_pos(pdev, 
doorbell <token> !!(readl(&pdev->adma_regs->ep_cmd) & DMA_EP_CMD_DRDY); <answer> = 
if (current_index >= <token> <answer> TRBS_PER_SEGMENT) 
goto <token> <answer> finish; 
while (TRB_FIELD_TO_TYPE(le32_to_cpu(trb->control)) == TRB_LINK <token> <answer> && 
<token> { <answer> le32_to_cpu(trb->length)) 
trace_cdns2_complete_trb(pep, <token> <answer> trb); 
trb = pep->ring.trbs + <token> <answer> pep->ring.dequeue; 
<token> pep->endpoint.address); <answer> cdns2_select_ep(pdev, 
while <token> preq)) { <answer> (cdns2_trb_handled(pep, 
if (preq->finished_trb >= <token> <answer> preq->num_of_trb) 
<token> = true; <answer> request_handled 
trb <token> pep->ring.trbs + pep->ring.dequeue; <answer> = 
<token> trb); <answer> trace_cdns2_complete_trb(pep, 
<token> (pep->dir && pep->type == USB_ENDPOINT_XFER_ISOC) <answer> if 
preq->request.actual = <token> <answer> preq->request.length; 
preq->request.actual <token> <answer> += 
if <token> { <answer> (request_handled) 
cdns2_gadget_giveback(pep, preq, <token> <answer> 0); 
<token> = false; <answer> request_handled 
} else <token> <answer> { 
goto <token> <answer> prepare_next_td; 
if (pep->type <token> USB_ENDPOINT_XFER_ISOC && <answer> != 
TRBS_PER_SEGMENT <token> 2) <answer> == 
if <token> && preq) <answer> (pep->skip 
<token> pep, preq); <answer> cdns2_skip_isoc_td(pdev, 
if (!(pep->ep_state <token> EP_STALLED) && <answer> & 
!(pep->ep_state & <token> <answer> EP_STALL_PENDING)) 
<token> pep); <answer> cdns2_start_all_request(pdev, 
<token> void cdns2_wakeup(struct cdns2_device *pdev) <answer> static 
<token> (!pdev->may_wakeup) <answer> if 
if ((ep_sts_reg & DMA_EP_STS_ISOERR) || isoerror) <token> <answer> { 
clear_reg_bit_32(&pdev->adma_regs->ep_cfg, <token> <answer> DMA_EP_CFG_ENABLE); 
if (pep->type == <token> && !pep->wa1_set) { <answer> USB_ENDPOINT_XFER_ISOC 
<token> (!pep->dir) <answer> if 
cdns2_transfer_completed(pdev, <token> <answer> pep); 
if (pep->ep_state <token> EP_DEFERRED_DRDY) { <answer> & 
pep->ep_state <token> ~EP_DEFERRED_DRDY; <answer> &= 
cdns2_set_drdy(pdev, <token> <answer> pep); 
cdns2_transfer_completed(pdev, <token> <answer> pep); 
<token> (!(pep->ep_state & EP_STALLED) && <answer> if 
!(pep->ep_state & EP_STALL_PENDING)) <token> <answer> { 
if <token> & EP_DEFERRED_DRDY) { <answer> (pep->ep_state 
pep->ep_state <token> ~EP_DEFERRED_DRDY; <answer> &= 
cdns2_start_all_request(pdev, <token> <answer> pep); 
} else <token> <answer> { 
cdns2_rearm_transfer(pep, <token> <answer> pep->wa1_set); 
<token> ((ep_sts_reg & DMA_EP_STS_IOC) || (ep_sts_reg & DMA_EP_STS_ISP)) <answer> if 
<token> pep); <answer> cdns2_transfer_completed(pdev, 
static void <token> cdns2_device *pdev) <answer> cdns2_disconnect_gadget(struct 
<token> (pdev->gadget_driver && pdev->gadget_driver->disconnect) <answer> if 
static irqreturn_t cdns2_usb_irq_handler(int irq, <token> *data) <answer> void 
struct cdns2_device *pdev <token> data; <answer> = 
unsigned long <token> <answer> reg_ep_ists; 
u8 <token> <answer> reg_usb_irq_m; 
<token> reg_ext_irq_m; <answer> u8 
u8 <token> <answer> reg_usb_irq; 
u8 <token> <answer> reg_ext_irq; 
if <token> <answer> (pdev->in_lpm) 
<token> IRQ_NONE; <answer> return 
reg_usb_irq_m = <token> <answer> readb(&pdev->interrupt_regs->usbien); 
<token> = readb(&pdev->interrupt_regs->extien); <answer> reg_ext_irq_m 
<token> (i = 0; i < 100; i++) { <answer> for 
speed <token> cdns2_get_speed(pdev); <answer> = 
<token> (speed == USB_SPEED_HIGH) <answer> if 
<token> = speed; <answer> pdev->gadget.speed 
<token> 0); <answer> cdns2_enable_l1(pdev, 
<token> = 0; <answer> pdev->may_wakeup 
if (usb_irq & USBIRQ_SUDAV) <token> <answer> { 
pdev->ep0_stage = <token> <answer> CDNS2_SETUP_STAGE; 
return <token> <answer> IRQ_HANDLED; 
<token> &pdev->adma_regs->ep_ien); <answer> writel(~0, 
<token> &pdev->interrupt_regs->usbien); <answer> writeb(USB_IEN_INIT, 
<token> &pdev->interrupt_regs->extien); <answer> writeb(EXTIRQ_WAKEUP, 
spin_unlock_irqrestore(&pdev->lock, <token> <answer> flags); 
return <token> <answer> IRQ_HANDLED; 
if (pep->type == USB_ENDPOINT_XFER_ISOC && <token> <answer> !pep->dir) 
enable = <token> <answer> 0; 
ret = <token> <answer> cdns2_alloc_tr_segment(pep); 
if <token> <answer> (ret) 
<token> exit; <answer> goto 
ret = cdns2_ep_config(pep, <token> <answer> enable); 
<token> (ret) { <answer> if 
ret = <token> <answer> -EINVAL; 
goto <token> <answer> exit; 
pep->ep_state <token> ~(EP_STALLED | EP_STALL_PENDING); <answer> &= 
pep->ep_state <token> EP_ENABLED; <answer> |= 
pep->wa1_set <token> 0; <answer> = 
pep->ring.enqueue <token> 0; <answer> = 
pep->ring.dequeue <token> 0; <answer> = 
<token> = readl(&pdev->adma_regs->ep_sts); <answer> reg 
pep->ring.pcs = <token> <answer> !!DMA_EP_STS_CCS(reg); 
pep->ring.ccs <token> !!DMA_EP_STS_CCS(reg); <answer> = 
<token> &pdev->adma_regs->ep_traddr); <answer> writel(pep->ring.dma, 
<token> val, <answer> readl_poll_timeout_atomic(&pdev->adma_regs->ep_sts, 
!(val <token> DMA_EP_STS_DBUSY), 1, 10); <answer> & 
writel(DMA_EP_CMD_EPRST, <token> <answer> &pdev->adma_regs->ep_cmd); 
readl_poll_timeout_atomic(&pdev->adma_regs->ep_cmd, <token> <answer> val, 
!(val & (DMA_EP_CMD_DFLUSH | <token> <answer> DMA_EP_CMD_EPRST)), 
<token> 1000); <answer> 1, 
while <token> { <answer> (!list_empty(&pep->pending_list)) 
<token> = cdns2_next_preq(&pep->pending_list); <answer> preq 
cdns2_gadget_giveback(pep, <token> -ESHUTDOWN); <answer> preq, 
while (!list_empty(&pep->deferred_list)) <token> <answer> { 
<token> = cdns2_next_preq(&pep->deferred_list); <answer> preq 
cdns2_gadget_giveback(pep, <token> -ESHUTDOWN); <answer> preq, 
ep->desc = <token> <answer> NULL; 
pep->ep_state <token> ~EP_ENABLED; <answer> &= 
spin_unlock_irqrestore(&pdev->lock, <token> <answer> flags); 
<token> 0; <answer> return 
static int <token> cdns2_endpoint *pep, <answer> cdns2_ep_enqueue(struct 
<token> cdns2_request *preq, <answer> struct 
<token> gfp_flags) <answer> gfp_t 
struct cdns2_device <token> = pep->pdev; <answer> *pdev 
<token> usb_request *request; <answer> struct 
int <token> <answer> ret; 
request = <token> <answer> &preq->request; 
<token> = 0; <answer> request->actual 
request->status = <token> <answer> -EINPROGRESS; 
ret = usb_gadget_map_request_by_dev(pdev->dev, <token> pep->dir); <answer> request, 
if <token> { <answer> (ret) 
return <token> <answer> ret; 
list_add_tail(&preq->list, <token> <answer> &pep->deferred_list); 
if (!(pep->ep_state <token> EP_STALLED) && !(pep->ep_state & EP_STALL_PENDING)) <answer> & 
<token> pep); <answer> cdns2_start_all_request(pdev, 
<token> 0; <answer> return 
static int cdns2_gadget_ep_queue(struct usb_ep *ep, <token> usb_request *request, <answer> struct 
gfp_t <token> <answer> gfp_flags) 
struct usb_request <token> <answer> *zlp_request; 
<token> cdns2_request *preq; <answer> struct 
struct cdns2_endpoint <token> <answer> *pep; 
<token> cdns2_device *pdev; <answer> struct 
unsigned long <token> <answer> flags; 
<token> ret; <answer> int 
<token> (!request || !ep) <answer> if 
<token> -EINVAL; <answer> return 
pep <token> ep_to_cdns2_ep(ep); <answer> = 
pdev <token> pep->pdev; <answer> = 
if (!(pep->ep_state & EP_ENABLED)) <token> <answer> { 
dev_err(pdev->dev, "%s: can't <token> to disabled endpoint\n", <answer> queue 
return <token> <answer> -EINVAL; 
<token> flags); <answer> spin_lock_irqsave(&pdev->lock, 
preq = <token> <answer> to_cdns2_request(request); 
<token> = cdns2_ep_enqueue(pep, preq, gfp_flags); <answer> ret 
if (ret == 0 && request->zero && request->length <token> <answer> && 
<token> % ep->maxpacket == 0)) { <answer> (request->length 
struct <token> *preq; <answer> cdns2_request 
zlp_request = cdns2_gadget_ep_alloc_request(ep, <token> <answer> GFP_ATOMIC); 
zlp_request->buf <token> pdev->zlp_buf; <answer> = 
zlp_request->length = <token> <answer> 0; 
<token> = to_cdns2_request(zlp_request); <answer> preq 
ret = cdns2_ep_enqueue(pep, <token> gfp_flags); <answer> preq, 
<token> flags); <answer> spin_unlock_irqrestore(&pdev->lock, 
<token> ret; <answer> return 
int <token> usb_ep *ep, <answer> cdns2_gadget_ep_dequeue(struct 
<token> usb_request *request) <answer> struct 
struct cdns2_request *preq, <token> *cur_preq; <answer> *preq_temp, 
struct cdns2_endpoint <token> <answer> *pep; 
struct cdns2_trb <token> <answer> *link_trb; 
<token> req_on_hw_ring = 0; <answer> u8 
<token> long flags; <answer> unsigned 
u32 <token> <answer> buffer; 
<token> val, i; <answer> int 
if (!ep <token> !request || !ep->desc) <answer> || 
return <token> <answer> -EINVAL; 
pep = <token> <answer> ep_to_cdns2_ep(ep); 
<token> (!pep->endpoint.desc) { <answer> if 
dev_err(pep->pdev->dev, "%s: <token> dequeue to disabled endpoint\n", <answer> can't 
<token> -ESHUTDOWN; <answer> return 
<token> struct <answer> static 
usb_ep <token> usb_gadget *gadget, <answer> *cdns2_gadget_match_ep(struct 
<token> usb_endpoint_descriptor *desc, <answer> struct 
struct <token> *comp_desc) <answer> usb_ss_ep_comp_descriptor 
struct cdns2_device <token> = gadget_to_cdns2_device(gadget); <answer> *pdev 
struct cdns2_endpoint <token> <answer> *pep; 
unsigned long <token> <answer> flags; 
<token> = cdns2_find_available_ep(pdev, desc); <answer> pep 
if (IS_ERR(pep)) <token> <answer> { 
dev_err(pdev->dev, "no <token> ep\n"); <answer> available 
<token> NULL; <answer> return 
spin_lock_irqsave(&pdev->lock, <token> <answer> flags); 
if <token> == USB_ENDPOINT_XFER_ISOC) <answer> (usb_endpoint_type(desc) 
<token> = 4; <answer> pep->buffering 
pep->buffering = <token> <answer> 1; 
<token> |= EP_CLAIMED; <answer> pep->ep_state 
spin_unlock_irqrestore(&pdev->lock, <token> <answer> flags); 
<token> &pep->endpoint; <answer> return 
static const struct <token> cdns2_gadget_ep_ops = { <answer> usb_ep_ops 
.enable = <token> <answer> cdns2_gadget_ep_enable, 
.disable = <token> <answer> cdns2_gadget_ep_disable, 
<token> = cdns2_gadget_ep_alloc_request, <answer> .alloc_request 
.free_request = <token> <answer> cdns2_gadget_ep_free_request, 
<token> = cdns2_gadget_ep_queue, <answer> .queue 
.dequeue <token> cdns2_gadget_ep_dequeue, <answer> = 
.set_halt = <token> <answer> cdns2_gadget_ep_set_halt, 
<token> = cdns2_gadget_ep_set_wedge, <answer> .set_wedge 
static int <token> usb_gadget *gadget) <answer> cdns2_gadget_get_frame(struct 
struct cdns2_device *pdev = <token> <answer> gadget_to_cdns2_device(gadget); 
return <token> <answer> readw(&pdev->usb_regs->frmnr); 
static <token> cdns2_gadget_wakeup(struct usb_gadget *gadget) <answer> int 
struct cdns2_device <token> = gadget_to_cdns2_device(gadget); <answer> *pdev 
unsigned long <token> <answer> flags; 
<token> flags); <answer> spin_lock_irqsave(&pdev->lock, 
<token> flags); <answer> spin_unlock_irqrestore(&pdev->lock, 
<token> 0; <answer> return 
static int <token> usb_gadget *gadget, <answer> cdns2_gadget_set_selfpowered(struct 
<token> is_selfpowered) <answer> int 
struct cdns2_device <token> = gadget_to_cdns2_device(gadget); <answer> *pdev 
<token> long flags; <answer> unsigned 
spin_lock_irqsave(&pdev->lock, <token> <answer> flags); 
<token> = !!is_selfpowered; <answer> pdev->is_selfpowered 
spin_unlock_irqrestore(&pdev->lock, <token> <answer> flags); 
<token> 0; <answer> return 
spin_lock_irqsave(&pdev->lock, <token> <answer> flags); 
if <token> { <answer> (is_on) 
<token> USBCS_DISCON); <answer> clear_reg_bit_8(&pdev->usb_regs->usbcs, 
<token> else { <answer> } 
spin_unlock_irqrestore(&pdev->lock, <token> <answer> flags); 
<token> 0; <answer> return 
static <token> cdns2_gadget_udc_start(struct usb_gadget *gadget, <answer> int 
struct usb_gadget_driver <token> <answer> *driver) 
struct cdns2_device *pdev = <token> <answer> gadget_to_cdns2_device(gadget); 
<token> usb_device_speed max_speed = driver->max_speed; <answer> enum 
unsigned <token> flags; <answer> long 
spin_lock_irqsave(&pdev->lock, <token> <answer> flags); 
pdev->gadget_driver <token> driver; <answer> = 
if <token> epnum, direction)) <answer> (!CDNS2_IF_EP_EXIST(pdev, 
pep = <token> <answer> &pdev->eps[i]; 
pep->pdev = <token> <answer> pdev; 
pep->num = <token> <answer> epnum; 
if (!pdev->onchip_tx_buf <token> !pdev->onchip_rx_buf) { <answer> && 
ret = <token> <answer> -EINVAL; 
<token> "Invalid on-chip memory configuration\n"); <answer> dev_err(pdev->dev, 
goto <token> <answer> put_gadget; 
<token> (!(pdev->eps_supported & ~0x00010001)) { <answer> if 
<token> = -EINVAL; <answer> ret 
dev_err(pdev->dev, "No <token> endpoints available\n"); <answer> hardware 
goto <token> <answer> put_gadget; 
<token> = usb_get_maximum_speed(pdev->dev); <answer> max_speed 
switch (max_speed) <token> <answer> { 
case <token> <answer> USB_SPEED_FULL: 
<token> USB_SPEED_HIGH: <answer> case 
dev_err(pdev->dev, "invalid maximum_speed <token> %d\n", <answer> parameter 
case <token> <answer> USB_SPEED_UNKNOWN: 
max_speed = <token> <answer> USB_SPEED_HIGH; 
<token> = max_speed; <answer> pdev->gadget.max_speed 
pdev->gadget.speed <token> USB_SPEED_UNKNOWN; <answer> = 
pdev->gadget.ops = <token> <answer> &cdns2_gadget_ops; 
pdev->gadget.name <token> "usbhs-gadget"; <answer> = 
pdev->gadget.quirk_avoids_skb_reserve = <token> <answer> 1; 
pdev->gadget.irq = <token> <answer> pdev->irq; 
INIT_WORK(&pdev->pending_status_wq, <token> <answer> cdns2_pending_setup_status_handler); 
ret = devm_request_threaded_irq(pdev->dev, <token> <answer> pdev->irq, 
<token> (ret) <answer> if 
goto <token> <answer> err0; 
return <token> <answer> 0; 
<token> ret; <answer> return 
#include <token> <answer> <linux/clk-provider.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/err.h> 
<token> <linux/delay.h> <answer> #include 
<token> "clk.h" <answer> #include 
#define <token> container_of(hw, struct mmp_clk_gate, hw) <answer> to_clk_mmp_gate(hw) 
static int <token> clk_hw *hw) <answer> mmp_clk_gate_enable(struct 
struct mmp_clk_gate *gate <token> to_clk_mmp_gate(hw); <answer> = 
unsigned long <token> = 0; <answer> flags 
unsigned <token> rate; <answer> long 
<token> tmp; <answer> u32 
if <token> <answer> (gate->lock) 
<token> flags); <answer> spin_lock_irqsave(gate->lock, 
<token> = readl(gate->reg); <answer> tmp 
<token> &= ~gate->mask; <answer> tmp 
<token> |= gate->val_enable; <answer> tmp 
<token> gate->reg); <answer> writel(tmp, 
<token> (gate->lock) <answer> if 
<token> flags); <answer> spin_unlock_irqrestore(gate->lock, 
<token> (gate->flags & MMP_CLK_GATE_NEED_DELAY) { <answer> if 
<token> = clk_hw_get_rate(hw); <answer> rate 
<token> _GNU_SOURCE <answer> #define 
<token> <errno.h> <answer> #include 
<token> <fcntl.h> <answer> #include 
#include <token> <answer> <signal.h> 
<token> <stdio.h> <answer> #include 
<token> <stdlib.h> <answer> #include 
<token> <string.h> <answer> #include 
<token> <ucontext.h> <answer> #include 
#include <token> <answer> <sys/mman.h> 
<token> "kselftest.h" <answer> #include 
<token> "mte_common_util.h" <answer> #include 
<token> "mte_def.h" <answer> #include 
<token> TEST_UNIT 10 <answer> #define 
#define <token> "/sys/kernel/mm/ksm/" <answer> PATH_KSM 
#define <token> 4 <answer> MAX_LOOP 
static <token> page_sz; <answer> size_t 
<token> unsigned long ksm_sysfs[5]; <answer> static 
static unsigned <token> read_sysfs(char *str) <answer> long 
FILE <token> <answer> *f; 
unsigned <token> val = 0; <answer> long 
f = <token> "r"); <answer> fopen(str, 
if <token> { <answer> (!f) 
<token> missing %s\n", str); <answer> ksft_print_msg("ERR: 
<token> 0; <answer> return 
if (fscanf(f, "%lu", &val) != 1) <token> <answer> { 
ksft_print_msg("ERR: parsing %s\n", <token> <answer> str); 
<token> = 0; <answer> val 
return <token> <answer> val; 
static void write_sysfs(char *str, <token> long val) <answer> unsigned 
FILE <token> <answer> *f; 
f <token> fopen(str, "w"); <answer> = 
if <token> { <answer> (!f) 
<token> missing %s\n", str); <answer> ksft_print_msg("ERR: 
<token> "%lu", val); <answer> fprintf(f, 
static <token> mte_ksm_setup(void) <answer> void 
ksm_sysfs[0] <token> read_sysfs(PATH_KSM "merge_across_nodes"); <answer> = 
<token> "merge_across_nodes", 1); <answer> write_sysfs(PATH_KSM 
ksm_sysfs[1] = <token> "sleep_millisecs"); <answer> read_sysfs(PATH_KSM 
write_sysfs(PATH_KSM "sleep_millisecs", <token> <answer> 0); 
ksm_sysfs[2] = read_sysfs(PATH_KSM <token> <answer> "run"); 
write_sysfs(PATH_KSM "run", <token> <answer> 1); 
<token> = read_sysfs(PATH_KSM "max_page_sharing"); <answer> ksm_sysfs[3] 
write_sysfs(PATH_KSM "max_page_sharing", ksm_sysfs[3] + <token> <answer> TEST_UNIT); 
ksm_sysfs[4] <token> read_sysfs(PATH_KSM "pages_to_scan"); <answer> = 
write_sysfs(PATH_KSM <token> ksm_sysfs[4] + TEST_UNIT); <answer> "pages_to_scan", 
static <token> mte_ksm_restore(void) <answer> void 
<token> "merge_across_nodes", ksm_sysfs[0]); <answer> write_sysfs(PATH_KSM 
write_sysfs(PATH_KSM <token> ksm_sysfs[1]); <answer> "sleep_millisecs", 
write_sysfs(PATH_KSM "run", <token> <answer> ksm_sysfs[2]); 
<token> "max_page_sharing", ksm_sysfs[3]); <answer> write_sysfs(PATH_KSM 
write_sysfs(PATH_KSM "pages_to_scan", <token> <answer> ksm_sysfs[4]); 
static <token> mte_ksm_scan(void) <answer> void 
int <token> = read_sysfs(PATH_KSM "full_scans"); <answer> cur_count 
int scan_count = <token> + 1; <answer> cur_count 
int max_loop_count = <token> <answer> MAX_LOOP; 
while ((cur_count < scan_count) && max_loop_count) <token> <answer> { 
<token> = read_sysfs(PATH_KSM "full_scans"); <answer> cur_count 
#ifdef <token> <answer> DEBUG 
ksft_print_msg("INFO: <token> pages_sharing=%lu\n", <answer> pages_shared=%lu 
<token> "pages_shared"), <answer> read_sysfs(PATH_KSM 
<token> "pages_sharing")); <answer> read_sysfs(PATH_KSM 
<token> int check_madvise_options(int mem_type, int mode, int mapping) <answer> static 
<token> *ptr; <answer> char 
int <token> ret; <answer> err, 
err = <token> <answer> KSFT_FAIL; 
if <token> F_OK) == -1) { <answer> (access(PATH_KSM, 
ksft_print_msg("ERR: Kernel <token> config not enabled\n"); <answer> KSM 
<token> err; <answer> return 
<token> MTE_ALLOW_NON_ZERO_TAG); <answer> mte_switch_mode(mode, 
ptr = mte_allocate_memory(TEST_UNIT <token> page_sz, mem_type, mapping, true); <answer> * 
<token> (check_allocated_memory(ptr, TEST_UNIT * page_sz, mem_type, false) != KSFT_PASS) <answer> if 
return <token> <answer> KSFT_FAIL; 
#include <token> <answer> <linux/eventfd.h> 
<token> "i915_drv.h" <answer> #include 
<token> "i915_reg.h" <answer> #include 
<token> "gvt.h" <answer> #include 
#include <token> <answer> "trace.h" 
struct intel_gvt_irq_info <token> <answer> { 
<token> *name; <answer> char 
i915_reg_t <token> <answer> reg_base; 
enum intel_gvt_event_type <token> <answer> bit_to_event[INTEL_GVT_IRQ_BITWIDTH]; 
int <token> <answer> group; 
DECLARE_BITMAP(downstream_irq_bitmap, <token> <answer> INTEL_GVT_IRQ_BITWIDTH); 
bool <token> <answer> has_upstream_irq; 
<token> intel_gvt_irq_map { <answer> struct 
int <token> <answer> up_irq_group; 
<token> up_irq_bit; <answer> int 
int <token> <answer> down_irq_group; 
u32 <token> <answer> down_irq_bitmask; 
int intel_vgpu_reg_imr_handler(struct <token> *vgpu, <answer> intel_vgpu 
unsigned int <token> void *p_data, unsigned int bytes) <answer> reg, 
struct intel_gvt <token> = vgpu->gvt; <answer> *gvt 
const <token> intel_gvt_irq_ops *ops = gvt->irq.ops; <answer> struct 
u32 imr = <token> *)p_data; <answer> *(u32 
<token> "IMR", reg, imr, vgpu_vreg(vgpu, reg), <answer> trace_write_ir(vgpu->id, 
(vgpu_vreg(vgpu, <token> ^ imr)); <answer> reg) 
vgpu_vreg(vgpu, reg) = <token> <answer> imr; 
<token> 0; <answer> return 
int intel_vgpu_reg_master_irq_handler(struct <token> *vgpu, <answer> intel_vgpu 
unsigned int reg, void *p_data, unsigned <token> bytes) <answer> int 
<token> intel_gvt *gvt = vgpu->gvt; <answer> struct 
const <token> intel_gvt_irq_ops *ops = gvt->irq.ops; <answer> struct 
u32 ier <token> *(u32 *)p_data; <answer> = 
<token> virtual_ier = vgpu_vreg(vgpu, reg); <answer> u32 
<token> "MASTER_IRQ", reg, ier, virtual_ier, <answer> trace_write_ir(vgpu->id, 
(virtual_ier <token> ier)); <answer> ^ 
ier &= <token> <answer> GEN8_MASTER_IRQ_CONTROL; 
virtual_ier <token> GEN8_MASTER_IRQ_CONTROL; <answer> &= 
<token> reg) &= ~GEN8_MASTER_IRQ_CONTROL; <answer> vgpu_vreg(vgpu, 
vgpu_vreg(vgpu, <token> |= ier; <answer> reg) 
<token> 0; <answer> return 
int intel_vgpu_reg_ier_handler(struct intel_vgpu <token> <answer> *vgpu, 
unsigned int reg, void *p_data, unsigned int <token> <answer> bytes) 
struct intel_gvt *gvt <token> vgpu->gvt; <answer> = 
struct drm_i915_private <token> = gvt->gt->i915; <answer> *i915 
<token> struct intel_gvt_irq_ops *ops = gvt->irq.ops; <answer> const 
<token> intel_gvt_irq_info *info; <answer> struct 
u32 <token> = *(u32 *)p_data; <answer> ier 
trace_write_ir(vgpu->id, "IER", reg, ier, <token> reg), <answer> vgpu_vreg(vgpu, 
(vgpu_vreg(vgpu, <token> ^ ier)); <answer> reg) 
<token> reg) = ier; <answer> vgpu_vreg(vgpu, 
info <token> regbase_to_irq_info(gvt, ier_to_regbase(reg)); <answer> = 
if (drm_WARN_ON(&i915->drm, <token> <answer> !info)) 
<token> -EINVAL; <answer> return 
if <token> <answer> (info->has_upstream_irq) 
<token> info); <answer> update_upstream_irq(vgpu, 
<token> 0; <answer> return 
int intel_vgpu_reg_iir_handler(struct intel_vgpu *vgpu, unsigned <token> reg, <answer> int 
void <token> unsigned int bytes) <answer> *p_data, 
struct drm_i915_private <token> = vgpu->gvt->gt->i915; <answer> *i915 
struct <token> *info = regbase_to_irq_info(vgpu->gvt, <answer> intel_gvt_irq_info 
u32 <token> = *(u32 *)p_data; <answer> iir 
trace_write_ir(vgpu->id, "IIR", reg, iir, vgpu_vreg(vgpu, <token> <answer> reg), 
<token> reg) ^ iir)); <answer> (vgpu_vreg(vgpu, 
<token> (drm_WARN_ON(&i915->drm, !info)) <answer> if 
return <token> <answer> -EINVAL; 
vgpu_vreg(vgpu, reg) &= <token> <answer> ~iir; 
<token> (info->has_upstream_irq) <answer> if 
update_upstream_irq(vgpu, <token> <answer> info); 
return <token> <answer> 0; 
static struct <token> gen8_irq_map[] = { <answer> intel_gvt_irq_map 
<token> INTEL_GVT_IRQ_INFO_MASTER, 0, INTEL_GVT_IRQ_INFO_GT0, 0xffff }, <answer> { 
<token> INTEL_GVT_IRQ_INFO_MASTER, 1, INTEL_GVT_IRQ_INFO_GT0, 0xffff0000 }, <answer> { 
{ INTEL_GVT_IRQ_INFO_MASTER, 2, INTEL_GVT_IRQ_INFO_GT1, <token> }, <answer> 0xffff 
{ INTEL_GVT_IRQ_INFO_MASTER, 3, INTEL_GVT_IRQ_INFO_GT1, <token> }, <answer> 0xffff0000 
{ INTEL_GVT_IRQ_INFO_MASTER, 4, INTEL_GVT_IRQ_INFO_GT2, 0xffff <token> <answer> }, 
{ INTEL_GVT_IRQ_INFO_MASTER, 6, INTEL_GVT_IRQ_INFO_GT3, 0xffff <token> <answer> }, 
{ INTEL_GVT_IRQ_INFO_MASTER, 16, <token> ~0 }, <answer> INTEL_GVT_IRQ_INFO_DE_PIPE_A, 
{ INTEL_GVT_IRQ_INFO_MASTER, 17, <token> ~0 }, <answer> INTEL_GVT_IRQ_INFO_DE_PIPE_B, 
{ INTEL_GVT_IRQ_INFO_MASTER, 18, <token> ~0 }, <answer> INTEL_GVT_IRQ_INFO_DE_PIPE_C, 
{ INTEL_GVT_IRQ_INFO_MASTER, 20, INTEL_GVT_IRQ_INFO_DE_PORT, <token> }, <answer> ~0 
<token> INTEL_GVT_IRQ_INFO_MASTER, 22, INTEL_GVT_IRQ_INFO_DE_MISC, ~0 }, <answer> { 
{ INTEL_GVT_IRQ_INFO_MASTER, 23, INTEL_GVT_IRQ_INFO_PCH, ~0 <token> <answer> }, 
{ INTEL_GVT_IRQ_INFO_MASTER, 30, <token> ~0 }, <answer> INTEL_GVT_IRQ_INFO_PCU, 
{ <token> -1, ~0 }, <answer> -1, 
static <token> update_upstream_irq(struct intel_vgpu *vgpu, <answer> void 
struct intel_gvt_irq_info <token> <answer> *info) 
struct drm_i915_private *i915 = <token> <answer> vgpu->gvt->gt->i915; 
struct <token> *irq = &vgpu->gvt->irq; <answer> intel_gvt_irq 
struct <token> *map = irq->irq_map; <answer> intel_gvt_irq_map 
struct intel_gvt_irq_info *up_irq_info <token> NULL; <answer> = 
u32 <token> = 0; <answer> set_bits 
<token> clear_bits = 0; <answer> u32 
<token> bit; <answer> int 
u32 val <token> vgpu_vreg(vgpu, <answer> = 
& <token> <answer> vgpu_vreg(vgpu, 
if <token> <answer> (!info->has_upstream_irq) 
for (map = irq->irq_map; map->up_irq_bit != -1; <token> { <answer> map++) 
if (info->group != <token> <answer> map->down_irq_group) 
<token> (!up_irq_info) <answer> if 
up_irq_info = <token> <answer> irq->info[map->up_irq_group]; 
<token> up_irq_info != <answer> drm_WARN_ON(&i915->drm, 
<token> = map->up_irq_bit; <answer> bit 
if <token> & map->down_irq_bitmask) <answer> (val 
set_bits <token> (1 << bit); <answer> |= 
<token> |= (1 << bit); <answer> clear_bits 
<token> (drm_WARN_ON(&i915->drm, !up_irq_info)) <answer> if 
if (up_irq_info->group == <token> { <answer> INTEL_GVT_IRQ_INFO_MASTER) 
u32 isr = <token> <answer> i915_mmio_reg_offset(up_irq_info->reg_base); 
vgpu_vreg(vgpu, isr) <token> ~clear_bits; <answer> &= 
<token> isr) |= set_bits; <answer> vgpu_vreg(vgpu, 
} else <token> <answer> { 
u32 iir <token> regbase_to_iir( <answer> = 
u32 imr = <token> <answer> regbase_to_imr( 
vgpu_vreg(vgpu, iir) |= (set_bits <token> ~vgpu_vreg(vgpu, imr)); <answer> & 
<token> (up_irq_info->has_upstream_irq) <answer> if 
update_upstream_irq(vgpu, <token> <answer> up_irq_info); 
<token> void init_irq_map(struct intel_gvt_irq *irq) <answer> static 
struct <token> *map; <answer> intel_gvt_irq_map 
struct intel_gvt_irq_info <token> *down_info; <answer> *up_info, 
int <token> <answer> up_bit; 
for (map = <token> map->up_irq_bit != -1; map++) { <answer> irq->irq_map; 
up_info <token> irq->info[map->up_irq_group]; <answer> = 
up_bit = <token> <answer> map->up_irq_bit; 
down_info <token> irq->info[map->down_irq_group]; <answer> = 
<token> up_info->downstream_irq_bitmap); <answer> set_bit(up_bit, 
<token> = true; <answer> down_info->has_upstream_irq 
gvt_dbg_irq("[up] grp <token> bit %d -> [down] grp %d bitmask %x\n", <answer> %d 
up_info->group, <token> <answer> up_bit, 
down_info->group, <token> <answer> map->down_irq_bitmask); 
<token> (!test_bit(INTEL_VGPU_STATUS_ATTACHED, vgpu->status)) <answer> if 
<token> (vgpu->msi_trigger) <answer> if 
static void <token> intel_gvt_irq *irq, <answer> propagate_event(struct 
enum intel_gvt_event_type <token> struct intel_vgpu *vgpu) <answer> event, 
struct <token> *info; <answer> intel_gvt_irq_info 
<token> int reg_base; <answer> unsigned 
int <token> <answer> bit; 
info = <token> event); <answer> get_irq_info(irq, 
if <token> <answer> (WARN_ON(!info)) 
reg_base = <token> <answer> i915_mmio_reg_offset(info->reg_base); 
bit <token> irq->events[event].bit; <answer> = 
if (!test_bit(bit, (void <token> <answer> *)&vgpu_vreg(vgpu, 
<token> { <answer> regbase_to_imr(reg_base)))) 
trace_propagate_event(vgpu->id, irq_name[event], <token> <answer> bit); 
<token> (void *)&vgpu_vreg(vgpu, <answer> set_bit(bit, 
void intel_vgpu_trigger_virtual_event(struct intel_vgpu <token> <answer> *vgpu, 
enum <token> event) <answer> intel_gvt_event_type 
struct drm_i915_private *i915 <token> vgpu->gvt->gt->i915; <answer> = 
struct intel_gvt <token> = vgpu->gvt; <answer> *gvt 
struct intel_gvt_irq <token> = &gvt->irq; <answer> *irq 
gvt_event_virt_handler_t <token> <answer> handler; 
const struct intel_gvt_irq_ops <token> = gvt->irq.ops; <answer> *ops 
handler <token> get_event_virt_handler(irq, event); <answer> = 
<token> !handler); <answer> drm_WARN_ON(&i915->drm, 
handler(irq, event, <token> <answer> vgpu); 
<token> void init_events( <answer> static 
struct <token> *irq) <answer> intel_gvt_irq 
<token> i; <answer> int 
for (i = 0; i < <token> i++) { <answer> INTEL_GVT_EVENT_MAX; 
<token> = NULL; <answer> irq->events[i].info 
irq->events[i].v_handler = <token> <answer> handle_default_event_virt; 
int intel_gvt_init_irq(struct <token> *gvt) <answer> intel_gvt 
struct intel_gvt_irq *irq <token> &gvt->irq; <answer> = 
gvt_dbg_core("init <token> framework\n"); <answer> irq 
<token> = &gen8_irq_ops; <answer> irq->ops 
irq->irq_map = <token> <answer> gen8_irq_map; 
#include <token> <answer> <linux/module.h> 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/comedi/comedi_pci.h> 
<token> "mite.h" <answer> #include 
<token> "ni_tio.h" <answer> #include 
<token> "ni_routes.h" <answer> #include 
<token> (chip) <answer> if 
bits <token> NI660X_CLK_CFG_COUNTER_SWAP; <answer> = 
ni_660x_write(dev, chip, bits, <token> <answer> NI660X_CLK_CFG); 
static <token> ni_660x_handle_gpct_interrupt(struct comedi_device *dev, <answer> void 
struct comedi_subdevice <token> <answer> *s) 
struct ni_gpct *counter <token> s->private; <answer> = 
<token> s); <answer> ni_tio_handle_interrupt(counter, 
comedi_handle_events(dev, <token> <answer> s); 
static irqreturn_t <token> irq, void *d) <answer> ni_660x_interrupt(int 
struct comedi_device *dev = <token> <answer> d; 
<token> ni_660x_private *devpriv = dev->private; <answer> struct 
<token> comedi_subdevice *s; <answer> struct 
unsigned <token> i; <answer> int 
unsigned long <token> <answer> flags; 
if <token> <answer> (!dev->attached) 
return <token> <answer> IRQ_NONE; 
<token> (mask) { <answer> if 
s->state &= <token> <answer> ~mask; 
<token> |= (bits & mask); <answer> s->state 
