#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/pci.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/nospec.h> 
#include <token> <answer> <sound/core.h> 
<token> <sound/control.h> <answer> #include 
<token> <sound/pcm.h> <answer> #include 
<token> <sound/info.h> <answer> #include 
<token> <sound/asoundef.h> <answer> #include 
<token> <sound/initval.h> <answer> #include 
<token> <asm/current.h> <answer> #include 
<token> RME9652_NCHANNELS 26 <answer> #define 
#define RME9636_NCHANNELS <token> <answer> 18 
<token> RME9652_REV15_buf_pos(x) ((((x)&0xE0000000)>>26)|((x)&RME9652_buf_pos)) <answer> #define 
<token> RME9652_IO_EXTENT 1024 <answer> #define 
<token> RME9652_init_buffer 0 <answer> #define 
<token> RME9652_status_register 0 <answer> #define 
<token> RME9652_DMA_AREA_BYTES ((RME9652_NCHANNELS+1) * RME9652_CHANNEL_BUFFER_BYTES) <answer> #define 
#define <token> (RME9652_DMA_AREA_BYTES/1024) <answer> RME9652_DMA_AREA_KILOBYTES 
struct <token> { <answer> snd_rme9652 
int <token> <answer> dev; 
<token> lock; <answer> spinlock_t 
<token> irq; <answer> int 
unsigned long <token> <answer> port; 
<token> __iomem *iobase; <answer> void 
<token> precise_ptr; <answer> int 
struct <token> playback_dma_buf; <answer> snd_dma_buffer 
<token> snd_dma_buffer capture_dma_buf; <answer> struct 
static const signed char channel_map_9652_ss[26] <token> { <answer> = 
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, <token> 16, 17, <answer> 15, 
18, 19, <token> 21, 22, 23, 24, 25 <answer> 20, 
static const signed <token> channel_map_9636_ss[26] = { <answer> char 
0, <token> 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, <answer> 1, 
delta = rme9652->prev_hw_offset <token> offset; <answer> - 
delta &= <token> <answer> 0xffff; 
if (delta <= (snd_pcm_sframes_t)rme9652->max_jitter <token> 4) <answer> * 
offset <token> rme9652->prev_hw_offset; <answer> = 
rme9652->prev_hw_offset <token> offset; <answer> = 
<token> &= rme9652->hw_offsetmask; <answer> offset 
offset /= <token> <answer> 4; 
frag = status & <token> <answer> RME9652_buffer_id; 
if <token> < period_size) { <answer> (offset 
if (offset <token> rme9652->max_jitter) { <answer> > 
<token> (frag) <answer> if 
"Unexpected hw_pointer position (bufid == 0): <token> %x offset: %d\n", <answer> status: 
<token> offset); <answer> status, 
} <token> if (!frag) <answer> else 
<token> 0; <answer> return 
offset <token> rme9652->max_jitter; <answer> -= 
<token> ((int)offset < 0) <answer> if 
offset += <token> * 2; <answer> period_size 
} else <token> <answer> { 
if (offset > period_size + <token> { <answer> rme9652->max_jitter) 
<token> (!frag) <answer> if 
"Unexpected hw_pointer position (bufid <token> 1): status: %x offset: %d\n", <answer> == 
status, <token> <answer> offset); 
<token> else if (frag) <answer> } 
<token> period_size; <answer> return 
<token> -= rme9652->max_jitter; <answer> offset 
<token> offset; <answer> return 
static <token> void rme9652_reset_hw_pointer(struct snd_rme9652 *rme9652) <answer> inline 
<token> i; <answer> int 
for (i = 0; i < <token> i++) { <answer> 8; 
rme9652_write(rme9652, i * <token> 0); <answer> 4, 
<token> = 0; <answer> rme9652->prev_hw_offset 
static inline void rme9652_start(struct snd_rme9652 <token> <answer> *s) 
s->control_register <token> (RME9652_IE | RME9652_start_bit); <answer> |= 
<token> RME9652_control_register, s->control_register); <answer> rme9652_write(s, 
static inline <token> rme9652_stop(struct snd_rme9652 *s) <answer> void 
s->control_register &= <token> | RME9652_IE); <answer> ~(RME9652_start_bit 
rme9652_write(s, <token> s->control_register); <answer> RME9652_control_register, 
static int <token> snd_rme9652 *s, <answer> rme9652_set_interrupt_interval(struct 
unsigned <token> frames) <answer> int 
int restart <token> 0; <answer> = 
<token> n; <answer> int 
restart <token> s->running; <answer> = 
if <token> <answer> (restart) 
frames >>= <token> <answer> 7; 
n <token> 0; <answer> = 
while <token> { <answer> (frames) 
frames >>= <token> <answer> 1; 
<token> &= ~RME9652_latency; <answer> s->control_register 
<token> |= rme9652_encode_latency(n); <answer> s->control_register 
rme9652_write(s, <token> s->control_register); <answer> RME9652_control_register, 
<token> (restart) <answer> if 
return <token> <answer> 0; 
static int rme9652_set_rate(struct snd_rme9652 *rme9652, int <token> <answer> rate) 
<token> restart; <answer> int 
int reject_if_open = <token> <answer> 0; 
int <token> <answer> xrate; 
if (!snd_rme9652_use_is_exclusive (rme9652)) <token> <answer> { 
<token> -EBUSY; <answer> return 
xrate <token> rme9652_adat_sample_rate(rme9652); <answer> = 
<token> (rate) { <answer> switch 
<token> 44100: <answer> case 
if (xrate > 48000) <token> <answer> { 
<token> = 1; <answer> reject_if_open 
rate <token> 0; <answer> = 
<token> 48000: <answer> case 
<token> (xrate > 48000) { <answer> if 
<token> = 1; <answer> reject_if_open 
rate <token> RME9652_freq; <answer> = 
case <token> <answer> 88200: 
if <token> < 48000) { <answer> (xrate 
<token> = 1; <answer> reject_if_open 
rate = <token> <answer> RME9652_DS; 
<token> 96000: <answer> case 
if (xrate < <token> { <answer> 48000) 
reject_if_open = <token> <answer> 1; 
rate <token> RME9652_DS | RME9652_freq; <answer> = 
return <token> <answer> -EINVAL; 
if (reject_if_open && (rme9652->capture_pid >= 0 || rme9652->playback_pid >= <token> { <answer> 0)) 
<token> -EBUSY; <answer> return 
<token> = rme9652->running; <answer> restart 
if <token> <answer> (restart) 
<token> &= ~(RME9652_freq | RME9652_DS); <answer> rme9652->control_register 
<token> |= rate; <answer> rme9652->control_register 
rme9652_write(rme9652, <token> rme9652->control_register); <answer> RME9652_control_register, 
<token> (restart) <answer> if 
if (rate & <token> { <answer> RME9652_DS) 
if (rme9652->ss_channels == RME9652_NCHANNELS) <token> <answer> { 
rme9652->channel_map <token> channel_map_9652_ds; <answer> = 
} else <token> <answer> { 
<token> = channel_map_9636_ds; <answer> rme9652->channel_map 
} else <token> <answer> { 
if <token> == RME9652_NCHANNELS) { <answer> (rme9652->ss_channels 
<token> = channel_map_9652_ss; <answer> rme9652->channel_map 
<token> else { <answer> } 
<token> = channel_map_9636_ss; <answer> rme9652->channel_map 
<token> 0; <answer> return 
static void rme9652_set_thru(struct snd_rme9652 *rme9652, int channel, <token> enable) <answer> int 
int <token> <answer> i; 
rme9652->passthru = <token> <answer> 0; 
if <token> < 0) { <answer> (channel 
<token> = <answer> rme9652->control_register 
RME9652_inp_0 <token> <answer> | 
rme9652_encode_latency(7) <token> <answer> | 
rme9652_write(rme9652, <token> <answer> RME9652_control_register, 
rme9652->passthru = <token> <answer> 1; 
} else <token> <answer> { 
rme9652_set_thru(rme9652, <token> 0); <answer> -1, 
<token> = 0; <answer> rme9652->passthru 
<token> 0; <answer> return 
static void rme9652_spdif_set_bit (struct snd_rme9652 *rme9652, int mask, <token> onoff) <answer> int 
<token> (onoff) <answer> if 
rme9652->control_register <token> mask; <answer> |= 
rme9652->control_register &= <token> <answer> ~mask; 
rme9652_write(rme9652, <token> rme9652->control_register); <answer> RME9652_control_register, 
<token> void rme9652_spdif_write_byte (struct snd_rme9652 *rme9652, const int val) <answer> static 
<token> mask; <answer> long 
<token> i; <answer> long 
for (i = 0, mask = 0x80; i < 8; <token> mask >>= 1) { <answer> i++, 
if (val <token> mask) <answer> & 
rme9652_spdif_set_bit (rme9652, RME9652_SPDIF_WRITE, <token> <answer> 1); 
rme9652_spdif_set_bit (rme9652, <token> 0); <answer> RME9652_SPDIF_WRITE, 
rme9652_spdif_set_bit (rme9652, <token> 1); <answer> RME9652_SPDIF_CLOCK, 
rme9652_spdif_set_bit (rme9652, RME9652_SPDIF_CLOCK, <token> <answer> 0); 
static int rme9652_spdif_read_byte (struct snd_rme9652 <token> <answer> *rme9652) 
long <token> <answer> mask; 
<token> val; <answer> long 
<token> i; <answer> long 
<token> = 0; <answer> val 
for (i = 0, mask = 0x80; i < 8; i++, <token> >>= 1) { <answer> mask 
<token> (rme9652, RME9652_SPDIF_CLOCK, 1); <answer> rme9652_spdif_set_bit 
if (rme9652_read (rme9652, RME9652_status_register) & <token> <answer> RME9652_SPDIF_READ) 
<token> |= mask; <answer> val 
rme9652_spdif_set_bit <token> RME9652_SPDIF_CLOCK, 0); <answer> (rme9652, 
return <token> <answer> val; 
static void rme9652_write_spdif_codec (struct snd_rme9652 *rme9652, const int address, const <token> data) <answer> int 
<token> (rme9652, RME9652_SPDIF_SELECT, 1); <answer> rme9652_spdif_set_bit 
rme9652_spdif_write_byte <token> 0x20); <answer> (rme9652, 
rme9652_spdif_write_byte (rme9652, <token> <answer> address); 
<token> (rme9652, data); <answer> rme9652_spdif_write_byte 
<token> (rme9652, RME9652_SPDIF_SELECT, 0); <answer> rme9652_spdif_set_bit 
static int rme9652_spdif_read_codec <token> snd_rme9652 *rme9652, const int address) <answer> (struct 
<token> ret; <answer> int 
<token> (rme9652, RME9652_SPDIF_SELECT, 1); <answer> rme9652_spdif_set_bit 
rme9652_spdif_write_byte <token> 0x20); <answer> (rme9652, 
rme9652_spdif_write_byte (rme9652, <token> <answer> address); 
rme9652_spdif_set_bit (rme9652, RME9652_SPDIF_SELECT, <token> <answer> 0); 
rme9652_spdif_set_bit (rme9652, <token> 1); <answer> RME9652_SPDIF_SELECT, 
rme9652_spdif_write_byte <token> 0x21); <answer> (rme9652, 
ret <token> rme9652_spdif_read_byte (rme9652); <answer> = 
rme9652_spdif_set_bit (rme9652, RME9652_SPDIF_SELECT, <token> <answer> 0); 
return <token> <answer> ret; 
static void rme9652_initialize_spdif_receiver <token> snd_rme9652 *rme9652) <answer> (struct 
static u32 snd_rme9652_convert_from_aes(struct snd_aes_iec958 <token> <answer> *aes) 
<token> val = 0; <answer> u32 
val |= (aes->status[0] & IEC958_AES0_PROFESSIONAL) ? RME9652_PRO <token> 0; <answer> : 
val |= (aes->status[0] & IEC958_AES0_NONAUDIO) ? RME9652_Dolby <token> 0; <answer> : 
<token> (val & RME9652_PRO) <answer> if 
val |= (aes->status[0] & IEC958_AES0_PRO_EMPHASIS_5015) ? RME9652_EMP : <token> <answer> 0; 
val |= (aes->status[0] & IEC958_AES0_CON_EMPHASIS_5015) ? RME9652_EMP : <token> <answer> 0; 
<token> val; <answer> return 
static void snd_rme9652_convert_to_aes(struct <token> *aes, u32 val) <answer> snd_aes_iec958 
aes->status[0] <token> ((val & RME9652_PRO) ? IEC958_AES0_PROFESSIONAL : 0) | <answer> = 
((val & <token> ? IEC958_AES0_NONAUDIO : 0); <answer> RME9652_Dolby) 
<token> (val & RME9652_PRO) <answer> if 
aes->status[0] |= (val & RME9652_EMP) ? IEC958_AES0_PRO_EMPHASIS_5015 : <token> <answer> 0; 
aes->status[0] |= <token> & RME9652_EMP) ? IEC958_AES0_CON_EMPHASIS_5015 : 0; <answer> (val 
static int snd_rme9652_control_spdif_info(struct snd_kcontrol *kcontrol, <token> snd_ctl_elem_info *uinfo) <answer> struct 
uinfo->type <token> SNDRV_CTL_ELEM_TYPE_IEC958; <answer> = 
uinfo->count = <token> <answer> 1; 
<token> 0; <answer> return 
static <token> snd_rme9652_control_spdif_get(struct snd_kcontrol *kcontrol, struct snd_ctl_elem_value *ucontrol) <answer> int 
struct snd_rme9652 *rme9652 = <token> <answer> snd_kcontrol_chip(kcontrol); 
<token> rme9652->creg_spdif); <answer> snd_rme9652_convert_to_aes(&ucontrol->value.iec958, 
return <token> <answer> 0; 
static int snd_rme9652_control_spdif_put(struct snd_kcontrol <token> struct snd_ctl_elem_value *ucontrol) <answer> *kcontrol, 
struct snd_rme9652 *rme9652 = <token> <answer> snd_kcontrol_chip(kcontrol); 
int <token> <answer> change; 
u32 <token> <answer> val; 
val <token> snd_rme9652_convert_from_aes(&ucontrol->value.iec958); <answer> = 
change = val != <token> <answer> rme9652->creg_spdif; 
<token> = val; <answer> rme9652->creg_spdif 
<token> change; <answer> return 
static int snd_rme9652_control_spdif_stream_info(struct snd_kcontrol *kcontrol, <token> snd_ctl_elem_info *uinfo) <answer> struct 
<token> = SNDRV_CTL_ELEM_TYPE_IEC958; <answer> uinfo->type 
uinfo->count <token> 1; <answer> = 
return <token> <answer> 0; 
static int <token> snd_kcontrol *kcontrol, struct snd_ctl_elem_value *ucontrol) <answer> snd_rme9652_control_spdif_stream_get(struct 
struct snd_rme9652 *rme9652 = <token> <answer> snd_kcontrol_chip(kcontrol); 
<token> rme9652->creg_spdif_stream); <answer> snd_rme9652_convert_to_aes(&ucontrol->value.iec958, 
return <token> <answer> 0; 
<token> int snd_rme9652_control_spdif_stream_put(struct snd_kcontrol *kcontrol, struct snd_ctl_elem_value *ucontrol) <answer> static 
struct snd_rme9652 <token> = snd_kcontrol_chip(kcontrol); <answer> *rme9652 
int <token> <answer> change; 
u32 <token> <answer> val; 
val <token> snd_rme9652_convert_from_aes(&ucontrol->value.iec958); <answer> = 
<token> = val != rme9652->creg_spdif_stream; <answer> change 
<token> = val; <answer> rme9652->creg_spdif_stream 
rme9652->control_register <token> ~(RME9652_PRO | RME9652_Dolby | RME9652_EMP); <answer> &= 
rme9652_write(rme9652, <token> rme9652->control_register |= val); <answer> RME9652_control_register, 
<token> change; <answer> return 
static int snd_rme9652_control_spdif_mask_info(struct <token> *kcontrol, struct snd_ctl_elem_info *uinfo) <answer> snd_kcontrol 
uinfo->type <token> SNDRV_CTL_ELEM_TYPE_IEC958; <answer> = 
uinfo->count = <token> <answer> 1; 
<token> 0; <answer> return 
static int snd_rme9652_control_spdif_mask_get(struct snd_kcontrol *kcontrol, struct snd_ctl_elem_value <token> <answer> *ucontrol) 
ucontrol->value.iec958.status[0] = <token> <answer> kcontrol->private_value; 
<token> 0; <answer> return 
#define <token> xindex) \ <answer> RME9652_ADAT1_IN(xname, 
{ .iface = SNDRV_CTL_ELEM_IFACE_MIXER, .name = xname, .index = xindex, <token> <answer> \ 
.info = snd_rme9652_info_adat1_in, <token> <answer> \ 
.get <token> snd_rme9652_get_adat1_in, \ <answer> = 
.put = snd_rme9652_put_adat1_in <token> <answer> } 
static <token> int rme9652_adat1_in(struct snd_rme9652 *rme9652) <answer> unsigned 
if <token> & RME9652_ADAT1_INTERNAL) <answer> (rme9652->control_register 
<token> 1; <answer> return 
return <token> <answer> 0; 
static int <token> snd_rme9652 *rme9652, int internal) <answer> rme9652_set_adat1_input(struct 
int restart <token> 0; <answer> = 
<token> (internal) { <answer> if 
rme9652->control_register |= <token> <answer> RME9652_ADAT1_INTERNAL; 
<token> else { <answer> } 
rme9652->control_register <token> ~RME9652_ADAT1_INTERNAL; <answer> &= 
<token> void <answer> static 
snd_rme9652_proc_read(struct snd_info_entry *entry, struct <token> *buffer) <answer> snd_info_buffer 
struct snd_rme9652 *rme9652 = (struct snd_rme9652 <token> entry->private_data; <answer> *) 
u32 thru_bits <token> rme9652->thru_bits; <answer> = 
int show_auto_sync_source = <token> <answer> 0; 
<token> i; <answer> int 
unsigned int <token> <answer> status; 
<token> x; <answer> int 
status = rme9652_read(rme9652, <token> <answer> RME9652_status_register); 
snd_iprintf(buffer, "%s (Card #%d)\n", <token> rme9652->card->number + 1); <answer> rme9652->card_name, 
snd_iprintf(buffer, <token> capture %p playback %p\n", <answer> "Buffers: 
rme9652->capture_buffer, <token> <answer> rme9652->playback_buffer); 
snd_iprintf(buffer, <token> %d Registers bus: 0x%lx VM: 0x%lx\n", <answer> "IRQ: 
<token> rme9652->port, (unsigned long)rme9652->iobase); <answer> rme9652->irq, 
<token> "Control register: %x\n", rme9652->control_register); <answer> snd_iprintf(buffer, 
snd_iprintf(buffer, <token> <answer> "\n"); 
x = 1 <token> (6 + rme9652_decode_latency(rme9652->control_register & <answer> << 
snd_iprintf(buffer, "Latency: %d samples (2 periods of <token> bytes)\n", <answer> %lu 
x, (unsigned long) <token> <answer> rme9652->period_bytes); 
snd_iprintf(buffer, "Hardware pointer (frames): <token> <answer> %ld\n", 
<token> "Passthru: %s\n", <answer> snd_iprintf(buffer, 
rme9652->passthru <token> "yes" : "no"); <answer> ? 
if ((rme9652->control_register & (RME9652_Master | <token> == 0) { <answer> RME9652_wsel)) 
<token> "Clock mode: autosync\n"); <answer> snd_iprintf(buffer, 
show_auto_sync_source <token> 1; <answer> = 
} else if (rme9652->control_register & <token> { <answer> RME9652_wsel) 
if (status <token> RME9652_wsel_rd) { <answer> & 
<token> "Clock mode: word clock\n"); <answer> snd_iprintf(buffer, 
<token> else { <answer> } 
snd_iprintf(buffer, <token> mode: word clock (no signal)\n"); <answer> "Clock 
} else <token> <answer> { 
<token> "Clock mode: master\n"); <answer> snd_iprintf(buffer, 
<token> (show_auto_sync_source) { <answer> if 
switch (rme9652->control_register <token> RME9652_SyncPref_Mask) { <answer> & 
<token> RME9652_SyncPref_ADAT1: <answer> case 
<token> "Pref. sync source: ADAT1\n"); <answer> snd_iprintf(buffer, 
case <token> <answer> RME9652_SyncPref_ADAT2: 
snd_iprintf(buffer, "Pref. sync <token> ADAT2\n"); <answer> source: 
<token> RME9652_SyncPref_ADAT3: <answer> case 
snd_iprintf(buffer, <token> sync source: ADAT3\n"); <answer> "Pref. 
case <token> <answer> RME9652_SyncPref_SPDIF: 
snd_iprintf(buffer, "Pref. sync <token> IEC958\n"); <answer> source: 
snd_iprintf(buffer, <token> sync source: ???\n"); <answer> "Pref. 
if <token> >= 15) <answer> (rme9652->hw_rev 
snd_iprintf(buffer, "\nADAT1 Input <token> %s\n", <answer> source: 
(rme9652->control_register & RME9652_ADAT1_INTERNAL) <token> <answer> ? 
"Internal" <token> "ADAT1 optical"); <answer> : 
<token> "\n"); <answer> snd_iprintf(buffer, 
switch (rme9652_decode_spdif_in(rme9652->control_register <token> <answer> & 
<token> { <answer> RME9652_inp)) 
<token> RME9652_SPDIFIN_OPTICAL: <answer> case 
snd_iprintf(buffer, "IEC958 <token> ADAT1\n"); <answer> input: 
<token> RME9652_SPDIFIN_COAXIAL: <answer> case 
<token> "IEC958 input: Coaxial\n"); <answer> snd_iprintf(buffer, 
case <token> <answer> RME9652_SPDIFIN_INTERN: 
snd_iprintf(buffer, "IEC958 input: <token> <answer> Internal\n"); 
<token> "IEC958 input: ???\n"); <answer> snd_iprintf(buffer, 
if (rme9652->control_register <token> RME9652_opt_out) { <answer> & 
snd_iprintf(buffer, "IEC958 output: <token> & ADAT1\n"); <answer> Coaxial 
} <token> { <answer> else 
snd_iprintf(buffer, <token> output: Coaxial only\n"); <answer> "IEC958 
<token> (rme9652->control_register & RME9652_PRO) { <answer> if 
snd_iprintf(buffer, <token> quality: Professional\n"); <answer> "IEC958 
<token> else { <answer> } 
snd_iprintf(buffer, "IEC958 quality: <token> <answer> Consumer\n"); 
if <token> & RME9652_EMP) { <answer> (rme9652->control_register 
snd_iprintf(buffer, "IEC958 emphasis: <token> <answer> on\n"); 
<token> else { <answer> } 
snd_iprintf(buffer, "IEC958 <token> off\n"); <answer> emphasis: 
<token> (rme9652->control_register & RME9652_Dolby) { <answer> if 
<token> "IEC958 Dolby: on\n"); <answer> snd_iprintf(buffer, 
} <token> { <answer> else 
snd_iprintf(buffer, "IEC958 <token> off\n"); <answer> Dolby: 
<token> = rme9652_spdif_sample_rate(rme9652); <answer> i 
if (i < <token> { <answer> 0) 
"IEC958 <token> rate: error flag set\n"); <answer> sample 
} else if <token> == 0) { <answer> (i 
snd_iprintf(buffer, <token> sample rate: undetermined\n"); <answer> "IEC958 
} <token> { <answer> else 
snd_iprintf(buffer, "IEC958 sample rate: <token> i); <answer> %d\n", 
snd_iprintf(buffer, <token> <answer> "\n"); 
snd_iprintf(buffer, <token> Sample rate: %dHz\n", <answer> "ADAT 
<token> = <answer> rme9652->control_register 
<token> | rme9652_encode_latency(7); <answer> RME9652_inp_0 
<token> RME9652_control_register, rme9652->control_register); <answer> rme9652_write(rme9652, 
if <token> != <answer> ((int)params_rate(params) 
<token> { <answer> rme9652_adat_sample_rate(rme9652)) 
<token> SNDRV_PCM_HW_PARAM_RATE); <answer> _snd_pcm_hw_param_setempty(params, 
return <token> <answer> -EBUSY; 
if (params_period_size(params) != rme9652->period_bytes / 4) <token> <answer> { 
<token> SNDRV_PCM_HW_PARAM_PERIOD_SIZE); <answer> _snd_pcm_hw_param_setempty(params, 
<token> -EBUSY; <answer> return 
<token> = rme9652_set_rate(rme9652, params_rate(params)); <answer> err 
if (err < 0) <token> <answer> { 
<token> SNDRV_PCM_HW_PARAM_RATE); <answer> _snd_pcm_hw_param_setempty(params, 
<token> err; <answer> return 
err <token> rme9652_set_interrupt_interval(rme9652, params_period_size(params)); <answer> = 
if (err < 0) <token> <answer> { 
_snd_pcm_hw_param_setempty(params, <token> <answer> SNDRV_PCM_HW_PARAM_PERIOD_SIZE); 
return <token> <answer> err; 
return <token> <answer> 0; 
static int snd_rme9652_channel_info(struct snd_pcm_substream <token> <answer> *substream, 
struct snd_pcm_channel_info <token> <answer> *info) 
struct <token> *rme9652 = snd_pcm_substream_chip(substream); <answer> snd_rme9652 
int <token> <answer> chn; 
if <token> >= RME9652_NCHANNELS)) <answer> (snd_BUG_ON(info->channel 
<token> -EINVAL; <answer> return 
<token> = rme9652->channel_map[array_index_nospec(info->channel, <answer> chn 
if (chn <token> 0) <answer> < 
return <token> <answer> -EINVAL; 
info->offset = chn <token> RME9652_CHANNEL_BUFFER_BYTES; <answer> * 
<token> = 0; <answer> info->first 
<token> = 32; <answer> info->step 
<token> 0; <answer> return 
static int snd_rme9652_ioctl(struct <token> *substream, <answer> snd_pcm_substream 
unsigned int cmd, void <token> <answer> *arg) 
switch (cmd) <token> <answer> { 
<token> SNDRV_PCM_IOCTL1_RESET: <answer> case 
<token> snd_rme9652_reset(substream); <answer> return 
case <token> <answer> SNDRV_PCM_IOCTL1_CHANNEL_INFO: 
struct snd_pcm_channel_info *info = <token> <answer> arg; 
return <token> info); <answer> snd_rme9652_channel_info(substream, 
<token> snd_pcm_lib_ioctl(substream, cmd, arg); <answer> return 
<token> void rme9652_silence_playback(struct snd_rme9652 *rme9652) <answer> static 
<token> 0, RME9652_DMA_AREA_BYTES); <answer> memset(rme9652->playback_buffer, 
static int <token> snd_pcm_substream *substream, <answer> snd_rme9652_trigger(struct 
<token> cmd) <answer> int 
<token> snd_rme9652 *rme9652 = snd_pcm_substream_chip(substream); <answer> struct 
struct <token> *other; <answer> snd_pcm_substream 
int <token> <answer> running; 
running = <token> <answer> rme9652->running; 
switch <token> { <answer> (cmd) 
case <token> <answer> SNDRV_PCM_TRIGGER_START: 
running |= <token> << substream->stream; <answer> 1 
<token> SNDRV_PCM_TRIGGER_STOP: <answer> case 
running <token> ~(1 << substream->stream); <answer> &= 
<token> -EINVAL; <answer> return 
if (substream->stream == <token> <answer> SNDRV_PCM_STREAM_PLAYBACK) 
other = <token> <answer> rme9652->capture_substream; 
other <token> rme9652->playback_substream; <answer> = 
if <token> { <answer> (other) 
struct <token> *s; <answer> snd_pcm_substream 
snd_pcm_group_for_each_entry(s, substream) <token> <answer> { 
if (s <token> other) { <answer> == 
<token> substream); <answer> snd_pcm_trigger_done(s, 
<token> (cmd == SNDRV_PCM_TRIGGER_START) <answer> if 
running <token> 1 << s->stream; <answer> |= 
running &= <token> << s->stream); <answer> ~(1 
<token> _ok; <answer> goto 
if <token> == SNDRV_PCM_TRIGGER_START) { <answer> (cmd 
if (!(running & (1 << <token> && <answer> SNDRV_PCM_STREAM_PLAYBACK)) 
substream->stream == <token> <answer> SNDRV_PCM_STREAM_CAPTURE) 
} <token> { <answer> else 
<token> (running && <answer> if 
substream->stream == <token> <answer> SNDRV_PCM_STREAM_PLAYBACK) 
<token> else { <answer> } 
if (substream->stream == <token> <answer> SNDRV_PCM_STREAM_CAPTURE) 
snd_pcm_trigger_done(substream, <token> <answer> substream); 
if (!rme9652->running <token> running) <answer> && 
<token> if (rme9652->running && !running) <answer> else 
<token> = running; <answer> rme9652->running 
return <token> <answer> 0; 
static int snd_rme9652_prepare(struct <token> *substream) <answer> snd_pcm_substream 
struct snd_rme9652 <token> = snd_pcm_substream_chip(substream); <answer> *rme9652 
unsigned <token> flags; <answer> long 
spin_lock_irqsave(&rme9652->lock, <token> <answer> flags); 
if <token> <answer> (!rme9652->running) 
spin_unlock_irqrestore(&rme9652->lock, <token> <answer> flags); 
return <token> <answer> 0; 
static const <token> snd_pcm_hardware snd_rme9652_playback_subinfo = <answer> struct 
.info = <token> | <answer> (SNDRV_PCM_INFO_MMAP 
SNDRV_PCM_INFO_MMAP_VALID <token> <answer> | 
SNDRV_PCM_INFO_NONINTERLEAVED <token> <answer> | 
SNDRV_PCM_INFO_SYNC_START <token> <answer> | 
<token> = SNDRV_PCM_FMTBIT_S32_LE, <answer> .formats 
.rates = <token> | <answer> (SNDRV_PCM_RATE_44100 
<token> | <answer> SNDRV_PCM_RATE_48000 
SNDRV_PCM_RATE_88200 <token> <answer> | 
<token> = 44100, <answer> .rate_min 
.rate_max <token> 96000, <answer> = 
.channels_min <token> 10, <answer> = 
.channels_max <token> 26, <answer> = 
.buffer_bytes_max <token> RME9652_CHANNEL_BUFFER_BYTES * 26, <answer> = 
.period_bytes_min = (64 * 4) * <token> <answer> 10, 
.period_bytes_max = (8192 * 4) <token> 26, <answer> * 
.periods_min = <token> <answer> 2, 
<token> = 2, <answer> .periods_max 
<token> = 0, <answer> .fifo_size 
static const struct <token> snd_rme9652_capture_subinfo = <answer> snd_pcm_hardware 
.info = (SNDRV_PCM_INFO_MMAP <token> <answer> | 
SNDRV_PCM_INFO_MMAP_VALID <token> <answer> | 
SNDRV_PCM_INFO_NONINTERLEAVED <token> <answer> | 
.formats = <token> <answer> SNDRV_PCM_FMTBIT_S32_LE, 
.rates <token> (SNDRV_PCM_RATE_44100 | <answer> = 
<token> | <answer> SNDRV_PCM_RATE_48000 
<token> | <answer> SNDRV_PCM_RATE_88200 
.rate_min = <token> <answer> 44100, 
.rate_max <token> 96000, <answer> = 
<token> = 10, <answer> .channels_min 
.channels_max <token> 26, <answer> = 
.buffer_bytes_max <token> RME9652_CHANNEL_BUFFER_BYTES *26, <answer> = 
.period_bytes_min <token> (64 * 4) * 10, <answer> = 
.period_bytes_max = (8192 * <token> * 26, <answer> 4) 
<token> = 2, <answer> .periods_min 
<token> = 2, <answer> .periods_max 
.fifo_size <token> 0, <answer> = 
static const unsigned int period_sizes[] = { 64, 128, 256, 512, 1024, 2048, <token> 8192 }; <answer> 4096, 
static const <token> snd_pcm_hw_constraint_list hw_constraints_period_sizes = { <answer> struct 
.count = <token> <answer> ARRAY_SIZE(period_sizes), 
<token> = period_sizes, <answer> .list 
.mask <token> 0 <answer> = 
static int snd_rme9652_hw_rule_channels(struct snd_pcm_hw_params <token> <answer> *params, 
<token> snd_pcm_hw_rule *rule) <answer> struct 
<token> snd_rme9652 *rme9652 = rule->private; <answer> struct 
struct <token> *c = hw_param_interval(params, SNDRV_PCM_HW_PARAM_CHANNELS); <answer> snd_interval 
unsigned int list[2] = <token> rme9652->ds_channels, rme9652->ss_channels }; <answer> { 
return snd_interval_list(c, <token> list, 0); <answer> 2, 
static int snd_rme9652_hw_rule_channels_rate(struct <token> *params, <answer> snd_pcm_hw_params 
struct <token> *rule) <answer> snd_pcm_hw_rule 
struct snd_rme9652 *rme9652 <token> rule->private; <answer> = 
struct <token> *c = hw_param_interval(params, SNDRV_PCM_HW_PARAM_CHANNELS); <answer> snd_interval 
struct snd_interval <token> = hw_param_interval(params, SNDRV_PCM_HW_PARAM_RATE); <answer> *r 
if (r->min <token> 48000) { <answer> > 
struct snd_interval t <token> { <answer> = 
.min <token> rme9652->ds_channels, <answer> = 
<token> = rme9652->ds_channels, <answer> .max 
.integer <token> 1, <answer> = 
return snd_interval_refine(c, <token> <answer> &t); 
<token> else if (r->max < 88200) { <answer> } 
struct snd_interval t = <token> <answer> { 
.min <token> rme9652->ss_channels, <answer> = 
<token> = rme9652->ss_channels, <answer> .max 
.integer <token> 1, <answer> = 
return <token> &t); <answer> snd_interval_refine(c, 
<token> 0; <answer> return 
static <token> snd_rme9652_hw_rule_rate_channels(struct snd_pcm_hw_params *params, <answer> int 
struct <token> *rule) <answer> snd_pcm_hw_rule 
<token> snd_rme9652 *rme9652 = rule->private; <answer> struct 
struct snd_interval *c <token> hw_param_interval(params, SNDRV_PCM_HW_PARAM_CHANNELS); <answer> = 
struct snd_interval *r = hw_param_interval(params, <token> <answer> SNDRV_PCM_HW_PARAM_RATE); 
<token> (c->min >= rme9652->ss_channels) { <answer> if 
struct snd_interval t <token> { <answer> = 
.min <token> 44100, <answer> = 
<token> = 48000, <answer> .max 
.integer <token> 1, <answer> = 
return snd_interval_refine(r, <token> <answer> &t); 
} else <token> (c->max <= rme9652->ds_channels) { <answer> if 
struct snd_interval <token> = { <answer> t 
.min <token> 88200, <answer> = 
.max <token> 96000, <answer> = 
.integer = <token> <answer> 1, 
return snd_interval_refine(r, <token> <answer> &t); 
<token> 0; <answer> return 
static int snd_rme9652_playback_open(struct <token> *substream) <answer> snd_pcm_substream 
struct snd_rme9652 *rme9652 <token> snd_pcm_substream_chip(substream); <answer> = 
struct snd_pcm_runtime <token> = substream->runtime; <answer> *runtime 
runtime->hw <token> snd_rme9652_playback_subinfo; <answer> = 
snd_pcm_set_runtime_buffer(substream, <token> <answer> &rme9652->playback_dma_buf); 
if (rme9652->capture_substream == NULL) <token> <answer> { 
<token> -1, 0); <answer> rme9652_set_thru(rme9652, 
rme9652->playback_pid = <token> <answer> current->pid; 
rme9652->playback_substream = <token> <answer> substream; 
snd_pcm_hw_constraint_msbits(runtime, <token> 32, 24); <answer> 0, 
snd_pcm_hw_constraint_list(runtime, 0, <token> &hw_constraints_period_sizes); <answer> SNDRV_PCM_HW_PARAM_PERIOD_SIZE, 
<token> 0, SNDRV_PCM_HW_PARAM_CHANNELS, <answer> snd_pcm_hw_rule_add(runtime, 
<token> rme9652, <answer> snd_rme9652_hw_rule_channels, 
SNDRV_PCM_HW_PARAM_CHANNELS, <token> <answer> -1); 
snd_pcm_hw_rule_add(runtime, 0, <token> <answer> SNDRV_PCM_HW_PARAM_CHANNELS, 
<token> rme9652, <answer> snd_rme9652_hw_rule_channels_rate, 
<token> -1); <answer> SNDRV_PCM_HW_PARAM_RATE, 
snd_pcm_hw_rule_add(runtime, <token> SNDRV_PCM_HW_PARAM_RATE, <answer> 0, 
<token> rme9652, <answer> snd_rme9652_hw_rule_rate_channels, 
SNDRV_PCM_HW_PARAM_CHANNELS, <token> <answer> -1); 
<token> = rme9652->creg_spdif; <answer> rme9652->creg_spdif_stream 
<token> &= ~SNDRV_CTL_ELEM_ACCESS_INACTIVE; <answer> rme9652->spdif_ctl->vd[0].access 
<token> SNDRV_CTL_EVENT_MASK_VALUE | <answer> snd_ctl_notify(rme9652->card, 
<token> &rme9652->spdif_ctl->id); <answer> SNDRV_CTL_EVENT_MASK_INFO, 
return <token> <answer> 0; 
static int <token> snd_pcm_substream *substream) <answer> snd_rme9652_playback_release(struct 
struct snd_rme9652 *rme9652 <token> snd_pcm_substream_chip(substream); <answer> = 
rme9652->playback_pid = <token> <answer> -1; 
rme9652->playback_substream = <token> <answer> NULL; 
rme9652->spdif_ctl->vd[0].access |= <token> <answer> SNDRV_CTL_ELEM_ACCESS_INACTIVE; 
snd_ctl_notify(rme9652->card, SNDRV_CTL_EVENT_MASK_VALUE <token> <answer> | 
SNDRV_CTL_EVENT_MASK_INFO, <token> <answer> &rme9652->spdif_ctl->id); 
<token> 0; <answer> return 
static int <token> snd_pcm_substream *substream) <answer> snd_rme9652_capture_open(struct 
struct snd_rme9652 <token> = snd_pcm_substream_chip(substream); <answer> *rme9652 
struct snd_pcm_runtime *runtime <token> substream->runtime; <answer> = 
<token> = snd_rme9652_capture_subinfo; <answer> runtime->hw 
snd_pcm_set_runtime_buffer(substream, <token> <answer> &rme9652->capture_dma_buf); 
if (rme9652->playback_substream == <token> { <answer> NULL) 
rme9652_set_thru(rme9652, <token> 0); <answer> -1, 
rme9652->capture_pid = <token> <answer> current->pid; 
rme9652->capture_substream <token> substream; <answer> = 
snd_pcm_hw_constraint_msbits(runtime, 0, 32, <token> <answer> 24); 
snd_pcm_hw_constraint_list(runtime, 0, SNDRV_PCM_HW_PARAM_PERIOD_SIZE, <token> <answer> &hw_constraints_period_sizes); 
<token> 0, SNDRV_PCM_HW_PARAM_CHANNELS, <answer> snd_pcm_hw_rule_add(runtime, 
snd_rme9652_hw_rule_channels, <token> <answer> rme9652, 
SNDRV_PCM_HW_PARAM_CHANNELS, <token> <answer> -1); 
<token> 0, SNDRV_PCM_HW_PARAM_CHANNELS, <answer> snd_pcm_hw_rule_add(runtime, 
snd_rme9652_hw_rule_channels_rate, <token> <answer> rme9652, 
SNDRV_PCM_HW_PARAM_RATE, <token> <answer> -1); 
snd_pcm_hw_rule_add(runtime, <token> SNDRV_PCM_HW_PARAM_RATE, <answer> 0, 
snd_rme9652_hw_rule_rate_channels, <token> <answer> rme9652, 
SNDRV_PCM_HW_PARAM_CHANNELS, <token> <answer> -1); 
<token> 0; <answer> return 
static int <token> snd_pcm_substream *substream) <answer> snd_rme9652_capture_release(struct 
<token> snd_rme9652 *rme9652 = snd_pcm_substream_chip(substream); <answer> struct 
rme9652->capture_pid <token> -1; <answer> = 
rme9652->capture_substream <token> NULL; <answer> = 
return <token> <answer> 0; 
static <token> struct snd_pcm_ops snd_rme9652_playback_ops = { <answer> const 
<token> = snd_rme9652_playback_open, <answer> .open 
<token> = snd_rme9652_playback_release, <answer> .close 
.ioctl = <token> <answer> snd_rme9652_ioctl, 
.hw_params = <token> <answer> snd_rme9652_hw_params, 
<token> = snd_rme9652_prepare, <answer> .prepare 
.trigger = <token> <answer> snd_rme9652_trigger, 
<token> = snd_rme9652_hw_pointer, <answer> .pointer 
.copy <token> snd_rme9652_playback_copy, <answer> = 
<token> = snd_rme9652_hw_silence, <answer> .fill_silence 
static const struct <token> snd_rme9652_capture_ops = { <answer> snd_pcm_ops 
<token> = snd_rme9652_capture_open, <answer> .open 
.close <token> snd_rme9652_capture_release, <answer> = 
.ioctl = <token> <answer> snd_rme9652_ioctl, 
<token> = snd_rme9652_hw_params, <answer> .hw_params 
<token> = snd_rme9652_prepare, <answer> .prepare 
.trigger <token> snd_rme9652_trigger, <answer> = 
.pointer = <token> <answer> snd_rme9652_hw_pointer, 
.copy <token> snd_rme9652_capture_copy, <answer> = 
static int <token> snd_card *card, <answer> snd_rme9652_create_pcm(struct 
struct snd_rme9652 <token> <answer> *rme9652) 
struct <token> *pcm; <answer> snd_pcm 
int <token> <answer> err; 
err = snd_pcm_new(card, rme9652->card_name, 0, 1, <token> &pcm); <answer> 1, 
<token> (err < 0) <answer> if 
return <token> <answer> err; 
rme9652->pcm <token> pcm; <answer> = 
pcm->private_data = <token> <answer> rme9652; 
<token> rme9652->card_name); <answer> strcpy(pcm->name, 
<token> SNDRV_PCM_STREAM_PLAYBACK, &snd_rme9652_playback_ops); <answer> snd_pcm_set_ops(pcm, 
snd_pcm_set_ops(pcm, <token> &snd_rme9652_capture_ops); <answer> SNDRV_PCM_STREAM_CAPTURE, 
pcm->info_flags = <token> <answer> SNDRV_PCM_INFO_JOINT_DUPLEX; 
<token> 0; <answer> return 
static int snd_rme9652_create(struct <token> *card, <answer> snd_card 
struct <token> *rme9652, <answer> snd_rme9652 
<token> precise_ptr) <answer> int 
struct pci_dev *pci <token> rme9652->pci; <answer> = 
<token> err; <answer> int 
int <token> <answer> status; 
unsigned <token> rev; <answer> short 
rme9652->irq = <token> <answer> -1; 
rme9652->card = <token> <answer> card; 
pci_read_config_word(rme9652->pci, <token> &rev); <answer> PCI_CLASS_REVISION, 
switch (rev & <token> { <answer> 0xff) 
case <token> <answer> 3: 
<token> 4: <answer> case 
<token> 8: <answer> case 
case <token> <answer> 9: 
status <token> rme9652_read(rme9652, RME9652_status_register); <answer> = 
<token> (rme9652_decode_spdif_rate(status&RME9652_F) == 1) { <answer> if 
<token> = 15; <answer> rme9652->hw_rev 
} <token> { <answer> else 
rme9652->hw_rev = <token> <answer> 11; 
<token> (rev) { <answer> switch 
#include <token> <answer> <signal.h> 
<token> <ucontext.h> <answer> #include 
#include <token> <answer> <sys/prctl.h> 
<token> "test_signals_utils.h" <answer> #include 
#include <token> <answer> "testcases.h" 
static <token> { <answer> union 
ucontext_t <token> <answer> uc; 
char buf[1024 <token> 64]; <answer> * 
<token> context; <answer> } 
static <token> int vls[SVE_VQ_MAX]; <answer> unsigned 
unsigned int <token> = 0; <answer> nvls 
static bool <token> tdescr *td) <answer> sme_get_vls(struct 
<token> vq, vl; <answer> int 
for (vq = SVE_VQ_MAX; vq > 0; <token> { <answer> --vq) 
vl = prctl(PR_SME_SET_VL, vq * <token> <answer> 16); 
<token> (vl == -1) <answer> if 
return <token> <answer> false; 
<token> &= PR_SME_VL_LEN_MASK; <answer> vl 
if (!get_current_context(td, <token> sizeof(context))) <answer> &context.uc, 
<token> 1; <answer> return 
head <token> get_header(head, SVE_MAGIC, GET_BUF_RESV_SIZE(context), <answer> = 
if (!head) <token> <answer> { 
fprintf(stderr, "No <token> context\n"); <answer> SVE 
<token> 1; <answer> return 
ssve = (struct sve_context <token> <answer> *)head; 
if <token> != vl) { <answer> (ssve->vl 
<token> "Got VL %d, expected %d\n", ssve->vl, vl); <answer> fprintf(stderr, 
return <token> <answer> 1; 
if (!(ssve->flags & <token> { <answer> SVE_SIG_FLAG_SM)) 
fprintf(stderr, "SVE_SIG_FLAG_SM not set <token> SVE record\n"); <answer> in 
<token> 1; <answer> return 
#define <token> "rtas: " fmt <answer> pr_fmt(fmt) 
<token> <linux/bsearch.h> <answer> #include 
<token> <linux/capability.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/export.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
<token> <linux/kconfig.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/lockdep.h> <answer> #include 
<token> <linux/memblock.h> <answer> #include 
#include <token> <answer> <linux/mutex.h> 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_fdt.h> <answer> #include 
<token> <linux/reboot.h> <answer> #include 
<token> <linux/sched.h> <answer> #include 
#include <token> <answer> <linux/security.h> 
<token> <linux/slab.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/stdarg.h> <answer> #include 
<token> <linux/syscalls.h> <answer> #include 
<token> <linux/types.h> <answer> #include 
#include <token> <answer> <linux/uaccess.h> 
#include <token> <answer> <linux/xarray.h> 
<token> <asm/delay.h> <answer> #include 
#include <token> <answer> <asm/firmware.h> 
#include <token> <answer> <asm/interrupt.h> 
#include <token> <answer> <asm/machdep.h> 
#include <token> <answer> <asm/mmu.h> 
<token> <asm/page.h> <answer> #include 
#include <token> <answer> <asm/rtas-work-area.h> 
<token> <asm/rtas.h> <answer> #include 
<token> <asm/time.h> <answer> #include 
#include <token> <answer> <asm/trace.h> 
<token> <asm/udbg.h> <answer> #include 
struct rtas_filter <token> <answer> { 
const int <token> <answer> fixed_size; 
struct rtas_function <token> <answer> { 
<token> token; <answer> s32 
const bool <token> <answer> banned_for_syscall_on_le:1; 
const char * <token> name; <answer> const 
const <token> rtas_filter *filter; <answer> struct 
struct mutex <token> <answer> *lock; 
<token> DEFINE_MUTEX(rtas_ibm_activate_firmware_lock); <answer> static 
<token> DEFINE_MUTEX(rtas_ibm_get_dynamic_sensor_state_lock); <answer> static 
<token> DEFINE_MUTEX(rtas_ibm_get_indices_lock); <answer> static 
static <token> <answer> DEFINE_MUTEX(rtas_ibm_lpar_perftools_lock); 
static <token> <answer> DEFINE_MUTEX(rtas_ibm_physical_attestation_lock); 
<token> DEFINE_MUTEX(rtas_ibm_set_dynamic_indicator_lock); <answer> static 
<token> struct rtas_function rtas_function_table[] __ro_after_init = { <answer> static 
<token> = { <answer> [RTAS_FNIDX__CHECK_EXCEPTION] 
.name = <token> <answer> "check-exception", 
[RTAS_FNIDX__DISPLAY_CHARACTER] <token> { <answer> = 
.name = <token> <answer> "display-character", 
.filter = <token> struct rtas_filter) { <answer> &(const 
.buf_idx1 = -1, .size_idx1 <token> -1, <answer> = 
.buf_idx2 = -1, .size_idx2 <token> -1, <answer> = 
<token> = { <answer> [RTAS_FNIDX__EVENT_SCAN] 
.name <token> "event-scan", <answer> = 
[RTAS_FNIDX__FREEZE_TIME_BASE] = <token> <answer> { 
<token> = "freeze-time-base", <answer> .name 
<token> = { <answer> [RTAS_FNIDX__GET_POWER_LEVEL] 
.name = <token> <answer> "get-power-level", 
.filter <token> &(const struct rtas_filter) { <answer> = 
.buf_idx1 = <token> .size_idx1 = -1, <answer> -1, 
.buf_idx2 = -1, <token> = -1, <answer> .size_idx2 
<token> = { <answer> [RTAS_FNIDX__GET_SENSOR_STATE] 
.name = <token> <answer> "get-sensor-state", 
.filter = &(const struct <token> { <answer> rtas_filter) 
.buf_idx1 <token> -1, .size_idx1 = -1, <answer> = 
.buf_idx2 = <token> .size_idx2 = -1, <answer> -1, 
[RTAS_FNIDX__GET_TERM_CHAR] = <token> <answer> { 
.name = <token> <answer> "get-term-char", 
[RTAS_FNIDX__GET_TIME_OF_DAY] <token> { <answer> = 
.name <token> "get-time-of-day", <answer> = 
.filter = &(const <token> rtas_filter) { <answer> struct 
<token> = -1, .size_idx1 = -1, <answer> .buf_idx1 
.buf_idx2 = -1, <token> = -1, <answer> .size_idx2 
[RTAS_FNIDX__IBM_ACTIVATE_FIRMWARE] = <token> <answer> { 
.name = <token> <answer> "ibm,activate-firmware", 
.filter <token> &(const struct rtas_filter) { <answer> = 
.buf_idx1 = -1, .size_idx1 = <token> <answer> -1, 
<token> = -1, .size_idx2 = -1, <answer> .buf_idx2 
<token> = &rtas_ibm_activate_firmware_lock, <answer> .lock 
[RTAS_FNIDX__IBM_CBE_START_PTCAL] = <token> <answer> { 
.name = <token> <answer> "ibm,cbe-start-ptcal", 
<token> = { <answer> [RTAS_FNIDX__IBM_CBE_STOP_PTCAL] 
.name = <token> <answer> "ibm,cbe-stop-ptcal", 
[RTAS_FNIDX__IBM_CHANGE_MSI] <token> { <answer> = 
.name <token> "ibm,change-msi", <answer> = 
<token> = { <answer> [RTAS_FNIDX__IBM_CLOSE_ERRINJCT] 
.name = <token> <answer> "ibm,close-errinjct", 
.filter = &(const struct <token> { <answer> rtas_filter) 
.buf_idx1 = -1, .size_idx1 <token> -1, <answer> = 
.buf_idx2 = -1, .size_idx2 <token> -1, <answer> = 
[RTAS_FNIDX__IBM_CONFIGURE_BRIDGE] = <token> <answer> { 
.name <token> "ibm,configure-bridge", <answer> = 
<token> = { <answer> [RTAS_FNIDX__IBM_CONFIGURE_CONNECTOR] 
<token> = "ibm,configure-connector", <answer> .name 
.filter = &(const <token> rtas_filter) { <answer> struct 
.buf_idx1 = 0, .size_idx1 = <token> <answer> -1, 
.buf_idx2 <token> 1, .size_idx2 = -1, <answer> = 
<token> = 4096, <answer> .fixed_size 
<token> = { <answer> [RTAS_FNIDX__IBM_CONFIGURE_KERNEL_DUMP] 
.name <token> "ibm,configure-kernel-dump", <answer> = 
<token> = { <answer> [RTAS_FNIDX__IBM_CONFIGURE_PE] 
.name <token> "ibm,configure-pe", <answer> = 
<token> = { <answer> [RTAS_FNIDX__IBM_CREATE_PE_DMA_WINDOW] 
<token> = "ibm,create-pe-dma-window", <answer> .name 
<token> = { <answer> [RTAS_FNIDX__IBM_DISPLAY_MESSAGE] 
.name <token> "ibm,display-message", <answer> = 
.filter = &(const struct rtas_filter) <token> <answer> { 
.buf_idx1 = 0, .size_idx1 <token> -1, <answer> = 
.buf_idx2 <token> -1, .size_idx2 = -1, <answer> = 
<token> = { <answer> [RTAS_FNIDX__IBM_ERRINJCT] 
.name <token> "ibm,errinjct", <answer> = 
.filter = &(const <token> rtas_filter) { <answer> struct 
<token> = 2, .size_idx1 = -1, <answer> .buf_idx1 
.buf_idx2 = -1, <token> = -1, <answer> .size_idx2 
.fixed_size = <token> <answer> 1024, 
[RTAS_FNIDX__IBM_EXTI2C] = <token> <answer> { 
<token> = "ibm,exti2c", <answer> .name 
[RTAS_FNIDX__IBM_GET_CONFIG_ADDR_INFO] = <token> <answer> { 
.name = <token> <answer> "ibm,get-config-addr-info", 
[RTAS_FNIDX__IBM_GET_CONFIG_ADDR_INFO2] = <token> <answer> { 
.name = <token> <answer> "ibm,get-config-addr-info2", 
.filter = &(const struct rtas_filter) <token> <answer> { 
.buf_idx1 = -1, .size_idx1 = <token> <answer> -1, 
<token> = -1, .size_idx2 = -1, <answer> .buf_idx2 
<token> = { <answer> [RTAS_FNIDX__IBM_GET_DYNAMIC_SENSOR_STATE] 
.name <token> "ibm,get-dynamic-sensor-state", <answer> = 
.filter = &(const struct rtas_filter) <token> <answer> { 
.buf_idx1 = <token> .size_idx1 = -1, <answer> 1, 
<token> = -1, .size_idx2 = -1, <answer> .buf_idx2 
.lock <token> &rtas_ibm_get_dynamic_sensor_state_lock, <answer> = 
[RTAS_FNIDX__IBM_GET_INDICES] <token> { <answer> = 
<token> = "ibm,get-indices", <answer> .name 
.filter = <token> struct rtas_filter) { <answer> &(const 
.buf_idx1 = 2, .size_idx1 = <token> <answer> 3, 
.buf_idx2 = -1, .size_idx2 <token> -1, <answer> = 
.lock <token> &rtas_ibm_get_indices_lock, <answer> = 
[RTAS_FNIDX__IBM_GET_RIO_TOPOLOGY] = <token> <answer> { 
<token> = "ibm,get-rio-topology", <answer> .name 
[RTAS_FNIDX__IBM_GET_SYSTEM_PARAMETER] <token> { <answer> = 
<token> = "ibm,get-system-parameter", <answer> .name 
.filter = &(const struct rtas_filter) <token> <answer> { 
<token> = 1, .size_idx1 = 2, <answer> .buf_idx1 
<token> = -1, .size_idx2 = -1, <answer> .buf_idx2 
[RTAS_FNIDX__IBM_GET_VPD] <token> { <answer> = 
<token> = "ibm,get-vpd", <answer> .name 
.filter = &(const struct <token> { <answer> rtas_filter) 
.buf_idx1 = 0, .size_idx1 <token> -1, <answer> = 
<token> = 1, .size_idx2 = 2, <answer> .buf_idx2 
<token> = &rtas_ibm_get_vpd_lock, <answer> .lock 
<token> = { <answer> [RTAS_FNIDX__IBM_GET_XIVE] 
.name <token> "ibm,get-xive", <answer> = 
[RTAS_FNIDX__IBM_INT_OFF] <token> { <answer> = 
<token> = "ibm,int-off", <answer> .name 
[RTAS_FNIDX__IBM_INT_ON] <token> { <answer> = 
.name <token> "ibm,int-on", <answer> = 
[RTAS_FNIDX__IBM_IO_QUIESCE_ACK] = <token> <answer> { 
.name <token> "ibm,io-quiesce-ack", <answer> = 
<token> = { <answer> [RTAS_FNIDX__IBM_LPAR_PERFTOOLS] 
.name = <token> <answer> "ibm,lpar-perftools", 
.filter = &(const struct rtas_filter) <token> <answer> { 
<token> = 2, .size_idx1 = 3, <answer> .buf_idx1 
.buf_idx2 = -1, .size_idx2 <token> -1, <answer> = 
<token> = &rtas_ibm_lpar_perftools_lock, <answer> .lock 
[RTAS_FNIDX__IBM_MANAGE_FLASH_IMAGE] <token> { <answer> = 
<token> = "ibm,manage-flash-image", <answer> .name 
<token> = { <answer> [RTAS_FNIDX__IBM_MANAGE_STORAGE_PRESERVATION] 
.name <token> "ibm,manage-storage-preservation", <answer> = 
[RTAS_FNIDX__IBM_NMI_INTERLOCK] <token> { <answer> = 
<token> = "ibm,nmi-interlock", <answer> .name 
<token> = { <answer> [RTAS_FNIDX__IBM_NMI_REGISTER] 
.name = <token> <answer> "ibm,nmi-register", 
[RTAS_FNIDX__IBM_OPEN_ERRINJCT] <token> { <answer> = 
.name = <token> <answer> "ibm,open-errinjct", 
.filter = &(const <token> rtas_filter) { <answer> struct 
<token> = -1, .size_idx1 = -1, <answer> .buf_idx1 
.buf_idx2 = <token> .size_idx2 = -1, <answer> -1, 
[RTAS_FNIDX__IBM_OPEN_SRIOV_ALLOW_UNFREEZE] = <token> <answer> { 
<token> = "ibm,open-sriov-allow-unfreeze", <answer> .name 
<token> = { <answer> [RTAS_FNIDX__IBM_OPEN_SRIOV_MAP_PE_NUMBER] 
<token> = "ibm,open-sriov-map-pe-number", <answer> .name 
[RTAS_FNIDX__IBM_OS_TERM] <token> { <answer> = 
.name = <token> <answer> "ibm,os-term", 
[RTAS_FNIDX__IBM_PARTNER_CONTROL] <token> { <answer> = 
.name <token> "ibm,partner-control", <answer> = 
[RTAS_FNIDX__IBM_PHYSICAL_ATTESTATION] = <token> <answer> { 
.name <token> "ibm,physical-attestation", <answer> = 
.filter = &(const struct rtas_filter) <token> <answer> { 
.buf_idx1 = <token> .size_idx1 = 1, <answer> 0, 
.buf_idx2 <token> -1, .size_idx2 = -1, <answer> = 
.lock = <token> <answer> &rtas_ibm_physical_attestation_lock, 
[RTAS_FNIDX__IBM_PLATFORM_DUMP] = <token> <answer> { 
<token> = "ibm,platform-dump", <answer> .name 
.filter = <token> struct rtas_filter) { <answer> &(const 
.buf_idx1 <token> 4, .size_idx1 = 5, <answer> = 
.buf_idx2 <token> -1, .size_idx2 = -1, <answer> = 
<token> = { <answer> [RTAS_FNIDX__IBM_POWER_OFF_UPS] 
.name = <token> <answer> "ibm,power-off-ups", 
[RTAS_FNIDX__IBM_QUERY_INTERRUPT_SOURCE_NUMBER] = <token> <answer> { 
<token> = "ibm,query-interrupt-source-number", <answer> .name 
<token> = { <answer> [RTAS_FNIDX__IBM_QUERY_PE_DMA_WINDOW] 
<token> = "ibm,query-pe-dma-window", <answer> .name 
[RTAS_FNIDX__IBM_READ_PCI_CONFIG] <token> { <answer> = 
.name = <token> <answer> "ibm,read-pci-config", 
[RTAS_FNIDX__IBM_READ_SLOT_RESET_STATE] = <token> <answer> { 
<token> = "ibm,read-slot-reset-state", <answer> .name 
.filter <token> &(const struct rtas_filter) { <answer> = 
.buf_idx1 <token> -1, .size_idx1 = -1, <answer> = 
<token> = -1, .size_idx2 = -1, <answer> .buf_idx2 
[RTAS_FNIDX__IBM_READ_SLOT_RESET_STATE2] = <token> <answer> { 
.name = <token> <answer> "ibm,read-slot-reset-state2", 
[RTAS_FNIDX__IBM_REMOVE_PE_DMA_WINDOW] = <token> <answer> { 
.name <token> "ibm,remove-pe-dma-window", <answer> = 
[RTAS_FNIDX__IBM_RESET_PE_DMA_WINDOW] = <token> <answer> { 
<token> = "ibm,reset-pe-dma-window", <answer> .name 
[RTAS_FNIDX__IBM_SCAN_LOG_DUMP] = <token> <answer> { 
<token> = "ibm,scan-log-dump", <answer> .name 
.filter <token> &(const struct rtas_filter) { <answer> = 
<token> = 0, .size_idx1 = 1, <answer> .buf_idx1 
.buf_idx2 = -1, .size_idx2 = <token> <answer> -1, 
<token> = { <answer> [RTAS_FNIDX__IBM_SET_DYNAMIC_INDICATOR] 
.name = <token> <answer> "ibm,set-dynamic-indicator", 
.filter = &(const struct <token> { <answer> rtas_filter) 
<token> = 2, .size_idx1 = -1, <answer> .buf_idx1 
<token> = -1, .size_idx2 = -1, <answer> .buf_idx2 
.lock <token> &rtas_ibm_set_dynamic_indicator_lock, <answer> = 
[RTAS_FNIDX__IBM_SET_EEH_OPTION] <token> { <answer> = 
<token> = "ibm,set-eeh-option", <answer> .name 
.filter = &(const <token> rtas_filter) { <answer> struct 
.buf_idx1 <token> -1, .size_idx1 = -1, <answer> = 
.buf_idx2 = -1, <token> = -1, <answer> .size_idx2 
[RTAS_FNIDX__IBM_SET_SLOT_RESET] = <token> <answer> { 
.name = <token> <answer> "ibm,set-slot-reset", 
<token> = { <answer> [RTAS_FNIDX__IBM_SET_SYSTEM_PARAMETER] 
<token> = "ibm,set-system-parameter", <answer> .name 
.filter = <token> struct rtas_filter) { <answer> &(const 
.buf_idx1 = <token> .size_idx1 = -1, <answer> 1, 
<token> = -1, .size_idx2 = -1, <answer> .buf_idx2 
[RTAS_FNIDX__IBM_SET_XIVE] = <token> <answer> { 
.name = <token> <answer> "ibm,set-xive", 
[RTAS_FNIDX__IBM_SLOT_ERROR_DETAIL] <token> { <answer> = 
.name <token> "ibm,slot-error-detail", <answer> = 
<token> = { <answer> [RTAS_FNIDX__IBM_SUSPEND_ME] 
.name <token> "ibm,suspend-me", <answer> = 
<token> = true, <answer> .banned_for_syscall_on_le 
.filter <token> &(const struct rtas_filter) { <answer> = 
.buf_idx1 <token> -1, .size_idx1 = -1, <answer> = 
.buf_idx2 = -1, .size_idx2 <token> -1, <answer> = 
[RTAS_FNIDX__IBM_TUNE_DMA_PARMS] <token> { <answer> = 
<token> = "ibm,tune-dma-parms", <answer> .name 
[RTAS_FNIDX__IBM_UPDATE_FLASH_64_AND_REBOOT] <token> { <answer> = 
.name = <token> <answer> "ibm,update-flash-64-and-reboot", 
[RTAS_FNIDX__IBM_UPDATE_NODES] <token> { <answer> = 
<token> = "ibm,update-nodes", <answer> .name 
<token> = true, <answer> .banned_for_syscall_on_le 
.filter <token> &(const struct rtas_filter) { <answer> = 
.buf_idx1 = <token> .size_idx1 = -1, <answer> 0, 
.buf_idx2 = -1, .size_idx2 <token> -1, <answer> = 
<token> = 4096, <answer> .fixed_size 
[RTAS_FNIDX__IBM_UPDATE_PROPERTIES] = <token> <answer> { 
<token> = "ibm,update-properties", <answer> .name 
.banned_for_syscall_on_le = <token> <answer> true, 
<token> = &(const struct rtas_filter) { <answer> .filter 
.buf_idx1 <token> 0, .size_idx1 = -1, <answer> = 
.buf_idx2 = <token> .size_idx2 = -1, <answer> -1, 
.fixed_size = <token> <answer> 4096, 
<token> = { <answer> [RTAS_FNIDX__IBM_VALIDATE_FLASH_IMAGE] 
.name = <token> <answer> "ibm,validate-flash-image", 
[RTAS_FNIDX__IBM_WRITE_PCI_CONFIG] = <token> <answer> { 
<token> = "ibm,write-pci-config", <answer> .name 
[RTAS_FNIDX__NVRAM_FETCH] <token> { <answer> = 
.name <token> "nvram-fetch", <answer> = 
<token> = { <answer> [RTAS_FNIDX__NVRAM_STORE] 
.name = <token> <answer> "nvram-store", 
[RTAS_FNIDX__POWER_OFF] <token> { <answer> = 
.name = <token> <answer> "power-off", 
<token> = { <answer> [RTAS_FNIDX__PUT_TERM_CHAR] 
<token> = "put-term-char", <answer> .name 
[RTAS_FNIDX__QUERY_CPU_STOPPED_STATE] <token> { <answer> = 
.name = <token> <answer> "query-cpu-stopped-state", 
[RTAS_FNIDX__READ_PCI_CONFIG] = <token> <answer> { 
.name = <token> <answer> "read-pci-config", 
[RTAS_FNIDX__RTAS_LAST_ERROR] = <token> <answer> { 
.name <token> "rtas-last-error", <answer> = 
[RTAS_FNIDX__SET_INDICATOR] <token> { <answer> = 
<token> = "set-indicator", <answer> .name 
<token> = &(const struct rtas_filter) { <answer> .filter 
.buf_idx1 = -1, .size_idx1 <token> -1, <answer> = 
.buf_idx2 = -1, .size_idx2 = <token> <answer> -1, 
[RTAS_FNIDX__SET_POWER_LEVEL] <token> { <answer> = 
<token> = "set-power-level", <answer> .name 
.filter = &(const struct <token> { <answer> rtas_filter) 
<token> = -1, .size_idx1 = -1, <answer> .buf_idx1 
.buf_idx2 = -1, .size_idx2 <token> -1, <answer> = 
[RTAS_FNIDX__SET_TIME_FOR_POWER_ON] = <token> <answer> { 
<token> = "set-time-for-power-on", <answer> .name 
.filter = <token> struct rtas_filter) { <answer> &(const 
.buf_idx1 = -1, .size_idx1 <token> -1, <answer> = 
.buf_idx2 = -1, .size_idx2 <token> -1, <answer> = 
[RTAS_FNIDX__SET_TIME_OF_DAY] <token> { <answer> = 
.name <token> "set-time-of-day", <answer> = 
.filter = &(const struct rtas_filter) <token> <answer> { 
.buf_idx1 = -1, .size_idx1 <token> -1, <answer> = 
.buf_idx2 = -1, .size_idx2 = <token> <answer> -1, 
[RTAS_FNIDX__START_CPU] <token> { <answer> = 
.name = <token> <answer> "start-cpu", 
[RTAS_FNIDX__STOP_SELF] <token> { <answer> = 
.name <token> "stop-self", <answer> = 
[RTAS_FNIDX__SYSTEM_REBOOT] = <token> <answer> { 
.name = <token> <answer> "system-reboot", 
[RTAS_FNIDX__THAW_TIME_BASE] = <token> <answer> { 
<token> = "thaw-time-base", <answer> .name 
[RTAS_FNIDX__WRITE_PCI_CONFIG] <token> { <answer> = 
.name <token> "write-pci-config", <answer> = 
<token> for_each_rtas_function(funcp) \ <answer> #define 
for (funcp = &rtas_function_table[0]; <token> <answer> \ 
funcp < <token> \ <answer> &rtas_function_table[ARRAY_SIZE(rtas_function_table)]; 
<token> DEFINE_RAW_SPINLOCK(rtas_lock); <answer> static 
static <token> rtas_args rtas_args; <answer> struct 
s32 rtas_function_token(const <token> handle) <answer> rtas_fn_handle_t 
const size_t <token> = handle.index; <answer> index 
const bool out_of_bounds = <token> >= ARRAY_SIZE(rtas_function_table); <answer> index 
if (WARN_ONCE(out_of_bounds, "invalid function index <token> index)) <answer> %zu", 
return <token> <answer> RTAS_UNKNOWN_SERVICE; 
<token> (!rtas.dev) <answer> if 
return <token> <answer> RTAS_UNKNOWN_SERVICE; 
<token> rtas_function_table[index].token; <answer> return 
static int rtas_function_cmp(const void <token> const void *b) <answer> *a, 
const struct rtas_function *f1 = <token> <answer> a; 
const <token> rtas_function *f2 = b; <answer> struct 
return strcmp(f1->name, <token> <answer> f2->name); 
static struct <token> *__rtas_name_to_function(const char *name) <answer> rtas_function 
<token> struct rtas_function key = { <answer> const 
.name = <token> <answer> name, 
struct rtas_function <token> <answer> *found; 
found = bsearch(&key, rtas_function_table, <token> <answer> ARRAY_SIZE(rtas_function_table), 
sizeof(rtas_function_table[0]), <token> <answer> rtas_function_cmp); 
return <token> <answer> found; 
static const <token> rtas_function *rtas_name_to_function(const char *name) <answer> struct 
<token> __rtas_name_to_function(name); <answer> return 
<token> DEFINE_XARRAY(rtas_token_to_function_xarray); <answer> static 
<token> int __init rtas_token_to_function_xarray_init(void) <answer> static 
const struct rtas_function <token> <answer> *func; 
int <token> = 0; <answer> err 
<token> { <answer> for_each_rtas_function(func) 
const s32 <token> = func->token; <answer> token 
<token> (token == RTAS_UNKNOWN_SERVICE) <answer> if 
<token> = xa_err(xa_store(&rtas_token_to_function_xarray, <answer> err 
token, (void <token> GFP_KERNEL)); <answer> *)func, 
<token> (err) <answer> if 
return <token> <answer> err; 
static const <token> rtas_function *rtas_token_to_function_untrusted(s32 token) <answer> struct 
return <token> token); <answer> xa_load(&rtas_token_to_function_xarray, 
static const <token> rtas_function *rtas_token_to_function(s32 token) <answer> struct 
const struct rtas_function <token> <answer> *func; 
if <token> < 0, "invalid token %d", token)) <answer> (WARN_ONCE(token 
<token> NULL; <answer> return 
<token> = rtas_token_to_function_untrusted(token); <answer> func 
<token> (func) <answer> if 
<token> func; <answer> return 
if <token> { <answer> (xa_empty(&rtas_token_to_function_xarray)) 
<token> { <answer> for_each_rtas_function(func) 
<token> (func->token == token) <answer> if 
return <token> <answer> func; 
WARN_ONCE(true, <token> failed lookup for token %d", token); <answer> "unexpected 
<token> NULL; <answer> return 
if <token> <answer> (func->lock) 
if (args <token> &rtas_args) <answer> == 
trace_rtas_input(args, <token> <answer> func->name); 
<token> func->name); <answer> trace_rtas_output(args, 
static void <token> rtas_args *args) <answer> do_enter_rtas(struct 
const unsigned long msr = <token> <answer> mfmsr(); 
const unsigned long <token> = MSR_IR | MSR_DR; <answer> mask 
const bool can_trace = <token> && <answer> likely(cpu_online(raw_smp_processor_id()) 
(msr & mask) <token> mask); <answer> == 
BUG_ON(!(msr <token> MSR_RI)); <answer> & 
<token> (*rtas_flash_term_hook)(int); <answer> void 
static <token> call_rtas_display_status(unsigned char c) <answer> void 
unsigned <token> flags; <answer> long 
if <token> <answer> (!rtas.base) 
raw_spin_lock_irqsave(&rtas_lock, <token> <answer> flags); 
rtas_call_unlocked(&rtas_args, 10, <token> 1, NULL, c); <answer> 1, 
raw_spin_unlock_irqrestore(&rtas_lock, <token> <answer> flags); 
static void <token> c) <answer> call_rtas_display_status_delay(char 
<token> unsigned int rtas_putchar_token = RTAS_UNKNOWN_SERVICE; <answer> static 
static unsigned int rtas_getchar_token <token> RTAS_UNKNOWN_SERVICE; <answer> = 
static <token> udbg_rtascon_putc(char c) <answer> void 
<token> tries; <answer> int 
<token> (!rtas.base) <answer> if 
if <token> { <answer> (pending_newline) 
<token> 1, 1, NULL, '\r'); <answer> rtas_call(display_character, 
rtas_call(display_character, <token> 1, NULL, '\n'); <answer> 1, 
pending_newline <token> 0; <answer> = 
<token> else { <answer> } 
<token> = 0; <answer> current_line 
<token> (form_feed) <answer> if 
rtas_call(display_character, <token> 1, NULL, <answer> 1, 
rtas_call(display_character, 1, 1, NULL, <token> <answer> '\r'); 
if <token> <answer> (row_width) 
width = <token> <answer> row_width[current_line]; 
width <token> display_width; <answer> = 
os <token> s; <answer> = 
<token> (*os) { <answer> while 
if (*os == '\n' || *os == '\r') <token> <answer> { 
if (*os == <token> && !os[1]) { <answer> '\n' 
pending_newline <token> 1; <answer> = 
if <token> > display_lines-1) <answer> (current_line 
<token> = display_lines-1; <answer> current_line 
rtas_call(display_character, 1, <token> NULL, *os); <answer> 1, 
if <token> <answer> (row_width) 
width <token> row_width[current_line]; <answer> = 
width <token> display_width; <answer> = 
} else <token> <answer> { 
<token> 1, 1, NULL, *os); <answer> rtas_call(display_character, 
WARN_ONCE(1, "unknown function `%s`, should it be added <token> rtas_function_table?\n", <answer> to 
tokp = of_get_property(rtas.dev, service, <token> <answer> NULL); 
return tokp ? be32_to_cpu(*tokp) <token> RTAS_UNKNOWN_SERVICE; <answer> : 
#ifdef <token> <answer> CONFIG_RTAS_ERROR_LOGGING 
<token> u32 rtas_error_log_max __ro_after_init = RTAS_ERROR_LOG_MAX; <answer> static 
int <token> <answer> rtas_get_error_log_max(void) 
return <token> <answer> rtas_error_log_max; 
static void <token> init_error_log_max(void) <answer> __init 
static const char <token> __initconst = "rtas-error-log-max"; <answer> propname[] 
<token> max; <answer> u32 
if (of_property_read_u32(rtas.dev, propname, <token> { <answer> &max)) 
pr_warn("%s <token> found, using default of %u\n", <answer> not 
propname, <token> <answer> RTAS_ERROR_LOG_MAX); 
max <token> RTAS_ERROR_LOG_MAX; <answer> = 
if (max <token> RTAS_ERROR_LOG_MAX) { <answer> > 
pr_warn("%s <token> %u, clamping max error log size to %u\n", <answer> = 
<token> max, RTAS_ERROR_LOG_MAX); <answer> propname, 
max = <token> <answer> RTAS_ERROR_LOG_MAX; 
<token> = max; <answer> rtas_error_log_max 
static char <token> <answer> rtas_err_buf[RTAS_ERROR_LOG_MAX]; 
<token> char *__fetch_rtas_last_error(char *altbuf) <answer> static 
const s32 token <token> rtas_function_token(RTAS_FN_RTAS_LAST_ERROR); <answer> = 
<token> rtas_args err_args, save_args; <answer> struct 
u32 <token> <answer> bufsz; 
char *buf <token> NULL; <answer> = 
if <token> == -1) <answer> (token 
return <token> <answer> NULL; 
bufsz = <token> <answer> rtas_get_error_log_max(); 
err_args.token = <token> <answer> cpu_to_be32(token); 
<token> = cpu_to_be32(2); <answer> err_args.nargs 
<token> = cpu_to_be32(1); <answer> err_args.nret 
err_args.args[0] <token> cpu_to_be32(__pa(rtas_err_buf)); <answer> = 
err_args.args[1] = <token> <answer> cpu_to_be32(bufsz); 
err_args.args[2] = <token> <answer> 0; 
save_args <token> rtas_args; <answer> = 
rtas_args = <token> <answer> err_args; 
<token> = rtas_args; <answer> err_args 
rtas_args = <token> <answer> save_args; 
void <token> rtas_args *args, int token, int nargs, int nret, ...) <answer> rtas_call_unlocked(struct 
va_list <token> <answer> list; 
<token> nret); <answer> va_start(list, 
va_rtas_call_unlocked(args, token, nargs, <token> list); <answer> nret, 
static bool <token> token) <answer> token_is_restricted_errinjct(s32 
return token == rtas_function_token(RTAS_FN_IBM_OPEN_ERRINJCT) <token> <answer> || 
token == <token> <answer> rtas_function_token(RTAS_FN_IBM_ERRINJCT); 
int rtas_call(int token, int nargs, int <token> int *outputs, ...) <answer> nret, 
struct <token> cookie; <answer> pin_cookie 
va_list <token> <answer> list; 
int <token> <answer> i; 
<token> long flags; <answer> unsigned 
<token> rtas_args *args; <answer> struct 
char *buff_copy = <token> <answer> NULL; 
int <token> <answer> ret; 
if (!rtas.entry || token == <token> <answer> RTAS_UNKNOWN_SERVICE) 
return <token> <answer> -1; 
<token> (token_is_restricted_errinjct(token)) { <answer> if 
if <token> <answer> (security_locked_down(LOCKDOWN_RTAS_ERROR_INJECTION)) 
return <token> <answer> -1; 
if ((mfmsr() <token> (MSR_IR|MSR_DR)) != (MSR_IR|MSR_DR)) { <answer> & 
<token> -1; <answer> return 
raw_spin_lock_irqsave(&rtas_lock, <token> <answer> flags); 
cookie = <token> <answer> lockdep_pin_lock(&rtas_lock); 
if (be32_to_cpu(args->rets[0]) == <token> <answer> -1) 
<token> = __fetch_rtas_last_error(NULL); <answer> buff_copy 
if (nret > 1 && outputs != <token> <answer> NULL) 
for (i = 0; i < <token> ++i) <answer> nret-1; 
outputs[i] <token> be32_to_cpu(args->rets[i + 1]); <answer> = 
ret = (nret > 0) ? be32_to_cpu(args->rets[0]) <token> 0; <answer> : 
<token> cookie); <answer> lockdep_unpin_lock(&rtas_lock, 
raw_spin_unlock_irqrestore(&rtas_lock, <token> <answer> flags); 
if (buff_copy) <token> <answer> { 
<token> ERR_TYPE_RTAS_LOG, 0); <answer> log_error(buff_copy, 
if <token> <answer> (slab_is_available()) 
return <token> <answer> ret; 
unsigned <token> rtas_busy_delay_time(int status) <answer> int 
int <token> <answer> order; 
unsigned int ms = <token> <answer> 0; 
if (status == <token> { <answer> RTAS_BUSY) 
<token> = 1; <answer> ms 
<token> else if (status >= RTAS_EXTENDED_DELAY_MIN && <answer> } 
status <= RTAS_EXTENDED_DELAY_MAX) <token> <answer> { 
order = status - <token> <answer> RTAS_EXTENDED_DELAY_MIN; 
for (ms = 1; <token> > 0; order--) <answer> order 
<token> *= 10; <answer> ms 
return <token> <answer> ms; 
static bool <token> rtas_busy_delay_early(int status) <answer> __init 
static size_t <token> __initdata; <answer> successive_ext_delays 
<token> retry; <answer> bool 
switch <token> { <answer> (status) 
case <token> <answer> RTAS_EXTENDED_DELAY_MIN...RTAS_EXTENDED_DELAY_MAX: 
<token> = true; <answer> retry 
<token> += 1; <answer> successive_ext_delays 
if (successive_ext_delays <token> 1000) { <answer> > 
<token> many extended delays, giving up\n"); <answer> pr_err("too 
<token> = false; <answer> retry 
successive_ext_delays = <token> <answer> 0; 
case <token> <answer> RTAS_BUSY: 
retry <token> true; <answer> = 
successive_ext_delays <token> 0; <answer> = 
<token> = false; <answer> retry 
successive_ext_delays = <token> <answer> 0; 
return <token> <answer> retry; 
bool __ref <token> status) <answer> rtas_busy_delay(int 
unsigned int <token> <answer> ms; 
<token> ret; <answer> bool 
<token> (system_state < SYSTEM_SCHEDULING) <answer> if 
<token> rtas_busy_delay_early(status); <answer> return 
switch (status) <token> <answer> { 
<token> RTAS_EXTENDED_DELAY_MIN...RTAS_EXTENDED_DELAY_MAX: <answer> case 
ret = <token> <answer> true; 
ms <token> rtas_busy_delay_time(status); <answer> = 
ms = clamp(ms, 1U, <token> <answer> 1000U); 
if <token> <= 20) <answer> (ms 
usleep_range(ms * <token> ms * 1000); <answer> 100, 
case <token> <answer> RTAS_BUSY: 
ret <token> true; <answer> = 
ret = <token> <answer> false; 
<token> ret; <answer> return 
int rtas_error_rc(int <token> <answer> rtas_rc) 
<token> rc; <answer> int 
switch (rtas_rc) <token> <answer> { 
int rtas_set_indicator_fast(int indicator, int index, int <token> <answer> new_value) 
int token <token> rtas_function_token(RTAS_FN_SET_INDICATOR); <answer> = 
int <token> <answer> rc; 
<token> (token == RTAS_UNKNOWN_SERVICE) <answer> if 
<token> -ENOENT; <answer> return 
<token> = rtas_call(token, 3, 1, NULL, indicator, index, new_value); <answer> rc 
WARN_ON(rc <token> RTAS_BUSY || (rc >= RTAS_EXTENDED_DELAY_MIN && <answer> == 
rc <token> RTAS_EXTENDED_DELAY_MAX)); <answer> <= 
if (rc <token> 0) <answer> < 
<token> rtas_error_rc(rc); <answer> return 
<token> rc; <answer> return 
int <token> *fw_status) <answer> rtas_ibm_suspend_me(int 
int token = <token> <answer> rtas_function_token(RTAS_FN_IBM_SUSPEND_ME); 
int <token> <answer> fwrc; 
<token> ret; <answer> int 
fwrc = rtas_call(token, 0, 1, <token> <answer> NULL); 
<token> (fwrc) { <answer> switch 
case <token> <answer> 0: 
ret <token> 0; <answer> = 
<token> RTAS_SUSPEND_ABORTED: <answer> case 
ret <token> -ECANCELED; <answer> = 
<token> RTAS_THREADS_ACTIVE: <answer> case 
ret = <token> <answer> -EAGAIN; 
case <token> <answer> RTAS_NOT_SUSPENDABLE: 
<token> RTAS_OUTSTANDING_COPROC: <answer> case 
ret = <token> <answer> -EBUSY; 
<token> -1: <answer> case 
<token> = -EIO; <answer> ret 
<token> (fw_status) <answer> if 
*fw_status <token> fwrc; <answer> = 
return <token> <answer> ret; 
void __noreturn <token> *cmd) <answer> rtas_restart(char 
<token> (rtas_flash_term_hook) <answer> if 
<token> returned %d\n", <answer> pr_emerg("system-reboot 
rtas_call(rtas_function_token(RTAS_FN_SYSTEM_REBOOT), 0, <token> NULL)); <answer> 1, 
<token> (;;); <answer> for 
void <token> <answer> rtas_power_off(void) 
if <token> <answer> (rtas_flash_term_hook) 
if (token == <token> || !ibm_extended_os_term) <answer> RTAS_UNKNOWN_SERVICE 
snprintf(rtas_os_term_buf, 2048, "OS <token> %s", str); <answer> panic: 
do <token> <answer> { 
rtas_call_unlocked(&args, token, 1, 1, NULL, <token> <answer> __pa(rtas_os_term_buf)); 
status <token> be32_to_cpu(args.rets[0]); <answer> = 
} while <token> <answer> (rtas_busy_delay_time(status)); 
if (status <token> 0) <answer> != 
pr_emerg("ibm,os-term call <token> %d\n", status); <answer> failed 
void <token> <answer> rtas_activate_firmware(void) 
int <token> = rtas_function_token(RTAS_FN_IBM_ACTIVATE_FIRMWARE); <answer> token 
int <token> <answer> fwrc; 
if <token> == RTAS_UNKNOWN_SERVICE) { <answer> (token 
pr_notice("ibm,activate-firmware <token> unavailable\n"); <answer> method 
do <token> <answer> { 
<token> = rtas_call(token, 0, 1, NULL); <answer> fwrc 
} <token> (rtas_busy_delay(fwrc)); <answer> while 
<token> (fwrc) <answer> if 
<token> failed (%i)\n", fwrc); <answer> pr_err("ibm,activate-firmware 
noinstr struct pseries_errorlog *get_pseries_errorlog(struct rtas_error_log <token> <answer> *log, 
<token> section_id) <answer> uint16_t 
struct <token> *ext_log = <answer> rtas_ext_event_log_v6 
(struct rtas_ext_event_log_v6 <token> <answer> *)log->buffer; 
struct <token> *sect; <answer> pseries_errorlog 
unsigned char *p, <token> <answer> *log_end; 
<token> ext_log_length = rtas_error_extended_log_length(log); <answer> uint32_t 
uint8_t log_format <token> rtas_ext_event_log_format(ext_log); <answer> = 
uint32_t company_id <token> rtas_ext_event_company_id(ext_log); <answer> = 
<token> bool in_rmo_buf(u32 base, u32 end) <answer> static 
return base >= <token> && <answer> rtas_rmo_buf 
<token> < (rtas_rmo_buf + RTAS_USER_REGION_SIZE) && <answer> base 
base <= <token> && <answer> end 
<token> >= rtas_rmo_buf && <answer> end 
end < (rtas_rmo_buf <token> RTAS_USER_REGION_SIZE); <answer> + 
static <token> block_rtas_call(const struct rtas_function *func, int nargs, <answer> bool 
struct <token> *args) <answer> rtas_args 
<token> struct rtas_filter *f; <answer> const 
const <token> is_platform_dump = <answer> bool 
func == <token> <answer> &rtas_function_table[RTAS_FNIDX__IBM_PLATFORM_DUMP]; 
const bool <token> = <answer> is_config_conn 
func == <token> <answer> &rtas_function_table[RTAS_FNIDX__IBM_CONFIGURE_CONNECTOR]; 
u32 base, size, <token> <answer> end; 
f = <token> <answer> func->filter; 
<token> (!f) <answer> if 
<token> err; <answer> goto 
if (IS_ENABLED(CONFIG_CPU_LITTLE_ENDIAN) <token> func->banned_for_syscall_on_le) <answer> && 
goto <token> <answer> err; 
if (f->buf_idx1 <token> -1) { <answer> != 
<token> = be32_to_cpu(args->args[f->buf_idx1]); <answer> base 
if (f->size_idx1 <token> -1) <answer> != 
size <token> be32_to_cpu(args->args[f->size_idx1]); <answer> = 
else <token> (f->fixed_size) <answer> if 
<token> = f->fixed_size; <answer> size 
size = <token> <answer> 1; 
end = base <token> size - 1; <answer> + 
<token> (is_platform_dump && base == 0) <answer> if 
return <token> <answer> false; 
<token> (!in_rmo_buf(base, end)) <answer> if 
goto <token> <answer> err; 
if <token> != -1) { <answer> (f->buf_idx2 
base <token> be32_to_cpu(args->args[f->buf_idx2]); <answer> = 
if <token> != -1) <answer> (f->size_idx2 
size <token> be32_to_cpu(args->args[f->size_idx2]); <answer> = 
<token> if (f->fixed_size) <answer> else 
size <token> f->fixed_size; <answer> = 
size = <token> <answer> 1; 
end = base + size - <token> <answer> 1; 
if (is_config_conn <token> base == 0) <answer> && 
return <token> <answer> false; 
<token> (!in_rmo_buf(base, end)) <answer> if 
<token> err; <answer> goto 
return <token> <answer> false; 
<token> RTAS call blocked - exploit attempt?\n"); <answer> pr_err_ratelimited("sys_rtas: 
pr_err_ratelimited("sys_rtas: %s <token> (called by %s)\n", <answer> nargs=%d 
func->name, nargs, <token> <answer> current->comm); 
return <token> <answer> true; 
func <token> rtas_token_to_function_untrusted(token); <answer> = 
if <token> <answer> (!func) 
return <token> <answer> -EINVAL; 
args.rets = <token> <answer> &args.args[nargs]; 
memset(args.rets, 0, <token> * sizeof(rtas_arg_t)); <answer> nret 
if (block_rtas_call(func, nargs, <token> <answer> &args)) 
<token> -EINVAL; <answer> return 
if <token> { <answer> (token_is_restricted_errinjct(token)) 
int <token> <answer> err; 
<token> = security_locked_down(LOCKDOWN_RTAS_ERROR_INJECTION); <answer> err 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> rc = 0; <answer> int 
<token> handle = ((u64)be32_to_cpu(args.args[0]) << 32) <answer> u64 
<token> be32_to_cpu(args.args[1]); <answer> | 
<token> = rtas_syscall_dispatch_ibm_suspend_me(handle); <answer> rc 
if <token> == -EAGAIN) <answer> (rc 
<token> = cpu_to_be32(RTAS_NOT_SUSPENDABLE); <answer> args.rets[0] 
else if (rc == <token> <answer> -EIO) 
args.rets[0] = <token> <answer> cpu_to_be32(-1); 
else <token> (rc) <answer> if 
<token> rc; <answer> return 
<token> copy_return; <answer> goto 
buff_copy = <token> <answer> get_errorlog_buffer(); 
<token> (func->lock) <answer> if 
raw_spin_lock_irqsave(&rtas_lock, <token> <answer> flags); 
cookie <token> lockdep_pin_lock(&rtas_lock); <answer> = 
rtas_args = <token> <answer> args; 
args = <token> <answer> rtas_args; 
if <token> == -1) <answer> (be32_to_cpu(args.rets[0]) 
<token> = __fetch_rtas_last_error(buff_copy); <answer> errbuf 
<token> cookie); <answer> lockdep_unpin_lock(&rtas_lock, 
<token> flags); <answer> raw_spin_unlock_irqrestore(&rtas_lock, 
if <token> <answer> (func->lock) 
if <token> { <answer> (buff_copy) 
if <token> <answer> (errbuf) 
log_error(errbuf, <token> 0); <answer> ERR_TYPE_RTAS_LOG, 
prior = &rtas_function_table[i <token> 1]; <answer> - 
<token> = strcmp(prior->name, curr->name); <answer> cmp 
if (cmp <token> 0) <answer> < 
if (cmp <token> 0) { <answer> == 
pr_err("'%s' has duplicate <token> table entries\n", <answer> function 
<token> else { <answer> } 
pr_err("function table unsorted: '%s' wrongly precedes <token> <answer> '%s'\n", 
prior->name, <token> <answer> curr->name); 
for_each_property_of_node(rtas.dev, <token> { <answer> prop) 
struct rtas_function <token> <answer> *func; 
if (prop->length <token> sizeof(u32)) <answer> != 
func <token> __rtas_name_to_function(prop->name); <answer> = 
<token> (!func) <answer> if 
func->token <token> be32_to_cpup((__be32 *)prop->value); <answer> = 
pr_debug("function %s has <token> %u\n", func->name, func->token); <answer> token 
void <token> rtas_initialize(void) <answer> __init 
unsigned long rtas_region = <token> <answer> RTAS_INSTANTIATE_MAX; 
<token> base, size, entry; <answer> u32 
int no_base, no_size, <token> <answer> no_entry; 
rtas.dev <token> of_find_node_by_name(NULL, "rtas"); <answer> = 
if <token> <answer> (!rtas.dev) 
no_base = of_property_read_u32(rtas.dev, "linux,rtas-base", <token> <answer> &base); 
<token> = of_property_read_u32(rtas.dev, "rtas-size", &size); <answer> no_size 
<token> (no_base || no_size) { <answer> if 
rtas.dev <token> NULL; <answer> = 
rtas.base = <token> <answer> base; 
rtas.size <token> size; <answer> = 
no_entry <token> of_property_read_u32(rtas.dev, "linux,rtas-entry", &entry); <answer> = 
rtas.entry <token> no_entry ? rtas.base : entry; <answer> = 
ibm_extended_os_term = <token> "ibm,extended-os-term"); <answer> of_property_read_bool(rtas.dev, 
<token> CONFIG_PPC64 <answer> #ifdef 
<token> (firmware_has_feature(FW_FEATURE_LPAR)) <answer> if 
rtas_region <token> min(ppc64_rma_size, RTAS_INSTANTIATE_MAX); <answer> = 
rtas_rmo_buf = memblock_phys_alloc_range(RTAS_USER_REGION_SIZE, <token> <answer> PAGE_SIZE, 
0, <token> <answer> rtas_region); 
<token> (!rtas_rmo_buf) <answer> if 
panic("ERROR: <token> Failed to allocate %lx bytes below %pa\n", <answer> RTAS: 
<token> &rtas_region); <answer> PAGE_SIZE, 
int __init early_init_dt_scan_rtas(unsigned long <token> <answer> node, 
const char <token> int depth, void *data) <answer> *uname, 
const u32 <token> *entryp, *sizep; <answer> *basep, 
<token> (depth != 1 || strcmp(uname, "rtas") != 0) <answer> if 
<token> 0; <answer> return 
<token> = of_get_flat_dt_prop(node, "linux,rtas-base", NULL); <answer> basep 
<token> = of_get_flat_dt_prop(node, "linux,rtas-entry", NULL); <answer> entryp 
<token> = of_get_flat_dt_prop(node, "rtas-size", NULL); <answer> sizep 
<token> CONFIG_PPC64 <answer> #ifdef 
#include <token> <answer> <linux/init.h> 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <asm/clock.h> 
#include <token> <answer> <asm/freq.h> 
<token> <asm/io.h> <answer> #include 
static int md_table[] = { 1, 2, 3, 4, 6, 8, <token> }; <answer> 12 
static <token> master_clk_init(struct clk *clk) <answer> void 
clk->rate *= md_table[__raw_readw(FRQCR) & <token> <answer> 0x0007]; 
static struct <token> sh7710_master_clk_ops = { <answer> sh_clk_ops 
.init <token> master_clk_init, <answer> = 
static <token> long module_clk_recalc(struct clk *clk) <answer> unsigned 
int idx = (__raw_readw(FRQCR) <token> 0x0007); <answer> & 
return clk->parent->rate / <token> <answer> md_table[idx]; 
static struct sh_clk_ops <token> = { <answer> sh7710_module_clk_ops 
.recalc = <token> <answer> module_clk_recalc, 
static <token> long bus_clk_recalc(struct clk *clk) <answer> unsigned 
int idx = <token> & 0x0700) >> 8; <answer> (__raw_readw(FRQCR) 
return <token> / md_table[idx]; <answer> clk->parent->rate 
static struct sh_clk_ops <token> = { <answer> sh7710_bus_clk_ops 
.recalc <token> bus_clk_recalc, <answer> = 
<token> unsigned long cpu_clk_recalc(struct clk *clk) <answer> static 
int <token> = (__raw_readw(FRQCR) & 0x0070) >> 4; <answer> idx 
return <token> / md_table[idx]; <answer> clk->parent->rate 
static struct sh_clk_ops sh7710_cpu_clk_ops <token> { <answer> = 
.recalc = <token> <answer> cpu_clk_recalc, 
static struct sh_clk_ops *sh7710_clk_ops[] <token> { <answer> = 
void <token> arch_init_clk_ops(struct sh_clk_ops **ops, int idx) <answer> __init 
<token> (idx < ARRAY_SIZE(sh7710_clk_ops)) <answer> if 
*ops <token> sh7710_clk_ops[idx]; <answer> = 
<token> <linux/module.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> "pinctrl-msm.h" <answer> #include 
<token> REG_SIZE 0x1000 <answer> #define 
#define PINGROUP(id, f1, f2, f3, f4, <token> f6, f7, f8, f9) \ <answer> f5, 
{ <token> <answer> \ 
.grp = PINCTRL_PINGROUP("gpio" #id, <token> <answer> \ 
<token> \ <answer> gpio##id##_pins, 
ARRAY_SIZE(gpio##id##_pins)), <token> <answer> \ 
.funcs = <token> \ <answer> (int[]){ 
static const <token> msm_pingroup x1e80100_groups[] = { <answer> struct 
[0] = PINGROUP(0, qup0_se0, ibi_i3c, _, _, _, _, _, _, <token> <answer> _), 
[1] = PINGROUP(1, qup0_se0, ibi_i3c, _, _, <token> _, _, _, _), <answer> _, 
[2] = PINGROUP(2, qup0_se0, _, <token> _, _, _, _, _, _), <answer> _, 
[3] = PINGROUP(3, <token> _, _, _, _, _, _, _, _), <answer> qup0_se0, 
[4] = PINGROUP(4, <token> _, _, _, _, _, _, _, _), <answer> qup0_se1, 
[5] = <token> qup0_se1, _, _, _, _, _, _, _, _), <answer> PINGROUP(5, 
[6] = PINGROUP(6, qup0_se1, <token> _, _, _, _, _, _, _), <answer> phase_flag, 
[7] = PINGROUP(7, qup0_se1, phase_flag, _, _, _, <token> _, _, _), <answer> _, 
<token> = PINGROUP(8, qup0_se2, phase_flag, _, _, _, _, _, _, _), <answer> [8] 
[9] = <token> qup0_se2, _, atest_usb, ddr_pxi0, _, _, _, _, _), <answer> PINGROUP(9, 
[10] = PINGROUP(10, qup0_se2, _, atest_usb, <token> _, _, _, _, _), <answer> ddr_pxi1, 
[11] = PINGROUP(11, qup0_se2, phase_flag, _, _, _, _, _, <token> _), <answer> _, 
[12] = PINGROUP(12, qup0_se3, <token> phase_flag, _, _, _, _, _, _), <answer> qup0_se7, 
[13] = PINGROUP(13, qup0_se3, qup0_se7, phase_flag, _, _, _, _, _, <token> <answer> _), 
[14] = PINGROUP(14, qup0_se3, qup0_se7, phase_flag, <token> _, _, _, _, _), <answer> _, 
[15] = PINGROUP(15, qup0_se3, qup0_se7, phase_flag, _, _, _, _, <token> _), <answer> _, 
[16] = PINGROUP(16, qup0_se4, phase_flag, _, _, _, _, _, <token> _), <answer> _, 
[17] = PINGROUP(17, qup0_se4, qup0_se2, phase_flag, <token> _, _, _, _, _), <answer> _, 
[18] = PINGROUP(18, <token> qup0_se2, phase_flag, _, qdss_cti, _, _, _, _), <answer> qup0_se4, 
[19] = PINGROUP(19, qup0_se4, qup0_se2, phase_flag, _, qdss_cti, _, <token> _, _), <answer> _, 
[20] = PINGROUP(20, qup0_se5, _, phase_flag, _, _, _, _, <token> _), <answer> _, 
[21] = <token> qup0_se5, qup0_se3, _, phase_flag, _, _, _, _, _), <answer> PINGROUP(21, 
<token> = PINGROUP(22, qup0_se5, qup0_se3, _, phase_flag, _, _, _, _, _), <answer> [22] 
[23] = PINGROUP(23, <token> qup0_se3, phase_flag, _, qdss_cti, _, _, _, _), <answer> qup0_se5, 
<token> = PINGROUP(24, qup0_se6, phase_flag, _, _, _, _, _, _, _), <answer> [24] 
[25] = <token> qup0_se6, phase_flag, _, _, _, _, _, _, _), <answer> PINGROUP(25, 
[26] = PINGROUP(26, qup0_se6, phase_flag, _, _, _, <token> _, _, _), <answer> _, 
[27] = PINGROUP(27, qup0_se6, phase_flag, _, qdss_cti, <token> _, _, _, _), <answer> _, 
[28] = PINGROUP(28, pll_bist, _, _, _, _, <token> _, _, _), <answer> _, 
[29] = PINGROUP(29, _, _, _, _, _, _, <token> _, _), <answer> _, 
[30] <token> PINGROUP(30, _, _, _, _, _, _, _, _, _), <answer> = 
[31] = PINGROUP(31, <token> _, _, _, _, _, _, _, _), <answer> _, 
[32] = PINGROUP(32, <token> ibi_i3c, _, _, _, _, _, _, _), <answer> qup1_se0, 
[33] = PINGROUP(33, qup1_se0, ibi_i3c, qup1_se3, _, _, <token> _, _, _), <answer> _, 
[34] = PINGROUP(34, qup1_se0, <token> tsense_pwm1, tsense_pwm2, tsense_pwm3, tsense_pwm4, _, _, _), <answer> qup1_se3, 
[35] = PINGROUP(35, qup1_se0, qup1_se3, pll_clk, atest_usb, _, _, <token> _, _), <answer> _, 
<token> = PINGROUP(36, qup1_se1, ibi_i3c, _, _, _, _, _, _, _), <answer> [36] 
[37] = PINGROUP(37, <token> ibi_i3c, _, _, _, _, _, _, _), <answer> qup1_se1, 
[38] = PINGROUP(38, qup1_se1, vsense_trigger, atest_usb, ddr_pxi0, _, _, <token> _, _), <answer> _, 
[39] = PINGROUP(39, qup1_se1, sys_throttle, phase_flag, <token> _, _, _, _, _), <answer> _, 
[40] = PINGROUP(40, qup1_se2, phase_flag, _, _, _, _, _, <token> _), <answer> _, 
[41] = PINGROUP(41, qup1_se2, atest_usb, ddr_pxi1, _, <token> _, _, _, _), <answer> _, 
<token> = PINGROUP(42, qup1_se2, jitter_bist, atest_usb, ddr_pxi2, _, _, _, _, _), <answer> [42] 
[43] = PINGROUP(43, qup1_se2, _, atest_usb, ddr_pxi2, <token> _, _, _, _), <answer> _, 
[44] = PINGROUP(44, qup1_se3, _, <token> ddr_pxi3, _, _, _, _, _), <answer> atest_usb, 
[45] = PINGROUP(45, qup1_se3, cmu_rng3, <token> atest_usb, ddr_pxi3, _, _, _, _), <answer> _, 
[46] = PINGROUP(46, qup1_se3, cmu_rng2, _, atest_usb, <token> _, _, _, _), <answer> ddr_pxi4, 
[47] = PINGROUP(47, qup1_se3, cmu_rng1, _, atest_usb, <token> _, _, _, _), <answer> ddr_pxi4, 
[48] = PINGROUP(48, qup1_se4, cmu_rng0, _, <token> ddr_pxi5, _, _, _, _), <answer> atest_usb, 
[49] = PINGROUP(49, qup1_se4, qup1_se2, _, <token> ddr_pxi5, _, _, _, _), <answer> atest_usb, 
[50] = PINGROUP(50, <token> qup1_se2, _, atest_usb, ddr_pxi6, _, _, _, _), <answer> qup1_se4, 
[51] = PINGROUP(51, qup1_se4, qup1_se2, dbg_out, atest_usb, ddr_pxi6, _, _, _, <token> <answer> _), 
[52] = PINGROUP(52, qup1_se5, qup1_se7, atest_usb, ddr_pxi7, _, _, <token> _, _), <answer> _, 
[53] = PINGROUP(53, qup1_se5, qup1_se7, <token> atest_usb, ddr_pxi7, _, _, _, _), <answer> _, 
<token> = PINGROUP(54, qup1_se5, qup1_se7, ddr_bist, atest_usb, _, _, _, _, _), <answer> [54] 
[55] = PINGROUP(55, qup1_se5, qup1_se7, ddr_bist, _, _, _, _, <token> _), <answer> _, 
[56] = PINGROUP(56, qup1_se6, ddr_bist, <token> _, _, _, _, _, _), <answer> _, 
[57] = PINGROUP(57, qup1_se6, ddr_bist, _, _, _, _, <token> _, _), <answer> _, 
<token> = PINGROUP(58, qup1_se6, atest_usb, _, _, _, _, _, _, _), <answer> [58] 
[59] = PINGROUP(59, <token> atest_usb, _, _, _, _, _, _, _), <answer> qup1_se6, 
[60] = PINGROUP(60, aoss_cti, _, _, _, _, <token> _, _, _), <answer> _, 
[61] = PINGROUP(61, aoss_cti, _, _, _, _, _, _, _, <token> <answer> _), 
[62] = <token> aoss_cti, _, _, _, _, _, _, _, _), <answer> PINGROUP(62, 
[63] = PINGROUP(63, aoss_cti, _, _, _, _, <token> _, _, _), <answer> _, 
[64] = <token> qup2_se0, gcc_gp2, _, _, _, _, _, _, _), <answer> PINGROUP(64, 
[65] = PINGROUP(65, <token> qup2_se3, tgu_ch1, atest_usb, _, _, _, _, _), <answer> qup2_se0, 
[66] = PINGROUP(66, qup2_se0, qup2_se3, tgu_ch2, atest_usb, _, _, <token> _, _), <answer> _, 
[67] = PINGROUP(67, qup2_se0, qup2_se3, <token> atest_usb, _, _, _, _, _), <answer> tgu_ch3, 
[68] = <token> qup2_se1, ibi_i3c, tgu_ch4, _, _, _, _, _, _), <answer> PINGROUP(68, 
[69] = PINGROUP(69, qup2_se1, ibi_i3c, tgu_ch5, _, _, _, _, <token> _), <answer> _, 
<token> = PINGROUP(70, qup2_se1, _, _, _, _, _, _, _, _), <answer> [70] 
[71] = PINGROUP(71, qup2_se1, gcc_gp1, _, <token> _, _, _, _, _), <answer> _, 
[72] = PINGROUP(72, qup2_se2, <token> atest_usb, _, _, _, _, _, _), <answer> gcc_gp1, 
[73] = PINGROUP(73, qup2_se2, gcc_gp2, atest_usb, _, _, <token> _, _, _), <answer> _, 
[74] = PINGROUP(74, qup2_se2, gcc_gp3, atest_usb, _, <token> _, _, _, _), <answer> _, 
[75] = PINGROUP(75, qup2_se2, atest_usb, _, _, _, _, _, <token> _), <answer> _, 
[76] = PINGROUP(76, qup2_se3, phase_flag, _, <token> _, _, _, _, _), <answer> _, 
[77] = PINGROUP(77, qup2_se3, phase_flag, _, <token> _, _, _, _, _), <answer> _, 
[78] = PINGROUP(78, qup2_se3, <token> _, _, _, _, _, _, _), <answer> phase_flag, 
[79] = PINGROUP(79, qup2_se3, _, _, _, _, _, _, <token> _), <answer> _, 
[80] = <token> qup2_se4, tgu_ch7, atest_usb, _, _, _, _, _, _), <answer> PINGROUP(80, 
[81] = <token> qup2_se4, qup2_se2, tgu_ch0, atest_usb, _, _, _, _, _), <answer> PINGROUP(81, 
[82] = PINGROUP(82, qup2_se4, qup2_se2, gcc_gp3, _, _, _, _, _, <token> <answer> _), 
[83] = PINGROUP(83, qup2_se4, qup2_se2, <token> atest_usb, _, _, _, _, _), <answer> tgu_ch6, 
[84] = PINGROUP(84, qup2_se5, qup2_se7, _, _, _, _, _, <token> _), <answer> _, 
[85] = PINGROUP(85, qup2_se5, qup2_se7, _, <token> _, _, _, _, _), <answer> _, 
[86] = PINGROUP(86, qup2_se5, qup2_se7, _, _, _, _, _, _, <token> <answer> _), 
[87] = <token> qup2_se5, qup2_se7, _, _, _, _, _, _, _), <answer> PINGROUP(87, 
[88] = PINGROUP(88, qup2_se6, _, _, _, _, _, _, _, <token> <answer> _), 
[89] = PINGROUP(89, qup2_se6, _, <token> _, _, _, _, _, _), <answer> _, 
[90] = PINGROUP(90, qup2_se6, _, _, _, <token> _, _, _, _), <answer> _, 
[91] = PINGROUP(91, qup2_se6, _, _, _, _, _, <token> _, _), <answer> _, 
[92] = PINGROUP(92, tmess_prng0, <token> _, _, _, _, _, _, _), <answer> _, 
[93] = PINGROUP(93, tmess_prng1, _, _, _, _, <token> _, _, _), <answer> _, 
[94] = PINGROUP(94, sys_throttle, tmess_prng2, _, _, _, _, _, _, <token> <answer> _), 
[95] = PINGROUP(95, tmess_prng3, _, _, _, <token> _, _, _, _), <answer> _, 
[96] = PINGROUP(96, cam_mclk, qdss_gpio, _, _, _, <token> _, _, _), <answer> _, 
[97] = PINGROUP(97, cam_mclk, qdss_gpio, _, _, _, <token> _, _, _), <answer> _, 
[98] = <token> cam_mclk, qdss_gpio, _, _, _, _, _, _, _), <answer> PINGROUP(98, 
[99] = <token> cam_mclk, qdss_gpio, _, _, _, _, _, _, _), <answer> PINGROUP(99, 
[100] = PINGROUP(100, cam_aon, qdss_gpio, _, _, _, _, _, _, <token> <answer> _), 
[101] = PINGROUP(101, cci_i2c, qdss_gpio, _, _, _, _, _, <token> _), <answer> _, 
[102] = PINGROUP(102, cci_i2c, <token> _, _, _, _, _, _, _), <answer> qdss_gpio, 
[103] = PINGROUP(103, cci_i2c, qdss_gpio, _, _, _, _, _, _, <token> <answer> _), 
[104] = PINGROUP(104, cci_i2c, qdss_gpio, _, _, <token> _, _, _, _), <answer> _, 
[105] = PINGROUP(105, cci_i2c, qdss_gpio, _, _, <token> _, _, _, _), <answer> _, 
[106] = PINGROUP(106, cci_i2c, qdss_gpio, _, _, _, _, _, <token> _), <answer> _, 
[107] = <token> qdss_gpio, _, _, _, _, _, _, _, _), <answer> PINGROUP(107, 
[108] = PINGROUP(108, qdss_gpio, _, _, _, <token> _, _, _, _), <answer> _, 
[109] = PINGROUP(109, cci_timer0, mdp_vsync4, <token> _, _, _, _, _, _), <answer> qdss_gpio, 
[110] = PINGROUP(110, cci_timer1, mdp_vsync5, qdss_gpio, _, _, <token> _, _, _), <answer> _, 
[111] = <token> cci_timer2, cci_async, mdp_vsync6, qdss_gpio, _, _, _, _, _), <answer> PINGROUP(111, 
[112] = PINGROUP(112, cci_timer3, cci_async, mdp_vsync7, qdss_gpio, _, _, <token> _, _), <answer> _, 
[113] = PINGROUP(113, cci_timer4, cci_async, mdp_vsync8, <token> _, _, _, _, _), <answer> qdss_gpio, 
[114] = PINGROUP(114, mdp_vsync0, <token> _, _, _, _, _, _, _), <answer> mdp_vsync1, 
[115] = PINGROUP(115, mdp_vsync3, <token> edp1_lcd, _, _, _, _, _, _), <answer> mdp_vsync2, 
[116] = PINGROUP(116, _, _, <token> _, _, _, _, _, _), <answer> _, 
[117] = PINGROUP(117, _, _, <token> _, _, _, _, _, _), <answer> _, 
[118] = PINGROUP(118, <token> _, _, _, _, _, _, _, _), <answer> _, 
<token> = PINGROUP(119, edp0_hot, edp1_lcd, _, _, _, _, _, _, _), <answer> [119] 
[120] <token> PINGROUP(120, edp1_hot, edp0_lcd, _, _, _, _, _, _, _), <answer> = 
[121] = PINGROUP(121, usb0_phy, _, _, _, _, <token> _, _, _), <answer> _, 
[122] = PINGROUP(122, usb0_dp, _, _, _, _, _, _, _, <token> <answer> _), 
[123] = PINGROUP(123, <token> _, _, _, _, _, _, _, _), <answer> usb1_phy, 
[124] = PINGROUP(124, usb1_dp, _, _, _, _, _, _, <token> _), <answer> _, 
[125] = PINGROUP(125, usb2_phy, _, _, _, _, _, _, <token> _), <answer> _, 
[126] = PINGROUP(126, usb2_dp, _, _, _, _, _, <token> _, _), <answer> _, 
[127] = PINGROUP(127, qspi0_clk, <token> _, _, _, _, _, _, _), <answer> sdc4_clk, 
[128] = PINGROUP(128, qspi00, sdc4_data0, _, _, _, _, <token> _, _), <answer> _, 
[129] = PINGROUP(129, qspi01, sdc4_data1, _, <token> _, _, _, _, _), <answer> _, 
<token> = PINGROUP(130, qspi02, sdc4_data2, _, _, _, _, _, _, _), <answer> [130] 
[131] = PINGROUP(131, qspi03, sdc4_data3, _, _, _, <token> _, _, _), <answer> _, 
[132] = <token> qspi0_cs0, sdc4_cmd, _, _, _, _, _, _, _), <answer> PINGROUP(132, 
[133] = PINGROUP(133, qspi0_cs1, tb_trig, _, _, _, _, _, _, <token> <answer> _), 
[134] = PINGROUP(134, audio_ext, _, <token> _, _, _, _, _, _), <answer> _, 
[135] = PINGROUP(135, i2s0_sck, _, _, _, _, <token> _, _, _), <answer> _, 
[136] = PINGROUP(136, i2s0_data0, <token> _, _, _, _, _, _, _), <answer> _, 
[137] <token> PINGROUP(137, i2s0_data1, tb_trig, _, _, _, _, _, _, _), <answer> = 
<token> = PINGROUP(138, i2s0_ws, _, _, _, _, _, _, _, _), <answer> [138] 
[139] = PINGROUP(139, i2s1_sck, _, _, _, _, _, <token> _, _), <answer> _, 
[140] = PINGROUP(140, i2s1_data0, _, _, _, _, _, <token> _, _), <answer> _, 
[141] = PINGROUP(141, i2s1_ws, _, _, _, _, <token> _, _, _), <answer> _, 
[142] = PINGROUP(142, i2s1_data1, audio_ext, audio_ref, _, _, _, <token> _, _), <answer> _, 
[143] = PINGROUP(143, _, _, _, _, _, <token> _, _, _), <answer> _, 
[144] = <token> pcie3_clk, _, _, _, _, _, _, _, _), <answer> PINGROUP(144, 
[145] = PINGROUP(145, _, <token> _, _, _, _, _, _, _), <answer> _, 
[146] <token> PINGROUP(146, _, _, _, _, _, _, _, _, _), <answer> = 
[147] = PINGROUP(147, pcie4_clk, _, _, _, <token> _, _, _, _), <answer> _, 
[148] = PINGROUP(148, _, _, _, _, _, _, _, _, <token> <answer> _), 
[149] = <token> _, _, _, _, _, _, _, _, _), <answer> PINGROUP(149, 
[150] = PINGROUP(150, pcie5_clk, _, _, _, <token> _, _, _, _), <answer> _, 
[151] = PINGROUP(151, _, _, _, _, _, _, _, _, <token> <answer> _), 
[152] <token> PINGROUP(152, _, _, _, _, _, _, _, _, _), <answer> = 
[153] = PINGROUP(153, pcie6a_clk, _, _, _, _, _, <token> _, _), <answer> _, 
<token> = PINGROUP(154, _, _, _, _, _, _, _, _, _), <answer> [154] 
[155] = PINGROUP(155, _, _, _, _, _, _, _, <token> _), <answer> _, 
[156] = PINGROUP(156, pcie6b_clk, _, _, _, <token> _, _, _, _), <answer> _, 
[157] = PINGROUP(157, _, _, _, _, _, <token> _, _, _), <answer> _, 
[158] = <token> _, _, _, _, _, _, _, _, _), <answer> PINGROUP(158, 
[159] = PINGROUP(159, _, _, _, _, _, <token> _, _, _), <answer> _, 
[160] = PINGROUP(160, RESOUT_GPIO, _, _, _, _, _, _, _, <token> <answer> _), 
[161] = PINGROUP(161, qdss_cti, _, _, _, _, _, _, <token> _), <answer> _, 
[162] = <token> sd_write, qdss_cti, _, _, _, _, _, _, _), <answer> PINGROUP(162, 
[163] = <token> usb0_sbrx, _, _, _, _, _, _, _, _), <answer> PINGROUP(163, 
[164] = PINGROUP(164, usb0_sbtx, _, _, _, <token> _, _, _, _), <answer> _, 
[165] = PINGROUP(165, usb0_sbtx, _, <token> _, _, _, _, _, _), <answer> _, 
[166] = PINGROUP(166, _, _, <token> _, _, _, _, _, _), <answer> _, 
[167] = PINGROUP(167, _, _, _, _, <token> _, _, _, _), <answer> _, 
[168] = PINGROUP(168, eusb0_ac, _, _, _, _, _, <token> _, _), <answer> _, 
[169] <token> PINGROUP(169, eusb3_ac, _, _, _, _, _, _, _, _), <answer> = 
[170] = PINGROUP(170, <token> _, _, _, _, _, _, _, _), <answer> _, 
[171] = PINGROUP(171, _, _, _, _, _, _, <token> _, _), <answer> _, 
[172] = <token> usb1_sbrx, _, _, _, _, _, _, _, _), <answer> PINGROUP(172, 
[173] = <token> usb1_sbtx, _, _, _, _, _, _, _, _), <answer> PINGROUP(173, 
[174] = PINGROUP(174, usb1_sbtx, <token> _, _, _, _, _, _, _), <answer> _, 
[175] = <token> _, _, _, _, _, _, _, _, _), <answer> PINGROUP(175, 
[176] <token> PINGROUP(176, _, _, _, _, _, _, _, _, _), <answer> = 
[177] = PINGROUP(177, eusb1_ac, _, _, _, _, _, <token> _, _), <answer> _, 
[178] = PINGROUP(178, eusb6_ac, _, _, _, _, <token> _, _, _), <answer> _, 
[179] = PINGROUP(179, _, _, <token> _, _, _, _, _, _), <answer> _, 
<token> = PINGROUP(180, _, _, _, _, _, _, _, _, _), <answer> [180] 
[181] = PINGROUP(181, usb2_sbrx, prng_rosc3, phase_flag, _, atest_char, _, _, _, <token> <answer> _), 
[182] = PINGROUP(182, usb2_sbtx, prng_rosc2, phase_flag, _, <token> _, _, _, _), <answer> atest_char3, 
<token> = PINGROUP(183, usb2_sbtx, _, _, _, _, _, _, _, _), <answer> [183] 
<token> = PINGROUP(184, phase_flag, _, atest_char1, _, _, _, _, _, _), <answer> [184] 
[185] = PINGROUP(185, phase_flag, _, atest_char0, <token> _, _, _, _, _), <answer> _, 
[186] = PINGROUP(186, <token> prng_rosc0, phase_flag, _, _, _, _, _, _), <answer> eusb2_ac, 
[187] = PINGROUP(187, eusb5_ac, cri_trng, <token> _, _, _, _, _, _), <answer> phase_flag, 
[188] = PINGROUP(188, prng_rosc1, phase_flag, <token> atest_char2, _, _, _, _, _), <answer> _, 
[189] = PINGROUP(189, <token> _, _, _, _, _, _, _, _), <answer> _, 
[190] = PINGROUP(190, _, <token> _, _, _, _, _, _, _), <answer> _, 
<token> = PINGROUP(191, _, _, _, _, _, _, _, _, _), <answer> [191] 
[192] = PINGROUP(192, _, _, _, _, _, _, _, <token> _), <answer> _, 
[193] = PINGROUP(193, _, _, <token> _, _, _, _, _, _), <answer> _, 
[194] <token> PINGROUP(194, _, _, _, _, _, _, _, _, _), <answer> = 
[195] <token> PINGROUP(195, _, _, _, _, _, _, _, _, _), <answer> = 
[196] <token> PINGROUP(196, _, _, _, _, _, _, _, _, _), <answer> = 
[197] = PINGROUP(197, <token> _, _, _, _, _, _, _, _), <answer> _, 
[198] = PINGROUP(198, _, _, <token> _, _, _, _, _, _), <answer> _, 
[199] <token> PINGROUP(199, _, _, _, _, _, _, _, _, _), <answer> = 
[200] = <token> _, _, _, _, _, _, _, _, _), <answer> PINGROUP(200, 
[201] = PINGROUP(201, _, _, _, _, _, _, <token> _, _), <answer> _, 
[202] = PINGROUP(202, _, _, _, _, _, _, _, <token> _), <answer> _, 
[203] <token> PINGROUP(203, _, _, _, _, _, _, _, _, _), <answer> = 
[204] = PINGROUP(204, _, _, _, _, <token> _, _, _, _), <answer> _, 
[205] = PINGROUP(205, _, <token> _, _, _, _, _, _, _), <answer> _, 
[206] = PINGROUP(206, _, _, <token> _, _, _, _, _, _), <answer> _, 
<token> = PINGROUP(207, _, _, _, _, _, _, _, _, _), <answer> [207] 
[208] = PINGROUP(208, _, _, _, <token> _, _, _, _, _), <answer> _, 
[209] = PINGROUP(209, _, _, _, _, _, <token> _, _, _), <answer> _, 
[210] = PINGROUP(210, _, _, _, _, _, <token> _, _, _), <answer> _, 
[211] <token> PINGROUP(211, _, _, _, _, _, _, _, _, _), <answer> = 
[212] <token> PINGROUP(212, _, _, _, _, _, _, _, _, _), <answer> = 
<token> = PINGROUP(213, _, _, _, _, _, _, _, _, _), <answer> [213] 
[214] = PINGROUP(214, _, _, _, _, _, _, _, _, <token> <answer> _), 
[215] = <token> _, qdss_cti, _, _, _, _, _, _, _), <answer> PINGROUP(215, 
[216] = PINGROUP(216, _, _, _, <token> _, _, _, _, _), <answer> _, 
<token> = PINGROUP(217, _, qdss_cti, _, _, _, _, _, _, _), <answer> [217] 
[218] = PINGROUP(218, _, _, _, _, _, _, <token> _, _), <answer> _, 
[219] = PINGROUP(219, _, qdss_gpio, _, _, _, _, _, _, <token> <answer> _), 
[220] = PINGROUP(220, _, qdss_gpio, _, <token> _, _, _, _, _), <answer> _, 
[221] = PINGROUP(221, _, qdss_gpio, _, _, _, <token> _, _, _), <answer> _, 
[222] = <token> _, qdss_gpio, _, _, _, _, _, _, _), <answer> PINGROUP(222, 
<token> = PINGROUP(223, _, qdss_gpio, _, _, _, _, _, _, _), <answer> [223] 
[224] = <token> _, qdss_gpio, _, _, _, _, _, _, _), <answer> PINGROUP(224, 
[225] = PINGROUP(225, _, qdss_gpio, <token> _, _, _, _, _, _), <answer> _, 
[226] = PINGROUP(226, _, qdss_gpio, _, _, _, _, _, _, <token> <answer> _), 
[227] = PINGROUP(227, _, qdss_gpio, <token> _, _, _, _, _, _), <answer> _, 
[228] = PINGROUP(228, _, qdss_gpio, _, <token> _, _, _, _, _), <answer> _, 
[229] = PINGROUP(229, <token> _, _, _, _, _, _, _, _), <answer> qdss_gpio, 
[230] = PINGROUP(230, qdss_gpio, _, _, _, _, _, _, <token> _), <answer> _, 
[231] = PINGROUP(231, qdss_gpio, _, _, _, _, _, _, _, <token> <answer> _), 
<token> = PINGROUP(232, qdss_gpio, _, _, _, _, _, _, _, _), <answer> [232] 
[233] = PINGROUP(233, qdss_gpio, _, _, _, _, _, <token> _, _), <answer> _, 
[234] = PINGROUP(234, qdss_gpio, _, _, _, _, _, _, _, <token> <answer> _), 
[235] = <token> aon_cci, qdss_gpio, _, _, _, _, _, _, _), <answer> PINGROUP(235, 
[236] = PINGROUP(236, aon_cci, qdss_gpio, <token> _, _, _, _, _, _), <answer> _, 
[237] = PINGROUP(237, _, _, _, _, _, _, <token> _, _), <answer> _, 
[238] = UFS_RESET(ufs_reset, <token> <answer> 0x1f9000), 
[239] = SDC_QDSD_PINGROUP(sdc2_clk, <token> 14, 6), <answer> 0x1f2000, 
[240] = <token> 0x1f2000, 11, 3), <answer> SDC_QDSD_PINGROUP(sdc2_cmd, 
<token> = SDC_QDSD_PINGROUP(sdc2_data, 0x1f2000, 9, 0), <answer> [241] 
static const struct <token> x1e80100_pdc_map[] = { <answer> msm_gpio_wakeirq_map 
{ 0, 72 }, { 2, 70 }, { 3, 71 }, { 6, 123 }, { 7, 67 }, <token> 11, 85 }, <answer> { 
{ 15, 68 }, { 18, <token> }, { 19, 69 }, { 21, 158 }, { 23, 143 }, { 26, 129 }, <answer> 122 
{ 27, 144 }, { 28, 77 }, { 29, 78 <token> { 30, 92 }, { 32, 145 }, { 33, 115 }, <answer> }, 
{ 34, 130 }, { 35, 146 }, { 36, 147 }, { 39, 80 }, { 43, 148 }, { 47, 149 <token> <answer> }, 
{ 51, 79 }, { 53, 89 }, { 59, 87 }, { 64, 90 }, { 65, 106 <token> { 66, 142 }, <answer> }, 
{ 67, 88 }, { 71, 91 }, { <token> 152 }, { 79, 153 }, { 80, 125 }, { 81, 128 }, <answer> 75, 
{ 84, 137 }, { 85, 155 }, <token> 87, 156 }, { 91, 157 }, { 92, 138 }, { 94, 140 }, <answer> { 
{ 95, 141 }, { 113, 84 }, { 121, <token> }, { 123, 74 }, { 129, 76 }, { 131, 82 }, <answer> 73 
{ 134, 83 }, { 141, <token> }, { 144, 94 }, { 147, 96 }, { 148, 97 }, { 150, 102 }, <answer> 93 
<token> 151, 103 }, { 153, 104 }, { 156, 105 }, { 157, 107 }, { 163, 98 }, { 166, 112 }, <answer> { 
{ 172, 99 <token> { 181, 101 }, { 184, 116 }, { 193, 40 }, { 193, 117 }, { 196, 108 }, <answer> }, 
{ 203, 133 }, <token> 212, 120 }, { 213, 150 }, { 214, 121 }, { 215, 118 }, { 217, 109 }, <answer> { 
{ 220, 110 }, { 221, 111 }, <token> 222, 124 }, { 224, 131 }, { 225, 132 }, <answer> { 
static const struct msm_pinctrl_soc_data x1e80100_pinctrl = <token> <answer> { 
.pins = <token> <answer> x1e80100_pins, 
<token> = ARRAY_SIZE(x1e80100_pins), <answer> .npins 
<token> = x1e80100_functions, <answer> .functions 
.nfunctions = <token> <answer> ARRAY_SIZE(x1e80100_functions), 
.groups <token> x1e80100_groups, <answer> = 
<token> = ARRAY_SIZE(x1e80100_groups), <answer> .ngroups 
.ngpios = <token> <answer> 239, 
.wakeirq_map = <token> <answer> x1e80100_pdc_map, 
.nwakeirq_map <token> ARRAY_SIZE(x1e80100_pdc_map), <answer> = 
.egpio_func <token> 9, <answer> = 
static <token> x1e80100_pinctrl_probe(struct platform_device *pdev) <answer> int 
<token> msm_pinctrl_probe(pdev, &x1e80100_pinctrl); <answer> return 
static <token> struct of_device_id x1e80100_pinctrl_of_match[] = { <answer> const 
{ <token> = "qcom,x1e80100-tlmm", }, <answer> .compatible 
<token> }, <answer> { 
static <token> platform_driver x1e80100_pinctrl_driver = { <answer> struct 
.driver <token> { <answer> = 
.name = <token> <answer> "x1e80100-tlmm", 
.of_match_table <token> x1e80100_pinctrl_of_match, <answer> = 
.probe = <token> <answer> x1e80100_pinctrl_probe, 
.remove_new <token> msm_pinctrl_remove, <answer> = 
static <token> __init x1e80100_pinctrl_init(void) <answer> int 
<token> platform_driver_register(&x1e80100_pinctrl_driver); <answer> return 
static void <token> x1e80100_pinctrl_exit(void) <answer> __exit 
MODULE_DESCRIPTION("QTI X1E80100 TLMM <token> driver"); <answer> pinctrl 
MODULE_DEVICE_TABLE(of, <token> <answer> x1e80100_pinctrl_of_match); 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/i2c.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/regulator/driver.h> 
#include <token> <answer> <linux/regulator/act8865.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/of_device.h> 
<token> <linux/power_supply.h> <answer> #include 
<token> <linux/regulator/of_regulator.h> <answer> #include 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> <dt-bindings/regulator/active-semi,8865-regulator.h> 
#define ACT8600_SYS_MODE <token> <answer> 0x00 
#define ACT8600_SYS_CTRL <token> <answer> 0x01 
#define ACT8600_DCDC1_VSET <token> <answer> 0x10 
<token> ACT8600_DCDC1_CTRL 0x12 <answer> #define 
<token> ACT8600_DCDC2_VSET 0x20 <answer> #define 
#define ACT8600_DCDC2_CTRL <token> <answer> 0x22 
#define ACT8600_DCDC3_VSET <token> <answer> 0x30 
#define <token> 0x32 <answer> ACT8600_DCDC3_CTRL 
#define ACT8600_SUDCDC4_VSET <token> <answer> 0x40 
<token> ACT8600_SUDCDC4_CTRL 0x41 <answer> #define 
<token> ACT8600_LDO5_VSET 0x50 <answer> #define 
<token> ACT8600_LDO5_CTRL 0x51 <answer> #define 
<token> ACT8600_LDO6_VSET 0x60 <answer> #define 
#define <token> 0x61 <answer> ACT8600_LDO6_CTRL 
#define ACT8600_LDO7_VSET <token> <answer> 0x70 
<token> ACT8600_LDO7_CTRL 0x71 <answer> #define 
#define <token> 0x80 <answer> ACT8600_LDO8_VSET 
#define <token> 0x81 <answer> ACT8600_LDO8_CTRL 
#define <token> 0x91 <answer> ACT8600_LDO910_CTRL 
#define <token> 0xA1 <answer> ACT8600_APCH0 
#define <token> 0xA8 <answer> ACT8600_APCH1 
#define <token> 0xA9 <answer> ACT8600_APCH2 
<token> ACT8600_APCH_STAT 0xAA <answer> #define 
<token> ACT8600_OTG0 0xB0 <answer> #define 
#define <token> 0xB2 <answer> ACT8600_OTG1 
#define <token> 0x00 <answer> ACT8846_SYS0 
#define ACT8846_SYS1 <token> <answer> 0x01 
#define <token> 0x10 <answer> ACT8846_REG1_VSET 
#define ACT8846_REG1_CTRL <token> <answer> 0x12 
<token> ACT8846_REG2_VSET0 0x20 <answer> #define 
#define <token> 0x21 <answer> ACT8846_REG2_VSET1 
<token> ACT8846_REG2_CTRL 0x22 <answer> #define 
#define <token> 0x30 <answer> ACT8846_REG3_VSET0 
#define <token> 0x31 <answer> ACT8846_REG3_VSET1 
#define <token> 0x32 <answer> ACT8846_REG3_CTRL 
#define ACT8846_REG4_VSET0 <token> <answer> 0x40 
<token> ACT8846_REG4_VSET1 0x41 <answer> #define 
#define <token> 0x42 <answer> ACT8846_REG4_CTRL 
<token> ACT8846_REG5_VSET 0x50 <answer> #define 
#define ACT8846_REG5_CTRL <token> <answer> 0x51 
<token> ACT8846_REG6_VSET 0x58 <answer> #define 
#define <token> 0x59 <answer> ACT8846_REG6_CTRL 
#define ACT8846_REG7_VSET <token> <answer> 0x60 
#define <token> 0x61 <answer> ACT8846_REG7_CTRL 
<token> ACT8846_REG8_VSET 0x68 <answer> #define 
#define <token> 0x69 <answer> ACT8846_REG8_CTRL 
#define <token> 0x70 <answer> ACT8846_REG9_VSET 
#define <token> 0x71 <answer> ACT8846_REG9_CTRL 
#define ACT8846_REG10_VSET <token> <answer> 0x80 
#define <token> 0x81 <answer> ACT8846_REG10_CTRL 
#define ACT8846_REG11_VSET <token> <answer> 0x90 
<token> ACT8846_REG11_CTRL 0x91 <answer> #define 
#define <token> 0xa0 <answer> ACT8846_REG12_VSET 
#define ACT8846_REG12_CTRL <token> <answer> 0xa1 
#define ACT8846_REG13_CTRL <token> <answer> 0xb1 
#define <token> 0xc3 <answer> ACT8846_GLB_OFF_CTRL 
<token> ACT8846_OFF_SYSMASK 0x18 <answer> #define 
#define <token> 0x00 <answer> ACT8865_SYS_MODE 
#define ACT8865_SYS_CTRL <token> <answer> 0x01 
#define <token> 0x0b <answer> ACT8865_SYS_UNLK_REGS 
<token> ACT8865_DCDC1_VSET1 0x20 <answer> #define 
#define <token> 0x21 <answer> ACT8865_DCDC1_VSET2 
<token> ACT8865_DCDC1_CTRL 0x22 <answer> #define 
<token> ACT8865_DCDC1_SUS 0x24 <answer> #define 
#define <token> 0x30 <answer> ACT8865_DCDC2_VSET1 
#define ACT8865_DCDC2_VSET2 <token> <answer> 0x31 
#define ACT8865_DCDC2_CTRL <token> <answer> 0x32 
<token> ACT8865_DCDC2_SUS 0x34 <answer> #define 
#define ACT8865_DCDC3_VSET1 <token> <answer> 0x40 
<token> ACT8865_DCDC3_VSET2 0x41 <answer> #define 
<token> ACT8865_DCDC3_CTRL 0x42 <answer> #define 
#define <token> 0x44 <answer> ACT8865_DCDC3_SUS 
#define ACT8865_LDO1_VSET <token> <answer> 0x50 
<token> ACT8865_LDO1_CTRL 0x51 <answer> #define 
#define <token> 0x52 <answer> ACT8865_LDO1_SUS 
#define <token> 0x54 <answer> ACT8865_LDO2_VSET 
<token> ACT8865_LDO2_CTRL 0x55 <answer> #define 
#define <token> 0x56 <answer> ACT8865_LDO2_SUS 
#define <token> 0x60 <answer> ACT8865_LDO3_VSET 
#define <token> 0x61 <answer> ACT8865_LDO3_CTRL 
#define <token> 0x62 <answer> ACT8865_LDO3_SUS 
#define <token> 0x64 <answer> ACT8865_LDO4_VSET 
<token> ACT8865_LDO4_CTRL 0x65 <answer> #define 
#define ACT8865_LDO4_SUS <token> <answer> 0x66 
<token> ACT8865_MSTROFF 0x20 <answer> #define 
<token> ACT8865_VOLTAGE_NUM 64 <answer> #define 
#define <token> 256 <answer> ACT8600_SUDCDC_VOLTAGE_NUM 
struct <token> { <answer> act8865 
struct regmap <token> <answer> *regmap; 
<token> off_reg; <answer> int 
<token> off_mask; <answer> int 
static const struct regmap_range act8600_reg_ranges[] <token> { <answer> = 
<token> 0x01), <answer> regmap_reg_range(0x00, 
regmap_reg_range(0x10, <token> <answer> 0x10), 
regmap_reg_range(0x12, <token> <answer> 0x12), 
regmap_reg_range(0x20, <token> <answer> 0x20), 
regmap_reg_range(0x22, <token> <answer> 0x22), 
regmap_reg_range(0x30, <token> <answer> 0x30), 
regmap_reg_range(0x32, <token> <answer> 0x32), 
<token> 0x41), <answer> regmap_reg_range(0x40, 
regmap_reg_range(0x50, <token> <answer> 0x51), 
<token> 0x61), <answer> regmap_reg_range(0x60, 
regmap_reg_range(0x70, <token> <answer> 0x71), 
regmap_reg_range(0x80, <token> <answer> 0x81), 
<token> 0x91), <answer> regmap_reg_range(0x91, 
regmap_reg_range(0xA1, <token> <answer> 0xA1), 
<token> 0xAA), <answer> regmap_reg_range(0xA8, 
regmap_reg_range(0xB0, <token> <answer> 0xB0), 
regmap_reg_range(0xB2, <token> <answer> 0xB2), 
regmap_reg_range(0xC1, <token> <answer> 0xC1), 
static <token> struct regmap_range act8600_reg_ro_ranges[] = { <answer> const 
regmap_reg_range(0xAA, <token> <answer> 0xAA), 
regmap_reg_range(0xC1, <token> <answer> 0xC1), 
static const <token> regmap_range act8600_reg_volatile_ranges[] = { <answer> struct 
regmap_reg_range(0x00, <token> <answer> 0x01), 
<token> 0x12), <answer> regmap_reg_range(0x12, 
<token> 0x22), <answer> regmap_reg_range(0x22, 
regmap_reg_range(0x32, <token> <answer> 0x32), 
regmap_reg_range(0x41, <token> <answer> 0x41), 
regmap_reg_range(0x51, <token> <answer> 0x51), 
<token> 0x61), <answer> regmap_reg_range(0x61, 
<token> 0x71), <answer> regmap_reg_range(0x71, 
regmap_reg_range(0x81, <token> <answer> 0x81), 
<token> 0xA8), <answer> regmap_reg_range(0xA8, 
regmap_reg_range(0xAA, <token> <answer> 0xAA), 
regmap_reg_range(0xB0, <token> <answer> 0xB0), 
<token> 0xC1), <answer> regmap_reg_range(0xC1, 
static <token> struct regmap_access_table act8600_write_ranges_table = { <answer> const 
.yes_ranges <token> act8600_reg_ranges, <answer> = 
.n_yes_ranges = <token> <answer> ARRAY_SIZE(act8600_reg_ranges), 
.no_ranges = <token> <answer> act8600_reg_ro_ranges, 
.n_no_ranges <token> ARRAY_SIZE(act8600_reg_ro_ranges), <answer> = 
static const struct regmap_access_table act8600_read_ranges_table <token> { <answer> = 
.yes_ranges = <token> <answer> act8600_reg_ranges, 
.n_yes_ranges <token> ARRAY_SIZE(act8600_reg_ranges), <answer> = 
static const struct regmap_access_table <token> = { <answer> act8600_volatile_ranges_table 
<token> = act8600_reg_volatile_ranges, <answer> .yes_ranges 
.n_yes_ranges <token> ARRAY_SIZE(act8600_reg_volatile_ranges), <answer> = 
static const struct regmap_config <token> = { <answer> act8600_regmap_config 
.reg_bits <token> 8, <answer> = 
.val_bits = <token> <answer> 8, 
.max_register = <token> <answer> 0xFF, 
.wr_table <token> &act8600_write_ranges_table, <answer> = 
.rd_table <token> &act8600_read_ranges_table, <answer> = 
.volatile_table <token> &act8600_volatile_ranges_table, <answer> = 
<token> const struct regmap_config act8865_regmap_config = { <answer> static 
<token> = 8, <answer> .reg_bits 
<token> = 8, <answer> .val_bits 
static const struct linear_range <token> = { <answer> act8865_voltage_ranges[] 
REGULATOR_LINEAR_RANGE(600000, 0, 23, <token> <answer> 25000), 
REGULATOR_LINEAR_RANGE(1200000, 24, <token> 50000), <answer> 47, 
<token> 48, 63, 100000), <answer> REGULATOR_LINEAR_RANGE(2400000, 
static const struct <token> act8600_sudcdc_voltage_ranges[] = { <answer> linear_range 
REGULATOR_LINEAR_RANGE(3000000, 0, 63, <token> <answer> 0), 
<token> 64, 159, 100000), <answer> REGULATOR_LINEAR_RANGE(3000000, 
REGULATOR_LINEAR_RANGE(12600000, <token> 191, 200000), <answer> 160, 
<token> 192, 247, 400000), <answer> REGULATOR_LINEAR_RANGE(19000000, 
REGULATOR_LINEAR_RANGE(41400000, 248, 255, <token> <answer> 0), 
static int act8865_set_suspend_state(struct regulator_dev <token> bool enable) <answer> *rdev, 
struct regmap *regmap <token> rdev->regmap; <answer> = 
int id <token> rdev->desc->id, reg, val; <answer> = 
<token> (id) { <answer> switch 
<token> ACT8865_ID_DCDC1: <answer> case 
reg <token> ACT8865_DCDC1_SUS; <answer> = 
<token> = 0xa8; <answer> val 
case <token> <answer> ACT8865_ID_DCDC2: 
reg <token> ACT8865_DCDC2_SUS; <answer> = 
<token> = 0xa8; <answer> val 
case <token> <answer> ACT8865_ID_DCDC3: 
reg = <token> <answer> ACT8865_DCDC3_SUS; 
val <token> 0xa8; <answer> = 
case <token> <answer> ACT8865_ID_LDO1: 
reg = <token> <answer> ACT8865_LDO1_SUS; 
val <token> 0xe8; <answer> = 
<token> ACT8865_ID_LDO2: <answer> case 
reg = <token> <answer> ACT8865_LDO2_SUS; 
val = <token> <answer> 0xe8; 
<token> ACT8865_ID_LDO3: <answer> case 
reg <token> ACT8865_LDO3_SUS; <answer> = 
val <token> 0xe8; <answer> = 
<token> ACT8865_ID_LDO4: <answer> case 
reg = <token> <answer> ACT8865_LDO4_SUS; 
<token> = 0xe8; <answer> val 
return <token> <answer> -EINVAL; 
<token> (enable) <answer> if 
<token> |= BIT(4); <answer> val 
return <token> reg, val); <answer> regmap_write(regmap, 
static int act8865_set_suspend_enable(struct regulator_dev <token> <answer> *rdev) 
return act8865_set_suspend_state(rdev, <token> <answer> true); 
static int <token> regulator_dev *rdev) <answer> act8865_set_suspend_disable(struct 
<token> act8865_set_suspend_state(rdev, false); <answer> return 
static unsigned int act8865_of_map_mode(unsigned int <token> <answer> mode) 
switch <token> { <answer> (mode) 
case <token> <answer> ACT8865_REGULATOR_MODE_FIXED: 
<token> REGULATOR_MODE_FAST; <answer> return 
case <token> <answer> ACT8865_REGULATOR_MODE_NORMAL: 
return <token> <answer> REGULATOR_MODE_NORMAL; 
case <token> <answer> ACT8865_REGULATOR_MODE_LOWPOWER: 
return <token> <answer> REGULATOR_MODE_STANDBY; 
return <token> <answer> REGULATOR_MODE_INVALID; 
static int <token> regulator_dev *rdev, unsigned int mode) <answer> act8865_set_mode(struct 
struct <token> *regmap = rdev->regmap; <answer> regmap 
<token> id = rdev_get_id(rdev); <answer> int 
int reg, <token> = 0; <answer> val 
switch <token> { <answer> (id) 
<token> ACT8865_ID_DCDC1: <answer> case 
reg = <token> <answer> ACT8865_DCDC1_CTRL; 
case <token> <answer> ACT8865_ID_DCDC2: 
<token> = ACT8865_DCDC2_CTRL; <answer> reg 
<token> ACT8865_ID_DCDC3: <answer> case 
reg = <token> <answer> ACT8865_DCDC3_CTRL; 
<token> ACT8865_ID_LDO1: <answer> case 
<token> = ACT8865_LDO1_CTRL; <answer> reg 
case <token> <answer> ACT8865_ID_LDO2: 
reg = <token> <answer> ACT8865_LDO2_CTRL; 
<token> ACT8865_ID_LDO3: <answer> case 
<token> = ACT8865_LDO3_CTRL; <answer> reg 
case <token> <answer> ACT8865_ID_LDO4: 
reg = <token> <answer> ACT8865_LDO4_CTRL; 
return <token> <answer> -EINVAL; 
switch (mode) <token> <answer> { 
case <token> <answer> REGULATOR_MODE_FAST: 
case <token> <answer> REGULATOR_MODE_NORMAL: 
<token> (id <= ACT8865_ID_DCDC3) <answer> if 
val <token> BIT(5); <answer> = 
case <token> <answer> REGULATOR_MODE_STANDBY: 
if (id <token> ACT8865_ID_DCDC3) <answer> > 
<token> = BIT(5); <answer> val 
<token> -EINVAL; <answer> return 
return <token> reg, BIT(5), val); <answer> regmap_update_bits(regmap, 
static unsigned int <token> regulator_dev *rdev) <answer> act8865_get_mode(struct 
struct regmap *regmap = <token> <answer> rdev->regmap; 
int <token> = rdev_get_id(rdev); <answer> id 
int <token> ret, val = 0; <answer> reg, 
<token> (id) { <answer> switch 
case <token> <answer> ACT8865_ID_DCDC1: 
<token> = ACT8865_DCDC1_CTRL; <answer> reg 
case <token> <answer> ACT8865_ID_DCDC2: 
reg = <token> <answer> ACT8865_DCDC2_CTRL; 
case <token> <answer> ACT8865_ID_DCDC3: 
<token> = ACT8865_DCDC3_CTRL; <answer> reg 
case <token> <answer> ACT8865_ID_LDO1: 
reg <token> ACT8865_LDO1_CTRL; <answer> = 
case <token> <answer> ACT8865_ID_LDO2: 
reg <token> ACT8865_LDO2_CTRL; <answer> = 
<token> ACT8865_ID_LDO3: <answer> case 
<token> = ACT8865_LDO3_CTRL; <answer> reg 
<token> ACT8865_ID_LDO4: <answer> case 
reg = <token> <answer> ACT8865_LDO4_CTRL; 
return <token> <answer> -EINVAL; 
ret = regmap_read(regmap, reg, <token> <answer> &val); 
if <token> <answer> (ret) 
<token> ret; <answer> return 
if (id <= ACT8865_ID_DCDC3 <token> (val & BIT(5))) <answer> && 
<token> REGULATOR_MODE_FAST; <answer> return 
<token> if (id > ACT8865_ID_DCDC3 && !(val & BIT(5))) <answer> else 
<token> REGULATOR_MODE_NORMAL; <answer> return 
return <token> <answer> REGULATOR_MODE_STANDBY; 
static const struct <token> act8865_ops = { <answer> regulator_ops 
<token> = regulator_list_voltage_linear_range, <answer> .list_voltage 
.map_voltage <token> regulator_map_voltage_linear_range, <answer> = 
<token> = regulator_get_voltage_sel_regmap, <answer> .get_voltage_sel 
.set_voltage_sel <token> regulator_set_voltage_sel_regmap, <answer> = 
<token> = regulator_enable_regmap, <answer> .enable 
.disable <token> regulator_disable_regmap, <answer> = 
.set_mode = <token> <answer> act8865_set_mode, 
.get_mode <token> act8865_get_mode, <answer> = 
.is_enabled <token> regulator_is_enabled_regmap, <answer> = 
<token> = act8865_set_suspend_enable, <answer> .set_suspend_enable 
<token> = act8865_set_suspend_disable, <answer> .set_suspend_disable 
static const struct <token> act8865_ldo_ops = { <answer> regulator_ops 
<token> = regulator_list_voltage_linear_range, <answer> .list_voltage 
.map_voltage = <token> <answer> regulator_map_voltage_linear_range, 
.get_voltage_sel = <token> <answer> regulator_get_voltage_sel_regmap, 
.set_voltage_sel = <token> <answer> regulator_set_voltage_sel_regmap, 
.enable <token> regulator_enable_regmap, <answer> = 
<token> = regulator_disable_regmap, <answer> .disable 
.set_mode = <token> <answer> act8865_set_mode, 
<token> = act8865_get_mode, <answer> .get_mode 
.is_enabled <token> regulator_is_enabled_regmap, <answer> = 
.set_suspend_enable = <token> <answer> act8865_set_suspend_enable, 
.set_suspend_disable = <token> <answer> act8865_set_suspend_disable, 
.set_pull_down = <token> <answer> regulator_set_pull_down_regmap, 
<token> const struct regulator_ops act8865_fixed_ldo_ops = { <answer> static 
.enable <token> regulator_enable_regmap, <answer> = 
.disable = <token> <answer> regulator_disable_regmap, 
.is_enabled = <token> <answer> regulator_is_enabled_regmap, 
#define ACT88xx_REG_(_name, _family, _id, _vsel_reg, <token> _ops) \ <answer> _supply, 
[_family##_ID_##_id] = <token> \ <answer> { 
.name = _name, <token> <answer> \ 
.of_match = of_match_ptr(_name), <token> <answer> \ 
.of_map_mode <token> act8865_of_map_mode, \ <answer> = 
.regulators_node = <token> \ <answer> of_match_ptr("regulators"), 
.supply_name = _supply, <token> <answer> \ 
.id = <token> \ <answer> _family##_ID_##_id, 
<token> = REGULATOR_VOLTAGE, \ <answer> .type 
.ops = <token> \ <answer> _ops, 
<token> = ACT8865_VOLTAGE_NUM, \ <answer> .n_voltages 
.linear_ranges <token> act8865_voltage_ranges, \ <answer> = 
.n_linear_ranges <token> ARRAY_SIZE(act8865_voltage_ranges), \ <answer> = 
.vsel_reg <token> _family##_##_id##_##_vsel_reg, \ <answer> = 
<token> = ACT8865_VSEL_MASK, \ <answer> .vsel_mask 
.enable_reg = _family##_##_id##_CTRL, <token> <answer> \ 
.enable_mask = <token> \ <answer> ACT8865_ENA, 
.pull_down_reg = _family##_##_id##_CTRL, <token> <answer> \ 
<token> = ACT8865_DIS, \ <answer> .pull_down_mask 
.owner = THIS_MODULE, <token> <answer> \ 
<token> ACT88xx_REG(_name, _family, _id, _vsel_reg, _supply) \ <answer> #define 
ACT88xx_REG_(_name, _family, <token> _vsel_reg, _supply, &act8865_ops) <answer> _id, 
#define ACT88xx_LDO(_name, _family, <token> _vsel_reg, _supply) \ <answer> _id, 
ACT88xx_REG_(_name, _family, _id, _vsel_reg, <token> &act8865_ldo_ops) <answer> _supply, 
<token> const struct regulator_desc act8600_regulators[] = { <answer> static 
ACT88xx_REG("DCDC1", ACT8600, DCDC1, <token> "vp1"), <answer> VSET, 
ACT88xx_REG("DCDC2", ACT8600, DCDC2, VSET, <token> <answer> "vp2"), 
ACT88xx_REG("DCDC3", <token> DCDC3, VSET, "vp3"), <answer> ACT8600, 
<token> = "SUDCDC_REG4", <answer> .name 
<token> = of_match_ptr("SUDCDC_REG4"), <answer> .of_match 
.regulators_node <token> of_match_ptr("regulators"), <answer> = 
.id <token> ACT8600_ID_SUDCDC4, <answer> = 
.ops <token> &act8865_ops, <answer> = 
.type <token> REGULATOR_VOLTAGE, <answer> = 
<token> = ACT8600_SUDCDC_VOLTAGE_NUM, <answer> .n_voltages 
.linear_ranges = <token> <answer> act8600_sudcdc_voltage_ranges, 
<token> = ARRAY_SIZE(act8600_sudcdc_voltage_ranges), <answer> .n_linear_ranges 
.vsel_reg = <token> <answer> ACT8600_SUDCDC4_VSET, 
.vsel_mask = <token> <answer> ACT8600_SUDCDC_VSEL_MASK, 
.enable_reg = <token> <answer> ACT8600_SUDCDC4_CTRL, 
.enable_mask = <token> <answer> ACT8865_ENA, 
.owner <token> THIS_MODULE, <answer> = 
ACT88xx_REG("LDO5", ACT8600, LDO5, <token> "inl"), <answer> VSET, 
ACT88xx_REG("LDO6", <token> LDO6, VSET, "inl"), <answer> ACT8600, 
<token> ACT8600, LDO7, VSET, "inl"), <answer> ACT88xx_REG("LDO7", 
ACT88xx_REG("LDO8", ACT8600, LDO8, VSET, <token> <answer> "inl"), 
.name = <token> <answer> "LDO_REG9", 
<token> = of_match_ptr("LDO_REG9"), <answer> .of_match 
.regulators_node = <token> <answer> of_match_ptr("regulators"), 
.id <token> ACT8600_ID_LDO9, <answer> = 
.ops <token> &act8865_fixed_ldo_ops, <answer> = 
<token> = REGULATOR_VOLTAGE, <answer> .type 
<token> = 1, <answer> .n_voltages 
.fixed_uV <token> 3300000, <answer> = 
<token> = ACT8600_LDO910_CTRL, <answer> .enable_reg 
.enable_mask = <token> <answer> ACT8865_ENA, 
.owner = <token> <answer> THIS_MODULE, 
.name <token> "LDO_REG10", <answer> = 
.of_match <token> of_match_ptr("LDO_REG10"), <answer> = 
<token> = of_match_ptr("regulators"), <answer> .regulators_node 
.id = <token> <answer> ACT8600_ID_LDO10, 
<token> = &act8865_fixed_ldo_ops, <answer> .ops 
.type = <token> <answer> REGULATOR_VOLTAGE, 
.n_voltages <token> 1, <answer> = 
<token> = 1200000, <answer> .fixed_uV 
.enable_reg = <token> <answer> ACT8600_LDO910_CTRL, 
<token> = ACT8600_LDO10_ENA, <answer> .enable_mask 
<token> = THIS_MODULE, <answer> .owner 
static const struct regulator_desc <token> = { <answer> act8846_regulators[] 
ACT88xx_REG("REG1", <token> REG1, VSET, "vp1"), <answer> ACT8846, 
ACT88xx_REG("REG2", ACT8846, REG2, VSET0, <token> <answer> "vp2"), 
<token> ACT8846, REG3, VSET0, "vp3"), <answer> ACT88xx_REG("REG3", 
<token> ACT8846, REG4, VSET0, "vp4"), <answer> ACT88xx_REG("REG4", 
<token> ACT8846, REG5, VSET, "inl1"), <answer> ACT88xx_REG("REG5", 
<token> ACT8846, REG6, VSET, "inl1"), <answer> ACT88xx_REG("REG6", 
ACT88xx_REG("REG7", ACT8846, REG7, <token> "inl1"), <answer> VSET, 
ACT88xx_REG("REG8", ACT8846, <token> VSET, "inl2"), <answer> REG8, 
ACT88xx_REG("REG9", ACT8846, REG9, VSET, <token> <answer> "inl2"), 
<token> ACT8846, REG10, VSET, "inl3"), <answer> ACT88xx_REG("REG10", 
ACT88xx_REG("REG11", ACT8846, <token> VSET, "inl3"), <answer> REG11, 
ACT88xx_REG("REG12", ACT8846, REG12, VSET, <token> <answer> "inl3"), 
<token> const struct regulator_desc act8865_regulators[] = { <answer> static 
ACT88xx_REG("DCDC_REG1", ACT8865, DCDC1, <token> "vp1"), <answer> VSET1, 
ACT88xx_REG("DCDC_REG2", ACT8865, DCDC2, VSET1, <token> <answer> "vp2"), 
<token> ACT8865, DCDC3, VSET1, "vp3"), <answer> ACT88xx_REG("DCDC_REG3", 
<token> ACT8865, LDO1, VSET, "inl45"), <answer> ACT88xx_LDO("LDO_REG1", 
ACT88xx_LDO("LDO_REG2", ACT8865, LDO2, <token> "inl45"), <answer> VSET, 
ACT88xx_LDO("LDO_REG3", ACT8865, LDO3, VSET, <token> <answer> "inl67"), 
ACT88xx_LDO("LDO_REG4", <token> LDO4, VSET, "inl67"), <answer> ACT8865, 
static const struct regulator_desc act8865_alt_regulators[] <token> { <answer> = 
ACT88xx_REG("DCDC_REG1", ACT8865, DCDC1, VSET2, <token> <answer> "vp1"), 
<token> ACT8865, DCDC2, VSET2, "vp2"), <answer> ACT88xx_REG("DCDC_REG2", 
<token> ACT8865, DCDC3, VSET2, "vp3"), <answer> ACT88xx_REG("DCDC_REG3", 
ACT88xx_LDO("LDO_REG1", <token> LDO1, VSET, "inl45"), <answer> ACT8865, 
ACT88xx_LDO("LDO_REG2", ACT8865, LDO2, VSET, <token> <answer> "inl45"), 
ACT88xx_LDO("LDO_REG3", ACT8865, LDO3, <token> "inl67"), <answer> VSET, 
ACT88xx_LDO("LDO_REG4", ACT8865, <token> VSET, "inl67"), <answer> LDO4, 
<token> CONFIG_OF <answer> #ifdef 
<token> const struct of_device_id act8865_dt_ids[] = { <answer> static 
{ <token> = "active-semi,act8600", .data = (void *)ACT8600 }, <answer> .compatible 
{ .compatible = <token> .data = (void *)ACT8846 }, <answer> "active-semi,act8846", 
<token> .compatible = "active-semi,act8865", .data = (void *)ACT8865 }, <answer> { 
{ <token> <answer> } 
<token> act8865_dt_ids); <answer> MODULE_DEVICE_TABLE(of, 
static struct act8865_regulator_data <token> <answer> *act8865_get_regulator_data( 
int <token> struct act8865_platform_data *pdata) <answer> id, 
<token> i; <answer> int 
for (i = 0; i < <token> i++) { <answer> pdata->num_regulators; 
if (pdata->regulators[i].id <token> id) <answer> == 
<token> &pdata->regulators[i]; <answer> return 
return <token> <answer> NULL; 
static struct i2c_client <token> <answer> *act8865_i2c_client; 
<token> void act8865_power_off(void) <answer> static 
struct act8865 <token> <answer> *act8865; 
act8865 = <token> <answer> i2c_get_clientdata(act8865_i2c_client); 
regmap_write(act8865->regmap, act8865->off_reg, <token> <answer> act8865->off_mask); 
<token> (1); <answer> while 
static int act8600_charger_get_status(struct <token> *map) <answer> regmap 
unsigned <token> val; <answer> int 
<token> ret; <answer> int 
<token> state0, state1; <answer> u8 
ret <token> regmap_read(map, ACT8600_APCH_STAT, &val); <answer> = 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
state0 = val & <token> <answer> ACT8600_APCH_CSTATE0; 
state1 = val <token> ACT8600_APCH_CSTATE1; <answer> & 
if <token> && !state1) <answer> (state0 
<token> POWER_SUPPLY_STATUS_CHARGING; <answer> return 
<token> (!state0 && state1) <answer> if 
<token> POWER_SUPPLY_STATUS_NOT_CHARGING; <answer> return 
if (!state0 && <token> <answer> !state1) 
return <token> <answer> POWER_SUPPLY_STATUS_DISCHARGING; 
return <token> <answer> POWER_SUPPLY_STATUS_UNKNOWN; 
static int <token> power_supply *psy, <answer> act8600_charger_get_property(struct 
<token> power_supply_property psp, union power_supply_propval *val) <answer> enum 
struct <token> *map = power_supply_get_drvdata(psy); <answer> regmap 
<token> ret; <answer> int 
switch <token> { <answer> (psp) 
case <token> <answer> POWER_SUPPLY_PROP_STATUS: 
<token> = act8600_charger_get_status(map); <answer> ret 
if (ret <token> 0) <answer> < 
return <token> <answer> ret; 
val->intval = <token> <answer> ret; 
<token> -EINVAL; <answer> return 
<token> 0; <answer> return 
static enum <token> act8600_charger_properties[] = { <answer> power_supply_property 
static const struct <token> act8600_charger_desc = { <answer> power_supply_desc 
<token> = "act8600-charger", <answer> .name 
<token> = POWER_SUPPLY_TYPE_BATTERY, <answer> .type 
.properties = <token> <answer> act8600_charger_properties, 
.num_properties = <token> <answer> ARRAY_SIZE(act8600_charger_properties), 
<token> = act8600_charger_get_property, <answer> .get_property 
static int act8600_charger_probe(struct device *dev, struct regmap <token> <answer> *regmap) 
struct power_supply <token> <answer> *charger; 
struct <token> cfg = { <answer> power_supply_config 
<token> = regmap, <answer> .drv_data 
<token> = dev->of_node, <answer> .of_node 
charger <token> devm_power_supply_register(dev, &act8600_charger_desc, &cfg); <answer> = 
return <token> <answer> PTR_ERR_OR_ZERO(charger); 
static int <token> i2c_client *client) <answer> act8865_pmic_probe(struct 
<token> struct i2c_device_id *i2c_id = i2c_client_get_device_id(client); <answer> const 
const <token> regulator_desc *regulators; <answer> struct 
struct act8865_platform_data *pdata <token> NULL; <answer> = 
struct device *dev = <token> <answer> &client->dev; 
int <token> ret, num_regulators; <answer> i, 
struct act8865 <token> <answer> *act8865; 
const <token> regmap_config *regmap_config; <answer> struct 
<token> long type; <answer> unsigned 
<token> off_reg, off_mask; <answer> int 
int <token> = 0; <answer> voltage_select 
if (dev->of_node) <token> <answer> { 
<token> struct of_device_id *id; <answer> const 
id <token> of_match_device(of_match_ptr(act8865_dt_ids), dev); <answer> = 
if <token> <answer> (!id) 
<token> -ENODEV; <answer> return 
type = <token> long) id->data; <answer> (unsigned 
voltage_select <token> !!of_get_property(dev->of_node, <answer> = 
} else <token> <answer> { 
<token> = i2c_id->driver_data; <answer> type 
<token> = dev_get_platdata(dev); <answer> pdata 
<token> (type) { <answer> switch 
<token> ACT8600: <answer> case 
regulators = <token> <answer> act8600_regulators; 
num_regulators <token> ARRAY_SIZE(act8600_regulators); <answer> = 
<token> = &act8600_regmap_config; <answer> regmap_config 
off_reg <token> -1; <answer> = 
off_mask <token> -1; <answer> = 
<token> ACT8846: <answer> case 
<token> = act8846_regulators; <answer> regulators 
num_regulators <token> ARRAY_SIZE(act8846_regulators); <answer> = 
regmap_config = <token> <answer> &act8865_regmap_config; 
off_reg <token> ACT8846_GLB_OFF_CTRL; <answer> = 
off_mask <token> ACT8846_OFF_SYSMASK; <answer> = 
<token> ACT8865: <answer> case 
<token> (voltage_select) { <answer> if 
regulators = <token> <answer> act8865_alt_regulators; 
num_regulators = <token> <answer> ARRAY_SIZE(act8865_alt_regulators); 
} <token> { <answer> else 
regulators = <token> <answer> act8865_regulators; 
num_regulators <token> ARRAY_SIZE(act8865_regulators); <answer> = 
regmap_config = <token> <answer> &act8865_regmap_config; 
off_reg = <token> <answer> ACT8865_SYS_CTRL; 
off_mask <token> ACT8865_MSTROFF; <answer> = 
dev_err(dev, <token> device id %lu\n", type); <answer> "invalid 
return <token> <answer> -EINVAL; 
<token> = devm_kzalloc(dev, sizeof(struct act8865), GFP_KERNEL); <answer> act8865 
if <token> <answer> (!act8865) 
return <token> <answer> -ENOMEM; 
act8865->regmap = <token> regmap_config); <answer> devm_regmap_init_i2c(client, 
if (IS_ERR(act8865->regmap)) <token> <answer> { 
ret <token> PTR_ERR(act8865->regmap); <answer> = 
dev_err(dev, "Failed to allocate register <token> %d\n", ret); <answer> map: 
return <token> <answer> ret; 
if (of_device_is_system_power_controller(dev->of_node)) <token> <answer> { 
if (!pm_power_off && (off_reg > 0)) <token> <answer> { 
act8865_i2c_client <token> client; <answer> = 
act8865->off_reg = <token> <answer> off_reg; 
act8865->off_mask <token> off_mask; <answer> = 
pm_power_off = <token> <answer> act8865_power_off; 
} else <token> <answer> { 
dev_err(dev, <token> to set poweroff capability, already defined\n"); <answer> "Failed 
<token> <linux/etherdevice.h> <answer> #include 
<token> <net/mac80211.h> <answer> #include 
#include <token> <answer> "data_rx.h" 
#include <token> <answer> "wfx.h" 
#include <token> <answer> "bh.h" 
#include <token> <answer> "sta.h" 
static void wfx_rx_handle_ba(struct <token> *wvif, struct ieee80211_mgmt *mgmt) <answer> wfx_vif 
struct ieee80211_vif *vif <token> wvif_to_vif(wvif); <answer> = 
int <token> tid; <answer> params, 
<token> (wfx_api_older_than(wvif->wdev, 3, 6)) <answer> if 
switch (mgmt->u.action.u.addba_req.action_code) <token> <answer> { 
<token> WLAN_ACTION_ADDBA_REQ: <answer> case 
<token> = le16_to_cpu(mgmt->u.action.u.addba_req.capab); <answer> params 
tid = (params & IEEE80211_ADDBA_PARAM_TID_MASK) >> <token> <answer> 2; 
<token> mgmt->sa, tid); <answer> ieee80211_start_rx_ba_session_offl(vif, 
case <token> <answer> WLAN_ACTION_DELBA: 
params <token> le16_to_cpu(mgmt->u.action.u.delba.params); <answer> = 
tid = (params & IEEE80211_DELBA_PARAM_TID_MASK) <token> 12; <answer> >> 
<token> mgmt->sa, tid); <answer> ieee80211_stop_rx_ba_session_offl(vif, 
void wfx_rx_cb(struct wfx_vif *wvif, const struct wfx_hif_ind_rx <token> struct sk_buff *skb) <answer> *arg, 
struct ieee80211_rx_status *hdr <token> IEEE80211_SKB_RXCB(skb); <answer> = 
struct ieee80211_hdr *frame <token> (struct ieee80211_hdr *)skb->data; <answer> = 
struct ieee80211_mgmt *mgmt = <token> ieee80211_mgmt *)skb->data; <answer> (struct 
memset(hdr, <token> sizeof(*hdr)); <answer> 0, 
if (arg->status == <token> <answer> HIF_STATUS_RX_FAIL_MIC) 
hdr->flag |= RX_FLAG_MMIC_ERROR | <token> <answer> RX_FLAG_IV_STRIPPED; 
else <token> (arg->status) <answer> if 
goto <token> <answer> drop; 
if <token> < sizeof(struct ieee80211_pspoll)) { <answer> (skb->len 
dev_warn(wvif->wdev->dev, "malformed <token> received\n"); <answer> SDU 
<token> drop; <answer> goto 
<token> = NL80211_BAND_2GHZ; <answer> hdr->band 
hdr->freq = <token> hdr->band); <answer> ieee80211_channel_to_frequency(arg->channel_number, 
if (arg->rxed_rate <token> 14) { <answer> >= 
<token> = RX_ENC_HT; <answer> hdr->encoding 
hdr->rate_idx = <token> - 14; <answer> arg->rxed_rate 
} else <token> (arg->rxed_rate >= 4) { <answer> if 
hdr->rate_idx = <token> - 2; <answer> arg->rxed_rate 
} <token> { <answer> else 
<token> = arg->rxed_rate; <answer> hdr->rate_idx 
<token> (!arg->rcpi_rssi) { <answer> if 
<token> |= RX_FLAG_NO_SIGNAL_VAL; <answer> hdr->flag 
dev_info(wvif->wdev->dev, <token> frame without RSSI data\n"); <answer> "received 
<token> = arg->rcpi_rssi / 2 - 110; <answer> hdr->signal 
hdr->antenna <token> 0; <answer> = 
<token> (arg->encryp) <answer> if 
hdr->flag |= <token> <answer> RX_FLAG_DECRYPTED; 
if <token> && <answer> (ieee80211_is_action(frame->frame_control) 
mgmt->u.action.category == WLAN_CATEGORY_BACK <token> <answer> && 
skb->len <token> IEEE80211_MIN_ACTION_SIZE) { <answer> > 
wfx_rx_handle_ba(wvif, <token> <answer> mgmt); 
goto <token> <answer> drop; 
<token> skb); <answer> ieee80211_rx_irqsafe(wvif->wdev->hw, 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/irqdomain.h> 
#include <token> <answer> <linux/io.h> 
<token> <linux/of_address.h> <answer> #include 
<token> <linux/of_irq.h> <answer> #include 
<token> <asm/exception.h> <answer> #include 
#include <token> <answer> <plat/irq.h> 
<token> <plat/orion-gpio.h> <answer> #include 
void __init <token> int irq_start, void __iomem *maskaddr) <answer> orion_irq_init(unsigned 
struct <token> *gc; <answer> irq_chip_generic 
struct irq_chip_type <token> <answer> *ct; 
writel(0, <token> <answer> maskaddr); 
gc = irq_alloc_generic_chip("orion_irq", 1, <token> maskaddr, <answer> irq_start, 
ct <token> gc->chip_types; <answer> = 
ct->chip.irq_mask <token> irq_gc_mask_clr_bit; <answer> = 
<token> = irq_gc_mask_set_bit; <answer> ct->chip.irq_unmask 
irq_setup_generic_chip(gc, <token> IRQ_GC_INIT_MASK_CACHE, <answer> IRQ_MSK(32), 
<token> IRQ_LEVEL | IRQ_NOPROBE); <answer> IRQ_NOREQUEST, 
#include <token> <answer> "bcachefs.h" 
<token> "alloc_background.h" <answer> #include 
#include <token> <answer> "alloc_foreground.h" 
<token> "btree_iter.h" <answer> #include 
<token> "btree_update.h" <answer> #include 
#include <token> <answer> "btree_write_buffer.h" 
#include <token> <answer> "buckets.h" 
<token> "clock.h" <answer> #include 
#include <token> <answer> "errcode.h" 
<token> "error.h" <answer> #include 
#include <token> <answer> "lru.h" 
#include <token> <answer> "move.h" 
<token> "movinggc.h" <answer> #include 
<token> "trace.h" <answer> #include 
<token> <linux/freezer.h> <answer> #include 
<token> <linux/kthread.h> <answer> #include 
<token> <linux/math64.h> <answer> #include 
#include <token> <answer> <linux/sched/task.h> 
<token> <linux/wait.h> <answer> #include 
<token> buckets_in_flight { <answer> struct 
struct <token> table; <answer> rhashtable 
struct <token> *first; <answer> move_bucket_in_flight 
struct <token> *last; <answer> move_bucket_in_flight 
size_t <token> <answer> nr; 
<token> sectors; <answer> size_t 
static const struct rhashtable_params bch_move_bucket_params <token> { <answer> = 
.head_offset = offsetof(struct move_bucket_in_flight, <token> <answer> hash), 
.key_offset <token> offsetof(struct move_bucket_in_flight, bucket.k), <answer> = 
<token> = sizeof(struct move_bucket_key), <answer> .key_len 
static <token> move_bucket_in_flight * <answer> struct 
<token> buckets_in_flight *list, struct move_bucket b) <answer> move_bucket_in_flight_add(struct 
struct move_bucket_in_flight <token> = kzalloc(sizeof(*new), GFP_KERNEL); <answer> *new 
int <token> <answer> ret; 
<token> (!new) <answer> if 
<token> ERR_PTR(-ENOMEM); <answer> return 
new->bucket <token> b; <answer> = 
ret = rhashtable_lookup_insert_fast(&list->table, <token> <answer> &new->hash, 
if (ret) <token> <answer> { 
<token> ERR_PTR(ret); <answer> return 
<token> (!list->first) <answer> if 
list->first = <token> <answer> new; 
<token> = new; <answer> list->last->next 
<token> = new; <answer> list->last 
<token> += b.sectors; <answer> list->sectors 
return <token> <answer> new; 
static <token> bch2_bucket_is_movable(struct btree_trans *trans, <answer> int 
struct move_bucket *b, <token> time) <answer> u64 
struct btree_iter <token> <answer> iter; 
<token> bkey_s_c k; <answer> struct 
struct <token> _a; <answer> bch_alloc_v4 
<token> struct bch_alloc_v4 *a; <answer> const 
<token> ret; <answer> int 
if <token> <answer> (bch2_bucket_is_open(trans->c, 
<token> 0; <answer> return 
k <token> bch2_bkey_get_iter(trans, &iter, BTREE_ID_alloc, <answer> = 
b->k.bucket, <token> <answer> BTREE_ITER_CACHED); 
ret <token> bkey_err(k); <answer> = 
if <token> <answer> (ret) 
<token> ret; <answer> return 
a <token> bch2_alloc_to_v4(k, &_a); <answer> = 
<token> = a->gen; <answer> b->k.gen 
b->sectors <token> bch2_bucket_sectors_dirty(*a); <answer> = 
ret <token> data_type_movable(a->data_type) && <answer> = 
<token> && <answer> a->fragmentation_lru 
a->fragmentation_lru <= <token> <answer> time; 
bch2_trans_iter_exit(trans, <token> <answer> &iter); 
return <token> <answer> ret; 
static void <token> moving_context *ctxt, <answer> move_buckets_wait(struct 
struct buckets_in_flight <token> <answer> *list, 
<token> flush) <answer> bool 
<token> move_bucket_in_flight *i; <answer> struct 
int <token> <answer> ret; 
while <token> = list->first)) { <answer> ((i 
<token> (flush) <answer> if 
move_ctxt_wait_event(ctxt, <token> <answer> !atomic_read(&i->count)); 
<token> (atomic_read(&i->count)) <answer> if 
list->first = <token> <answer> i->next; 
if <token> <answer> (!list->first) 
list->last <token> NULL; <answer> = 
list->sectors <token> i->bucket.sectors; <answer> -= 
ret <token> rhashtable_remove_fast(&list->table, &i->hash, <answer> = 
static bool bucket_in_flight(struct buckets_in_flight <token> <answer> *list, 
struct <token> k) <answer> move_bucket_key 
return rhashtable_lookup_fast(&list->table, <token> bch_move_bucket_params); <answer> &k, 
typedef DARRAY(struct move_bucket) <token> <answer> move_buckets; 
static int bch2_copygc_get_buckets(struct moving_context <token> <answer> *ctxt, 
struct buckets_in_flight <token> <answer> *buckets_in_flight, 
<token> *buckets) <answer> move_buckets 
struct btree_trans *trans <token> ctxt->trans; <answer> = 
struct <token> *c = trans->c; <answer> bch_fs 
size_t nr_to_get = max_t(size_t, 16U, buckets_in_flight->nr <token> 4); <answer> / 
size_t saw = 0, in_flight = 0, not_movable = 0, sectors <token> 0; <answer> = 
<token> ret; <answer> int 
move_buckets_wait(ctxt, buckets_in_flight, <token> <answer> false); 
ret = <token> <answer> bch2_btree_write_buffer_tryflush(trans); 
<token> (bch2_err_matches(ret, EROFS)) <answer> if 
return <token> <answer> ret; 
<token> (bch2_fs_fatal_err_on(ret, c, "%s: from bch2_btree_write_buffer_tryflush()", bch2_err_str(ret))) <answer> if 
return <token> <answer> ret; 
ret = for_each_btree_key_upto(trans, iter, <token> <answer> BTREE_ID_lru, 
lru_pos(BCH_LRU_FRAGMENTATION_START, 0, <token> <answer> 0), 
lru_pos(BCH_LRU_FRAGMENTATION_START, U64_MAX, <token> <answer> LRU_TIME_MAX), 
0, <token> ({ <answer> k, 
<token> move_bucket b = { .k.bucket = u64_to_bucket(k.k->p.offset) }; <answer> struct 
int <token> = 0; <answer> ret2 
ret2 = bch2_bucket_is_movable(trans, <token> lru_pos_time(k.k->p)); <answer> &b, 
<token> (ret2 < 0) <answer> if 
goto <token> <answer> err; 
if <token> <answer> (!ret2) 
else <token> (bucket_in_flight(buckets_in_flight, b.k)) <answer> if 
else <token> <answer> { 
ret2 = <token> b); <answer> darray_push(buckets, 
<token> (ret2) <answer> if 
goto <token> <answer> err; 
sectors <token> b.sectors; <answer> += 
ret2 = buckets->nr >= <token> <answer> nr_to_get; 
pr_debug("have: %zu (%zu) saw %zu in flight %zu not movable %zu got %zu (%zu)/%zu <token> ret %i", <answer> buckets 
<token> buckets_in_flight->sectors, <answer> buckets_in_flight->nr, 
saw, in_flight, not_movable, buckets->nr, sectors, nr_to_get, <token> <answer> ret); 
return <token> < 0 ? ret : 0; <answer> ret 
static <token> bch2_copygc(struct moving_context *ctxt, <answer> int 
<token> buckets_in_flight *buckets_in_flight, <answer> struct 
<token> *did_work) <answer> bool 
struct btree_trans *trans = <token> <answer> ctxt->trans; 
struct <token> *c = trans->c; <answer> bch_fs 
struct data_update_opts data_opts <token> { <answer> = 
<token> = BCH_WATERMARK_copygc, <answer> .btree_insert_flags 
move_buckets buckets <token> { 0 }; <answer> = 
struct <token> *f; <answer> move_bucket_in_flight 
u64 moved <token> atomic64_read(&ctxt->stats->sectors_moved); <answer> = 
int <token> = 0; <answer> ret 
ret <token> bch2_copygc_get_buckets(ctxt, buckets_in_flight, &buckets); <answer> = 
if <token> <answer> (ret) 
<token> err; <answer> goto 
darray_for_each(buckets, i) <token> <answer> { 
if (kthread_should_stop() <token> freezing(current)) <answer> || 
f = move_bucket_in_flight_add(buckets_in_flight, <token> <answer> *i); 
ret <token> PTR_ERR_OR_ZERO(f); <answer> = 
unsigned long bch2_copygc_wait_amount(struct bch_fs <token> <answer> *c) 
s64 wait <token> S64_MAX, fragmented_allowed, fragmented; <answer> = 
for_each_rw_member(c, <token> { <answer> ca) 
struct bch_dev_usage usage <token> bch2_dev_usage_read(ca); <answer> = 
<token> = ((__dev_buckets_available(ca, usage, BCH_WATERMARK_stripe) * <answer> fragmented_allowed 
ca->mi.bucket_size) >> <token> <answer> 1); 
fragmented <token> 0; <answer> = 
for (unsigned i = <token> i < BCH_DATA_NR; i++) <answer> 0; 
<token> (data_type_movable(i)) <answer> if 
fragmented += <token> <answer> usage.d[i].fragmented; 
wait = min(wait, max(0LL, <token> - fragmented)); <answer> fragmented_allowed 
<token> wait; <answer> return 
void bch2_copygc_wait_to_text(struct printbuf *out, <token> bch_fs *c) <answer> struct 
prt_printf(out, <token> waiting for: "); <answer> "Currently 
prt_human_readable_u64(out, max(0LL, c->copygc_wait <token> <answer> - 
atomic64_read(&c->io_clock[WRITE].now)) << <token> <answer> 9); 
prt_printf(out, "Currently waiting <token> "); <answer> since: 
<token> max(0LL, <answer> prt_human_readable_u64(out, 
atomic64_read(&c->io_clock[WRITE].now) <token> <answer> - 
<token> << 9); <answer> c->copygc_wait_at) 
prt_printf(out, <token> calculated wait: "); <answer> "Currently 
prt_human_readable_u64(out, <token> <answer> bch2_copygc_wait_amount(c)); 
static <token> bch2_copygc_thread(void *arg) <answer> int 
struct bch_fs <token> = arg; <answer> *c 
struct <token> ctxt; <answer> moving_context 
struct <token> move_stats; <answer> bch_move_stats 
struct io_clock <token> = &c->io_clock[WRITE]; <answer> *clock 
<token> buckets_in_flight *buckets; <answer> struct 
u64 last, <token> <answer> wait; 
int ret = <token> <answer> 0; 
buckets = kzalloc(sizeof(struct <token> GFP_KERNEL); <answer> buckets_in_flight), 
<token> (!buckets) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = rhashtable_init(&buckets->table, &bch_move_bucket_params); <answer> ret 
bch_err_msg(c, ret, "allocating copygc buckets <token> flight"); <answer> in 
<token> (ret) { <answer> if 
return <token> <answer> ret; 
<token> "copygc"); <answer> bch2_move_stats_init(&move_stats, 
bch2_moving_ctxt_init(&ctxt, <token> NULL, &move_stats, <answer> c, 
while <token> && !kthread_should_stop()) { <answer> (!ret 
<token> did_work = false; <answer> bool 
if (!c->copy_gc_enabled) <token> <answer> { 
<token> buckets, true); <answer> move_buckets_wait(&ctxt, 
kthread_wait_freezable(c->copy_gc_enabled <token> <answer> || 
if (unlikely(freezing(current))) <token> <answer> { 
move_buckets_wait(&ctxt, <token> true); <answer> buckets, 
last <token> atomic64_read(&clock->now); <answer> = 
wait <token> bch2_copygc_wait_amount(c); <answer> = 
if (wait <token> clock->max_slop) { <answer> > 
<token> = last; <answer> c->copygc_wait_at 
<token> = last + wait; <answer> c->copygc_wait 
<token> buckets, true); <answer> move_buckets_wait(&ctxt, 
trace_and_count(c, <token> c, wait, last + wait); <answer> copygc_wait, 
bch2_kthread_io_clock_wait(clock, last + <token> <answer> wait, 
<token> = 0; <answer> c->copygc_wait 
c->copygc_running <token> true; <answer> = 
<token> = bch2_copygc(&ctxt, buckets, &did_work); <answer> ret 
c->copygc_running = <token> <answer> false; 
if <token> && !did_work) { <answer> (!wait 
u64 <token> = bch2_min_rw_member_capacity(c); <answer> min_member_capacity 
<token> (min_member_capacity == U64_MAX) <answer> if 
min_member_capacity = 128 <token> 2048; <answer> * 
bch2_kthread_io_clock_wait(clock, last <token> (min_member_capacity >> 6), <answer> + 
move_buckets_wait(&ctxt, buckets, <token> <answer> true); 
<token> c); <answer> bch2_move_stats_exit(&move_stats, 
return <token> <answer> 0; 
void bch2_copygc_stop(struct <token> *c) <answer> bch_fs 
if (c->copygc_thread) <token> <answer> { 
c->copygc_thread <token> NULL; <answer> = 
int bch2_copygc_start(struct bch_fs <token> <answer> *c) 
struct task_struct <token> <answer> *t; 
int <token> <answer> ret; 
<token> (c->copygc_thread) <answer> if 
return <token> <answer> 0; 
<token> (c->opts.nochanges) <answer> if 
<token> 0; <answer> return 
if <token> <answer> (bch2_fs_init_fault("copygc_start")) 
return <token> <answer> -ENOMEM; 
t = <token> c, "bch-copygc/%s", c->name); <answer> kthread_create(bch2_copygc_thread, 
<token> = PTR_ERR_OR_ZERO(t); <answer> ret 
bch_err_msg(c, <token> "creating copygc thread"); <answer> ret, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
c->copygc_thread <token> t; <answer> = 
return <token> <answer> 0; 
<token> bch2_fs_copygc_init(struct bch_fs *c) <answer> void 
c->copygc_running <token> false; <answer> = 
<token> <linux/wmi.h> <answer> #include 
#include <token> <answer> "bioscfg.h" 
<token> bios_args { <answer> struct 
<token> signature; <answer> u32 
<token> command; <answer> u32 
u32 <token> <answer> commandtype; 
<token> datasize; <answer> u32 
u8 <token> __counted_by(datasize); <answer> data[] 
int hp_set_attribute(const char *a_name, const <token> *a_value) <answer> char 
int <token> <answer> security_area_size; 
<token> a_name_size, a_value_size; <answer> int 
u16 <token> = NULL; <answer> *buffer 
u16 <token> <answer> *start; 
int buffer_size, <token> ret; <answer> instance, 
<token> *auth_token_choice; <answer> char 
instance <token> hp_get_password_instance_for_type(SETUP_PASSWD); <answer> = 
if (instance < <token> { <answer> 0) 
<token> = -EINVAL; <answer> ret 
goto <token> <answer> out_set_attribute; 
int hp_wmi_perform_query(int query, enum hp_wmi_command command, void <token> <answer> *buffer, 
u32 insize, u32 <token> <answer> outsize) 
struct acpi_buffer input, output = { ACPI_ALLOCATE_BUFFER, NULL <token> <answer> }; 
struct bios_return <token> <answer> *bios_return; 
union <token> *obj = NULL; <answer> acpi_object 
struct <token> *args = NULL; <answer> bios_args 
int mid, <token> ret; <answer> actual_outsize, 
size_t <token> <answer> bios_args_size; 
<token> = hp_encode_outsize_for_pvsz(outsize); <answer> mid 
if <token> < 0)) <answer> (WARN_ON(mid 
return <token> <answer> mid; 
bios_args_size = struct_size(args, <token> insize); <answer> data, 
args <token> kmalloc(bios_args_size, GFP_KERNEL); <answer> = 
<token> (!args) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = bios_args_size; <answer> input.length 
input.pointer = <token> <answer> args; 
void *hp_ascii_to_utf16_unicode(u16 *p, const u8 <token> <answer> *str) 
<token> len = strlen(str); <answer> int 
<token> ret; <answer> int 
if (len <token> 0) <answer> == 
return <token> <answer> utf16_empty_string(p); 
int hp_wmi_set_bios_setting(u16 *input_buffer, <token> input_size) <answer> u32 
<token> acpi_object *obj; <answer> union 
<token> acpi_buffer input = {input_size, input_buffer}; <answer> struct 
struct acpi_buffer output <token> {ACPI_ALLOCATE_BUFFER, NULL}; <answer> = 
int <token> <answer> ret; 
ret = <token> 0, 1, &input, &output); <answer> wmi_evaluate_method(HP_WMI_SET_BIOS_SETTING_GUID, 
obj <token> output.pointer; <answer> = 
<token> (!obj) <answer> if 
<token> -EINVAL; <answer> return 
<token> (obj->type != ACPI_TYPE_INTEGER) { <answer> if 
<token> = -EINVAL; <answer> ret 
goto <token> <answer> out_free; 
ret <token> obj->integer.value; <answer> = 
if (ret) <token> <answer> { 
ret <token> hp_wmi_error_and_message(ret); <answer> = 
goto <token> <answer> out_free; 
return <token> <answer> ret; 
static <token> hp_attr_set_interface_probe(struct wmi_device *wdev, const void *context) <answer> int 
return <token> <answer> 0; 
static void hp_attr_set_interface_remove(struct <token> *wdev) <answer> wmi_device 
static const struct wmi_device_id <token> = { <answer> hp_attr_set_interface_id_table[] 
<token> .guid_string = HP_WMI_BIOS_GUID}, <answer> { 
<token> } <answer> { 
static struct wmi_driver hp_attr_set_interface_driver <token> { <answer> = 
.driver <token> { <answer> = 
<token> = DRIVER_NAME, <answer> .name 
.probe = <token> <answer> hp_attr_set_interface_probe, 
.remove = <token> <answer> hp_attr_set_interface_remove, 
.id_table <token> hp_attr_set_interface_id_table, <answer> = 
<token> hp_init_attr_set_interface(void) <answer> int 
<token> wmi_driver_register(&hp_attr_set_interface_driver); <answer> return 
void <token> <answer> hp_exit_attr_set_interface(void) 
<token> hp_attr_set_interface_id_table); <answer> MODULE_DEVICE_TABLE(wmi, 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/time.h> 
#include <token> <answer> <linux/cper.h> 
<token> <linux/dmi.h> <answer> #include 
#include <token> <answer> <linux/acpi.h> 
<token> <linux/pci.h> <answer> #include 
<token> <linux/printk.h> <answer> #include 
#include <token> <answer> <linux/bcd.h> 
<token> <acpi/ghes.h> <answer> #include 
#include <token> <answer> <ras/ras_event.h> 
<token> const char * const arm_reg_ctx_strs[] = { <answer> static 
"AArch32 general <token> registers", <answer> purpose 
"AArch32 EL1 <token> registers", <answer> context 
"AArch32 EL2 context <token> <answer> registers", 
"AArch32 <token> context registers", <answer> secure 
"AArch64 general <token> registers", <answer> purpose 
"AArch64 EL1 <token> registers", <answer> context 
"AArch64 <token> context registers", <answer> EL2 
"AArch64 <token> context registers", <answer> EL3 
<token> system register structure", <answer> "Misc. 
static const char * const <token> = { <answer> arm_err_trans_type_strs[] 
"Data <token> <answer> Access", 
static const char * <token> arm_bus_err_op_strs[] = { <answer> const 
<token> error (type cannot be determined)", <answer> "Generic 
"Generic read <token> of instruction or data request cannot be determined)", <answer> (type 
"Generic write (type of instruction of data request cannot be <token> <answer> determined)", 
"Data <token> <answer> read", 
"Data <token> <answer> write", 
"Instruction <token> <answer> fetch", 
<token> const char * const arm_cache_err_op_strs[] = { <answer> static 
"Generic <token> (type cannot be determined)", <answer> error 
<token> read (type of instruction or data request cannot be determined)", <answer> "Generic 
"Generic write (type of instruction of data <token> cannot be determined)", <answer> request 
"Data <token> <answer> read", 
"Data <token> <answer> write", 
"Instruction <token> <answer> fetch", 
"Snooping (processor initiated <token> cache snoop that resulted in an error)", <answer> a 
"Snooped (processor raised a <token> error caused by another processor or device snooping its cache)", <answer> cache 
static const char <token> const arm_tlb_err_op_strs[] = { <answer> * 
"Generic error (type cannot be <token> <answer> determined)", 
"Generic read (type of instruction <token> data request cannot be determined)", <answer> or 
"Generic write (type of instruction of data request cannot be <token> <answer> determined)", 
"Data <token> <answer> read", 
<token> write", <answer> "Data 
<token> fetch", <answer> "Instruction 
"Local management <token> (processor initiated a TLB management operation that resulted in an error)", <answer> operation 
"External management operation (processor raised a TLB error caused by another processor <token> device broadcasting TLB operations)", <answer> or 
static <token> char * const arm_bus_err_part_type_strs[] = { <answer> const 
"Local processor originated <token> <answer> request", 
<token> processor responded to request", <answer> "Local 
<token> processor observed", <answer> "Local 
static const char * const <token> = { <answer> arm_bus_err_addr_space_strs[] 
<token> Memory Access", <answer> "External 
<token> Memory Access", <answer> "Internal 
"Device Memory <token> <answer> Access", 
static void <token> char *pfx, u32 type, <answer> cper_print_arm_err_info(const 
u64 <token> <answer> error_info) 
u8 trans_type, op_type, level, <token> address_space; <answer> participation_type, 
u16 <token> <answer> mem_attributes; 
bool proc_context_corrupt, corrected, <token> restartable_pc; <answer> precise_pc, 
bool <token> access_mode; <answer> time_out, 
if <token> == CPER_ARM_VENDOR_ERROR) <answer> (type 
if (error_info & <token> { <answer> CPER_ARM_ERR_VALID_TRANSACTION_TYPE) 
<token> = ((error_info >> CPER_ARM_ERR_TRANSACTION_SHIFT) <answer> trans_type 
<token> CPER_ARM_ERR_TRANSACTION_MASK); <answer> & 
if <token> < ARRAY_SIZE(arm_err_trans_type_strs)) { <answer> (trans_type 
printk("%stransaction type: <token> pfx, <answer> %s\n", 
if (error_info <token> CPER_ARM_ERR_VALID_OPERATION_TYPE) { <answer> & 
op_type <token> ((error_info >> CPER_ARM_ERR_OPERATION_SHIFT) <answer> = 
& <token> <answer> CPER_ARM_ERR_OPERATION_MASK); 
<token> (type) { <answer> switch 
case <token> <answer> CPER_ARM_CACHE_ERROR: 
<token> (op_type < ARRAY_SIZE(arm_cache_err_op_strs)) { <answer> if 
printk("%soperation <token> %s\n", pfx, <answer> type: 
case <token> <answer> CPER_ARM_TLB_ERROR: 
if (op_type < ARRAY_SIZE(arm_tlb_err_op_strs)) <token> <answer> { 
printk("%soperation type: %s\n", <token> <answer> pfx, 
case <token> <answer> CPER_ARM_BUS_ERROR: 
if (op_type < <token> { <answer> ARRAY_SIZE(arm_bus_err_op_strs)) 
printk("%soperation type: <token> pfx, <answer> %s\n", 
if (error_info & CPER_ARM_ERR_VALID_LEVEL) <token> <answer> { 
<token> = ((error_info >> CPER_ARM_ERR_LEVEL_SHIFT) <answer> level 
<token> CPER_ARM_ERR_LEVEL_MASK); <answer> & 
<token> (type) { <answer> switch 
<token> CPER_ARM_CACHE_ERROR: <answer> case 
<token> level: %d\n", pfx, level); <answer> printk("%scache 
<token> CPER_ARM_TLB_ERROR: <answer> case 
printk("%sTLB level: %d\n", <token> level); <answer> pfx, 
case <token> <answer> CPER_ARM_BUS_ERROR: 
printk("%saffinity level at <token> the bus error occurred: %d\n", <answer> which 
<token> level); <answer> pfx, 
<token> (error_info & CPER_ARM_ERR_VALID_PROC_CONTEXT_CORRUPT) { <answer> if 
<token> = ((error_info >> CPER_ARM_ERR_PC_CORRUPT_SHIFT) <answer> proc_context_corrupt 
<token> CPER_ARM_ERR_PC_CORRUPT_MASK); <answer> & 
if <token> <answer> (proc_context_corrupt) 
printk("%sprocessor context corrupted\n", <token> <answer> pfx); 
printk("%sprocessor <token> not corrupted\n", pfx); <answer> context 
if (error_info & <token> { <answer> CPER_ARM_ERR_VALID_CORRECTED) 
corrected <token> ((error_info >> CPER_ARM_ERR_CORRECTED_SHIFT) <answer> = 
& <token> <answer> CPER_ARM_ERR_CORRECTED_MASK); 
if <token> <answer> (corrected) 
<token> error has been corrected\n", pfx); <answer> printk("%sthe 
<token> error has not been corrected\n", pfx); <answer> printk("%sthe 
if (error_info & <token> { <answer> CPER_ARM_ERR_VALID_PRECISE_PC) 
precise_pc = ((error_info >> <token> <answer> CPER_ARM_ERR_PRECISE_PC_SHIFT) 
<token> CPER_ARM_ERR_PRECISE_PC_MASK); <answer> & 
<token> (precise_pc) <answer> if 
printk("%sPC is precise\n", <token> <answer> pfx); 
printk("%sPC is <token> pfx); <answer> imprecise\n", 
if (error_info <token> CPER_ARM_ERR_VALID_RESTARTABLE_PC) { <answer> & 
<token> = ((error_info >> CPER_ARM_ERR_RESTARTABLE_PC_SHIFT) <answer> restartable_pc 
<token> CPER_ARM_ERR_RESTARTABLE_PC_MASK); <answer> & 
<token> (restartable_pc) <answer> if 
printk("%sProgram execution can be restarted reliably at the PC associated with the <token> pfx); <answer> error.\n", 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> "pinctrl-msm.h" 
#define <token> f1, f2, f3, f4, f5, f6, f7, f8, f9) \ <answer> PINGROUP(id, 
{ <token> <answer> \ 
.grp = <token> #id, \ <answer> PINCTRL_PINGROUP("gpio" 
gpio##id##_pins, <token> <answer> \ 
ARRAY_SIZE(gpio##id##_pins)), <token> <answer> \ 
.funcs = (int[]){ <token> <answer> \ 
<token> const struct msm_pingroup sc7280_groups[] = { <answer> static 
[0] = PINGROUP(0, qup00, <token> _, _, _, _, _, _, _), <answer> ibi_i3c, 
[1] <token> PINGROUP(1, qup00, ibi_i3c, _, _, _, _, _, _, _), <answer> = 
[2] = PINGROUP(2, qup00, qup07, _, qdss, _, _, _, <token> _), <answer> _, 
[3] = PINGROUP(3, qup00, qup07, _, qdss, <token> _, _, _, _), <answer> _, 
[4] = PINGROUP(4, qup01, ibi_i3c, _, _, _, _, _, <token> _), <answer> _, 
[5] = PINGROUP(5, <token> ibi_i3c, _, _, _, _, _, _, _), <answer> qup01, 
[6] = PINGROUP(6, qup01, qup07, _, _, _, <token> _, _, _), <answer> _, 
[7] = PINGROUP(7, qup01, <token> _, _, _, _, _, _, _), <answer> _, 
[8] = PINGROUP(8, qup02, _, qdss, _, _, <token> _, _, _), <answer> _, 
[9] = PINGROUP(9, qup02, _, qdss, _, <token> _, _, _, _), <answer> _, 
<token> = PINGROUP(10, qup02, _, qdss, _, _, _, _, _, _), <answer> [10] 
[11] = PINGROUP(11, qup02, _, <token> _, _, _, _, _, _), <answer> qdss, 
[12] = PINGROUP(12, qup03, qspi_data, sdc40, tb_trig, phase_flag, qdss, <token> _, _), <answer> ddr_pxi1, 
[13] = <token> qup03, qspi_data, sdc41, tb_trig, phase_flag, qdss, ddr_pxi1, _, _), <answer> PINGROUP(13, 
[14] = PINGROUP(14, qup03, qspi_clk, sdc4_clk, mdp_vsync, <token> ddr_pxi0, _, _, _), <answer> phase_flag, 
[15] = PINGROUP(15, <token> qspi_cs, tb_trig, phase_flag, qdss_cti, ddr_pxi0, _, _, _), <answer> qup03, 
[16] = PINGROUP(16, qup04, qspi_data, <token> mdp_vsync, phase_flag, qdss_cti, _, _, _), <answer> sdc42, 
[17] = PINGROUP(17, qup04, qspi_data, sdc43, _, <token> _, _, _, _), <answer> phase_flag, 
[18] = PINGROUP(18, qup04, _, phase_flag, qdss_cti, _, <token> _, _, _), <answer> _, 
<token> = PINGROUP(19, qup04, qspi_cs, sdc4_cmd, _, phase_flag, qdss_cti, _, _, _), <answer> [19] 
[20] = PINGROUP(20, qup05, cci_timer0, <token> qdss, _, _, _, _, _), <answer> _, 
[21] <token> PINGROUP(21, qup05, cci_timer1, _, qdss, _, _, _, _, _), <answer> = 
[22] = PINGROUP(22, qup05, _, qdss, _, _, _, _, <token> _), <answer> _, 
[23] = PINGROUP(23, qup05, _, qdss, _, _, _, <token> _, _), <answer> _, 
[24] = <token> qup06, _, qdss, _, _, _, _, _, _), <answer> PINGROUP(24, 
[25] <token> PINGROUP(25, qup06, _, qdss, _, _, _, _, _, _), <answer> = 
[26] = PINGROUP(26, qup06, <token> _, qdss, _, _, _, _, _), <answer> host2wlan_sol, 
[27] = PINGROUP(27, qup06, _, qdss, _, _, _, <token> _, _), <answer> _, 
<token> = PINGROUP(28, qup07, _, qdss, _, _, _, _, _, _), <answer> [28] 
[29] = PINGROUP(29, qup07, <token> _, _, _, _, _, _, _), <answer> qdss, 
[30] = PINGROUP(30, qup07, _, _, _, _, _, <token> _, _), <answer> _, 
[31] = PINGROUP(31, qup07, _, _, _, _, <token> _, _, _), <answer> _, 
[32] = PINGROUP(32, qup10, _, <token> _, _, _, _, _, _), <answer> _, 
[33] = PINGROUP(33, qup10, _, _, _, <token> _, _, _, _), <answer> _, 
[34] = PINGROUP(34, qup10, _, _, _, _, _, _, <token> _), <answer> _, 
[35] = PINGROUP(35, qup10, _, _, _, _, _, _, <token> _), <answer> _, 
[36] = PINGROUP(36, qup11, ibi_i3c, _, _, _, _, _, <token> _), <answer> _, 
[37] = PINGROUP(37, <token> ibi_i3c, _, _, _, _, _, _, _), <answer> qup11, 
[38] = <token> qup11, qup14, dbg_out, _, _, _, _, _, _), <answer> PINGROUP(38, 
[39] = PINGROUP(39, qup11, _, _, _, _, _, _, <token> _), <answer> _, 
[40] = PINGROUP(40, qup12, _, _, _, _, _, _, _, <token> <answer> _), 
[41] = PINGROUP(41, qup12, _, _, _, _, <token> _, _, _), <answer> _, 
[42] = PINGROUP(42, qup12, _, _, _, _, _, _, _, <token> <answer> _), 
[43] <token> PINGROUP(43, qup12, _, _, _, _, _, _, _, _), <answer> = 
<token> = PINGROUP(44, qup13, _, _, _, _, _, _, _, _), <answer> [44] 
<token> = PINGROUP(45, qup13, _, _, _, _, _, _, _, _), <answer> [45] 
[46] = PINGROUP(46, qup13, edp_lcd, _, _, _, _, <token> _, _), <answer> _, 
<token> = PINGROUP(47, qup13, dp_hot, _, _, _, _, _, _, _), <answer> [47] 
<token> = PINGROUP(48, qup14, _, _, _, _, _, _, _, _), <answer> [48] 
[49] = PINGROUP(49, qup14, _, _, _, _, _, _, <token> _), <answer> _, 
[50] = PINGROUP(50, qup14, <token> _, _, _, _, _, _, _), <answer> qup16, 
[51] = PINGROUP(51, qup14, _, _, _, _, _, _, _, <token> <answer> _), 
[52] = PINGROUP(52, qup15, _, _, _, _, _, _, <token> _), <answer> _, 
[53] = PINGROUP(53, <token> _, _, _, _, _, _, _, _), <answer> qup15, 
[54] = PINGROUP(54, qup15, qup14, _, <token> _, _, _, _, _), <answer> _, 
[55] = PINGROUP(55, qup15, qup14, _, _, _, _, _, <token> _), <answer> _, 
[56] = PINGROUP(56, qup16, <token> phase_flag, _, _, _, _, _, _), <answer> ddr_bist, 
[57] = PINGROUP(57, qup16, ddr_bist, phase_flag, _, _, _, _, <token> _), <answer> _, 
[58] = PINGROUP(58, qup16, ddr_bist, phase_flag, qdss, _, <token> _, _, _), <answer> _, 
<token> = PINGROUP(59, qup16, ddr_bist, phase_flag, qdss, _, _, _, _, _), <answer> [59] 
[60] = PINGROUP(60, qup17, edp_hot, _, phase_flag, _, _, _, _, <token> <answer> _), 
[61] = PINGROUP(61, qup17, sd_write, phase_flag, tsense_pwm1, tsense_pwm2, _, _, _, <token> <answer> _), 
[62] = PINGROUP(62, qup17, qup16, phase_flag, _, _, <token> _, _, _), <answer> _, 
[63] = PINGROUP(63, qup17, qup16, phase_flag, <token> _, _, _, _, _), <answer> _, 
[64] = PINGROUP(64, cam_mclk, _, <token> _, _, _, _, _, _), <answer> _, 
[65] = PINGROUP(65, cam_mclk, tgu_ch0, _, _, <token> _, _, _, _), <answer> _, 
[66] = PINGROUP(66, <token> pll_bypassnl, tgu_ch1, _, _, _, _, _, _), <answer> cam_mclk, 
[67] = PINGROUP(67, cam_mclk, pll_reset, _, _, _, _, _, _, <token> <answer> _), 
[68] = PINGROUP(68, <token> _, _, _, _, _, _, _, _), <answer> cam_mclk, 
[69] = PINGROUP(69, cci_i2c, _, _, _, _, <token> _, _, _), <answer> _, 
[70] = PINGROUP(70, cci_i2c, _, <token> _, _, _, _, _, _), <answer> _, 
[71] = PINGROUP(71, cci_i2c, _, _, _, _, <token> _, _, _), <answer> _, 
[72] = PINGROUP(72, cci_i2c, _, <token> _, _, _, _, _, _), <answer> _, 
[73] = PINGROUP(73, cci_i2c, _, _, _, _, <token> _, _, _), <answer> _, 
[74] = PINGROUP(74, cci_i2c, _, _, _, _, _, _, <token> _), <answer> _, 
[75] = PINGROUP(75, cci_i2c, _, _, _, _, <token> _, _, _), <answer> _, 
[76] = PINGROUP(76, cci_i2c, gcc_gp1, _, _, _, _, _, _, <token> <answer> _), 
[77] = <token> cci_timer2, gcc_gp2, _, atest_usb13, atest_char0, _, _, _, _), <answer> PINGROUP(77, 
[78] = PINGROUP(78, cci_timer3, cci_async, gcc_gp3, _, atest_usb12, atest_char1, <token> _, _), <answer> _, 
[79] <token> PINGROUP(79, cci_timer4, cci_async, pcie1_clkreqn, mdp_vsync, jitter_bist, atest_usb11, atest_char2, _, _), <answer> = 
[80] = PINGROUP(80, <token> vfr_0, mdp_vsync0, mdp_vsync1, mdp_vsync4, pll_bist, atest_usb10, atest_char3, _), <answer> mdp_vsync, 
[81] = PINGROUP(81, mdp_vsync, <token> mdp_vsync2, mdp_vsync3, mdp_vsync5, atest_usb1, atest_char, _, _), <answer> dp_lcd, 
<token> = PINGROUP(82, _, _, _, _, _, _, _, _, _), <answer> [82] 
[83] = <token> _, _, _, _, _, _, _, _, _), <answer> PINGROUP(83, 
[84] = PINGROUP(84, usb2phy_ac, _, _, _, _, _, _, <token> _), <answer> _, 
[85] = PINGROUP(85, usb2phy_ac, _, _, _, _, <token> _, _, _), <answer> _, 
[86] = PINGROUP(86, _, _, _, <token> _, _, _, _, _), <answer> _, 
[87] = PINGROUP(87, _, _, _, _, _, _, <token> _, _), <answer> _, 
[88] = PINGROUP(88, pcie0_clkreqn, _, _, _, _, _, _, _, <token> <answer> _), 
[89] = PINGROUP(89, _, _, _, _, _, _, <token> _, _), <answer> _, 
[90] = PINGROUP(90, _, <token> _, _, _, _, _, _, _), <answer> _, 
[91] = PINGROUP(91, _, _, _, _, _, _, <token> _, _), <answer> _, 
[92] = PINGROUP(92, _, _, _, _, <token> _, _, _, _), <answer> _, 
<token> = PINGROUP(93, cam_mclk, cci_async, _, _, _, _, _, _, _), <answer> [93] 
[94] = PINGROUP(94, lpass_slimbus, <token> _, _, _, _, _, _, _), <answer> _, 
[95] = PINGROUP(95, lpass_slimbus, _, _, _, _, _, _, _, <token> <answer> _), 
[96] = <token> pri_mi2s, _, _, _, _, _, _, _, _), <answer> PINGROUP(96, 
[97] = PINGROUP(97, <token> _, _, _, _, _, _, _, _), <answer> mi2s0_sck, 
[98] = PINGROUP(98, mi2s0_data0, _, <token> _, _, _, _, _, _), <answer> _, 
[99] = PINGROUP(99, mi2s0_data1, <token> _, _, _, _, _, _, _), <answer> _, 
<token> = PINGROUP(100, mi2s0_ws, _, vsense_trigger, _, _, _, _, _, _), <answer> [100] 
[101] = PINGROUP(101, mi2s2_sck, _, qdss, _, _, _, _, <token> _), <answer> _, 
[102] = PINGROUP(102, mi2s2_data0, <token> _, qdss, _, _, _, _, _), <answer> _, 
[103] = PINGROUP(103, mi2s2_ws, vfr_1, _, _, qdss, _, atest_usb03, _, <token> <answer> _), 
[104] = PINGROUP(104, <token> _, _, qdss, _, atest_usb02, _, _, _), <answer> mi2s2_data1, 
[105] = PINGROUP(105, sec_mi2s, mi2s1_data1, audio_ref, <token> _, qdss, atest_usb01, _, _), <answer> gcc_gp1, 
[106] = PINGROUP(106, mi2s1_sck, <token> _, qdss, atest_usb00, _, _, _, _), <answer> gcc_gp2, 
[107] = PINGROUP(107, mi2s1_data0, gcc_gp3, _, qdss, atest_usb0, _, <token> _, _), <answer> _, 
[108] <token> PINGROUP(108, mi2s1_ws, _, qdss, _, _, _, _, _, _), <answer> = 
[109] = PINGROUP(109, uim1_data, _, _, _, _, <token> _, _, _), <answer> _, 
[110] = PINGROUP(110, <token> _, _, _, _, _, _, _, _), <answer> uim1_clk, 
[111] = PINGROUP(111, <token> _, _, _, _, _, _, _, _), <answer> uim1_reset, 
[112] = PINGROUP(112, uim1_present, _, _, _, _, _, _, _, <token> <answer> _), 
[113] = PINGROUP(113, uim0_data, _, _, _, <token> _, _, _, _), <answer> _, 
[114] <token> PINGROUP(114, uim0_clk, _, _, _, _, _, _, _, _), <answer> = 
[115] = PINGROUP(115, uim0_reset, _, _, _, _, <token> _, _, _), <answer> _, 
[116] = PINGROUP(116, uim0_present, _, _, _, <token> _, _, _, _), <answer> _, 
[117] = PINGROUP(117, _, mss_grfc0, <token> phase_flag, _, _, _, _, _), <answer> cmu_rng3, 
[118] = PINGROUP(118, _, mss_grfc1, <token> phase_flag, _, _, _, _, _), <answer> cmu_rng2, 
[119] = <token> _, mss_grfc2, cmu_rng1, phase_flag, _, _, _, _, _), <answer> PINGROUP(119, 
[120] = PINGROUP(120, _, mss_grfc3, cmu_rng0, phase_flag, _, _, _, <token> _), <answer> _, 
[121] = PINGROUP(121, _, mss_grfc4, <token> phase_flag, _, _, _, _, _), <answer> cri_trng0, 
<token> = PINGROUP(122, _, mss_grfc5, cri_trng1, phase_flag, _, _, _, _, _), <answer> [122] 
[123] = <token> _, mss_grfc6, prng_rosc, phase_flag, _, _, _, _, _), <answer> PINGROUP(123, 
[124] = PINGROUP(124, _, mss_grfc7, cri_trng, phase_flag, _, <token> _, _, _), <answer> _, 
[125] = PINGROUP(125, _, <token> phase_flag, _, _, _, _, _, _), <answer> mss_grfc8, 
[126] = PINGROUP(126, _, mss_grfc9, phase_flag, _, _, _, _, <token> _), <answer> _, 
[127] = PINGROUP(127, <token> mss_grfc10, phase_flag, _, _, _, _, _, _), <answer> coex_uart1, 
<token> = PINGROUP(128, coex_uart1, mss_grfc11, phase_flag, _, _, _, _, _, _), <answer> [128] 
[129] = PINGROUP(129, nav_gpio0, phase_flag, _, _, _, _, _, _, <token> <answer> _), 
[130] = PINGROUP(130, nav_gpio1, phase_flag, _, <token> _, _, _, _, _), <answer> _, 
[131] = PINGROUP(131, mss_grfc12, nav_gpio2, pa_indicator, phase_flag, _, _, _, _, <token> <answer> _), 
[132] = PINGROUP(132, <token> phase_flag, _, _, _, _, _, _, _), <answer> mss_grfc0, 
[133] = PINGROUP(133, qlink0_request, _, _, _, _, <token> _, _, _), <answer> _, 
[134] = PINGROUP(134, qlink0_enable, _, _, <token> _, _, _, _, _), <answer> _, 
[135] = PINGROUP(135, qlink0_wmss, _, _, <token> _, _, _, _, _), <answer> _, 
<token> = PINGROUP(136, qlink1_request, _, _, _, _, _, _, _, _), <answer> [136] 
[137] = PINGROUP(137, qlink1_enable, <token> _, _, _, _, _, _, _), <answer> _, 
[138] = <token> qlink1_wmss, _, _, _, _, _, _, _, _), <answer> PINGROUP(138, 
[139] <token> PINGROUP(139, _, _, _, _, _, _, _, _, _), <answer> = 
[140] = PINGROUP(140, usb_phy, pll_clk, _, _, _, _, <token> _, _), <answer> _, 
[141] <token> PINGROUP(141, _, _, _, _, _, _, _, _, _), <answer> = 
[142] = PINGROUP(142, _, _, _, _, _, _, <token> _, _), <answer> _, 
[143] = PINGROUP(143, _, _, _, _, _, <token> _, _, _), <answer> _, 
[144] = PINGROUP(144, _, <token> _, _, _, _, _, _, egpio), <answer> _, 
[145] = PINGROUP(145, _, _, <token> _, _, _, _, _, egpio), <answer> _, 
[146] = PINGROUP(146, <token> _, _, _, _, _, _, _, egpio), <answer> _, 
[147] = PINGROUP(147, _, _, _, _, <token> _, _, _, egpio), <answer> _, 
[148] = <token> _, _, _, _, _, _, _, _, egpio), <answer> PINGROUP(148, 
[149] = <token> _, _, _, _, _, _, _, _, egpio), <answer> PINGROUP(149, 
[150] <token> PINGROUP(150, qdss, _, _, _, _, _, _, _, egpio), <answer> = 
[151] = PINGROUP(151, qdss, _, _, _, _, _, _, <token> egpio), <answer> _, 
[152] = PINGROUP(152, qdss, _, _, _, _, _, <token> _, egpio), <answer> _, 
[153] = PINGROUP(153, qdss, _, _, _, _, _, _, <token> egpio), <answer> _, 
[154] = PINGROUP(154, _, _, _, _, _, _, _, _, <token> <answer> egpio), 
[155] = PINGROUP(155, _, <token> _, _, _, _, _, _, egpio), <answer> _, 
[156] = PINGROUP(156, qdss_cti, _, _, _, _, _, _, <token> egpio), <answer> _, 
[157] = <token> qdss_cti, _, _, _, _, _, _, _, egpio), <answer> PINGROUP(157, 
[158] <token> PINGROUP(158, _, _, _, _, _, _, _, _, egpio), <answer> = 
[159] = PINGROUP(159, _, _, _, _, <token> _, _, _, egpio), <answer> _, 
[160] = PINGROUP(160, _, _, <token> _, _, _, _, _, egpio), <answer> _, 
[161] = PINGROUP(161, _, _, <token> _, _, _, _, _, egpio), <answer> _, 
[162] = PINGROUP(162, _, _, <token> _, _, _, _, _, egpio), <answer> _, 
[163] = PINGROUP(163, _, _, _, _, <token> _, _, _, egpio), <answer> _, 
[164] = PINGROUP(164, _, _, _, _, <token> _, _, _, egpio), <answer> _, 
[165] = PINGROUP(165, qdss_cti, _, _, _, _, _, _, <token> egpio), <answer> _, 
[166] = PINGROUP(166, <token> _, _, _, _, _, _, _, egpio), <answer> qdss_cti, 
[167] = PINGROUP(167, _, _, _, _, <token> _, _, _, egpio), <answer> _, 
[168] = PINGROUP(168, _, _, _, _, _, _, _, _, <token> <answer> egpio), 
[169] = PINGROUP(169, _, _, <token> _, _, _, _, _, egpio), <answer> _, 
[170] = PINGROUP(170, _, _, _, _, <token> _, _, _, egpio), <answer> _, 
[171] = PINGROUP(171, qdss, _, _, _, _, _, <token> _, egpio), <answer> _, 
[172] = PINGROUP(172, qdss, _, <token> _, _, _, _, _, egpio), <answer> _, 
[173] = <token> qdss, _, _, _, _, _, _, _, egpio), <answer> PINGROUP(173, 
[174] = PINGROUP(174, qdss, _, _, _, _, _, _, <token> egpio), <answer> _, 
[175] <token> UFS_RESET(ufs_reset, 0xbe000), <answer> = 
[176] <token> SDC_QDSD_PINGROUP(sdc1_rclk, 0xb3004, 0, 6), <answer> = 
[177] <token> SDC_QDSD_PINGROUP(sdc1_clk, 0xb3000, 13, 6), <answer> = 
[178] = SDC_QDSD_PINGROUP(sdc1_cmd, 0xb3000, <token> 3), <answer> 11, 
[179] = SDC_QDSD_PINGROUP(sdc1_data, 0xb3000, <token> 0), <answer> 9, 
[180] = SDC_QDSD_PINGROUP(sdc2_clk, 0xb4000, 14, <token> <answer> 6), 
[181] <token> SDC_QDSD_PINGROUP(sdc2_cmd, 0xb4000, 11, 3), <answer> = 
[182] = SDC_QDSD_PINGROUP(sdc2_data, 0xb4000, <token> 0), <answer> 9, 
static const struct msm_gpio_wakeirq_map sc7280_pdc_map[] = <token> <answer> { 
{ 0, 134 }, { <token> 131 }, { 4, 121 }, { 7, 103 }, { 8, 155 }, <answer> 3, 
{ 11, 93 }, { 12, 78 }, { 15, 79 }, { 16, 80 }, { <token> 81 }, <answer> 18, 
{ 19, 107 <token> { 20, 82 }, { 21, 83 }, { 23, 99 }, { 24, 86 }, <answer> }, 
{ <token> 95 }, { 27, 158 }, { 28, 159 }, { 31, 90 }, { 32, 144 }, <answer> 25, 
{ 34, 77 <token> { 35, 92 }, { 36, 157 }, { 39, 73 }, { 40, 97 }, <answer> }, 
{ 41, 98 }, { 43, 85 }, { 44, 100 }, { 45, 101 }, { <token> 102 }, <answer> 47, 
{ 48, 74 }, { 51, 112 }, { 52, 156 }, { 54, 117 }, <token> 55, 84 }, <answer> { 
{ 56, 108 }, { 59, 110 }, { 60, 111 <token> { 61, 123 }, { 63, 104 }, <answer> }, 
{ 68, 127 }, { 72, 150 }, { 75, <token> }, { 77, 125 }, { 78, 105 }, <answer> 133 
{ 79, 106 }, { 80, 118 }, <token> 81, 119 }, { 82, 162 }, { 83, 122 }, <answer> { 
{ 86, 75 }, { 88, 154 }, { 89, 124 <token> { 90, 149 }, { 91, 76 }, <answer> }, 
{ 93, <token> }, { 95, 160 }, { 101, 126 }, { 102, 96 }, { 103, 116 }, <answer> 128 
{ 104, 114 }, { 112, 72 }, { 116, 135 }, { 117, 163 }, <token> 119, 137 }, <answer> { 
{ 121, 138 <token> { 123, 139 }, { 125, 140 }, { 127, 141 }, { 128, 165 }, <answer> }, 
{ <token> 143 }, { 130, 94 }, { 131, 145 }, { 133, 146 }, { 136, 147 }, <answer> 129, 
{ 140, 148 }, { <token> 115 }, { 142, 113 }, { 145, 130 }, { 148, 132 }, <answer> 141, 
{ 150, 87 }, { 151, 88 }, { 153, 89 }, <token> 155, 164 }, { 156, 129 }, <answer> { 
{ 157, 161 }, { 158, 120 }, { 161, 136 }, { 163, 142 }, { 172, <token> }, <answer> 166 
{ 174, <token> }, <answer> 167 
<token> const struct msm_pinctrl_soc_data sc7280_pinctrl = { <answer> static 
.pins = <token> <answer> sc7280_pins, 
.npins = <token> <answer> ARRAY_SIZE(sc7280_pins), 
.functions = <token> <answer> sc7280_functions, 
<token> = ARRAY_SIZE(sc7280_functions), <answer> .nfunctions 
.groups <token> sc7280_groups, <answer> = 
.ngroups <token> ARRAY_SIZE(sc7280_groups), <answer> = 
<token> = 176, <answer> .ngpios 
.wakeirq_map = <token> <answer> sc7280_pdc_map, 
.nwakeirq_map <token> ARRAY_SIZE(sc7280_pdc_map), <answer> = 
.egpio_func = <token> <answer> 9, 
static <token> sc7280_pinctrl_probe(struct platform_device *pdev) <answer> int 
<token> msm_pinctrl_probe(pdev, &sc7280_pinctrl); <answer> return 
static const struct <token> sc7280_pinctrl_of_match[] = { <answer> of_device_id 
{ .compatible <token> "qcom,sc7280-pinctrl", }, <answer> = 
{ <token> <answer> }, 
static <token> platform_driver sc7280_pinctrl_driver = { <answer> struct 
.driver = <token> <answer> { 
.name = <token> <answer> "sc7280-pinctrl", 
.pm = <token> <answer> &msm_pinctrl_dev_pm_ops, 
<token> = sc7280_pinctrl_of_match, <answer> .of_match_table 
.probe <token> sc7280_pinctrl_probe, <answer> = 
.remove_new = <token> <answer> msm_pinctrl_remove, 
static int <token> sc7280_pinctrl_init(void) <answer> __init 
<token> platform_driver_register(&sc7280_pinctrl_driver); <answer> return 
static void <token> sc7280_pinctrl_exit(void) <answer> __exit 
<token> sc7280 pinctrl driver"); <answer> MODULE_DESCRIPTION("QTI 
MODULE_LICENSE("GPL <token> <answer> v2"); 
MODULE_DEVICE_TABLE(of, <token> <answer> sc7280_pinctrl_of_match); 
#define pr_fmt(fmt) KBUILD_MODNAME <token> " fmt <answer> ": 
#include <token> <answer> <linux/list.h> 
<token> <linux/slab.h> <answer> #include 
<token> <net/neighbour.h> <answer> #include 
<token> <linux/notifier.h> <answer> #include 
<token> <linux/atomic.h> <answer> #include 
<token> <linux/proc_fs.h> <answer> #include 
#include <token> <answer> <linux/if_vlan.h> 
#include <token> <answer> <net/netevent.h> 
<token> <linux/highmem.h> <answer> #include 
<token> <linux/vmalloc.h> <answer> #include 
#include <token> <answer> <linux/export.h> 
<token> "common.h" <answer> #include 
<token> "regs.h" <answer> #include 
#include <token> <answer> "cxgb3_ioctl.h" 
#include <token> <answer> "cxgb3_ctl_defs.h" 
#include <token> <answer> "cxgb3_defs.h" 
<token> "l2t.h" <answer> #include 
<token> "firmware_exports.h" <answer> #include 
<token> "cxgb3_offload.h" <answer> #include 
<token> LIST_HEAD(client_list); <answer> static 
<token> LIST_HEAD(ofld_dev_list); <answer> static 
static <token> <answer> DEFINE_MUTEX(cxgb3_db_lock); 
static <token> <answer> DEFINE_RWLOCK(adapter_list_lock); 
static <token> <answer> LIST_HEAD(adapter_list); 
static const unsigned int <token> = 64 * 1024; <answer> MAX_ATIDS 
static <token> unsigned int ATID_BASE = 0x10000; <answer> const 
static void cxgb_neigh_update(struct neighbour <token> <answer> *neigh); 
static void <token> dst_entry *old, struct dst_entry *new, <answer> cxgb_redirect(struct 
struct neighbour *neigh, const void <token> <answer> *daddr); 
static inline int offload_activated(struct t3cdev <token> <answer> *tdev) 
const struct adapter <token> = tdev2adap(tdev); <answer> *adapter 
<token> test_bit(OFFLOAD_DEVMAP_BIT, &adapter->open_device_map); <answer> return 
void cxgb3_register_client(struct <token> *client) <answer> cxgb3_client 
struct t3cdev <token> <answer> *tdev; 
<token> &client_list); <answer> list_add_tail(&client->client_list, 
<token> (client->add) { <answer> if 
list_for_each_entry(tdev, &ofld_dev_list, ofld_dev_list) <token> <answer> { 
<token> (offload_activated(tdev)) <answer> if 
void cxgb3_unregister_client(struct <token> *client) <answer> cxgb3_client 
<token> t3cdev *tdev; <answer> struct 
<token> (client->remove) { <answer> if 
<token> &ofld_dev_list, ofld_dev_list) { <answer> list_for_each_entry(tdev, 
<token> (offload_activated(tdev)) <answer> if 
void cxgb3_add_clients(struct t3cdev <token> <answer> *tdev) 
<token> cxgb3_client *client; <answer> struct 
list_for_each_entry(client, <token> client_list) { <answer> &client_list, 
if <token> <answer> (client->add) 
void cxgb3_remove_clients(struct t3cdev <token> <answer> *tdev) 
<token> cxgb3_client *client; <answer> struct 
list_for_each_entry(client, &client_list, <token> { <answer> client_list) 
<token> (client->remove) <answer> if 
void <token> t3cdev *tdev, u32 event, u32 port) <answer> cxgb3_event_notify(struct 
<token> cxgb3_client *client; <answer> struct 
<token> &client_list, client_list) { <answer> list_for_each_entry(client, 
<token> (client->event_handler) <answer> if 
client->event_handler(tdev, event, <token> <answer> port); 
static struct net_device <token> adapter *adapter, <answer> *get_iff_from_mac(struct 
const <token> char *mac, <answer> unsigned 
unsigned <token> vlan) <answer> int 
<token> i; <answer> int 
for_each_port(adapter, <token> { <answer> i) 
<token> net_device *dev = adapter->port[i]; <answer> struct 
if (ether_addr_equal(dev->dev_addr, mac)) <token> <answer> { 
if (vlan <token> vlan != VLAN_VID_MASK) { <answer> && 
dev = <token> htons(ETH_P_8021Q), vlan); <answer> __vlan_find_dev_deep_rcu(dev, 
<token> else if (netif_is_bond_slave(dev)) { <answer> } 
struct net_device <token> <answer> *upper_dev; 
while ((upper_dev <token> <answer> = 
dev = <token> <answer> upper_dev; 
return <token> <answer> dev; 
<token> NULL; <answer> return 
static int cxgb_ulp_iscsi_ctl(struct <token> *adapter, unsigned int req, <answer> adapter 
<token> *data) <answer> void 
<token> i; <answer> int 
<token> ret = 0; <answer> int 
unsigned int <token> = 0; <answer> val 
struct <token> *uiip = data; <answer> ulp_iscsi_info 
switch <token> { <answer> (req) 
<token> ULP_ISCSI_GET_PARAMS: <answer> case 
<token> = adapter->pdev; <answer> uiip->pdev 
uiip->llimit = <token> A_ULPRX_ISCSI_LLIMIT); <answer> t3_read_reg(adapter, 
<token> = t3_read_reg(adapter, A_ULPRX_ISCSI_ULIMIT); <answer> uiip->ulimit 
uiip->tagmask <token> t3_read_reg(adapter, A_ULPRX_ISCSI_TAGMASK); <answer> = 
val <token> t3_read_reg(adapter, A_ULPRX_ISCSI_PSZ); <answer> = 
for <token> = 0; i < 4; i++, val >>= 8) <answer> (i 
uiip->pgsz_factor[i] <token> val & 0xFF; <answer> = 
val <token> t3_read_reg(adapter, A_TP_PARA_REG7); <answer> = 
uiip->max_txsz <token> <answer> = 
uiip->max_rxsz = <token> >> S_PMMAXXFERLEN0)&M_PMMAXXFERLEN0, <answer> min((val 
(val >> <token> <answer> S_PMMAXXFERLEN1)&M_PMMAXXFERLEN1); 
val <token> min(adapter->params.tp.tx_pg_size, <answer> = 
<token> A_PM1_TX_CFG) >> 17); <answer> t3_read_reg(adapter, 
uiip->max_txsz <token> min(val, uiip->max_txsz); <answer> = 
<token> = min(adapter->params.tp.rx_pg_size, <answer> val 
((t3_read_reg(adapter, A_TP_PARA_REG2)) <token> <answer> >> 
<token> & M_MAXRXDATA); <answer> S_MAXRXDATA) 
uiip->max_rxsz = <token> uiip->max_rxsz); <answer> min(val, 
case <token> <answer> ULP_ISCSI_SET_PARAMS: 
t3_write_reg(adapter, A_ULPRX_ISCSI_TAGMASK, <token> <answer> uiip->tagmask); 
static int rx_offload_blackhole(struct t3cdev *dev, struct sk_buff <token> <answer> **skbs, 
int <token> <answer> n) 
while <token> <answer> (n--) 
<token> 0; <answer> return 
static <token> dummy_neigh_update(struct t3cdev *dev, struct neighbour *neigh) <answer> void 
void cxgb3_set_dummy_ops(struct <token> *dev) <answer> t3cdev 
dev->recv <token> rx_offload_blackhole; <answer> = 
dev->neigh_update = <token> <answer> dummy_neigh_update; 
void *cxgb3_free_atid(struct t3cdev *tdev, <token> atid) <answer> int 
struct <token> *t = &(T3C_DATA(tdev))->tid_maps; <answer> tid_info 
union active_open_entry *p = atid2entry(t, <token> <answer> atid); 
void *ctx = <token> <answer> p->t3c_tid.ctx; 
p->next <token> t->afree; <answer> = 
t->afree <token> p; <answer> = 
return <token> <answer> ctx; 
void <token> t3cdev *tdev, int stid) <answer> cxgb3_free_stid(struct 
struct <token> *t = &(T3C_DATA(tdev))->tid_maps; <answer> tid_info 
union listen_entry *p = <token> stid); <answer> stid2entry(t, 
<token> = t->sfree; <answer> p->next 
t->sfree = <token> <answer> p; 
<token> cxgb3_insert_tid(struct t3cdev *tdev, struct cxgb3_client *client, <answer> void 
void *ctx, unsigned int <token> <answer> tid) 
struct <token> *t = &(T3C_DATA(tdev))->tid_maps; <answer> tid_info 
t->tid_tab[tid].client <token> client; <answer> = 
t->tid_tab[tid].ctx = <token> <answer> ctx; 
static inline void mk_tid_release(struct <token> *skb, unsigned int tid) <answer> sk_buff 
struct <token> *req; <answer> cpl_tid_release 
<token> = CPL_PRIORITY_SETUP; <answer> skb->priority 
<token> = __skb_put(skb, sizeof(*req)); <answer> req 
<token> = htonl(V_WR_OP(FW_WROPCODE_FORWARD)); <answer> req->wr.wr_hi 
OPCODE_TID(req) = <token> tid)); <answer> htonl(MK_OPCODE_TID(CPL_TID_RELEASE, 
<token> void t3_process_tid_release_list(struct work_struct *work) <answer> static 
struct t3c_data *td = container_of(work, <token> t3c_data, <answer> struct 
struct sk_buff <token> <answer> *skb; 
struct t3cdev *tdev = <token> <answer> td->dev; 
while <token> { <answer> (td->tid_release_list) 
struct t3c_tid_entry *p <token> td->tid_release_list; <answer> = 
td->tid_release_list = <token> <answer> p->ctx; 
skb = <token> cpl_tid_release), <answer> alloc_skb(sizeof(struct 
<token> (!skb) <answer> if 
skb = <token> <answer> td->nofail_skb; 
<token> (!skb) { <answer> if 
<token> = (void *)td->tid_release_list; <answer> p->ctx 
td->tid_release_list = <token> <answer> p; 
mk_tid_release(skb, <token> - td->tid_maps.tid_tab); <answer> p 
<token> skb); <answer> cxgb3_ofld_send(tdev, 
<token> = NULL; <answer> p->ctx 
if <token> == td->nofail_skb) <answer> (skb 
td->nofail_skb <token> <answer> = 
alloc_skb(sizeof(struct <token> <answer> cpl_tid_release), 
td->release_list_incomplete <token> (td->tid_release_list == NULL) ? 0 : 1; <answer> = 
<token> (!td->nofail_skb) <answer> if 
td->nofail_skb <token> <answer> = 
<token> cpl_tid_release), <answer> alloc_skb(sizeof(struct 
void cxgb3_remove_tid(struct t3cdev *tdev, void *ctx, unsigned int <token> <answer> tid) 
struct tid_info <token> = &(T3C_DATA(tdev))->tid_maps; <answer> *t 
BUG_ON(tid >= <token> <answer> t->ntids); 
if (tdev->type <token> T3A) <answer> == 
<token> ctx, NULL); <answer> (void)cmpxchg(&t->tid_tab[tid].ctx, 
else <token> <answer> { 
struct <token> *skb; <answer> sk_buff 
<token> = alloc_skb(sizeof(struct cpl_tid_release), GFP_ATOMIC); <answer> skb 
<token> (likely(skb)) { <answer> if 
mk_tid_release(skb, <token> <answer> tid); 
<token> skb); <answer> cxgb3_ofld_send(tdev, 
<token> = NULL; <answer> t->tid_tab[tid].ctx 
<token> else <answer> } 
cxgb3_queue_tid_release(tdev, <token> <answer> tid); 
int cxgb3_alloc_atid(struct t3cdev *tdev, struct cxgb3_client <token> <answer> *client, 
<token> *ctx) <answer> void 
<token> atid = -1; <answer> int 
struct tid_info <token> = &(T3C_DATA(tdev))->tid_maps; <answer> *t 
<token> (t->afree && <answer> if 
t->atids_in_use + atomic_read(&t->tids_in_use) + MC5_MIN_TIDS <token> <answer> <= 
<token> { <answer> t->ntids) 
union <token> *p = t->afree; <answer> active_open_entry 
atid = (p <token> t->atid_tab) + t->atid_base; <answer> - 
<token> = p->next; <answer> t->afree 
p->t3c_tid.ctx <token> ctx; <answer> = 
p->t3c_tid.client = <token> <answer> client; 
return <token> <answer> atid; 
<token> cxgb3_alloc_stid(struct t3cdev *tdev, struct cxgb3_client *client, <answer> int 
<token> *ctx) <answer> void 
<token> stid = -1; <answer> int 
struct tid_info *t = <token> <answer> &(T3C_DATA(tdev))->tid_maps; 
<token> (t->sfree) { <answer> if 
union <token> *p = t->sfree; <answer> listen_entry 
stid = <token> - t->stid_tab) + t->stid_base; <answer> (p 
t->sfree <token> p->next; <answer> = 
p->t3c_tid.ctx <token> ctx; <answer> = 
<token> = client; <answer> p->t3c_tid.client 
return <token> <answer> stid; 
static struct sk_buff *cxgb3_get_cpl_reply_skb(struct <token> *skb, size_t len, <answer> sk_buff 
<token> gfp) <answer> gfp_t 
<token> (likely(!skb_cloned(skb))) { <answer> if 
BUG_ON(skb->len <token> len); <answer> < 
__skb_trim(skb, <token> <answer> len); 
<token> else { <answer> } 
skb = alloc_skb(len, <token> <answer> gfp); 
<token> (skb) <answer> if 
<token> len); <answer> __skb_put(skb, 
<token> skb; <answer> return 
static int do_abort_req_rss(struct t3cdev *dev, struct <token> *skb) <answer> sk_buff 
union opcode_tid *p <token> cplhdr(skb); <answer> = 
<token> int hwtid = G_TID(ntohl(p->opcode_tid)); <answer> unsigned 
struct <token> *t3c_tid; <answer> t3c_tid_entry 
<token> = lookup_tid(&(T3C_DATA(dev))->tid_maps, hwtid); <answer> t3c_tid 
if (t3c_tid <token> t3c_tid->ctx && t3c_tid->client->handlers && <answer> && 
<token> { <answer> t3c_tid->client->handlers[p->opcode]) 
<token> t3c_tid->client->handlers[p->opcode] <answer> return 
(dev, <token> t3c_tid->ctx); <answer> skb, 
} <token> { <answer> else 
struct cpl_abort_req_rss *req = <token> <answer> cplhdr(skb); 
struct <token> *rpl; <answer> cpl_abort_rpl 
struct sk_buff <token> <answer> *reply_skb; 
unsigned int tid = <token> <answer> GET_TID(req); 
u8 cmd <token> req->status; <answer> = 
if (req->status == <token> || <answer> CPL_ERR_RTX_NEG_ADVICE 
req->status == <token> <answer> CPL_ERR_PERSIST_NEG_ADVICE) 
goto <token> <answer> out; 
reply_skb <token> cxgb3_get_cpl_reply_skb(skb, <answer> = 
if <token> { <answer> (!reply_skb) 
printk("do_abort_req_rss: couldn't get <token> <answer> skb!\n"); 
<token> out; <answer> goto 
<token> = CPL_PRIORITY_DATA; <answer> reply_skb->priority 
<token> sizeof(struct cpl_abort_rpl)); <answer> __skb_put(reply_skb, 
rpl <token> cplhdr(reply_skb); <answer> = 
<token> = <answer> rpl->wr.wr_hi 
rpl->wr.wr_lo = <token> <answer> htonl(V_WR_TID(tid)); 
<token> = htonl(MK_OPCODE_TID(CPL_ABORT_RPL, tid)); <answer> OPCODE_TID(rpl) 
rpl->cmd <token> cmd; <answer> = 
<token> reply_skb); <answer> cxgb3_ofld_send(dev, 
return <token> <answer> CPL_RET_BUF_DONE; 
static int <token> t3cdev *dev, struct sk_buff *skb) <answer> do_act_establish(struct 
<token> cpl_act_establish *req = cplhdr(skb); <answer> struct 
<token> int atid = G_PASS_OPEN_TID(ntohl(req->tos_tid)); <answer> unsigned 
struct tid_info *t <token> &(T3C_DATA(dev))->tid_maps; <answer> = 
struct <token> *t3c_tid; <answer> t3c_tid_entry 
unsigned int <token> = GET_TID(req); <answer> tid 
if (unlikely(tid >= <token> { <answer> t->ntids)) 
printk("%s: <token> establish TID %u too large\n", <answer> active 
<token> tid); <answer> dev->name, 
<token> CPL_RET_BUF_DONE; <answer> return 
t3c_tid = lookup_atid(t, <token> <answer> atid); 
if (t3c_tid && t3c_tid->ctx && t3c_tid->client->handlers <token> <answer> && 
t3c_tid->client->handlers[CPL_ACT_ESTABLISH]) <token> <answer> { 
return <token> <answer> t3c_tid->client->handlers[CPL_ACT_ESTABLISH] 
<token> skb, t3c_tid->ctx); <answer> (dev, 
<token> else { <answer> } 
pr_err("%s: received clientless CPL <token> 0x%x\n", <answer> command 
<token> CPL_ACT_ESTABLISH); <answer> dev->name, 
return CPL_RET_BUF_DONE <token> CPL_RET_BAD_MSG; <answer> | 
<token> int do_trace(struct t3cdev *dev, struct sk_buff *skb) <answer> static 
struct cpl_trace_pkt *p = <token> <answer> cplhdr(skb); 
<token> = htons(0xffff); <answer> skb->protocol 
skb->dev <token> dev->lldev; <answer> = 
<token> sizeof(*p)); <answer> skb_pull(skb, 
return <token> <answer> 0; 
<token> inline u32 get_hwtid(struct sk_buff *skb) <answer> static 
return ntohl((__force __be32)skb->priority) >> <token> & 0xfffff; <answer> 8 
static inline u32 <token> sk_buff *skb) <answer> get_opcode(struct 
return G_OPCODE(ntohl((__force <token> <answer> __be32)skb->csum)); 
static int <token> t3cdev *dev, struct sk_buff *skb) <answer> do_term(struct 
unsigned <token> hwtid = get_hwtid(skb); <answer> int 
unsigned int opcode <token> get_opcode(skb); <answer> = 
struct t3c_tid_entry <token> <answer> *t3c_tid; 
<token> = lookup_tid(&(T3C_DATA(dev))->tid_maps, hwtid); <answer> t3c_tid 
if (t3c_tid && t3c_tid->ctx && t3c_tid->client->handlers <token> <answer> && 
<token> { <answer> t3c_tid->client->handlers[opcode]) 
return <token> (dev, skb, <answer> t3c_tid->client->handlers[opcode] 
} <token> { <answer> else 
<token> received clientless CPL command 0x%x\n", <answer> pr_err("%s: 
<token> opcode); <answer> dev->name, 
return CPL_RET_BUF_DONE | <token> <answer> CPL_RET_BAD_MSG; 
static int nb_callback(struct notifier_block *self, unsigned <token> event, <answer> long 
<token> *ctx) <answer> void 
<token> (event) { <answer> switch 
case <token> <answer> (NETEVENT_NEIGH_UPDATE):{ 
<token> neighbour *)ctx); <answer> cxgb_neigh_update((struct 
case <token> <answer> (NETEVENT_REDIRECT):{ 
struct netevent_redirect *nr <token> ctx; <answer> = 
<token> nr->new, nr->neigh, <answer> cxgb_redirect(nr->old, 
return <token> <answer> 0; 
static struct notifier_block nb <token> { <answer> = 
.notifier_call <token> nb_callback <answer> = 
<token> int do_bad_cpl(struct t3cdev *dev, struct sk_buff *skb) <answer> static 
pr_err("%s: received bad CPL <token> 0x%x\n", dev->name, *skb->data); <answer> command 
return CPL_RET_BUF_DONE <token> CPL_RET_BAD_MSG; <answer> | 
<token> cpl_handler_func cpl_handlers[NUM_CPL_CMDS]; <answer> static 
void <token> int opcode, cpl_handler_func h) <answer> t3_register_cpl_handler(unsigned 
if (opcode <token> NUM_CPL_CMDS) <answer> < 
cpl_handlers[opcode] = h ? <token> : do_bad_cpl; <answer> h 
pr_err("T3C: <token> registration for opcode %x failed\n", <answer> handler 
<token> int process_rx(struct t3cdev *dev, struct sk_buff **skbs, int n) <answer> static 
<token> (n--) { <answer> while 
struct <token> *skb = *skbs++; <answer> sk_buff 
unsigned int <token> = get_opcode(skb); <answer> opcode 
int ret = cpl_handlers[opcode] (dev, <token> <answer> skb); 
<token> VALIDATE_TID <answer> #if 
if (ret & CPL_RET_UNKNOWN_TID) <token> <answer> { 
union opcode_tid *p <token> cplhdr(skb); <answer> = 
pr_err("%s: CPL <token> (opcode %u) had unknown TID %u\n", <answer> message 
<token> opcode, G_TID(ntohl(p->opcode_tid))); <answer> dev->name, 
if <token> & CPL_RET_BUF_DONE) <answer> (ret 
return <token> <answer> 0; 
int cxgb3_ofld_send(struct <token> *dev, struct sk_buff *skb) <answer> t3cdev 
<token> r; <answer> int 
r <token> dev->send(dev, skb); <answer> = 
<token> r; <answer> return 
static int is_offloading(struct net_device <token> <answer> *dev) 
struct <token> *adapter; <answer> adapter 
int <token> <answer> i; 
<token> &adapter_list, adapter_list) { <answer> list_for_each_entry(adapter, 
<token> i) { <answer> for_each_port(adapter, 
if (dev == <token> { <answer> adapter->port[i]) 
return <token> <answer> 1; 
<token> 0; <answer> return 
static void cxgb_neigh_update(struct neighbour <token> <answer> *neigh) 
struct <token> *dev; <answer> net_device 
if <token> <answer> (!neigh) 
dev = <token> <answer> neigh->dev; 
if (dev <token> (is_offloading(dev))) { <answer> && 
struct <token> *tdev = dev2t3cdev(dev); <answer> t3cdev 
<token> neigh); <answer> t3_l2t_update(tdev, 
static void set_l2t_ix(struct t3cdev *tdev, u32 <token> struct l2t_entry *e) <answer> tid, 
<token> sk_buff *skb; <answer> struct 
struct <token> *req; <answer> cpl_set_tcb_field 
<token> = alloc_skb(sizeof(*req), GFP_ATOMIC); <answer> skb 
if (!skb) <token> <answer> { 
pr_err("%s: <token> allocate skb!\n", __func__); <answer> cannot 
skb->priority <token> CPL_PRIORITY_CONTROL; <answer> = 
req = skb_put(skb, <token> <answer> sizeof(*req)); 
req->wr.wr_hi = <token> <answer> htonl(V_WR_OP(FW_WROPCODE_FORWARD)); 
OPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_SET_TCB_FIELD, <token> <answer> tid)); 
req->reply <token> 0; <answer> = 
req->cpu_idx <token> 0; <answer> = 
<token> = htons(W_TCB_L2T_IX); <answer> req->word 
<token> = cpu_to_be64(V_TCB_L2T_IX(M_TCB_L2T_IX)); <answer> req->mask 
req->val <token> cpu_to_be64(V_TCB_L2T_IX(e->idx)); <answer> = 
tdev->send(tdev, <token> <answer> skb); 
static <token> cxgb_redirect(struct dst_entry *old, struct dst_entry *new, <answer> void 
struct neighbour <token> <answer> *neigh, 
const <token> *daddr) <answer> void 
struct net_device <token> <answer> *dev; 
struct tid_info <token> <answer> *ti; 
<token> t3cdev *tdev; <answer> struct 
<token> tid; <answer> u32 
int <token> <answer> update_tcb; 
struct <token> *e; <answer> l2t_entry 
<token> t3c_tid_entry *te; <answer> struct 
<token> = neigh->dev; <answer> dev 
if <token> <answer> (!is_offloading(dev)) 
tdev <token> dev2t3cdev(dev); <answer> = 
<token> int init_tid_tabs(struct tid_info *t, unsigned int ntids, <answer> static 
unsigned int <token> unsigned int nstids, <answer> natids, 
unsigned int <token> unsigned int stid_base) <answer> atid_base, 
unsigned long size = ntids * <token> + <answer> sizeof(*t->tid_tab) 
natids * sizeof(*t->atid_tab) + nstids <token> sizeof(*t->stid_tab); <answer> * 
t->tid_tab = kvzalloc(size, <token> <answer> GFP_KERNEL); 
<token> (!t->tid_tab) <answer> if 
<token> -ENOMEM; <answer> return 
t->stid_tab <token> (union listen_entry *)&t->tid_tab[ntids]; <answer> = 
t->atid_tab <token> (union active_open_entry *)&t->stid_tab[nstids]; <answer> = 
<token> = ntids; <answer> t->ntids 
<token> = nstids; <answer> t->nstids 
t->stid_base = <token> <answer> stid_base; 
t->sfree = <token> <answer> NULL; 
t->natids <token> natids; <answer> = 
t->atid_base <token> atid_base; <answer> = 
t->afree <token> NULL; <answer> = 
t->stids_in_use = <token> = 0; <answer> t->atids_in_use 
<token> 0); <answer> atomic_set(&t->tids_in_use, 
if (nstids) <token> <answer> { 
<token> (--nstids) <answer> while 
t->stid_tab[nstids - 1].next = <token> <answer> &t->stid_tab[nstids]; 
t->sfree = <token> <answer> t->stid_tab; 
<token> (natids) { <answer> if 
<token> (--natids) <answer> while 
<token> - 1].next = &t->atid_tab[natids]; <answer> t->atid_tab[natids 
t->afree = <token> <answer> t->atid_tab; 
<token> 0; <answer> return 
<token> void free_tid_maps(struct tid_info *t) <answer> static 
static inline void add_adapter(struct <token> *adap) <answer> adapter 
list_add_tail(&adap->adapter_list, <token> <answer> &adapter_list); 
<token> inline void remove_adapter(struct adapter *adap) <answer> static 
int cxgb3_offload_activate(struct <token> *adapter) <answer> adapter 
struct t3cdev *dev = <token> <answer> &adapter->tdev; 
<token> natids, err; <answer> int 
<token> t3c_data *t; <answer> struct 
struct tid_range <token> tid_range; <answer> stid_range, 
struct mtutab <token> <answer> mtutab; 
unsigned int <token> <answer> l2t_capacity; 
struct l2t_data <token> <answer> *l2td; 
t = kzalloc(sizeof(*t), <token> <answer> GFP_KERNEL); 
<token> (!t) <answer> if 
return <token> <answer> -ENOMEM; 
err = <token> <answer> -EOPNOTSUPP; 
if (dev->ctl(dev, <token> &t->tx_max_chunk) < 0 || <answer> GET_TX_MAX_CHUNK, 
dev->ctl(dev, GET_MAX_OUTSTANDING_WR, &t->max_wrs) < 0 <token> <answer> || 
<token> GET_L2T_CAPACITY, &l2t_capacity) < 0 || <answer> dev->ctl(dev, 
dev->ctl(dev, GET_MTUS, <token> < 0 || <answer> &mtutab) 
dev->ctl(dev, GET_TID_RANGE, &tid_range) <token> 0 || <answer> < 
dev->ctl(dev, <token> &stid_range) < 0) <answer> GET_STID_RANGE, 
<token> out_free; <answer> goto 
err = <token> <answer> -ENOMEM; 
l2td = <token> <answer> t3_init_l2t(l2t_capacity); 
<token> (!l2td) <answer> if 
goto <token> <answer> out_free; 
natids = min(tid_range.num / 2, <token> <answer> MAX_ATIDS); 
err = init_tid_tabs(&t->tid_maps, <token> natids, <answer> tid_range.num, 
<token> ATID_BASE, stid_range.base); <answer> stid_range.num, 
<token> (err) <answer> if 
<token> out_free_l2t; <answer> goto 
t->mtus = <token> <answer> mtutab.mtus; 
t->nmtus = <token> <answer> mtutab.size; 
<token> t3_process_tid_release_list); <answer> INIT_WORK(&t->tid_release_task, 
t->dev = <token> <answer> dev; 
RCU_INIT_POINTER(dev->l2opt, <token> <answer> l2td); 
T3C_DATA(dev) = <token> <answer> t; 
dev->recv = <token> <answer> process_rx; 
dev->neigh_update = <token> <answer> t3_l2t_update; 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/gpio/consumer.h> 
<token> <linux/lcd.h> <answer> #include 
<token> <linux/mod_devicetable.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/property.h> <answer> #include 
#include <token> <answer> <linux/spi/spi.h> 
#define <token> 3 <answer> HX8357_NUM_IM_PINS 
#define HX8357_SWRESET <token> <answer> 0x01 
<token> HX8357_GET_RED_CHANNEL 0x06 <answer> #define 
#define HX8357_GET_GREEN_CHANNEL <token> <answer> 0x07 
#define <token> 0x08 <answer> HX8357_GET_BLUE_CHANNEL 
<token> HX8357_GET_POWER_MODE 0x0a <answer> #define 
#define <token> 0x0b <answer> HX8357_GET_MADCTL 
<token> HX8357_GET_PIXEL_FORMAT 0x0c <answer> #define 
<token> HX8357_GET_DISPLAY_MODE 0x0d <answer> #define 
#define <token> 0x0e <answer> HX8357_GET_SIGNAL_MODE 
<token> HX8357_GET_DIAGNOSTIC_RESULT 0x0f <answer> #define 
#define HX8357_ENTER_SLEEP_MODE <token> <answer> 0x10 
<token> HX8357_EXIT_SLEEP_MODE 0x11 <answer> #define 
<token> HX8357_ENTER_PARTIAL_MODE 0x12 <answer> #define 
#define <token> 0x13 <answer> HX8357_ENTER_NORMAL_MODE 
#define HX8357_EXIT_INVERSION_MODE <token> <answer> 0x20 
#define <token> 0x21 <answer> HX8357_ENTER_INVERSION_MODE 
#define <token> 0x28 <answer> HX8357_SET_DISPLAY_OFF 
#define HX8357_SET_DISPLAY_ON <token> <answer> 0x29 
<token> HX8357_SET_COLUMN_ADDRESS 0x2a <answer> #define 
<token> HX8357_SET_PAGE_ADDRESS 0x2b <answer> #define 
#define HX8357_WRITE_MEMORY_START <token> <answer> 0x2c 
#define HX8357_READ_MEMORY_START <token> <answer> 0x2e 
#define HX8357_SET_PARTIAL_AREA <token> <answer> 0x30 
#define HX8357_SET_SCROLL_AREA <token> <answer> 0x33 
<token> HX8357_SET_TEAR_OFF 0x34 <answer> #define 
#define HX8357_SET_TEAR_ON <token> <answer> 0x35 
<token> HX8357_SET_ADDRESS_MODE 0x36 <answer> #define 
#define HX8357_SET_SCROLL_START <token> <answer> 0x37 
#define <token> 0x38 <answer> HX8357_EXIT_IDLE_MODE 
<token> HX8357_ENTER_IDLE_MODE 0x39 <answer> #define 
<token> HX8357_SET_PIXEL_FORMAT 0x3a <answer> #define 
<token> HX8357_SET_PIXEL_FORMAT_DBI_3BIT (0x1) <answer> #define 
<token> HX8357_SET_PIXEL_FORMAT_DBI_16BIT (0x5) <answer> #define 
#define <token> (0x6) <answer> HX8357_SET_PIXEL_FORMAT_DBI_18BIT 
<token> HX8357_SET_PIXEL_FORMAT_DPI_3BIT (0x1 << 4) <answer> #define 
#define HX8357_SET_PIXEL_FORMAT_DPI_16BIT <token> << 4) <answer> (0x5 
#define <token> (0x6 << 4) <answer> HX8357_SET_PIXEL_FORMAT_DPI_18BIT 
#define HX8357_WRITE_MEMORY_CONTINUE <token> <answer> 0x3c 
<token> HX8357_READ_MEMORY_CONTINUE 0x3e <answer> #define 
#define HX8357_SET_TEAR_SCAN_LINES <token> <answer> 0x44 
#define <token> 0x45 <answer> HX8357_GET_SCAN_LINES 
#define HX8357_READ_DDB_START <token> <answer> 0xa1 
#define HX8357_SET_DISPLAY_MODE <token> <answer> 0xb4 
<token> HX8357_SET_DISPLAY_MODE_RGB_THROUGH (0x3) <answer> #define 
#define <token> (1 << 4) <answer> HX8357_SET_DISPLAY_MODE_RGB_INTERFACE 
#define HX8357_SET_PANEL_DRIVING <token> <answer> 0xc0 
#define <token> 0xc5 <answer> HX8357_SET_DISPLAY_FRAME 
<token> HX8357_SET_RGB 0xc6 <answer> #define 
#define HX8357_SET_RGB_ENABLE_HIGH <token> << 1) <answer> (1 
<token> HX8357_SET_GAMMA 0xc8 <answer> #define 
#define <token> 0xd0 <answer> HX8357_SET_POWER 
#define <token> 0xd1 <answer> HX8357_SET_VCOM 
<token> HX8357_SET_POWER_NORMAL 0xd2 <answer> #define 
#define HX8357_SET_PANEL_RELATED <token> <answer> 0xe9 
#define HX8369_SET_DISPLAY_BRIGHTNESS <token> <answer> 0x51 
#define <token> 0x53 <answer> HX8369_WRITE_CABC_DISPLAY_VALUE 
#define <token> 0x55 <answer> HX8369_WRITE_CABC_BRIGHT_CTRL 
#define <token> 0x5e <answer> HX8369_WRITE_CABC_MIN_BRIGHTNESS 
#define HX8369_SET_POWER <token> <answer> 0xb1 
<token> HX8369_SET_DISPLAY_MODE 0xb2 <answer> #define 
#define <token> 0xb4 <answer> HX8369_SET_DISPLAY_WAVEFORM_CYC 
<token> HX8369_SET_VCOM 0xb6 <answer> #define 
#define HX8369_SET_EXTENSION_COMMAND <token> <answer> 0xb9 
<token> HX8369_SET_GIP 0xd5 <answer> #define 
#define <token> 0xe0 <answer> HX8369_SET_GAMMA_CURVE_RELATED 
struct <token> { <answer> hx8357_data 
<token> gpio_descs *im_pins; <answer> struct 
struct <token> *reset; <answer> gpio_desc 
<token> spi_device *spi; <answer> struct 
<token> state; <answer> int 
static <token> hx8357_seq_power[] = { <answer> u8 
HX8357_SET_POWER, <token> 0x41, 0x06, <answer> 0x44, 
<token> u8 hx8357_seq_vcom[] = { <answer> static 
HX8357_SET_VCOM, <token> 0x10, <answer> 0x40, 
static u8 hx8357_seq_power_normal[] <token> { <answer> = 
HX8357_SET_POWER_NORMAL, <token> 0x12, <answer> 0x05, 
static <token> hx8357_seq_panel_driving[] = { <answer> u8 
<token> 0x14, 0x3b, 0x00, 0x02, 0x11, <answer> HX8357_SET_PANEL_DRIVING, 
static <token> hx8357_seq_display_frame[] = { <answer> u8 
HX8357_SET_DISPLAY_FRAME, <token> <answer> 0x0c, 
static <token> hx8357_seq_panel_related[] = { <answer> u8 
<token> 0x01, <answer> HX8357_SET_PANEL_RELATED, 
static u8 hx8357_seq_undefined1[] <token> { <answer> = 
0xea, 0x03, 0x00, <token> <answer> 0x00, 
static u8 <token> = { <answer> hx8357_seq_undefined2[] 
<token> 0x40, 0x54, 0x26, 0xdb, <answer> 0xeb, 
static <token> hx8357_seq_gamma[] = { <answer> u8 
<token> 0x00, 0x15, 0x00, 0x22, 0x00, <answer> HX8357_SET_GAMMA, 
0x08, 0x77, 0x26, 0x77, <token> 0x04, 0x00, <answer> 0x22, 
<token> u8 hx8357_seq_address_mode[] = { <answer> static 
HX8357_SET_ADDRESS_MODE, <token> <answer> 0xc0, 
static u8 hx8357_seq_pixel_format[] = <token> <answer> { 
<token> | <answer> HX8357_SET_PIXEL_FORMAT_DPI_18BIT 
<token> u8 hx8357_seq_column_address[] = { <answer> static 
HX8357_SET_COLUMN_ADDRESS, 0x00, 0x00, <token> 0x3f, <answer> 0x01, 
<token> u8 hx8357_seq_page_address[] = { <answer> static 
<token> 0x00, 0x00, 0x01, 0xdf, <answer> HX8357_SET_PAGE_ADDRESS, 
static u8 hx8357_seq_rgb[] = <token> <answer> { 
<token> 0x02, <answer> HX8357_SET_RGB, 
static u8 <token> = { <answer> hx8357_seq_display_mode[] 
HX8357_SET_DISPLAY_MODE_RGB_THROUGH <token> <answer> | 
static u8 hx8369_seq_write_CABC_min_brightness[] = <token> <answer> { 
<token> 0x00, <answer> HX8369_WRITE_CABC_MIN_BRIGHTNESS, 
<token> u8 hx8369_seq_write_CABC_control[] = { <answer> static 
<token> 0x24, <answer> HX8369_WRITE_CABC_DISPLAY_VALUE, 
static u8 hx8369_seq_set_display_brightness[] <token> { <answer> = 
HX8369_SET_DISPLAY_BRIGHTNESS, <token> <answer> 0xFF, 
static u8 hx8369_seq_write_CABC_control_setting[] <token> { <answer> = 
HX8369_WRITE_CABC_BRIGHT_CTRL, <token> <answer> 0x02, 
static <token> hx8369_seq_extension_command[] = { <answer> u8 
HX8369_SET_EXTENSION_COMMAND, 0xff, 0x83, <token> <answer> 0x69, 
static u8 <token> = { <answer> hx8369_seq_display_related[] 
HX8369_SET_DISPLAY_MODE, 0x00, 0x2b, <token> 0x03, 0x70, 0x00, <answer> 0x03, 
0xff, 0x00, 0x00, 0x00, 0x00, <token> 0x03, 0x00, 0x01, <answer> 0x03, 
<token> u8 hx8369_seq_panel_waveform_cycle[] = { <answer> static 
HX8369_SET_DISPLAY_WAVEFORM_CYC, 0x0a, <token> 0x80, 0x06, 0x02, <answer> 0x1d, 
<token> u8 hx8369_seq_set_address_mode[] = { <answer> static 
HX8357_SET_ADDRESS_MODE, <token> <answer> 0x00, 
static u8 hx8369_seq_vcom[] <token> { <answer> = 
HX8369_SET_VCOM, <token> 0x3e, <answer> 0x3e, 
<token> u8 hx8369_seq_gip[] = { <answer> static 
HX8369_SET_GIP, <token> 0x01, 0x03, 0x25, 0x01, 0x02, 0x28, 0x70, <answer> 0x00, 
<token> 0x13, 0x00, 0x00, 0x40, 0x26, 0x51, 0x37, 0x00, 0x00, 0x71, <answer> 0x11, 
<token> 0x60, 0x24, 0x07, 0x0f, 0x04, 0x04, <answer> 0x35, 
static u8 hx8369_seq_power[] <token> { <answer> = 
HX8369_SET_POWER, 0x01, 0x00, 0x34, 0x03, <token> 0x11, 0x11, 0x32, <answer> 0x00, 
0x2f, 0x3f, 0x3f, 0x01, 0x3a, 0x01, 0xe6, 0xe6, 0xe6, 0xe6, <token> <answer> 0xe6, 
<token> u8 hx8369_seq_gamma_curve_related[] = { <answer> static 
HX8369_SET_GAMMA_CURVE_RELATED, 0x00, 0x0d, <token> 0x2f, 0x3b, 0x3d, <answer> 0x19, 
0x2e, 0x4a, 0x08, 0x0e, 0x0f, 0x14, 0x16, 0x14, 0x14, <token> 0x1e, <answer> 0x14, 
0x00, 0x0d, 0x19, 0x2f, 0x3b, 0x3d, 0x2e, 0x4a, 0x08, 0x0e, <token> <answer> 0x0f, 
0x14, 0x16, <token> 0x14, 0x14, 0x1e, <answer> 0x14, 
static <token> hx8357_spi_write_then_read(struct lcd_device *lcdev, <answer> int 
u8 *txbuf, <token> txlen, <answer> u16 
u8 *rxbuf, <token> rxlen) <answer> u16 
struct hx8357_data *lcd <token> lcd_get_data(lcdev); <answer> = 
struct <token> msg; <answer> spi_message 
struct spi_transfer <token> <answer> xfer[2]; 
<token> *local_txbuf = NULL; <answer> u16 
<token> ret = 0; <answer> int 
memset(xfer, <token> sizeof(xfer)); <answer> 0, 
if (txlen) <token> <answer> { 
int <token> <answer> i; 
local_txbuf <token> kcalloc(txlen, sizeof(*local_txbuf), GFP_KERNEL); <answer> = 
<token> (!local_txbuf) <answer> if 
<token> -ENOMEM; <answer> return 
for (i = 0; i < txlen; i++) <token> <answer> { 
<token> = txbuf[i]; <answer> local_txbuf[i] 
if <token> > 0) <answer> (i 
local_txbuf[i] |= <token> << 8; <answer> 1 
xfer[0].len = 2 * <token> <answer> txlen; 
<token> = 9; <answer> xfer[0].bits_per_word 
xfer[0].tx_buf = <token> <answer> local_txbuf; 
spi_message_add_tail(&xfer[0], <token> <answer> &msg); 
if (rxlen) <token> <answer> { 
xfer[1].len <token> rxlen; <answer> = 
xfer[1].bits_per_word <token> 8; <answer> = 
xfer[1].rx_buf <token> rxbuf; <answer> = 
<token> &msg); <answer> spi_message_add_tail(&xfer[1], 
ret = spi_sync(lcd->spi, <token> <answer> &msg); 
if (ret < <token> <answer> 0) 
dev_err(&lcdev->dev, "Couldn't send SPI <token> <answer> data\n"); 
<token> (txlen) <answer> if 
<token> ret; <answer> return 
static inline int hx8357_spi_write_array(struct lcd_device <token> <answer> *lcdev, 
<token> *value, u8 len) <answer> u8 
return hx8357_spi_write_then_read(lcdev, value, len, <token> 0); <answer> NULL, 
static <token> int hx8357_spi_write_byte(struct lcd_device *lcdev, <answer> inline 
<token> value) <answer> u8 
return hx8357_spi_write_then_read(lcdev, &value, 1, NULL, <token> <answer> 0); 
static <token> hx8357_enter_standby(struct lcd_device *lcdev) <answer> int 
<token> ret; <answer> int 
ret = hx8357_spi_write_byte(lcdev, <token> <answer> HX8357_SET_DISPLAY_OFF); 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
<token> 12000); <answer> usleep_range(10000, 
ret <token> hx8357_spi_write_byte(lcdev, HX8357_ENTER_SLEEP_MODE); <answer> = 
if (ret <token> 0) <answer> < 
return <token> <answer> ret; 
return <token> <answer> 0; 
static int <token> lcd_device *lcdev) <answer> hx8357_exit_standby(struct 
<token> ret; <answer> int 
<token> = hx8357_spi_write_byte(lcdev, HX8357_EXIT_SLEEP_MODE); <answer> ret 
if (ret <token> 0) <answer> < 
return <token> <answer> ret; 
ret <token> hx8357_spi_write_byte(lcdev, HX8357_SET_DISPLAY_ON); <answer> = 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
<token> 0; <answer> return 
static void <token> lcd_device *lcdev) <answer> hx8357_lcd_reset(struct 
struct hx8357_data *lcd = <token> <answer> lcd_get_data(lcdev); 
if <token> { <answer> (lcd->im_pins) 
<token> 1); <answer> gpiod_set_value_cansleep(lcd->im_pins->desc[0], 
<token> 0); <answer> gpiod_set_value_cansleep(lcd->im_pins->desc[1], 
gpiod_set_value_cansleep(lcd->im_pins->desc[2], <token> <answer> 1); 
<token> = hx8357_spi_write_array(lcdev, hx8357_seq_power, <answer> ret 
if <token> < 0) <answer> (ret 
<token> ret; <answer> return 
ret <token> hx8357_spi_write_array(lcdev, hx8357_seq_vcom, <answer> = 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
ret <token> hx8357_spi_write_array(lcdev, hx8357_seq_power_normal, <answer> = 
if (ret <token> 0) <answer> < 
return <token> <answer> ret; 
ret = <token> hx8357_seq_panel_driving, <answer> hx8357_spi_write_array(lcdev, 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
ret = hx8357_spi_write_array(lcdev, <token> <answer> hx8357_seq_display_frame, 
if <token> < 0) <answer> (ret 
return <token> <answer> ret; 
ret <token> hx8357_spi_write_array(lcdev, hx8357_seq_panel_related, <answer> = 
if <token> < 0) <answer> (ret 
<token> ret; <answer> return 
ret = hx8357_spi_write_array(lcdev, <token> <answer> hx8357_seq_undefined1, 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
ret = <token> hx8357_seq_undefined2, <answer> hx8357_spi_write_array(lcdev, 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
ret = <token> hx8357_seq_gamma, <answer> hx8357_spi_write_array(lcdev, 
if <token> < 0) <answer> (ret 
return <token> <answer> ret; 
<token> = hx8357_spi_write_array(lcdev, hx8357_seq_address_mode, <answer> ret 
<token> (ret < 0) <answer> if 
<token> ret; <answer> return 
<token> = hx8357_spi_write_array(lcdev, hx8357_seq_pixel_format, <answer> ret 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
ret = hx8357_spi_write_array(lcdev, <token> <answer> hx8357_seq_column_address, 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
ret = hx8357_spi_write_array(lcdev, <token> <answer> hx8357_seq_page_address, 
if <token> < 0) <answer> (ret 
<token> ret; <answer> return 
<token> = hx8357_spi_write_array(lcdev, hx8357_seq_rgb, <answer> ret 
<token> (ret < 0) <answer> if 
<token> ret; <answer> return 
ret = <token> hx8357_seq_display_mode, <answer> hx8357_spi_write_array(lcdev, 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
ret = <token> HX8357_EXIT_SLEEP_MODE); <answer> hx8357_spi_write_byte(lcdev, 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
ret <token> hx8357_spi_write_byte(lcdev, HX8357_SET_DISPLAY_ON); <answer> = 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
<token> 7000); <answer> usleep_range(5000, 
ret = <token> HX8357_WRITE_MEMORY_START); <answer> hx8357_spi_write_byte(lcdev, 
<token> (ret < 0) <answer> if 
<token> ret; <answer> return 
return <token> <answer> 0; 
static <token> hx8369_lcd_init(struct lcd_device *lcdev) <answer> int 
<token> ret; <answer> int 
ret = hx8357_spi_write_array(lcdev, <token> <answer> hx8369_seq_extension_command, 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
usleep_range(10000, <token> <answer> 12000); 
ret = <token> hx8369_seq_display_related, <answer> hx8357_spi_write_array(lcdev, 
<token> (ret < 0) <answer> if 
<token> ret; <answer> return 
<token> = hx8357_spi_write_array(lcdev, hx8369_seq_panel_waveform_cycle, <answer> ret 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
<token> = hx8357_spi_write_array(lcdev, hx8369_seq_set_address_mode, <answer> ret 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
ret <token> hx8357_spi_write_array(lcdev, hx8369_seq_vcom, <answer> = 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
ret = hx8357_spi_write_array(lcdev, <token> <answer> hx8369_seq_gip, 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
ret <token> hx8357_spi_write_array(lcdev, hx8369_seq_power, <answer> = 
if <token> < 0) <answer> (ret 
return <token> <answer> ret; 
ret <token> hx8357_spi_write_byte(lcdev, HX8357_EXIT_SLEEP_MODE); <answer> = 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
ret = hx8357_spi_write_array(lcdev, <token> <answer> hx8369_seq_gamma_curve_related, 
if <token> < 0) <answer> (ret 
return <token> <answer> ret; 
ret = <token> HX8357_EXIT_SLEEP_MODE); <answer> hx8357_spi_write_byte(lcdev, 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
usleep_range(1000, <token> <answer> 1200); 
ret <token> hx8357_spi_write_array(lcdev, hx8369_seq_write_CABC_control, <answer> = 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
usleep_range(10000, <token> <answer> 12000); 
ret <token> hx8357_spi_write_array(lcdev, <answer> = 
<token> (ret < 0) <answer> if 
<token> ret; <answer> return 
ret <token> hx8357_spi_write_array(lcdev, <answer> = 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
usleep_range(10000, <token> <answer> 12000); 
ret <token> hx8357_spi_write_array(lcdev, hx8369_seq_set_display_brightness, <answer> = 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
ret = hx8357_spi_write_byte(lcdev, <token> <answer> HX8357_SET_DISPLAY_ON); 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
return <token> <answer> 0; 
#define POWER_IS_ON(pwr) ((pwr) <token> FB_BLANK_NORMAL) <answer> <= 
static int hx8357_set_power(struct <token> *lcdev, int power) <answer> lcd_device 
struct hx8357_data *lcd <token> lcd_get_data(lcdev); <answer> = 
<token> ret = 0; <answer> int 
if <token> && !POWER_IS_ON(lcd->state)) <answer> (POWER_IS_ON(power) 
ret <token> hx8357_exit_standby(lcdev); <answer> = 
<token> if (!POWER_IS_ON(power) && POWER_IS_ON(lcd->state)) <answer> else 
ret = <token> <answer> hx8357_enter_standby(lcdev); 
if (ret == <token> <answer> 0) 
lcd->state <token> power; <answer> = 
dev_warn(&lcdev->dev, "failed <token> set power mode %d\n", power); <answer> to 
return <token> <answer> ret; 
static int hx8357_get_power(struct <token> *lcdev) <answer> lcd_device 
<token> hx8357_data *lcd = lcd_get_data(lcdev); <answer> struct 
return <token> <answer> lcd->state; 
static <token> lcd_ops hx8357_ops = { <answer> struct 
.set_power = <token> <answer> hx8357_set_power, 
.get_power = <token> <answer> hx8357_get_power, 
typedef int (*hx8357_init_fn)(struct lcd_device <token> <answer> *); 
<token> int hx8357_probe(struct spi_device *spi) <answer> static 
struct device *dev = <token> <answer> &spi->dev; 
struct <token> *lcdev; <answer> lcd_device 
struct <token> *lcd; <answer> hx8357_data 
<token> init_fn; <answer> hx8357_init_fn 
int i, <token> <answer> ret; 
lcd = devm_kzalloc(dev, <token> GFP_KERNEL); <answer> sizeof(*lcd), 
<token> (!lcd) <answer> if 
return <token> <answer> -ENOMEM; 
ret <token> spi_setup(spi); <answer> = 
if <token> < 0) <answer> (ret 
return <token> ret, "SPI setup failed.\n"); <answer> dev_err_probe(dev, 
lcd->spi = <token> <answer> spi; 
init_fn <token> device_get_match_data(dev); <answer> = 
if <token> <answer> (!init_fn) 
<token> -EINVAL; <answer> return 
lcd->reset = devm_gpiod_get(dev, <token> GPIOD_OUT_LOW); <answer> "reset", 
<token> (IS_ERR(lcd->reset)) <answer> if 
<token> dev_err_probe(dev, PTR_ERR(lcd->reset), "failed to request reset GPIO\n"); <answer> return 
gpiod_set_consumer_name(lcd->reset, <token> <answer> "hx8357-reset"); 
lcd->im_pins <token> devm_gpiod_get_array_optional(dev, "im", GPIOD_OUT_LOW); <answer> = 
if <token> <answer> (IS_ERR(lcd->im_pins)) 
return dev_err_probe(dev, PTR_ERR(lcd->im_pins), "failed to request im <token> <answer> GPIOs\n"); 
if <token> { <answer> (lcd->im_pins) 
<token> (lcd->im_pins->ndescs < HX8357_NUM_IM_PINS) <answer> if 
<token> dev_err_probe(dev, -EINVAL, "not enough im GPIOs\n"); <answer> return 
for (i = 0; i <token> HX8357_NUM_IM_PINS; i++) <answer> < 
gpiod_set_consumer_name(lcd->im_pins->desc[i], <token> <answer> "im_pins"); 
lcdev = <token> "mxsfb", dev, lcd, &hx8357_ops); <answer> devm_lcd_device_register(dev, 
if <token> { <answer> (IS_ERR(lcdev)) 
ret = <token> <answer> PTR_ERR(lcdev); 
<token> ret; <answer> return 
spi_set_drvdata(spi, <token> <answer> lcdev); 
<token> = init_fn(lcdev); <answer> ret 
<token> (ret) <answer> if 
return dev_err_probe(dev, ret, "Couldn't initialize <token> <answer> panel\n"); 
<token> "Panel probed\n"); <answer> dev_info(dev, 
<token> 0; <answer> return 
static const struct of_device_id <token> = { <answer> hx8357_dt_ids[] 
<token> = "himax,hx8357", <answer> .compatible 
<token> = hx8357_lcd_init, <answer> .data 
.compatible <token> "himax,hx8369", <answer> = 
.data <token> hx8369_lcd_init, <answer> = 
MODULE_DEVICE_TABLE(of, <token> <answer> hx8357_dt_ids); 
static <token> spi_driver hx8357_driver = { <answer> struct 
<token> = hx8357_probe, <answer> .probe 
.driver = <token> <answer> { 
<token> = "hx8357", <answer> .name 
.of_match_table = <token> <answer> hx8357_dt_ids, 
<token> Ripard <maxime.ripard@free-electrons.com>"); <answer> MODULE_AUTHOR("Maxime 
<token> HX-8357 LCD Driver"); <answer> MODULE_DESCRIPTION("Himax 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/mod_devicetable.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/mutex.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/spi/spi.h> 
<token> <linux/iio/iio.h> <answer> #include 
<token> <linux/iio/sysfs.h> <answer> #include 
<token> <linux/iio/trigger.h> <answer> #include 
<token> <linux/iio/buffer.h> <answer> #include 
<token> <linux/iio/triggered_buffer.h> <answer> #include 
#include <token> <answer> <linux/iio/trigger_consumer.h> 
<token> MAXIM_THERMOCOUPLE_DRV_NAME "maxim_thermocouple" <answer> #define 
enum <token> <answer> { 
static const <token> maxim_tc_types[] = { <answer> char 
'K', '?', <token> 'J', 'N', 'S', 'T', 'E', 'R' <answer> 'K', 
static const struct iio_chan_spec max6675_channels[] <token> { <answer> = 
<token> <linux/bits.h> <answer> #include 
#include <token> <answer> <linux/device.h> 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/ioport.h> 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/isa.h> 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/moduleparam.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/types.h> 
<token> "gpio-idio-16.h" <answer> #include 
<token> IDIO_16_EXTENT 8 <answer> #define 
#define <token> max_num_isa_dev(IDIO_16_EXTENT) <answer> MAX_NUM_IDIO_16 
static <token> int base[MAX_NUM_IDIO_16]; <answer> unsigned 
static unsigned int <token> <answer> num_idio_16; 
module_param_hw_array(base, uint, <token> &num_idio_16, 0); <answer> ioport, 
MODULE_PARM_DESC(base, "ACCES <token> base addresses"); <answer> 104-IDIO-16 
static unsigned <token> irq[MAX_NUM_IDIO_16]; <answer> int 
<token> unsigned int num_irq; <answer> static 
<token> uint, irq, &num_irq, 0); <answer> module_param_hw_array(irq, 
MODULE_PARM_DESC(irq, "ACCES <token> interrupt line numbers"); <answer> 104-IDIO-16 
static const struct regmap_range idio_16_wr_ranges[] = <token> <answer> { 
regmap_reg_range(0x0, 0x2), regmap_reg_range(0x4, <token> <answer> 0x4), 
static const struct <token> idio_16_rd_ranges[] = { <answer> regmap_range 
regmap_reg_range(0x1, 0x2), regmap_reg_range(0x5, <token> <answer> 0x5), 
static const struct regmap_range <token> = { <answer> idio_16_precious_ranges[] 
<token> 0x2), <answer> regmap_reg_range(0x2, 
static const struct <token> idio_16_wr_table = { <answer> regmap_access_table 
.yes_ranges = <token> <answer> idio_16_wr_ranges, 
.n_yes_ranges <token> ARRAY_SIZE(idio_16_wr_ranges), <answer> = 
static const struct <token> idio_16_rd_table = { <answer> regmap_access_table 
<token> = idio_16_rd_ranges, <answer> .yes_ranges 
<token> = ARRAY_SIZE(idio_16_rd_ranges), <answer> .n_yes_ranges 
static const struct regmap_access_table idio_16_precious_table = <token> <answer> { 
<token> = idio_16_precious_ranges, <answer> .yes_ranges 
.n_yes_ranges = <token> <answer> ARRAY_SIZE(idio_16_precious_ranges), 
static <token> struct regmap_config idio_16_regmap_config = { <answer> const 
<token> = 8, <answer> .reg_bits 
.reg_stride <token> 1, <answer> = 
.val_bits <token> 8, <answer> = 
<token> = true, <answer> .io_port 
.wr_table = <token> <answer> &idio_16_wr_table, 
<token> = &idio_16_rd_table, <answer> .rd_table 
.volatile_table <token> &idio_16_rd_table, <answer> = 
.precious_table = <token> <answer> &idio_16_precious_table, 
.cache_type <token> REGCACHE_FLAT, <answer> = 
<token> = true, <answer> .use_raw_spinlock 
#include <token> <answer> <linux/prime_numbers.h> 
<token> "gem/i915_gem_internal.h" <answer> #include 
#include <token> <answer> "i915_selftest.h" 
#include <token> <answer> "intel_engine_heartbeat.h" 
#include <token> <answer> "intel_engine_pm.h" 
#include <token> <answer> "intel_reset.h" 
<token> "intel_ring.h" <answer> #include 
#include <token> <answer> "selftest_engine_heartbeat.h" 
<token> "selftests/i915_random.h" <answer> #include 
#include <token> <answer> "selftests/igt_flush_test.h" 
#include <token> <answer> "selftests/igt_live_test.h" 
<token> "selftests/igt_spinner.h" <answer> #include 
<token> "selftests/lib_sw_fence.h" <answer> #include 
#include <token> <answer> "shmem_utils.h" 
<token> "gem/selftests/igt_gem_utils.h" <answer> #include 
<token> "gem/selftests/mock_context.h" <answer> #include 
<token> CS_GPR(engine, n) ((engine)->mmio_base + 0x600 + (n) * 4) <answer> #define 
#define NUM_GPR <token> <answer> 16 
lri_mask = <token> lri); <answer> get_lri_mask(engine, 
<token> &= 0x7f; <answer> lri 
while (lri) <token> <answer> { 
<token> offset = READ_ONCE(hw[dw]); <answer> u32 
if ((offset ^ lrc[dw]) & <token> { <answer> lri_mask) 
<token> Different registers found at dword %d, expected %x, found %x\n", <answer> pr_err("%s: 
engine->name, dw, <token> lrc[dw]); <answer> offset, 
<token> = -EINVAL; <answer> err 
dw += <token> <answer> 2; 
lri -= <token> <answer> 2; 
} while (!err && <token> & ~BIT(0)) != MI_BATCH_BUFFER_END); <answer> (lrc[dw] 
if <token> { <answer> (err) 
pr_info("%s: HW register image:\n", <token> <answer> engine->name); 
igt_hexdump(hw, <token> <answer> PAGE_SIZE); 
pr_info("%s: <token> register image:\n", engine->name); <answer> SW 
<token> PAGE_SIZE); <answer> igt_hexdump(lrc, 
<token> hw); <answer> shmem_unpin_map(engine->default_state, 
if <token> <answer> (err) 
free_page((unsigned <token> <answer> long)lrc); 
return <token> <answer> err; 
static int find_offset(const <token> *lri, u32 offset) <answer> u32 
int <token> <answer> i; 
for (i <token> 0; i < PAGE_SIZE / sizeof(u32); i++) <answer> = 
if (lri[i] <token> offset) <answer> == 
return <token> <answer> i; 
return <token> <answer> -1; 
static <token> live_lrc_fixed(void *arg) <answer> int 
struct <token> *gt = arg; <answer> intel_gt 
<token> intel_engine_cs *engine; <answer> struct 
enum intel_engine_id <token> <answer> id; 
int <token> = 0; <answer> err 
<token> gt, id) { <answer> for_each_engine(engine, 
const struct <token> <answer> { 
u32 <token> <answer> reg; 
<token> offset; <answer> u32 
const char <token> <answer> *name; 
} tbl[] <token> { <answer> = 
<token> - 1, <answer> CTX_RING_START 
<token> - 1, <answer> CTX_RING_CTL 
CTX_RING_HEAD <token> 1, <answer> - 
CTX_RING_TAIL <token> 1, <answer> - 
CTX_BB_STATE - <token> <answer> 1, 
<token> - 1, <answer> CTX_TIMESTAMP 
i915_mmio_reg_offset(GEN8_RING_CS_GPR(engine->mmio_base, <token> <answer> 0)), 
<token> }, <answer> { 
<token> *t; <answer> }, 
u32 <token> <answer> *hw; 
<token> (!engine->default_state) <answer> if 
hw = <token> <answer> shmem_pin_map(engine->default_state); 
<token> (!hw) { <answer> if 
err = <token> <answer> -ENOMEM; 
hw += <token> / sizeof(*hw); <answer> LRC_STATE_OFFSET 
for (t = tbl; t->name; t++) <token> <answer> { 
int dw = <token> t->reg); <answer> find_offset(hw, 
if (dw != <token> { <answer> t->offset) 
pr_err("%s: Offset for %s <token> mismatch, found %x, expected %x\n", <answer> [0x%x] 
err <token> -EINVAL; <answer> = 
shmem_unpin_map(engine->default_state, <token> <answer> hw); 
<token> err; <answer> return 
<token> int __live_lrc_state(struct intel_engine_cs *engine, <answer> static 
struct <token> *scratch) <answer> i915_vma 
struct intel_context <token> <answer> *ce; 
struct i915_request <token> <answer> *rq; 
struct i915_gem_ww_ctx <token> <answer> ww; 
enum <token> <answer> { 
RING_START_IDX <token> 0, <answer> = 
u32 <token> <answer> expected[MAX_IDX]; 
<token> *cs; <answer> u32 
int <token> <answer> err; 
<token> n; <answer> int 
<token> = intel_context_create(engine); <answer> ce 
<token> (IS_ERR(ce)) <answer> if 
<token> PTR_ERR(ce); <answer> return 
<token> false); <answer> i915_gem_ww_ctx_init(&ww, 
err = <token> &ww); <answer> i915_gem_object_lock(scratch->obj, 
<token> (!err) <answer> if 
err <token> intel_context_pin_ww(ce, &ww); <answer> = 
<token> (err) <answer> if 
<token> err_put; <answer> goto 
rq <token> i915_request_create(ce); <answer> = 
<token> (IS_ERR(rq)) { <answer> if 
<token> = PTR_ERR(rq); <answer> err 
<token> err_unpin; <answer> goto 
cs = <token> 4 * MAX_IDX); <answer> intel_ring_begin(rq, 
if (IS_ERR(cs)) <token> <answer> { 
err = <token> <answer> PTR_ERR(cs); 
<token> err_unpin; <answer> goto 
*cs++ = MI_STORE_REGISTER_MEM_GEN8 | <token> <answer> MI_USE_GGTT; 
<token> = i915_mmio_reg_offset(RING_START(engine->mmio_base)); <answer> *cs++ 
*cs++ = i915_ggtt_offset(scratch) <token> RING_START_IDX * sizeof(u32); <answer> + 
*cs++ = <token> <answer> 0; 
<token> = i915_ggtt_offset(ce->ring->vma); <answer> expected[RING_START_IDX] 
*cs++ = MI_STORE_REGISTER_MEM_GEN8 <token> MI_USE_GGTT; <answer> | 
*cs++ <token> i915_mmio_reg_offset(RING_TAIL(engine->mmio_base)); <answer> = 
*cs++ = i915_ggtt_offset(scratch) + RING_TAIL_IDX <token> sizeof(u32); <answer> * 
<token> = 0; <answer> *cs++ 
<token> = i915_vma_move_to_active(scratch, rq, EXEC_OBJECT_WRITE); <answer> err 
<token> (err) <answer> if 
goto <token> <answer> err_rq; 
<token> = ce->ring->tail; <answer> expected[RING_TAIL_IDX] 
if <token> 0, HZ / 5) < 0) { <answer> (i915_request_wait(rq, 
err = <token> <answer> -ETIME; 
goto <token> <answer> err_rq; 
cs = <token> I915_MAP_WB); <answer> i915_gem_object_pin_map(scratch->obj, 
<token> (IS_ERR(cs)) { <answer> if 
err <token> PTR_ERR(cs); <answer> = 
<token> err_rq; <answer> goto 
<token> (n = 0; n < MAX_IDX; n++) { <answer> for 
if (cs[n] != expected[n]) <token> <answer> { 
pr_err("%s: Stored register[%d] value[0x%x] did <token> match expected[0x%x]\n", <answer> not 
<token> n, cs[n], expected[n]); <answer> engine->name, 
err = <token> <answer> -EINVAL; 
if <token> == -EDEADLK) { <answer> (err 
err = <token> <answer> i915_gem_ww_ctx_backoff(&ww); 
if <token> <answer> (!err) 
goto <token> <answer> retry; 
<token> err; <answer> return 
static int live_lrc_state(void <token> <answer> *arg) 
struct intel_gt <token> = arg; <answer> *gt 
struct intel_engine_cs <token> <answer> *engine; 
<token> i915_vma *scratch; <answer> struct 
<token> intel_engine_id id; <answer> enum 
int <token> = 0; <answer> err 
scratch = <token> <answer> create_scratch(gt); 
<token> (IS_ERR(scratch)) <answer> if 
return <token> <answer> PTR_ERR(scratch); 
for_each_engine(engine, <token> id) { <answer> gt, 
err = __live_lrc_state(engine, <token> <answer> scratch); 
<token> (err) <answer> if 
<token> (igt_flush_test(gt->i915)) <answer> if 
err = <token> <answer> -EIO; 
<token> 0); <answer> i915_vma_unpin_and_release(&scratch, 
<token> err; <answer> return 
static <token> gpr_make_dirty(struct intel_context *ce) <answer> int 
struct i915_request <token> <answer> *rq; 
u32 <token> <answer> *cs; 
<token> n; <answer> int 
<token> = intel_context_create_request(ce); <answer> rq 
<token> (IS_ERR(rq)) <answer> if 
<token> PTR_ERR(rq); <answer> return 
cs = intel_ring_begin(rq, 2 * NUM_GPR_DW + <token> <answer> 2); 
<token> (IS_ERR(cs)) { <answer> if 
<token> PTR_ERR(cs); <answer> return 
*cs++ = <token> <answer> MI_LOAD_REGISTER_IMM(NUM_GPR_DW); 
for (n = 0; n < NUM_GPR_DW; n++) <token> <answer> { 
<token> = CS_GPR(ce->engine, n); <answer> *cs++ 
*cs++ <token> STACK_MAGIC; <answer> = 
*cs++ = <token> <answer> MI_NOOP; 
<token> cs); <answer> intel_ring_advance(rq, 
rq->sched.attr.priority <token> I915_PRIORITY_BARRIER; <answer> = 
<token> 0; <answer> return 
static <token> i915_request * <answer> struct 
__gpr_read(struct intel_context *ce, struct i915_vma *scratch, <token> *slot) <answer> u32 
const u32 offset <token> <answer> = 
<token> + <answer> i915_ggtt_offset(ce->engine->status_page.vma) 
<token> i915_request *rq; <answer> struct 
<token> *cs; <answer> u32 
int <token> <answer> err; 
int <token> <answer> n; 
rq <token> intel_context_create_request(ce); <answer> = 
if <token> <answer> (IS_ERR(rq)) 
<token> rq; <answer> return 
cs = intel_ring_begin(rq, 6 + <token> * NUM_GPR_DW); <answer> 4 
if (IS_ERR(cs)) <token> <answer> { 
return <token> <answer> ERR_CAST(cs); 
*cs++ = MI_ARB_ON_OFF <token> MI_ARB_ENABLE; <answer> | 
<token> = MI_NOOP; <answer> *cs++ 
*cs++ <token> MI_SEMAPHORE_WAIT | <answer> = 
<token> | <answer> MI_SEMAPHORE_GLOBAL_GTT 
MI_SEMAPHORE_POLL <token> <answer> | 
*cs++ = <token> <answer> 0; 
<token> = offset; <answer> *cs++ 
<token> = 0; <answer> *cs++ 
for (n = 0; n < NUM_GPR_DW; <token> { <answer> n++) 
*cs++ <token> MI_STORE_REGISTER_MEM_GEN8 | MI_USE_GGTT; <answer> = 
<token> = CS_GPR(ce->engine, n); <answer> *cs++ 
<token> = i915_ggtt_offset(scratch) + n * sizeof(u32); <answer> *cs++ 
*cs++ <token> 0; <answer> = 
err = igt_vma_move_to_active_unlocked(scratch, <token> EXEC_OBJECT_WRITE); <answer> rq, 
if <token> { <answer> (err) 
rq = <token> <answer> ERR_PTR(err); 
return <token> <answer> rq; 
static int __live_lrc_gpr(struct intel_engine_cs <token> <answer> *engine, 
<token> i915_vma *scratch, <answer> struct 
<token> preempt) <answer> bool 
u32 *slot <token> memset32(engine->status_page.addr + 1000, 0, 4); <answer> = 
<token> intel_context *ce; <answer> struct 
<token> i915_request *rq; <answer> struct 
u32 <token> <answer> *cs; 
<token> err; <answer> int 
int <token> <answer> n; 
if (GRAPHICS_VER(engine->i915) < 9 && engine->class <token> RENDER_CLASS) <answer> != 
scratch <token> create_scratch(gt); <answer> = 
<token> (IS_ERR(scratch)) <answer> if 
<token> PTR_ERR(scratch); <answer> return 
<token> gt, id) { <answer> for_each_engine(engine, 
<token> = __live_lrc_gpr(engine, scratch, false); <answer> err 
<token> (err) <answer> if 
<token> err; <answer> goto 
err = __live_lrc_gpr(engine, scratch, <token> <answer> true); 
if <token> <answer> (err) 
<token> err; <answer> goto 
if <token> <answer> (igt_flush_test(gt->i915)) 
<token> = -EIO; <answer> err 
if <token> <answer> (err) 
<token> 0); <answer> i915_vma_unpin_and_release(&scratch, 
return <token> <answer> err; 
static struct i915_request <token> <answer> * 
create_timestamp(struct <token> *ce, void *slot, int idx) <answer> intel_context 
const <token> offset = <answer> u32 
i915_ggtt_offset(ce->engine->status_page.vma) <token> <answer> + 
struct i915_request <token> <answer> *rq; 
<token> *cs; <answer> u32 
int <token> <answer> err; 
<token> = intel_context_create_request(ce); <answer> rq 
if <token> <answer> (IS_ERR(rq)) 
return <token> <answer> rq; 
cs = intel_ring_begin(rq, <token> <answer> 10); 
if <token> { <answer> (IS_ERR(cs)) 
err <token> PTR_ERR(cs); <answer> = 
goto <token> <answer> err; 
*cs++ = MI_ARB_ON_OFF <token> MI_ARB_ENABLE; <answer> | 
*cs++ = <token> <answer> MI_NOOP; 
<token> = MI_SEMAPHORE_WAIT | <answer> *cs++ 
MI_SEMAPHORE_GLOBAL_GTT <token> <answer> | 
<token> | <answer> MI_SEMAPHORE_POLL 
*cs++ = <token> <answer> 0; 
*cs++ = <token> <answer> offset; 
*cs++ <token> 0; <answer> = 
<token> = MI_STORE_REGISTER_MEM_GEN8 | MI_USE_GGTT; <answer> *cs++ 
*cs++ <token> i915_mmio_reg_offset(RING_CTX_TIMESTAMP(rq->engine->mmio_base)); <answer> = 
<token> = offset + idx * sizeof(u32); <answer> *cs++ 
*cs++ = <token> <answer> 0; 
intel_ring_advance(rq, <token> <answer> cs); 
<token> = 0; <answer> err 
if <token> { <answer> (err) 
<token> ERR_PTR(err); <answer> return 
<token> rq; <answer> return 
struct <token> { <answer> lrc_timestamp 
<token> intel_engine_cs *engine; <answer> struct 
<token> intel_context *ce[2]; <answer> struct 
<token> poison; <answer> u32 
static bool timestamp_advanced(u32 <token> u32 end) <answer> start, 
return <token> - start) > 0; <answer> (s32)(end 
static <token> __lrc_timestamp(const struct lrc_timestamp *arg, bool preempt) <answer> int 
u32 *slot = memset32(arg->engine->status_page.addr + <token> 0, 4); <answer> 1000, 
struct i915_request <token> <answer> *rq; 
u32 <token> <answer> timestamp; 
int err = <token> <answer> 0; 
arg->ce[0]->lrc_reg_state[CTX_TIMESTAMP] <token> arg->poison; <answer> = 
rq = create_timestamp(arg->ce[0], <token> 1); <answer> slot, 
if <token> <answer> (IS_ERR(rq)) 
return <token> <answer> PTR_ERR(rq); 
<token> = wait_for_submit(rq->engine, rq, HZ / 2); <answer> err 
if <token> <answer> (err) 
goto <token> <answer> err; 
if (preempt) <token> <answer> { 
<token> = 0xdeadbeef; <answer> arg->ce[1]->lrc_reg_state[CTX_TIMESTAMP] 
err = <token> slot); <answer> emit_semaphore_signal(arg->ce[1], 
if <token> <answer> (err) 
goto <token> <answer> err; 
} else <token> <answer> { 
slot[0] <token> 1; <answer> = 
for_each_engine(data.engine, gt, id) <token> <answer> { 
<token> i, err = 0; <answer> int 
for <token> = 0; i < ARRAY_SIZE(data.ce); i++) { <answer> (i 
struct <token> *tmp; <answer> intel_context 
<token> = intel_context_create(data.engine); <answer> tmp 
if <token> { <answer> (IS_ERR(tmp)) 
<token> = PTR_ERR(tmp); <answer> err 
<token> err; <answer> goto 
err = <token> <answer> intel_context_pin(tmp); 
<token> (err) { <answer> if 
<token> err; <answer> goto 
<token> = tmp; <answer> data.ce[i] 
for (i = 0; i < <token> i++) { <answer> ARRAY_SIZE(poison); 
data.poison <token> poison[i]; <answer> = 
err <token> __lrc_timestamp(&data, false); <answer> = 
if <token> <answer> (err) 
err = <token> true); <answer> __lrc_timestamp(&data, 
<token> (err) <answer> if 
for <token> = 0; i < ARRAY_SIZE(data.ce); i++) { <answer> (i 
<token> (!data.ce[i]) <answer> if 
if <token> <answer> (igt_flush_test(gt->i915)) 
err <token> -EIO; <answer> = 
<token> (err) <answer> if 
<token> err; <answer> return 
return <token> <answer> 0; 
static <token> i915_vma * <answer> struct 
create_user_vma(struct i915_address_space *vm, unsigned <token> size) <answer> long 
struct <token> *obj; <answer> drm_i915_gem_object 
<token> i915_vma *vma; <answer> struct 
<token> err; <answer> int 
obj <token> i915_gem_object_create_internal(vm->i915, size); <answer> = 
<token> (IS_ERR(obj)) <answer> if 
return <token> <answer> ERR_CAST(obj); 
vma = i915_vma_instance(obj, <token> NULL); <answer> vm, 
<token> (IS_ERR(vma)) { <answer> if 
<token> vma; <answer> return 
err = i915_vma_pin(vma, 0, 0, <token> <answer> PIN_USER); 
if (err) <token> <answer> { 
return <token> <answer> ERR_PTR(err); 
<token> vma; <answer> return 
static <token> safe_poison(u32 offset, u32 poison) <answer> u32 
<token> (offset == i915_mmio_reg_offset(RING_PREDICATE_RESULT(0))) <answer> if 
poison <token> ~REG_BIT(0); <answer> &= 
<token> poison; <answer> return 
static struct <token> * <answer> i915_vma 
store_context(struct <token> *ce, struct i915_vma *scratch) <answer> intel_context 
<token> i915_vma *batch; <answer> struct 
u32 dw, <token> *cs, *hw; <answer> x, 
u32 <token> <answer> *defaults; 
batch <token> create_user_vma(ce->vm, SZ_64K); <answer> = 
<token> (IS_ERR(batch)) <answer> if 
return <token> <answer> batch; 
cs <token> i915_gem_object_pin_map_unlocked(batch->obj, I915_MAP_WC); <answer> = 
if <token> { <answer> (IS_ERR(cs)) 
return <token> <answer> ERR_CAST(cs); 
defaults <token> shmem_pin_map(ce->engine->default_state); <answer> = 
<token> (!defaults) { <answer> if 
return <token> <answer> ERR_PTR(-ENOMEM); 
x <token> 0; <answer> = 
<token> = 0; <answer> dw 
<token> = defaults; <answer> hw 
hw += <token> / sizeof(*hw); <answer> LRC_STATE_OFFSET 
do <token> <answer> { 
u32 <token> = hw[dw] & LRI_LENGTH_MASK; <answer> len 
if ((hw[dw] >> <token> != INSTR_MI_CLIENT) <answer> INSTR_CLIENT_SHIFT) 
if (hw[dw] == 0) <token> <answer> { 
if ((hw[dw] <token> GENMASK(31, 23)) != LRI_HEADER) { <answer> & 
for_each_engine(engine, <token> id) { <answer> gt, 
<token> i; <answer> int 
<token> per_ctx); <answer> wabb_ctx_setup(a, 
wabb_ctx_setup(b, <token> <answer> per_ctx); 
err <token> wabb_ctx_check(a, per_ctx); <answer> = 
<token> (err) <answer> if 
goto <token> <answer> unpin_b; 
<token> = wabb_ctx_check(b, per_ctx); <answer> err 
<token> err; <answer> return 
static int lrc_wabb_ctx(void <token> bool per_ctx) <answer> *arg, 
struct intel_gt *gt = <token> <answer> arg; 
<token> intel_engine_cs *engine; <answer> struct 
enum intel_engine_id <token> <answer> id; 
int <token> = 0; <answer> err 
<token> gt, id) { <answer> for_each_engine(engine, 
err = <token> per_ctx); <answer> __lrc_wabb_ctx(engine, 
<token> (igt_flush_test(gt->i915)) <answer> if 
<token> = -EIO; <answer> err 
if <token> <answer> (err) 
<token> err; <answer> return 
<token> int live_lrc_indirect_ctx_bb(void *arg) <answer> static 
<token> lrc_wabb_ctx(arg, false); <answer> return 
static <token> live_lrc_per_ctx_bb(void *arg) <answer> int 
return lrc_wabb_ctx(arg, <token> <answer> true); 
static void <token> intel_engine_cs *engine, <answer> garbage_reset(struct 
<token> i915_request *rq) <answer> struct 
const unsigned int bit <token> I915_RESET_ENGINE + engine->id; <answer> = 
unsigned long *lock <token> &engine->gt->reset.flags; <answer> = 
if (!test_and_set_bit(bit, <token> { <answer> lock)) 
if <token> <answer> (!rq->fence.error) 
__intel_engine_reset_bh(engine, <token> <answer> NULL); 
<token> lock); <answer> clear_and_wake_up_bit(bit, 
static <token> i915_request *garbage(struct intel_context *ce, <answer> struct 
struct <token> *prng) <answer> rnd_state 
struct i915_request <token> <answer> *rq; 
<token> err; <answer> int 
err <token> intel_context_pin(ce); <answer> = 
<token> (err) <answer> if 
return <token> <answer> ERR_PTR(err); 
ce->engine->context_size <token> <answer> - 
rq = <token> <answer> intel_context_create_request(ce); 
if <token> { <answer> (IS_ERR(rq)) 
err = <token> <answer> PTR_ERR(rq); 
<token> err_unpin; <answer> goto 
return <token> <answer> rq; 
<token> ERR_PTR(err); <answer> return 
static int __lrc_garbage(struct intel_engine_cs *engine, struct rnd_state <token> <answer> *prng) 
struct <token> *ce; <answer> intel_context 
<token> i915_request *hang; <answer> struct 
int err = <token> <answer> 0; 
ce = <token> <answer> intel_context_create(engine); 
if <token> <answer> (IS_ERR(ce)) 
<token> PTR_ERR(ce); <answer> return 
hang = garbage(ce, <token> <answer> prng); 
<token> (IS_ERR(hang)) { <answer> if 
<token> = PTR_ERR(hang); <answer> err 
<token> err_ce; <answer> goto 
if (wait_for_submit(engine, <token> HZ / 2)) { <answer> hang, 
err <token> -ETIME; <answer> = 
<token> err_ce; <answer> goto 
garbage_reset(engine, <token> <answer> hang); 
<token> (!hang->fence.error) { <answer> if 
pr_err("%s: corrupted <token> was not reset\n", <answer> context 
err <token> -EINVAL; <answer> = 
goto <token> <answer> err_ce; 
if (i915_request_wait(hang, 0, HZ / <token> < 0) { <answer> 2) 
pr_err("%s: corrupted context did not <token> <answer> recover\n", 
<token> = -EIO; <answer> err 
goto <token> <answer> err_ce; 
<token> err; <answer> return 
<token> int live_lrc_garbage(void *arg) <answer> static 
struct intel_gt *gt <token> arg; <answer> = 
struct <token> *engine; <answer> intel_engine_cs 
<token> intel_engine_id id; <answer> enum 
<token> (!IS_ENABLED(CONFIG_DRM_I915_SELFTEST_BROKEN)) <answer> if 
return <token> <answer> 0; 
<token> gt, id) { <answer> for_each_engine(engine, 
<token> err = 0, i; <answer> int 
if <token> <answer> (!intel_has_reset_engine(engine->gt)) 
for (i = 0; i < <token> i++) { <answer> 3; 
err <token> __lrc_garbage(engine, &prng); <answer> = 
if <token> <answer> (err) 
<token> (igt_flush_test(gt->i915)) <answer> if 
<token> = -EIO; <answer> err 
if <token> <answer> (err) 
return <token> <answer> err; 
<token> 0; <answer> return 
static <token> __live_pphwsp_runtime(struct intel_engine_cs *engine) <answer> int 
struct <token> *ce; <answer> intel_context 
struct <token> *rq; <answer> i915_request 
int <token> <answer> err; 
<token> = intel_context_create(engine); <answer> ce 
if <token> <answer> (IS_ERR(ce)) 
return <token> <answer> PTR_ERR(ce); 
ce->stats.runtime.num_underflow <token> 0; <answer> = 
<token> = 0; <answer> ce->stats.runtime.max_underflow 
<token> { <answer> do 
unsigned int loop <token> 1024; <answer> = 
<token> (loop) { <answer> while 
rq = <token> <answer> intel_context_create_request(ce); 
if <token> { <answer> (IS_ERR(rq)) 
err <token> PTR_ERR(rq); <answer> = 
goto <token> <answer> err_rq; 
if (--loop <token> 0) <answer> == 
<token> (__igt_timeout(end_time, NULL)) <answer> if 
} <token> (1); <answer> while 
err = <token> 0, HZ / 5); <answer> i915_request_wait(rq, 
if <token> < 0) { <answer> (err 
pr_err("%s: <token> not completed!\n", engine->name); <answer> request 
<token> err_wait; <answer> goto 
pr_info("%s: pphwsp <token> %lluns, average %lluns\n", <answer> runtime 
err <token> 0; <answer> = 
if (ce->stats.runtime.num_underflow) <token> <answer> { 
<token> pphwsp underflow %u time(s), max %u cycles!\n", <answer> pr_err("%s: 
err <token> -EOVERFLOW; <answer> = 
<token> err; <answer> return 
static int <token> *arg) <answer> live_pphwsp_runtime(void 
<token> intel_gt *gt = arg; <answer> struct 
<token> intel_engine_cs *engine; <answer> struct 
enum intel_engine_id <token> <answer> id; 
int err = <token> <answer> 0; 
for_each_engine(engine, gt, id) <token> <answer> { 
err = <token> <answer> __live_pphwsp_runtime(engine); 
<token> (err) <answer> if 
<token> (igt_flush_test(gt->i915)) <answer> if 
err = <token> <answer> -EIO; 
<token> err; <answer> return 
int <token> drm_i915_private *i915) <answer> intel_lrc_live_selftests(struct 
static const <token> i915_subtest tests[] = { <answer> struct 
<token> (!HAS_LOGICAL_RING_CONTEXTS(i915)) <answer> if 
return <token> <answer> 0; 
<token> intel_gt_live_subtests(tests, to_gt(i915)); <answer> return 
#include <token> <answer> <linux/of.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/pm_domain.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <soc/tegra/bpmp.h> <answer> #include 
#include <token> <answer> <soc/tegra/bpmp-abi.h> 
struct tegra_powergate_info <token> <answer> { 
unsigned int <token> <answer> id; 
<token> *name; <answer> char 
struct tegra_powergate <token> <answer> { 
struct <token> genpd; <answer> generic_pm_domain 
<token> tegra_bpmp *bpmp; <answer> struct 
<token> int id; <answer> unsigned 
<token> inline struct tegra_powergate * <answer> static 
to_tegra_powergate(struct <token> *genpd) <answer> generic_pm_domain 
<token> container_of(genpd, struct tegra_powergate, genpd); <answer> return 
static int <token> tegra_bpmp *bpmp, <answer> tegra_bpmp_powergate_set_state(struct 
unsigned int id, <token> state) <answer> u32 
struct mrq_pg_request <token> <answer> request; 
struct <token> msg; <answer> tegra_bpmp_message 
int <token> <answer> err; 
memset(&request, <token> sizeof(request)); <answer> 0, 
request.cmd <token> CMD_PG_SET_STATE; <answer> = 
request.id = <token> <answer> id; 
request.set_state.state <token> state; <answer> = 
memset(&msg, <token> sizeof(msg)); <answer> 0, 
msg.mrq = <token> <answer> MRQ_PG; 
msg.tx.data = <token> <answer> &request; 
msg.tx.size <token> sizeof(request); <answer> = 
err = <token> &msg); <answer> tegra_bpmp_transfer(bpmp, 
if <token> < 0) <answer> (err 
<token> err; <answer> return 
else if (msg.rx.ret <token> 0) <answer> < 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
static int tegra_bpmp_powergate_get_state(struct tegra_bpmp <token> <answer> *bpmp, 
unsigned int <token> <answer> id) 
struct <token> response; <answer> mrq_pg_response 
struct <token> request; <answer> mrq_pg_request 
<token> tegra_bpmp_message msg; <answer> struct 
int <token> <answer> err; 
memset(&request, 0, <token> <answer> sizeof(request)); 
<token> = CMD_PG_GET_STATE; <answer> request.cmd 
request.id <token> id; <answer> = 
memset(&response, 0, <token> <answer> sizeof(response)); 
<token> 0, sizeof(msg)); <answer> memset(&msg, 
<token> = MRQ_PG; <answer> msg.mrq 
msg.tx.data = <token> <answer> &request; 
msg.tx.size <token> sizeof(request); <answer> = 
msg.rx.data <token> &response; <answer> = 
msg.rx.size <token> sizeof(response); <answer> = 
err = <token> &msg); <answer> tegra_bpmp_transfer(bpmp, 
if <token> < 0) <answer> (err 
return <token> <answer> PG_STATE_OFF; 
else <token> (msg.rx.ret < 0) <answer> if 
return <token> <answer> -EINVAL; 
<token> response.get_state.state; <answer> return 
static int tegra_bpmp_powergate_get_max_id(struct tegra_bpmp <token> <answer> *bpmp) 
<token> mrq_pg_response response; <answer> struct 
<token> mrq_pg_request request; <answer> struct 
struct tegra_bpmp_message <token> <answer> msg; 
<token> err; <answer> int 
memset(&request, <token> sizeof(request)); <answer> 0, 
<token> = CMD_PG_GET_MAX_ID; <answer> request.cmd 
memset(&response, 0, <token> <answer> sizeof(response)); 
<token> 0, sizeof(msg)); <answer> memset(&msg, 
msg.mrq = <token> <answer> MRQ_PG; 
<token> = &request; <answer> msg.tx.data 
<token> = sizeof(request); <answer> msg.tx.size 
msg.rx.data <token> &response; <answer> = 
<token> = sizeof(response); <answer> msg.rx.size 
err = tegra_bpmp_transfer(bpmp, <token> <answer> &msg); 
if <token> < 0) <answer> (err 
<token> err; <answer> return 
else if (msg.rx.ret <token> 0) <answer> < 
<token> -EINVAL; <answer> return 
return <token> <answer> response.get_max_id.max_id; 
static char *tegra_bpmp_powergate_get_name(struct tegra_bpmp <token> <answer> *bpmp, 
<token> int id) <answer> unsigned 
struct <token> response; <answer> mrq_pg_response 
struct mrq_pg_request <token> <answer> request; 
<token> tegra_bpmp_message msg; <answer> struct 
int <token> <answer> err; 
memset(&request, 0, <token> <answer> sizeof(request)); 
request.cmd = <token> <answer> CMD_PG_GET_NAME; 
request.id = <token> <answer> id; 
memset(&response, 0, <token> <answer> sizeof(response)); 
<token> 0, sizeof(msg)); <answer> memset(&msg, 
msg.mrq = <token> <answer> MRQ_PG; 
msg.tx.data = <token> <answer> &request; 
<token> = sizeof(request); <answer> msg.tx.size 
msg.rx.data <token> &response; <answer> = 
<token> = sizeof(response); <answer> msg.rx.size 
<token> = tegra_bpmp_transfer(bpmp, &msg); <answer> err 
if (err < 0 || msg.rx.ret <token> 0) <answer> < 
return <token> <answer> NULL; 
return <token> GFP_KERNEL); <answer> kstrdup(response.get_name.name, 
static <token> bool tegra_bpmp_powergate_is_powered(struct tegra_bpmp *bpmp, <answer> inline 
unsigned <token> id) <answer> int 
return <token> id) != PG_STATE_OFF; <answer> tegra_bpmp_powergate_get_state(bpmp, 
static <token> tegra_powergate_power_on(struct generic_pm_domain *domain) <answer> int 
struct tegra_powergate <token> = to_tegra_powergate(domain); <answer> *powergate 
struct tegra_bpmp <token> = powergate->bpmp; <answer> *bpmp 
<token> tegra_bpmp_powergate_set_state(bpmp, powergate->id, <answer> return 
static int tegra_powergate_power_off(struct generic_pm_domain <token> <answer> *domain) 
struct tegra_powergate *powergate = <token> <answer> to_tegra_powergate(domain); 
struct tegra_bpmp <token> = powergate->bpmp; <answer> *bpmp 
return <token> powergate->id, <answer> tegra_bpmp_powergate_set_state(bpmp, 
<token> struct tegra_powergate * <answer> static 
tegra_powergate_add(struct <token> *bpmp, <answer> tegra_bpmp 
const <token> tegra_powergate_info *info) <answer> struct 
struct tegra_powergate <token> <answer> *powergate; 
<token> off; <answer> bool 
int <token> <answer> err; 
<token> = !tegra_bpmp_powergate_is_powered(bpmp, info->id); <answer> off 
powergate = devm_kzalloc(bpmp->dev, <token> GFP_KERNEL); <answer> sizeof(*powergate), 
if <token> <answer> (!powergate) 
return <token> <answer> ERR_PTR(-ENOMEM); 
powergate->id = <token> <answer> info->id; 
powergate->bpmp = <token> <answer> bpmp; 
powergate->genpd.name = kstrdup(info->name, <token> <answer> GFP_KERNEL); 
powergate->genpd.power_on = <token> <answer> tegra_powergate_power_on; 
powergate->genpd.power_off <token> tegra_powergate_power_off; <answer> = 
err = pm_genpd_init(&powergate->genpd, <token> off); <answer> NULL, 
<token> (err < 0) { <answer> if 
return <token> <answer> ERR_PTR(err); 
<token> powergate; <answer> return 
<token> void tegra_powergate_remove(struct tegra_powergate *powergate) <answer> static 
struct <token> *genpd = &powergate->genpd; <answer> generic_pm_domain 
struct tegra_bpmp *bpmp <token> powergate->bpmp; <answer> = 
<token> err; <answer> int 
<token> = pm_genpd_remove(genpd); <answer> err 
if (err <token> 0) <answer> < 
dev_err(bpmp->dev, "failed to <token> power domain %s: %d\n", <answer> remove 
genpd->name, <token> <answer> err); 
<token> int <answer> static 
tegra_bpmp_probe_powergates(struct <token> *bpmp, <answer> tegra_bpmp 
struct <token> **powergatesp) <answer> tegra_powergate_info 
struct tegra_powergate_info <token> <answer> *powergates; 
<token> int max_id, id, count = 0; <answer> unsigned 
unsigned int <token> = 0; <answer> num_holes 
<token> err; <answer> int 
err = <token> <answer> tegra_bpmp_powergate_get_max_id(bpmp); 
if (err < <token> <answer> 0) 
return <token> <answer> err; 
<token> = err; <answer> max_id 
dev_dbg(bpmp->dev, "maximum powergate ID: %u\n", <token> <answer> max_id); 
powergates = kcalloc(max_id + <token> sizeof(*powergates), GFP_KERNEL); <answer> 1, 
if <token> <answer> (!powergates) 
return <token> <answer> -ENOMEM; 
for (id <token> 0; id <= max_id; id++) { <answer> = 
struct tegra_powergate_info *info <token> &powergates[count]; <answer> = 
info->name = tegra_bpmp_powergate_get_name(bpmp, <token> <answer> id); 
if (!info->name || info->name[0] == <token> { <answer> '\0') 
<token> = id; <answer> info->id 
<token> "holes: %u\n", num_holes); <answer> dev_dbg(bpmp->dev, 
*powergatesp <token> powergates; <answer> = 
<token> count; <answer> return 
static int tegra_bpmp_add_powergates(struct tegra_bpmp <token> <answer> *bpmp, 
<token> tegra_powergate_info *powergates, <answer> struct 
unsigned int <token> <answer> count) 
struct <token> *genpd = &bpmp->genpd; <answer> genpd_onecell_data 
struct generic_pm_domain <token> <answer> **domains; 
struct <token> *powergate; <answer> tegra_powergate 
<token> int i; <answer> unsigned 
int <token> <answer> err; 
domains <token> kcalloc(count, sizeof(*domains), GFP_KERNEL); <answer> = 
<token> (!domains) <answer> if 
return <token> <answer> -ENOMEM; 
for (i = 0; i <token> count; i++) { <answer> < 
powergate <token> tegra_powergate_add(bpmp, &powergates[i]); <answer> = 
<token> (IS_ERR(powergate)) { <answer> if 
err <token> PTR_ERR(powergate); <answer> = 
<token> remove; <answer> goto 
dev_dbg(bpmp->dev, "added power <token> %s\n", <answer> domain 
domains[i] <token> &powergate->genpd; <answer> = 
genpd->num_domains = <token> <answer> count; 
genpd->domains = <token> <answer> domains; 
return <token> <answer> 0; 
while <token> { <answer> (i--) 
<token> = to_tegra_powergate(domains[i]); <answer> powergate 
<token> err; <answer> return 
<token> void tegra_bpmp_remove_powergates(struct tegra_bpmp *bpmp) <answer> static 
struct genpd_onecell_data *genpd = <token> <answer> &bpmp->genpd; 
<token> int i = genpd->num_domains; <answer> unsigned 
struct <token> *powergate; <answer> tegra_powergate 
while (i--) <token> <answer> { 
dev_dbg(bpmp->dev, "removing power domain <token> <answer> %s\n", 
powergate = <token> <answer> to_tegra_powergate(genpd->domains[i]); 
<token> struct generic_pm_domain * <answer> static 
tegra_powergate_xlate(const struct of_phandle_args <token> void *data) <answer> *spec, 
struct generic_pm_domain *domain <token> ERR_PTR(-ENOENT); <answer> = 
<token> genpd_onecell_data *genpd = data; <answer> struct 
<token> int i; <answer> unsigned 
for <token> = 0; i < genpd->num_domains; i++) { <answer> (i 
struct tegra_powergate <token> <answer> *powergate; 
powergate = <token> <answer> to_tegra_powergate(genpd->domains[i]); 
<token> (powergate->id == spec->args[0]) { <answer> if 
<token> = &powergate->genpd; <answer> domain 
return <token> <answer> domain; 
int tegra_bpmp_init_powergates(struct <token> *bpmp) <answer> tegra_bpmp 
<token> device_node *np = bpmp->dev->of_node; <answer> struct 
struct tegra_powergate_info <token> <answer> *powergates; 
struct device <token> = bpmp->dev; <answer> *dev 
unsigned int count, <token> <answer> i; 
int <token> <answer> err; 
err = <token> &powergates); <answer> tegra_bpmp_probe_powergates(bpmp, 
if <token> < 0) <answer> (err 
<token> err; <answer> return 
<token> = err; <answer> count 
dev_dbg(dev, "%u power <token> probed\n", count); <answer> domains 
<token> = tegra_bpmp_add_powergates(bpmp, powergates, count); <answer> err 
if (err < <token> <answer> 0) 
<token> free; <answer> goto 
bpmp->genpd.xlate <token> tegra_powergate_xlate; <answer> = 
err = <token> &bpmp->genpd); <answer> of_genpd_add_provider_onecell(np, 
<token> (err < 0) { <answer> if 
dev_err(dev, "failed <token> add power domain provider: %d\n", err); <answer> to 
for (i <token> 0; i < count; i++) <answer> = 
<token> err; <answer> return 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/pci.h> 
<token> <linux/slab.h> <answer> #include 
<token> <linux/skbuff.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/if_ether.h> <answer> #include 
<token> <linux/if_vlan.h> <answer> #include 
<token> <linux/workqueue.h> <answer> #include 
<token> <scsi/fc/fc_fip.h> <answer> #include 
#include <token> <answer> <scsi/fc/fc_els.h> 
<token> <scsi/fc/fc_fcoe.h> <answer> #include 
<token> <scsi/fc_frame.h> <answer> #include 
<token> <scsi/libfc.h> <answer> #include 
#include <token> <answer> "fnic_io.h" 
#include <token> <answer> "fnic.h" 
#include <token> <answer> "fnic_fip.h" 
#include <token> <answer> "cq_enet_desc.h" 
<token> "cq_exch_desc.h" <answer> #include 
<token> u8 fcoe_all_fcfs[ETH_ALEN] = FIP_ALL_FCF_MACS; <answer> static 
struct <token> *fnic_fip_queue; <answer> workqueue_struct 
struct workqueue_struct <token> <answer> *fnic_event_queue; 
static <token> fnic_set_eth_mode(struct fnic *); <answer> void 
static void fnic_fcoe_send_vlan_req(struct <token> *fnic); <answer> fnic 
static <token> fnic_fcoe_start_fcf_disc(struct fnic *fnic); <answer> void 
static void <token> fnic *fnic, struct sk_buff *); <answer> fnic_fcoe_process_vlan_resp(struct 
static int fnic_fcoe_vlan_check(struct fnic *fnic, <token> flag); <answer> u16 
static int <token> fnic *fnic, struct sk_buff *skb); <answer> fnic_fcoe_handle_fip_frame(struct 
void fnic_handle_link(struct work_struct <token> <answer> *work) 
struct fnic <token> = container_of(work, struct fnic, link_work); <answer> *fnic 
unsigned <token> flags; <answer> long 
int <token> <answer> old_link_status; 
u32 <token> <answer> old_link_down_cnt; 
u64 old_port_speed, <token> <answer> new_port_speed; 
spin_lock_irqsave(&fnic->fnic_lock, <token> <answer> flags); 
<token> fnic_handle_frame(struct work_struct *work) <answer> void 
struct fnic *fnic = container_of(work, struct fnic, <token> <answer> frame_work); 
struct fc_lport *lp = <token> <answer> fnic->lport; 
<token> long flags; <answer> unsigned 
<token> sk_buff *skb; <answer> struct 
<token> fc_frame *fp; <answer> struct 
while ((skb <token> skb_dequeue(&fnic->frame_queue))) { <answer> = 
spin_lock_irqsave(&fnic->fnic_lock, <token> <answer> flags); 
<token> (fnic->stop_rx_link_events) { <answer> if 
spin_unlock_irqrestore(&fnic->fnic_lock, <token> <answer> flags); 
fp = (struct fc_frame <token> <answer> *)skb; 
if <token> != FNIC_IN_FC_MODE && <answer> (fnic->state 
fnic->state != <token> { <answer> FNIC_IN_ETH_MODE) 
skb_queue_head(&fnic->frame_queue, <token> <answer> skb); 
spin_unlock_irqrestore(&fnic->fnic_lock, <token> <answer> flags); 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
<token> fp); <answer> fc_exch_recv(lp, 
void fnic_fcoe_evlist_free(struct fnic <token> <answer> *fnic) 
struct fnic_event *fevt = <token> <answer> NULL; 
<token> fnic_event *next = NULL; <answer> struct 
<token> long flags; <answer> unsigned 
<token> flags); <answer> spin_lock_irqsave(&fnic->fnic_lock, 
if <token> { <answer> (list_empty(&fnic->evlist)) 
spin_unlock_irqrestore(&fnic->fnic_lock, <token> <answer> flags); 
list_for_each_entry_safe(fevt, next, &fnic->evlist, <token> { <answer> list) 
spin_unlock_irqrestore(&fnic->fnic_lock, <token> <answer> flags); 
<token> fnic_handle_event(struct work_struct *work) <answer> void 
struct fnic *fnic = container_of(work, struct fnic, <token> <answer> event_work); 
struct fnic_event *fevt = <token> <answer> NULL; 
<token> fnic_event *next = NULL; <answer> struct 
<token> long flags; <answer> unsigned 
<token> flags); <answer> spin_lock_irqsave(&fnic->fnic_lock, 
<token> (list_empty(&fnic->evlist)) { <answer> if 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
list_for_each_entry_safe(fevt, next, <token> list) { <answer> &fnic->evlist, 
<token> (fnic->stop_rx_link_events) { <answer> if 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
if (fnic->state != FNIC_IN_FC_MODE <token> <answer> && 
<token> != FNIC_IN_ETH_MODE) { <answer> fnic->state 
spin_unlock_irqrestore(&fnic->fnic_lock, <token> <answer> flags); 
switch <token> { <answer> (fevt->event) 
<token> FNIC_EVT_START_VLAN_DISC: <answer> case 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
<token> flags); <answer> spin_lock_irqsave(&fnic->fnic_lock, 
<token> FNIC_EVT_START_FCF_DISC: <answer> case 
FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host, <token> <answer> fnic->fnic_num, 
"Start FCF <token> <answer> Discovery\n"); 
<token> fnic->lport->host, fnic->fnic_num, <answer> FNIC_FCS_DBG(KERN_DEBUG, 
"Unknown <token> 0x%x\n", fevt->event); <answer> event 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
<token> inline int is_fnic_fip_flogi_reject(struct fcoe_ctlr *fip, <answer> static 
struct <token> *skb) <answer> sk_buff 
struct <token> *lport = fip->lp; <answer> fc_lport 
<token> fip_header *fiph; <answer> struct 
struct fc_frame_header *fh = <token> <answer> NULL; 
struct <token> *desc; <answer> fip_desc 
<token> fip_encaps *els; <answer> struct 
u16 <token> <answer> op; 
<token> els_op; <answer> u8 
<token> sub; <answer> u8 
size_t <token> <answer> rlen; 
<token> dlen = 0; <answer> size_t 
<token> (skb_linearize(skb)) <answer> if 
return <token> <answer> 0; 
if (skb->len < <token> <answer> sizeof(*fiph)) 
<token> 0; <answer> return 
fiph = (struct fip_header <token> <answer> *)skb->data; 
op = <token> <answer> ntohs(fiph->fip_op); 
<token> = fiph->fip_subcode; <answer> sub 
if <token> != FIP_OP_LS) <answer> (op 
<token> 0; <answer> return 
<token> (sub != FIP_SC_REP) <answer> if 
<token> 0; <answer> return 
rlen = <token> * 4; <answer> ntohs(fiph->fip_dl_len) 
if <token> + sizeof(*fiph) > skb->len) <answer> (rlen 
return <token> <answer> 0; 
desc = (struct fip_desc <token> + 1); <answer> *)(fiph 
<token> = desc->fip_dlen * FIP_BPW; <answer> dlen 
<token> (desc->fip_dtype == FIP_DT_FLOGI) { <answer> if 
if <token> < sizeof(*els) + sizeof(*fh) + 1) <answer> (dlen 
<token> 0; <answer> return 
els = (struct <token> *)desc; <answer> fip_encaps 
fh = <token> fc_frame_header *)(els + 1); <answer> (struct 
if <token> <answer> (!fh) 
return <token> <answer> 0; 
els_op = *(u8 <token> + 1); <answer> *)(fh 
if (els_op == <token> { <answer> ELS_LS_RJT) 
<token> lport->host, <answer> shost_printk(KERN_INFO, 
"Flogi Request Rejected by <token> <answer> Switch\n"); 
<token> 1; <answer> return 
shost_printk(KERN_INFO, <token> <answer> lport->host, 
"Flogi Request Accepted <token> Switch\n"); <answer> by 
<token> 0; <answer> return 
<token> void fnic_fcoe_send_vlan_req(struct fnic *fnic) <answer> static 
struct fcoe_ctlr <token> = &fnic->ctlr; <answer> *fip 
<token> fnic_stats *fnic_stats = &fnic->fnic_stats; <answer> struct 
struct sk_buff <token> <answer> *skb; 
char <token> <answer> *eth_fr; 
struct fip_vlan <token> <answer> *vlan; 
<token> vlan_tov; <answer> u64 
fnic->set_vlan(fnic, <token> <answer> 0); 
<token> (printk_ratelimit()) <answer> if 
<token> fnic->lport->host, fnic->fnic_num, <answer> FNIC_FCS_DBG(KERN_INFO, 
<token> VLAN request...\n"); <answer> "Sending 
skb = <token> fip_vlan)); <answer> dev_alloc_skb(sizeof(struct 
<token> (!skb) <answer> if 
eth_fr = (char <token> <answer> *)skb->data; 
vlan = (struct fip_vlan <token> <answer> *)eth_fr; 
<token> 0, sizeof(*vlan)); <answer> memset(vlan, 
memcpy(vlan->eth.h_source, fip->ctl_src_addr, <token> <answer> ETH_ALEN); 
<token> fcoe_all_fcfs, ETH_ALEN); <answer> memcpy(vlan->eth.h_dest, 
<token> = htons(ETH_P_FIP); <answer> vlan->eth.h_proto 
<token> = FIP_VER_ENCAPS(FIP_VER); <answer> vlan->fip.fip_ver 
vlan->fip.fip_op <token> htons(FIP_OP_VLAN); <answer> = 
vlan->fip.fip_subcode <token> FIP_SC_VL_REQ; <answer> = 
vlan->fip.fip_dl_len = <token> / FIP_BPW); <answer> htons(sizeof(vlan->desc) 
vlan->desc.mac.fd_desc.fip_dtype <token> FIP_DT_MAC; <answer> = 
vlan->desc.mac.fd_desc.fip_dlen = <token> / FIP_BPW; <answer> sizeof(vlan->desc.mac) 
<token> fip->ctl_src_addr, ETH_ALEN); <answer> memcpy(&vlan->desc.mac.fd_mac, 
vlan->desc.wwnn.fd_desc.fip_dtype <token> FIP_DT_NAME; <answer> = 
vlan->desc.wwnn.fd_desc.fip_dlen = sizeof(vlan->desc.wwnn) / <token> <answer> FIP_BPW; 
put_unaligned_be64(fip->lp->wwnn, <token> <answer> &vlan->desc.wwnn.fd_wwn); 
<token> sizeof(*vlan)); <answer> skb_put(skb, 
skb->protocol <token> htons(ETH_P_FIP); <answer> = 
<token> skb); <answer> fip->send(fip, 
if (fnic->state != <token> && <answer> FNIC_IN_FC_MODE 
fnic->state != <token> { <answer> FNIC_IN_ETH_MODE) 
skb_queue_head(&fnic->fip_frame_queue, <token> <answer> skb); 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
eh = (struct <token> *)skb->data; <answer> ethhdr 
if <token> == htons(ETH_P_FIP)) { <answer> (eh->h_proto 
skb_pull(skb, <token> <answer> sizeof(*eh)); 
<token> (fnic_fcoe_handle_fip_frame(fnic, skb) <= 0) { <answer> if 
if <token> skb)) { <answer> (is_fnic_fip_flogi_reject(&fnic->ctlr, 
shost_printk(KERN_INFO, <token> <answer> fnic->lport->host, 
"Trigger a <token> down - VLAN Disc\n"); <answer> Link 
static inline <token> fnic_import_rq_eth_pkt(struct fnic *fnic, struct sk_buff *skb) <answer> int 
<token> fc_frame *fp; <answer> struct 
struct ethhdr <token> <answer> *eh; 
struct fcoe_hdr <token> <answer> *fcoe_hdr; 
<token> fcoe_crc_eof *ft; <answer> struct 
eh = <token> ethhdr *)skb->data; <answer> (struct 
if (eh->h_proto <token> htons(ETH_P_8021Q)) { <answer> == 
memmove((u8 *)eh + VLAN_HLEN, eh, ETH_ALEN * <token> <answer> 2); 
<token> = skb_pull(skb, VLAN_HLEN); <answer> eh 
if (eh->h_proto == <token> { <answer> htons(ETH_P_FIP)) 
<token> (!(fnic->config.flags & VFCF_FIP_CAPABLE)) { <answer> if 
printk(KERN_ERR "Dropped <token> frame, as firmware " <answer> FIP 
"uses non-FIP mode, Enable FIP <token> <answer> " 
"using <token> <answer> UCSM\n"); 
<token> drop; <answer> goto 
if <token> <answer> ((fnic_fc_trace_set_data(fnic->lport->host->host_no, 
FNIC_FC_RECV|0x80, (char *)skb->data, skb->len)) <token> 0) { <answer> != 
printk(KERN_ERR <token> ctlr frame trace error!!!"); <answer> "fnic 
<token> skb); <answer> skb_queue_tail(&fnic->fip_frame_queue, 
<token> &fnic->fip_frame_work); <answer> queue_work(fnic_fip_queue, 
void fnic_update_mac_locked(struct fnic <token> u8 *new) <answer> *fnic, 
u8 *ctl <token> fnic->ctlr.ctl_src_addr; <answer> = 
<token> *data = fnic->data_src_addr; <answer> u8 
<token> (is_zero_ether_addr(new)) <answer> if 
<token> = ctl; <answer> new 
<token> (ether_addr_equal(data, new)) <answer> if 
<token> fnic->lport->host, fnic->fnic_num, <answer> FNIC_FCS_DBG(KERN_DEBUG, 
<token> %pM\n", new); <answer> "update_mac 
<token> (!is_zero_ether_addr(data) && !ether_addr_equal(data, ctl)) <answer> if 
<token> data); <answer> vnic_dev_del_addr(fnic->vdev, 
memcpy(data, <token> ETH_ALEN); <answer> new, 
if (!ether_addr_equal(new, <token> <answer> ctl)) 
vnic_dev_add_addr(fnic->vdev, <token> <answer> new); 
void fnic_update_mac(struct fc_lport <token> u8 *new) <answer> *lport, 
struct fnic *fnic = <token> <answer> lport_priv(lport); 
<token> new); <answer> fnic_update_mac_locked(fnic, 
void fnic_set_port_id(struct fc_lport *lport, u32 port_id, <token> fc_frame *fp) <answer> struct 
struct fnic *fnic = <token> <answer> lport_priv(lport); 
<token> *mac; <answer> u8 
<token> ret; <answer> int 
<token> lport->host, fnic->fnic_num, <answer> FNIC_FCS_DBG(KERN_DEBUG, 
"set port_id <token> fp 0x%p\n", <answer> 0x%x 
port_id, <token> <answer> fp); 
<token> (!port_id) { <answer> if 
fnic_update_mac(lport, <token> <answer> fnic->ctlr.ctl_src_addr); 
<token> (fp) { <answer> if 
mac = <token> <answer> fr_cb(fp)->granted_mac; 
if (is_zero_ether_addr(mac)) <token> <answer> { 
ret = <token> port_id); <answer> fnic_flogi_reg_handler(fnic, 
if (ret <token> 0) { <answer> < 
if <token> == FNIC_IN_ETH_TRANS_FC_MODE) <answer> (fnic->state 
<token> = FNIC_IN_ETH_MODE; <answer> fnic->state 
<token> void fnic_rq_cmpl_frame_recv(struct vnic_rq *rq, struct cq_desc <answer> static 
*cq_desc, struct <token> *buf, <answer> vnic_rq_buf 
<token> skipped __attribute__((unused)), <answer> int 
void <token> <answer> *opaque) 
struct fnic *fnic = <token> <answer> vnic_dev_priv(rq->vdev); 
struct <token> *skb; <answer> sk_buff 
struct fc_frame <token> <answer> *fp; 
struct fnic_stats *fnic_stats = <token> <answer> &fnic->fnic_stats; 
u8 type, <token> eop, sop, ingress_port, vlan_stripped; <answer> color, 
u8 fcoe = 0, <token> fcoe_eof; <answer> fcoe_sof, 
<token> fcoe_fc_crc_ok = 1, fcoe_enc_error = 0; <answer> u8 
u8 <token> udp, tcp, ipv4_csum_ok; <answer> tcp_udp_csum_ok, 
u8 ipv6, <token> ipv4_fragment, rss_type, csum_not_calc; <answer> ipv4, 
<token> fcs_ok = 1, packet_error = 0; <answer> u8 
<token> q_number, completed_index, bytes_written = 0, vlan, checksum; <answer> u16 
u32 <token> <answer> rss_hash; 
u16 <token> tmpl; <answer> exchange_id, 
u8 sof = <token> <answer> 0; 
u8 eof = <token> <answer> 0; 
u32 fcp_bytes_written = <token> <answer> 0; 
unsigned <token> flags; <answer> long 
dma_unmap_single(&fnic->pdev->dev, buf->dma_addr, <token> <answer> buf->len, 
<token> = buf->os_buf; <answer> skb 
<token> = (struct fc_frame *)skb; <answer> fp 
buf->os_buf = <token> <answer> NULL; 
cq_desc_dec(cq_desc, <token> &color, &q_number, &completed_index); <answer> &type, 
<token> (type == CQ_DESC_TYPE_RQ_FCP) { <answer> if 
cq_fcp_rq_desc_dec((struct cq_fcp_rq_desc <token> <answer> *)cq_desc, 
&type, &color, &q_number, <token> <answer> &completed_index, 
<token> &sop, &fcoe_fc_crc_ok, &exchange_id, <answer> &eop, 
&tmpl, &fcp_bytes_written, <token> &eof, <answer> &sof, 
<token> &packet_error, <answer> &ingress_port, 
<token> &fcs_ok, &vlan_stripped, <answer> &fcoe_enc_error, 
<token> fcp_bytes_written); <answer> skb_trim(skb, 
fr_sof(fp) = <token> <answer> sof; 
fr_eof(fp) <token> eof; <answer> = 
} else if <token> == CQ_DESC_TYPE_RQ_ENET) { <answer> (type 
cq_enet_rq_desc_dec((struct <token> *)cq_desc, <answer> cq_enet_rq_desc 
&type, &color, <token> &completed_index, <answer> &q_number, 
<token> &fcoe, &eop, &sop, <answer> &ingress_port, 
&rss_type, <token> &rss_hash, <answer> &csum_not_calc, 
&bytes_written, <token> <answer> &packet_error, 
&vlan_stripped, <token> &checksum, <answer> &vlan, 
<token> &fcoe_fc_crc_ok, <answer> &fcoe_sof, 
&fcoe_enc_error, <token> <answer> &fcoe_eof, 
<token> &udp, &tcp, <answer> &tcp_udp_csum_ok, 
&ipv4_csum_ok, <token> &ipv4, <answer> &ipv6, 
&ipv4_fragment, <token> <answer> &fcs_ok); 
skb_trim(skb, <token> <answer> bytes_written); 
if <token> { <answer> (!fcs_ok) 
FNIC_FCS_DBG(KERN_DEBUG, <token> fnic->fnic_num, <answer> fnic->lport->host, 
<token> error. dropping packet.\n"); <answer> "fcs 
goto <token> <answer> drop; 
if <token> skb)) <answer> (fnic_import_rq_eth_pkt(fnic, 
} <token> { <answer> else 
int fnic_alloc_rq_frame(struct <token> *rq) <answer> vnic_rq 
struct fnic <token> = vnic_dev_priv(rq->vdev); <answer> *fnic 
<token> sk_buff *skb; <answer> struct 
<token> len; <answer> u16 
dma_addr_t <token> <answer> pa; 
int <token> <answer> r; 
len <token> FC_FRAME_HEADROOM + FC_MAX_FRAME + FC_FRAME_TAILROOM; <answer> = 
<token> = dev_alloc_skb(len); <answer> skb 
if <token> { <answer> (!skb) 
FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host, <token> <answer> fnic->fnic_num, 
"Unable to <token> RQ sk_buff\n"); <answer> allocate 
<token> -ENOMEM; <answer> return 
<token> len); <answer> skb_put(skb, 
pa = dma_map_single(&fnic->pdev->dev, skb->data, len, <token> <answer> DMA_FROM_DEVICE); 
if <token> pa)) { <answer> (dma_mapping_error(&fnic->pdev->dev, 
r <token> -ENOMEM; <answer> = 
printk(KERN_ERR "PCI mapping failed <token> error %d\n", r); <answer> with 
<token> free_skb; <answer> goto 
fnic_queue_rq_desc(rq, <token> pa, len); <answer> skb, 
<token> 0; <answer> return 
return <token> <answer> r; 
void <token> vnic_rq *rq, struct vnic_rq_buf *buf) <answer> fnic_free_rq_buf(struct 
<token> fc_frame *fp = buf->os_buf; <answer> struct 
struct fnic *fnic <token> vnic_dev_priv(rq->vdev); <answer> = 
<token> buf->dma_addr, buf->len, <answer> dma_unmap_single(&fnic->pdev->dev, 
buf->os_buf = <token> <answer> NULL; 
void fnic_eth_send(struct fcoe_ctlr *fip, <token> sk_buff *skb) <answer> struct 
struct fnic *fnic <token> fnic_from_ctlr(fip); <answer> = 
struct <token> *wq = &fnic->wq[0]; <answer> vnic_wq 
<token> pa; <answer> dma_addr_t 
struct <token> *eth_hdr; <answer> ethhdr 
struct vlan_ethhdr <token> <answer> *vlan_hdr; 
<token> long flags; <answer> unsigned 
if <token> { <answer> (!fnic->vlan_hw_insert) 
eth_hdr = <token> ethhdr *)skb_mac_header(skb); <answer> (struct 
vlan_hdr <token> skb_push(skb, sizeof(*vlan_hdr) - sizeof(*eth_hdr)); <answer> = 
memcpy(vlan_hdr, eth_hdr, 2 * <token> <answer> ETH_ALEN); 
vlan_hdr->h_vlan_proto <token> htons(ETH_P_8021Q); <answer> = 
<token> = eth_hdr->h_proto; <answer> vlan_hdr->h_vlan_encapsulated_proto 
<token> = htons(fnic->vlan_id); <answer> vlan_hdr->h_vlan_TCI 
if <token> <answer> ((fnic_fc_trace_set_data(fnic->lport->host->host_no, 
FNIC_FC_SEND|0x80, <token> *)eth_hdr, skb->len)) != 0) { <answer> (char 
printk(KERN_ERR <token> ctlr frame trace error!!!"); <answer> "fnic 
<token> else { <answer> } 
<token> ((fnic_fc_trace_set_data(fnic->lport->host->host_no, <answer> if 
FNIC_FC_SEND|0x80, (char *)skb->data, skb->len)) != <token> { <answer> 0) 
printk(KERN_ERR <token> ctlr frame trace error!!!"); <answer> "fnic 
pa = <token> skb->data, skb->len, <answer> dma_map_single(&fnic->pdev->dev, 
if (dma_mapping_error(&fnic->pdev->dev, pa)) <token> <answer> { 
printk(KERN_ERR <token> mapping failed\n"); <answer> "DMA 
goto <token> <answer> free_skb; 
<token> flags); <answer> spin_lock_irqsave(&fnic->wq_lock[0], 
<token> (!vnic_wq_desc_avail(wq)) <answer> if 
<token> irq_restore; <answer> goto 
<token> skb, pa, skb->len, <answer> fnic_queue_wq_eth_desc(wq, 
static <token> fnic_send_frame(struct fnic *fnic, struct fc_frame *fp) <answer> int 
struct vnic_wq *wq <token> &fnic->wq[0]; <answer> = 
<token> sk_buff *skb; <answer> struct 
dma_addr_t <token> <answer> pa; 
struct <token> *eth_hdr; <answer> ethhdr 
struct vlan_ethhdr <token> <answer> *vlan_hdr; 
struct <token> *fcoe_hdr; <answer> fcoe_hdr 
struct <token> *fh; <answer> fc_frame_header 
<token> tot_len, eth_hdr_len; <answer> u32 
<token> ret = 0; <answer> int 
unsigned <token> flags; <answer> long 
fh <token> fc_frame_header_get(fp); <answer> = 
<token> = fp_skb(fp); <answer> skb 
if (unlikely(fh->fh_r_ctl == FC_RCTL_ELS_REQ) <token> <answer> && 
fcoe_ctlr_els_send(&fnic->ctlr, <token> skb)) <answer> fnic->lport, 
return <token> <answer> 0; 
if <token> { <answer> (!fnic->vlan_hw_insert) 
eth_hdr_len = sizeof(*vlan_hdr) + <token> <answer> sizeof(*fcoe_hdr); 
vlan_hdr = <token> eth_hdr_len); <answer> skb_push(skb, 
eth_hdr = (struct <token> *)vlan_hdr; <answer> ethhdr 
<token> = htons(ETH_P_8021Q); <answer> vlan_hdr->h_vlan_proto 
vlan_hdr->h_vlan_encapsulated_proto = <token> <answer> htons(ETH_P_FCOE); 
vlan_hdr->h_vlan_TCI <token> htons(fnic->vlan_id); <answer> = 
fcoe_hdr = (struct fcoe_hdr *)(vlan_hdr <token> 1); <answer> + 
} <token> { <answer> else 
eth_hdr_len <token> sizeof(*eth_hdr) + sizeof(*fcoe_hdr); <answer> = 
eth_hdr <token> skb_push(skb, eth_hdr_len); <answer> = 
<token> = htons(ETH_P_FCOE); <answer> eth_hdr->h_proto 
fcoe_hdr = (struct <token> *)(eth_hdr + 1); <answer> fcoe_hdr 
if <token> <answer> (fnic->ctlr.map_dest) 
<token> fh->fh_d_id); <answer> fc_fcoe_set_mac(eth_hdr->h_dest, 
memcpy(eth_hdr->h_dest, <token> ETH_ALEN); <answer> fnic->ctlr.dest_addr, 
memcpy(eth_hdr->h_source, fnic->data_src_addr, <token> <answer> ETH_ALEN); 
tot_len <token> skb->len; <answer> = 
BUG_ON(tot_len <token> 4); <answer> % 
<token> 0, sizeof(*fcoe_hdr)); <answer> memset(fcoe_hdr, 
fcoe_hdr->fcoe_sof <token> fr_sof(fp); <answer> = 
if <token> <answer> (FC_FCOE_VER) 
<token> FC_FCOE_VER); <answer> FC_FCOE_ENCAPS_VER(fcoe_hdr, 
pa <token> dma_map_single(&fnic->pdev->dev, eth_hdr, tot_len, DMA_TO_DEVICE); <answer> = 
if <token> pa)) { <answer> (dma_mapping_error(&fnic->pdev->dev, 
ret <token> -ENOMEM; <answer> = 
printk(KERN_ERR "DMA map failed <token> error %d\n", ret); <answer> with 
<token> free_skb_on_err; <answer> goto 
<token> ((fnic_fc_trace_set_data(fnic->lport->host->host_no, FNIC_FC_SEND, <answer> if 
(char *)eth_hdr, tot_len)) <token> 0) { <answer> != 
printk(KERN_ERR "fnic ctlr frame <token> error!!!"); <answer> trace 
spin_lock_irqsave(&fnic->wq_lock[0], <token> <answer> flags); 
if (!vnic_wq_desc_avail(wq)) <token> <answer> { 
<token> pa, tot_len, DMA_TO_DEVICE); <answer> dma_unmap_single(&fnic->pdev->dev, 
ret = <token> <answer> -1; 
goto <token> <answer> irq_restore; 
fnic_queue_wq_desc(wq, <token> pa, tot_len, fr_eof(fp), <answer> skb, 
<token> fnic_send(struct fc_lport *lp, struct fc_frame *fp) <answer> int 
struct fnic <token> = lport_priv(lp); <answer> *fnic 
<token> long flags; <answer> unsigned 
<token> (fnic->in_remove) { <answer> if 
return <token> <answer> -1; 
spin_lock_irqsave(&fnic->fnic_lock, <token> <answer> flags); 
if (fnic->state != FNIC_IN_FC_MODE && <token> != FNIC_IN_ETH_MODE) { <answer> fnic->state 
skb_queue_tail(&fnic->tx_queue, <token> <answer> fp_skb(fp)); 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
<token> 0; <answer> return 
spin_unlock_irqrestore(&fnic->fnic_lock, <token> <answer> flags); 
return <token> fp); <answer> fnic_send_frame(fnic, 
<token> fnic_flush_tx(struct work_struct *work) <answer> void 
struct <token> *fnic = container_of(work, struct fnic, flush_work); <answer> fnic 
<token> sk_buff *skb; <answer> struct 
struct fc_frame <token> <answer> *fp; 
<token> ((skb = skb_dequeue(&fnic->tx_queue))) { <answer> while 
fp <token> (struct fc_frame *)skb; <answer> = 
<token> fp); <answer> fnic_send_frame(fnic, 
static void <token> fnic *fnic) <answer> fnic_set_eth_mode(struct 
<token> long flags; <answer> unsigned 
<token> fnic_state old_state; <answer> enum 
<token> ret; <answer> int 
spin_lock_irqsave(&fnic->fnic_lock, <token> <answer> flags); 
<token> = fnic->state; <answer> old_state 
<token> (old_state) { <answer> switch 
case <token> <answer> FNIC_IN_FC_MODE: 
case <token> <answer> FNIC_IN_ETH_TRANS_FC_MODE: 
<token> = FNIC_IN_FC_TRANS_ETH_MODE; <answer> fnic->state 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
<token> = fnic_fw_reset_handler(fnic); <answer> ret 
<token> flags); <answer> spin_lock_irqsave(&fnic->fnic_lock, 
if <token> != FNIC_IN_FC_TRANS_ETH_MODE) <answer> (fnic->state 
goto <token> <answer> again; 
<token> (ret) <answer> if 
fnic->state <token> old_state; <answer> = 
<token> FNIC_IN_FC_TRANS_ETH_MODE: <answer> case 
case <token> <answer> FNIC_IN_ETH_MODE: 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
static <token> fnic_wq_complete_frame_send(struct vnic_wq *wq, <answer> void 
struct <token> *cq_desc, <answer> cq_desc 
struct vnic_wq_buf *buf, void <token> <answer> *opaque) 
struct sk_buff *skb <token> buf->os_buf; <answer> = 
struct fc_frame *fp = <token> fc_frame *)skb; <answer> (struct 
struct fnic *fnic <token> vnic_dev_priv(wq->vdev); <answer> = 
dma_unmap_single(&fnic->pdev->dev, buf->dma_addr, <token> <answer> buf->len, 
buf->os_buf = <token> <answer> NULL; 
static int <token> vnic_dev *vdev, <answer> fnic_wq_cmpl_handler_cont(struct 
struct <token> *cq_desc, u8 type, <answer> cq_desc 
<token> q_number, u16 completed_index, <answer> u16 
<token> *opaque) <answer> void 
struct fnic <token> = vnic_dev_priv(vdev); <answer> *fnic 
unsigned long <token> <answer> flags; 
spin_lock_irqsave(&fnic->wq_lock[q_number], <token> <answer> flags); 
vnic_wq_service(&fnic->wq[q_number], cq_desc, <token> <answer> completed_index, 
<token> NULL); <answer> fnic_wq_complete_frame_send, 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->wq_lock[q_number], 
<token> 0; <answer> return 
int fnic_wq_cmpl_handler(struct <token> *fnic, int work_to_do) <answer> fnic 
<token> int wq_work_done = 0; <answer> unsigned 
unsigned int <token> <answer> i; 
for (i <token> 0; i < fnic->raw_wq_count; i++) { <answer> = 
wq_work_done += <token> <answer> vnic_cq_service(&fnic->cq[fnic->rq_count+i], 
return <token> <answer> wq_work_done; 
<token> fnic_free_wq_buf(struct vnic_wq *wq, struct vnic_wq_buf *buf) <answer> void 
struct fc_frame *fp = <token> <answer> buf->os_buf; 
struct fnic *fnic <token> vnic_dev_priv(wq->vdev); <answer> = 
dma_unmap_single(&fnic->pdev->dev, buf->dma_addr, <token> <answer> buf->len, 
buf->os_buf <token> NULL; <answer> = 
void fnic_fcoe_reset_vlans(struct <token> *fnic) <answer> fnic 
unsigned <token> flags; <answer> long 
struct <token> *vlan; <answer> fcoe_vlan 
struct fcoe_vlan <token> <answer> *next; 
<token> flags); <answer> spin_lock_irqsave(&fnic->vlans_lock, 
<token> (!list_empty(&fnic->vlans)) { <answer> if 
list_for_each_entry_safe(vlan, next, &fnic->vlans, list) <token> <answer> { 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->vlans_lock, 
<token> fnic_handle_fip_timer(struct fnic *fnic) <answer> void 
unsigned <token> flags; <answer> long 
struct fcoe_vlan <token> <answer> *vlan; 
struct fnic_stats *fnic_stats = <token> <answer> &fnic->fnic_stats; 
u64 <token> <answer> sol_time; 
<token> flags); <answer> spin_lock_irqsave(&fnic->fnic_lock, 
<token> (fnic->stop_rx_link_events) { <answer> if 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
spin_unlock_irqrestore(&fnic->fnic_lock, <token> <answer> flags); 
if (fnic->ctlr.mode == <token> <answer> FIP_MODE_NON_FIP) 
<token> flags); <answer> spin_lock_irqsave(&fnic->vlans_lock, 
<token> (list_empty(&fnic->vlans)) { <answer> if 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->vlans_lock, 
<token> fnic->lport->host, fnic->fnic_num, <answer> FNIC_FCS_DBG(KERN_INFO, 
"Dequeue this VLAN ID %d <token> list\n", <answer> from 
vlan = <token> <answer> NULL; 
<token> (list_empty(&fnic->vlans)) { <answer> if 
<token> <linux/init.h> <answer> #include 
<token> <linux/mm.h> <answer> #include 
#include <token> <answer> <asm/cache.h> 
#include <token> <answer> <asm/addrspace.h> 
#include <token> <answer> <asm/processor.h> 
<token> <asm/cacheflush.h> <answer> #include 
<token> <asm/io.h> <answer> #include 
<token> MAX_OCACHE_PAGES 32 <answer> #define 
#define MAX_ICACHE_PAGES <token> <answer> 32 
#ifdef <token> <answer> CONFIG_CACHE_WRITEBACK 
static void sh2a_flush_oc_line(unsigned <token> v, int way) <answer> long 
unsigned long addr = (v & 0x000007f0) | (way <token> 11); <answer> << 
<token> long data; <answer> unsigned 
<token> = __raw_readl(CACHE_OC_ADDRESS_ARRAY | addr); <answer> data 
<token> ((data & CACHE_PHYSADDR_MASK) == (v & CACHE_PHYSADDR_MASK)) { <answer> if 
data &= <token> <answer> ~SH_CACHE_UPDATED; 
__raw_writel(data, CACHE_OC_ADDRESS_ARRAY <token> addr); <answer> | 
static void sh2a_invalidate_line(unsigned long cache_addr, <token> long v) <answer> unsigned 
static void sh2a__flush_wback_region(void *start, int <token> <answer> size) 
<token> CONFIG_CACHE_WRITEBACK <answer> #ifdef 
unsigned long <token> <answer> v; 
unsigned <token> begin, end; <answer> long 
<token> long flags; <answer> unsigned 
int <token> <answer> nr_ways; 
begin = <token> long)start & ~(L1_CACHE_BYTES-1); <answer> (unsigned 
end = ((unsigned long)start + size + <token> <answer> L1_CACHE_BYTES-1) 
& <token> <answer> ~(L1_CACHE_BYTES-1); 
nr_ways <token> current_cpu_data.dcache.ways; <answer> = 
static <token> sh2a__flush_purge_region(void *start, int size) <answer> void 
unsigned long <token> <answer> v; 
<token> long begin, end; <answer> unsigned 
unsigned long <token> <answer> flags; 
begin <token> (unsigned long)start & ~(L1_CACHE_BYTES-1); <answer> = 
end = <token> long)start + size + L1_CACHE_BYTES-1) <answer> ((unsigned 
<token> ~(L1_CACHE_BYTES-1); <answer> & 
for (v = <token> v < end; v+=L1_CACHE_BYTES) { <answer> begin; 
<token> CONFIG_CACHE_WRITEBACK <answer> #ifdef 
int <token> <answer> way; 
<token> nr_ways = current_cpu_data.dcache.ways; <answer> int 
for (way = 0; way <token> nr_ways; way++) <answer> < 
sh2a_flush_oc_line(v, <token> <answer> way); 
<token> v); <answer> sh2a_invalidate_line(CACHE_OC_ADDRESS_ARRAY, 
static void <token> *start, int size) <answer> sh2a__flush_invalidate_region(void 
unsigned long <token> <answer> v; 
unsigned <token> begin, end; <answer> long 
unsigned <token> flags; <answer> long 
begin <token> (unsigned long)start & ~(L1_CACHE_BYTES-1); <answer> = 
<token> = ((unsigned long)start + size + L1_CACHE_BYTES-1) <answer> end 
<token> ~(L1_CACHE_BYTES-1); <answer> & 
static void <token> *args) <answer> sh2a_flush_icache_range(void 
struct flusher_data <token> = args; <answer> *data 
unsigned <token> start, end; <answer> long 
<token> long v; <answer> unsigned 
unsigned <token> flags; <answer> long 
start = data->addr1 <token> ~(L1_CACHE_BYTES-1); <answer> & 
end = (data->addr2 + <token> & ~(L1_CACHE_BYTES-1); <answer> L1_CACHE_BYTES-1) 
<token> CONFIG_CACHE_WRITEBACK <answer> #ifdef 
sh2a__flush_wback_region((void *)start, <token> <answer> end-start); 
<token> <linux/errno.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/ioport.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/serial_8250.h> <answer> #include 
<token> <cobalt.h> <answer> #include 
<token> <irq.h> <answer> #include 
static struct resource cobalt_uart_resource[] <token> = { <answer> __initdata 
.start <token> 0x1c800000, <answer> = 
<token> = 0x1c800007, <answer> .end 
.flags <token> IORESOURCE_MEM, <answer> = 
<token> = SERIAL_IRQ, <answer> .start 
<token> = SERIAL_IRQ, <answer> .end 
<token> = IORESOURCE_IRQ, <answer> .flags 
<token> struct plat_serial8250_port cobalt_serial8250_port[] = { <answer> static 
.irq = <token> <answer> SERIAL_IRQ, 
.uartclk <token> 18432000, <answer> = 
.iotype <token> UPIO_MEM, <answer> = 
.flags = <token> | UPF_BOOT_AUTOCONF | UPF_SKIP_TEST, <answer> UPF_IOREMAP 
<token> = 0x1c800000, <answer> .mapbase 
<token> __init int cobalt_uart_add(void) <answer> static 
struct <token> *pdev; <answer> platform_device 
<token> retval; <answer> int 
if (cobalt_board_id <token> COBALT_BRD_ID_QUBE1) <answer> == 
<token> 0; <answer> return 
pdev <token> platform_device_alloc("serial8250", -1); <answer> = 
<token> (!pdev) <answer> if 
<token> -ENOMEM; <answer> return 
pdev->id = <token> <answer> PLAT8250_DEV_PLATFORM; 
pdev->dev.platform_data = <token> <answer> cobalt_serial8250_port; 
retval <token> platform_device_add_resources(pdev, cobalt_uart_resource, ARRAY_SIZE(cobalt_uart_resource)); <answer> = 
<token> (retval) <answer> if 
goto <token> <answer> err_free_device; 
<token> = platform_device_add(pdev); <answer> retval 
if <token> <answer> (retval) 
goto <token> <answer> err_free_device; 
return <token> <answer> 0; 
<token> retval; <answer> return 
<token> <linux/acpi.h> <answer> #include 
<token> <linux/device.h> <answer> #include 
#include <token> <answer> <linux/etherdevice.h> 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/netdevice.h> 
#include <token> <answer> <linux/pci.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/if_vlan.h> <answer> #include 
<token> <linux/crash_dump.h> <answer> #include 
<token> <net/ipv6.h> <answer> #include 
<token> <net/rtnetlink.h> <answer> #include 
<token> "hclge_cmd.h" <answer> #include 
<token> "hclge_dcb.h" <answer> #include 
<token> "hclge_main.h" <answer> #include 
#include <token> <answer> "hclge_mbx.h" 
<token> "hclge_mdio.h" <answer> #include 
<token> "hclge_regs.h" <answer> #include 
#include <token> <answer> "hclge_tm.h" 
#include <token> <answer> "hclge_err.h" 
<token> "hnae3.h" <answer> #include 
<token> "hclge_devlink.h" <answer> #include 
<token> "hclge_comm_cmd.h" <answer> #include 
#define HCLGE_NAME <token> <answer> "hclge" 
#define HCLGE_BUF_SIZE_UNIT <token> <answer> 256U 
#define <token> 2 <answer> HCLGE_BUF_MUL_BY 
#define <token> 2 <answer> HCLGE_BUF_DIV_BY 
<token> NEED_RESERVE_TC_NUM 2 <answer> #define 
#define BUF_MAX_PERCENT <token> <answer> 100 
#define BUF_RESERVE_PERCENT <token> <answer> 90 
<token> HCLGE_RESET_MAX_FAIL_CNT 5 <answer> #define 
#define HCLGE_RESET_SYNC_TIME <token> <answer> 100 
<token> HCLGE_PF_RESET_SYNC_TIME 20 <answer> #define 
<token> HCLGE_PF_RESET_SYNC_CNT 1500 <answer> #define 
<token> HCLGE_LINK_STATUS_MS 10 <answer> #define 
static int hclge_set_mac_mtu(struct hclge_dev <token> int new_mps); <answer> *hdev, 
<token> int hclge_init_vlan_config(struct hclge_dev *hdev); <answer> static 
<token> void hclge_sync_vlan_filter(struct hclge_dev *hdev); <answer> static 
static int hclge_reset_ae_dev(struct <token> *ae_dev); <answer> hnae3_ae_dev 
<token> bool hclge_get_hw_reset_stat(struct hnae3_handle *handle); <answer> static 
<token> void hclge_rfs_filter_expire(struct hclge_dev *hdev); <answer> static 
static int hclge_clear_arfs_rules(struct hclge_dev <token> <answer> *hdev); 
<token> enum hnae3_reset_type hclge_get_reset_level(struct hnae3_ae_dev *ae_dev, <answer> static 
unsigned <token> *addr); <answer> long 
static int <token> hclge_dev *hdev); <answer> hclge_set_default_loopback(struct 
static <token> hclge_sync_mac_table(struct hclge_dev *hdev); <answer> void 
static void <token> hclge_dev *hdev); <answer> hclge_restore_hw_table(struct 
static void hclge_sync_promisc_mode(struct <token> *hdev); <answer> hclge_dev 
static void hclge_sync_fd_table(struct hclge_dev <token> <answer> *hdev); 
static void hclge_update_fec_stats(struct hclge_dev <token> <answer> *hdev); 
<token> int hclge_mac_link_status_wait(struct hclge_dev *hdev, int link_ret, <answer> static 
<token> wait_cnt); <answer> int 
<token> int hclge_update_port_info(struct hclge_dev *hdev); <answer> static 
static struct hnae3_ae_algo <token> <answer> ae_algo; 
static struct <token> *hclge_wq; <answer> workqueue_struct 
static const struct pci_device_id <token> = { <answer> ae_algo_pci_tbl[] 
{PCI_VDEVICE(HUAWEI, <token> 0}, <answer> HNAE3_DEV_ID_GE), 
{PCI_VDEVICE(HUAWEI, <token> 0}, <answer> HNAE3_DEV_ID_25GE), 
{PCI_VDEVICE(HUAWEI, HNAE3_DEV_ID_25GE_RDMA), <token> <answer> 0}, 
{PCI_VDEVICE(HUAWEI, HNAE3_DEV_ID_25GE_RDMA_MACSEC), <token> <answer> 0}, 
{PCI_VDEVICE(HUAWEI, <token> 0}, <answer> HNAE3_DEV_ID_50GE_RDMA), 
<token> HNAE3_DEV_ID_50GE_RDMA_MACSEC), 0}, <answer> {PCI_VDEVICE(HUAWEI, 
{PCI_VDEVICE(HUAWEI, HNAE3_DEV_ID_100G_RDMA_MACSEC), <token> <answer> 0}, 
{PCI_VDEVICE(HUAWEI, <token> 0}, <answer> HNAE3_DEV_ID_200G_RDMA), 
int hclge_cmd_send(struct hclge_hw *hw, struct <token> *desc, int num) <answer> hclge_desc 
return hclge_comm_cmd_send(&hw->hw, desc, <token> <answer> num); 
static int <token> hclge_dev *hdev) <answer> hclge_mac_update_stats_defective(struct 
#define HCLGE_MAC_CMD_NUM <token> <answer> 21 
u64 *data <token> (u64 *)(&hdev->mac_stats); <answer> = 
struct hclge_desc <token> <answer> desc[HCLGE_MAC_CMD_NUM]; 
<token> *desc_data; <answer> __le64 
u32 <token> <answer> data_size; 
int <token> <answer> ret; 
<token> i; <answer> u32 
hclge_cmd_setup_basic_desc(&desc[0], <token> true); <answer> HCLGE_OPC_STATS_MAC, 
<token> = hclge_cmd_send(&hdev->hw, desc, HCLGE_MAC_CMD_NUM); <answer> ret 
if (ret) <token> <answer> { 
"Get <token> pkt stats fail, status = %d.\n", ret); <answer> MAC 
return <token> <answer> ret; 
*data += <token> <answer> le64_to_cpu(*desc_data); 
<token> 0; <answer> return 
static <token> hclge_mac_update_stats_complete(struct hclge_dev *hdev) <answer> int 
<token> HCLGE_REG_NUM_PER_DESC 4 <answer> #define 
u32 reg_num <token> hdev->ae_dev->dev_specs.mac_stats_num; <answer> = 
u64 *data <token> (u64 *)(&hdev->mac_stats); <answer> = 
<token> hclge_desc *desc; <answer> struct 
__le64 <token> <answer> *desc_data; 
<token> data_size; <answer> u32 
<token> desc_num; <answer> u32 
int <token> <answer> ret; 
<token> i; <answer> u32 
desc = kcalloc(desc_num, <token> hclge_desc), GFP_ATOMIC); <answer> sizeof(struct 
if <token> <answer> (!desc) 
return <token> <answer> -ENOMEM; 
hclge_cmd_setup_basic_desc(&desc[0], <token> true); <answer> HCLGE_OPC_STATS_MAC_ALL, 
ret = <token> desc, desc_num); <answer> hclge_cmd_send(&hdev->hw, 
if (ret) <token> <answer> { 
<token> ret; <answer> return 
<token> = min_t(u32, sizeof(hdev->mac_stats) / sizeof(u64), reg_num); <answer> data_size 
desc_data <token> (__le64 *)(&desc[0].data[0]); <answer> = 
for (i = <token> i < data_size; i++) { <answer> 0; 
<token> += le64_to_cpu(*desc_data); <answer> *data 
return <token> <answer> 0; 
<token> int hclge_mac_query_reg_num(struct hclge_dev *hdev, u32 *reg_num) <answer> static 
struct hclge_desc <token> <answer> desc; 
<token> ret; <answer> int 
if (hdev->ae_dev->dev_version == HNAE3_DEVICE_VERSION_V2) <token> <answer> { 
*reg_num <token> HCLGE_MAC_STATS_MAX_NUM_V1; <answer> = 
<token> 0; <answer> return 
hclge_cmd_setup_basic_desc(&desc, <token> true); <answer> HCLGE_OPC_QUERY_MAC_REG_NUM, 
ret = hclge_cmd_send(&hdev->hw, &desc, <token> <answer> 1); 
if (ret) <token> <answer> { 
"failed to query mac statistic <token> number, ret = %d\n", <answer> reg 
<token> ret; <answer> return 
*reg_num <token> le32_to_cpu(desc.data[0]); <answer> = 
if (*reg_num <token> 0) { <answer> == 
<token> statistic reg number is invalid!\n"); <answer> "mac 
<token> -ENODATA; <answer> return 
return <token> <answer> 0; 
int hclge_mac_update_stats(struct hclge_dev <token> <answer> *hdev) 
if <token> == ETH_SS_TEST) { <answer> (stringset 
hdev->num_msi = hdev->num_nic_msi <token> hdev->num_roce_msi; <answer> + 
} else <token> <answer> { 
hdev->num_msi = <token> <answer> hdev->num_nic_msi; 
return <token> <answer> 0; 
<token> int hclge_parse_speed(u8 speed_cmd, u32 *speed) <answer> static 
switch <token> { <answer> (speed_cmd) 
<token> HCLGE_FW_MAC_SPEED_10M: <answer> case 
*speed = <token> <answer> HCLGE_MAC_SPEED_10M; 
<token> HCLGE_FW_MAC_SPEED_100M: <answer> case 
<token> = HCLGE_MAC_SPEED_100M; <answer> *speed 
<token> HCLGE_FW_MAC_SPEED_1G: <answer> case 
*speed <token> HCLGE_MAC_SPEED_1G; <answer> = 
<token> HCLGE_FW_MAC_SPEED_10G: <answer> case 
*speed <token> HCLGE_MAC_SPEED_10G; <answer> = 
case <token> <answer> HCLGE_FW_MAC_SPEED_25G: 
*speed <token> HCLGE_MAC_SPEED_25G; <answer> = 
<token> HCLGE_FW_MAC_SPEED_40G: <answer> case 
*speed <token> HCLGE_MAC_SPEED_40G; <answer> = 
<token> HCLGE_FW_MAC_SPEED_50G: <answer> case 
<token> = HCLGE_MAC_SPEED_50G; <answer> *speed 
<token> HCLGE_FW_MAC_SPEED_100G: <answer> case 
<token> = HCLGE_MAC_SPEED_100G; <answer> *speed 
<token> HCLGE_FW_MAC_SPEED_200G: <answer> case 
*speed = <token> <answer> HCLGE_MAC_SPEED_200G; 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
static const struct hclge_speed_bit_map speed_bit_map[] <token> { <answer> = 
<token> HCLGE_SUPPORT_10M_BIT}, <answer> {HCLGE_MAC_SPEED_10M, 
{HCLGE_MAC_SPEED_100M, <token> <answer> HCLGE_SUPPORT_100M_BIT}, 
<token> HCLGE_SUPPORT_1G_BIT}, <answer> {HCLGE_MAC_SPEED_1G, 
{HCLGE_MAC_SPEED_10G, <token> <answer> HCLGE_SUPPORT_10G_BIT}, 
{HCLGE_MAC_SPEED_25G, <token> <answer> HCLGE_SUPPORT_25G_BIT}, 
<token> HCLGE_SUPPORT_40G_BIT}, <answer> {HCLGE_MAC_SPEED_40G, 
<token> HCLGE_SUPPORT_50G_BITS}, <answer> {HCLGE_MAC_SPEED_50G, 
{HCLGE_MAC_SPEED_100G, <token> <answer> HCLGE_SUPPORT_100G_BITS}, 
{HCLGE_MAC_SPEED_200G, <token> <answer> HCLGE_SUPPORT_200G_BITS}, 
static int hclge_get_speed_bit(u32 <token> u32 *speed_bit) <answer> speed, 
u16 <token> <answer> i; 
for (i = 0; i < <token> i++) { <answer> ARRAY_SIZE(speed_bit_map); 
if (speed == <token> { <answer> speed_bit_map[i].speed) 
<token> = speed_bit_map[i].speed_bit; <answer> *speed_bit 
<token> 0; <answer> return 
return <token> <answer> -EINVAL; 
static int <token> hnae3_handle *handle, u32 speed) <answer> hclge_check_port_speed(struct 
struct hclge_vport *vport <token> hclge_get_vport(handle); <answer> = 
struct hclge_dev *hdev <token> vport->back; <answer> = 
<token> speed_ability = hdev->hw.mac.speed_ability; <answer> u32 
u32 speed_bit <token> 0; <answer> = 
int <token> <answer> ret; 
<token> = hclge_get_speed_bit(speed, &speed_bit); <answer> ret 
<token> (ret) <answer> if 
return <token> <answer> ret; 
if (speed_bit & <token> <answer> speed_ability) 
return <token> <answer> 0; 
return <token> <answer> -EINVAL; 
static void hclge_update_fec_support(struct hclge_mac <token> <answer> *mac) 
<token> mac->supported); <answer> linkmode_clear_bit(ETHTOOL_LINK_MODE_FEC_BASER_BIT, 
<token> mac->supported); <answer> linkmode_clear_bit(ETHTOOL_LINK_MODE_FEC_RS_BIT, 
linkmode_clear_bit(ETHTOOL_LINK_MODE_FEC_LLRS_BIT, <token> <answer> mac->supported); 
linkmode_clear_bit(ETHTOOL_LINK_MODE_FEC_NONE_BIT, <token> <answer> mac->supported); 
if (mac->fec_ability <token> BIT(HNAE3_FEC_BASER)) <answer> & 
if (mac->fec_ability & <token> <answer> BIT(HNAE3_FEC_RS)) 
if <token> & BIT(HNAE3_FEC_LLRS)) <answer> (mac->fec_ability 
if (mac->fec_ability <token> BIT(HNAE3_FEC_NONE)) <answer> & 
static const struct hclge_link_mode_bmap hclge_sr_link_mode_bmap[] = <token> <answer> { 
{HCLGE_SUPPORT_10G_BIT, <token> <answer> ETHTOOL_LINK_MODE_10000baseSR_Full_BIT}, 
{HCLGE_SUPPORT_25G_BIT, <token> <answer> ETHTOOL_LINK_MODE_25000baseSR_Full_BIT}, 
{HCLGE_SUPPORT_40G_BIT, <token> <answer> ETHTOOL_LINK_MODE_40000baseSR4_Full_BIT}, 
{HCLGE_SUPPORT_50G_R2_BIT, <token> <answer> ETHTOOL_LINK_MODE_50000baseSR2_Full_BIT}, 
{HCLGE_SUPPORT_50G_R1_BIT, <token> <answer> ETHTOOL_LINK_MODE_50000baseSR_Full_BIT}, 
<token> ETHTOOL_LINK_MODE_100000baseSR4_Full_BIT}, <answer> {HCLGE_SUPPORT_100G_R4_BIT, 
<token> ETHTOOL_LINK_MODE_100000baseSR2_Full_BIT}, <answer> {HCLGE_SUPPORT_100G_R2_BIT, 
{HCLGE_SUPPORT_200G_R4_BIT, <token> <answer> ETHTOOL_LINK_MODE_200000baseSR4_Full_BIT}, 
static const struct <token> hclge_lr_link_mode_bmap[] = { <answer> hclge_link_mode_bmap 
<token> ETHTOOL_LINK_MODE_10000baseLR_Full_BIT}, <answer> {HCLGE_SUPPORT_10G_BIT, 
<token> ETHTOOL_LINK_MODE_40000baseLR4_Full_BIT}, <answer> {HCLGE_SUPPORT_40G_BIT, 
<token> ETHTOOL_LINK_MODE_50000baseLR_ER_FR_Full_BIT}, <answer> {HCLGE_SUPPORT_50G_R1_BIT, 
static const struct hclge_link_mode_bmap hclge_cr_link_mode_bmap[] <token> { <answer> = 
<token> ETHTOOL_LINK_MODE_10000baseCR_Full_BIT}, <answer> {HCLGE_SUPPORT_10G_BIT, 
<token> ETHTOOL_LINK_MODE_25000baseCR_Full_BIT}, <answer> {HCLGE_SUPPORT_25G_BIT, 
<token> ETHTOOL_LINK_MODE_40000baseCR4_Full_BIT}, <answer> {HCLGE_SUPPORT_40G_BIT, 
{HCLGE_SUPPORT_50G_R2_BIT, <token> <answer> ETHTOOL_LINK_MODE_50000baseCR2_Full_BIT}, 
<token> ETHTOOL_LINK_MODE_50000baseCR_Full_BIT}, <answer> {HCLGE_SUPPORT_50G_R1_BIT, 
{HCLGE_SUPPORT_100G_R4_BIT, <token> <answer> ETHTOOL_LINK_MODE_100000baseCR4_Full_BIT}, 
{HCLGE_SUPPORT_100G_R2_BIT, <token> <answer> ETHTOOL_LINK_MODE_100000baseCR2_Full_BIT}, 
{HCLGE_SUPPORT_200G_R4_BIT, <token> <answer> ETHTOOL_LINK_MODE_200000baseCR4_Full_BIT}, 
static const struct hclge_link_mode_bmap hclge_kr_link_mode_bmap[] = <token> <answer> { 
<token> ETHTOOL_LINK_MODE_1000baseKX_Full_BIT}, <answer> {HCLGE_SUPPORT_1G_BIT, 
<token> ETHTOOL_LINK_MODE_10000baseKR_Full_BIT}, <answer> {HCLGE_SUPPORT_10G_BIT, 
<token> ETHTOOL_LINK_MODE_25000baseKR_Full_BIT}, <answer> {HCLGE_SUPPORT_25G_BIT, 
{HCLGE_SUPPORT_40G_BIT, <token> <answer> ETHTOOL_LINK_MODE_40000baseKR4_Full_BIT}, 
{HCLGE_SUPPORT_50G_R2_BIT, <token> <answer> ETHTOOL_LINK_MODE_50000baseKR2_Full_BIT}, 
{HCLGE_SUPPORT_50G_R1_BIT, <token> <answer> ETHTOOL_LINK_MODE_50000baseKR_Full_BIT}, 
<token> ETHTOOL_LINK_MODE_100000baseKR4_Full_BIT}, <answer> {HCLGE_SUPPORT_100G_R4_BIT, 
{HCLGE_SUPPORT_100G_R2_BIT, <token> <answer> ETHTOOL_LINK_MODE_100000baseKR2_Full_BIT}, 
{HCLGE_SUPPORT_200G_R4_BIT, <token> <answer> ETHTOOL_LINK_MODE_200000baseKR4_Full_BIT}, 
static void hclge_convert_setting_sr(u16 <token> <answer> speed_ability, 
<token> long *link_mode) <answer> unsigned 
<token> i; <answer> int 
for (i = 0; i < <token> i++) { <answer> ARRAY_SIZE(hclge_sr_link_mode_bmap); 
if <token> & hclge_sr_link_mode_bmap[i].support_bit) <answer> (speed_ability 
static void <token> speed_ability, <answer> hclge_convert_setting_lr(u16 
unsigned long <token> <answer> *link_mode) 
int <token> <answer> i; 
for (i = 0; i <token> ARRAY_SIZE(hclge_lr_link_mode_bmap); i++) { <answer> < 
if <token> & hclge_lr_link_mode_bmap[i].support_bit) <answer> (speed_ability 
static void <token> speed_ability, <answer> hclge_convert_setting_cr(u16 
<token> long *link_mode) <answer> unsigned 
int <token> <answer> i; 
for <token> = 0; i < ARRAY_SIZE(hclge_cr_link_mode_bmap); i++) { <answer> (i 
if (speed_ability <token> hclge_cr_link_mode_bmap[i].support_bit) <answer> & 
static <token> hclge_convert_setting_kr(u16 speed_ability, <answer> void 
unsigned long <token> <answer> *link_mode) 
int <token> <answer> i; 
for (i = 0; i < ARRAY_SIZE(hclge_kr_link_mode_bmap); i++) <token> <answer> { 
if (speed_ability <token> hclge_kr_link_mode_bmap[i].support_bit) <answer> & 
static <token> hclge_convert_setting_fec(struct hclge_mac *mac) <answer> void 
cfg->pf_rss_size_max = <token> ? <answer> cfg->pf_rss_size_max 
1U << cfg->pf_rss_size_max <token> <answer> : 
<token> = hnae3_get_field(__le32_to_cpu(req->param[2]), <answer> cfg->tx_spare_buf_size 
cfg->tx_spare_buf_size <token> HCLGE_TX_SPARE_SIZE_UNIT; <answer> *= 
static int hclge_get_cfg(struct hclge_dev <token> struct hclge_cfg *hcfg) <answer> *hdev, 
struct <token> desc[HCLGE_PF_CFG_DESC_NUM]; <answer> hclge_desc 
struct hclge_cfg_param_cmd <token> <answer> *req; 
<token> int i; <answer> unsigned 
int <token> <answer> ret; 
for <token> = 0; i < HCLGE_PF_CFG_DESC_NUM; i++) { <answer> (i 
<token> offset = 0; <answer> u32 
req = (struct <token> *)desc[i].data; <answer> hclge_cfg_param_cmd 
<token> HCLGE_OPC_GET_CFG_PARAM, <answer> hclge_cmd_setup_basic_desc(&desc[i], 
hnae3_set_field(offset, <token> <answer> HCLGE_CFG_OFFSET_M, 
HCLGE_CFG_OFFSET_S, i * <token> <answer> HCLGE_CFG_RD_LEN_BYTES); 
if (hdev->ae_dev->dev_version < HNAE3_DEVICE_VERSION_V3) <token> <answer> { 
return <token> <answer> 0; 
for (i = <token> i < HCLGE_QUERY_DEV_SPECS_BD_NUM - 1; i++) { <answer> 0; 
<token> HCLGE_OPC_QUERY_DEV_SPECS, <answer> hclge_cmd_setup_basic_desc(&desc[i], 
<token> |= cpu_to_le16(HCLGE_COMM_CMD_FLAG_NEXT); <answer> desc[i].flag 
<token> HCLGE_OPC_QUERY_DEV_SPECS, true); <answer> hclge_cmd_setup_basic_desc(&desc[i], 
<token> = hclge_cmd_send(&hdev->hw, desc, HCLGE_QUERY_DEV_SPECS_BD_NUM); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
hclge_parse_dev_specs(hdev, <token> <answer> desc); 
<token> 0; <answer> return 
static <token> hclge_get_cap(struct hclge_dev *hdev) <answer> int 
<token> ret; <answer> int 
ret = <token> <answer> hclge_query_function_status(hdev); 
<token> (ret) { <answer> if 
"query function status <token> %d.\n", ret); <answer> error 
return <token> <answer> ret; 
if (i <token> HCLGE_TQP_MAX_SIZE_DEV_V2) <answer> < 
tqp->q.io_base = hdev->hw.hw.io_base <token> <answer> + 
<token> + <answer> HCLGE_TQP_REG_OFFSET 
i <token> HCLGE_TQP_REG_SIZE; <answer> * 
tqp->q.io_base = hdev->hw.hw.io_base <token> <answer> + 
<token> + <answer> HCLGE_TQP_REG_OFFSET 
HCLGE_TQP_EXT_REG_OFFSET <token> <answer> + 
<token> - HCLGE_TQP_MAX_SIZE_DEV_V2) * <answer> (i 
if <token> ae_dev->caps)) <answer> (test_bit(HNAE3_DEV_SUPPORT_TX_PUSH_B, 
<token> = hdev->hw.hw.mem_base + <answer> tqp->q.mem_base 
<token> i); <answer> HCLGE_TQP_MEM_OFFSET(hdev, 
return <token> <answer> 0; 
<token> int hclge_map_tqps_to_func(struct hclge_dev *hdev, u16 func_id, <answer> static 
u16 <token> u16 tqp_vid, bool is_pf) <answer> tqp_pid, 
<token> hclge_tqp_map_cmd *req; <answer> struct 
<token> hclge_desc desc; <answer> struct 
<token> ret; <answer> int 
<token> HCLGE_OPC_SET_TQP_MAP, false); <answer> hclge_cmd_setup_basic_desc(&desc, 
req = (struct hclge_tqp_map_cmd <token> <answer> *)desc.data; 
req->tqp_id = <token> <answer> cpu_to_le16(tqp_pid); 
<token> = func_id; <answer> req->tqp_vf 
<token> = 1U << HCLGE_TQP_MAP_EN_B; <answer> req->tqp_flag 
<token> (!is_pf) <answer> if 
req->tqp_flag |= 1U <token> HCLGE_TQP_MAP_TYPE_B; <answer> << 
req->tqp_vid = <token> <answer> cpu_to_le16(tqp_vid); 
ret <token> hclge_cmd_send(&hdev->hw, &desc, 1); <answer> = 
<token> (ret) <answer> if 
<token> "TQP map failed %d.\n", ret); <answer> dev_err(&hdev->pdev->dev, 
<token> ret; <answer> return 
static int hclge_assign_tqp(struct hclge_vport <token> u16 num_tqps) <answer> *vport, 
struct hnae3_knic_private_info *kinfo <token> &vport->nic.kinfo; <answer> = 
struct <token> *hdev = vport->back; <answer> hclge_dev 
int <token> alloced; <answer> i, 
<token> (i = 0, alloced = 0; i < hdev->num_tqps && <answer> for 
<token> < num_tqps; i++) { <answer> alloced 
if <token> { <answer> (!hdev->htqp[i].alloced) 
<token> = &vport->nic; <answer> hdev->htqp[i].q.handle 
hdev->htqp[i].q.tqp_index = <token> <answer> alloced; 
hdev->htqp[i].q.tx_desc_num <token> kinfo->num_tx_desc; <answer> = 
hdev->htqp[i].q.rx_desc_num = <token> <answer> kinfo->num_rx_desc; 
kinfo->tqp[alloced] <token> &hdev->htqp[i].q; <answer> = 
hdev->htqp[i].alloced <token> true; <answer> = 
vport->alloc_tqps <token> alloced; <answer> = 
<token> = min_t(u16, hdev->pf_rss_size_max, <answer> kinfo->rss_size 
vport->alloc_tqps / <token> <answer> hdev->tm_info.num_tc); 
static int <token> hclge_dev *hdev, <answer> hclge_rx_buffer_calc(struct 
<token> hclge_pkt_buf_alloc *buf_alloc) <answer> struct 
if (mac->media_type == <token> && <answer> HNAE3_MEDIA_TYPE_BACKPLANE 
mac->module_type <token> HNAE3_MODULE_TYPE_UNKNOWN) <answer> == 
mac->module_type = <token> <answer> HNAE3_MODULE_TYPE_KR; 
else if (mac->media_type <token> HNAE3_MEDIA_TYPE_COPPER) <answer> == 
mac->module_type <token> HNAE3_MODULE_TYPE_TP; <answer> = 
if (mac->support_autoneg) <token> <answer> { 
<token> mac->supported); <answer> linkmode_set_bit(ETHTOOL_LINK_MODE_Autoneg_BIT, 
<token> mac->supported); <answer> linkmode_copy(mac->advertising, 
} <token> { <answer> else 
static int hclge_get_sfp_speed(struct hclge_dev *hdev, u32 <token> <answer> *speed) 
struct <token> *resp; <answer> hclge_sfp_info_cmd 
<token> hclge_desc desc; <answer> struct 
int <token> <answer> ret; 
hclge_cmd_setup_basic_desc(&desc, <token> true); <answer> HCLGE_OPC_GET_SFP_INFO, 
resp = (struct <token> *)desc.data; <answer> hclge_sfp_info_cmd 
ret = hclge_cmd_send(&hdev->hw, &desc, <token> <answer> 1); 
if (ret == <token> { <answer> -EOPNOTSUPP) 
"IMP do not support <token> SFP speed %d\n", ret); <answer> get 
<token> ret; <answer> return 
} else if (ret) <token> <answer> { 
<token> "get sfp speed failed %d\n", ret); <answer> dev_err(&hdev->pdev->dev, 
return <token> <answer> ret; 
<token> = le32_to_cpu(resp->speed); <answer> *speed 
<token> 0; <answer> return 
static <token> hclge_get_sfp_info(struct hclge_dev *hdev, struct hclge_mac *mac) <answer> int 
struct <token> *resp; <answer> hclge_sfp_info_cmd 
struct <token> desc; <answer> hclge_desc 
int <token> <answer> ret; 
<token> HCLGE_OPC_GET_SFP_INFO, true); <answer> hclge_cmd_setup_basic_desc(&desc, 
resp = (struct <token> *)desc.data; <answer> hclge_sfp_info_cmd 
resp->query_type = <token> <answer> QUERY_ACTIVE_SPEED; 
ret = <token> &desc, 1); <answer> hclge_cmd_send(&hdev->hw, 
if (ret == -EOPNOTSUPP) <token> <answer> { 
"IMP does not <token> get SFP info %d\n", ret); <answer> support 
return <token> <answer> ret; 
<token> else if (ret) { <answer> } 
dev_err(&hdev->pdev->dev, "get sfp info failed <token> ret); <answer> %d\n", 
return <token> <answer> ret; 
<token> (!le32_to_cpu(resp->speed)) <answer> if 
<token> 0; <answer> return 
<token> = le32_to_cpu(resp->speed); <answer> mac->speed 
if <token> { <answer> (resp->speed_ability) 
<token> = le32_to_cpu(resp->module_type); <answer> mac->module_type 
<token> = le32_to_cpu(resp->speed_ability); <answer> mac->speed_ability 
mac->autoneg = <token> <answer> resp->autoneg; 
mac->support_autoneg <token> resp->autoneg_ability; <answer> = 
<token> = QUERY_ACTIVE_SPEED; <answer> mac->speed_type 
mac->lane_num <token> resp->lane_num; <answer> = 
<token> (!resp->active_fec) <answer> if 
mac->fec_mode <token> 0; <answer> = 
<token> = BIT(resp->active_fec); <answer> mac->fec_mode 
mac->fec_ability <token> resp->fec_ability; <answer> = 
} else <token> <answer> { 
mac->speed_type <token> QUERY_SFP_SPEED; <answer> = 
return <token> <answer> 0; 
<token> int hclge_get_phy_link_ksettings(struct hnae3_handle *handle, <answer> static 
struct ethtool_link_ksettings <token> <answer> *cmd) 
struct <token> desc[HCLGE_PHY_LINK_SETTING_BD_NUM]; <answer> hclge_desc 
struct hclge_vport *vport <token> hclge_get_vport(handle); <answer> = 
<token> hclge_phy_link_ksetting_0_cmd *req0; <answer> struct 
struct <token> *req1; <answer> hclge_phy_link_ksetting_1_cmd 
u32 supported, advertising, <token> <answer> lp_advertising; 
struct hclge_dev <token> = vport->back; <answer> *hdev 
<token> ret; <answer> int 
<token> HCLGE_OPC_PHY_LINK_KSETTING, <answer> hclge_cmd_setup_basic_desc(&desc[0], 
<token> |= cpu_to_le16(HCLGE_COMM_CMD_FLAG_NEXT); <answer> desc[0].flag 
<token> HCLGE_OPC_PHY_LINK_KSETTING, <answer> hclge_cmd_setup_basic_desc(&desc[1], 
<token> = hclge_cmd_send(&hdev->hw, desc, HCLGE_PHY_LINK_SETTING_BD_NUM); <answer> ret 
if <token> { <answer> (ret) 
"failed <token> get phy link ksetting, ret = %d.\n", ret); <answer> to 
return <token> <answer> ret; 
req0 = <token> hclge_phy_link_ksetting_0_cmd *)desc[0].data; <answer> (struct 
cmd->base.autoneg = <token> <answer> req0->autoneg; 
<token> = le32_to_cpu(req0->speed); <answer> cmd->base.speed 
<token> = req0->duplex; <answer> cmd->base.duplex 
cmd->base.port <token> req0->port; <answer> = 
cmd->base.transceiver = <token> <answer> req0->transceiver; 
cmd->base.phy_address = <token> <answer> req0->phy_address; 
cmd->base.eth_tp_mdix = <token> <answer> req0->eth_tp_mdix; 
cmd->base.eth_tp_mdix_ctrl = <token> <answer> req0->eth_tp_mdix_ctrl; 
supported <token> le32_to_cpu(req0->supported); <answer> = 
<token> = le32_to_cpu(req0->advertising); <answer> advertising 
lp_advertising <token> le32_to_cpu(req0->lp_advertising); <answer> = 
req1 = (struct <token> *)desc[1].data; <answer> hclge_phy_link_ksetting_1_cmd 
<token> = req1->master_slave_cfg; <answer> cmd->base.master_slave_cfg 
cmd->base.master_slave_state = <token> <answer> req1->master_slave_state; 
return <token> <answer> 0; 
<token> int <answer> static 
hclge_set_phy_link_ksettings(struct hnae3_handle <token> <answer> *handle, 
<token> struct ethtool_link_ksettings *cmd) <answer> const 
struct hclge_desc <token> <answer> desc[HCLGE_PHY_LINK_SETTING_BD_NUM]; 
struct hclge_vport <token> = hclge_get_vport(handle); <answer> *vport 
struct <token> *req0; <answer> hclge_phy_link_ksetting_0_cmd 
struct <token> *req1; <answer> hclge_phy_link_ksetting_1_cmd 
struct hclge_dev *hdev <token> vport->back; <answer> = 
u32 <token> <answer> advertising; 
<token> ret; <answer> int 
if (cmd->base.autoneg == <token> && <answer> AUTONEG_DISABLE 
((cmd->base.speed <token> SPEED_100 && cmd->base.speed != SPEED_10) || <answer> != 
(cmd->base.duplex != <token> && <answer> DUPLEX_HALF 
cmd->base.duplex <token> DUPLEX_FULL))) <answer> != 
<token> -EINVAL; <answer> return 
hclge_cmd_setup_basic_desc(&desc[0], <token> <answer> HCLGE_OPC_PHY_LINK_KSETTING, 
<token> |= cpu_to_le16(HCLGE_COMM_CMD_FLAG_NEXT); <answer> desc[0].flag 
hclge_cmd_setup_basic_desc(&desc[1], <token> <answer> HCLGE_OPC_PHY_LINK_KSETTING, 
req0 <token> (struct hclge_phy_link_ksetting_0_cmd *)desc[0].data; <answer> = 
<token> = cmd->base.autoneg; <answer> req0->autoneg 
req0->speed <token> cpu_to_le32(cmd->base.speed); <answer> = 
<token> = cmd->base.duplex; <answer> req0->duplex 
<token> = cpu_to_le32(advertising); <answer> req0->advertising 
<token> = cmd->base.eth_tp_mdix_ctrl; <answer> req0->eth_tp_mdix_ctrl 
req1 = <token> hclge_phy_link_ksetting_1_cmd *)desc[1].data; <answer> (struct 
req1->master_slave_cfg <token> cmd->base.master_slave_cfg; <answer> = 
ret = <token> desc, HCLGE_PHY_LINK_SETTING_BD_NUM); <answer> hclge_cmd_send(&hdev->hw, 
<token> (ret) { <answer> if 
"failed to set phy link ksettings, <token> = %d.\n", ret); <answer> ret 
<token> ret; <answer> return 
hdev->hw.mac.req_autoneg <token> cmd->base.autoneg; <answer> = 
hdev->hw.mac.req_speed = <token> <answer> cmd->base.speed; 
hdev->hw.mac.req_duplex <token> cmd->base.duplex; <answer> = 
<token> cmd->link_modes.advertising); <answer> linkmode_copy(hdev->hw.mac.advertising, 
<token> 0; <answer> return 
static int <token> hclge_dev *hdev) <answer> hclge_update_tp_port_info(struct 
struct <token> cmd; <answer> ethtool_link_ksettings 
int <token> <answer> ret; 
<token> (!hnae3_dev_phy_imp_supported(hdev)) <answer> if 
return <token> <answer> 0; 
ret = <token> &cmd); <answer> hclge_get_phy_link_ksettings(&hdev->vport->nic, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
<token> = cmd.base.autoneg; <answer> hdev->hw.mac.autoneg 
<token> = cmd.base.speed; <answer> hdev->hw.mac.speed 
hdev->hw.mac.duplex = <token> <answer> cmd.base.duplex; 
linkmode_copy(hdev->hw.mac.advertising, <token> <answer> cmd.link_modes.advertising); 
return <token> <answer> 0; 
static int <token> hclge_dev *hdev) <answer> hclge_tp_port_init(struct 
struct <token> cmd; <answer> ethtool_link_ksettings 
<token> (!hnae3_dev_phy_imp_supported(hdev)) <answer> if 
<token> 0; <answer> return 
cmd.base.autoneg <token> hdev->hw.mac.req_autoneg; <answer> = 
cmd.base.speed <token> hdev->hw.mac.req_speed; <answer> = 
cmd.base.duplex <token> hdev->hw.mac.req_duplex; <answer> = 
<token> hdev->hw.mac.advertising); <answer> linkmode_copy(cmd.link_modes.advertising, 
return hclge_set_phy_link_ksettings(&hdev->vport->nic, <token> <answer> &cmd); 
static int hclge_update_port_info(struct <token> *hdev) <answer> hclge_dev 
struct hclge_mac *mac <token> &hdev->hw.mac; <answer> = 
int <token> <answer> speed; 
<token> ret; <answer> int 
if <token> &vport->state)) <answer> (!test_bit(HCLGE_VPORT_STATE_ALIVE, 
<token> 0; <answer> return 
ret <token> hclge_push_vf_link_status(vport); <answer> = 
if <token> { <answer> (ret) 
vport->vf_info.link_state = <token> <answer> link_state_old; 
"failed to push <token> link status, ret = %d\n", vf, ret); <answer> vf%d 
return <token> <answer> ret; 
static u32 hclge_check_event_cause(struct hclge_dev *hdev, <token> *clearval) <answer> u32 
u32 cmdq_src_reg, <token> hw_err_src_reg; <answer> msix_src_reg, 
if (BIT(HCLGE_VECTOR0_IMPRESET_INT_B) & msix_src_reg) <token> <answer> { 
dev_info(&hdev->pdev->dev, "IMP reset <token> <answer> interrupt\n"); 
<token> &hdev->reset_pending); <answer> set_bit(HNAE3_IMP_RESET, 
<token> &hdev->hw.hw.comm_state); <answer> set_bit(HCLGE_COMM_STATE_CMD_DISABLE, 
*clearval = <token> <answer> BIT(HCLGE_VECTOR0_IMPRESET_INT_B); 
<token> HCLGE_VECTOR0_EVENT_RST; <answer> return 
if (BIT(HCLGE_VECTOR0_GLOBALRESET_INT_B) <token> msix_src_reg) { <answer> & 
dev_info(&hdev->pdev->dev, "global reset <token> <answer> interrupt\n"); 
<token> &hdev->hw.hw.comm_state); <answer> set_bit(HCLGE_COMM_STATE_CMD_DISABLE, 
set_bit(HNAE3_GLOBAL_RESET, <token> <answer> &hdev->reset_pending); 
*clearval = <token> <answer> BIT(HCLGE_VECTOR0_GLOBALRESET_INT_B); 
return <token> <answer> HCLGE_VECTOR0_EVENT_RST; 
"received unknown or unhandled event of <token> <answer> vector0\n"); 
hclge_clear_event_cause(hdev, <token> clearval); <answer> event_cause, 
<token> = hclge_inform_reset_assert_to_vf(vport); <answer> ret 
<token> (ret) <answer> if 
"inform reset <token> vf(%u) failed %d!\n", <answer> to 
vport->vport_id - <token> <answer> HCLGE_VF_VPORT_START_NUM, 
return <token> <answer> 0; 
static <token> hclge_mailbox_service_task(struct hclge_dev *hdev) <answer> void 
if (!test_and_clear_bit(HCLGE_STATE_MBX_SERVICE_SCHED, <token> || <answer> &hdev->state) 
test_bit(HCLGE_COMM_STATE_CMD_DISABLE, <token> || <answer> &hdev->hw.hw.comm_state) 
test_and_set_bit(HCLGE_STATE_MBX_HANDLING, <token> <answer> &hdev->state)) 
<token> (time_is_before_jiffies(hdev->last_mbx_scheduled + <answer> if 
"mbx service <token> is scheduled after %ums on cpu%u!\n", <answer> task 
jiffies_to_msecs(jiffies <token> hdev->last_mbx_scheduled), <answer> - 
<token> &hdev->state); <answer> clear_bit(HCLGE_STATE_MBX_HANDLING, 
static <token> hclge_func_reset_sync_vf(struct hclge_dev *hdev) <answer> void 
struct <token> *req; <answer> hclge_pf_rst_sync_cmd 
<token> hclge_desc desc; <answer> struct 
int cnt <token> 0; <answer> = 
<token> ret; <answer> int 
<token> = (struct hclge_pf_rst_sync_cmd *)desc.data; <answer> req 
<token> HCLGE_OPC_QUERY_VF_RST_RDY, true); <answer> hclge_cmd_setup_basic_desc(&desc, 
<token> { <answer> do 
if <token> == -EOPNOTSUPP) { <answer> (ret 
} else if <token> { <answer> (ret) 
dev_warn(&hdev->pdev->dev, "sync with <token> fail %d!\n", <answer> VF 
} else if <token> { <answer> (req->all_vf_ready) 
hclge_comm_cmd_reuse_desc(&desc, <token> <answer> true); 
} while <token> < HCLGE_PF_RESET_SYNC_CNT); <answer> (cnt++ 
dev_warn(&hdev->pdev->dev, "sync <token> VF timeout!\n"); <answer> with 
<token> hclge_report_hw_error(struct hclge_dev *hdev, <answer> void 
enum hnae3_hw_error_type <token> <answer> type) 
struct hnae3_client <token> = hdev->nic_client; <answer> *client 
if (!client || !client->ops->process_hw_error <token> <answer> || 
<token> &hdev->state)) <answer> !test_bit(HCLGE_STATE_NIC_REGISTERED, 
client->ops->process_hw_error(&hdev->vport[0].nic, <token> <answer> type); 
static <token> hclge_handle_imp_error(struct hclge_dev *hdev) <answer> void 
u32 <token> <answer> reg_val; 
<token> = hclge_read_dev(&hdev->hw, HCLGE_PF_OTHER_INT_REG); <answer> reg_val 
if (reg_val & <token> { <answer> BIT(HCLGE_VECTOR0_IMP_RD_POISON_B)) 
<token> HNAE3_IMP_RD_POISON_ERROR); <answer> hclge_report_hw_error(hdev, 
<token> &= ~BIT(HCLGE_VECTOR0_IMP_RD_POISON_B); <answer> reg_val 
hclge_write_dev(&hdev->hw, HCLGE_PF_OTHER_INT_REG, <token> <answer> reg_val); 
<token> (reg_val & BIT(HCLGE_VECTOR0_IMP_CMDQ_ERR_B)) { <answer> if 
hclge_report_hw_error(hdev, <token> <answer> HNAE3_CMDQ_ECC_ERROR); 
reg_val <token> ~BIT(HCLGE_VECTOR0_IMP_CMDQ_ERR_B); <answer> &= 
hclge_write_dev(&hdev->hw, <token> reg_val); <answer> HCLGE_PF_OTHER_INT_REG, 
int hclge_func_reset_cmd(struct <token> *hdev, int func_id) <answer> hclge_dev 
struct <token> desc; <answer> hclge_desc 
struct hclge_reset_cmd *req = (struct hclge_reset_cmd <token> <answer> *)desc.data; 
<token> ret; <answer> int 
<token> HCLGE_OPC_CFG_RST_TRIGGER, false); <answer> hclge_cmd_setup_basic_desc(&desc, 
<token> HCLGE_CFG_RESET_FUNC_B, 1); <answer> hnae3_set_bit(req->mac_func_reset, 
req->fun_reset_vfid = <token> <answer> func_id; 
ret = hclge_cmd_send(&hdev->hw, <token> 1); <answer> &desc, 
<token> (ret) <answer> if 
<token> function reset cmd fail, status =%d\n", ret); <answer> "send 
return <token> <answer> ret; 
static <token> hclge_do_reset(struct hclge_dev *hdev) <answer> void 
struct hnae3_handle *handle = <token> <answer> &hdev->vport[0].nic; 
struct pci_dev <token> = hdev->pdev; <answer> *pdev 
<token> val; <answer> u32 
<token> (hclge_get_hw_reset_stat(handle)) { <answer> if 
dev_info(&pdev->dev, <token> reset not finish\n"); <answer> "hardware 
dev_info(&pdev->dev, "func_rst_reg:0x%x, <token> <answer> global_rst_reg:0x%x\n", 
hclge_read_dev(&hdev->hw, <token> <answer> HCLGE_FUN_RST_ING), 
<token> HCLGE_GLOBAL_RESET_REG)); <answer> hclge_read_dev(&hdev->hw, 
switch (hdev->reset_type) <token> <answer> { 
case <token> <answer> HNAE3_IMP_RESET: 
dev_info(&pdev->dev, <token> reset requested\n"); <answer> "IMP 
val = <token> HCLGE_PF_OTHER_INT_REG); <answer> hclge_read_dev(&hdev->hw, 
<token> HCLGE_TRIGGER_IMP_RESET_B, 1); <answer> hnae3_set_bit(val, 
<token> HCLGE_PF_OTHER_INT_REG, val); <answer> hclge_write_dev(&hdev->hw, 
<token> HNAE3_GLOBAL_RESET: <answer> case 
dev_info(&pdev->dev, "global <token> requested\n"); <answer> reset 
val = <token> HCLGE_GLOBAL_RESET_REG); <answer> hclge_read_dev(&hdev->hw, 
<token> HCLGE_GLOBAL_RESET_BIT, 1); <answer> hnae3_set_bit(val, 
hclge_write_dev(&hdev->hw, <token> val); <answer> HCLGE_GLOBAL_RESET_REG, 
<token> HNAE3_FUNC_RESET: <answer> case 
dev_info(&pdev->dev, "PF reset <token> <answer> requested\n"); 
if (hdev->ae_dev->dev_version < <token> <answer> HNAE3_DEVICE_VERSION_V2) 
<token> HCLGE_MISC_RESET_STS_REG, <answer> hclge_write_dev(&hdev->hw, 
hclge_enable_vector(&hdev->misc_vector, <token> <answer> true); 
static void hclge_reset_handshake(struct hclge_dev <token> bool enable) <answer> *hdev, 
u32 <token> <answer> reg_val; 
<token> = hclge_read_dev(&hdev->hw, HCLGE_COMM_NIC_CSQ_DEPTH_REG); <answer> reg_val 
if <token> <answer> (enable) 
reg_val <token> HCLGE_COMM_NIC_SW_RST_RDY; <answer> |= 
<token> &= ~HCLGE_COMM_NIC_SW_RST_RDY; <answer> reg_val 
hclge_write_dev(&hdev->hw, <token> reg_val); <answer> HCLGE_COMM_NIC_CSQ_DEPTH_REG, 
static int hclge_func_reset_notify_vf(struct hclge_dev <token> <answer> *hdev) 
<token> ret; <answer> int 
<token> = hclge_set_all_vf_rst(hdev, true); <answer> ret 
if <token> <answer> (ret) 
<token> ret; <answer> return 
return <token> <answer> 0; 
static int hclge_reset_prepare_wait(struct <token> *hdev) <answer> hclge_dev 
u32 <token> <answer> reg_val; 
int ret = <token> <answer> 0; 
switch (hdev->reset_type) <token> <answer> { 
<token> HNAE3_FUNC_RESET: <answer> case 
ret = <token> <answer> hclge_func_reset_notify_vf(hdev); 
if <token> <answer> (ret) 
<token> ret; <answer> return 
ret = <token> 0); <answer> hclge_func_reset_cmd(hdev, 
<token> (ret) { <answer> if 
"asserting function <token> fail %d!\n", ret); <answer> reset 
return <token> <answer> ret; 
<token> &hdev->hw.hw.comm_state); <answer> set_bit(HCLGE_COMM_STATE_CMD_DISABLE, 
case <token> <answer> HNAE3_FLR_RESET: 
ret = <token> <answer> hclge_func_reset_notify_vf(hdev); 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> HNAE3_IMP_RESET: <answer> case 
reg_val <token> hclge_read_dev(&hdev->hw, HCLGE_PF_OTHER_INT_REG); <answer> = 
<token> HCLGE_PF_OTHER_INT_REG, <answer> hclge_write_dev(&hdev->hw, 
BIT(HCLGE_VECTOR0_IMP_RESET_INT_B) | <token> <answer> reg_val); 
<token> &hdev->reset_request); <answer> hclge_get_reset_level(ae_dev, 
<token> = hclge_get_reset_level(ae_dev, <answer> reset_level 
if (reset_level <token> HNAE3_NONE_RESET) <answer> != 
<token> &hdev->reset_request); <answer> set_bit(reset_level, 
static int hclge_set_rst_done(struct <token> *hdev) <answer> hclge_dev 
struct hclge_pf_rst_done_cmd <token> <answer> *req; 
struct hclge_desc <token> <answer> desc; 
<token> ret; <answer> int 
req = <token> hclge_pf_rst_done_cmd *)desc.data; <answer> (struct 
<token> HCLGE_OPC_PF_RST_DONE, false); <answer> hclge_cmd_setup_basic_desc(&desc, 
req->pf_rst_done <token> HCLGE_PF_RESET_DONE_BIT; <answer> |= 
<token> = hclge_cmd_send(&hdev->hw, &desc, 1); <answer> ret 
if <token> == -EOPNOTSUPP) { <answer> (ret 
"current firmware does not <token> command(0x%x)!\n", <answer> support 
return <token> <answer> 0; 
} else <token> (ret) { <answer> if 
dev_err(&hdev->pdev->dev, "assert <token> reset done fail %d!\n", <answer> PF 
return <token> <answer> ret; 
static <token> hclge_reset_prepare_up(struct hclge_dev *hdev) <answer> int 
int ret = <token> <answer> 0; 
switch (hdev->reset_type) <token> <answer> { 
<token> HNAE3_FUNC_RESET: <answer> case 
<token> HNAE3_FLR_RESET: <answer> case 
<token> = hclge_set_all_vf_rst(hdev, false); <answer> ret 
case <token> <answer> HNAE3_GLOBAL_RESET: 
case <token> <answer> HNAE3_IMP_RESET: 
ret = <token> <answer> hclge_set_rst_done(hdev); 
if (ret <token> <answer> && 
<token> < HCLGE_RESET_MAX_FAIL_CNT - 1) <answer> hdev->rst_stats.reset_fail_cnt 
<token> ret; <answer> return 
ret = <token> <answer> hclge_reset_prepare_up(hdev); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
ret = <token> HNAE3_UP_CLIENT); <answer> hclge_notify_client(hdev, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
<token> = hclge_notify_roce_client(hdev, HNAE3_UP_CLIENT); <answer> ret 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> = jiffies; <answer> hdev->last_reset_time 
<token> = 0; <answer> hdev->rst_stats.reset_fail_cnt 
<token> &hdev->state); <answer> clear_bit(HCLGE_STATE_RST_FAIL, 
return <token> <answer> 0; 
<token> void hclge_reset(struct hclge_dev *hdev) <answer> static 
if <token> <answer> (hclge_reset_prepare(hdev)) 
<token> err_reset; <answer> goto 
<token> (hclge_reset_wait(hdev)) <answer> if 
<token> err_reset; <answer> goto 
if <token> <answer> (hclge_reset_rebuild(hdev)) 
<token> err_reset; <answer> goto 
if <token> <answer> (hclge_reset_err_handle(hdev)) 
static void hclge_reset_event(struct pci_dev *pdev, struct <token> *handle) <answer> hnae3_handle 
struct hnae3_ae_dev <token> = pci_get_drvdata(pdev); <answer> *ae_dev 
<token> hclge_dev *hdev = ae_dev->priv; <answer> struct 
<token> (time_before(jiffies, (hdev->last_reset_time + <answer> if 
HCLGE_RESET_INTERVAL))) <token> <answer> { 
<token> jiffies + HCLGE_RESET_INTERVAL); <answer> mod_timer(&hdev->reset_timer, 
if <token> { <answer> (hdev->default_reset_request) 
<token> = <answer> hdev->reset_level 
} else if <token> (hdev->last_reset_time + 4 * 5 * HZ))) { <answer> (time_after(jiffies, 
hdev->reset_level <token> HNAE3_FUNC_RESET; <answer> = 
<token> "received reset event, reset type is %d\n", <answer> dev_info(&hdev->pdev->dev, 
<token> (!hdev->default_reset_request) <answer> if 
"triggering <token> in reset timer\n"); <answer> reset 
hclge_reset_event(hdev->pdev, <token> <answer> NULL); 
static <token> hclge_reset_subtask(struct hclge_dev *hdev) <answer> void 
struct hnae3_ae_dev <token> = pci_get_drvdata(hdev->pdev); <answer> *ae_dev 
hdev->last_reset_time = <token> <answer> jiffies; 
<token> = hclge_get_reset_level(ae_dev, &hdev->reset_pending); <answer> hdev->reset_type 
if (hdev->reset_type <token> HNAE3_NONE_RESET) <answer> != 
if (time_is_after_jiffies(hdev->last_serv_processed + <token> { <answer> HZ)) 
delta = jiffies <token> hdev->last_serv_processed; <answer> - 
if (delta < round_jiffies_relative(HZ)) <token> <answer> { 
delta = round_jiffies_relative(HZ) <token> delta; <answer> - 
<token> out; <answer> goto 
if (test_bit(HCLGE_STATE_DOWN, &hdev->state)) <token> <answer> { 
hdev->last_serv_processed = <token> <answer> jiffies; 
<token> out; <answer> goto 
if (!(hdev->serv_processed_cnt % <token> <answer> HCLGE_STATS_TIMER_INTERVAL)) 
if (!(hdev->serv_processed_cnt % <token> <answer> HCLGE_ARFS_EXPIRE_INTERVAL)) 
<token> = jiffies; <answer> hdev->last_serv_processed 
hclge_task_schedule(hdev, <token> <answer> delta); 
<token> void hclge_ptp_service_task(struct hclge_dev *hdev) <answer> static 
unsigned <token> flags; <answer> long 
<token> (!test_bit(HCLGE_STATE_PTP_EN, &hdev->state) || <answer> if 
!test_bit(HCLGE_STATE_PTP_TX_HANDLING, &hdev->state) <token> <answer> || 
<token> + HZ)) <answer> !time_is_before_jiffies(hdev->ptp->tx_start 
if (test_bit(HCLGE_STATE_PTP_TX_HANDLING, <token> <answer> &hdev->state)) 
spin_unlock_irqrestore(&hdev->ptp->lock, <token> <answer> flags); 
static void hclge_service_task(struct work_struct <token> <answer> *work) 
<token> hclge_dev *hdev = <answer> struct 
<token> struct hclge_dev, service_task.work); <answer> container_of(work, 
struct hclge_vport <token> hnae3_handle *handle) <answer> *hclge_get_vport(struct 
<token> (rss_size > ae_dev->dev_specs.rss_ind_tbl_size || <answer> if 
rss_size <token> 0) { <answer> == 
"Configure rss tc size failed, <token> TC_SIZE = %u\n", <answer> invalid 
<token> -EINVAL; <answer> return 
roundup_size <token> roundup_pow_of_two(rss_size); <answer> = 
roundup_size <token> ilog2(roundup_size); <answer> = 
tc_valid[i] = <token> <answer> 1; 
tc_size[i] <token> roundup_size; <answer> = 
tc_offset[i] <token> tc_info->tqp_offset[i]; <answer> = 
return hclge_comm_set_rss_tc_mode(&hdev->hw.hw, <token> tc_valid, <answer> tc_offset, 
int hclge_rss_init_hw(struct hclge_dev <token> <answer> *hdev) 
<token> *rss_indir = hdev->rss_cfg.rss_indirection_tbl; <answer> u16 
u8 *key <token> hdev->rss_cfg.rss_hash_key; <answer> = 
<token> hfunc = hdev->rss_cfg.rss_algo; <answer> u8 
int <token> <answer> ret; 
ret = <token> &hdev->hw.hw, <answer> hclge_comm_set_rss_indir_table(hdev->ae_dev, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
<token> = hclge_comm_set_rss_algo_key(&hdev->hw.hw, hfunc, key); <answer> ret 
<token> (ret) <answer> if 
return <token> <answer> ret; 
ret = <token> &hdev->rss_cfg); <answer> hclge_comm_set_rss_input_tuple(&hdev->hw.hw, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> hclge_init_rss_tc_mode(hdev); <answer> return 
<token> hclge_bind_ring_with_vector(struct hclge_vport *vport, <answer> int 
int <token> bool en, <answer> vector_id, 
struct <token> *ring_chain) <answer> hnae3_ring_chain_node 
struct hclge_dev *hdev <token> vport->back; <answer> = 
struct hnae3_ring_chain_node <token> <answer> *node; 
struct hclge_desc <token> <answer> desc; 
struct hclge_ctrl_vector_chain_cmd *req <token> <answer> = 
(struct hclge_ctrl_vector_chain_cmd <token> <answer> *)desc.data; 
enum <token> status; <answer> hclge_comm_cmd_status 
enum <token> op; <answer> hclge_opcode_type 
<token> tqp_type_and_id; <answer> u16 
int <token> <answer> i; 
op = en ? HCLGE_OPC_ADD_RING_TO_VECTOR : <token> <answer> HCLGE_OPC_DEL_RING_TO_VECTOR; 
hclge_cmd_setup_basic_desc(&desc, <token> false); <answer> op, 
<token> = hnae3_get_field(vector_id, <answer> req->int_vector_id_l 
req->int_vector_id_h <token> hnae3_get_field(vector_id, <answer> = 
i <token> 0; <answer> = 
for (node = ring_chain; node; node = node->next) <token> <answer> { 
<token> = le16_to_cpu(req->tqp_type_and_id[i]); <answer> tqp_type_and_id 
<token> HCLGE_INT_TYPE_M, <answer> hnae3_set_field(tqp_type_and_id, 
hnae3_get_bit(node->flag, <token> <answer> HNAE3_RING_TYPE_B)); 
<token> HCLGE_TQP_ID_M, <answer> hnae3_set_field(tqp_type_and_id, 
HCLGE_TQP_ID_S, <token> <answer> node->tqp_index); 
<token> HCLGE_INT_GL_IDX_M, <answer> hnae3_set_field(tqp_type_and_id, 
<token> = cpu_to_le16(tqp_type_and_id); <answer> req->tqp_type_and_id[i] 
if (++i >= HCLGE_VECTOR_ELEMENTS_PER_CMD) <token> <answer> { 
req->int_cause_num <token> HCLGE_VECTOR_ELEMENTS_PER_CMD; <answer> = 
req->vfid = <token> <answer> vport->vport_id; 
status = <token> &desc, 1); <answer> hclge_cmd_send(&hdev->hw, 
if (status) <token> <answer> { 
"Map TQP fail, status <token> %d.\n", <answer> is 
<token> -EIO; <answer> return 
i = <token> <answer> 0; 
<token> = <answer> req->int_vector_id_l 
req->int_vector_id_h <token> <answer> = 
if (i > 0) <token> <answer> { 
req->int_cause_num <token> i; <answer> = 
<token> = vport->vport_id; <answer> req->vfid 
status = hclge_cmd_send(&hdev->hw, <token> 1); <answer> &desc, 
if <token> { <answer> (status) 
"Map TQP fail, status is %d.\n", <token> <answer> status); 
<token> -EIO; <answer> return 
<token> 0; <answer> return 
static int <token> hnae3_handle *handle, int vector, <answer> hclge_map_ring_to_vector(struct 
<token> hnae3_ring_chain_node *ring_chain) <answer> struct 
struct hclge_vport *vport <token> hclge_get_vport(handle); <answer> = 
struct hclge_dev <token> = vport->back; <answer> *hdev 
int <token> <answer> vector_id; 
vector_id = <token> vector); <answer> hclge_get_vector_index(hdev, 
if (vector_id < 0) <token> <answer> { 
"failed to get vector <token> vector=%d\n", vector); <answer> index. 
return <token> <answer> vector_id; 
return hclge_bind_ring_with_vector(vport, <token> true, ring_chain); <answer> vector_id, 
static int hclge_unmap_ring_frm_vector(struct <token> *handle, int vector, <answer> hnae3_handle 
struct <token> *ring_chain) <answer> hnae3_ring_chain_node 
struct hclge_vport *vport <token> hclge_get_vport(handle); <answer> = 
<token> hclge_dev *hdev = vport->back; <answer> struct 
int <token> ret; <answer> vector_id, 
if (test_bit(HCLGE_STATE_RST_HANDLING, <token> <answer> &hdev->state)) 
<token> 0; <answer> return 
vector_id <token> hclge_get_vector_index(hdev, vector); <answer> = 
if (vector_id < 0) <token> <answer> { 
"Get <token> index fail. ret =%d\n", vector_id); <answer> vector 
<token> vector_id; <answer> return 
ret = hclge_bind_ring_with_vector(vport, <token> false, ring_chain); <answer> vector_id, 
<token> (ret) <answer> if 
"Unmap ring from vector fail. vectorid=%d, ret <token> <answer> =%d\n", 
<token> ret); <answer> vector_id, 
return <token> <answer> ret; 
<token> int hclge_cmd_set_promisc_mode(struct hclge_dev *hdev, u8 vf_id, <answer> static 
bool en_uc, bool en_mc, <token> en_bc) <answer> bool 
struct hclge_vport <token> = &hdev->vport[vf_id]; <answer> *vport 
struct hnae3_handle *handle <token> &vport->nic; <answer> = 
<token> hclge_promisc_cfg_cmd *req; <answer> struct 
<token> hclge_desc desc; <answer> struct 
bool <token> = en_uc; <answer> uc_tx_en 
u8 <token> = 0; <answer> promisc_cfg 
int <token> <answer> ret; 
hclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_CFG_PROMISC_MODE, <token> <answer> false); 
<token> = (struct hclge_promisc_cfg_cmd *)desc.data; <answer> req 
req->vf_id <token> vf_id; <answer> = 
<token> (test_bit(HNAE3_PFLAG_LIMIT_PROMISC, &handle->priv_flags)) <answer> if 
uc_tx_en = <token> <answer> false; 
hnae3_set_bit(promisc_cfg, HCLGE_PROMISC_UC_RX_EN, en_uc ? 1 <token> 0); <answer> : 
hnae3_set_bit(promisc_cfg, HCLGE_PROMISC_MC_RX_EN, en_mc ? 1 : <token> <answer> 0); 
hnae3_set_bit(promisc_cfg, HCLGE_PROMISC_BC_RX_EN, en_bc <token> 1 : 0); <answer> ? 
<token> HCLGE_PROMISC_UC_TX_EN, uc_tx_en ? 1 : 0); <answer> hnae3_set_bit(promisc_cfg, 
hnae3_set_bit(promisc_cfg, HCLGE_PROMISC_MC_TX_EN, <token> ? 1 : 0); <answer> en_mc 
hnae3_set_bit(promisc_cfg, HCLGE_PROMISC_BC_TX_EN, <token> ? 1 : 0); <answer> en_bc 
<token> = promisc_cfg; <answer> req->extend_promisc 
if (hdev->ae_dev->dev_version <token> HNAE3_DEVICE_VERSION_V2) <answer> < 
en_bc_pmc = handle->netdev_flags & HNAE3_BPE ? <token> : false; <answer> true 
return hclge_set_vport_promisc_mode(vport, en_uc_pmc, <token> <answer> en_mc_pmc, 
<token> void hclge_request_update_promisc_mode(struct hnae3_handle *handle) <answer> static 
struct <token> *vport = hclge_get_vport(handle); <answer> hclge_vport 
<token> &vport->state); <answer> set_bit(HCLGE_VPORT_STATE_PROMISC_CHANGE, 
<token> void hclge_sync_fd_state(struct hclge_dev *hdev) <answer> static 
if <token> <answer> (hlist_empty(&hdev->fd_rule_list)) 
hdev->fd_active_type = <token> <answer> HCLGE_FD_RULE_NONE; 
static void hclge_fd_inc_rule_cnt(struct hclge_dev *hdev, u16 <token> <answer> location) 
if (!test_bit(location, <token> { <answer> hdev->fd_bmap)) 
<token> hdev->fd_bmap); <answer> set_bit(location, 
static void hclge_fd_dec_rule_cnt(struct hclge_dev <token> u16 location) <answer> *hdev, 
<token> (test_bit(location, hdev->fd_bmap)) { <answer> if 
clear_bit(location, <token> <answer> hdev->fd_bmap); 
static void hclge_fd_free_node(struct <token> *hdev, <answer> hclge_dev 
struct <token> *rule) <answer> hclge_fd_rule 
static <token> hclge_update_fd_rule_node(struct hclge_dev *hdev, <answer> void 
struct <token> *old_rule, <answer> hclge_fd_rule 
struct hclge_fd_rule <token> <answer> *new_rule, 
<token> HCLGE_FD_NODE_STATE state) <answer> enum 
switch <token> { <answer> (state) 
<token> HCLGE_FD_TO_ADD: <answer> case 
<token> HCLGE_FD_ACTIVE: <answer> case 
new_rule->rule_node.next = <token> <answer> old_rule->rule_node.next; 
new_rule->rule_node.pprev = <token> <answer> old_rule->rule_node.pprev; 
<token> new_rule, sizeof(*old_rule)); <answer> memcpy(old_rule, 
<token> HCLGE_FD_DELETED: <answer> case 
hclge_fd_dec_rule_cnt(hdev, <token> <answer> old_rule->location); 
<token> old_rule); <answer> hclge_fd_free_node(hdev, 
case <token> <answer> HCLGE_FD_TO_DEL: 
if (old_rule->state == <token> { <answer> HCLGE_FD_TO_ADD) 
<token> old_rule->location); <answer> hclge_fd_dec_rule_cnt(hdev, 
<token> old_rule); <answer> hclge_fd_free_node(hdev, 
old_rule->state = <token> <answer> HCLGE_FD_TO_DEL; 
static struct <token> *hclge_find_fd_rule(struct hlist_head *hlist, <answer> hclge_fd_rule 
u16 <token> <answer> location, 
struct hclge_fd_rule <token> <answer> **parent) 
<token> hclge_fd_rule *rule; <answer> struct 
struct <token> *node; <answer> hlist_node 
hlist_for_each_entry_safe(rule, node, hlist, <token> { <answer> rule_node) 
if <token> == location) <answer> (rule->location 
return <token> <answer> rule; 
else if (rule->location <token> location) <answer> > 
return <token> <answer> NULL; 
*parent = <token> <answer> rule; 
<token> NULL; <answer> return 
if <token> == HCLGE_FD_TO_DEL || state == HCLGE_FD_DELETED)) { <answer> (unlikely(state 
"failed to delete fd rule %u, it's <token> <answer> inexistent\n", 
<token> new_rule); <answer> hclge_fd_inc_user_def_refcnt(hdev, 
<token> true); <answer> hclge_sync_fd_user_def_cfg(hdev, 
hclge_fd_insert_rule_node(hlist, new_rule, <token> <answer> parent); 
<token> new_rule->location); <answer> hclge_fd_inc_rule_cnt(hdev, 
if <token> == HCLGE_FD_TO_ADD) { <answer> (state 
<token> &hdev->state); <answer> set_bit(HCLGE_STATE_FD_TBL_CHANGED, 
hclge_task_schedule(hdev, <token> <answer> 0); 
static int hclge_get_fd_mode(struct hclge_dev <token> u8 *fd_mode) <answer> *hdev, 
struct hclge_get_fd_mode_cmd <token> <answer> *req; 
struct hclge_desc <token> <answer> desc; 
int <token> <answer> ret; 
hclge_cmd_setup_basic_desc(&desc, <token> true); <answer> HCLGE_OPC_FD_MODE_CTRL, 
req = (struct <token> *)desc.data; <answer> hclge_get_fd_mode_cmd 
<token> = hclge_cmd_send(&hdev->hw, &desc, 1); <answer> ret 
if (ret) <token> <answer> { 
dev_err(&hdev->pdev->dev, "get fd mode fail, <token> ret); <answer> ret=%d\n", 
return <token> <answer> ret; 
*fd_mode = <token> <answer> req->mode; 
<token> ret; <answer> return 
<token> int hclge_get_fd_allocation(struct hclge_dev *hdev, <answer> static 
u32 <token> <answer> *stage1_entry_num, 
u32 <token> <answer> *stage2_entry_num, 
u16 <token> <answer> *stage1_counter_num, 
<token> *stage2_counter_num) <answer> u16 
struct hclge_get_fd_allocation_cmd <token> <answer> *req; 
<token> hclge_desc desc; <answer> struct 
<token> ret; <answer> int 
hclge_cmd_setup_basic_desc(&desc, <token> true); <answer> HCLGE_OPC_FD_GET_ALLOCATION, 
req = (struct <token> *)desc.data; <answer> hclge_get_fd_allocation_cmd 
ret = <token> &desc, 1); <answer> hclge_cmd_send(&hdev->hw, 
if (ret) <token> <answer> { 
dev_err(&hdev->pdev->dev, "query fd allocation <token> ret=%d\n", <answer> fail, 
<token> ret; <answer> return 
<token> = le32_to_cpu(req->stage1_entry_num); <answer> *stage1_entry_num 
*stage2_entry_num <token> le32_to_cpu(req->stage2_entry_num); <answer> = 
*stage1_counter_num <token> le16_to_cpu(req->stage1_counter_num); <answer> = 
<token> = le16_to_cpu(req->stage2_counter_num); <answer> *stage2_counter_num 
return <token> <answer> ret; 
static int hclge_set_fd_key_config(struct <token> *hdev, <answer> hclge_dev 
<token> HCLGE_FD_STAGE stage_num) <answer> enum 
struct hclge_set_fd_key_config_cmd <token> <answer> *req; 
struct <token> *stage; <answer> hclge_fd_key_cfg 
struct <token> desc; <answer> hclge_desc 
int <token> <answer> ret; 
hclge_cmd_setup_basic_desc(&desc, <token> false); <answer> HCLGE_OPC_FD_KEY_CONFIG, 
req = <token> hclge_set_fd_key_config_cmd *)desc.data; <answer> (struct 
stage <token> &hdev->fd_cfg.key_cfg[stage_num]; <answer> = 
<token> = stage_num; <answer> req->stage 
req->key_select <token> stage->key_sel; <answer> = 
<token> = stage->inner_sipv6_word_en; <answer> req->inner_sipv6_word_en 
req->inner_dipv6_word_en = <token> <answer> stage->inner_dipv6_word_en; 
req->outer_sipv6_word_en <token> stage->outer_sipv6_word_en; <answer> = 
<token> = stage->outer_dipv6_word_en; <answer> req->outer_dipv6_word_en 
<token> = cpu_to_le32(~stage->tuple_active); <answer> req->tuple_mask 
<token> = cpu_to_le32(~stage->meta_data_active); <answer> req->meta_data_mask 
ret = hclge_cmd_send(&hdev->hw, <token> 1); <answer> &desc, 
<token> (ret) <answer> if 
dev_err(&hdev->pdev->dev, "set fd key fail, ret=%d\n", <token> <answer> ret); 
return <token> <answer> ret; 
<token> void hclge_fd_disable_user_def(struct hclge_dev *hdev) <answer> static 
struct hclge_fd_user_def_cfg *cfg = <token> <answer> hdev->fd_cfg.user_def_cfg; 
memset(cfg, <token> sizeof(hdev->fd_cfg.user_def_cfg)); <answer> 0, 
<token> cfg); <answer> hclge_fd_set_user_def_cmd(hdev, 
static int hclge_init_fd_config(struct <token> *hdev) <answer> hclge_dev 
<token> LOW_2_WORDS 0x03 <answer> #define 
struct <token> *key_cfg; <answer> hclge_fd_key_cfg 
int <token> <answer> ret; 
<token> (!hnae3_ae_dev_fd_supported(hdev->ae_dev)) <answer> if 
return <token> <answer> 0; 
ret <token> hclge_get_fd_mode(hdev, &hdev->fd_cfg.fd_mode); <answer> = 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> (hdev->fd_cfg.fd_mode) { <answer> switch 
case <token> <answer> HCLGE_FD_MODE_DEPTH_2K_WIDTH_400B_STAGE_1: 
hdev->fd_cfg.max_key_length <token> MAX_KEY_LENGTH; <answer> = 
case <token> <answer> HCLGE_FD_MODE_DEPTH_4K_WIDTH_200B_STAGE_1: 
hdev->fd_cfg.max_key_length <token> MAX_KEY_LENGTH / 2; <answer> = 
"Unsupported flow <token> mode %u\n", <answer> director 
return <token> <answer> -EOPNOTSUPP; 
key_cfg = <token> <answer> &hdev->fd_cfg.key_cfg[HCLGE_FD_STAGE_1]; 
<token> = HCLGE_FD_KEY_BASE_ON_TUPLE; <answer> key_cfg->key_sel 
<token> = LOW_2_WORDS; <answer> key_cfg->inner_sipv6_word_en 
key_cfg->inner_dipv6_word_en <token> LOW_2_WORDS; <answer> = 
key_cfg->outer_sipv6_word_en <token> 0; <answer> = 
key_cfg->outer_dipv6_word_en = <token> <answer> 0; 
key_cfg->tuple_active = BIT(INNER_VLAN_TAG_FST) | BIT(INNER_ETH_TYPE) <token> <answer> | 
BIT(INNER_IP_PROTO) | <token> | <answer> BIT(INNER_IP_TOS) 
BIT(INNER_SRC_IP) <token> BIT(INNER_DST_IP) | <answer> | 
BIT(INNER_SRC_PORT) | <token> <answer> BIT(INNER_DST_PORT); 
key_cfg->meta_data_active = <token> | BIT(DST_VPORT); <answer> BIT(ROCE_TYPE) 
ret = <token> <answer> hclge_get_fd_allocation(hdev, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
return hclge_set_fd_key_config(hdev, <token> <answer> HCLGE_FD_STAGE_1); 
static int <token> hclge_dev *hdev, u8 stage, bool sel_x, <answer> hclge_fd_tcam_config(struct 
int loc, <token> *key, bool is_add) <answer> u8 
struct hclge_fd_tcam_config_1_cmd <token> <answer> *req1; 
struct hclge_fd_tcam_config_2_cmd <token> <answer> *req2; 
struct hclge_fd_tcam_config_3_cmd <token> <answer> *req3; 
<token> hclge_desc desc[3]; <answer> struct 
int <token> <answer> ret; 
hclge_cmd_setup_basic_desc(&desc[0], HCLGE_OPC_FD_TCAM_OP, <token> <answer> false); 
<token> |= cpu_to_le16(HCLGE_COMM_CMD_FLAG_NEXT); <answer> desc[0].flag 
hclge_cmd_setup_basic_desc(&desc[1], HCLGE_OPC_FD_TCAM_OP, <token> <answer> false); 
<token> |= cpu_to_le16(HCLGE_COMM_CMD_FLAG_NEXT); <answer> desc[1].flag 
hclge_cmd_setup_basic_desc(&desc[2], HCLGE_OPC_FD_TCAM_OP, <token> <answer> false); 
req1 <token> (struct hclge_fd_tcam_config_1_cmd *)desc[0].data; <answer> = 
req2 = (struct <token> *)desc[1].data; <answer> hclge_fd_tcam_config_2_cmd 
req3 = <token> hclge_fd_tcam_config_3_cmd *)desc[2].data; <answer> (struct 
req1->stage <token> stage; <answer> = 
<token> = sel_x ? 1 : 0; <answer> req1->xy_sel 
<token> HCLGE_FD_EPORT_SW_EN_B, 0); <answer> hnae3_set_bit(req1->port_info, 
<token> = cpu_to_le32(loc); <answer> req1->index 
req1->entry_vld = sel_x ? is_add : <token> <answer> 0; 
if <token> { <answer> (key) 
memcpy(req1->tcam_data, <token> sizeof(req1->tcam_data)); <answer> &key[0], 
<token> &key[sizeof(req1->tcam_data)], <answer> memcpy(req2->tcam_data, 
memcpy(req3->tcam_data, <token> + <answer> &key[sizeof(req1->tcam_data) 
<token> sizeof(req3->tcam_data)); <answer> sizeof(req2->tcam_data)], 
<token> = hclge_cmd_send(&hdev->hw, desc, 3); <answer> ret 
if <token> <answer> (ret) 
"config tcam key <token> ret=%d\n", <answer> fail, 
<token> ret; <answer> return 
static <token> hclge_fd_ad_config(struct hclge_dev *hdev, u8 stage, int loc, <answer> int 
struct <token> *action) <answer> hclge_fd_ad_data 
struct <token> *ae_dev = pci_get_drvdata(hdev->pdev); <answer> hnae3_ae_dev 
struct <token> *req; <answer> hclge_fd_ad_config_cmd 
struct hclge_desc <token> <answer> desc; 
u64 <token> = 0; <answer> ad_data 
<token> ret; <answer> int 
hclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_FD_AD_OP, <token> <answer> false); 
<token> = (struct hclge_fd_ad_config_cmd *)desc.data; <answer> req 
req->index = <token> <answer> cpu_to_le32(loc); 
req->stage <token> stage; <answer> = 
<token> HCLGE_FD_AD_WR_RULE_ID_B, <answer> hnae3_set_bit(ad_data, 
hnae3_set_field(ad_data, <token> HCLGE_FD_AD_RULE_ID_S, <answer> HCLGE_FD_AD_RULE_ID_M, 
<token> (test_bit(HNAE3_DEV_SUPPORT_FD_FORWARD_TC_B, ae_dev->caps)) { <answer> if 
<token> HCLGE_FD_AD_TC_OVRD_B, <answer> hnae3_set_bit(ad_data, 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/pci.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/delay.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/mfd/core.h> <answer> #include 
<token> <linux/mfd/janz.h> <answer> #include 
#define DRV_NAME <token> <answer> "janz-cmodio" 
static int cmodio_setup_subdevice(struct cmodio_device <token> <answer> *priv, 
char *name, unsigned int <token> <answer> devno, 
<token> int modno) <answer> unsigned 
struct janz_platform_data <token> <answer> *pdata; 
struct <token> *cell; <answer> mfd_cell 
struct resource <token> <answer> *res; 
struct pci_dev <token> <answer> *pci; 
<token> = priv->pdev; <answer> pci 
cell <token> &priv->cells[devno]; <answer> = 
res = &priv->resources[devno <token> 3]; <answer> * 
<token> = &priv->pdata[devno]; <answer> pdata 
cell->name = <token> <answer> name; 
<token> = res; <answer> cell->resources 
cell->num_resources <token> 3; <answer> = 
<token> = IORESOURCE_IRQ; <answer> res->flags 
<token> = NULL; <answer> res->parent 
res->start <token> 0; <answer> = 
<token> = 0; <answer> res->end 
return <token> <answer> 0; 
static ssize_t modulbus_number_show(struct <token> *dev, <answer> device 
<token> device_attribute *attr, char *buf) <answer> struct 
struct cmodio_device *priv <token> dev_get_drvdata(dev); <answer> = 
<token> sysfs_emit(buf, "%x\n", priv->hex); <answer> return 
static <token> <answer> DEVICE_ATTR_RO(modulbus_number); 
static struct attribute *cmodio_sysfs_attrs[] = <token> <answer> { 
static const struct attribute_group <token> = { <answer> cmodio_sysfs_attr_group 
.attrs <token> cmodio_sysfs_attrs, <answer> = 
static <token> cmodio_pci_probe(struct pci_dev *dev, <answer> int 
const <token> pci_device_id *id) <answer> struct 
struct <token> *priv; <answer> cmodio_device 
<token> ret; <answer> int 
priv = devm_kzalloc(&dev->dev, sizeof(*priv), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!priv) 
<token> -ENOMEM; <answer> return 
pci_set_drvdata(dev, <token> <answer> priv); 
<token> = dev; <answer> priv->pdev 
iowrite8(0xf, <token> <answer> &priv->ctrl->int_disable); 
<token> <asm/unaligned.h> <answer> #include 
<token> <linux/acpi.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/i2c.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/pm_runtime.h> <answer> #include 
#include <token> <answer> <media/v4l2-ctrls.h> 
#include <token> <answer> <media/v4l2-device.h> 
#include <token> <answer> <media/v4l2-fwnode.h> 
#define <token> 1 <answer> OG01A1B_REG_VALUE_08BIT 
#define <token> 2 <answer> OG01A1B_REG_VALUE_16BIT 
#define <token> 3 <answer> OG01A1B_REG_VALUE_24BIT 
#define OG01A1B_LINK_FREQ_500MHZ <token> <answer> 500000000ULL 
#define OG01A1B_SCLK <token> <answer> 120000000LL 
#define <token> 19200000 <answer> OG01A1B_MCLK 
#define <token> 2 <answer> OG01A1B_DATA_LANES 
#define OG01A1B_RGB_DEPTH <token> <answer> 10 
<token> OG01A1B_REG_CHIP_ID 0x300a <answer> #define 
#define OG01A1B_CHIP_ID <token> <answer> 0x470141 
<token> OG01A1B_REG_MODE_SELECT 0x0100 <answer> #define 
#define OG01A1B_MODE_STANDBY <token> <answer> 0x00 
#define OG01A1B_MODE_STREAMING <token> <answer> 0x01 
return <token> <answer> 0; 
<token> ret; <answer> return 
<token> CONFIG_ACPI <answer> #ifdef 
static const struct acpi_device_id og01a1b_acpi_ids[] <token> { <answer> = 
<token> og01a1b_acpi_ids); <answer> MODULE_DEVICE_TABLE(acpi, 
static <token> i2c_driver og01a1b_i2c_driver = { <answer> struct 
.driver <token> { <answer> = 
.name <token> "og01a1b", <answer> = 
.acpi_match_table <token> ACPI_PTR(og01a1b_acpi_ids), <answer> = 
.probe = <token> <answer> og01a1b_probe, 
.remove <token> og01a1b_remove, <answer> = 
<token> Tu"); <answer> MODULE_AUTHOR("Shawn 
MODULE_DESCRIPTION("OmniVision <token> sensor driver"); <answer> OG01A1B 
MODULE_LICENSE("GPL <token> <answer> v2"); 
#define gt215_ram(p) container_of((p), struct <token> base) <answer> gt215_ram, 
#include <token> <answer> "ram.h" 
#include <token> <answer> "ramfuc.h" 
#include <token> <answer> <core/memory.h> 
#include <token> <answer> <core/option.h> 
<token> <subdev/bios.h> <answer> #include 
<token> <subdev/bios/M0205.h> <answer> #include 
#include <token> <answer> <subdev/bios/rammap.h> 
#include <token> <answer> <subdev/bios/timing.h> 
#include <token> <answer> <subdev/clk/gt215.h> 
#include <token> <answer> <subdev/gpio.h> 
struct <token> { <answer> gt215_ramfuc 
<token> ramfuc base; <answer> struct 
struct <token> r_0x001610; <answer> ramfuc_reg 
struct <token> r_0x001700; <answer> ramfuc_reg 
struct ramfuc_reg <token> <answer> r_0x002504; 
struct <token> r_0x004000; <answer> ramfuc_reg 
<token> ramfuc_reg r_0x004004; <answer> struct 
struct ramfuc_reg <token> <answer> r_0x004018; 
struct <token> r_0x004128; <answer> ramfuc_reg 
struct <token> r_0x004168; <answer> ramfuc_reg 
<token> ramfuc_reg r_0x100080; <answer> struct 
<token> ramfuc_reg r_0x100200; <answer> struct 
struct <token> r_0x100210; <answer> ramfuc_reg 
struct <token> r_0x100220[9]; <answer> ramfuc_reg 
struct <token> r_0x100264; <answer> ramfuc_reg 
<token> ramfuc_reg r_0x1002d0; <answer> struct 
<token> ramfuc_reg r_0x1002d4; <answer> struct 
struct <token> r_0x1002dc; <answer> ramfuc_reg 
struct <token> r_0x10053c; <answer> ramfuc_reg 
<token> ramfuc_reg r_0x1005a0; <answer> struct 
struct ramfuc_reg <token> <answer> r_0x1005a4; 
<token> ramfuc_reg r_0x100700; <answer> struct 
struct <token> r_0x100714; <answer> ramfuc_reg 
struct <token> r_0x100718; <answer> ramfuc_reg 
struct ramfuc_reg <token> <answer> r_0x10071c; 
struct <token> r_0x100720; <answer> ramfuc_reg 
struct <token> r_0x100760; <answer> ramfuc_reg 
<token> ramfuc_reg r_0x1007a0; <answer> struct 
struct ramfuc_reg <token> <answer> r_0x1007e0; 
struct <token> r_0x100da0; <answer> ramfuc_reg 
struct <token> r_0x10f804; <answer> ramfuc_reg 
struct <token> r_0x1110e0; <answer> ramfuc_reg 
<token> ramfuc_reg r_0x111100; <answer> struct 
<token> ramfuc_reg r_0x111104; <answer> struct 
<token> ramfuc_reg r_0x1111e0; <answer> struct 
<token> ramfuc_reg r_0x111400; <answer> struct 
struct <token> r_0x611200; <answer> ramfuc_reg 
struct ramfuc_reg <token> <answer> r_mr[4]; 
struct ramfuc_reg <token> <answer> r_gpio[4]; 
struct gt215_ltrain <token> <answer> { 
<token> { <answer> enum 
<token> state; <answer> } 
<token> r_100720; <answer> u32 
u32 <token> <answer> r_1111e0; 
<token> r_111400; <answer> u32 
struct nvkm_memory <token> <answer> *memory; 
<token> gt215_ram { <answer> struct 
struct nvkm_ram <token> <answer> base; 
struct <token> fuc; <answer> gt215_ramfuc 
struct <token> ltrain; <answer> gt215_ltrain 
<token> void <answer> static 
<token> *vals, struct gt215_ltrain *train) <answer> gt215_link_train_calc(u32 
int i, lo, <token> <answer> hi; 
u8 median[8], bins[4] = {0, 0, <token> 0}, bin = 0, qty = 0; <answer> 0, 
for (i = 0; i <token> 8; i++) { <answer> < 
for (lo = 0; lo < 0x40; lo++) <token> <answer> { 
if (!(vals[lo] & <token> <answer> 0x80000000)) 
if (vals[lo] & (0x101 << <token> <answer> i)) 
<token> (lo == 0x40) <answer> if 
for (hi = lo + <token> hi < 0x40; hi++) { <answer> 1; 
<token> (!(vals[lo] & 0x80000000)) <answer> if 
<token> (!(vals[hi] & (0x101 << i))) { <answer> if 
median[i] = ((hi - <token> >> 1) + lo; <answer> lo) 
bins[(median[i] & <token> >> 4]++; <answer> 0xf0) 
median[i] <token> 0x30; <answer> += 
<token> int <answer> static 
gt215_link_train(struct <token> *ram) <answer> gt215_ram 
struct gt215_ltrain *train = <token> <answer> &ram->ltrain; 
struct gt215_ramfuc *fuc <token> &ram->fuc; <answer> = 
<token> nvkm_subdev *subdev = &ram->base.fb->subdev; <answer> struct 
struct <token> *device = subdev->device; <answer> nvkm_device 
struct nvkm_bios <token> = device->bios; <answer> *bios 
struct <token> *clk = device->clk; <answer> nvkm_clk 
u32 <token> r1700; <answer> *result, 
int ret, <token> <answer> i; 
struct nvbios_M0205T M0205T <token> { 0 }; <answer> = 
u8 ver, hdr, cnt, len, <token> ssz; <answer> snr, 
<token> int clk_current; <answer> unsigned 
<token> long flags; <answer> unsigned 
unsigned <token> *f = &flags; <answer> long 
if (nvkm_boolopt(device->cfgopt, "NvMemExec", true) <token> true) <answer> != 
<token> -ENOSYS; <answer> return 
if (!nvbios_M0205Ep(bios, i, <token> &hdr, &cnt, &len, &M0205E)) <answer> &ver, 
return <token> <answer> -ENOENT; 
if (M0205E.type != <token> <answer> 5) 
<token> 0; <answer> return 
train->state = <token> <answer> NVA3_TRAIN_ONCE; 
ret = nvkm_ram_get(device, NVKM_RAM_MM_NORMAL, <token> 16, 0x8000, <answer> 0x01, 
true, true, <token> <answer> &ram->ltrain.memory); 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> = nvkm_memory_addr(ram->ltrain.memory); <answer> addr 
nvkm_wr32(device, 0x100538, 0x10000000 | (addr >> <token> <answer> 16)); 
<token> 0x1005a8, 0x0000ffff); <answer> nvkm_wr32(device, 
nvkm_mask(device, 0x10f800, <token> 0x00000001); <answer> 0x00000001, 
for (i <token> 0; i < 0x30; i++) { <answer> = 
nvkm_wr32(device, 0x10f8c0, (i << 8) | <token> <answer> i); 
nvkm_wr32(device, <token> pattern[i % 16]); <answer> 0x10f900, 
for (i <token> 0; i < 0x30; i++) { <answer> = 
nvkm_wr32(device, 0x10f8e0, <token> << 8) | i); <answer> (i 
nvkm_wr32(device, 0x10f920, <token> % 16]); <answer> pattern[i 
<token> T(t) cfg->timing_10_##t <answer> #define 
static <token> <answer> int 
gt215_ram_timing_calc(struct gt215_ram *ram, u32 <token> <answer> *timing) 
struct <token> *cfg = &ram->base.target.bios; <answer> nvbios_ramcfg 
struct nvkm_subdev *subdev <token> &ram->base.fb->subdev; <answer> = 
struct nvkm_device *device = <token> <answer> subdev->device; 
<token> tUNK_base, tUNK_40_0, prevCL; <answer> int 
u32 cur2, cur3, cur7, <token> <answer> cur8; 
<token> = nvkm_rd32(device, 0x100228); <answer> cur2 
cur3 = nvkm_rd32(device, <token> <answer> 0x10022c); 
cur7 = <token> 0x10023c); <answer> nvkm_rd32(device, 
cur8 <token> nvkm_rd32(device, 0x100240); <answer> = 
switch ((!T(CWL)) <token> ram->base.type) { <answer> * 
<token> NVKM_RAM_TYPE_DDR2: <answer> case 
T(CWL) = T(CL) - <token> <answer> 1; 
<token> NVKM_RAM_TYPE_GDDR3: <answer> case 
T(CWL) <token> ((cur2 & 0xff000000) >> 24) + 1; <answer> = 
prevCL = (cur3 & <token> + 1; <answer> 0x000000ff) 
tUNK_base = ((cur7 & 0x00ff0000) >> 16) <token> prevCL; <answer> - 
timing[0] = (T(RP) << 24 | <token> << 16 | T(RFC) << 8 | T(RC)); <answer> T(RAS) 
timing[1] <token> (T(WR) + 1 + T(CWL)) << 24 | <answer> = 
max_t(u8,T(18), 1) << <token> | <answer> 16 
(T(WTR) + 1 + T(CWL)) << 8 <token> <answer> | 
(5 + <token> - T(CWL)); <answer> T(CL) 
timing[2] = (T(CWL) - 1) << 24 <token> <answer> | 
(T(RRD) << 16) <token> <answer> | 
(T(RCDWR) << <token> | <answer> 8) 
timing[3] = (cur3 & <token> | <answer> 0x00ff0000) 
(0x30 + T(CL)) << 24 <token> <answer> | 
(0xb + T(CL)) << 8 <token> <answer> | 
<token> - 1); <answer> (T(CL) 
timing[4] = T(20) << <token> | <answer> 24 
T(21) <token> 16 | <answer> << 
T(13) << <token> | <answer> 8 
timing[5] = T(RFC) << 24 <token> <answer> | 
<token> T(RCDWR)) << 16 | <answer> max_t(u8,T(RCDRD), 
max_t(u8, (T(CWL) + 6), (T(CL) + 2)) << 8 <token> <answer> | 
timing[6] = <token> + T(CL)) << 16 | <answer> (0x5a 
max_t(u8, 1, (6 <token> T(CL) + T(CWL))) << 8 | <answer> - 
(0x50 <token> T(CL) - T(CWL)); <answer> + 
timing[7] = (cur7 & <token> | <answer> 0xff000000) 
((tUNK_base + T(CL)) << 16) <token> <answer> | 
timing[8] = <token> & 0xffffff00; <answer> cur8 
switch (ram->base.type) <token> <answer> { 
<token> NVKM_RAM_TYPE_DDR2: <answer> case 
case <token> <answer> NVKM_RAM_TYPE_GDDR3: 
tUNK_40_0 = prevCL - (cur8 & <token> <answer> 0xff); 
if (tUNK_40_0 > <token> <answer> 0) 
timing[8] <token> T(CL); <answer> |= 
nvkm_debug(subdev, "Entry: 220: %08x <token> %08x %08x\n", <answer> %08x 
<token> timing[1], timing[2], timing[3]); <answer> timing[0], 
nvkm_debug(subdev, " 230: %08x %08x <token> %08x\n", <answer> %08x 
timing[4], timing[5], <token> timing[7]); <answer> timing[6], 
nvkm_debug(subdev, " 240: <token> timing[8]); <answer> %08x\n", 
<token> 0; <answer> return 
#undef <token> <answer> T 
<token> void <answer> static 
nvkm_sddr2_dll_reset(struct <token> *fuc) <answer> gt215_ramfuc 
ram_mask(fuc, <token> 0x100, 0x100); <answer> mr[0], 
<token> 1000); <answer> ram_nsec(fuc, 
ram_mask(fuc, <token> 0x100, 0x000); <answer> mr[0], 
<token> 1000); <answer> ram_nsec(fuc, 
<token> void <answer> static 
nvkm_sddr3_dll_disable(struct gt215_ramfuc <token> u32 *mr) <answer> *fuc, 
u32 mr1_old = ram_rd32(fuc, <token> <answer> mr[1]); 
if (!(mr1_old <token> 0x1)) { <answer> & 
ram_wr32(fuc, 0x1002d4, <token> <answer> 0x00000001); 
ram_wr32(fuc, <token> mr[1]); <answer> mr[1], 
ram_nsec(fuc, <token> <answer> 1000); 
static <token> <answer> void 
nvkm_gddr3_dll_disable(struct gt215_ramfuc <token> u32 *mr) <answer> *fuc, 
u32 mr1_old <token> ram_rd32(fuc, mr[1]); <answer> = 
<token> (!(mr1_old & 0x40)) { <answer> if 
<token> mr[1], mr[1]); <answer> ram_wr32(fuc, 
<token> 1000); <answer> ram_nsec(fuc, 
<token> void <answer> static 
gt215_ram_lock_pll(struct gt215_ramfuc *fuc, <token> gt215_clk_info *mclk) <answer> struct 
ram_wr32(fuc, <token> mclk->pll); <answer> 0x004004, 
ram_mask(fuc, <token> 0x00000001, 0x00000001); <answer> 0x004000, 
<token> 0x004000, 0x00000010, 0x00000000); <answer> ram_mask(fuc, 
ram_wait(fuc, 0x004000, <token> 0x00020000, 64000); <answer> 0x00020000, 
ram_mask(fuc, 0x004000, <token> 0x00000010); <answer> 0x00000010, 
<token> void <answer> static 
gt215_ram_gpio(struct gt215_ramfuc *fuc, u8 tag, <token> val) <answer> u32 
<token> nvkm_gpio *gpio = fuc->base.fb->subdev.device->gpio; <answer> struct 
struct <token> func; <answer> dcb_gpio_func 
u32 reg, sh, <token> <answer> gpio_val; 
int <token> <answer> ret; 
if (nvkm_gpio_get(gpio, 0, tag, <token> != val) { <answer> DCB_GPIO_UNUSED) 
<token> = nvkm_gpio_find(gpio, 0, tag, DCB_GPIO_UNUSED, &func); <answer> ret 
if <token> <answer> (ret) 
reg = func.line <token> 3; <answer> >> 
sh = <token> & 0x7) << 2; <answer> (func.line 
<token> = ram_rd32(fuc, gpio[reg]); <answer> gpio_val 
if <token> & (8 << sh)) <answer> (gpio_val 
val = <token> <answer> !val; 
if <token> & 1)) <answer> (!(func.log[1] 
<token> = !val; <answer> val 
ram_mask(fuc, gpio[reg], (0x3 << sh), <token> | 0x2) << sh)); <answer> ((val 
ram_nsec(fuc, <token> <answer> 20000); 
<token> int <answer> static 
<token> nvkm_ram *base, u32 freq) <answer> gt215_ram_calc(struct 
<token> gt215_ram *ram = gt215_ram(base); <answer> struct 
struct gt215_ramfuc <token> = &ram->fuc; <answer> *fuc 
struct gt215_ltrain <token> = &ram->ltrain; <answer> *train 
struct nvkm_subdev <token> = &ram->base.fb->subdev; <answer> *subdev 
struct nvkm_device <token> = subdev->device; <answer> *device 
struct nvkm_bios <token> = device->bios; <answer> *bios 
struct gt215_clk_info <token> <answer> mclk; 
struct nvkm_gpio *gpio = <token> <answer> device->gpio; 
struct nvkm_ram_data <token> <answer> *next; 
u8 ver, <token> cnt, len, strap; <answer> hdr, 
u32 <token> <answer> data; 
u32 r004018, <token> r100da0, r111100, ctrl; <answer> r100760, 
<token> unk714, unk718, unk71c; <answer> u32 
<token> ret, i; <answer> int 
<token> timing[9]; <answer> u32 
bool <token> <answer> pll2pll; 
next <token> &ram->base.target; <answer> = 
<token> = freq; <answer> next->freq 
<token> = next; <answer> ram->base.next 
<token> (ram->ltrain.state == NVA3_TRAIN_ONCE) <answer> if 
if (nvkm_gpio_get(gpio, 0, 0x18, <token> == <answer> DCB_GPIO_UNUSED) 
<token> { <answer> next->bios.ramcfg_FBVDDQ) 
data = <token> 0x004000) & 0x9; <answer> ram_rd32(fuc, 
if (data == <token> <answer> 0x1) 
ram_mask(fuc, <token> 0x8, 0x8); <answer> 0x004000, 
if (data <token> 0x1) <answer> & 
ram_mask(fuc, 0x004000, 0x1, <token> <answer> 0x0); 
gt215_ram_gpio(fuc, 0x18, <token> <answer> !next->bios.ramcfg_FBVDDQ); 
if (data & <token> <answer> 0x1) 
ram_mask(fuc, 0x004000, <token> 0x1); <answer> 0x1, 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/i2c.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/iopoll.h> 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/io.h> 
<token> <linux/of_address.h> <answer> #include 
<token> <linux/of_irq.h> <answer> #include 
#include <token> <answer> <linux/spinlock.h> 
<token> <linux/clk.h> <answer> #include 
#include <token> <answer> <linux/wait.h> 
#include <token> <answer> <linux/mfd/syscon.h> 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/math64.h> 
#define <token> ((mod) << 1) <answer> REG_CON_MOD(mod) 
#define <token> (BIT(1) | BIT(2)) <answer> REG_CON_MOD_MASK 
#define REG_CON_START <token> <answer> BIT(3) 
#define REG_CON_STOP <token> <answer> BIT(4) 
struct <token> { <answer> i2c_spec_values 
<token> long min_hold_start_ns; <answer> unsigned 
unsigned long <token> <answer> min_low_ns; 
unsigned <token> min_high_ns; <answer> long 
unsigned <token> min_setup_start_ns; <answer> long 
<token> long max_data_hold_ns; <answer> unsigned 
unsigned long <token> <answer> min_data_setup_ns; 
<token> long min_setup_stop_ns; <answer> unsigned 
unsigned long <token> <answer> min_hold_buffer_ns; 
static const struct i2c_spec_values standard_mode_spec = <token> <answer> { 
<token> = 4000, <answer> .min_hold_start_ns 
.min_low_ns = <token> <answer> 4700, 
.min_high_ns = <token> <answer> 4000, 
.min_setup_start_ns = <token> <answer> 4700, 
.max_data_hold_ns <token> 3450, <answer> = 
.min_data_setup_ns = <token> <answer> 250, 
<token> = 4000, <answer> .min_setup_stop_ns 
.min_hold_buffer_ns = <token> <answer> 4700, 
static <token> struct i2c_spec_values fast_mode_spec = { <answer> const 
<token> = 600, <answer> .min_hold_start_ns 
.min_low_ns <token> 1300, <answer> = 
.min_high_ns = <token> <answer> 600, 
<token> = 600, <answer> .min_setup_start_ns 
.max_data_hold_ns = <token> <answer> 900, 
.min_data_setup_ns = <token> <answer> 100, 
<token> = 600, <answer> .min_setup_stop_ns 
.min_hold_buffer_ns = <token> <answer> 1300, 
static const struct <token> fast_mode_plus_spec = { <answer> i2c_spec_values 
.min_hold_start_ns = <token> <answer> 260, 
.min_low_ns = <token> <answer> 500, 
<token> = 260, <answer> .min_high_ns 
.min_setup_start_ns <token> 260, <answer> = 
.max_data_hold_ns = <token> <answer> 400, 
<token> = 50, <answer> .min_data_setup_ns 
.min_setup_stop_ns <token> 260, <answer> = 
.min_hold_buffer_ns = <token> <answer> 500, 
struct rk3x_i2c_calced_timings <token> <answer> { 
unsigned long <token> <answer> div_low; 
unsigned <token> div_high; <answer> long 
<token> int tuning; <answer> unsigned 
enum rk3x_i2c_state <token> <answer> { 
struct <token> { <answer> rk3x_i2c_soc_data 
<token> grf_offset; <answer> int 
int (*calc_timings)(unsigned <token> struct i2c_timings *, <answer> long, 
struct <token> *); <answer> rk3x_i2c_calced_timings 
struct rk3x_i2c <token> <answer> { 
<token> i2c_adapter adap; <answer> struct 
<token> device *dev; <answer> struct 
const struct <token> *soc_data; <answer> rk3x_i2c_soc_data 
static void rk3x_i2c_start(struct <token> *i2c) <answer> rk3x_i2c 
u32 val = <token> REG_CON) & REG_CON_TUNING_MASK; <answer> i2c_readl(i2c, 
i2c_writel(i2c, REG_INT_START, <token> <answer> REG_IEN); 
<token> void rk3x_i2c_stop(struct rk3x_i2c *i2c, int error) <answer> static 
unsigned <token> ctrl; <answer> int 
<token> = 0; <answer> i2c->processed 
i2c->msg = <token> <answer> NULL; 
i2c->error <token> error; <answer> = 
if <token> { <answer> (i2c->is_last_msg) 
ctrl = i2c_readl(i2c, REG_CON) <token> REG_CON_TUNING_MASK; <answer> & 
<token> ctrl, REG_CON); <answer> i2c_writel(i2c, 
static <token> rk3x_i2c_prepare_read(struct rk3x_i2c *i2c) <answer> void 
unsigned int len = <token> - i2c->processed; <answer> i2c->msg->len 
<token> con; <answer> u32 
con = <token> REG_CON); <answer> i2c_readl(i2c, 
if (len > <token> { <answer> 32) 
len <token> 32; <answer> = 
<token> &= ~REG_CON_LASTACK; <answer> con 
} else <token> <answer> { 
<token> |= REG_CON_LASTACK; <answer> con 
static <token> rk3x_i2c_fill_transmit_buf(struct rk3x_i2c *i2c) <answer> void 
unsigned <token> i, j; <answer> int 
u32 cnt = <token> <answer> 0; 
<token> val; <answer> u32 
<token> byte; <answer> u8 
<token> (i = 0; i < 8; ++i) { <answer> for 
val <token> 0; <answer> = 
for (j = 0; j <token> 4; ++j) { <answer> < 
if <token> == i2c->msg->len) && (cnt != 0)) <answer> ((i2c->processed 
if (i2c->processed == <token> && cnt == 0) <answer> 0 
byte = (i2c->addr <token> 0x7f) << 1; <answer> & 
byte <token> i2c->msg->buf[i2c->processed++]; <answer> = 
val <token> byte << (j * 8); <answer> |= 
i2c_writel(i2c, <token> TXBUFFER_BASE + 4 * i); <answer> val, 
if (i2c->processed == <token> <answer> i2c->msg->len) 
<token> cnt, REG_MTXCNT); <answer> i2c_writel(i2c, 
i2c_writel(i2c, REG_INT_NAKRCV, <token> <answer> REG_IPD); 
ipd <token> ~REG_INT_NAKRCV; <answer> &= 
if (!(i2c->msg->flags & <token> <answer> I2C_M_IGNORE_NAK)) 
<token> -ENXIO); <answer> rk3x_i2c_stop(i2c, 
static const struct i2c_spec_values <token> int speed) <answer> *rk3x_i2c_get_spec(unsigned 
if (speed <= <token> <answer> I2C_MAX_STANDARD_MODE_FREQ) 
return <token> <answer> &standard_mode_spec; 
else if (speed <= <token> <answer> I2C_MAX_FAST_MODE_FREQ) 
return <token> <answer> &fast_mode_spec; 
<token> &fast_mode_plus_spec; <answer> return 
static int <token> long clk_rate, <answer> rk3x_i2c_v0_calc_timings(unsigned 
struct i2c_timings <token> <answer> *t, 
struct <token> *t_calc) <answer> rk3x_i2c_calced_timings 
unsigned long min_low_ns, <token> <answer> min_high_ns; 
<token> long max_low_ns, min_total_ns; <answer> unsigned 
<token> long clk_rate_khz, scl_rate_khz; <answer> unsigned 
unsigned long <token> min_high_div; <answer> min_low_div, 
unsigned <token> max_low_div; <answer> long 
unsigned long min_div_for_hold, <token> <answer> min_total_div; 
unsigned long extra_div, <token> ideal_low_div; <answer> extra_low_div, 
unsigned long data_hold_buffer_ns = <token> <answer> 50; 
const struct <token> *spec; <answer> i2c_spec_values 
int ret = <token> <answer> 0; 
<token> = rk3x_i2c_get_spec(t->bus_freq_hz); <answer> spec 
<token> = t->scl_rise_ns + spec->min_high_ns; <answer> min_high_ns 
min_high_ns = <token> DIV_ROUND_UP( <answer> max(min_high_ns, 
(t->scl_rise_ns + spec->min_setup_start_ns) * 1000, <token> <answer> 875)); 
min_high_ns <token> max(min_high_ns, DIV_ROUND_UP( <answer> = 
(t->scl_rise_ns + spec->min_setup_start_ns <token> t->sda_fall_ns + <answer> + 
spec->min_high_ns), <token> <answer> 2)); 
min_low_ns = t->scl_fall_ns + <token> <answer> spec->min_low_ns; 
max_low_ns = spec->max_data_hold_ns * 2 <token> data_hold_buffer_ns; <answer> - 
min_total_ns = <token> + min_high_ns; <answer> min_low_ns 
min_total_div <token> DIV_ROUND_UP(clk_rate_khz, scl_rate_khz * 8); <answer> = 
max_low_div <token> clk_rate_khz * max_low_ns / (8 * 1000000); <answer> = 
<token> (min_low_div > max_low_div) { <answer> if 
<token> min_low_div %lu, max_low_div %lu\n", <answer> "Conflicting, 
<token> max_low_div); <answer> min_low_div, 
max_low_div = <token> <answer> min_low_div; 
if (min_div_for_hold <token> min_total_div) { <answer> > 
t_calc->div_low <token> min_low_div; <answer> = 
<token> = min_high_div; <answer> t_calc->div_high 
<token> else { <answer> } 
extra_div = <token> - min_div_for_hold; <answer> min_total_div 
ideal_low_div = DIV_ROUND_UP(clk_rate_khz * <token> <answer> min_low_ns, 
<token> * 8 * min_total_ns); <answer> scl_rate_khz 
if <token> > min_low_div + extra_div) <answer> (ideal_low_div 
ideal_low_div = <token> + extra_div; <answer> min_low_div 
<token> int rk3x_i2c_v1_calc_timings(unsigned long clk_rate, <answer> static 
<token> i2c_timings *t, <answer> struct 
struct <token> *t_calc) <answer> rk3x_i2c_calced_timings 
<token> long min_low_ns, min_high_ns; <answer> unsigned 
<token> long min_setup_start_ns, min_setup_data_ns; <answer> unsigned 
unsigned long min_setup_stop_ns, <token> <answer> max_hold_data_ns; 
unsigned <token> clk_rate_khz, scl_rate_khz; <answer> long 
unsigned long min_low_div, <token> <answer> min_high_div; 
unsigned long <token> min_total_div; <answer> min_div_for_hold, 
unsigned long extra_div, <token> <answer> extra_low_div; 
unsigned long sda_update_cfg, <token> stp_sto_cfg; <answer> stp_sta_cfg, 
const struct i2c_spec_values <token> <answer> *spec; 
int <token> = 0; <answer> ret 
<token> = rk3x_i2c_get_spec(t->bus_freq_hz); <answer> spec 
min_high_div = (min_high_div < <token> ? 2 : min_high_div; <answer> 1) 
min_low_div = (min_low_div < 1) <token> 2 : min_low_div; <answer> ? 
<token> (min_div_for_hold >= min_total_div) { <answer> if 
<token> = min_low_div; <answer> t_calc->div_low 
t_calc->div_high = <token> <answer> min_high_div; 
<token> else { <answer> } 
extra_div <token> min_total_div - min_div_for_hold; <answer> = 
extra_low_div = DIV_ROUND_UP(min_low_div <token> extra_div, <answer> * 
t_calc->div_low <token> min_low_div + extra_low_div; <answer> = 
t_calc->div_high = min_high_div + (extra_div - <token> <answer> extra_low_div); 
for (sda_update_cfg = 3; sda_update_cfg > 0; <token> { <answer> sda_update_cfg--) 
max_hold_data_ns = <token> <answer> DIV_ROUND_UP((sda_update_cfg 
* (t_calc->div_low) <token> 1) <answer> + 
<token> 1000000, clk_rate_khz); <answer> * 
min_setup_data_ns = DIV_ROUND_UP(((8 <token> sda_update_cfg) <answer> - 
* (t_calc->div_low) + <token> <answer> 1) 
<token> 1000000, clk_rate_khz); <answer> * 
<token> ((max_hold_data_ns < spec->max_data_hold_ns) && <answer> if 
(min_setup_data_ns <token> spec->min_data_setup_ns)) <answer> > 
static int rk3x_i2c_clk_notifier_cb(struct notifier_block *nb, <token> long <answer> unsigned 
<token> void *data) <answer> event, 
struct clk_notifier_data *ndata <token> data; <answer> = 
struct rk3x_i2c *i2c = container_of(nb, <token> rk3x_i2c, clk_rate_nb); <answer> struct 
<token> rk3x_i2c_calced_timings calc; <answer> struct 
switch (event) <token> <answer> { 
<token> PRE_RATE_CHANGE: <answer> case 
<token> (i2c->soc_data->calc_timings(ndata->new_rate, &i2c->t, <answer> if 
&calc) != <token> <answer> 0) 
<token> NOTIFY_STOP; <answer> return 
static int rk3x_i2c_setup(struct rk3x_i2c *i2c, struct i2c_msg *msgs, int <token> <answer> num) 
u32 addr = (msgs[0].addr & 0x7f) <token> 1; <answer> << 
int <token> = 0; <answer> ret 
if (num >= 2 && msgs[0].len < 4 <token> <answer> && 
!(msgs[0].flags & <token> && (msgs[1].flags & I2C_M_RD)) { <answer> I2C_M_RD) 
u32 <token> = 0; <answer> reg_addr 
int <token> <answer> i; 
dev_dbg(i2c->dev, "Combined write/read <token> addr 0x%x\n", <answer> from 
addr >> <token> <answer> 1); 
if (msgs[0].flags & I2C_M_RD) <token> <answer> { 
i2c->mode <token> REG_CON_MOD_REGISTER_TX; <answer> = 
i2c_writel(i2c, addr | <token> <answer> REG_MRXADDR_VALID(0), 
<token> 0, REG_MRXRADDR); <answer> i2c_writel(i2c, 
} <token> { <answer> else 
i2c->mode = <token> <answer> REG_CON_MOD_TX; 
i2c->msg <token> &msgs[0]; <answer> = 
<token> = 1; <answer> ret 
i2c->addr = <token> <answer> msgs[0].addr; 
i2c->busy <token> true; <answer> = 
i2c->state <token> STATE_START; <answer> = 
i2c->processed <token> 0; <answer> = 
<token> = 0; <answer> i2c->error 
return <token> <answer> ret; 
static int rk3x_i2c_wait_xfer_poll(struct <token> *i2c) <answer> rk3x_i2c 
ktime_t timeout = <token> WAIT_TIMEOUT); <answer> ktime_add_ms(ktime_get(), 
while (READ_ONCE(i2c->busy) <token> <answer> && 
ktime_compare(ktime_get(), timeout) < 0) <token> <answer> { 
rk3x_i2c_irq(0, <token> <answer> i2c); 
return <token> <answer> !i2c->busy; 
static <token> rk3x_i2c_xfer_common(struct i2c_adapter *adap, <answer> int 
struct i2c_msg *msgs, int num, <token> polling) <answer> bool 
struct rk3x_i2c *i2c = (struct <token> *)adap->algo_data; <answer> rk3x_i2c 
unsigned <token> timeout, flags; <answer> long 
u32 <token> <answer> val; 
<token> ret = 0; <answer> int 
<token> i; <answer> int 
spin_lock_irqsave(&i2c->lock, <token> <answer> flags); 
<token> = false; <answer> i2c->is_last_msg 
<token> (i = 0; i < num; i += ret) { <answer> for 
ret = rk3x_i2c_setup(i2c, msgs + i, num <token> i); <answer> - 
if (ret < <token> { <answer> 0) 
dev_err(i2c->dev, <token> failed\n"); <answer> "rk3x_i2c_setup() 
if (i + ret <token> num) <answer> >= 
i2c->is_last_msg <token> true; <answer> = 
<token> flags); <answer> spin_unlock_irqrestore(&i2c->lock, 
<token> (!polling) { <answer> if 
timeout = wait_event_timeout(i2c->wait, <token> <answer> !i2c->busy, 
} <token> { <answer> else 
timeout <token> rk3x_i2c_wait_xfer_poll(i2c); <answer> = 
spin_lock_irqsave(&i2c->lock, <token> <answer> flags); 
if (timeout == 0) <token> <answer> { 
dev_err(i2c->dev, "timeout, ipd: <token> state: %d\n", <answer> 0x%02x, 
<token> REG_IPD), i2c->state); <answer> i2c_readl(i2c, 
if (i2c->soc_data->grf_offset <token> 0) { <answer> >= 
struct <token> *grf; <answer> regmap 
grf = <token> "rockchip,grf"); <answer> syscon_regmap_lookup_by_phandle(np, 
if <token> { <answer> (IS_ERR(grf)) 
"rk3x-i2c <token> 'rockchip,grf' property\n"); <answer> needs 
<token> PTR_ERR(grf); <answer> return 
if (bus_nr < <token> { <answer> 0) 
<token> "rk3x-i2c needs i2cX alias"); <answer> dev_err(&pdev->dev, 
return <token> <answer> -EINVAL; 
#include <token> <answer> <linux/pagemap.h> 
<token> <linux/writeback.h> <answer> #include 
<token> <linux/page-flags.h> <answer> #include 
#include <token> <answer> <linux/mount.h> 
#include <token> <answer> <linux/file.h> 
<token> <linux/scatterlist.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/xattr.h> <answer> #include 
#include <token> <answer> <asm/unaligned.h> 
#include <token> <answer> "ecryptfs_kernel.h" 
struct page <token> inode *inode, loff_t index) <answer> *ecryptfs_get_locked_page(struct 
struct page *page = <token> index, NULL); <answer> read_mapping_page(inode->i_mapping, 
<token> (!IS_ERR(page)) <answer> if 
return <token> <answer> page; 
static int ecryptfs_writepage(struct page *page, struct <token> *wbc) <answer> writeback_control 
int <token> <answer> rc; 
rc <token> ecryptfs_encrypt_page(page); <answer> = 
if (rc) <token> <answer> { 
ecryptfs_printk(KERN_WARNING, "Error encrypting <token> <answer> " 
"page (upper index [0x%.16lx])\n", <token> <answer> page->index); 
goto <token> <answer> out; 
<token> rc; <answer> return 
static void <token> *page_virt, <answer> strip_xattr_flag(char 
<token> ecryptfs_crypt_stat *crypt_stat) <answer> struct 
if (crypt_stat->flags & ECRYPTFS_METADATA_IN_XATTR) <token> <answer> { 
<token> written; <answer> size_t 
<token> &= ~ECRYPTFS_METADATA_IN_XATTR; <answer> crypt_stat->flags 
ecryptfs_write_crypt_stat_flags(page_virt, <token> <answer> crypt_stat, 
crypt_stat->flags |= <token> <answer> ECRYPTFS_METADATA_IN_XATTR; 
<token> int <answer> static 
ecryptfs_copy_up_encrypted_with_header(struct page <token> <answer> *page, 
struct ecryptfs_crypt_stat <token> <answer> *crypt_stat) 
loff_t extent_num_in_page <token> 0; <answer> = 
loff_t <token> = (PAGE_SIZE <answer> num_extents_per_page 
/ <token> <answer> crypt_stat->extent_size); 
int rc = <token> <answer> 0; 
<token> (extent_num_in_page < num_extents_per_page) { <answer> while 
loff_t view_extent_num <token> ((((loff_t)page->index) <answer> = 
<token> num_extents_per_page) <answer> * 
+ <token> <answer> extent_num_in_page); 
<token> num_header_extents_at_front = <answer> size_t 
<token> / crypt_stat->extent_size); <answer> (crypt_stat->metadata_size 
if <token> < num_header_extents_at_front) { <answer> (view_extent_num 
static int ecryptfs_read_folio(struct <token> *file, struct folio *folio) <answer> file 
struct page *page = <token> <answer> &folio->page; 
struct ecryptfs_crypt_stat <token> = <answer> *crypt_stat 
int rc <token> 0; <answer> = 
if <token> || !(crypt_stat->flags & ECRYPTFS_ENCRYPTED)) { <answer> (!crypt_stat 
rc = ecryptfs_read_lower_page_segment(page, page->index, <token> <answer> 0, 
} else <token> (crypt_stat->flags & ECRYPTFS_VIEW_AS_ENCRYPTED) { <answer> if 
if <token> & ECRYPTFS_METADATA_IN_XATTR) { <answer> (crypt_stat->flags 
rc = <token> <answer> ecryptfs_copy_up_encrypted_with_header(page, 
<token> (rc) { <answer> if 
printk(KERN_ERR <token> Error attempting to copy " <answer> "%s: 
"the <token> content from the lower " <answer> encrypted 
"file whilst inserting the <token> " <answer> metadata 
<token> the xattr into the header; rc = " <answer> "from 
"[%d]\n", __func__, <token> <answer> rc); 
<token> out; <answer> goto 
<token> else { <answer> } 
rc <token> ecryptfs_read_lower_page_segment( <answer> = 
page, page->index, 0, <token> <answer> PAGE_SIZE, 
<token> (rc) { <answer> if 
<token> "Error reading page; rc = " <answer> printk(KERN_ERR 
<token> rc); <answer> "[%d]\n", 
<token> out; <answer> goto 
<token> else { <answer> } 
rc = <token> <answer> ecryptfs_decrypt_page(page); 
if <token> { <answer> (rc) 
<token> "Error decrypting page; " <answer> ecryptfs_printk(KERN_ERR, 
"rc = [%d]\n", <token> <answer> rc); 
goto <token> <answer> out; 
<token> (rc) <answer> if 
ecryptfs_printk(KERN_DEBUG, "Unlocking <token> with index = [0x%.16lx]\n", <answer> page 
return <token> <answer> rc; 
static int fill_zeros_to_end_of_page(struct page *page, unsigned int <token> <answer> to) 
<token> inode *inode = page->mapping->host; <answer> struct 
int <token> <answer> end_byte_in_page; 
if ((i_size_read(inode) / PAGE_SIZE) != <token> <answer> page->index) 
goto <token> <answer> out; 
end_byte_in_page = i_size_read(inode) <token> PAGE_SIZE; <answer> % 
<token> (to > end_byte_in_page) <answer> if 
end_byte_in_page = <token> <answer> to; 
zero_user_segment(page, <token> PAGE_SIZE); <answer> end_byte_in_page, 
return <token> <answer> 0; 
static <token> ecryptfs_write_begin(struct file *file, <answer> int 
<token> address_space *mapping, <answer> struct 
loff_t <token> unsigned len, <answer> pos, 
struct page <token> void **fsdata) <answer> **pagep, 
pgoff_t index = <token> >> PAGE_SHIFT; <answer> pos 
<token> page *page; <answer> struct 
loff_t <token> <answer> prev_page_end_size; 
int rc = <token> <answer> 0; 
page = <token> index); <answer> grab_cache_page_write_begin(mapping, 
if <token> <answer> (!page) 
<token> -ENOMEM; <answer> return 
*pagep = <token> <answer> page; 
prev_page_end_size <token> ((loff_t)index << PAGE_SHIFT); <answer> = 
<token> (!PageUptodate(page)) { <answer> if 
struct ecryptfs_crypt_stat *crypt_stat <token> <answer> = 
if (!(crypt_stat->flags & ECRYPTFS_ENCRYPTED)) <token> <answer> { 
<token> = ecryptfs_read_lower_page_segment( <answer> rc 
page, index, 0, <token> mapping->host); <answer> PAGE_SIZE, 
if <token> { <answer> (rc) 
printk(KERN_ERR "%s: Error attempting to <token> " <answer> read 
"lower <token> segment; rc = [%d]\n", <answer> page 
__func__, <token> <answer> rc); 
goto <token> <answer> out; 
} <token> <answer> else 
} else if (crypt_stat->flags & <token> { <answer> ECRYPTFS_VIEW_AS_ENCRYPTED) 
<token> (crypt_stat->flags & ECRYPTFS_METADATA_IN_XATTR) { <answer> if 
rc <token> ecryptfs_copy_up_encrypted_with_header( <answer> = 
<token> crypt_stat); <answer> page, 
<token> (rc) { <answer> if 
printk(KERN_ERR <token> Error attempting " <answer> "%s: 
"to copy the encrypted <token> " <answer> content 
"from the lower <token> whilst " <answer> file 
<token> the metadata from " <answer> "inserting 
<token> xattr into the header; rc " <answer> "the 
<token> [%d]\n", __func__, rc); <answer> "= 
<token> out; <answer> goto 
} else <token> <answer> { 
<token> = ecryptfs_read_lower_page_segment( <answer> rc 
page, index, <token> PAGE_SIZE, <answer> 0, 
if (rc) <token> <answer> { 
printk(KERN_ERR "%s: Error reading <token> <answer> " 
"page; rc <token> [%d]\n", <answer> = 
__func__, <token> <answer> rc); 
goto <token> <answer> out; 
} <token> { <answer> else 
if <token> <answer> (prev_page_end_size 
>= i_size_read(page->mapping->host)) <token> <answer> { 
<token> 0, PAGE_SIZE); <answer> zero_user(page, 
} else if (len < <token> { <answer> PAGE_SIZE) 
rc = <token> <answer> ecryptfs_decrypt_page(page); 
<token> (rc) { <answer> if 
printk(KERN_ERR <token> Error decrypting " <answer> "%s: 
<token> at index [%ld]; " <answer> "page 
<token> = [%d]\n", <answer> "rc 
__func__, page->index, <token> <answer> rc); 
goto <token> <answer> out; 
if (index <token> 0) { <answer> != 
if (prev_page_end_size > i_size_read(page->mapping->host)) <token> <answer> { 
rc = <token> <answer> ecryptfs_truncate(file->f_path.dentry, 
if <token> { <answer> (rc) 
printk(KERN_ERR "%s: Error on attempt to <token> <answer> " 
<token> to (higher) offset [%lld];" <answer> "truncate 
" rc <token> [%d]\n", __func__, <answer> = 
<token> rc); <answer> prev_page_end_size, 
goto <token> <answer> out; 
if ((i_size_read(mapping->host) == <token> <answer> prev_page_end_size) 
&& <token> != 0)) <answer> (pos 
zero_user(page, <token> PAGE_SIZE); <answer> 0, 
if (unlikely(rc)) <token> <answer> { 
<token> = NULL; <answer> *pagep 
<token> rc; <answer> return 
static int <token> inode *ecryptfs_inode) <answer> ecryptfs_write_inode_size_to_header(struct 
char <token> <answer> *file_size_virt; 
<token> rc; <answer> int 
file_size_virt = <token> GFP_KERNEL); <answer> kmalloc(sizeof(u64), 
if (!file_size_virt) <token> <answer> { 
rc = <token> <answer> -ENOMEM; 
goto <token> <answer> out; 
<token> file_size_virt); <answer> put_unaligned_be64(i_size_read(ecryptfs_inode), 
rc = ecryptfs_write_lower(ecryptfs_inode, <token> 0, <answer> file_size_virt, 
if (rc < <token> <answer> 0) 
<token> "%s: Error writing file size to header; " <answer> printk(KERN_ERR 
<token> = [%d]\n", __func__, rc); <answer> "rc 
<token> = 0; <answer> rc 
<token> rc; <answer> return 
struct kmem_cache <token> <answer> *ecryptfs_xattr_cache; 
static int ecryptfs_write_inode_size_to_xattr(struct inode <token> <answer> *ecryptfs_inode) 
<token> size; <answer> ssize_t 
<token> *xattr_virt; <answer> void 
struct dentry <token> = <answer> *lower_dentry 
struct inode *lower_inode = <token> <answer> d_inode(lower_dentry); 
int <token> <answer> rc; 
if (!(lower_inode->i_opflags & <token> { <answer> IOP_XATTR)) 
"No support for setting xattr in <token> filesystem\n"); <answer> lower 
rc <token> -ENOSYS; <answer> = 
goto <token> <answer> out; 
xattr_virt = <token> GFP_KERNEL); <answer> kmem_cache_alloc(ecryptfs_xattr_cache, 
if <token> { <answer> (!xattr_virt) 
<token> = -ENOMEM; <answer> rc 
goto <token> <answer> out; 
size <token> __vfs_getxattr(lower_dentry, lower_inode, ECRYPTFS_XATTR_NAME, <answer> = 
xattr_virt, <token> <answer> PAGE_SIZE); 
if (size <token> 0) <answer> < 
size = <token> <answer> 8; 
put_unaligned_be64(i_size_read(ecryptfs_inode), <token> <answer> xattr_virt); 
rc = <token> lower_dentry, lower_inode, <answer> __vfs_setxattr(&nop_mnt_idmap, 
ECRYPTFS_XATTR_NAME, xattr_virt, size, <token> <answer> 0); 
if <token> <answer> (rc) 
printk(KERN_ERR "Error whilst attempting <token> write inode size " <answer> to 
"to <token> file xattr; rc = [%d]\n", rc); <answer> lower 
<token> xattr_virt); <answer> kmem_cache_free(ecryptfs_xattr_cache, 
<token> rc; <answer> return 
<token> ecryptfs_write_inode_size_to_metadata(struct inode *ecryptfs_inode) <answer> int 
struct ecryptfs_crypt_stat <token> <answer> *crypt_stat; 
<token> = &ecryptfs_inode_to_private(ecryptfs_inode)->crypt_stat; <answer> crypt_stat 
BUG_ON(!(crypt_stat->flags <token> ECRYPTFS_ENCRYPTED)); <answer> & 
if (crypt_stat->flags & <token> <answer> ECRYPTFS_METADATA_IN_XATTR) 
<token> ecryptfs_write_inode_size_to_xattr(ecryptfs_inode); <answer> return 
<token> ecryptfs_write_inode_size_to_header(ecryptfs_inode); <answer> return 
static int <token> file *file, <answer> ecryptfs_write_end(struct 
struct <token> *mapping, <answer> address_space 
loff_t pos, unsigned len, unsigned <token> <answer> copied, 
struct page *page, <token> *fsdata) <answer> void 
pgoff_t index <token> pos >> PAGE_SHIFT; <answer> = 
unsigned from = pos & (PAGE_SIZE - <token> <answer> 1); 
unsigned to = from + <token> <answer> copied; 
struct <token> *ecryptfs_inode = mapping->host; <answer> inode 
struct ecryptfs_crypt_stat <token> = <answer> *crypt_stat 
int <token> <answer> rc; 
ecryptfs_printk(KERN_DEBUG, "Calling <token> <answer> fill_zeros_to_end_of_page" 
"(page <token> index = [0x%.16lx], to = [%d])\n", index, to); <answer> w/ 
if (!(crypt_stat->flags & ECRYPTFS_ENCRYPTED)) <token> <answer> { 
rc = ecryptfs_write_lower_page_segment(ecryptfs_inode, <token> 0, <answer> page, 
<token> (!rc) { <answer> if 
<token> = copied; <answer> rc 
goto <token> <answer> out; 
<token> (!PageUptodate(page)) { <answer> if 
if <token> < PAGE_SIZE) { <answer> (copied 
rc = <token> <answer> 0; 
<token> out; <answer> goto 
<token> CONFIG_BLOCK <answer> #ifdef 
.dirty_folio = <token> <answer> block_dirty_folio, 
.invalidate_folio <token> block_invalidate_folio, <answer> = 
<token> = ecryptfs_writepage, <answer> .writepage 
.read_folio = <token> <answer> ecryptfs_read_folio, 
.write_begin <token> ecryptfs_write_begin, <answer> = 
.write_end = <token> <answer> ecryptfs_write_end, 
.bmap <token> ecryptfs_bmap, <answer> = 
<token> void icrdma_ena_irq(struct irdma_sc_dev *dev, u32 idx) <answer> static 
u32 <token> <answer> val; 
u32 interval = <token> <answer> 0; 
<token> (dev->ceq_itr && dev->aeq->msix_idx != idx) <answer> if 
static void icrdma_disable_irq(struct irdma_sc_dev *dev, u32 <token> <answer> idx) 
if <token> != IRDMA_GEN_1) <answer> (dev->hw_attrs.uk_attrs.hw_rev 
writel(0, <token> + idx); <answer> dev->hw_regs[IRDMA_GLINT_DYN_CTL] 
writel(0, dev->hw_regs[IRDMA_GLINT_DYN_CTL] + (idx - <token> <answer> 1)); 
<token> void icrdma_cfg_ceq(struct irdma_sc_dev *dev, u32 ceq_id, u32 idx, <answer> static 
bool <token> <answer> enable) 
u32 <token> <answer> reg_val; 
reg_val = FIELD_PREP(IRDMA_GLINT_CEQCTL_CAUSE_ENA, enable) <token> <answer> | 
<token> idx) | <answer> FIELD_PREP(IRDMA_GLINT_CEQCTL_MSIX_INDX, 
<token> 3); <answer> FIELD_PREP(IRDMA_GLINT_CEQCTL_ITR_INDX, 
writel(reg_val, dev->hw_regs[IRDMA_GLINT_CEQCTL] + <token> <answer> ceq_id); 
<token> const struct irdma_irq_ops icrdma_irq_ops = { <answer> static 
.irdma_cfg_aeq = <token> <answer> irdma_cfg_aeq, 
<token> = icrdma_cfg_ceq, <answer> .irdma_cfg_ceq 
.irdma_dis_irq = <token> <answer> icrdma_disable_irq, 
.irdma_en_irq <token> icrdma_ena_irq, <answer> = 
static const struct irdma_hw_stat_map <token> = { <answer> icrdma_hw_stat_map[] 
[IRDMA_HW_STAT_INDEX_RXVLANERR] = <token> 0, 32, IRDMA_MAX_STATS_24 }, <answer> { 
[IRDMA_HW_STAT_INDEX_IP4RXOCTS] = { 8, 0, IRDMA_MAX_STATS_48 <token> <answer> }, 
[IRDMA_HW_STAT_INDEX_IP4RXPKTS] = { 16, 0, IRDMA_MAX_STATS_48 <token> <answer> }, 
[IRDMA_HW_STAT_INDEX_IP4RXDISCARD] = <token> 24, 32, IRDMA_MAX_STATS_32 }, <answer> { 
[IRDMA_HW_STAT_INDEX_IP4RXTRUNC] = { 24, 0, IRDMA_MAX_STATS_32 <token> <answer> }, 
[IRDMA_HW_STAT_INDEX_IP4RXFRAGS] = { <token> 0, IRDMA_MAX_STATS_48 }, <answer> 32, 
[IRDMA_HW_STAT_INDEX_IP4RXMCOCTS] = { 40, 0, IRDMA_MAX_STATS_48 <token> <answer> }, 
[IRDMA_HW_STAT_INDEX_IP4RXMCPKTS] <token> { 48, 0, IRDMA_MAX_STATS_48 }, <answer> = 
[IRDMA_HW_STAT_INDEX_IP6RXOCTS] = { 56, <token> IRDMA_MAX_STATS_48 }, <answer> 0, 
[IRDMA_HW_STAT_INDEX_IP6RXPKTS] = <token> 64, 0, IRDMA_MAX_STATS_48 }, <answer> { 
[IRDMA_HW_STAT_INDEX_IP6RXDISCARD] = { 72, 32, <token> }, <answer> IRDMA_MAX_STATS_32 
[IRDMA_HW_STAT_INDEX_IP6RXTRUNC] = { 72, <token> IRDMA_MAX_STATS_32 }, <answer> 0, 
[IRDMA_HW_STAT_INDEX_IP6RXFRAGS] <token> { 80, 0, IRDMA_MAX_STATS_48 }, <answer> = 
[IRDMA_HW_STAT_INDEX_IP6RXMCOCTS] = { <token> 0, IRDMA_MAX_STATS_48 }, <answer> 88, 
[IRDMA_HW_STAT_INDEX_IP6RXMCPKTS] = { 96, 0, <token> }, <answer> IRDMA_MAX_STATS_48 
[IRDMA_HW_STAT_INDEX_IP4TXOCTS] = { 104, <token> IRDMA_MAX_STATS_48 }, <answer> 0, 
[IRDMA_HW_STAT_INDEX_IP4TXPKTS] <token> { 112, 0, IRDMA_MAX_STATS_48 }, <answer> = 
[IRDMA_HW_STAT_INDEX_IP4TXFRAGS] = { 120, 0, IRDMA_MAX_STATS_48 <token> <answer> }, 
[IRDMA_HW_STAT_INDEX_IP4TXMCOCTS] = { 128, 0, IRDMA_MAX_STATS_48 <token> <answer> }, 
[IRDMA_HW_STAT_INDEX_IP4TXMCPKTS] <token> { 136, 0, IRDMA_MAX_STATS_48 }, <answer> = 
[IRDMA_HW_STAT_INDEX_IP6TXOCTS] = { <token> 0, IRDMA_MAX_STATS_48 }, <answer> 144, 
[IRDMA_HW_STAT_INDEX_IP6TXPKTS] = { 152, 0, IRDMA_MAX_STATS_48 <token> <answer> }, 
[IRDMA_HW_STAT_INDEX_IP6TXFRAGS] <token> { 160, 0, IRDMA_MAX_STATS_48 }, <answer> = 
[IRDMA_HW_STAT_INDEX_IP6TXMCOCTS] = { <token> 0, IRDMA_MAX_STATS_48 }, <answer> 168, 
[IRDMA_HW_STAT_INDEX_IP6TXMCPKTS] <token> { 176, 0, IRDMA_MAX_STATS_48 }, <answer> = 
[IRDMA_HW_STAT_INDEX_IP4TXNOROUTE] = { 184, <token> IRDMA_MAX_STATS_24 }, <answer> 32, 
[IRDMA_HW_STAT_INDEX_IP6TXNOROUTE] = { 184, 0, <token> }, <answer> IRDMA_MAX_STATS_24 
[IRDMA_HW_STAT_INDEX_TCPRXSEGS] = { 192, 32, <token> }, <answer> IRDMA_MAX_STATS_48 
[IRDMA_HW_STAT_INDEX_TCPRXOPTERR] = { 200, <token> IRDMA_MAX_STATS_24 }, <answer> 32, 
[IRDMA_HW_STAT_INDEX_TCPRXPROTOERR] = { <token> 0, IRDMA_MAX_STATS_24 }, <answer> 200, 
[IRDMA_HW_STAT_INDEX_TCPTXSEG] <token> { 208, 0, IRDMA_MAX_STATS_48 }, <answer> = 
[IRDMA_HW_STAT_INDEX_TCPRTXSEG] = { <token> 32, IRDMA_MAX_STATS_32 }, <answer> 216, 
<token> = { 224, 0, IRDMA_MAX_STATS_48 }, <answer> [IRDMA_HW_STAT_INDEX_UDPRXPKTS] 
[IRDMA_HW_STAT_INDEX_UDPTXPKTS] = { 232, 0, <token> }, <answer> IRDMA_MAX_STATS_48 
[IRDMA_HW_STAT_INDEX_RDMARXWRS] = { 240, 0, <token> }, <answer> IRDMA_MAX_STATS_48 
[IRDMA_HW_STAT_INDEX_RDMARXRDS] = { 248, 0, <token> }, <answer> IRDMA_MAX_STATS_48 
[IRDMA_HW_STAT_INDEX_RDMARXSNDS] = { 256, 0, <token> }, <answer> IRDMA_MAX_STATS_48 
[IRDMA_HW_STAT_INDEX_RDMATXWRS] = { 264, 0, <token> }, <answer> IRDMA_MAX_STATS_48 
[IRDMA_HW_STAT_INDEX_RDMATXRDS] <token> { 272, 0, IRDMA_MAX_STATS_48 }, <answer> = 
[IRDMA_HW_STAT_INDEX_RDMATXSNDS] = <token> 280, 0, IRDMA_MAX_STATS_48 }, <answer> { 
[IRDMA_HW_STAT_INDEX_RDMAVBND] = <token> 288, 0, IRDMA_MAX_STATS_48 }, <answer> { 
[IRDMA_HW_STAT_INDEX_RDMAVINV] <token> { 296, 0, IRDMA_MAX_STATS_48 }, <answer> = 
[IRDMA_HW_STAT_INDEX_RXNPECNMARKEDPKTS] <token> { 304, 0, IRDMA_MAX_STATS_56 }, <answer> = 
[IRDMA_HW_STAT_INDEX_RXRPCNPIGNORED] = { 312, 32, IRDMA_MAX_STATS_24 <token> <answer> }, 
[IRDMA_HW_STAT_INDEX_RXRPCNPHANDLED] = { 312, 0, <token> }, <answer> IRDMA_MAX_STATS_32 
[IRDMA_HW_STAT_INDEX_TXNPCNPSENT] = <token> 320, 0, IRDMA_MAX_STATS_32 }, <answer> { 
void icrdma_init_hw(struct <token> *dev) <answer> irdma_sc_dev 
int <token> <answer> i; 
u8 __iomem <token> <answer> *hw_addr; 
<token> (i = 0; i < IRDMA_MAX_REGS; ++i) { <answer> for 
hw_addr <token> dev->hw->hw_addr; <answer> = 
if <token> == IRDMA_DB_ADDR_OFFSET) <answer> (i 
hw_addr = <token> <answer> NULL; 
<token> = (u32 __iomem *)(hw_addr + icrdma_regs[i]); <answer> dev->hw_regs[i] 
dev->hw_attrs.max_hw_vf_fpm_id = <token> <answer> IRDMA_MAX_VF_FPM_ID; 
<token> = IRDMA_FIRST_VF_FPM_ID; <answer> dev->hw_attrs.first_hw_vf_fpm_id 
<token> (i = 0; i < IRDMA_MAX_SHIFTS; ++i) <answer> for 
dev->hw_shifts[i] = <token> <answer> icrdma_shifts[i]; 
for (i <token> 0; i < IRDMA_MAX_MASKS; ++i) <answer> = 
dev->hw_masks[i] <token> icrdma_masks[i]; <answer> = 
<token> = dev->hw_regs[IRDMA_WQEALLOC]; <answer> dev->wqe_alloc_db 
<token> = dev->hw_regs[IRDMA_CQARM]; <answer> dev->cq_arm_db 
dev->aeq_alloc_db <token> dev->hw_regs[IRDMA_AEQALLOC]; <answer> = 
dev->cqp_db = <token> <answer> dev->hw_regs[IRDMA_CQPDB]; 
<token> = dev->hw_regs[IRDMA_CQACK]; <answer> dev->cq_ack_db 
dev->irq_ops <token> &icrdma_irq_ops; <answer> = 
<token> = SZ_4K | SZ_2M | SZ_1G; <answer> dev->hw_attrs.page_size_cap 
<token> = icrdma_hw_stat_map; <answer> dev->hw_stats_map 
dev->hw_attrs.max_hw_ird <token> ICRDMA_MAX_IRD_SIZE; <answer> = 
dev->hw_attrs.max_hw_ord = <token> <answer> ICRDMA_MAX_ORD_SIZE; 
dev->hw_attrs.max_stat_inst = <token> <answer> ICRDMA_MAX_STATS_COUNT; 
dev->hw_attrs.max_stat_idx = <token> <answer> IRDMA_HW_STAT_INDEX_MAX_GEN_2; 
dev->hw_attrs.uk_attrs.min_hw_wq_size = <token> <answer> ICRDMA_MIN_WQ_SIZE; 
dev->hw_attrs.uk_attrs.max_hw_sq_chunk = <token> <answer> IRDMA_MAX_QUANTA_PER_WR; 
dev->hw_attrs.uk_attrs.feature_flags |= IRDMA_FEATURE_RTS_AE <token> <answer> | 
#include <token> <answer> <linux/pci.h> 
#include <token> <answer> "amdgpu.h" 
#include <token> <answer> "amdgpu_ih.h" 
<token> "vid.h" <answer> #include 
#include <token> <answer> "oss/oss_3_0_1_d.h" 
<token> "oss/oss_3_0_1_sh_mask.h" <answer> #include 
#include <token> <answer> "bif/bif_5_1_d.h" 
#include <token> <answer> "bif/bif_5_1_sh_mask.h" 
static void cz_ih_set_interrupt_funcs(struct amdgpu_device <token> <answer> *adev); 
static <token> cz_ih_enable_interrupts(struct amdgpu_device *adev) <answer> void 
u32 <token> = RREG32(mmIH_CNTL); <answer> ih_cntl 
u32 <token> = RREG32(mmIH_RB_CNTL); <answer> ih_rb_cntl 
<token> = REG_SET_FIELD(ih_cntl, IH_CNTL, ENABLE_INTR, 1); <answer> ih_cntl 
ih_rb_cntl <token> REG_SET_FIELD(ih_rb_cntl, IH_RB_CNTL, RB_ENABLE, 1); <answer> = 
WREG32(mmIH_CNTL, <token> <answer> ih_cntl); 
WREG32(mmIH_RB_CNTL, <token> <answer> ih_rb_cntl); 
adev->irq.ih.enabled <token> true; <answer> = 
static void <token> amdgpu_device *adev) <answer> cz_ih_disable_interrupts(struct 
u32 ih_rb_cntl <token> RREG32(mmIH_RB_CNTL); <answer> = 
u32 <token> = RREG32(mmIH_CNTL); <answer> ih_cntl 
ih_rb_cntl = REG_SET_FIELD(ih_rb_cntl, IH_RB_CNTL, RB_ENABLE, <token> <answer> 0); 
ih_cntl = REG_SET_FIELD(ih_cntl, IH_CNTL, <token> 0); <answer> ENABLE_INTR, 
WREG32(mmIH_RB_CNTL, <token> <answer> ih_rb_cntl); 
WREG32(mmIH_CNTL, <token> <answer> ih_cntl); 
static int cz_ih_irq_init(struct amdgpu_device <token> <answer> *adev) 
<token> amdgpu_ih_ring *ih = &adev->irq.ih; <answer> struct 
u32 <token> ih_cntl, ih_rb_cntl; <answer> interrupt_cntl, 
int <token> <answer> rb_bufsz; 
interrupt_cntl = REG_SET_FIELD(interrupt_cntl, INTERRUPT_CNTL, <token> 0); <answer> IH_DUMMY_RD_OVERRIDE, 
static void <token> amdgpu_device *adev) <answer> cz_ih_irq_disable(struct 
static u32 cz_ih_get_wptr(struct <token> *adev, <answer> amdgpu_device 
<token> amdgpu_ih_ring *ih) <answer> struct 
u32 wptr, <token> <answer> tmp; 
<token> = le32_to_cpu(*ih->wptr_cpu); <answer> wptr 
<token> (!REG_GET_FIELD(wptr, IH_RB_WPTR, RB_OVERFLOW)) <answer> if 
goto <token> <answer> out; 
dev_warn(adev->dev, "IH ring buffer overflow <token> 0x%08X, 0x%08X)\n", <answer> (0x%08X, 
wptr, ih->rptr, (wptr <token> 16) & ih->ptr_mask); <answer> + 
ih->rptr = (wptr <token> 16) & ih->ptr_mask; <answer> + 
tmp <token> RREG32(mmIH_RB_CNTL); <answer> = 
tmp = REG_SET_FIELD(tmp, <token> WPTR_OVERFLOW_CLEAR, 1); <answer> IH_RB_CNTL, 
WREG32(mmIH_RB_CNTL, <token> <answer> tmp); 
<token> = REG_SET_FIELD(tmp, IH_RB_CNTL, WPTR_OVERFLOW_CLEAR, 0); <answer> tmp 
WREG32(mmIH_RB_CNTL, <token> <answer> tmp); 
return (wptr <token> ih->ptr_mask); <answer> & 
static void cz_ih_decode_iv(struct amdgpu_device <token> <answer> *adev, 
struct amdgpu_ih_ring <token> <answer> *ih, 
<token> amdgpu_iv_entry *entry) <answer> struct 
<token> void cz_ih_set_rptr(struct amdgpu_device *adev, <answer> static 
<token> amdgpu_ih_ring *ih) <answer> struct 
<token> ih->rptr); <answer> WREG32(mmIH_RB_RPTR, 
<token> int cz_ih_early_init(void *handle) <answer> static 
struct <token> *adev = (struct amdgpu_device *)handle; <answer> amdgpu_device 
<token> ret; <answer> int 
<token> = amdgpu_irq_add_domain(adev); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
return <token> <answer> 0; 
static <token> cz_ih_sw_init(void *handle) <answer> int 
int <token> <answer> r; 
struct amdgpu_device *adev <token> (struct amdgpu_device *)handle; <answer> = 
r = amdgpu_ih_ring_init(adev, &adev->irq.ih, 64 <token> 1024, false); <answer> * 
<token> (r) <answer> if 
return <token> <answer> r; 
r <token> amdgpu_irq_init(adev); <answer> = 
<token> r; <answer> return 
static <token> cz_ih_sw_fini(void *handle) <answer> int 
struct <token> *adev = (struct amdgpu_device *)handle; <answer> amdgpu_device 
<token> 0; <answer> return 
static int <token> *handle) <answer> cz_ih_hw_init(void 
<token> r; <answer> int 
struct <token> *adev = (struct amdgpu_device *)handle; <answer> amdgpu_device 
<token> = cz_ih_irq_init(adev); <answer> r 
<token> (r) <answer> if 
return <token> <answer> r; 
<token> 0; <answer> return 
<token> int cz_ih_hw_fini(void *handle) <answer> static 
<token> amdgpu_device *adev = (struct amdgpu_device *)handle; <answer> struct 
return <token> <answer> 0; 
static int <token> *handle) <answer> cz_ih_suspend(void 
struct amdgpu_device *adev = <token> amdgpu_device *)handle; <answer> (struct 
return <token> <answer> cz_ih_hw_fini(adev); 
<token> int cz_ih_resume(void *handle) <answer> static 
<token> amdgpu_device *adev = (struct amdgpu_device *)handle; <answer> struct 
<token> cz_ih_hw_init(adev); <answer> return 
<token> bool cz_ih_is_idle(void *handle) <answer> static 
struct amdgpu_device <token> = (struct amdgpu_device *)handle; <answer> *adev 
<token> tmp = RREG32(mmSRBM_STATUS); <answer> u32 
if (REG_GET_FIELD(tmp, <token> IH_BUSY)) <answer> SRBM_STATUS, 
<token> false; <answer> return 
return <token> <answer> true; 
static int cz_ih_wait_for_idle(void <token> <answer> *handle) 
<token> i; <answer> unsigned 
<token> tmp; <answer> u32 
<token> amdgpu_device *adev = (struct amdgpu_device *)handle; <answer> struct 
for (i = 0; i < <token> i++) { <answer> adev->usec_timeout; 
#include <token> <answer> <linux/device.h> 
#include <token> <answer> <linux/err.h> 
<token> <linux/freezer.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/kthread.h> <answer> #include 
#include <token> <answer> <linux/mm.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/poll.h> <answer> #include 
<token> <linux/sched.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <media/v4l2-common.h> 
#include <token> <answer> <media/v4l2-dev.h> 
<token> <media/v4l2-device.h> <answer> #include 
<token> <media/v4l2-event.h> <answer> #include 
<token> <media/v4l2-fh.h> <answer> #include 
<token> <media/videobuf2-v4l2.h> <answer> #include 
<token> int debug; <answer> static 
<token> int, 0644); <answer> module_param(debug, 
#define <token> level, fmt, arg...) \ <answer> dprintk(q, 
do <token> \ <answer> { 
<token> (debug >= level) \ <answer> if 
pr_info("vb2-v4l2: [%p] %s: " fmt, <token> <answer> \ 
(q)->name, __func__, ## <token> \ <answer> arg); 
<token> while (0) <answer> } 
static int <token> vb2_buffer *vb, const struct v4l2_buffer *b) <answer> __verify_planes_array(struct 
if <token> <answer> (!V4L2_TYPE_IS_MULTIPLANAR(b->type)) 
<token> 0; <answer> return 
static int __verify_length(struct vb2_buffer *vb, const <token> v4l2_buffer *b) <answer> struct 
unsigned <token> length; <answer> int 
<token> int bytesused; <answer> unsigned 
unsigned int <token> <answer> plane; 
<token> (V4L2_TYPE_IS_CAPTURE(b->type)) <answer> if 
<token> 0; <answer> return 
if <token> { <answer> (V4L2_TYPE_IS_MULTIPLANAR(b->type)) 
for (plane = <token> plane < vb->num_planes; ++plane) { <answer> 0; 
<token> = (b->memory == VB2_MEMORY_USERPTR || <answer> length 
b->memory == <token> <answer> VB2_MEMORY_DMABUF) 
<token> b->m.planes[plane].length <answer> ? 
<token> vb->planes[plane].length; <answer> : 
bytesused = <token> <answer> b->m.planes[plane].bytesused 
? b->m.planes[plane].bytesused <token> length; <answer> : 
if (b->m.planes[plane].bytesused <token> length) <answer> > 
<token> -EINVAL; <answer> return 
<token> (b->m.planes[plane].data_offset > 0 && <answer> if 
b->m.planes[plane].data_offset <token> bytesused) <answer> >= 
return <token> <answer> -EINVAL; 
} else <token> <answer> { 
<token> = (b->memory == VB2_MEMORY_USERPTR) <answer> length 
? b->length : <token> <answer> vb->planes[0].length; 
if (b->bytesused <token> length) <answer> > 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
static void <token> vb2_buffer *vb) <answer> __init_vb2_v4l2_buffer(struct 
struct vb2_v4l2_buffer <token> = to_vb2_v4l2_buffer(vb); <answer> *vbuf 
vbuf->request_fd = <token> <answer> -1; 
static void __copy_timestamp(struct <token> *vb, const void *pb) <answer> vb2_buffer 
const struct <token> *b = pb; <answer> v4l2_buffer 
struct <token> *vbuf = to_vb2_v4l2_buffer(vb); <answer> vb2_v4l2_buffer 
struct vb2_queue <token> = vb->vb2_queue; <answer> *q 
<token> (q->is_output) { <answer> if 
<token> (q->copy_timestamp) <answer> if 
vb->timestamp <token> v4l2_buffer_get_timestamp(b); <answer> = 
<token> |= b->flags & V4L2_BUF_FLAG_TIMECODE; <answer> vbuf->flags 
if (b->flags & <token> <answer> V4L2_BUF_FLAG_TIMECODE) 
<token> = b->timecode; <answer> vbuf->timecode 
static void vb2_warn_zero_bytesused(struct <token> *vb) <answer> vb2_buffer 
static bool <token> <answer> check_once; 
<token> (check_once) <answer> if 
check_once <token> true; <answer> = 
pr_warn("use of bytesused == 0 is deprecated and will be removed <token> the future,\n"); <answer> in 
if <token> <answer> (vb->vb2_queue->allow_zero_bytesused) 
pr_warn("use <token> instead.\n"); <answer> VIDIOC_DECODER_CMD(V4L2_DEC_CMD_STOP) 
pr_warn("use the <token> size instead.\n"); <answer> actual 
static int <token> vb2_buffer *vb, struct v4l2_buffer *b) <answer> vb2_fill_vb2_v4l2_buffer(struct 
<token> vb2_queue *q = vb->vb2_queue; <answer> struct 
struct vb2_v4l2_buffer *vbuf <token> to_vb2_v4l2_buffer(vb); <answer> = 
<token> vb2_plane *planes = vbuf->planes; <answer> struct 
unsigned <token> plane; <answer> int 
<token> ret; <answer> int 
<token> = __verify_length(vb, b); <answer> ret 
if (ret < <token> { <answer> 0) 
dprintk(q, 1, "plane parameters verification failed: <token> ret); <answer> %d\n", 
return <token> <answer> ret; 
if (b->field == <token> && q->is_output) { <answer> V4L2_FIELD_ALTERNATE 
dprintk(q, 1, <token> field is incorrectly set to ALTERNATE for an output buffer\n"); <answer> "the 
<token> -EINVAL; <answer> return 
vbuf->sequence <token> 0; <answer> = 
<token> = -1; <answer> vbuf->request_fd 
<token> = false; <answer> vbuf->is_held 
if (V4L2_TYPE_IS_MULTIPLANAR(b->type)) <token> <answer> { 
<token> (b->memory) { <answer> switch 
case <token> <answer> VB2_MEMORY_USERPTR: 
for (plane = 0; plane <token> vb->num_planes; ++plane) { <answer> < 
planes[plane].m.userptr <token> <answer> = 
<token> = <answer> planes[plane].length 
case <token> <answer> VB2_MEMORY_DMABUF: 
for (plane = 0; <token> < vb->num_planes; ++plane) { <answer> plane 
<token> = <answer> planes[plane].m.fd 
<token> = <answer> planes[plane].length 
<token> (plane = 0; plane < vb->num_planes; ++plane) { <answer> for 
planes[plane].m.offset <token> <answer> = 
planes[plane].length <token> <answer> = 
for <token> = 0; plane < vb->num_planes; ++plane) { <answer> (plane 
struct vb2_plane *pdst = <token> <answer> &planes[plane]; 
<token> v4l2_plane *psrc = &b->m.planes[plane]; <answer> struct 
if (psrc->bytesused == <token> <answer> 0) 
<token> (vb->vb2_queue->allow_zero_bytesused) <answer> if 
<token> = psrc->bytesused; <answer> pdst->bytesused 
<token> = psrc->bytesused ? <answer> pdst->bytesused 
<token> : pdst->length; <answer> psrc->bytesused 
pdst->data_offset <token> psrc->data_offset; <answer> = 
} else <token> <answer> { 
switch (b->memory) <token> <answer> { 
<token> VB2_MEMORY_USERPTR: <answer> case 
planes[0].m.userptr = <token> <answer> b->m.userptr; 
planes[0].length = <token> <answer> b->length; 
<token> VB2_MEMORY_DMABUF: <answer> case 
planes[0].m.fd = <token> <answer> b->m.fd; 
planes[0].length <token> b->length; <answer> = 
planes[0].m.offset = <token> <answer> vb->planes[0].m.offset; 
planes[0].length <token> vb->planes[0].length; <answer> = 
<token> = 0; <answer> planes[0].data_offset 
if (V4L2_TYPE_IS_OUTPUT(b->type)) <token> <answer> { 
if (b->bytesused == <token> <answer> 0) 
<token> (vb->vb2_queue->allow_zero_bytesused) <answer> if 
planes[0].bytesused <token> b->bytesused; <answer> = 
planes[0].bytesused <token> b->bytesused ? <answer> = 
b->bytesused : <token> <answer> planes[0].length; 
<token> else <answer> } 
<token> = 0; <answer> planes[0].bytesused 
vbuf->flags <token> ~V4L2_BUF_FLAG_TSTAMP_SRC_MASK; <answer> &= 
if <token> { <answer> (V4L2_TYPE_IS_OUTPUT(b->type)) 
vbuf->flags &= <token> <answer> ~V4L2_BUF_FLAG_TIMECODE; 
vbuf->field = <token> <answer> b->field; 
if <token> & VB2_V4L2_FL_SUPPORTS_M2M_HOLD_CAPTURE_BUF)) <answer> (!(q->subsystem_flags 
<token> &= ~V4L2_BUF_FLAG_M2M_HOLD_CAPTURE_BUF; <answer> vbuf->flags 
<token> else { <answer> } 
<token> &= ~V4L2_BUF_FLAG_NO_CACHE_INVALIDATE; <answer> b->flags 
b->flags &= <token> <answer> ~V4L2_BUF_FLAG_NO_CACHE_CLEAN; 
if (b->flags <token> V4L2_BUF_FLAG_NO_CACHE_INVALIDATE) <answer> & 
vb->skip_cache_sync_on_finish = <token> <answer> 1; 
if (b->flags <token> V4L2_BUF_FLAG_NO_CACHE_CLEAN) <answer> & 
vb->skip_cache_sync_on_prepare <token> 1; <answer> = 
static int vb2_queue_or_prepare_buf(struct vb2_queue <token> struct media_device *mdev, <answer> *q, 
struct <token> *vb, struct v4l2_buffer *b, <answer> vb2_buffer 
<token> is_prepare, struct media_request **p_req) <answer> bool 
const char *opname = is_prepare ? "prepare_buf" : <token> <answer> "qbuf"; 
struct <token> *req; <answer> media_request 
struct <token> *vbuf; <answer> vb2_v4l2_buffer 
<token> ret; <answer> int 
if <token> != q->type) { <answer> (b->type 
dprintk(q, 1, <token> invalid buffer type\n", opname); <answer> "%s: 
return <token> <answer> -EINVAL; 
<token> (b->memory != q->memory) { <answer> if 
dprintk(q, 1, "%s: invalid <token> type\n", opname); <answer> memory 
return <token> <answer> -EINVAL; 
vbuf <token> to_vb2_v4l2_buffer(vb); <answer> = 
ret = __verify_planes_array(vb, <token> <answer> b); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
if (!is_prepare && (b->flags & V4L2_BUF_FLAG_REQUEST_FD) <token> <answer> && 
vb->state != <token> { <answer> VB2_BUF_STATE_DEQUEUED) 
<token> 1, "%s: buffer is not in dequeued state\n", opname); <answer> dprintk(q, 
<token> -EINVAL; <answer> return 
<token> (!vb->prepared) { <answer> if 
<token> vb, b); <answer> set_buffer_cache_hints(q, 
if (WARN_ON(!q->lock <token> !p_req)) <answer> || 
return <token> <answer> -EINVAL; 
if <token> <answer> (WARN_ON(!q->ops->buf_request_complete)) 
return <token> <answer> -EINVAL; 
if (WARN_ON((q->type <token> V4L2_BUF_TYPE_VIDEO_OUTPUT || <answer> == 
q->type == V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE) <token> <answer> && 
<token> -EINVAL; <answer> return 
req = media_request_get_by_fd(mdev, <token> <answer> b->request_fd); 
<token> (IS_ERR(req)) { <answer> if 
dprintk(q, 1, <token> invalid request_fd\n", opname); <answer> "%s: 
<token> PTR_ERR(req); <answer> return 
if (req->state != MEDIA_REQUEST_STATE_IDLE <token> <answer> && 
req->state != <token> { <answer> MEDIA_REQUEST_STATE_UPDATING) 
dprintk(q, 1, <token> request is not idle\n", opname); <answer> "%s: 
<token> -EBUSY; <answer> return 
*p_req = <token> <answer> req; 
<token> = b->request_fd; <answer> vbuf->request_fd 
<token> 0; <answer> return 
static <token> __fill_v4l2_buffer(struct vb2_buffer *vb, void *pb) <answer> void 
struct v4l2_buffer <token> = pb; <answer> *b 
struct vb2_v4l2_buffer *vbuf <token> to_vb2_v4l2_buffer(vb); <answer> = 
struct vb2_queue *q = <token> <answer> vb->vb2_queue; 
unsigned int <token> <answer> plane; 
b->length = <token> <answer> vb->num_planes; 
for (plane = 0; <token> < vb->num_planes; ++plane) { <answer> plane 
struct v4l2_plane *pdst = <token> <answer> &b->m.planes[plane]; 
struct vb2_plane <token> = &vb->planes[plane]; <answer> *psrc 
pdst->bytesused <token> psrc->bytesused; <answer> = 
pdst->length = <token> <answer> psrc->length; 
if (q->memory <token> VB2_MEMORY_MMAP) <answer> == 
<token> = psrc->m.offset; <answer> pdst->m.mem_offset 
else <token> (q->memory == VB2_MEMORY_USERPTR) <answer> if 
pdst->m.userptr <token> psrc->m.userptr; <answer> = 
<token> if (q->memory == VB2_MEMORY_DMABUF) <answer> else 
pdst->m.fd = <token> <answer> psrc->m.fd; 
pdst->data_offset = <token> <answer> psrc->data_offset; 
memset(pdst->reserved, 0, <token> <answer> sizeof(pdst->reserved)); 
} else <token> <answer> { 
<token> = vb->planes[0].length; <answer> b->length 
b->bytesused = <token> <answer> vb->planes[0].bytesused; 
if <token> == VB2_MEMORY_MMAP) <answer> (q->memory 
b->m.offset = <token> <answer> vb->planes[0].m.offset; 
<token> if (q->memory == VB2_MEMORY_USERPTR) <answer> else 
b->m.userptr = <token> <answer> vb->planes[0].m.userptr; 
else if (q->memory <token> VB2_MEMORY_DMABUF) <answer> == 
b->m.fd = <token> <answer> vb->planes[0].m.fd; 
b->flags <token> ~V4L2_BUFFER_MASK_FLAGS; <answer> &= 
b->flags |= <token> & V4L2_BUF_FLAG_TIMESTAMP_MASK; <answer> q->timestamp_flags 
<token> (!q->copy_timestamp) { <answer> if 
b->flags &= <token> <answer> ~V4L2_BUF_FLAG_TSTAMP_SRC_MASK; 
b->flags |= <token> & V4L2_BUF_FLAG_TSTAMP_SRC_MASK; <answer> q->timestamp_flags 
<token> (vb->state) { <answer> switch 
<token> VB2_BUF_STATE_QUEUED: <answer> case 
<token> VB2_BUF_STATE_ACTIVE: <answer> case 
b->flags <token> V4L2_BUF_FLAG_QUEUED; <answer> |= 
case <token> <answer> VB2_BUF_STATE_IN_REQUEST: 
<token> |= V4L2_BUF_FLAG_IN_REQUEST; <answer> b->flags 
<token> VB2_BUF_STATE_ERROR: <answer> case 
<token> |= V4L2_BUF_FLAG_ERROR; <answer> b->flags 
<token> VB2_BUF_STATE_DONE: <answer> case 
b->flags |= <token> <answer> V4L2_BUF_FLAG_DONE; 
case <token> <answer> VB2_BUF_STATE_PREPARING: 
case <token> <answer> VB2_BUF_STATE_DEQUEUED: 
<token> int __fill_vb2_buffer(struct vb2_buffer *vb, struct vb2_plane *planes) <answer> static 
struct vb2_v4l2_buffer *vbuf <token> to_vb2_v4l2_buffer(vb); <answer> = 
unsigned <token> plane; <answer> int 
if <token> <answer> (!vb->vb2_queue->copy_timestamp) 
vb->timestamp <token> 0; <answer> = 
for (plane = 0; <token> < vb->num_planes; ++plane) { <answer> plane 
if (vb->vb2_queue->memory != VB2_MEMORY_MMAP) <token> <answer> { 
planes[plane].m = <token> <answer> vbuf->planes[plane].m; 
<token> = vbuf->planes[plane].length; <answer> planes[plane].length 
planes[plane].bytesused <token> vbuf->planes[plane].bytesused; <answer> = 
planes[plane].data_offset = <token> <answer> vbuf->planes[plane].data_offset; 
return <token> <answer> 0; 
static const <token> vb2_buf_ops v4l2_buf_ops = { <answer> struct 
<token> = __verify_planes_array_core, <answer> .verify_planes_array 
<token> = __init_vb2_v4l2_buffer, <answer> .init_buffer 
<token> = __fill_v4l2_buffer, <answer> .fill_user_buffer 
.fill_vb2_buffer = <token> <answer> __fill_vb2_buffer, 
.copy_timestamp <token> __copy_timestamp, <answer> = 
struct vb2_buffer *vb2_find_buffer(struct vb2_queue *q, <token> timestamp) <answer> u64 
<token> int i; <answer> unsigned 
struct <token> *vb2; <answer> vb2_buffer 
for (i = 0; i < q->max_num_buffers; i++) <token> <answer> { 
<token> = vb2_get_buffer(q, i); <answer> vb2 
<token> (!vb2) <answer> if 
if <token> && <answer> (vb2->copied_timestamp 
<token> == timestamp) <answer> vb2->timestamp 
return <token> <answer> vb2; 
<token> NULL; <answer> return 
int vb2_querybuf(struct vb2_queue <token> struct v4l2_buffer *b) <answer> *q, 
struct vb2_buffer <token> <answer> *vb; 
<token> ret; <answer> int 
if (b->type != <token> { <answer> q->type) 
dprintk(q, 1, <token> buffer type\n"); <answer> "wrong 
return <token> <answer> -EINVAL; 
<token> = vb2_get_buffer(q, b->index); <answer> vb 
if <token> { <answer> (!vb) 
dprintk(q, 1, "can't find the requested buffer <token> b->index); <answer> %u\n", 
return <token> <answer> -EINVAL; 
ret <token> __verify_planes_array(vb, b); <answer> = 
if <token> <answer> (!ret) 
vb2_core_querybuf(q, vb, <token> <answer> b); 
return <token> <answer> ret; 
static void vb2_set_flags_and_caps(struct vb2_queue <token> u32 memory, <answer> *q, 
u32 *flags, u32 <token> u32 *max_num_bufs) <answer> *caps, 
if (!q->allow_cache_hints || memory != V4L2_MEMORY_MMAP) <token> <answer> { 
*flags <token> 0; <answer> = 
} <token> { <answer> else 
b->flags <token> ~V4L2_BUF_FLAG_DONE; <answer> &= 
return <token> <answer> ret; 
int vb2_streamon(struct vb2_queue <token> enum v4l2_buf_type type) <answer> *q, 
if <token> { <answer> (vb2_fileio_is_active(q)) 
dprintk(q, 1, "file io <token> progress\n"); <answer> in 
<token> -EBUSY; <answer> return 
return vb2_core_streamon(q, <token> <answer> type); 
int vb2_streamoff(struct <token> *q, enum v4l2_buf_type type) <answer> vb2_queue 
if <token> { <answer> (vb2_fileio_is_active(q)) 
<token> 1, "file io in progress\n"); <answer> dprintk(q, 
<token> -EBUSY; <answer> return 
return vb2_core_streamoff(q, <token> <answer> type); 
int vb2_expbuf(struct vb2_queue *q, struct v4l2_exportbuffer <token> <answer> *eb) 
struct <token> *vb; <answer> vb2_buffer 
vb = <token> eb->index); <answer> vb2_get_buffer(q, 
if (!vb) <token> <answer> { 
dprintk(q, 1, "can't find the requested buffer <token> eb->index); <answer> %u\n", 
return <token> <answer> -EINVAL; 
return vb2_core_expbuf(q, &eb->fd, <token> vb, <answer> eb->type, 
<token> eb->flags); <answer> eb->plane, 
int vb2_queue_init_name(struct vb2_queue *q, <token> char *name) <answer> const 
if (WARN_ON(!q) <token> <answer> || 
WARN_ON(q->timestamp_flags <token> <answer> & 
<token> | <answer> ~(V4L2_BUF_FLAG_TIMESTAMP_MASK 
return <token> <answer> -EINVAL; 
q->quirk_poll_must_check_waiting_for_buffers <token> true; <answer> = 
if <token> <answer> (name) 
<token> name, sizeof(q->name)); <answer> strscpy(q->name, 
q->name[0] = <token> <answer> '\0'; 
return <token> <answer> vb2_core_queue_init(q); 
int vb2_queue_init(struct <token> *q) <answer> vb2_queue 
<token> vb2_queue_init_name(q, NULL); <answer> return 
<token> vb2_queue_release(struct vb2_queue *q) <answer> void 
int vb2_queue_change_type(struct vb2_queue *q, unsigned int <token> <answer> type) 
if <token> == q->type) <answer> (type 
return <token> <answer> 0; 
<token> (vb2_is_busy(q)) <answer> if 
return <token> <answer> -EBUSY; 
<token> = type; <answer> q->type 
return <token> <answer> 0; 
__poll_t <token> vb2_queue *q, struct file *file, poll_table *wait) <answer> vb2_poll(struct 
struct video_device *vfd = <token> <answer> video_devdata(file); 
<token> res; <answer> __poll_t 
res = vb2_core_poll(q, file, <token> <answer> wait); 
if (test_bit(V4L2_FL_USES_V4L2_FH, &vfd->flags)) <token> <answer> { 
struct v4l2_fh <token> = file->private_data; <answer> *fh 
poll_wait(file, &fh->wait, <token> <answer> wait); 
if <token> <answer> (v4l2_event_pending(fh)) 
res |= <token> <answer> EPOLLPRI; 
return <token> <answer> res; 
if (res <token> 0) <answer> == 
vdev->queue->owner <token> p->count ? file->private_data : NULL; <answer> = 
return <token> <answer> res; 
int <token> file *file, void *priv, <answer> vb2_ioctl_create_bufs(struct 
<token> v4l2_create_buffers *p) <answer> struct 
struct video_device *vdev = <token> <answer> video_devdata(file); 
int res = <token> p->memory, p->format.type); <answer> vb2_verify_memory_type(vdev->queue, 
p->index = <token> <answer> vb2_get_num_buffers(vdev->queue); 
vb2_set_flags_and_caps(vdev->queue, p->memory, <token> <answer> &p->flags, 
&p->capabilities, <token> <answer> &p->max_num_buffers); 
if (p->count <token> 0) <answer> == 
return res != -EBUSY <token> res : 0; <answer> ? 
<token> (res) <answer> if 
<token> res; <answer> return 
<token> (vb2_queue_is_busy(vdev->queue, file)) <answer> if 
<token> -EBUSY; <answer> return 
res = vb2_create_bufs(vdev->queue, <token> <answer> p); 
if (res <token> 0) <answer> == 
vdev->queue->owner <token> file->private_data; <answer> = 
<token> res; <answer> return 
int vb2_ioctl_prepare_buf(struct <token> *file, void *priv, <answer> file 
<token> v4l2_buffer *p) <answer> struct 
struct video_device *vdev = <token> <answer> video_devdata(file); 
if (vb2_queue_is_busy(vdev->queue, <token> <answer> file)) 
return <token> <answer> -EBUSY; 
return <token> vdev->v4l2_dev->mdev, p); <answer> vb2_prepare_buf(vdev->queue, 
int vb2_ioctl_querybuf(struct file *file, void *priv, struct v4l2_buffer <token> <answer> *p) 
struct video_device *vdev = <token> <answer> video_devdata(file); 
if <token> && mutex_lock_interruptible(lock)) <answer> (lock 
<token> EPOLLERR; <answer> return 
fileio = <token> <answer> q->fileio; 
res = <token> file, wait); <answer> vb2_poll(vdev->queue, 
<token> (vdev->queue) { <answer> if 
struct mutex *lock = vdev->queue->lock <token> <answer> ? 
vdev->queue->lock <token> vdev->lock; <answer> : 
<token> (lock) <answer> if 
vdev->queue->owner <token> NULL; <answer> = 
if <token> <answer> (lock) 
int vb2_request_validate(struct <token> *req) <answer> media_request 
struct <token> *obj; <answer> media_request_object 
int <token> = 0; <answer> ret 
<token> (!vb2_request_buffer_cnt(req)) <answer> if 
<token> -ENOENT; <answer> return 
list_for_each_entry(obj, &req->objects, <token> { <answer> list) 
if <token> <answer> (!obj->ops->prepare) 
ret = <token> <answer> obj->ops->prepare(obj); 
<token> (ret) <answer> if 
if <token> { <answer> (ret) 
list_for_each_entry_continue_reverse(obj, <token> list) <answer> &req->objects, 
if <token> <answer> (obj->ops->unprepare) 
<token> ret; <answer> return 
<token> 0; <answer> return 
void <token> media_request *req) <answer> vb2_request_queue(struct 
struct media_request_object <token> *obj_safe; <answer> *obj, 
list_for_each_entry_safe(obj, obj_safe, &req->objects, <token> <answer> list) 
if <token> <answer> (obj->ops->queue) 
MODULE_DESCRIPTION("Driver helper <token> for Video for Linux 2"); <answer> framework 
MODULE_AUTHOR("Pawel <token> <pawel@osciak.com>, Marek Szyprowski"); <answer> Osciak 
#include <token> <answer> <linux/kernel.h> 
<token> "mt76x02.h" <answer> #include 
void mt76x02_tx(struct ieee80211_hw *hw, struct ieee80211_tx_control <token> <answer> *control, 
struct <token> *skb) <answer> sk_buff 
struct <token> *info = IEEE80211_SKB_CB(skb); <answer> ieee80211_tx_info 
struct mt76x02_dev *dev <token> hw->priv; <answer> = 
struct ieee80211_vif <token> = info->control.vif; <answer> *vif 
struct mt76_wcid *wcid = <token> <answer> &dev->mt76.global_wcid; 
if (control->sta) <token> <answer> { 
<token> mt76x02_sta *msta; <answer> struct 
<token> = (struct mt76x02_sta *)control->sta->drv_priv; <answer> msta 
<token> = &msta->wcid; <answer> wcid 
} else <token> (vif) { <answer> if 
struct <token> *mvif; <answer> mt76x02_vif 
mvif = <token> mt76x02_vif *)vif->drv_priv; <answer> (struct 
wcid = <token> <answer> &mvif->group_wcid; 
mt76_tx(&dev->mphy, <token> wcid, skb); <answer> control->sta, 
void mt76x02_queue_rx_skb(struct mt76_dev *mdev, enum mt76_rxq_id <token> <answer> q, 
struct sk_buff *skb, u32 <token> <answer> *info) 
struct mt76x02_dev *dev = container_of(mdev, struct <token> mt76); <answer> mt76x02_dev, 
void *rxwi = <token> <answer> skb->data; 
if (q <token> MT_RXQ_MCU) { <answer> == 
mt76_mcu_rx_event(&dev->mt76, <token> <answer> skb); 
skb_pull(skb, sizeof(struct <token> <answer> mt76x02_rxwi)); 
if (mt76x02_mac_process_rx(dev, skb, <token> { <answer> rxwi)) 
<token> q, skb); <answer> mt76_rx(mdev, 
s8 <token> mt76x02_dev *dev, <answer> mt76x02_tx_get_max_txpwr_adj(struct 
const struct <token> *rate) <answer> ieee80211_tx_rate 
<token> max_txpwr; <answer> s8 
if <token> & IEEE80211_TX_RC_VHT_MCS) { <answer> (rate->flags 
u8 mcs <token> ieee80211_rate_get_vht_mcs(rate); <answer> = 
if (mcs == 8 || mcs == <token> { <answer> 9) 
max_txpwr <token> dev->rate_power.vht[0]; <answer> = 
} <token> { <answer> else 
<token> nss, idx; <answer> u8 
nss <token> ieee80211_rate_get_vht_nss(rate); <answer> = 
idx = ((nss - 1) << <token> + mcs; <answer> 3) 
<token> = dev->rate_power.ht[idx & 0xf]; <answer> max_txpwr 
} else if (rate->flags & <token> { <answer> IEEE80211_TX_RC_MCS) 
<token> = dev->rate_power.ht[rate->idx & 0xf]; <answer> max_txpwr 
} <token> { <answer> else 
<token> nl80211_band band = dev->mphy.chandef.chan->band; <answer> enum 
if <token> == NL80211_BAND_2GHZ) { <answer> (band 
<token> struct ieee80211_rate *r; <answer> const 
struct wiphy *wiphy = <token> <answer> dev->mt76.hw->wiphy; 
struct mt76x02_rate_power <token> = &dev->rate_power; <answer> *rp 
<token> = &wiphy->bands[band]->bitrates[rate->idx]; <answer> r 
if (r->flags <token> IEEE80211_RATE_SHORT_PREAMBLE) <answer> & 
max_txpwr = rp->cck[r->hw_value & <token> <answer> 0x3]; 
<token> = rp->ofdm[r->hw_value & 0x7]; <answer> max_txpwr 
} <token> { <answer> else 
max_txpwr <token> dev->rate_power.ofdm[rate->idx & 0x7]; <answer> = 
<token> max_txpwr; <answer> return 
s8 <token> mt76x02_dev *dev, s8 txpwr, s8 max_txpwr_adj) <answer> mt76x02_tx_get_txpwr_adj(struct 
<token> = min_t(s8, txpwr, dev->txpower_conf); <answer> txpwr 
txpwr -= (dev->target_power <token> dev->target_power_delta[0]); <answer> + 
txpwr = min_t(s8, <token> max_txpwr_adj); <answer> txpwr, 
<token> (!dev->enable_tpc) <answer> if 
return <token> <answer> 0; 
else if (txpwr <token> 0) <answer> >= 
<token> min_t(s8, txpwr, 7); <answer> return 
return (txpwr < -16) ? 8 : (txpwr + <token> / 2; <answer> 32) 
void mt76x02_tx_set_txpwr_auto(struct mt76x02_dev *dev, <token> txpwr) <answer> s8 
s8 <token> <answer> txpwr_adj; 
<token> = mt76x02_tx_get_txpwr_adj(dev, txpwr, <answer> txpwr_adj 
<token> MT_PROT_AUTO_TX_CFG, <answer> mt76_rmw_field(dev, 
<token> txpwr_adj); <answer> MT_PROT_AUTO_TX_CFG_PROT_PADJ, 
<token> MT_PROT_AUTO_TX_CFG, <answer> mt76_rmw_field(dev, 
MT_PROT_AUTO_TX_CFG_AUTO_PADJ, <token> <answer> txpwr_adj); 
bool mt76x02_tx_status_data(struct mt76_dev *mdev, <token> *update) <answer> u8 
struct mt76x02_dev *dev <token> container_of(mdev, struct mt76x02_dev, mt76); <answer> = 
struct mt76x02_tx_status <token> <answer> stat; 
if (!mt76x02_mac_load_tx_status(dev, <token> <answer> &stat)) 
<token> false; <answer> return 
mt76x02_send_tx_status(dev, <token> update); <answer> &stat, 
<token> true; <answer> return 
int mt76x02_tx_prepare_skb(struct <token> *mdev, void *txwi_ptr, <answer> mt76_dev 
enum mt76_txq_id qid, struct <token> *wcid, <answer> mt76_wcid 
<token> ieee80211_sta *sta, <answer> struct 
struct <token> *tx_info) <answer> mt76_tx_info 
<token> mt76x02_dev *dev = container_of(mdev, struct mt76x02_dev, mt76); <answer> struct 
struct ieee80211_hdr *hdr <token> (struct ieee80211_hdr *)tx_info->skb->data; <answer> = 
struct mt76x02_txwi *txwi = <token> <answer> txwi_ptr; 
<token> ampdu = IEEE80211_SKB_CB(tx_info->skb)->flags & IEEE80211_TX_CTL_AMPDU; <answer> bool 
int hdrlen, len, pid, <token> = MT_QSEL_EDCA; <answer> qsel 
if (qid == MT_TXQ_PSD && wcid <token> wcid->idx < 128) <answer> && 
mt76x02_mac_wcid_set_drop(dev, <token> false); <answer> wcid->idx, 
hdrlen = <token> <answer> ieee80211_hdrlen(hdr->frame_control); 
<token> = tx_info->skb->len - (hdrlen & 2); <answer> len 
mt76x02_mac_write_txwi(dev, txwi, <token> wcid, sta, len); <answer> tx_info->skb, 
<token> = mt76_tx_status_skb_add(mdev, wcid, tx_info->skb); <answer> pid 
<token> <linux/module.h> <answer> #include 
<token> <net/tcp.h> <answer> #include 
static const struct hstcp_aimd_val <token> <answer> { 
<token> int cwnd; <answer> unsigned 
unsigned int <token> <answer> md; 
<token> hstcp_aimd_vals[] = { <answer> } 
tp->snd_cwnd_clamp <token> min_t(u32, tp->snd_cwnd_clamp, 0xffffffff/128); <answer> = 
<token> void hstcp_cong_avoid(struct sock *sk, u32 ack, u32 acked) <answer> static 
struct tcp_sock *tp <token> tcp_sk(sk); <answer> = 
struct <token> *ca = inet_csk_ca(sk); <answer> hstcp 
<token> (!tcp_is_cwnd_limited(sk)) <answer> if 
if <token> <answer> (tcp_in_slow_start(tp)) 
tcp_slow_start(tp, <token> <answer> acked); 
else <token> <answer> { 
if <token> > hstcp_aimd_vals[ca->ai].cwnd) { <answer> (tcp_snd_cwnd(tp) 
<token> (tcp_snd_cwnd(tp) > hstcp_aimd_vals[ca->ai].cwnd && <answer> while 
ca->ai < <token> - 1) <answer> HSTCP_AIMD_MAX 
} else if (ca->ai && tcp_snd_cwnd(tp) <= hstcp_aimd_vals[ca->ai-1].cwnd) <token> <answer> { 
while (ca->ai && tcp_snd_cwnd(tp) <= <token> <answer> hstcp_aimd_vals[ca->ai-1].cwnd) 
#include <token> <answer> <linux/quotaops.h> 
#include <token> <answer> "ext4_jbd2.h" 
#include <token> <answer> "ext4.h" 
#include <token> <answer> "xattr.h" 
<token> "acl.h" <answer> #include 
static struct posix_acl <token> <answer> * 
ext4_acl_from_disk(const <token> *value, size_t size) <answer> void 
const char *end = (char *)value <token> size; <answer> + 
<token> n, count; <answer> int 
struct <token> *acl; <answer> posix_acl 
if <token> <answer> (!value) 
return <token> <answer> NULL; 
<token> (size < sizeof(ext4_acl_header)) <answer> if 
return <token> <answer> ERR_PTR(-EINVAL); 
if <token> *)value)->a_version != <answer> (((ext4_acl_header 
<token> ERR_PTR(-EINVAL); <answer> return 
value = (char <token> + sizeof(ext4_acl_header); <answer> *)value 
<token> = ext4_acl_count(size); <answer> count 
<token> (count < 0) <answer> if 
return <token> <answer> ERR_PTR(-EINVAL); 
if (count == <token> <answer> 0) 
return <token> <answer> NULL; 
<token> = posix_acl_alloc(count, GFP_NOFS); <answer> acl 
if <token> <answer> (!acl) 
return <token> <answer> ERR_PTR(-ENOMEM); 
for (n <token> 0; n < count; n++) { <answer> = 
<token> *entry = <answer> ext4_acl_entry 
(ext4_acl_entry <token> <answer> *)value; 
if <token> *)value + sizeof(ext4_acl_entry_short) > end) <answer> ((char 
<token> fail; <answer> goto 
acl->a_entries[n].e_tag <token> le16_to_cpu(entry->e_tag); <answer> = 
<token> = le16_to_cpu(entry->e_perm); <answer> acl->a_entries[n].e_perm 
switch (acl->a_entries[n].e_tag) <token> <answer> { 
<token> ACL_USER_OBJ: <answer> case 
case <token> <answer> ACL_GROUP_OBJ: 
case <token> <answer> ACL_MASK: 
case <token> <answer> ACL_OTHER: 
value = <token> *)value + <answer> (char 
<token> ACL_USER: <answer> case 
value = (char <token> + sizeof(ext4_acl_entry); <answer> *)value 
if ((char <token> > end) <answer> *)value 
goto <token> <answer> fail; 
<token> = <answer> acl->a_entries[n].e_uid 
case <token> <answer> ACL_GROUP: 
value = <token> *)value + sizeof(ext4_acl_entry); <answer> (char 
if ((char *)value > <token> <answer> end) 
goto <token> <answer> fail; 
acl->a_entries[n].e_gid <token> <answer> = 
goto <token> <answer> fail; 
<token> (value != end) <answer> if 
goto <token> <answer> fail; 
<token> acl; <answer> return 
return <token> <answer> ERR_PTR(-EINVAL); 
<token> void * <answer> static 
<token> struct posix_acl *acl, size_t *size) <answer> ext4_acl_to_disk(const 
<token> *ext_acl; <answer> ext4_acl_header 
<token> *e; <answer> char 
<token> n; <answer> size_t 
*size = <token> <answer> ext4_acl_size(acl->a_count); 
ext_acl <token> kmalloc(sizeof(ext4_acl_header) + acl->a_count * <answer> = 
<token> GFP_NOFS); <answer> sizeof(ext4_acl_entry), 
if <token> <answer> (!ext_acl) 
<token> ERR_PTR(-ENOMEM); <answer> return 
<token> = cpu_to_le32(EXT4_ACL_VERSION); <answer> ext_acl->a_version 
e <token> (char *)ext_acl + sizeof(ext4_acl_header); <answer> = 
for (n = 0; n < acl->a_count; n++) <token> <answer> { 
const struct posix_acl_entry *acl_e = <token> <answer> &acl->a_entries[n]; 
ext4_acl_entry *entry <token> (ext4_acl_entry *)e; <answer> = 
<token> = cpu_to_le16(acl_e->e_tag); <answer> entry->e_tag 
entry->e_perm = <token> <answer> cpu_to_le16(acl_e->e_perm); 
<token> (acl_e->e_tag) { <answer> switch 
<token> ACL_USER: <answer> case 
entry->e_id = <token> <answer> cpu_to_le32( 
from_kuid(&init_user_ns, <token> <answer> acl_e->e_uid)); 
<token> += sizeof(ext4_acl_entry); <answer> e 
<token> ACL_GROUP: <answer> case 
entry->e_id = <token> <answer> cpu_to_le32( 
<token> acl_e->e_gid)); <answer> from_kgid(&init_user_ns, 
e <token> sizeof(ext4_acl_entry); <answer> += 
case <token> <answer> ACL_USER_OBJ: 
<token> ACL_GROUP_OBJ: <answer> case 
<token> ACL_MASK: <answer> case 
<token> ACL_OTHER: <answer> case 
<token> += sizeof(ext4_acl_entry_short); <answer> e 
<token> fail; <answer> goto 
return <token> *)ext_acl; <answer> (char 
<token> ERR_PTR(-EINVAL); <answer> return 
struct posix_acl <token> <answer> * 
ext4_get_acl(struct inode <token> int type, bool rcu) <answer> *inode, 
<token> name_index; <answer> int 
<token> *value = NULL; <answer> char 
struct posix_acl <token> <answer> *acl; 
<token> retval; <answer> int 
if <token> <answer> (rcu) 
return <token> <answer> ERR_PTR(-ECHILD); 
switch (type) <token> <answer> { 
<token> ACL_TYPE_ACCESS: <answer> case 
name_index <token> EXT4_XATTR_INDEX_POSIX_ACL_ACCESS; <answer> = 
case <token> <answer> ACL_TYPE_DEFAULT: 
name_index <token> EXT4_XATTR_INDEX_POSIX_ACL_DEFAULT; <answer> = 
retval = ext4_xattr_get(inode, name_index, <token> NULL, 0); <answer> "", 
if (retval > <token> { <answer> 0) 
value <token> kmalloc(retval, GFP_NOFS); <answer> = 
<token> (!value) <answer> if 
<token> ERR_PTR(-ENOMEM); <answer> return 
retval <token> ext4_xattr_get(inode, name_index, "", value, retval); <answer> = 
if <token> > 0) <answer> (retval 
acl = ext4_acl_from_disk(value, <token> <answer> retval); 
<token> if (retval == -ENODATA || retval == -ENOSYS) <answer> else 
acl = <token> <answer> NULL; 
acl <token> ERR_PTR(retval); <answer> = 
return <token> <answer> acl; 
static <token> <answer> int 
__ext4_set_acl(handle_t *handle, struct inode *inode, <token> type, <answer> int 
struct posix_acl *acl, int <token> <answer> xattr_flags) 
int <token> <answer> name_index; 
void *value = <token> <answer> NULL; 
size_t <token> = 0; <answer> size 
int <token> <answer> error; 
switch <token> { <answer> (type) 
<token> ACL_TYPE_ACCESS: <answer> case 
<token> = EXT4_XATTR_INDEX_POSIX_ACL_ACCESS; <answer> name_index 
case <token> <answer> ACL_TYPE_DEFAULT: 
name_index <token> EXT4_XATTR_INDEX_POSIX_ACL_DEFAULT; <answer> = 
if <token> <answer> (!S_ISDIR(inode->i_mode)) 
return acl <token> -EACCES : 0; <answer> ? 
return <token> <answer> -EINVAL; 
if <token> { <answer> (acl) 
<token> = ext4_acl_to_disk(acl, &size); <answer> value 
<token> (IS_ERR(value)) <answer> if 
<token> (int)PTR_ERR(value); <answer> return 
error = ext4_xattr_set_handle(handle, <token> name_index, "", <answer> inode, 
value, size, <token> <answer> xattr_flags); 
if <token> <answer> (!error) 
set_cached_acl(inode, type, <token> <answer> acl); 
return <token> <answer> error; 
ext4_set_acl(struct mnt_idmap *idmap, struct <token> *dentry, <answer> dentry 
struct <token> *acl, int type) <answer> posix_acl 
handle_t <token> <answer> *handle; 
<token> error, credits, retries = 0; <answer> int 
size_t <token> = acl ? ext4_acl_size(acl->a_count) : 0; <answer> acl_size 
struct inode *inode = <token> <answer> d_inode(dentry); 
<token> mode = inode->i_mode; <answer> umode_t 
int update_mode = <token> <answer> 0; 
error = <token> <answer> dquot_initialize(inode); 
if <token> <answer> (error) 
<token> error; <answer> return 
ext4_init_acl(handle_t *handle, struct <token> *inode, struct inode *dir) <answer> inode 
<token> posix_acl *default_acl, *acl; <answer> struct 
int <token> <answer> error; 
error = posix_acl_create(dir, &inode->i_mode, &default_acl, <token> <answer> &acl); 
<token> (error) <answer> if 
<token> error; <answer> return 
<token> (default_acl) { <answer> if 
error = __ext4_set_acl(handle, <token> ACL_TYPE_DEFAULT, <answer> inode, 
default_acl, <token> <answer> XATTR_CREATE); 
} else <token> <answer> { 
inode->i_default_acl <token> NULL; <answer> = 
if (acl) <token> <answer> { 
if <token> <answer> (!error) 
error = __ext4_set_acl(handle, <token> ACL_TYPE_ACCESS, <answer> inode, 
acl, <token> <answer> XATTR_CREATE); 
} <token> { <answer> else 
inode->i_acl = <token> <answer> NULL; 
return <token> <answer> error; 
<token> <errno.h> <answer> #include 
<token> <stdio.h> <answer> #include 
<token> <stdint.h> <answer> #include 
<token> <stdlib.h> <answer> #include 
<token> <unistd.h> <answer> #include 
<token> <sys/ioctl.h> <answer> #include 
<token> <sys/types.h> <answer> #include 
#include <token> <answer> <sys/stat.h> 
#include <token> <answer> <fcntl.h> 
#include <token> <answer> <linux/fs.h> 
static int set_immutable(const <token> *path, int immutable) <answer> char 
unsigned <token> flags; <answer> int 
<token> fd; <answer> int 
int <token> <answer> rc; 
int <token> <answer> error; 
<token> = open(path, O_RDONLY); <answer> fd 
<token> (fd < 0) <answer> if 
return <token> <answer> fd; 
rc <token> ioctl(fd, FS_IOC_GETFLAGS, &flags); <answer> = 
if (rc < <token> { <answer> 0) 
error = <token> <answer> errno; 
errno <token> error; <answer> = 
return <token> <answer> rc; 
<token> (immutable) <answer> if 
<token> |= FS_IMMUTABLE_FL; <answer> flags 
flags &= <token> <answer> ~FS_IMMUTABLE_FL; 
<token> = ioctl(fd, FS_IOC_SETFLAGS, &flags); <answer> rc 
<token> = errno; <answer> error 
errno = <token> <answer> error; 
return <token> <answer> rc; 
static int get_immutable(const <token> *path) <answer> char 
unsigned int <token> <answer> flags; 
<token> fd; <answer> int 
<token> rc; <answer> int 
<token> error; <answer> int 
fd <token> open(path, O_RDONLY); <answer> = 
if (fd <token> 0) <answer> < 
return <token> <answer> fd; 
<token> = ioctl(fd, FS_IOC_GETFLAGS, &flags); <answer> rc 
if (rc <token> 0) { <answer> < 
<token> = errno; <answer> error 
<token> = error; <answer> errno 
return <token> <answer> rc; 
<token> (flags & FS_IMMUTABLE_FL) <answer> if 
return <token> <answer> 1; 
return <token> <answer> 0; 
int <token> argc, char **argv) <answer> main(int 
const char <token> <answer> *path; 
<token> buf[5]; <answer> char 
int <token> rc; <answer> fd, 
if <token> < 2) { <answer> (argc 
fprintf(stderr, "usage: <token> <path>\n", argv[0]); <answer> %s 
return <token> <answer> EXIT_FAILURE; 
path = <token> <answer> argv[1]; 
*(uint32_t *)buf = <token> <answer> 0x7; 
buf[4] = <token> <answer> 0; 
<token> "internal.h" <answer> #include 
int determine_node_id(struct addr_ctx *ctx, u8 socket_id, u8 <token> <answer> die_id) 
<token> socket_id_bits, die_id_bits; <answer> u16 
if (socket_id > 0 && df_cfg.socket_id_mask <token> 0) { <answer> == 
atl_debug(ctx, "Invalid <token> inputs: socket_id=%u socket_id_mask=0x%x", <answer> socket 
<token> df_cfg.socket_id_mask); <answer> socket_id, 
<token> -EINVAL; <answer> return 
<token> = FIELD_GET(DF_MAJOR_REVISION, reg); <answer> rev 
if <token> <answer> (!rev) 
return <token> <answer> determine_df_rev_legacy(); 
if (rev == <token> <answer> 4) 
return <token> <answer> df4_determine_df_rev(reg); 
<token> -EINVAL; <answer> return 
<token> void get_num_maps(void) <answer> static 
switch <token> { <answer> (df_cfg.rev) 
case <token> <answer> DF2: 
<token> DF3: <answer> case 
<token> DF3p5: <answer> case 
<token> = 2; <answer> df_cfg.num_coh_st_maps 
case <token> <answer> DF4: 
case <token> <answer> DF4p5: 
df_cfg.num_coh_st_maps <token> 4; <answer> = 
static <token> apply_node_id_shift(void) <answer> void 
if <token> == DF2) <answer> (df_cfg.rev 
<token> = df_cfg.node_id_shift; <answer> df_cfg.die_id_shift 
df_cfg.die_id_mask <token> df_cfg.node_id_shift; <answer> <<= 
<token> <<= df_cfg.node_id_shift; <answer> df_cfg.socket_id_mask 
df_cfg.socket_id_shift += <token> <answer> df_cfg.node_id_shift; 
static void <token> <answer> dump_df_cfg(void) 
pr_debug("rev=0x%x", <token> <answer> df_cfg.rev); 
<token> df_cfg.component_id_mask); <answer> pr_debug("component_id_mask=0x%x", 
pr_debug("die_id_mask=0x%x", <token> <answer> df_cfg.die_id_mask); 
pr_debug("node_id_mask=0x%x", <token> <answer> df_cfg.node_id_mask); 
<token> df_cfg.socket_id_mask); <answer> pr_debug("socket_id_mask=0x%x", 
<token> df_cfg.die_id_shift); <answer> pr_debug("die_id_shift=0x%x", 
pr_debug("node_id_shift=0x%x", <token> <answer> df_cfg.node_id_shift); 
pr_debug("socket_id_shift=0x%x", <token> <answer> df_cfg.socket_id_shift); 
pr_debug("num_coh_st_maps=%u", <token> <answer> df_cfg.num_coh_st_maps); 
<token> df_cfg.flags.legacy_ficaa); <answer> pr_debug("flags.legacy_ficaa=%u", 
pr_debug("flags.socket_id_shift_quirk=%u", <token> <answer> df_cfg.flags.socket_id_shift_quirk); 
int <token> <answer> get_df_system_info(void) 
<token> (determine_df_rev()) { <answer> if 
pr_warn("amd_atl: Failed to determine <token> Revision"); <answer> DF 
<token> = UNKNOWN; <answer> df_cfg.rev 
<token> -EINVAL; <answer> return 
<token> 0; <answer> return 
#include <token> <answer> <linux/socket.h> 
<token> <linux/net.h> <answer> #include 
<token> <linux/ipv6.h> <answer> #include 
#include <token> <answer> <linux/proc_fs.h> 
#include <token> <answer> <linux/seq_file.h> 
<token> <linux/stddef.h> <answer> #include 
<token> <linux/export.h> <answer> #include 
#include <token> <answer> <net/net_namespace.h> 
<token> <net/ip.h> <answer> #include 
#include <token> <answer> <net/sock.h> 
<token> <net/tcp.h> <answer> #include 
<token> <net/udp.h> <answer> #include 
#include <token> <answer> <net/transp_v6.h> 
#include <token> <answer> <net/ipv6.h> 
#define <token> b, c, d) \ <answer> MAX4(a, 
max_t(u32, max_t(u32, a, b), max_t(u32, c, <token> <answer> d)) 
<token> SNMP_MIB_MAX MAX4(UDP_MIB_MAX, TCP_MIB_MAX, \ <answer> #define 
IPSTATS_MIB_MAX, <token> <answer> ICMP_MIB_MAX) 
static int sockstat6_seq_show(struct <token> *seq, void *v) <answer> seq_file 
struct net <token> = seq->private; <answer> *net 
seq_printf(seq, "TCP6: <token> %d\n", <answer> inuse 
<token> &tcpv6_prot)); <answer> sock_prot_inuse_get(net, 
seq_printf(seq, <token> inuse %d\n", <answer> "UDP6: 
sock_prot_inuse_get(net, <token> <answer> &udpv6_prot)); 
seq_printf(seq, <token> inuse %d\n", <answer> "UDPLITE6: 
<token> &udplitev6_prot)); <answer> sock_prot_inuse_get(net, 
<token> "RAW6: inuse %d\n", <answer> seq_printf(seq, 
<token> &rawv6_prot)); <answer> sock_prot_inuse_get(net, 
seq_printf(seq, <token> inuse %u memory %lu\n", <answer> "FRAG6: 
<token> 0; <answer> return 
static <token> struct snmp_mib snmp6_ipstats_list[] = { <answer> const 
static <token> snmp6_seq_show_item(struct seq_file *seq, void __percpu *pcpumib, <answer> void 
atomic_long_t <token> <answer> *smib, 
<token> struct snmp_mib *itemlist) <answer> const 
unsigned <token> buff[SNMP_MIB_MAX]; <answer> long 
<token> i; <answer> int 
if (pcpumib) <token> <answer> { 
memset(buff, 0, sizeof(unsigned <token> * SNMP_MIB_MAX); <answer> long) 
snmp_get_cpu_field_batch(buff, <token> pcpumib); <answer> itemlist, 
for (i <token> 0; itemlist[i].name; i++) <answer> = 
<token> "%-32s\t%lu\n", <answer> seq_printf(seq, 
itemlist[i].name, <token> <answer> buff[i]); 
} else <token> <answer> { 
for (i <token> 0; itemlist[i].name; i++) <answer> = 
<token> "%-32s\t%lu\n", itemlist[i].name, <answer> seq_printf(seq, 
atomic_long_read(smib + <token> <answer> itemlist[i].entry)); 
static void <token> seq_file *seq, void __percpu *mib, <answer> snmp6_seq_show_item64(struct 
const struct snmp_mib <token> size_t syncpoff) <answer> *itemlist, 
<token> buff64[SNMP_MIB_MAX]; <answer> u64 
int <token> <answer> i; 
memset(buff64, <token> sizeof(u64) * SNMP_MIB_MAX); <answer> 0, 
<token> itemlist, mib, syncpoff); <answer> snmp_get_cpu_field64_batch(buff64, 
<token> (i = 0; itemlist[i].name; i++) <answer> for 
seq_printf(seq, "%-32s\t%llu\n", <token> buff64[i]); <answer> itemlist[i].name, 
static <token> snmp6_seq_show(struct seq_file *seq, void *v) <answer> int 
struct net *net = <token> net *)seq->private; <answer> (struct 
<token> net->mib.ipv6_statistics, <answer> snmp6_seq_show_item64(seq, 
snmp6_ipstats_list, offsetof(struct ipstats_mib, <token> <answer> syncp)); 
<token> net->mib.icmpv6_statistics, <answer> snmp6_seq_show_item(seq, 
<token> snmp6_icmp6_list); <answer> NULL, 
snmp6_seq_show_icmpv6msg(seq, <token> <answer> net->mib.icmpv6msg_statistics->mibs); 
<token> net->mib.udp_stats_in6, <answer> snmp6_seq_show_item(seq, 
<token> snmp6_udp6_list); <answer> NULL, 
<token> net->mib.udplite_stats_in6, <answer> snmp6_seq_show_item(seq, 
<token> snmp6_udplite6_list); <answer> NULL, 
return <token> <answer> 0; 
static int snmp6_dev_seq_show(struct seq_file *seq, <token> *v) <answer> void 
struct inet6_dev <token> = (struct inet6_dev *)seq->private; <answer> *idev 
seq_printf(seq, "%-32s\t%u\n", <token> idev->dev->ifindex); <answer> "ifIndex", 
<token> idev->stats.ipv6, <answer> snmp6_seq_show_item64(seq, 
snmp6_ipstats_list, offsetof(struct <token> syncp)); <answer> ipstats_mib, 
snmp6_seq_show_item(seq, <token> idev->stats.icmpv6dev->mibs, <answer> NULL, 
<token> idev->stats.icmpv6msgdev->mibs); <answer> snmp6_seq_show_icmpv6msg(seq, 
<token> 0; <answer> return 
int snmp6_register_dev(struct inet6_dev <token> <answer> *idev) 
struct <token> *p; <answer> proc_dir_entry 
struct <token> *net; <answer> net 
if <token> || !idev->dev) <answer> (!idev 
<token> -EINVAL; <answer> return 
<token> = dev_net(idev->dev); <answer> net 
<token> (!net->mib.proc_net_devsnmp6) <answer> if 
<token> -ENOENT; <answer> return 
p <token> proc_create_single_data(idev->dev->name, 0444, <answer> = 
net->mib.proc_net_devsnmp6, snmp6_dev_seq_show, <token> <answer> idev); 
<token> (!p) <answer> if 
<token> -ENOMEM; <answer> return 
idev->stats.proc_dir_entry <token> p; <answer> = 
return <token> <answer> 0; 
int snmp6_unregister_dev(struct inet6_dev <token> <answer> *idev) 
struct net <token> = dev_net(idev->dev); <answer> *net 
<token> (!net->mib.proc_net_devsnmp6) <answer> if 
return <token> <answer> -ENOENT; 
<token> (!idev->stats.proc_dir_entry) <answer> if 
<token> -EINVAL; <answer> return 
<token> = NULL; <answer> idev->stats.proc_dir_entry 
<token> 0; <answer> return 
static int __net_init ipv6_proc_init_net(struct net <token> <answer> *net) 
if (!proc_create_net_single("sockstat6", <token> net->proc_net, <answer> 0444, 
sockstat6_seq_show, <token> <answer> NULL)) 
return <token> <answer> -ENOMEM; 
<token> (!proc_create_net_single("snmp6", 0444, net->proc_net, <answer> if 
snmp6_seq_show, <token> <answer> NULL)) 
<token> proc_snmp6_fail; <answer> goto 
<token> = proc_mkdir("dev_snmp6", net->proc_net); <answer> net->mib.proc_net_devsnmp6 
<token> (!net->mib.proc_net_devsnmp6) <answer> if 
goto <token> <answer> proc_dev_snmp6_fail; 
return <token> <answer> 0; 
<token> net->proc_net); <answer> remove_proc_entry("snmp6", 
remove_proc_entry("sockstat6", <token> <answer> net->proc_net); 
<token> -ENOMEM; <answer> return 
static void <token> ipv6_proc_exit_net(struct net *net) <answer> __net_exit 
<token> net->proc_net); <answer> remove_proc_entry("sockstat6", 
<token> net->proc_net); <answer> remove_proc_entry("dev_snmp6", 
remove_proc_entry("snmp6", <token> <answer> net->proc_net); 
static struct pernet_operations <token> = { <answer> ipv6_proc_ops 
.init = <token> <answer> ipv6_proc_init_net, 
<token> = ipv6_proc_exit_net, <answer> .exit 
int __init <token> <answer> ipv6_misc_proc_init(void) 
return <token> <answer> register_pernet_subsys(&ipv6_proc_ops); 
void <token> <answer> ipv6_misc_proc_exit(void) 
#include <token> <answer> "xfs.h" 
<token> "xfs_fs.h" <answer> #include 
<token> "xfs_shared.h" <answer> #include 
#include <token> <answer> "xfs_format.h" 
<token> "xfs_trans_resv.h" <answer> #include 
#include <token> <answer> "xfs_mount.h" 
<token> "xfs_defer.h" <answer> #include 
<token> "xfs_btree.h" <answer> #include 
#include <token> <answer> "xfs_bit.h" 
#include <token> <answer> "xfs_format.h" 
#include <token> <answer> "xfs_log_format.h" 
<token> "xfs_trans.h" <answer> #include 
#include <token> <answer> "xfs_sb.h" 
#include <token> <answer> "xfs_inode.h" 
#include <token> <answer> "xfs_inode_fork.h" 
<token> "xfs_alloc.h" <answer> #include 
<token> "xfs_bmap.h" <answer> #include 
#include <token> <answer> "xfs_quota.h" 
#include <token> <answer> "xfs_qm.h" 
<token> "xfs_dquot.h" <answer> #include 
<token> "xfs_dquot_item.h" <answer> #include 
#include <token> <answer> "xfs_reflink.h" 
<token> "xfs_bmap_btree.h" <answer> #include 
<token> "xfs_trans_space.h" <answer> #include 
#include <token> <answer> "scrub/xfs_scrub.h" 
<token> "scrub/scrub.h" <answer> #include 
#include <token> <answer> "scrub/common.h" 
#include <token> <answer> "scrub/quota.h" 
<token> "scrub/trace.h" <answer> #include 
<token> "scrub/repair.h" <answer> #include 
struct xrep_quota_info <token> <answer> { 
struct <token> *sc; <answer> xfs_scrub 
bool <token> <answer> need_quotacheck; 
<token> int <answer> STATIC 
<token> xfs_scrub *sc, <answer> struct 
struct xfs_dquot <token> <answer> *dq, 
<token> xfs_bmbt_irec *irec) <answer> struct 
<token> xfs_buf *bp; <answer> struct 
struct <token> *mp = sc->mp; <answer> xfs_mount 
int <token> = 1; <answer> nmaps 
int <token> <answer> error; 
xfs_trans_ijoin(sc->tp, <token> 0); <answer> sc->ip, 
<token> = xrep_defer_finish(sc); <answer> error 
if <token> <answer> (error) 
<token> error; <answer> return 
return <token> <answer> xfs_trans_roll(&sc->tp); 
dq->q_blkno <token> XFS_FSB_TO_DADDR(mp, irec.br_startblock); <answer> = 
*dirty = <token> <answer> true; 
return <token> <answer> 0; 
xchk_ilock(sc, <token> <answer> XFS_ILOCK_EXCL); 
error = <token> dq, &dirty); <answer> xrep_quota_item_bmap(sc, 
<token> XFS_ILOCK_EXCL); <answer> xchk_iunlock(sc, 
if <token> <answer> (error) 
<token> error; <answer> return 
if <token> && dq->q_blk.count > mp->m_sb.sb_dblocks) { <answer> (!xfs_has_reflink(mp) 
dq->q_blk.reserved -= <token> <answer> dq->q_blk.count; 
<token> += mp->m_sb.sb_dblocks; <answer> dq->q_blk.reserved 
dq->q_blk.count = <token> <answer> mp->m_sb.sb_dblocks; 
<token> = true; <answer> rqi->need_quotacheck 
<token> = true; <answer> dirty 
fs_icount = <token> <answer> percpu_counter_sum(&mp->m_icount); 
if <token> > fs_icount) { <answer> (dq->q_ino.count 
dq->q_ino.reserved <token> dq->q_ino.count; <answer> -= 
dq->q_ino.reserved <token> fs_icount; <answer> += 
<token> = fs_icount; <answer> dq->q_ino.count 
rqi->need_quotacheck = <token> <answer> true; 
dirty = <token> <answer> true; 
if (dq->q_rtb.count > mp->m_sb.sb_rblocks) <token> <answer> { 
<token> -= dq->q_rtb.count; <answer> dq->q_rtb.reserved 
dq->q_rtb.reserved += <token> <answer> mp->m_sb.sb_rblocks; 
dq->q_rtb.count = <token> <answer> mp->m_sb.sb_rblocks; 
rqi->need_quotacheck = <token> <answer> true; 
<token> = true; <answer> dirty 
<token> &dq->q_blk, &dirty); <answer> xrep_quota_item_timer(sc, 
<token> &dq->q_ino, &dirty); <answer> xrep_quota_item_timer(sc, 
xrep_quota_item_timer(sc, <token> &dirty); <answer> &dq->q_rtb, 
<token> (!dirty) <answer> if 
return <token> <answer> 0; 
<token> dq->q_type, dq->q_id); <answer> trace_xrep_dquot_item(sc->mp, 
dq->q_flags <token> XFS_DQFLAG_DIRTY; <answer> |= 
xfs_trans_dqjoin(sc->tp, <token> <answer> dq); 
if (dq->q_id) <token> <answer> { 
<token> dq); <answer> xfs_trans_log_dquot(sc->tp, 
error = <token> <answer> xfs_trans_roll(&sc->tp); 
<token> error; <answer> return 
<token> ((ddq->d_type & XFS_DQTYPE_REC_MASK) != dqtype || <answer> if 
<token> == be32_to_cpu(ddq->d_id)) { <answer> id 
<token> bp); <answer> xfs_trans_brelse(sc->tp, 
<token> 0; <answer> return 
<token> error; <answer> return 
<token> int <answer> STATIC 
<token> xfs_scrub *sc, <answer> struct 
<token> dqtype) <answer> xfs_dqtype_t 
<token> xfs_bmbt_irec irec = { 0 }; <answer> struct 
struct <token> icur; <answer> xfs_iext_cursor 
struct xfs_quotainfo <token> = sc->mp->m_quotainfo; <answer> *qi 
<token> xfs_ifork *ifp; <answer> struct 
xfs_fileoff_t <token> <answer> max_dqid_off; 
<token> off; <answer> xfs_fileoff_t 
<token> fsbno; <answer> xfs_fsblock_t 
bool truncate = <token> <answer> false; 
bool <token> = false; <answer> joined 
<token> error = 0; <answer> int 
error = <token> <answer> xrep_metadata_inode_forks(sc); 
<token> (error) <answer> if 
goto <token> <answer> out; 
xfs_trans_log_inode(sc->tp, <token> XFS_ILOG_CORE); <answer> sc->ip, 
STATIC <token> <answer> int 
struct xfs_scrub <token> <answer> *sc, 
xfs_dqtype_t <token> <answer> dqtype) 
struct xchk_dqiter <token> = { }; <answer> cursor 
struct xrep_quota_info rqi = { .sc = <token> }; <answer> sc 
struct <token> *dq; <answer> xfs_dquot 
<token> error; <answer> int 
<token> sc, dqtype); <answer> xchk_dqiter_init(&cursor, 
while ((error <token> xchk_dquot_iter(&cursor, &dq)) == 1) { <answer> = 
error = <token> dq); <answer> xrep_quota_item(&rqi, 
if <token> <answer> (error) 
if <token> <answer> (error) 
return <token> <answer> error; 
if <token> & XFS_ILOCK_EXCL)) <answer> (!(sc->ilock_flags 
xchk_ilock(sc, <token> <answer> XFS_ILOCK_EXCL); 
error = <token> dqtype); <answer> xrep_quota_data_fork(sc, 
if <token> <answer> (error) 
return <token> <answer> error; 
error <token> xrep_defer_finish(sc); <answer> = 
if <token> <answer> (error) 
return <token> <answer> error; 
error = <token> <answer> xfs_trans_roll(&sc->tp); 
<token> (error) <answer> if 
<token> error; <answer> return 
xchk_iunlock(sc, <token> <answer> sc->ilock_flags); 
<token> <linux/netdevice.h> <answer> #include 
#include <token> <answer> <net/dcbnl.h> 
<token> "xgbe.h" <answer> #include 
#include <token> <answer> "xgbe-common.h" 
static <token> xgbe_dcb_ieee_getets(struct net_device *netdev, <answer> int 
struct ieee_ets <token> <answer> *ets) 
struct xgbe_prv_data *pdata = <token> <answer> netdev_priv(netdev); 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> <linux/i3c/device.h> 
<token> <linux/i3c/master.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
static <token> regmap_i3c_write(void *context, const void *data, size_t count) <answer> int 
struct device <token> = context; <answer> *dev 
struct <token> *i3c = dev_to_i3cdev(dev); <answer> i3c_device 
struct <token> xfers[] = { <answer> i3c_priv_xfer 
.rnw = <token> <answer> false, 
<token> = count, <answer> .len 
.data.out = <token> <answer> data, 
return <token> xfers, 1); <answer> i3c_device_do_priv_xfers(i3c, 
static <token> regmap_i3c_read(void *context, <answer> int 
const void *reg, <token> reg_size, <answer> size_t 
<token> *val, size_t val_size) <answer> void 
struct <token> *dev = context; <answer> device 
<token> i3c_device *i3c = dev_to_i3cdev(dev); <answer> struct 
<token> i3c_priv_xfer xfers[2]; <answer> struct 
<token> = false; <answer> xfers[0].rnw 
xfers[0].len <token> reg_size; <answer> = 
xfers[0].data.out <token> reg; <answer> = 
xfers[1].rnw = <token> <answer> true; 
xfers[1].len = <token> <answer> val_size; 
xfers[1].data.in = <token> <answer> val; 
return <token> xfers, 2); <answer> i3c_device_do_priv_xfers(i3c, 
static const struct <token> regmap_i3c = { <answer> regmap_bus 
.write = <token> <answer> regmap_i3c_write, 
.read <token> regmap_i3c_read, <answer> = 
struct regmap <token> i3c_device *i3c, <answer> *__devm_regmap_init_i3c(struct 
const struct <token> *config, <answer> regmap_config 
struct lock_class_key <token> <answer> *lock_key, 
const char <token> <answer> *lock_name) 
return __devm_regmap_init(&i3c->dev, &regmap_i3c, &i3c->dev, <token> <answer> config, 
<token> lock_name); <answer> lock_key, 
MODULE_AUTHOR("Vitor Soares <token> <answer> <vitor.soares@synopsys.com>"); 
MODULE_DESCRIPTION("Regmap <token> Module"); <answer> I3C 
<token> v2"); <answer> MODULE_LICENSE("GPL 
#include <token> <answer> <linux/cpu.h> 
<token> <linux/irqflags.h> <answer> #include 
<token> <asm/barrier.h> <answer> #include 
#include <token> <answer> <asm/cpuidle.h> 
<token> <asm/cpufeature.h> <answer> #include 
<token> <asm/sysreg.h> <answer> #include 
void __cpuidle <token> <answer> cpu_do_idle(void) 
struct arm_cpuidle_irq_context <token> <answer> context; 
<token> __cpuidle arch_cpu_idle(void) <answer> void 
<token> <linux/module.h> <answer> #include 
<token> <linux/moduleparam.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
<token> <linux/bitops.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
<token> <linux/gpio/consumer.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/regulator/driver.h> 
#include <token> <answer> <linux/regulator/machine.h> 
<token> <linux/regulator/of_regulator.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/regulator/arizona-ldo1.h> 
<token> <linux/mfd/arizona/core.h> <answer> #include 
<token> <linux/mfd/arizona/pdata.h> <answer> #include 
<token> <linux/mfd/arizona/registers.h> <answer> #include 
<token> <linux/mfd/madera/core.h> <answer> #include 
#include <token> <answer> <linux/mfd/madera/pdata.h> 
#include <token> <answer> <linux/mfd/madera/registers.h> 
struct arizona_ldo1 <token> <answer> { 
<token> regulator_dev *regulator; <answer> struct 
struct regmap <token> <answer> *regmap; 
<token> regulator_consumer_supply supply; <answer> struct 
struct <token> init_data; <answer> regulator_init_data 
struct gpio_desc <token> <answer> *ena_gpiod; 
<token> int arizona_ldo1_hc_set_voltage_sel(struct regulator_dev *rdev, <answer> static 
<token> sel) <answer> unsigned 
struct regmap *regmap <token> rdev_get_regmap(rdev); <answer> = 
unsigned <token> val; <answer> int 
<token> ret; <answer> int 
if (sel <token> rdev->desc->n_voltages - 1) <answer> == 
<token> = ARIZONA_LDO1_HI_PWR; <answer> val 
val <token> 0; <answer> = 
ret = regmap_update_bits(regmap, <token> <answer> ARIZONA_LDO1_CONTROL_2, 
ARIZONA_LDO1_HI_PWR, <token> <answer> val); 
<token> (ret != 0) <answer> if 
return <token> <answer> ret; 
if <token> <answer> (val) 
return <token> <answer> 0; 
<token> regulator_set_voltage_sel_regmap(rdev, sel); <answer> return 
<token> int arizona_ldo1_hc_get_voltage_sel(struct regulator_dev *rdev) <answer> static 
struct regmap *regmap <token> rdev_get_regmap(rdev); <answer> = 
unsigned <token> val; <answer> int 
int <token> <answer> ret; 
ret = <token> ARIZONA_LDO1_CONTROL_2, &val); <answer> regmap_read(regmap, 
if (ret <token> 0) <answer> != 
return <token> <answer> ret; 
if (val <token> ARIZONA_LDO1_HI_PWR) <answer> & 
<token> rdev->desc->n_voltages - 1; <answer> return 
<token> regulator_get_voltage_sel_regmap(rdev); <answer> return 
static const struct regulator_ops arizona_ldo1_hc_ops = <token> <answer> { 
<token> = regulator_list_voltage_linear_range, <answer> .list_voltage 
.map_voltage = <token> <answer> regulator_map_voltage_linear_range, 
<token> = arizona_ldo1_hc_get_voltage_sel, <answer> .get_voltage_sel 
.set_voltage_sel <token> arizona_ldo1_hc_set_voltage_sel, <answer> = 
.get_bypass <token> regulator_get_bypass_regmap, <answer> = 
.set_bypass <token> regulator_set_bypass_regmap, <answer> = 
static const struct linear_range arizona_ldo1_hc_ranges[] = <token> <answer> { 
REGULATOR_LINEAR_RANGE(900000, <token> 0x6, 50000), <answer> 0, 
<token> 0x7, 0x7, 0), <answer> REGULATOR_LINEAR_RANGE(1800000, 
static const struct <token> arizona_ldo1_hc = { <answer> regulator_desc 
<token> = "LDO1", <answer> .name 
.supply_name <token> "LDOVDD", <answer> = 
.type <token> REGULATOR_VOLTAGE, <answer> = 
<token> = &arizona_ldo1_hc_ops, <answer> .ops 
.vsel_reg = <token> <answer> ARIZONA_LDO1_CONTROL_1, 
.vsel_mask = <token> <answer> ARIZONA_LDO1_VSEL_MASK, 
<token> = ARIZONA_LDO1_CONTROL_1, <answer> .bypass_reg 
.bypass_mask <token> ARIZONA_LDO1_BYPASS, <answer> = 
<token> = arizona_ldo1_hc_ranges, <answer> .linear_ranges 
.n_linear_ranges <token> ARRAY_SIZE(arizona_ldo1_hc_ranges), <answer> = 
<token> = 8, <answer> .n_voltages 
.enable_time <token> 1500, <answer> = 
.ramp_delay <token> 24000, <answer> = 
.owner = <token> <answer> THIS_MODULE, 
static const struct regulator_ops <token> = { <answer> arizona_ldo1_ops 
.list_voltage <token> regulator_list_voltage_linear, <answer> = 
.map_voltage = <token> <answer> regulator_map_voltage_linear, 
.get_voltage_sel <token> regulator_get_voltage_sel_regmap, <answer> = 
.set_voltage_sel <token> regulator_set_voltage_sel_regmap, <answer> = 
static const struct <token> arizona_ldo1 = { <answer> regulator_desc 
.name <token> "LDO1", <answer> = 
.supply_name = <token> <answer> "LDOVDD", 
<token> = REGULATOR_VOLTAGE, <answer> .type 
.ops = <token> <answer> &arizona_ldo1_ops, 
.vsel_reg = <token> <answer> ARIZONA_LDO1_CONTROL_1, 
<token> = ARIZONA_LDO1_VSEL_MASK, <answer> .vsel_mask 
.min_uV = <token> <answer> 900000, 
.uV_step = <token> <answer> 25000, 
.n_voltages = <token> <answer> 13, 
.enable_time = <token> <answer> 500, 
.ramp_delay = <token> <answer> 24000, 
.owner = <token> <answer> THIS_MODULE, 
static const <token> regulator_init_data arizona_ldo1_dvfs = { <answer> struct 
<token> = { <answer> .constraints 
.min_uV = <token> <answer> 1200000, 
.max_uV <token> 1800000, <answer> = 
.valid_ops_mask <token> REGULATOR_CHANGE_STATUS | <answer> = 
.num_consumer_supplies = <token> <answer> 1, 
static const <token> regulator_init_data arizona_ldo1_default = { <answer> struct 
.constraints = <token> <answer> { 
<token> = REGULATOR_CHANGE_STATUS, <answer> .valid_ops_mask 
.num_consumer_supplies = <token> <answer> 1, 
<token> const struct regulator_init_data arizona_ldo1_wm5110 = { <answer> static 
.constraints = <token> <answer> { 
.min_uV <token> 1175000, <answer> = 
.max_uV <token> 1200000, <answer> = 
<token> = REGULATOR_CHANGE_STATUS | <answer> .valid_ops_mask 
.num_consumer_supplies = <token> <answer> 1, 
static const struct regulator_desc <token> = { <answer> madera_ldo1 
.name <token> "LDO1", <answer> = 
.supply_name <token> "LDOVDD", <answer> = 
<token> = REGULATOR_VOLTAGE, <answer> .type 
.ops <token> &arizona_ldo1_ops, <answer> = 
<token> = MADERA_LDO1_CONTROL_1, <answer> .vsel_reg 
.vsel_mask <token> MADERA_LDO1_VSEL_MASK, <answer> = 
.min_uV = <token> <answer> 900000, 
<token> = 25000, <answer> .uV_step 
<token> = 13, <answer> .n_voltages 
<token> = 3000, <answer> .enable_time 
<token> = THIS_MODULE, <answer> .owner 
static <token> struct regulator_init_data madera_ldo1_default = { <answer> const 
.constraints <token> { <answer> = 
.min_uV = <token> <answer> 1200000, 
.max_uV <token> 1200000, <answer> = 
<token> = REGULATOR_CHANGE_STATUS, <answer> .valid_ops_mask 
<token> = 1, <answer> .num_consumer_supplies 
static <token> arizona_ldo1_of_get_pdata(struct arizona_ldo1_pdata *pdata, <answer> int 
struct regulator_config <token> <answer> *config, 
<token> struct regulator_desc *desc, <answer> const 
<token> *external_dcvdd) <answer> bool 
struct arizona_ldo1 *ldo1 = <token> <answer> config->driver_data; 
struct device_node *np <token> config->dev->of_node; <answer> = 
struct device_node <token> *dcvdd_node; <answer> *init_node, 
struct regulator_init_data <token> <answer> *init_data; 
init_node <token> of_get_child_by_name(np, "ldo1"); <answer> = 
dcvdd_node <token> of_parse_phandle(np, "DCVDD-supply", 0); <answer> = 
if <token> { <answer> (init_node) 
config->of_node = <token> <answer> init_node; 
init_data = <token> init_node, <answer> of_get_regulator_init_data(config->dev, 
if <token> { <answer> (init_data) 
init_data->consumer_supplies = <token> <answer> &ldo1->supply; 
<token> = 1; <answer> init_data->num_consumer_supplies 
if (dcvdd_node <token> dcvdd_node != init_node) <answer> && 
<token> = true; <answer> *external_dcvdd 
pdata->init_data = <token> <answer> init_data; 
} else <token> (dcvdd_node) { <answer> if 
*external_dcvdd = <token> <answer> true; 
<token> 0; <answer> return 
static <token> arizona_ldo1_common_init(struct platform_device *pdev, <answer> int 
struct arizona_ldo1 <token> <answer> *ldo1, 
<token> struct regulator_desc *desc, <answer> const 
<token> arizona_ldo1_pdata *pdata, <answer> struct 
<token> *external_dcvdd) <answer> bool 
struct <token> *parent_dev = pdev->dev.parent; <answer> device 
struct <token> config = { }; <answer> regulator_config 
int <token> <answer> ret; 
*external_dcvdd <token> false; <answer> = 
<token> = "DCVDD"; <answer> ldo1->supply.supply 
ldo1->init_data.consumer_supplies = <token> <answer> &ldo1->supply; 
<token> = dev_name(parent_dev); <answer> ldo1->supply.dev_name 
config.dev = <token> <answer> parent_dev; 
config.driver_data <token> ldo1; <answer> = 
<token> = ldo1->regmap; <answer> config.regmap 
if <token> { <answer> (IS_ENABLED(CONFIG_OF)) 
if (!dev_get_platdata(parent_dev)) <token> <answer> { 
ret <token> arizona_ldo1_of_get_pdata(pdata, <answer> = 
<token> desc, <answer> &config, 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
config.ena_gpiod <token> gpiod_get_optional(parent_dev, "wlf,ldoena", <answer> = 
GPIOD_OUT_LOW | <token> <answer> GPIOD_FLAGS_BIT_NONEXCLUSIVE); 
if <token> <answer> (IS_ERR(config.ena_gpiod)) 
<token> PTR_ERR(config.ena_gpiod); <answer> return 
ldo1->ena_gpiod = <token> <answer> config.ena_gpiod; 
<token> (pdata->init_data) <answer> if 
<token> = pdata->init_data; <answer> config.init_data 
config.init_data <token> &ldo1->init_data; <answer> = 
if (config.init_data->num_consumer_supplies <token> 0) <answer> == 
<token> = true; <answer> *external_dcvdd 
ldo1->regulator = <token> desc, &config); <answer> devm_regulator_register(&pdev->dev, 
if <token> { <answer> (IS_ERR(ldo1->regulator)) 
ret <token> PTR_ERR(ldo1->regulator); <answer> = 
dev_err(&pdev->dev, <token> to register LDO1 supply: %d\n", <answer> "Failed 
return <token> <answer> ret; 
<token> ldo1); <answer> platform_set_drvdata(pdev, 
return <token> <answer> 0; 
<token> int arizona_ldo1_probe(struct platform_device *pdev) <answer> static 
<token> arizona *arizona = dev_get_drvdata(pdev->dev.parent); <answer> struct 
struct <token> *ldo1; <answer> arizona_ldo1 
const struct <token> *desc; <answer> regulator_desc 
<token> external_dcvdd; <answer> bool 
<token> ret; <answer> int 
<token> = devm_kzalloc(&pdev->dev, sizeof(*ldo1), GFP_KERNEL); <answer> ldo1 
if <token> <answer> (!ldo1) 
return <token> <answer> -ENOMEM; 
<token> = arizona->regmap; <answer> ldo1->regmap 
switch <token> { <answer> (arizona->type) 
case <token> <answer> WM5102: 
case <token> <answer> WM8997: 
case <token> <answer> WM8998: 
<token> WM1814: <answer> case 
desc <token> &arizona_ldo1_hc; <answer> = 
ldo1->init_data <token> arizona_ldo1_dvfs; <answer> = 
case <token> <answer> WM5110: 
case <token> <answer> WM8280: 
<token> = &arizona_ldo1; <answer> desc 
ldo1->init_data <token> arizona_ldo1_wm5110; <answer> = 
<token> = &arizona_ldo1; <answer> desc 
ldo1->init_data <token> arizona_ldo1_default; <answer> = 
<token> = arizona_ldo1_common_init(pdev, ldo1, desc, <answer> ret 
<token> (ret == 0) <answer> if 
<token> = external_dcvdd; <answer> arizona->external_dcvdd 
return <token> <answer> ret; 
static void arizona_ldo1_remove(struct <token> *pdev) <answer> platform_device 
struct arizona_ldo1 *ldo1 = <token> <answer> platform_get_drvdata(pdev); 
if <token> <answer> (ldo1->ena_gpiod) 
static int madera_ldo1_probe(struct platform_device <token> <answer> *pdev) 
struct madera *madera <token> dev_get_drvdata(pdev->dev.parent); <answer> = 
struct arizona_ldo1 <token> <answer> *ldo1; 
<token> external_dcvdd; <answer> bool 
int <token> <answer> ret; 
<token> = devm_kzalloc(&pdev->dev, sizeof(*ldo1), GFP_KERNEL); <answer> ldo1 
if <token> <answer> (!ldo1) 
<token> -ENOMEM; <answer> return 
ldo1->regmap <token> madera->regmap; <answer> = 
<token> = madera_ldo1_default; <answer> ldo1->init_data 
ret = arizona_ldo1_common_init(pdev, ldo1, <token> <answer> &madera_ldo1, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> = !external_dcvdd; <answer> madera->internal_dcvdd 
<token> 0; <answer> return 
static <token> platform_driver arizona_ldo1_driver = { <answer> struct 
.probe = <token> <answer> arizona_ldo1_probe, 
.remove_new = <token> <answer> arizona_ldo1_remove, 
.driver <token> { <answer> = 
<token> = "arizona-ldo1", <answer> .name 
.probe_type <token> PROBE_FORCE_SYNCHRONOUS, <answer> = 
static struct platform_driver madera_ldo1_driver <token> { <answer> = 
.probe = <token> <answer> madera_ldo1_probe, 
.remove_new = <token> <answer> arizona_ldo1_remove, 
<token> = { <answer> .driver 
.name <token> "madera-ldo1", <answer> = 
.probe_type = <token> <answer> PROBE_FORCE_SYNCHRONOUS, 
static struct platform_driver * const madera_ldo1_drivers[] = <token> <answer> { 
<token> int __init arizona_ldo1_init(void) <answer> static 
return <token> <answer> platform_register_drivers(madera_ldo1_drivers, 
static void __exit <token> <answer> madera_ldo1_exit(void) 
<token> "mvm.h" <answer> #include 
#include <token> <answer> "debugfs.h" 
static void <token> iwl_mvm *mvm, <answer> iwl_dbgfs_update_pm(struct 
struct <token> *vif, <answer> ieee80211_vif 
enum <token> param, int val) <answer> iwl_dbgfs_pm_mask 
struct iwl_mvm_vif *mvmvif <token> iwl_mvm_vif_from_mac80211(vif); <answer> = 
<token> iwl_dbgfs_pm *dbgfs_pm = &mvmvif->dbgfs_pm; <answer> struct 
dbgfs_pm->mask <token> param; <answer> |= 
switch (param) <token> <answer> { 
case MVM_DEBUGFS_PM_KEEP_ALIVE: <token> <answer> { 
int <token> = vif->bss_conf.dtim_period ?: 1; <answer> dtimper 
int dtimper_msec = dtimper <token> vif->bss_conf.beacon_int; <answer> * 
<token> "debugfs: set keep_alive= %d sec\n", val); <answer> IWL_DEBUG_POWER(mvm, 
if (val * MSEC_PER_SEC < 3 * <token> <answer> dtimper_msec) 
<token> keep alive period (%ld msec) is less than minimum required (%d msec)\n", <answer> "debugfs: 
val <token> MSEC_PER_SEC, 3 * dtimper_msec); <answer> * 
dbgfs_pm->keep_alive_seconds = <token> <answer> val; 
<token> MVM_DEBUGFS_PM_SKIP_OVER_DTIM: <answer> case 
IWL_DEBUG_POWER(mvm, <token> %s\n", <answer> "skip_over_dtim 
val ? "enabled" <token> "disabled"); <answer> : 
dbgfs_pm->skip_over_dtim = <token> <answer> val; 
<token> MVM_DEBUGFS_PM_SKIP_DTIM_PERIODS: <answer> case 
IWL_DEBUG_POWER(mvm, "skip_dtim_periods=%d\n", <token> <answer> val); 
<token> = val; <answer> dbgfs_pm->skip_dtim_periods 
<token> MVM_DEBUGFS_PM_RX_DATA_TIMEOUT: <answer> case 
<token> "rx_data_timeout=%d\n", val); <answer> IWL_DEBUG_POWER(mvm, 
<token> = val; <answer> dbgfs_pm->rx_data_timeout 
case <token> <answer> MVM_DEBUGFS_PM_TX_DATA_TIMEOUT: 
IWL_DEBUG_POWER(mvm, "tx_data_timeout=%d\n", <token> <answer> val); 
<token> = val; <answer> dbgfs_pm->tx_data_timeout 
case <token> <answer> MVM_DEBUGFS_PM_LPRX_ENA: 
IWL_DEBUG_POWER(mvm, "lprx %s\n", val <token> "enabled" : "disabled"); <answer> ? 
<token> = val; <answer> dbgfs_pm->lprx_ena 
<token> MVM_DEBUGFS_PM_LPRX_RSSI_THRESHOLD: <answer> case 
IWL_DEBUG_POWER(mvm, "lprx_rssi_threshold=%d\n", <token> <answer> val); 
<token> = val; <answer> dbgfs_pm->lprx_rssi_threshold 
case <token> <answer> MVM_DEBUGFS_PM_SNOOZE_ENABLE: 
<token> "snooze_enable=%d\n", val); <answer> IWL_DEBUG_POWER(mvm, 
dbgfs_pm->snooze_ena = <token> <answer> val; 
case <token> <answer> MVM_DEBUGFS_PM_UAPSD_MISBEHAVING: 
<token> "uapsd_misbehaving_enable=%d\n", val); <answer> IWL_DEBUG_POWER(mvm, 
dbgfs_pm->uapsd_misbehaving = <token> <answer> val; 
case <token> <answer> MVM_DEBUGFS_PM_USE_PS_POLL: 
<token> "use_ps_poll=%d\n", val); <answer> IWL_DEBUG_POWER(mvm, 
dbgfs_pm->use_ps_poll = <token> <answer> val; 
static ssize_t iwl_dbgfs_pm_params_write(struct <token> *vif, char *buf, <answer> ieee80211_vif 
size_t count, <token> *ppos) <answer> loff_t 
struct iwl_mvm_vif <token> = iwl_mvm_vif_from_mac80211(vif); <answer> *mvmvif 
struct iwl_mvm *mvm = <token> <answer> mvmvif->mvm; 
enum <token> param; <answer> iwl_dbgfs_pm_mask 
int <token> ret; <answer> val, 
if <token> buf, 11)) { <answer> (!strncmp("keep_alive=", 
if (sscanf(buf + 11, "%d", &val) != <token> <answer> 1) 
return <token> <answer> -EINVAL; 
param <token> MVM_DEBUGFS_PM_KEEP_ALIVE; <answer> = 
} else if (!strncmp("skip_over_dtim=", buf, <token> { <answer> 15)) 
if (sscanf(buf + 15, "%d", &val) <token> 1) <answer> != 
<token> -EINVAL; <answer> return 
<token> = MVM_DEBUGFS_PM_SKIP_OVER_DTIM; <answer> param 
} else if (!strncmp("skip_dtim_periods=", <token> 18)) { <answer> buf, 
if <token> + 18, "%d", &val) != 1) <answer> (sscanf(buf 
<token> -EINVAL; <answer> return 
<token> = MVM_DEBUGFS_PM_SKIP_DTIM_PERIODS; <answer> param 
} <token> if (!strncmp("rx_data_timeout=", buf, 16)) { <answer> else 
if (sscanf(buf + 16, "%d", &val) <token> 1) <answer> != 
<token> -EINVAL; <answer> return 
<token> = MVM_DEBUGFS_PM_RX_DATA_TIMEOUT; <answer> param 
} else if <token> buf, 16)) { <answer> (!strncmp("tx_data_timeout=", 
if (sscanf(buf + <token> "%d", &val) != 1) <answer> 16, 
return <token> <answer> -EINVAL; 
<token> = MVM_DEBUGFS_PM_TX_DATA_TIMEOUT; <answer> param 
} else if (!strncmp("lprx=", buf, <token> { <answer> 5)) 
if (sscanf(buf <token> 5, "%d", &val) != 1) <answer> + 
return <token> <answer> -EINVAL; 
param = <token> <answer> MVM_DEBUGFS_PM_LPRX_ENA; 
} else if (!strncmp("lprx_rssi_threshold=", buf, <token> { <answer> 20)) 
if (sscanf(buf + 20, "%d", &val) <token> 1) <answer> != 
<token> -EINVAL; <answer> return 
if (val <token> POWER_LPRX_RSSI_THRESHOLD_MAX || val < <answer> > 
<token> -EINVAL; <answer> return 
param = <token> <answer> MVM_DEBUGFS_PM_LPRX_RSSI_THRESHOLD; 
} <token> if (!strncmp("snooze_enable=", buf, 14)) { <answer> else 
if (sscanf(buf + 14, "%d", &val) <token> 1) <answer> != 
<token> -EINVAL; <answer> return 
<token> = MVM_DEBUGFS_PM_SNOOZE_ENABLE; <answer> param 
} <token> if (!strncmp("uapsd_misbehaving=", buf, 18)) { <answer> else 
if (sscanf(buf <token> 18, "%d", &val) != 1) <answer> + 
return <token> <answer> -EINVAL; 
<token> = MVM_DEBUGFS_PM_UAPSD_MISBEHAVING; <answer> param 
} else if (!strncmp("use_ps_poll=", <token> 12)) { <answer> buf, 
if (sscanf(buf + 12, "%d", <token> != 1) <answer> &val) 
<token> -EINVAL; <answer> return 
param = <token> <answer> MVM_DEBUGFS_PM_USE_PS_POLL; 
} else <token> <answer> { 
return <token> <answer> -EINVAL; 
iwl_dbgfs_update_pm(mvm, vif, param, <token> <answer> val); 
ret <token> iwl_mvm_power_update_mac(mvm); <answer> = 
return <token> ?: count; <answer> ret 
<token> ssize_t iwl_dbgfs_tx_pwr_lmt_read(struct file *file, <answer> static 
char <token> *user_buf, <answer> __user 
<token> count, loff_t *ppos) <answer> size_t 
struct ieee80211_vif *vif <token> file->private_data; <answer> = 
char <token> <answer> buf[64]; 
int <token> = sizeof(buf); <answer> bufsz 
int <token> <answer> pos; 
pos = scnprintf(buf, bufsz, "bss <token> = %d\n", <answer> limit 
return simple_read_from_buffer(user_buf, count, ppos, <token> pos); <answer> buf, 
static ssize_t <token> file *file, <answer> iwl_dbgfs_pm_params_read(struct 
<token> __user *user_buf, <answer> char 
<token> count, loff_t *ppos) <answer> size_t 
struct <token> *vif = file->private_data; <answer> ieee80211_vif 
struct iwl_mvm_vif <token> = iwl_mvm_vif_from_mac80211(vif); <answer> *mvmvif 
struct iwl_mvm <token> = mvmvif->mvm; <answer> *mvm 
char <token> <answer> buf[512]; 
<token> bufsz = sizeof(buf); <answer> int 
int <token> <answer> pos; 
pos = iwl_mvm_power_mac_dbgfs_read(mvm, <token> buf, bufsz); <answer> vif, 
<token> simple_read_from_buffer(user_buf, count, ppos, buf, pos); <answer> return 
static <token> iwl_dbgfs_mac_params_read(struct file *file, <answer> ssize_t 
char __user <token> <answer> *user_buf, 
size_t count, <token> *ppos) <answer> loff_t 
struct ieee80211_vif *vif = <token> <answer> file->private_data; 
<token> iwl_mvm_vif *mvmvif = iwl_mvm_vif_from_mac80211(vif); <answer> struct 
struct <token> *mvm = mvmvif->mvm; <answer> iwl_mvm 
u8 <token> <answer> ap_sta_id; 
struct ieee80211_chanctx_conf <token> <answer> *chanctx_conf; 
char <token> <answer> buf[512]; 
int bufsz = <token> <answer> sizeof(buf); 
int pos <token> 0; <answer> = 
int <token> <answer> i; 
ap_sta_id = <token> <answer> mvmvif->deflink.ap_sta_id; 
switch (ieee80211_vif_type_p2p(vif)) <token> <answer> { 
<token> NL80211_IFTYPE_ADHOC: <answer> case 
pos += scnprintf(buf+pos, bufsz-pos, "type: <token> <answer> ibss\n"); 
<token> NL80211_IFTYPE_STATION: <answer> case 
pos <token> scnprintf(buf+pos, bufsz-pos, "type: bss\n"); <answer> += 
case <token> <answer> NL80211_IFTYPE_AP: 
pos += <token> bufsz-pos, "type: ap\n"); <answer> scnprintf(buf+pos, 
<token> NL80211_IFTYPE_P2P_CLIENT: <answer> case 
pos += scnprintf(buf+pos, bufsz-pos, "type: p2p <token> <answer> client\n"); 
<token> NL80211_IFTYPE_P2P_GO: <answer> case 
pos += <token> bufsz-pos, "type: p2p go\n"); <answer> scnprintf(buf+pos, 
<token> NL80211_IFTYPE_P2P_DEVICE: <answer> case 
<token> += scnprintf(buf+pos, bufsz-pos, "type: p2p dev\n"); <answer> pos 
<token> += scnprintf(buf+pos, bufsz-pos, "mac id/color: %d / %d\n", <answer> pos 
mvmvif->id, <token> <answer> mvmvif->color); 
pos += scnprintf(buf+pos, bufsz-pos, <token> %pM\n", <answer> "bssid: 
<token> += scnprintf(buf+pos, bufsz-pos, "Load: %d\n", <answer> pos 
pos += scnprintf(buf+pos, bufsz-pos, <token> <answer> "QoS:\n"); 
for (i = 0; i <token> ARRAY_SIZE(mvmvif->deflink.queue_params); i++) <answer> < 
<token> += scnprintf(buf+pos, bufsz-pos, <answer> pos 
"\t%d: txop:%d - cw_min:%d - cw_max = %d - aifs = %d upasd = <token> <answer> %d\n", 
i, <token> <answer> mvmvif->deflink.queue_params[i].txop, 
if (vif->type == NL80211_IFTYPE_STATION <token> <answer> && 
<token> != IWL_MVM_INVALID_STA) { <answer> ap_sta_id 
struct iwl_mvm_sta <token> <answer> *mvm_sta; 
mvm_sta <token> iwl_mvm_sta_from_staid_protected(mvm, ap_sta_id); <answer> = 
if <token> { <answer> (mvm_sta) 
<token> += scnprintf(buf+pos, bufsz-pos, <answer> pos 
<token> %d - reduced Tx power %d\n", <answer> "ap_sta_id 
<token> = rcu_dereference(vif->bss_conf.chanctx_conf); <answer> chanctx_conf 
if <token> <answer> (chanctx_conf) 
pos <token> scnprintf(buf+pos, bufsz-pos, <answer> += 
"idle rx chains <token> active rx chains: %d\n", <answer> %d, 
return simple_read_from_buffer(user_buf, count, <token> buf, pos); <answer> ppos, 
static <token> iwl_dbgfs_update_bf(struct ieee80211_vif *vif, <answer> void 
enum iwl_dbgfs_bf_mask param, <token> value) <answer> int 
struct iwl_mvm_vif *mvmvif = <token> <answer> iwl_mvm_vif_from_mac80211(vif); 
struct iwl_dbgfs_bf *dbgfs_bf <token> &mvmvif->dbgfs_bf; <answer> = 
dbgfs_bf->mask <token> param; <answer> |= 
switch (param) <token> <answer> { 
<token> MVM_DEBUGFS_BF_ENERGY_DELTA: <answer> case 
dbgfs_bf->bf_energy_delta = <token> <answer> value; 
<token> MVM_DEBUGFS_BF_ROAMING_ENERGY_DELTA: <answer> case 
<token> = value; <answer> dbgfs_bf->bf_roaming_energy_delta 
<token> MVM_DEBUGFS_BF_ROAMING_STATE: <answer> case 
dbgfs_bf->bf_roaming_state <token> value; <answer> = 
<token> MVM_DEBUGFS_BF_TEMP_THRESHOLD: <answer> case 
<token> = value; <answer> dbgfs_bf->bf_temp_threshold 
<token> MVM_DEBUGFS_BF_TEMP_FAST_FILTER: <answer> case 
<token> = value; <answer> dbgfs_bf->bf_temp_fast_filter 
<token> MVM_DEBUGFS_BF_TEMP_SLOW_FILTER: <answer> case 
dbgfs_bf->bf_temp_slow_filter = <token> <answer> value; 
<token> MVM_DEBUGFS_BF_ENABLE_BEACON_FILTER: <answer> case 
dbgfs_bf->bf_enable_beacon_filter <token> value; <answer> = 
case <token> <answer> MVM_DEBUGFS_BF_DEBUG_FLAG: 
dbgfs_bf->bf_debug_flag <token> value; <answer> = 
<token> MVM_DEBUGFS_BF_ESCAPE_TIMER: <answer> case 
<token> = value; <answer> dbgfs_bf->bf_escape_timer 
case <token> <answer> MVM_DEBUGFS_BA_ENABLE_BEACON_ABORT: 
<token> = value; <answer> dbgfs_bf->ba_enable_beacon_abort 
case <token> <answer> MVM_DEBUGFS_BA_ESCAPE_TIMER: 
dbgfs_bf->ba_escape_timer = <token> <answer> value; 
static ssize_t iwl_dbgfs_bf_params_write(struct ieee80211_vif *vif, <token> *buf, <answer> char 
size_t <token> loff_t *ppos) <answer> count, 
struct iwl_mvm_vif <token> = iwl_mvm_vif_from_mac80211(vif); <answer> *mvmvif 
struct iwl_mvm *mvm <token> mvmvif->mvm; <answer> = 
enum iwl_dbgfs_bf_mask <token> <answer> param; 
int value, <token> = 0; <answer> ret 
<token> (!strncmp("bf_energy_delta=", buf, 16)) { <answer> if 
if (sscanf(buf+16, "%d", &value) != <token> <answer> 1) 
return <token> <answer> -EINVAL; 
if (value <token> IWL_BF_ENERGY_DELTA_MIN || <answer> < 
value <token> IWL_BF_ENERGY_DELTA_MAX) <answer> > 
<token> -EINVAL; <answer> return 
param <token> MVM_DEBUGFS_BF_ENERGY_DELTA; <answer> = 
} else if <token> buf, 24)) { <answer> (!strncmp("bf_roaming_energy_delta=", 
if (sscanf(buf+24, "%d", &value) != <token> <answer> 1) 
return <token> <answer> -EINVAL; 
if (value < <token> || <answer> IWL_BF_ROAMING_ENERGY_DELTA_MIN 
value > <token> <answer> IWL_BF_ROAMING_ENERGY_DELTA_MAX) 
<token> -EINVAL; <answer> return 
param <token> MVM_DEBUGFS_BF_ROAMING_ENERGY_DELTA; <answer> = 
} <token> if (!strncmp("bf_roaming_state=", buf, 17)) { <answer> else 
if (sscanf(buf+17, "%d", &value) != <token> <answer> 1) 
return <token> <answer> -EINVAL; 
if <token> < IWL_BF_ROAMING_STATE_MIN || <answer> (value 
value > <token> <answer> IWL_BF_ROAMING_STATE_MAX) 
<token> -EINVAL; <answer> return 
<token> = MVM_DEBUGFS_BF_ROAMING_STATE; <answer> param 
} else if (!strncmp("bf_temp_threshold=", <token> 18)) { <answer> buf, 
if (sscanf(buf+18, "%d", &value) != <token> <answer> 1) 
return <token> <answer> -EINVAL; 
<token> (value < IWL_BF_TEMP_THRESHOLD_MIN || <answer> if 
<token> > IWL_BF_TEMP_THRESHOLD_MAX) <answer> value 
return <token> <answer> -EINVAL; 
<token> = MVM_DEBUGFS_BF_TEMP_THRESHOLD; <answer> param 
} else if (!strncmp("bf_temp_fast_filter=", buf, <token> { <answer> 20)) 
if <token> "%d", &value) != 1) <answer> (sscanf(buf+20, 
return <token> <answer> -EINVAL; 
if (value < <token> || <answer> IWL_BF_TEMP_FAST_FILTER_MIN 
<token> > IWL_BF_TEMP_FAST_FILTER_MAX) <answer> value 
<token> -EINVAL; <answer> return 
param = <token> <answer> MVM_DEBUGFS_BF_TEMP_FAST_FILTER; 
} else if (!strncmp("bf_temp_slow_filter=", buf, <token> { <answer> 20)) 
<token> (sscanf(buf+20, "%d", &value) != 1) <answer> if 
<token> -EINVAL; <answer> return 
if (value <token> IWL_BF_TEMP_SLOW_FILTER_MIN || <answer> < 
<token> > IWL_BF_TEMP_SLOW_FILTER_MAX) <answer> value 
return <token> <answer> -EINVAL; 
<token> = MVM_DEBUGFS_BF_TEMP_SLOW_FILTER; <answer> param 
} else if (!strncmp("bf_enable_beacon_filter=", buf, 24)) <token> <answer> { 
<token> (sscanf(buf+24, "%d", &value) != 1) <answer> if 
return <token> <answer> -EINVAL; 
if (value < 0 || value <token> 1) <answer> > 
return <token> <answer> -EINVAL; 
param <token> MVM_DEBUGFS_BF_ENABLE_BEACON_FILTER; <answer> = 
} else if <token> buf, 14)) { <answer> (!strncmp("bf_debug_flag=", 
if (sscanf(buf+14, "%d", &value) != <token> <answer> 1) 
<token> -EINVAL; <answer> return 
if (value < 0 || <token> > 1) <answer> value 
return <token> <answer> -EINVAL; 
<token> = MVM_DEBUGFS_BF_DEBUG_FLAG; <answer> param 
} else if (!strncmp("bf_escape_timer=", <token> 16)) { <answer> buf, 
if (sscanf(buf+16, "%d", <token> != 1) <answer> &value) 
<token> -EINVAL; <answer> return 
if (value < <token> || <answer> IWL_BF_ESCAPE_TIMER_MIN 
<token> > IWL_BF_ESCAPE_TIMER_MAX) <answer> value 
<token> -EINVAL; <answer> return 
param <token> MVM_DEBUGFS_BF_ESCAPE_TIMER; <answer> = 
} else if <token> buf, 16)) { <answer> (!strncmp("ba_escape_timer=", 
if (sscanf(buf+16, "%d", &value) <token> 1) <answer> != 
return <token> <answer> -EINVAL; 
if <token> < IWL_BA_ESCAPE_TIMER_MIN || <answer> (value 
value <token> IWL_BA_ESCAPE_TIMER_MAX) <answer> > 
return <token> <answer> -EINVAL; 
param <token> MVM_DEBUGFS_BA_ESCAPE_TIMER; <answer> = 
} else if (!strncmp("ba_enable_beacon_abort=", buf, 23)) <token> <answer> { 
if (sscanf(buf+23, "%d", <token> != 1) <answer> &value) 
return <token> <answer> -EINVAL; 
if <token> < 0 || value > 1) <answer> (value 
return <token> <answer> -EINVAL; 
param = <token> <answer> MVM_DEBUGFS_BA_ENABLE_BEACON_ABORT; 
} else <token> <answer> { 
return <token> <answer> -EINVAL; 
<token> param, value); <answer> iwl_dbgfs_update_bf(vif, 
if (param == <token> && !value) <answer> MVM_DEBUGFS_BF_ENABLE_BEACON_FILTER 
<token> = iwl_mvm_disable_beacon_filter(mvm, vif); <answer> ret 
ret = <token> vif); <answer> iwl_mvm_enable_beacon_filter(mvm, 
<token> ret ?: count; <answer> return 
static ssize_t <token> file *file, <answer> iwl_dbgfs_bf_params_read(struct 
char __user <token> <answer> *user_buf, 
size_t count, <token> *ppos) <answer> loff_t 
struct <token> *vif = file->private_data; <answer> ieee80211_vif 
struct iwl_mvm_vif *mvmvif = <token> <answer> iwl_mvm_vif_from_mac80211(vif); 
<token> buf[256]; <answer> char 
int <token> = 0; <answer> pos 
const size_t <token> = sizeof(buf); <answer> bufsz 
struct iwl_beacon_filter_cmd <token> = { <answer> cmd 
<token> = <answer> .bf_enable_beacon_filter 
.ba_enable_beacon_abort <token> <answer> = 
<token> &cmd); <answer> iwl_mvm_beacon_filter_debugfs_parameters(vif, 
if <token> <answer> (mvmvif->bf_data.bf_enabled) 
<token> = cpu_to_le32(1); <answer> cmd.bf_enable_beacon_filter 
cmd.bf_enable_beacon_filter <token> 0; <answer> = 
pos += scnprintf(buf+pos, bufsz-pos, "bf_energy_delta = <token> <answer> %d\n", 
<token> += scnprintf(buf+pos, bufsz-pos, "bf_roaming_energy_delta = %d\n", <answer> pos 
<token> += scnprintf(buf+pos, bufsz-pos, "bf_roaming_state = %d\n", <answer> pos 
pos += scnprintf(buf+pos, <token> "bf_temp_threshold = %d\n", <answer> bufsz-pos, 
pos += scnprintf(buf+pos, bufsz-pos, "bf_temp_fast_filter <token> %d\n", <answer> = 
pos += scnprintf(buf+pos, bufsz-pos, <token> = %d\n", <answer> "bf_temp_slow_filter 
<token> += scnprintf(buf+pos, bufsz-pos, "bf_enable_beacon_filter = %d\n", <answer> pos 
pos += scnprintf(buf+pos, bufsz-pos, "bf_debug_flag = <token> <answer> %d\n", 
pos += scnprintf(buf+pos, bufsz-pos, <token> = %d\n", <answer> "bf_escape_timer 
pos += <token> bufsz-pos, "ba_escape_timer = %d\n", <answer> scnprintf(buf+pos, 
pos += <token> bufsz-pos, "ba_enable_beacon_abort = %d\n", <answer> scnprintf(buf+pos, 
return simple_read_from_buffer(user_buf, <token> ppos, buf, pos); <answer> count, 
static ssize_t iwl_dbgfs_os_device_timediff_read(struct file <token> <answer> *file, 
char <token> *user_buf, <answer> __user 
size_t count, loff_t <token> <answer> *ppos) 
struct ieee80211_vif <token> = file->private_data; <answer> *vif 
struct <token> *mvmvif = iwl_mvm_vif_from_mac80211(vif); <answer> iwl_mvm_vif 
struct iwl_mvm <token> = mvmvif->mvm; <answer> *mvm 
<token> curr_gp2; <answer> u32 
<token> curr_os; <answer> u64 
s64 <token> <answer> diff; 
char <token> <answer> buf[64]; 
const size_t bufsz = <token> <answer> sizeof(buf); 
int pos <token> 0; <answer> = 
<token> CLOCK_BOOTTIME, &curr_gp2, &curr_os, NULL); <answer> iwl_mvm_get_sync_time(mvm, 
do_div(curr_os, <token> <answer> NSEC_PER_USEC); 
<token> = curr_os - curr_gp2; <answer> diff 
pos += <token> + pos, bufsz - pos, "diff=%lld\n", diff); <answer> scnprintf(buf 
return simple_read_from_buffer(user_buf, count, ppos, buf, <token> <answer> pos); 
static ssize_t <token> ieee80211_vif *vif, char *buf, <answer> iwl_dbgfs_low_latency_write(struct 
<token> count, loff_t *ppos) <answer> size_t 
struct iwl_mvm_vif *mvmvif <token> iwl_mvm_vif_from_mac80211(vif); <answer> = 
struct iwl_mvm <token> = mvmvif->mvm; <answer> *mvm 
u8 <token> <answer> value; 
<token> ret; <answer> int 
ret = <token> 0, &value); <answer> kstrtou8(buf, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
if <token> > 1) <answer> (value 
<token> -EINVAL; <answer> return 
<token> vif, value, LOW_LATENCY_DEBUGFS); <answer> iwl_mvm_update_low_latency(mvm, 
return <token> <answer> count; 
static <token> <answer> ssize_t 
<token> ieee80211_vif *vif, char *buf, <answer> iwl_dbgfs_low_latency_force_write(struct 
size_t count, loff_t <token> <answer> *ppos) 
<token> iwl_mvm_vif *mvmvif = iwl_mvm_vif_from_mac80211(vif); <answer> struct 
struct <token> *mvm = mvmvif->mvm; <answer> iwl_mvm 
u8 <token> <answer> value; 
<token> ret; <answer> int 
ret <token> kstrtou8(buf, 0, &value); <answer> = 
if <token> <answer> (ret) 
<token> ret; <answer> return 
if (value > <token> <answer> NUM_LOW_LATENCY_FORCE) 
<token> -EINVAL; <answer> return 
if <token> == LOW_LATENCY_FORCE_UNSET) { <answer> (value 
iwl_mvm_update_low_latency(mvm, vif, <token> <answer> false, 
iwl_mvm_update_low_latency(mvm, vif, <token> <answer> false, 
<token> else { <answer> } 
<token> vif, <answer> iwl_mvm_update_low_latency(mvm, 
value == <token> <answer> LOW_LATENCY_FORCE_ON, 
iwl_mvm_update_low_latency(mvm, <token> true, <answer> vif, 
return <token> <answer> count; 
static ssize_t <token> file *file, <answer> iwl_dbgfs_low_latency_read(struct 
char <token> *user_buf, <answer> __user 
size_t <token> loff_t *ppos) <answer> count, 
struct ieee80211_vif *vif <token> file->private_data; <answer> = 
struct <token> *mvmvif = iwl_mvm_vif_from_mac80211(vif); <answer> iwl_mvm_vif 
char <token> = "traffic=%d\ndbgfs=%d\nvcmd=%d\nvif_type=%d\n" <answer> format[] 
char buf[sizeof(format) + <token> = {}; <answer> 1] 
<token> len; <answer> int 
len <token> scnprintf(buf, sizeof(buf) - 1, format, <answer> = 
<token> & LOW_LATENCY_TRAFFIC), <answer> !!(mvmvif->low_latency 
<token> & LOW_LATENCY_DEBUGFS), <answer> !!(mvmvif->low_latency 
!!(mvmvif->low_latency <token> LOW_LATENCY_VCMD), <answer> & 
!!(mvmvif->low_latency <token> LOW_LATENCY_VIF_TYPE), <answer> & 
<token> & <answer> !!(mvmvif->low_latency 
<token> & LOW_LATENCY_DEBUGFS_FORCE), <answer> !!(mvmvif->low_latency 
return simple_read_from_buffer(user_buf, count, ppos, <token> len); <answer> buf, 
static <token> iwl_dbgfs_uapsd_misbehaving_read(struct file *file, <answer> ssize_t 
char <token> *user_buf, <answer> __user 
size_t count, loff_t <token> <answer> *ppos) 
<token> ieee80211_vif *vif = file->private_data; <answer> struct 
struct iwl_mvm_vif *mvmvif = <token> <answer> iwl_mvm_vif_from_mac80211(vif); 
<token> buf[20]; <answer> char 
<token> len; <answer> int 
len = <token> "%pM\n", mvmvif->uapsd_misbehaving_ap_addr); <answer> sprintf(buf, 
return <token> count, ppos, buf, len); <answer> simple_read_from_buffer(user_buf, 
static <token> iwl_dbgfs_uapsd_misbehaving_write(struct ieee80211_vif *vif, <answer> ssize_t 
char *buf, <token> count, <answer> size_t 
<token> *ppos) <answer> loff_t 
struct iwl_mvm_vif *mvmvif <token> iwl_mvm_vif_from_mac80211(vif); <answer> = 
struct iwl_mvm <token> = mvmvif->mvm; <answer> *mvm 
bool <token> <answer> ret; 
ret = <token> mvmvif->uapsd_misbehaving_ap_addr); <answer> mac_pton(buf, 
return ret <token> count : -EINVAL; <answer> ? 
static ssize_t iwl_dbgfs_rx_phyinfo_write(struct ieee80211_vif *vif, <token> *buf, <answer> char 
size_t count, <token> *ppos) <answer> loff_t 
struct iwl_mvm_vif <token> = iwl_mvm_vif_from_mac80211(vif); <answer> *mvmvif 
struct <token> *mvm = mvmvif->mvm; <answer> iwl_mvm 
struct ieee80211_bss_conf <token> <answer> *link_conf; 
u16 <token> <answer> value; 
int link_id, <token> = -EINVAL; <answer> ret 
<token> = kstrtou16(buf, 0, &value); <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ret; 
mvm->dbgfs_rx_phyinfo = <token> <answer> value; 
for_each_vif_active_link(vif, <token> link_id) { <answer> link_conf, 
struct ieee80211_chanctx_conf <token> <answer> *chanctx_conf; 
struct cfg80211_chan_def <token> ap_def; <answer> min_def, 
<token> iwl_mvm_phy_ctxt *phy_ctxt; <answer> struct 
u8 chains_static, <token> <answer> chains_dynamic; 
chanctx_conf = <token> <answer> rcu_dereference(link_conf->chanctx_conf); 
<token> (!chanctx_conf) { <answer> if 
<token> = chanctx_conf->min_def; <answer> min_def 
ap_def = <token> <answer> chanctx_conf->ap; 
chains_static <token> chanctx_conf->rx_chains_static; <answer> = 
chains_dynamic <token> chanctx_conf->rx_chains_dynamic; <answer> = 
<token> = mvmvif->link[link_id]->phy_ctxt; <answer> phy_ctxt 
if <token> <answer> (!phy_ctxt) 
ret = <token> phy_ctxt, &min_def, &ap_def, <answer> iwl_mvm_phy_ctxt_changed(mvm, 
<token> chains_dynamic); <answer> chains_static, 
return ret ?: <token> <answer> count; 
static ssize_t iwl_dbgfs_rx_phyinfo_read(struct <token> *file, <answer> file 
char __user <token> <answer> *user_buf, 
size_t <token> loff_t *ppos) <answer> count, 
struct ieee80211_vif *vif <token> file->private_data; <answer> = 
struct iwl_mvm_vif *mvmvif <token> iwl_mvm_vif_from_mac80211(vif); <answer> = 
<token> buf[8]; <answer> char 
<token> len; <answer> int 
len <token> scnprintf(buf, sizeof(buf), "0x%04x\n", <answer> = 
return simple_read_from_buffer(user_buf, <token> ppos, buf, len); <answer> count, 
static void iwl_dbgfs_quota_check(void <token> u8 *mac, <answer> *data, 
struct ieee80211_vif <token> <answer> *vif) 
<token> iwl_mvm_vif *mvmvif = iwl_mvm_vif_from_mac80211(vif); <answer> struct 
int *ret <token> data; <answer> = 
if <token> <answer> (mvmvif->dbgfs_quota_min) 
*ret = <token> <answer> -EINVAL; 
static ssize_t iwl_dbgfs_quota_min_write(struct ieee80211_vif *vif, char <token> <answer> *buf, 
size_t count, <token> *ppos) <answer> loff_t 
struct <token> *mvmvif = iwl_mvm_vif_from_mac80211(vif); <answer> iwl_mvm_vif 
struct iwl_mvm *mvm <token> mvmvif->mvm; <answer> = 
<token> value; <answer> u16 
<token> ret; <answer> int 
ret = kstrtou16(buf, 0, <token> <answer> &value); 
<token> (ret) <answer> if 
return <token> <answer> ret; 
if <token> > 95) <answer> (value 
return <token> <answer> -EINVAL; 
<token> = 0; <answer> mvmvif->dbgfs_quota_min 
ieee80211_iterate_interfaces(mvm->hw, <token> <answer> IEEE80211_IFACE_ITER_NORMAL, 
<token> &ret); <answer> iwl_dbgfs_quota_check, 
if (ret == <token> { <answer> 0) 
mvmvif->dbgfs_quota_min <token> value; <answer> = 
iwl_mvm_update_quotas(mvm, <token> NULL); <answer> false, 
return <token> ?: count; <answer> ret 
<token> ssize_t iwl_dbgfs_quota_min_read(struct file *file, <answer> static 
char <token> *user_buf, <answer> __user 
size_t count, <token> *ppos) <answer> loff_t 
struct <token> *vif = file->private_data; <answer> ieee80211_vif 
struct iwl_mvm_vif *mvmvif = <token> <answer> iwl_mvm_vif_from_mac80211(vif); 
<token> buf[10]; <answer> char 
int <token> <answer> len; 
len = <token> sizeof(buf), "%d\n", mvmvif->dbgfs_quota_min); <answer> scnprintf(buf, 
return simple_read_from_buffer(user_buf, count, <token> buf, len); <answer> ppos, 
#define <token> bufsz) \ <answer> MVM_DEBUGFS_WRITE_FILE_OPS(name, 
<token> bufsz, struct ieee80211_vif) <answer> _MVM_DEBUGFS_WRITE_FILE_OPS(name, 
<token> MVM_DEBUGFS_READ_WRITE_FILE_OPS(name, bufsz) \ <answer> #define 
<token> bufsz, struct ieee80211_vif) <answer> _MVM_DEBUGFS_READ_WRITE_FILE_OPS(name, 
<token> MVM_DEBUGFS_ADD_FILE_VIF(name, parent, mode) do { \ <answer> #define 
debugfs_create_file(#name, mode, <token> vif, \ <answer> parent, 
&iwl_dbgfs_##name##_ops); <token> <answer> \ 
<token> while (0) <answer> } 
MVM_DEBUGFS_READ_WRITE_FILE_OPS(pm_params, <token> <answer> 32); 
MVM_DEBUGFS_READ_WRITE_FILE_OPS(bf_params, <token> <answer> 256); 
<token> 10); <answer> MVM_DEBUGFS_READ_WRITE_FILE_OPS(low_latency, 
MVM_DEBUGFS_WRITE_FILE_OPS(low_latency_force, <token> <answer> 10); 
<token> 20); <answer> MVM_DEBUGFS_READ_WRITE_FILE_OPS(uapsd_misbehaving, 
MVM_DEBUGFS_READ_WRITE_FILE_OPS(rx_phyinfo, <token> <answer> 10); 
<token> 32); <answer> MVM_DEBUGFS_READ_WRITE_FILE_OPS(quota_min, 
void iwl_mvm_vif_add_debugfs(struct ieee80211_hw *hw, struct ieee80211_vif <token> <answer> *vif) 
struct iwl_mvm <token> = IWL_MAC80211_GET_MVM(hw); <answer> *mvm 
<token> dentry *dbgfs_dir = vif->debugfs_dir; <answer> struct 
struct <token> *mvmvif = iwl_mvm_vif_from_mac80211(vif); <answer> iwl_mvm_vif 
mvmvif->dbgfs_dir = <token> dbgfs_dir); <answer> debugfs_create_dir("iwlmvm", 
if (IS_ERR_OR_NULL(mvmvif->dbgfs_dir)) <token> <answer> { 
IWL_ERR(mvm, <token> to create debugfs directory under %pd\n", <answer> "Failed 
if (iwlmvm_mod_params.power_scheme <token> IWL_POWER_SCHEME_CAM && <answer> != 
((vif->type == NL80211_IFTYPE_STATION && <token> || <answer> !vif->p2p) 
<token> == NL80211_IFTYPE_STATION && vif->p2p))) <answer> (vif->type 
MVM_DEBUGFS_ADD_FILE_VIF(pm_params, <token> 0600); <answer> mvmvif->dbgfs_dir, 
MVM_DEBUGFS_ADD_FILE_VIF(tx_pwr_lmt, mvmvif->dbgfs_dir, <token> <answer> 0400); 
MVM_DEBUGFS_ADD_FILE_VIF(mac_params, <token> 0400); <answer> mvmvif->dbgfs_dir, 
<token> mvmvif->dbgfs_dir, 0600); <answer> MVM_DEBUGFS_ADD_FILE_VIF(low_latency, 
MVM_DEBUGFS_ADD_FILE_VIF(low_latency_force, <token> 0600); <answer> mvmvif->dbgfs_dir, 
MVM_DEBUGFS_ADD_FILE_VIF(uapsd_misbehaving, mvmvif->dbgfs_dir, <token> <answer> 0600); 
MVM_DEBUGFS_ADD_FILE_VIF(rx_phyinfo, mvmvif->dbgfs_dir, <token> <answer> 0600); 
<token> mvmvif->dbgfs_dir, 0600); <answer> MVM_DEBUGFS_ADD_FILE_VIF(quota_min, 
MVM_DEBUGFS_ADD_FILE_VIF(os_device_timediff, <token> 0400); <answer> mvmvif->dbgfs_dir, 
<token> (vif->type == NL80211_IFTYPE_STATION && !vif->p2p && <answer> if 
<token> == mvm->bf_allowed_vif) <answer> mvmvif 
<token> mvmvif->dbgfs_dir, 0600); <answer> MVM_DEBUGFS_ADD_FILE_VIF(bf_params, 
void iwl_mvm_vif_dbgfs_add_link(struct iwl_mvm *mvm, struct <token> *vif) <answer> ieee80211_vif 
struct dentry *dbgfs_dir <token> vif->debugfs_dir; <answer> = 
struct iwl_mvm_vif <token> = iwl_mvm_vif_from_mac80211(vif); <answer> *mvmvif 
char buf[3 * 3 + <token> + (NL80211_WIPHY_NAME_MAXLEN + 1) + <answer> 11 
(7 + IFNAMSIZ + 1) + <token> + 1]; <answer> 6 
char <token> + IFNAMSIZ + 1]; <answer> name[7 
snprintf(name, sizeof(name), <token> dbgfs_dir); <answer> "%pd", 
<token> sizeof(buf), "../../../%pd3/iwlmvm", dbgfs_dir); <answer> snprintf(buf, 
mvmvif->dbgfs_slink <token> <answer> = 
<token> mvm->debugfs_dir, buf); <answer> debugfs_create_symlink(name, 
void iwl_mvm_vif_dbgfs_rm_link(struct iwl_mvm <token> struct ieee80211_vif *vif) <answer> *mvm, 
struct iwl_mvm_vif *mvmvif = <token> <answer> iwl_mvm_vif_from_mac80211(vif); 
<token> = NULL; <answer> mvmvif->dbgfs_slink 
#define MVM_DEBUGFS_WRITE_LINK_FILE_OPS(name, <token> \ <answer> bufsz) 
<token> bufsz, \ <answer> _MVM_DEBUGFS_WRITE_FILE_OPS(link_##name, 
<token> ieee80211_bss_conf) <answer> struct 
#define MVM_DEBUGFS_READ_WRITE_LINK_FILE_OPS(name, <token> \ <answer> bufsz) 
_MVM_DEBUGFS_READ_WRITE_FILE_OPS(link_##name, bufsz, <token> <answer> \ 
<token> ieee80211_bss_conf) <answer> struct 
#define MVM_DEBUGFS_ADD_LINK_FILE(name, <token> mode) \ <answer> parent, 
debugfs_create_file(#name, mode, <token> link_conf, \ <answer> parent, 
static void iwl_mvm_debugfs_add_link_files(struct ieee80211_vif <token> <answer> *vif, 
struct <token> *link_conf, <answer> ieee80211_bss_conf 
struct dentry <token> <answer> *mvm_dir) 
#define pr_fmt(fmt) <token> " fmt <answer> "perf/amd_iommu: 
<token> <linux/perf_event.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/cpumask.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/amd-iommu.h> <answer> #include 
#include <token> <answer> "../perf_event.h" 
<token> "iommu.h" <answer> #include 
<token> "config:0-7"); <answer> PMU_FORMAT_ATTR(csource, 
PMU_FORMAT_ATTR(devid, <token> <answer> "config:8-23"); 
PMU_FORMAT_ATTR(domid, <token> <answer> "config:24-39"); 
PMU_FORMAT_ATTR(pasid, <token> <answer> "config:40-59"); 
<token> "config1:0-15"); <answer> PMU_FORMAT_ATTR(devid_mask, 
<token> "config1:16-31"); <answer> PMU_FORMAT_ATTR(domid_mask, 
PMU_FORMAT_ATTR(pasid_mask, <token> <answer> "config1:32-51"); 
static struct attribute <token> = { <answer> *iommu_format_attrs[] 
static struct attribute_group amd_iommu_format_group = <token> <answer> { 
.name <token> "format", <answer> = 
.attrs <token> iommu_format_attrs, <answer> = 
static <token> attribute_group amd_iommu_events_group = { <answer> struct 
.name = <token> <answer> "events", 
<token> amd_iommu_event_desc { <answer> struct 
struct <token> attr; <answer> device_attribute 
<token> char *event; <answer> const 
static ssize_t <token> device *dev, <answer> _iommu_event_show(struct 
<token> device_attribute *attr, char *buf) <answer> struct 
struct amd_iommu_event_desc <token> = <answer> *event 
container_of(attr, struct amd_iommu_event_desc, <token> <answer> attr); 
return sprintf(buf, <token> event->event); <answer> "%s\n", 
<token> AMD_IOMMU_EVENT_DESC(_name, _event) \ <answer> #define 
<token> \ <answer> { 
.attr = __ATTR(_name, 0444, _iommu_event_show, NULL), <token> <answer> \ 
.event <token> _event, \ <answer> = 
<token> struct amd_iommu_event_desc amd_iommu_v2_event_descs[] = { <answer> static 
AMD_IOMMU_EVENT_DESC(mem_pass_untrans, <token> <answer> "csource=0x01"), 
<token> "csource=0x02"), <answer> AMD_IOMMU_EVENT_DESC(mem_pass_pretrans, 
AMD_IOMMU_EVENT_DESC(mem_pass_excl, <token> <answer> "csource=0x03"), 
AMD_IOMMU_EVENT_DESC(mem_target_abort, <token> <answer> "csource=0x04"), 
<token> "csource=0x05"), <answer> AMD_IOMMU_EVENT_DESC(mem_trans_total, 
AMD_IOMMU_EVENT_DESC(mem_iommu_tlb_pte_hit, <token> <answer> "csource=0x06"), 
AMD_IOMMU_EVENT_DESC(mem_iommu_tlb_pte_mis, <token> <answer> "csource=0x07"), 
<token> "csource=0x08"), <answer> AMD_IOMMU_EVENT_DESC(mem_iommu_tlb_pde_hit, 
<token> "csource=0x09"), <answer> AMD_IOMMU_EVENT_DESC(mem_iommu_tlb_pde_mis, 
AMD_IOMMU_EVENT_DESC(mem_dte_hit, <token> <answer> "csource=0x0a"), 
<token> "csource=0x0b"), <answer> AMD_IOMMU_EVENT_DESC(mem_dte_mis, 
AMD_IOMMU_EVENT_DESC(page_tbl_read_tot, <token> <answer> "csource=0x0c"), 
<token> "csource=0x0d"), <answer> AMD_IOMMU_EVENT_DESC(page_tbl_read_nst, 
<token> "csource=0x0e"), <answer> AMD_IOMMU_EVENT_DESC(page_tbl_read_gst, 
AMD_IOMMU_EVENT_DESC(int_dte_hit, <token> <answer> "csource=0x0f"), 
AMD_IOMMU_EVENT_DESC(int_dte_mis, <token> <answer> "csource=0x10"), 
<token> "csource=0x11"), <answer> AMD_IOMMU_EVENT_DESC(cmd_processed, 
<token> "csource=0x12"), <answer> AMD_IOMMU_EVENT_DESC(cmd_processed_inv, 
<token> "csource=0x13"), <answer> AMD_IOMMU_EVENT_DESC(tlb_inv, 
<token> "csource=0x14"), <answer> AMD_IOMMU_EVENT_DESC(ign_rd_wr_mmio_1ff8h, 
<token> "csource=0x15"), <answer> AMD_IOMMU_EVENT_DESC(vapic_int_non_guest, 
<token> "csource=0x16"), <answer> AMD_IOMMU_EVENT_DESC(vapic_int_guest, 
<token> "csource=0x17"), <answer> AMD_IOMMU_EVENT_DESC(smi_recv, 
AMD_IOMMU_EVENT_DESC(smi_blk, <token> <answer> "csource=0x18"), 
<token> cpumask_t iommu_cpumask; <answer> static 
static ssize_t _iommu_cpumask_show(struct device <token> <answer> *dev, 
struct device_attribute <token> <answer> *attr, 
<token> *buf) <answer> char 
return cpumap_print_to_pagebuf(true, buf, <token> <answer> &iommu_cpumask); 
static DEVICE_ATTR(cpumask, S_IRUGO, _iommu_cpumask_show, <token> <answer> NULL); 
static struct attribute *iommu_cpumask_attrs[] <token> { <answer> = 
static struct <token> amd_iommu_cpumask_group = { <answer> attribute_group 
.attrs = <token> <answer> iommu_cpumask_attrs, 
if (is_sampling_event(event) || event->attach_state & <token> <answer> PERF_ATTACH_TASK) 
return <token> <answer> -EINVAL; 
if (event->cpu < <token> <answer> 0) 
return <token> <answer> -EINVAL; 
if (flags & <token> { <answer> PERF_EF_RELOAD) 
u64 count = <token> <answer> 0; 
struct <token> *iommu = perf_event_2_iommu(event); <answer> amd_iommu 
amd_iommu_pc_set_reg(iommu, hwc->iommu_bank, <token> <answer> hwc->iommu_cntr, 
<token> &count); <answer> IOMMU_PC_COUNTER_REG, 
static void perf_iommu_read(struct perf_event <token> <answer> *event) 
<token> count; <answer> u64 
struct hw_perf_event *hwc = <token> <answer> &event->hw; 
struct amd_iommu *iommu = <token> <answer> perf_event_2_iommu(event); 
if (amd_iommu_pc_get_reg(iommu, hwc->iommu_bank, <token> <answer> hwc->iommu_cntr, 
<token> &count)) <answer> IOMMU_PC_COUNTER_REG, 
<token> &event->count); <answer> local64_add(count, 
static void perf_iommu_stop(struct perf_event *event, int <token> <answer> flags) 
struct <token> *hwc = &event->hw; <answer> hw_perf_event 
if (hwc->state <token> PERF_HES_UPTODATE) <answer> & 
<token> |= PERF_HES_UPTODATE; <answer> hwc->state 
WARN_ON_ONCE(hwc->state <token> PERF_HES_STOPPED); <answer> & 
<token> |= PERF_HES_STOPPED; <answer> hwc->state 
static <token> perf_iommu_add(struct perf_event *event, int flags) <answer> int 
<token> retval; <answer> int 
event->hw.state = PERF_HES_UPTODATE <token> PERF_HES_STOPPED; <answer> | 
for (i = 0; i <token> amd_iommu_get_num_iommus(); i++) { <answer> < 
ret = <token> <answer> init_one_iommu(i); 
<token> (!ret) <answer> if 
if <token> { <answer> (!cnt) 
<token> -ENODEV; <answer> return 
#include <token> <answer> "saa7164.h" 
int <token> saa7164_dev *dev) <answer> saa7164_bus_setup(struct 
<token> tmComResBusInfo *b = &dev->bus; <answer> struct 
b->Type <token> TYPE_BUS_PCIe; <answer> = 
<token> = SAA_DEVICE_MAXREQUESTSIZE; <answer> b->m_wMaxReqSize 
b->m_pdwSetRing <token> (u8 __iomem *)(dev->bmmio + <answer> = 
b->m_dwSizeSetRing <token> SAA_DEVICE_BUFFERBLOCKSIZE; <answer> = 
b->m_pdwGetRing <token> (u8 __iomem *)(dev->bmmio + <answer> = 
b->m_dwSizeGetRing = <token> <answer> SAA_DEVICE_BUFFERBLOCKSIZE; 
b->m_dwSetWritePos = <token> + <answer> ((u32)dev->intfdesc.BARLocation) 
(2 * <token> <answer> sizeof(u64)); 
b->m_dwSetReadPos = b->m_dwSetWritePos <token> (1 * sizeof(u32)); <answer> + 
b->m_dwGetWritePos = <token> + (2 * sizeof(u32)); <answer> b->m_dwSetWritePos 
b->m_dwGetReadPos = <token> + (3 * sizeof(u32)); <answer> b->m_dwSetWritePos 
<token> 0; <answer> return 
void saa7164_bus_dump(struct <token> *dev) <answer> saa7164_dev 
struct <token> *b = &dev->bus; <answer> tmComResBusInfo 
<token> "Dumping the bus structure:\n"); <answer> dprintk(DBGLVL_BUS, 
dprintk(DBGLVL_BUS, " .type = %d\n", <token> <answer> b->Type); 
dprintk(DBGLVL_BUS, " .dev->bmmio = <token> dev->bmmio); <answer> 0x%p\n", 
dprintk(DBGLVL_BUS, <token> .m_wMaxReqSize = 0x%x\n", b->m_wMaxReqSize); <answer> " 
dprintk(DBGLVL_BUS, <token> .m_pdwSetRing = 0x%p\n", b->m_pdwSetRing); <answer> " 
dprintk(DBGLVL_BUS, " .m_dwSizeSetRing = <token> b->m_dwSizeSetRing); <answer> 0x%x\n", 
dprintk(DBGLVL_BUS, " <token> = 0x%p\n", b->m_pdwGetRing); <answer> .m_pdwGetRing 
dprintk(DBGLVL_BUS, <token> .m_dwSizeGetRing = 0x%x\n", b->m_dwSizeGetRing); <answer> " 
dprintk(DBGLVL_BUS, " .m_dwSetReadPos <token> 0x%x (0x%08x)\n", <answer> = 
b->m_dwSetReadPos, <token> <answer> saa7164_readl(b->m_dwSetReadPos)); 
dprintk(DBGLVL_BUS, " .m_dwSetWritePos <token> 0x%x (0x%08x)\n", <answer> = 
b->m_dwSetWritePos, <token> <answer> saa7164_readl(b->m_dwSetWritePos)); 
<token> " .m_dwGetReadPos = 0x%x (0x%08x)\n", <answer> dprintk(DBGLVL_BUS, 
<token> saa7164_readl(b->m_dwGetReadPos)); <answer> b->m_dwGetReadPos, 
<token> " .m_dwGetWritePos = 0x%x (0x%08x)\n", <answer> dprintk(DBGLVL_BUS, 
b->m_dwGetWritePos, <token> <answer> saa7164_readl(b->m_dwGetWritePos)); 
int saa7164_bus_set(struct <token> *dev, struct tmComResInfo* msg, <answer> saa7164_dev 
<token> *buf) <answer> void 
struct tmComResBusInfo *bus <token> &dev->bus; <answer> = 
u32 bytes_to_write, free_write_space, timeout, <token> curr_swp; <answer> curr_srp, 
u32 new_swp, <token> <answer> space_rem; 
<token> ret = SAA_ERR_BAD_PARAMETER; <answer> int 
<token> size; <answer> u16 
<token> (!msg) { <answer> if 
printk(KERN_ERR <token> !msg\n", __func__); <answer> "%s() 
return <token> <answer> SAA_ERR_BAD_PARAMETER; 
<token> "%s()\n", __func__); <answer> dprintk(DBGLVL_BUS, 
<token> (msg->size > dev->bus.m_wMaxReqSize) { <answer> if 
<token> "%s() Exceeded dev->bus.m_wMaxReqSize\n", <answer> printk(KERN_ERR 
<token> SAA_ERR_BAD_PARAMETER; <answer> return 
if ((msg->size <token> 0) && (buf == NULL)) { <answer> > 
printk(KERN_ERR "%s() Missing message buffer\n", <token> <answer> __func__); 
<token> SAA_ERR_BAD_PARAMETER; <answer> return 
size = <token> <answer> msg->size; 
int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* <token> <answer> msg, 
void *buf, int <token> <answer> peekonly) 
struct tmComResBusInfo *bus = <token> <answer> &dev->bus; 
u32 <token> write_distance, curr_grp, curr_gwp, <answer> bytes_to_read, 
new_grp, <token> space_rem; <answer> buf_size, 
struct tmComResInfo <token> <answer> msg_tmp; 
int ret <token> SAA_ERR_BAD_PARAMETER; <answer> = 
<token> (msg == NULL) <answer> if 
<token> ret; <answer> return 
if (msg->size > dev->bus.m_wMaxReqSize) <token> <answer> { 
<token> "%s() Exceeded dev->bus.m_wMaxReqSize\n", <answer> printk(KERN_ERR 
return <token> <answer> ret; 
if ((peekonly == 0) && (msg->size > <token> && (buf == NULL)) { <answer> 0) 
"%s() Missing msg buf, size should be %d <token> <answer> bytes\n", 
__func__, <token> <answer> msg->size); 
return <token> <answer> ret; 
<token> = saa7164_readl(bus->m_dwGetWritePos); <answer> curr_gwp 
<token> = saa7164_readl(bus->m_dwGetReadPos); <answer> curr_grp 
<token> (curr_gwp == curr_grp) { <answer> if 
ret <token> SAA_ERR_EMPTY; <answer> = 
<token> out; <answer> goto 
bytes_to_read <token> sizeof(*msg); <answer> = 
#include <token> <answer> <linux/capability.h> 
#include <token> <answer> <linux/file.h> 
#include <token> <answer> <linux/fdtable.h> 
<token> <linux/filelock.h> <answer> #include 
<token> <linux/fs.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/security.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/syscalls.h> <answer> #include 
#include <token> <answer> <linux/time.h> 
#include <token> <answer> <linux/rcupdate.h> 
#include <token> <answer> <linux/pid_namespace.h> 
<token> <linux/hashtable.h> <answer> #include 
<token> <linux/percpu.h> <answer> #include 
#include <token> <answer> <linux/sysctl.h> 
<token> CREATE_TRACE_POINTS <answer> #define 
#include <token> <answer> <trace/events/filelock.h> 
#include <token> <answer> <linux/uaccess.h> 
static struct file_lock <token> file_lock_core *flc) <answer> *file_lock(struct 
return container_of(flc, <token> file_lock, c); <answer> struct 
static struct <token> *file_lease(struct file_lock_core *flc) <answer> file_lease 
return container_of(flc, <token> file_lease, c); <answer> struct 
static <token> lease_breaking(struct file_lease *fl) <answer> bool 
<token> fl->c.flc_flags & (FL_UNLOCK_PENDING | FL_DOWNGRADE_PENDING); <answer> return 
<token> int target_leasetype(struct file_lease *fl) <answer> static 
if (fl->c.flc_flags & <token> <answer> FL_UNLOCK_PENDING) 
<token> F_UNLCK; <answer> return 
if <token> & FL_DOWNGRADE_PENDING) <answer> (fl->c.flc_flags 
return <token> <answer> F_RDLCK; 
return <token> <answer> fl->c.flc_type; 
static int leases_enable = <token> <answer> 1; 
static int lease_break_time <token> 45; <answer> = 
<token> CONFIG_SYSCTL <answer> #ifdef 
static struct ctl_table locks_sysctls[] = <token> <answer> { 
<token> = "leases-enable", <answer> .procname 
.data = <token> <answer> &leases_enable, 
.maxlen <token> sizeof(int), <answer> = 
<token> = 0644, <answer> .mode 
.proc_handler <token> proc_dointvec, <answer> = 
#ifdef <token> <answer> CONFIG_MMU 
.procname <token> "lease-break-time", <answer> = 
<token> = &lease_break_time, <answer> .data 
.maxlen <token> sizeof(int), <answer> = 
.mode <token> 0644, <answer> = 
.proc_handler <token> proc_dointvec, <answer> = 
struct <token> { <answer> file_lock_list_struct 
<token> lock; <answer> spinlock_t 
struct hlist_head <token> <answer> hlist; 
static <token> file_lock_list_struct, file_lock_list); <answer> DEFINE_PER_CPU(struct 
<token> BLOCKED_HASH_BITS 7 <answer> #define 
static DEFINE_HASHTABLE(blocked_hash, <token> <answer> BLOCKED_HASH_BITS); 
static <token> <answer> DEFINE_SPINLOCK(blocked_lock_lock); 
static struct <token> *flctx_cache __ro_after_init; <answer> kmem_cache 
static struct <token> *filelock_cache __ro_after_init; <answer> kmem_cache 
static <token> kmem_cache *filelease_cache __ro_after_init; <answer> struct 
static <token> file_lock_context * <answer> struct 
locks_get_lock_context(struct inode *inode, int <token> <answer> type) 
<token> file_lock_context *ctx; <answer> struct 
if (cmpxchg(&inode->i_flctx, NULL, <token> { <answer> ctx)) 
<token> ctx); <answer> kmem_cache_free(flctx_cache, 
<token> = locks_inode_context(inode); <answer> ctx 
<token> type, ctx); <answer> trace_locks_get_lock_context(inode, 
<token> ctx; <answer> return 
static <token> <answer> void 
locks_dump_ctx_list(struct <token> *list, char *list_type) <answer> list_head 
struct file_lock_core <token> <answer> *flc; 
list_for_each_entry(flc, list, <token> <answer> flc_list) 
pr_warn("%s: fl_owner=%p <token> fl_type=0x%x fl_pid=%u\n", <answer> fl_flags=0x%x 
<token> flc->flc_owner, flc->flc_flags, <answer> list_type, 
flc->flc_type, <token> <answer> flc->flc_pid); 
<token> void <answer> static 
locks_check_ctx_lists(struct inode <token> <answer> *inode) 
struct file_lock_context *ctx <token> inode->i_flctx; <answer> = 
<token> (unlikely(!list_empty(&ctx->flc_flock) || <answer> if 
<token> || <answer> !list_empty(&ctx->flc_posix) 
!list_empty(&ctx->flc_lease))) <token> <answer> { 
pr_warn("Leaked <token> on dev=0x%x:0x%x ino=0x%lx:\n", <answer> locks 
<token> MINOR(inode->i_sb->s_dev), <answer> MAJOR(inode->i_sb->s_dev), 
locks_dump_ctx_list(&ctx->flc_flock, <token> <answer> "FLOCK"); 
locks_dump_ctx_list(&ctx->flc_posix, <token> <answer> "POSIX"); 
locks_dump_ctx_list(&ctx->flc_lease, <token> <answer> "LEASE"); 
static <token> <answer> void 
<token> file *filp, struct list_head *list, char *list_type) <answer> locks_check_ctx_file_list(struct 
struct <token> *flc; <answer> file_lock_core 
struct <token> *inode = file_inode(filp); <answer> inode 
<token> list, flc_list) <answer> list_for_each_entry(flc, 
<token> (flc->flc_file == filp) <answer> if 
pr_warn("Leaked <token> lock on dev=0x%x:0x%x ino=0x%lx " <answer> %s 
" fl_owner=%p fl_flags=0x%x fl_type=0x%x <token> <answer> fl_pid=%u\n", 
<token> MAJOR(inode->i_sb->s_dev), <answer> list_type, 
MINOR(inode->i_sb->s_dev), <token> <answer> inode->i_ino, 
<token> flc->flc_flags, <answer> flc->flc_owner, 
flc->flc_type, <token> <answer> flc->flc_pid); 
<token> inode *inode) <answer> locks_free_lock_context(struct 
struct file_lock_context *ctx <token> locks_inode_context(inode); <answer> = 
if <token> { <answer> (unlikely(ctx)) 
<token> ctx); <answer> kmem_cache_free(flctx_cache, 
static void locks_init_lock_heads(struct file_lock_core <token> <answer> *flc) 
bool locks_owner_has_blockers(struct file_lock_context *flctx, <token> owner) <answer> fl_owner_t 
<token> file_lock_core *flc; <answer> struct 
<token> &flctx->flc_posix, flc_list) { <answer> list_for_each_entry(flc, 
<token> (flc->flc_owner != owner) <answer> if 
if <token> { <answer> (!list_empty(&flc->flc_blocked_requests)) 
return <token> <answer> true; 
<token> false; <answer> return 
<token> locks_copy_conflock(struct file_lock *new, struct file_lock *fl) <answer> void 
new->c.flc_owner = <token> <answer> fl->c.flc_owner; 
new->c.flc_pid = <token> <answer> fl->c.flc_pid; 
new->c.flc_file = <token> <answer> NULL; 
new->c.flc_flags = <token> <answer> fl->c.flc_flags; 
new->c.flc_type <token> fl->c.flc_type; <answer> = 
<token> = fl->fl_start; <answer> new->fl_start 
new->fl_end = <token> <answer> fl->fl_end; 
new->fl_lmops <token> fl->fl_lmops; <answer> = 
<token> = NULL; <answer> new->fl_ops 
<token> (fl->fl_lmops) { <answer> if 
<token> (fl->fl_lmops->lm_get_owner) <answer> if 
void <token> file_lock *new, struct file_lock *fl) <answer> locks_copy_lock(struct 
if <token> <answer> (list_empty(&fl->c.flc_blocked_requests)) 
<token> &new->c.flc_blocked_requests, <answer> list_for_each_entry(f, 
f->c.flc_blocker = <token> <answer> &new->c; 
static <token> int flock_translate_cmd(int cmd) { <answer> inline 
switch <token> { <answer> (cmd) 
case <token> <answer> LOCK_SH: 
<token> F_RDLCK; <answer> return 
<token> LOCK_EX: <answer> case 
<token> F_WRLCK; <answer> return 
case <token> <answer> LOCK_UN: 
return <token> <answer> F_UNLCK; 
return <token> <answer> -EINVAL; 
if (l->l_len > <token> { <answer> 0) 
if (l->l_len - 1 > OFFSET_MAX - <token> <answer> fl->fl_start) 
return <token> <answer> -EOVERFLOW; 
fl->fl_end = fl->fl_start <token> (l->l_len - 1); <answer> + 
<token> else if (l->l_len < 0) { <answer> } 
if (fl->fl_start + l->l_len < <token> <answer> 0) 
<token> -EINVAL; <answer> return 
fl->fl_end = <token> - 1; <answer> fl->fl_start 
fl->fl_start <token> l->l_len; <answer> += 
} <token> <answer> else 
fl->fl_end <token> OFFSET_MAX; <answer> = 
fl->c.flc_owner = <token> <answer> current->files; 
<token> = current->tgid; <answer> fl->c.flc_pid 
fl->c.flc_file <token> filp; <answer> = 
fl->c.flc_flags <token> FL_POSIX; <answer> = 
fl->fl_ops = <token> <answer> NULL; 
fl->fl_lmops = <token> <answer> NULL; 
return assign_type(&fl->c, <token> <answer> l->l_type); 
static int flock_to_posix_lock(struct file *filp, struct file_lock <token> <answer> *fl, 
struct flock <token> <answer> *l) 
struct <token> ll = { <answer> flock64 
<token> = l->l_type, <answer> .l_type 
.l_whence <token> l->l_whence, <answer> = 
<token> = l->l_start, <answer> .l_start 
.l_len <token> l->l_len, <answer> = 
<token> flock64_to_posix_lock(filp, fl, &ll); <answer> return 
if (!fasync_insert_entry(fa->fa_fd, filp, <token> fa)) <answer> &fl->fl_fasync, 
*priv = <token> <answer> NULL; 
__f_setown(filp, task_pid(current), <token> 0); <answer> PIDTYPE_TGID, 
<token> const struct lease_manager_operations lease_manager_ops = { <answer> static 
.lm_break = <token> <answer> lease_break_callback, 
.lm_change = <token> <answer> lease_modify, 
<token> = lease_setup, <answer> .lm_setup 
static int lease_init(struct file *filp, int type, struct <token> *fl) <answer> file_lease 
if (assign_type(&fl->c, type) <token> 0) <answer> != 
return <token> <answer> -EINVAL; 
fl->c.flc_owner <token> filp; <answer> = 
fl->c.flc_pid = <token> <answer> current->tgid; 
fl->c.flc_file <token> filp; <answer> = 
fl->c.flc_flags = <token> <answer> FL_LEASE; 
fl->fl_lmops = <token> <answer> &lease_manager_ops; 
<token> 0; <answer> return 
static <token> int locks_overlap(struct file_lock *fl1, struct file_lock *fl2) <answer> inline 
return ((fl1->fl_end >= fl2->fl_start) <token> <answer> && 
(fl2->fl_end >= <token> <answer> fl1->fl_start)); 
static int posix_same_owner(struct file_lock_core <token> struct file_lock_core *fl2) <answer> *fl1, 
return <token> == fl2->flc_owner; <answer> fl1->flc_owner 
<token> (hlist_unhashed(&flc->flc_link)) <answer> if 
<token> = per_cpu_ptr(&file_lock_list, flc->flc_link_cpu); <answer> fll 
static <token> long <answer> unsigned 
<token> file_lock_core *flc) <answer> posix_owner_key(struct 
return (unsigned long) <token> <answer> flc->flc_owner; 
static void locks_insert_global_blocked(struct file_lock_core <token> <answer> *waiter) 
hash_add(blocked_hash, &waiter->flc_link, <token> <answer> posix_owner_key(waiter)); 
<token> void locks_delete_global_blocked(struct file_lock_core *waiter) <answer> static 
static void __locks_unlink_block(struct <token> *waiter) <answer> file_lock_core 
<token> void __locks_wake_up_blocks(struct file_lock_core *blocker) <answer> static 
while (!list_empty(&blocker->flc_blocked_requests)) <token> <answer> { 
struct <token> *waiter; <answer> file_lock_core 
<token> file_lock *fl; <answer> struct 
waiter = <token> <answer> list_first_entry(&blocker->flc_blocked_requests, 
<token> file_lock_core, flc_blocked_member); <answer> struct 
<token> = file_lock(waiter); <answer> fl 
if ((waiter->flc_flags & <token> | FL_FLOCK)) && <answer> (FL_POSIX 
fl->fl_lmops && <token> <answer> fl->fl_lmops->lm_notify) 
smp_store_release(&waiter->flc_blocker, <token> <answer> NULL); 
static int <token> file_lock_core *waiter) <answer> __locks_delete_block(struct 
int <token> = -ENOENT; <answer> status 
if <token> && <answer> (!smp_load_acquire(&waiter->flc_blocker) 
<token> status; <answer> return 
<token> (waiter->flc_blocker) <answer> if 
status = <token> <answer> 0; 
smp_store_release(&waiter->flc_blocker, <token> <answer> NULL); 
<token> status; <answer> return 
int <token> file_lock *waiter) <answer> locks_delete_block(struct 
return <token> <answer> __locks_delete_block(&waiter->c); 
static void __locks_insert_block(struct file_lock_core <token> <answer> *blocker, 
struct <token> *waiter, <answer> file_lock_core 
bool conflict(struct <token> *, <answer> file_lock_core 
struct file_lock_core <token> <answer> *)) 
struct file_lock_core <token> <answer> *flc; 
list_for_each_entry(flc, &blocker->flc_blocked_requests, <token> <answer> flc_blocked_member) 
<token> (conflict(flc, waiter)) { <answer> if 
blocker <token> flc; <answer> = 
goto <token> <answer> new_blocker; 
<token> = blocker; <answer> waiter->flc_blocker 
if ((blocker->flc_flags & <token> == FL_POSIX) <answer> (FL_POSIX|FL_OFDLCK)) 
static void locks_wake_up_blocks(struct <token> *blocker) <answer> file_lock_core 
<token> (list_empty(&blocker->flc_blocked_requests)) <answer> if 
<token> void <answer> static 
locks_insert_lock_ctx(struct file_lock_core *fl, <token> list_head *before) <answer> struct 
list_add_tail(&fl->flc_list, <token> <answer> before); 
<token> void <answer> static 
locks_unlink_lock_ctx(struct file_lock_core <token> <answer> *fl) 
static <token> <answer> void 
locks_delete_lock_ctx(struct file_lock_core <token> struct list_head *dispose) <answer> *fl, 
<token> (dispose) <answer> if 
<token> dispose); <answer> list_add(&fl->flc_list, 
static bool <token> file_lock_core *caller_flc, <answer> locks_conflict(struct 
<token> file_lock_core *sys_flc) <answer> struct 
if (sys_flc->flc_type <token> F_WRLCK) <answer> == 
return <token> <answer> true; 
if <token> == F_WRLCK) <answer> (caller_flc->flc_type 
return <token> <answer> true; 
<token> false; <answer> return 
static <token> posix_locks_conflict(struct file_lock_core *caller_flc, <answer> bool 
struct <token> *sys_flc) <answer> file_lock_core 
struct file_lock *caller_fl = <token> <answer> file_lock(caller_flc); 
<token> file_lock *sys_fl = file_lock(sys_flc); <answer> struct 
if <token> sys_flc)) <answer> (posix_same_owner(caller_flc, 
<token> false; <answer> return 
<token> bool posix_test_locks_conflict(struct file_lock *caller_fl, <answer> static 
struct <token> *sys_fl) <answer> file_lock 
<token> file_lock_core *caller = &caller_fl->c; <answer> struct 
struct file_lock_core *sys <token> &sys_fl->c; <answer> = 
static bool flock_locks_conflict(struct file_lock_core <token> <answer> *caller_flc, 
<token> file_lock_core *sys_flc) <answer> struct 
if (caller_flc->flc_file <token> sys_flc->flc_file) <answer> == 
return <token> <answer> false; 
<token> locks_conflict(caller_flc, sys_flc); <answer> return 
posix_test_lock(struct file *filp, struct <token> *fl) <answer> file_lock 
<token> file_lock *cfl; <answer> struct 
struct file_lock_context <token> <answer> *ctx; 
struct inode *inode <token> file_inode(filp); <answer> = 
void <token> <answer> *owner; 
<token> (*func)(void); <answer> void 
ctx = <token> <answer> locks_inode_context(inode); 
<token> (!ctx || list_empty_careful(&ctx->flc_posix)) { <answer> if 
fl->c.flc_type <token> F_UNLCK; <answer> = 
list_for_each_entry(cfl, &ctx->flc_posix, c.flc_list) <token> <answer> { 
if <token> cfl)) <answer> (!posix_test_locks_conflict(fl, 
if (cfl->fl_lmops && <token> <answer> cfl->fl_lmops->lm_lock_expirable 
&& (*cfl->fl_lmops->lm_lock_expirable)(cfl)) <token> <answer> { 
owner <token> cfl->fl_lmops->lm_mod_owner; <answer> = 
func = <token> <answer> cfl->fl_lmops->lm_expire_lock; 
<token> retry; <answer> goto 
locks_copy_conflock(fl, <token> <answer> cfl); 
<token> out; <answer> goto 
<token> = F_UNLCK; <answer> fl->c.flc_type 
#define MAX_DEADLK_ITERATIONS <token> <answer> 10 
if <token> & FL_OFDLCK) <answer> (caller->flc_flags 
return <token> <answer> false; 
while ((blocker = what_owner_is_waiting_for(blocker))) <token> <answer> { 
if <token> > MAX_DEADLK_ITERATIONS) <answer> (i++ 
<token> false; <answer> return 
if <token> blocker)) <answer> (posix_same_owner(caller, 
<token> true; <answer> return 
return <token> <answer> false; 
static int flock_lock_inode(struct <token> *inode, struct file_lock *request) <answer> inode 
struct file_lock <token> = NULL; <answer> *new_fl 
struct file_lock <token> <answer> *fl; 
struct <token> *ctx; <answer> file_lock_context 
<token> error = 0; <answer> int 
bool <token> = false; <answer> found 
ctx = locks_get_lock_context(inode, <token> <answer> request->c.flc_type); 
if <token> { <answer> (!ctx) 
if (request->c.flc_type != <token> <answer> F_UNLCK) 
return <token> <answer> -ENOMEM; 
return (request->c.flc_flags & <token> ? -ENOENT : 0; <answer> FL_EXISTS) 
if (!(request->c.flc_flags & <token> && (request->c.flc_type != F_UNLCK)) { <answer> FL_ACCESS) 
<token> = locks_alloc_lock(); <answer> new_fl 
if <token> <answer> (!new_fl) 
<token> -ENOMEM; <answer> return 
<token> (request->c.flc_flags & FL_ACCESS) <answer> if 
goto <token> <answer> find_conflict; 
<token> &ctx->flc_flock, c.flc_list) { <answer> list_for_each_entry(fl, 
if (request->c.flc_file != <token> <answer> fl->c.flc_file) 
<token> (request->c.flc_type == fl->c.flc_type) <answer> if 
goto <token> <answer> out; 
found = <token> <answer> true; 
locks_delete_lock_ctx(&fl->c, <token> <answer> &dispose); 
if (lock_is_unlock(request)) <token> <answer> { 
if <token> & FL_EXISTS) && !found) <answer> ((request->c.flc_flags 
error = <token> <answer> -ENOENT; 
<token> out; <answer> goto 
list_for_each_entry(fl, &ctx->flc_flock, <token> { <answer> c.flc_list) 
if <token> &fl->c)) <answer> (!flock_locks_conflict(&request->c, 
error <token> -EAGAIN; <answer> = 
if <token> & FL_SLEEP)) <answer> (!(request->c.flc_flags 
goto <token> <answer> out; 
<token> = FILE_LOCK_DEFERRED; <answer> error 
<token> &request->c, flock_locks_conflict); <answer> locks_insert_block(&fl->c, 
goto <token> <answer> out; 
if <token> & FL_ACCESS) <answer> (request->c.flc_flags 
goto <token> <answer> out; 
<token> request); <answer> locks_copy_lock(new_fl, 
locks_move_blocks(new_fl, <token> <answer> request); 
locks_insert_lock_ctx(&new_fl->c, <token> <answer> &ctx->flc_flock); 
new_fl <token> NULL; <answer> = 
error = <token> <answer> 0; 
<token> (new_fl) <answer> if 
trace_flock_lock_inode(inode, <token> error); <answer> request, 
return <token> <answer> error; 
<token> int posix_lock_inode(struct inode *inode, struct file_lock *request, <answer> static 
<token> file_lock *conflock) <answer> struct 
struct file_lock *fl, <token> <answer> *tmp; 
struct <token> *new_fl = NULL; <answer> file_lock 
struct <token> *new_fl2 = NULL; <answer> file_lock 
struct file_lock *left <token> NULL; <answer> = 
struct <token> *right = NULL; <answer> file_lock 
<token> file_lock_context *ctx; <answer> struct 
int <token> <answer> error; 
<token> added = false; <answer> bool 
void <token> <answer> *owner; 
<token> (*func)(void); <answer> void 
ctx = <token> request->c.flc_type); <answer> locks_get_lock_context(inode, 
<token> (!ctx) <answer> if 
<token> lock_is_unlock(request) ? 0 : -ENOMEM; <answer> return 
if <token> & FL_ACCESS) && <answer> (!(request->c.flc_flags 
<token> != F_UNLCK || <answer> (request->c.flc_type 
<token> != 0 || request->fl_end != OFFSET_MAX)) { <answer> request->fl_start 
new_fl = <token> <answer> locks_alloc_lock(); 
new_fl2 <token> locks_alloc_lock(); <answer> = 
if (request->c.flc_type != F_UNLCK) <token> <answer> { 
<token> &ctx->flc_posix, c.flc_list) { <answer> list_for_each_entry(fl, 
<token> (!posix_locks_conflict(&request->c, &fl->c)) <answer> if 
if (fl->fl_lmops <token> fl->fl_lmops->lm_lock_expirable <answer> && 
<token> (*fl->fl_lmops->lm_lock_expirable)(fl)) { <answer> && 
owner <token> fl->fl_lmops->lm_mod_owner; <answer> = 
func <token> fl->fl_lmops->lm_expire_lock; <answer> = 
goto <token> <answer> retry; 
<token> (conflock) <answer> if 
<token> fl); <answer> locks_copy_conflock(conflock, 
error = <token> <answer> -EAGAIN; 
if (!(request->c.flc_flags & <token> <answer> FL_SLEEP)) 
goto <token> <answer> out; 
<token> = -EDEADLK; <answer> error 
if <token> fl))) { <answer> (likely(!posix_locks_deadlock(request, 
error <token> FILE_LOCK_DEFERRED; <answer> = 
<token> &request->c, <answer> __locks_insert_block(&fl->c, 
goto <token> <answer> out; 
<token> (fl->fl_end < request->fl_start - 1) <answer> if 
if (fl->fl_start - 1 <token> request->fl_end) <answer> > 
if <token> > request->fl_start) <answer> (fl->fl_start 
fl->fl_start = <token> <answer> request->fl_start; 
<token> = fl->fl_start; <answer> request->fl_start 
if <token> < request->fl_end) <answer> (fl->fl_end 
fl->fl_end <token> request->fl_end; <answer> = 
request->fl_end = <token> <answer> fl->fl_end; 
<token> (added) { <answer> if 
<token> &dispose); <answer> locks_delete_lock_ctx(&fl->c, 
request = <token> <answer> fl; 
<token> = true; <answer> added 
} <token> { <answer> else 
if (fl->fl_end < <token> <answer> request->fl_start) 
<token> (fl->fl_start > request->fl_end) <answer> if 
<token> (lock_is_unlock(request)) <answer> if 
added = <token> <answer> true; 
<token> (fl->fl_start < request->fl_start) <answer> if 
left <token> fl; <answer> = 
if (fl->fl_end > <token> { <answer> request->fl_end) 
<token> = fl; <answer> right 
if <token> >= request->fl_start) { <answer> (fl->fl_start 
if (added) <token> <answer> { 
<token> &dispose); <answer> locks_delete_lock_ctx(&fl->c, 
error = <token> <answer> -ENOLCK; 
if <token> <answer> (!new_fl) 
goto <token> <answer> out; 
locks_copy_lock(new_fl, <token> <answer> request); 
locks_move_blocks(new_fl, <token> <answer> request); 
request = <token> <answer> new_fl; 
new_fl = <token> <answer> NULL; 
<token> &dispose); <answer> locks_delete_lock_ctx(&fl->c, 
added <token> true; <answer> = 
<token> = new_fl2; <answer> left 
new_fl2 <token> NULL; <answer> = 
locks_copy_lock(left, <token> <answer> right); 
<token> &fl->c.flc_list); <answer> locks_insert_lock_ctx(&left->c, 
right->fl_start = request->fl_end <token> 1; <answer> + 
<token> (left) { <answer> if 
left->fl_end <token> request->fl_start - 1; <answer> = 
trace_posix_lock_inode(inode, request, <token> <answer> error); 
if <token> <answer> (new_fl) 
if <token> <answer> (new_fl2) 
return <token> <answer> error; 
int posix_lock_file(struct file *filp, <token> file_lock *fl, <answer> struct 
<token> file_lock *conflock) <answer> struct 
<token> posix_lock_inode(file_inode(filp), fl, conflock); <answer> return 
static int posix_lock_inode_wait(struct inode *inode, struct <token> *fl) <answer> file_lock 
<token> error; <answer> int 
might_sleep <token> <answer> (); 
for <token> { <answer> (;;) 
error = <token> fl, NULL); <answer> posix_lock_inode(inode, 
if (error != <token> <answer> FILE_LOCK_DEFERRED) 
<token> = wait_event_interruptible(fl->c.flc_wait, <answer> error 
<token> (error) <answer> if 
<token> error; <answer> return 
static void lease_clear_pending(struct file_lease *fl, <token> arg) <answer> int 
<token> (arg) { <answer> switch 
case <token> <answer> F_UNLCK: 
fl->c.flc_flags <token> ~FL_UNLOCK_PENDING; <answer> &= 
<token> F_RDLCK: <answer> case 
fl->c.flc_flags <token> ~FL_DOWNGRADE_PENDING; <answer> &= 
int __break_lease(struct inode *inode, unsigned int mode, <token> int type) <answer> unsigned 
int error = <token> <answer> 0; 
struct file_lock_context <token> <answer> *ctx; 
struct file_lease <token> *fl, *tmp; <answer> *new_fl, 
<token> long break_time; <answer> unsigned 
int want_write = (mode <token> O_ACCMODE) != O_RDONLY; <answer> & 
new_fl <token> lease_alloc(NULL, want_write ? F_WRLCK : F_RDLCK); <answer> = 
if <token> <answer> (IS_ERR(new_fl)) 
return <token> <answer> PTR_ERR(new_fl); 
new_fl->c.flc_flags <token> type; <answer> = 
if (error == <token> <answer> 0) 
time_out_leases(inode, <token> <answer> &dispose); 
<token> (any_leases_conflict(inode, new_fl)) <answer> if 
<token> restart; <answer> goto 
<token> = 0; <answer> error 
return <token> <answer> error; 
void lease_get_mtime(struct inode *inode, struct timespec64 <token> <answer> *time) 
bool <token> = false; <answer> has_lease 
struct file_lock_context <token> <answer> *ctx; 
<token> file_lock_core *flc; <answer> struct 
ctx = <token> <answer> locks_inode_context(inode); 
if (ctx && <token> { <answer> !list_empty_careful(&ctx->flc_lease)) 
flc <token> list_first_entry_or_null(&ctx->flc_lease, <answer> = 
<token> file_lock_core, flc_list); <answer> struct 
<token> (flc && flc->flc_type == F_WRLCK) <answer> if 
has_lease <token> true; <answer> = 
if <token> <answer> (has_lease) 
<token> = current_time(inode); <answer> *time 
<token> fcntl_getlease(struct file *filp) <answer> int 
struct file_lease <token> <answer> *fl; 
<token> inode *inode = file_inode(filp); <answer> struct 
struct <token> *ctx; <answer> file_lock_context 
int type = <token> <answer> F_UNLCK; 
<token> = locks_inode_context(inode); <answer> ctx 
if (ctx && !list_empty_careful(&ctx->flc_lease)) <token> <answer> { 
<token> &dispose); <answer> time_out_leases(inode, 
list_for_each_entry(fl, <token> c.flc_list) { <answer> &ctx->flc_lease, 
if <token> != filp) <answer> (fl->c.flc_file 
<token> = target_leasetype(fl); <answer> type 
<token> type; <answer> return 
<token> int <answer> static 
<token> file *filp, const int arg, int flags) <answer> check_conflicting_open(struct 
struct inode *inode = <token> <answer> file_inode(filp); 
<token> self_wcount = 0, self_rcount = 0; <answer> int 
if <token> & FL_LAYOUT) <answer> (flags 
return <token> <answer> 0; 
if (flags & <token> <answer> FL_DELEG) 
if (filp->f_mode & <token> <answer> FMODE_WRITE) 
self_wcount = <token> <answer> 1; 
else <token> (filp->f_mode & FMODE_READ) <answer> if 
self_rcount = <token> <answer> 1; 
<token> (atomic_read(&inode->i_writecount) != self_wcount || <answer> if 
atomic_read(&inode->i_readcount) <token> self_rcount) <answer> != 
return <token> <answer> -EAGAIN; 
<token> 0; <answer> return 
<token> int <answer> static 
generic_add_lease(struct file *filp, int arg, struct <token> **flp, void **priv) <answer> file_lease 
<token> file_lease *fl, *my_fl = NULL, *lease; <answer> struct 
<token> inode *inode = file_inode(filp); <answer> struct 
struct <token> *ctx; <answer> file_lock_context 
bool is_deleg = <token> & FL_DELEG; <answer> (*flp)->c.flc_flags 
int <token> <answer> error; 
<token> = *flp; <answer> lease 
trace_generic_add_lease(inode, <token> <answer> lease); 
if (is_deleg <token> !inode_trylock(inode)) <answer> && 
<token> -EAGAIN; <answer> return 
<token> &dispose); <answer> time_out_leases(inode, 
error = <token> arg, lease->c.flc_flags); <answer> check_conflicting_open(filp, 
if <token> <answer> (error) 
<token> out; <answer> goto 
<token> = -EAGAIN; <answer> error 
list_for_each_entry(fl, <token> c.flc_list) { <answer> &ctx->flc_lease, 
if <token> == filp && <answer> (fl->c.flc_file 
fl->c.flc_owner == <token> { <answer> lease->c.flc_owner) 
my_fl = <token> <answer> fl; 
if (arg == <token> <answer> F_WRLCK) 
goto <token> <answer> out; 
<token> (fl->c.flc_flags & FL_UNLOCK_PENDING) <answer> if 
<token> out; <answer> goto 
if (my_fl != NULL) <token> <answer> { 
<token> = my_fl; <answer> lease 
error = <token> arg, &dispose); <answer> lease->fl_lmops->lm_change(lease, 
if <token> <answer> (error) 
<token> out; <answer> goto 
<token> out_setup; <answer> goto 
<token> = -EINVAL; <answer> error 
<token> (!leases_enable) <answer> if 
<token> out; <answer> goto 
locks_insert_lock_ctx(&lease->c, <token> <answer> &ctx->flc_lease); 
error <token> check_conflicting_open(filp, arg, lease->c.flc_flags); <answer> = 
if (error) <token> <answer> { 
<token> out; <answer> goto 
<token> (lease->fl_lmops->lm_setup) <answer> if 
<token> priv); <answer> lease->fl_lmops->lm_setup(lease, 
if <token> <answer> (is_deleg) 
if <token> && !my_fl) <answer> (!error 
<token> = NULL; <answer> *flp 
<token> error; <answer> return 
static int generic_delete_lease(struct file <token> void *owner) <answer> *filp, 
int <token> = -EAGAIN; <answer> error 
struct <token> *fl, *victim = NULL; <answer> file_lease 
struct inode *inode <token> file_inode(filp); <answer> = 
<token> file_lock_context *ctx; <answer> struct 
<token> = locks_inode_context(inode); <answer> ctx 
<token> (!ctx) { <answer> if 
trace_generic_delete_lease(inode, <token> <answer> NULL); 
<token> error; <answer> return 
list_for_each_entry(fl, &ctx->flc_lease, <token> { <answer> c.flc_list) 
if (fl->c.flc_file <token> filp && <answer> == 
fl->c.flc_owner == owner) <token> <answer> { 
victim <token> fl; <answer> = 
<token> victim); <answer> trace_generic_delete_lease(inode, 
<token> (victim) <answer> if 
error <token> fl->fl_lmops->lm_change(victim, F_UNLCK, &dispose); <answer> = 
<token> error; <answer> return 
int generic_setlease(struct file *filp, int <token> struct file_lease **flp, <answer> arg, 
void <token> <answer> **priv) 
switch (arg) <token> <answer> { 
<token> F_UNLCK: <answer> case 
return generic_delete_lease(filp, <token> <answer> *priv); 
<token> F_RDLCK: <answer> case 
<token> F_WRLCK: <answer> case 
if <token> { <answer> (!(*flp)->fl_lmops->lm_break) 
return <token> <answer> -ENOLCK; 
<token> generic_add_lease(filp, arg, flp, priv); <answer> return 
return <token> <answer> -EINVAL; 
static <token> srcu_notifier_head lease_notifier_chain; <answer> struct 
<token> inline void <answer> static 
static inline <token> <answer> void 
setlease_notifier(int arg, struct <token> *lease) <answer> file_lease 
<token> (arg != F_UNLCK) <answer> if 
srcu_notifier_call_chain(&lease_notifier_chain, <token> lease); <answer> arg, 
int lease_register_notifier(struct <token> *nb) <answer> notifier_block 
return srcu_notifier_chain_register(&lease_notifier_chain, <token> <answer> nb); 
void lease_unregister_notifier(struct notifier_block <token> <answer> *nb) 
srcu_notifier_chain_unregister(&lease_notifier_chain, <token> <answer> nb); 
kernel_setlease(struct file *filp, int arg, struct file_lease <token> void **priv) <answer> **lease, 
if <token> <answer> (lease) 
setlease_notifier(arg, <token> <answer> *lease); 
if <token> <answer> (filp->f_op->setlease) 
return filp->f_op->setlease(filp, arg, <token> priv); <answer> lease, 
return generic_setlease(filp, arg, lease, <token> <answer> priv); 
vfs_setlease(struct file *filp, int arg, struct <token> **lease, void **priv) <answer> file_lease 
struct inode <token> = file_inode(filp); <answer> *inode 
vfsuid_t vfsuid = i_uid_into_vfsuid(file_mnt_idmap(filp), <token> <answer> inode); 
<token> error; <answer> int 
if ((!vfsuid_eq_kuid(vfsuid, current_fsuid())) <token> !capable(CAP_LEASE)) <answer> && 
return <token> <answer> -EACCES; 
if <token> <answer> (!S_ISREG(inode->i_mode)) 
<token> -EINVAL; <answer> return 
error = <token> arg); <answer> security_file_lock(filp, 
<token> (error) <answer> if 
return <token> <answer> error; 
return <token> arg, lease, priv); <answer> kernel_setlease(filp, 
static int do_fcntl_add_lease(unsigned int fd, struct file <token> int arg) <answer> *filp, 
<token> file_lease *fl; <answer> struct 
struct <token> *new; <answer> fasync_struct 
int <token> <answer> error; 
fl = lease_alloc(filp, <token> <answer> arg); 
if <token> <answer> (IS_ERR(fl)) 
<token> PTR_ERR(fl); <answer> return 
<token> = fasync_alloc(); <answer> new 
<token> (!new) { <answer> if 
<token> -ENOMEM; <answer> return 
<token> = fd; <answer> new->fa_fd 
error = vfs_setlease(filp, arg, &fl, (void <token> <answer> **)&new); 
<token> (fl) <answer> if 
if <token> <answer> (new) 
<token> error; <answer> return 
int <token> int fd, struct file *filp, int arg) <answer> fcntl_setlease(unsigned 
if <token> == F_UNLCK) <answer> (arg 
return <token> F_UNLCK, NULL, (void **)&filp); <answer> vfs_setlease(filp, 
<token> do_fcntl_add_lease(fd, filp, arg); <answer> return 
<token> int flock_lock_inode_wait(struct inode *inode, struct file_lock *fl) <answer> static 
<token> error; <answer> int 
for <token> { <answer> (;;) 
error <token> flock_lock_inode(inode, fl); <answer> = 
if (error <token> FILE_LOCK_DEFERRED) <answer> != 
error = <token> <answer> wait_event_interruptible(fl->c.flc_wait, 
<token> (error) <answer> if 
return <token> <answer> error; 
int <token> inode *inode, struct file_lock *fl) <answer> locks_lock_inode_wait(struct 
<token> res = 0; <answer> int 
switch (fl->c.flc_flags <token> (FL_POSIX|FL_FLOCK)) { <answer> & 
<token> FL_POSIX: <answer> case 
res = posix_lock_inode_wait(inode, <token> <answer> fl); 
<token> FL_FLOCK: <answer> case 
<token> = flock_lock_inode_wait(inode, fl); <answer> res 
return <token> <answer> res; 
SYSCALL_DEFINE2(flock, unsigned int, <token> unsigned int, cmd) <answer> fd, 
int <token> error, type; <answer> can_sleep, 
struct file_lock <token> <answer> fl; 
<token> fd f; <answer> struct 
if (cmd & LOCK_MAND) <token> <answer> { 
pr_warn_once("%s(%d): Attempt <token> set a LOCK_MAND lock via flock(2). This support has been removed and the request ignored.\n", current->comm, current->pid); <answer> to 
return <token> <answer> 0; 
type = flock_translate_cmd(cmd <token> ~LOCK_NB); <answer> & 
<token> (type < 0) <answer> if 
return <token> <answer> type; 
error <token> -EBADF; <answer> = 
<token> = fdget(fd); <answer> f 
<token> (!f.file) <answer> if 
<token> error; <answer> return 
if (type != F_UNLCK && !(f.file->f_mode & (FMODE_READ | <token> <answer> FMODE_WRITE))) 
goto <token> <answer> out_putf; 
flock_make_lock(f.file, &fl, <token> <answer> type); 
<token> = security_file_lock(f.file, fl.c.flc_type); <answer> error 
<token> (error) <answer> if 
goto <token> <answer> out_putf; 
<token> = !(cmd & LOCK_NB); <answer> can_sleep 
<token> (can_sleep) <answer> if 
fl.c.flc_flags |= <token> <answer> FL_SLEEP; 
<token> (f.file->f_op->flock) <answer> if 
error = <token> <answer> f.file->f_op->flock(f.file, 
(can_sleep) <token> F_SETLKW : F_SETLK, <answer> ? 
error = locks_lock_file_wait(f.file, <token> <answer> &fl); 
return <token> <answer> error; 
int vfs_test_lock(struct file *filp, struct <token> *fl) <answer> file_lock 
<token> != fl->c.flc_file); <answer> WARN_ON_ONCE(filp 
if <token> <answer> (filp->f_op->lock) 
return <token> F_GETLK, fl); <answer> filp->f_op->lock(filp, 
<token> fl); <answer> posix_test_lock(filp, 
return <token> <answer> 0; 
static pid_t locks_translate_pid(struct file_lock_core <token> struct pid_namespace *ns) <answer> *fl, 
pid_t <token> <answer> vnr; 
struct <token> *pid; <answer> pid 
if (fl->flc_flags & <token> <answer> FL_OFDLCK) 
<token> -1; <answer> return 
if <token> == &init_pid_ns) <answer> (ns 
<token> (pid_t) fl->flc_pid; <answer> return 
pid <token> find_pid_ns(fl->flc_pid, &init_pid_ns); <answer> = 
vnr = pid_nr_ns(pid, <token> <answer> ns); 
return <token> <answer> vnr; 
static int posix_lock_to_flock(struct <token> *flock, struct file_lock *fl) <answer> flock 
<token> = locks_translate_pid(&fl->c, task_active_pid_ns(current)); <answer> flock->l_pid 
#if <token> == 32 <answer> BITS_PER_LONG 
if <token> > OFFT_OFFSET_MAX) <answer> (fl->fl_start 
return <token> <answer> -EOVERFLOW; 
if (fl->fl_end != OFFSET_MAX && <token> > OFFT_OFFSET_MAX) <answer> fl->fl_end 
return <token> <answer> -EOVERFLOW; 
flock->l_start = <token> <answer> fl->fl_start; 
flock->l_len = fl->fl_end <token> OFFSET_MAX ? 0 : <answer> == 
<token> - fl->fl_start + 1; <answer> fl->fl_end 
<token> = 0; <answer> flock->l_whence 
<token> = fl->c.flc_type; <answer> flock->l_type 
return <token> <answer> 0; 
#if BITS_PER_LONG <token> 32 <answer> == 
static void posix_lock_to_flock64(struct flock64 *flock, struct file_lock <token> <answer> *fl) 
<token> = locks_translate_pid(&fl->c, task_active_pid_ns(current)); <answer> flock->l_pid 
flock->l_start <token> fl->fl_start; <answer> = 
flock->l_len = fl->fl_end == <token> ? 0 : <answer> OFFSET_MAX 
fl->fl_end - <token> + 1; <answer> fl->fl_start 
<token> = 0; <answer> flock->l_whence 
flock->l_type <token> fl->c.flc_type; <answer> = 
int fcntl_getlk(struct file <token> unsigned int cmd, struct flock *flock) <answer> *filp, 
struct file_lock <token> <answer> *fl; 
<token> error; <answer> int 
<token> = locks_alloc_lock(); <answer> fl 
if (fl == <token> <answer> NULL) 
<token> -ENOMEM; <answer> return 
error <token> -EINVAL; <answer> = 
if (cmd != F_OFD_GETLK && flock->l_type != <token> <answer> F_RDLCK 
&& <token> != F_WRLCK) <answer> flock->l_type 
goto <token> <answer> out; 
error = flock_to_posix_lock(filp, <token> flock); <answer> fl, 
<token> (error) <answer> if 
goto <token> <answer> out; 
<token> (cmd == F_OFD_GETLK) { <answer> if 
error <token> -EINVAL; <answer> = 
if <token> != 0) <answer> (flock->l_pid 
<token> out; <answer> goto 
<token> |= FL_OFDLCK; <answer> fl->c.flc_flags 
fl->c.flc_owner <token> filp; <answer> = 
<token> = vfs_test_lock(filp, fl); <answer> error 
<token> (error) <answer> if 
<token> out; <answer> goto 
flock->l_type <token> fl->c.flc_type; <answer> = 
if (fl->c.flc_type != <token> { <answer> F_UNLCK) 
error = posix_lock_to_flock(flock, <token> <answer> fl); 
if <token> <answer> (error) 
<token> out; <answer> goto 
return <token> <answer> error; 
int vfs_lock_file(struct file *filp, unsigned int cmd, struct file_lock <token> struct file_lock *conf) <answer> *fl, 
WARN_ON_ONCE(filp <token> fl->c.flc_file); <answer> != 
if <token> <answer> (filp->f_op->lock) 
<token> filp->f_op->lock(filp, cmd, fl); <answer> return 
return <token> fl, conf); <answer> posix_lock_file(filp, 
static int do_lock_file_wait(struct file <token> unsigned int cmd, <answer> *filp, 
struct <token> *fl) <answer> file_lock 
int <token> <answer> error; 
error = security_file_lock(filp, <token> <answer> fl->c.flc_type); 
<token> (error) <answer> if 
<token> error; <answer> return 
for (;;) <token> <answer> { 
error <token> vfs_lock_file(filp, cmd, fl, NULL); <answer> = 
<token> (error != FILE_LOCK_DEFERRED) <answer> if 
<token> = wait_event_interruptible(fl->c.flc_wait, <answer> error 
<token> (error) <answer> if 
<token> error; <answer> return 
int fcntl_setlk(unsigned int fd, struct file *filp, unsigned int <token> <answer> cmd, 
struct flock <token> <answer> *flock) 
struct <token> *file_lock = locks_alloc_lock(); <answer> file_lock 
struct <token> *inode = file_inode(filp); <answer> inode 
struct file <token> <answer> *f; 
int <token> <answer> error; 
if (file_lock <token> NULL) <answer> == 
return <token> <answer> -ENOLCK; 
error = <token> file_lock, flock); <answer> flock_to_posix_lock(filp, 
if <token> <answer> (error) 
<token> out; <answer> goto 
error <token> check_fmode_for_setlk(file_lock); <answer> = 
if <token> <answer> (error) 
goto <token> <answer> out; 
switch <token> { <answer> (cmd) 
<token> F_OFD_SETLK: <answer> case 
<token> = -EINVAL; <answer> error 
<token> (flock->l_pid != 0) <answer> if 
goto <token> <answer> out; 
cmd <token> F_SETLK; <answer> = 
file_lock->c.flc_flags <token> FL_OFDLCK; <answer> |= 
<token> = filp; <answer> file_lock->c.flc_owner 
<token> F_OFD_SETLKW: <answer> case 
error <token> -EINVAL; <answer> = 
if (flock->l_pid <token> 0) <answer> != 
goto <token> <answer> out; 
<token> = F_SETLKW; <answer> cmd 
file_lock->c.flc_flags |= <token> <answer> FL_OFDLCK; 
file_lock->c.flc_owner = <token> <answer> filp; 
case <token> <answer> F_SETLKW: 
file_lock->c.flc_flags <token> FL_SLEEP; <answer> |= 
error = <token> cmd, file_lock); <answer> do_lock_file_wait(filp, 
if (!error && file_lock->c.flc_type != F_UNLCK <token> <answer> && 
<token> & FL_OFDLCK)) { <answer> !(file_lock->c.flc_flags 
struct files_struct <token> = current->files; <answer> *files 
<token> = files_lookup_fd_locked(files, fd); <answer> f 
if (f != filp) <token> <answer> { 
file_lock->c.flc_type = <token> <answer> F_UNLCK; 
error = <token> cmd, file_lock); <answer> do_lock_file_wait(filp, 
<token> = -EBADF; <answer> error 
trace_fcntl_setlk(inode, <token> error); <answer> file_lock, 
<token> error; <answer> return 
<token> BITS_PER_LONG == 32 <answer> #if 
int fcntl_getlk64(struct file <token> unsigned int cmd, struct flock64 *flock) <answer> *filp, 
<token> file_lock *fl; <answer> struct 
int <token> <answer> error; 
<token> = locks_alloc_lock(); <answer> fl 
if <token> == NULL) <answer> (fl 
<token> -ENOMEM; <answer> return 
error = <token> <answer> -EINVAL; 
if (cmd != F_OFD_GETLK && <token> != F_RDLCK <answer> flock->l_type 
<token> flock->l_type != F_WRLCK) <answer> && 
goto <token> <answer> out; 
error = flock64_to_posix_lock(filp, <token> flock); <answer> fl, 
<token> (error) <answer> if 
<token> out; <answer> goto 
if (cmd == F_OFD_GETLK) <token> <answer> { 
error <token> -EINVAL; <answer> = 
if <token> != 0) <answer> (flock->l_pid 
goto <token> <answer> out; 
fl->c.flc_flags <token> FL_OFDLCK; <answer> |= 
fl->c.flc_owner = <token> <answer> filp; 
error = <token> fl); <answer> vfs_test_lock(filp, 
if <token> <answer> (error) 
goto <token> <answer> out; 
flock->l_type <token> fl->c.flc_type; <answer> = 
if (fl->c.flc_type != <token> <answer> F_UNLCK) 
posix_lock_to_flock64(flock, <token> <answer> fl); 
return <token> <answer> error; 
int fcntl_setlk64(unsigned int fd, struct <token> *filp, unsigned int cmd, <answer> file 
struct flock64 <token> <answer> *flock) 
<token> file_lock *file_lock = locks_alloc_lock(); <answer> struct 
<token> file *f; <answer> struct 
<token> error; <answer> int 
if (file_lock <token> NULL) <answer> == 
return <token> <answer> -ENOLCK; 
error = flock64_to_posix_lock(filp, file_lock, <token> <answer> flock); 
<token> (error) <answer> if 
goto <token> <answer> out; 
error = <token> <answer> check_fmode_for_setlk(file_lock); 
<token> (error) <answer> if 
goto <token> <answer> out; 
switch <token> { <answer> (cmd) 
case <token> <answer> F_OFD_SETLK: 
<token> = -EINVAL; <answer> error 
<token> (flock->l_pid != 0) <answer> if 
goto <token> <answer> out; 
<token> = F_SETLK64; <answer> cmd 
<token> |= FL_OFDLCK; <answer> file_lock->c.flc_flags 
file_lock->c.flc_owner = <token> <answer> filp; 
case <token> <answer> F_OFD_SETLKW: 
error = <token> <answer> -EINVAL; 
if (flock->l_pid <token> 0) <answer> != 
goto <token> <answer> out; 
cmd <token> F_SETLKW64; <answer> = 
<token> |= FL_OFDLCK; <answer> file_lock->c.flc_flags 
file_lock->c.flc_owner <token> filp; <answer> = 
case <token> <answer> F_SETLKW64: 
<token> |= FL_SLEEP; <answer> file_lock->c.flc_flags 
<token> = do_lock_file_wait(filp, cmd, file_lock); <answer> error 
if (!error && file_lock->c.flc_type != F_UNLCK <token> <answer> && 
!(file_lock->c.flc_flags & <token> { <answer> FL_OFDLCK)) 
struct files_struct *files = <token> <answer> current->files; 
<token> = files_lookup_fd_locked(files, fd); <answer> f 
if (f != filp) <token> <answer> { 
<token> = F_UNLCK; <answer> file_lock->c.flc_type 
<token> = do_lock_file_wait(filp, cmd, file_lock); <answer> error 
error = <token> <answer> -EBADF; 
return <token> <answer> error; 
void <token> file *filp, fl_owner_t owner) <answer> locks_remove_posix(struct 
<token> error; <answer> int 
struct inode *inode <token> file_inode(filp); <answer> = 
struct file_lock <token> <answer> lock; 
struct file_lock_context <token> <answer> *ctx; 
ctx <token> locks_inode_context(inode); <answer> = 
if (!ctx <token> list_empty(&ctx->flc_posix)) <answer> || 
lock.c.flc_type <token> F_UNLCK; <answer> = 
<token> = FL_POSIX | FL_CLOSE; <answer> lock.c.flc_flags 
lock.fl_start = <token> <answer> 0; 
<token> = OFFSET_MAX; <answer> lock.fl_end 
<token> = owner; <answer> lock.c.flc_owner 
lock.c.flc_pid = <token> <answer> current->tgid; 
lock.c.flc_file <token> filp; <answer> = 
<token> = NULL; <answer> lock.fl_ops 
lock.fl_lmops = <token> <answer> NULL; 
error = vfs_lock_file(filp, F_SETLK, <token> NULL); <answer> &lock, 
if (lock.fl_ops <token> lock.fl_ops->fl_release_private) <answer> && 
<token> &lock, error); <answer> trace_locks_remove_posix(inode, 
void locks_remove_file(struct file <token> <answer> *filp) 
<token> file_lock_context *ctx; <answer> struct 
ctx <token> locks_inode_context(file_inode(filp)); <answer> = 
<token> (!ctx) <answer> if 
int vfs_cancel_lock(struct file *filp, struct file_lock <token> <answer> *fl) 
WARN_ON_ONCE(filp <token> fl->c.flc_file); <answer> != 
<token> (filp->f_op->lock) <answer> if 
return filp->f_op->lock(filp, <token> fl); <answer> F_CANCELLK, 
return <token> <answer> 0; 
bool vfs_inode_has_locks(struct inode <token> <answer> *inode) 
<token> file_lock_context *ctx; <answer> struct 
bool <token> <answer> ret; 
ctx = <token> <answer> locks_inode_context(inode); 
if <token> <answer> (!ctx) 
return <token> <answer> false; 
ret <token> !list_empty(&ctx->flc_posix) || !list_empty(&ctx->flc_flock); <answer> = 
<token> ret; <answer> return 
<token> CONFIG_PROC_FS <answer> #ifdef 
#include <token> <answer> <linux/proc_fs.h> 
<token> <linux/seq_file.h> <answer> #include 
struct <token> { <answer> locks_iterator 
<token> li_cpu; <answer> int 
<token> li_pos; <answer> loff_t 
static void lock_get_status(struct seq_file *f, <token> file_lock_core *flc, <answer> struct 
loff_t <token> char *pfx, int repeat) <answer> id, 
