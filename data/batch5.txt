#include <token> <answer> <linux/stddef.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/reboot.h> 
<token> <linux/seq_file.h> <answer> #include 
#include <token> <answer> <linux/of_fdt.h> 
<token> <linux/of_platform.h> <answer> #include 
#include <token> <answer> <asm/machdep.h> 
<token> <asm/udbg.h> <answer> #include 
<token> <asm/mpic.h> <answer> #include 
<token> <sysdev/fsl_soc.h> <answer> #include 
static <token> __init ppa8548_pic_init(void) <answer> void 
struct mpic *mpic = mpic_alloc(NULL, <token> MPIC_BIG_ENDIAN, <answer> 0, 
0, 256, <token> OpenPIC "); <answer> " 
BUG_ON(mpic <token> NULL); <answer> == 
static void <token> ppa8548_setup_arch(void) <answer> __init 
if <token> <answer> (ppc_md.progress) 
<token> 0); <answer> ppc_md.progress("ppa8548_setup_arch()", 
static void ppa8548_show_cpuinfo(struct seq_file <token> <answer> *m) 
<token> svid, phid1; <answer> uint32_t 
svid = <token> <answer> mfspr(SPRN_SVR); 
seq_printf(m, "Vendor\t\t: Prodrive <token> <answer> B.V.\n"); 
seq_printf(m, <token> 0x%x\n", svid); <answer> "SVR\t\t: 
#include <token> <answer> <linux/delay.h> 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/gpio/consumer.h> 
#include <token> <answer> <linux/i2c.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> <linux/regulator/driver.h> 
#include <token> <answer> <linux/regulator/machine.h> 
#include <token> <answer> <linux/bitops.h> 
#include <token> <answer> <linux/dmapool.h> 
#include <token> <answer> <linux/dma/xilinx_dma.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/iopoll.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_dma.h> <answer> #include 
<token> <linux/of_irq.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/clk.h> <answer> #include 
#include <token> <answer> <linux/io-64-nonatomic-lo-hi.h> 
<token> "../dmaengine.h" <answer> #include 
<token> XILINX_DMA_DMASR_ERR_RECOVER_MASK \ <answer> #define 
(XILINX_DMA_DMASR_SOF_LATE_ERR <token> \ <answer> | 
<token> | \ <answer> XILINX_DMA_DMASR_EOF_EARLY_ERR 
XILINX_DMA_DMASR_SOF_EARLY_ERR | <token> <answer> \ 
struct xilinx_vdma_desc_hw <token> <answer> { 
u32 <token> <answer> next_desc; 
u32 <token> <answer> pad1; 
u32 <token> <answer> buf_addr; 
<token> buf_addr_msb; <answer> u32 
<token> vsize; <answer> u32 
u32 <token> <answer> hsize; 
<token> stride; <answer> u32 
<token> __aligned(64); <answer> } 
<token> xilinx_axidma_desc_hw { <answer> struct 
u32 <token> <answer> next_desc; 
u32 <token> <answer> next_desc_msb; 
<token> buf_addr; <answer> u32 
<token> buf_addr_msb; <answer> u32 
u32 <token> <answer> reserved1; 
<token> reserved2; <answer> u32 
u32 <token> <answer> control; 
u32 <token> <answer> status; 
<token> app[XILINX_DMA_NUM_APP_WORDS]; <answer> u32 
} <token> <answer> __aligned(64); 
struct <token> { <answer> xilinx_aximcdma_desc_hw 
u32 <token> <answer> next_desc; 
u32 <token> <answer> next_desc_msb; 
<token> buf_addr; <answer> u32 
u32 <token> <answer> buf_addr_msb; 
<token> rsvd; <answer> u32 
<token> control; <answer> u32 
<token> status; <answer> u32 
<token> sideband_status; <answer> u32 
<token> app[XILINX_DMA_NUM_APP_WORDS]; <answer> u32 
<token> __aligned(64); <answer> } 
struct <token> { <answer> xilinx_cdma_desc_hw 
<token> next_desc; <answer> u32 
<token> next_desc_msb; <answer> u32 
<token> src_addr; <answer> u32 
<token> src_addr_msb; <answer> u32 
u32 <token> <answer> dest_addr; 
<token> dest_addr_msb; <answer> u32 
u32 <token> <answer> control; 
<token> status; <answer> u32 
<token> __aligned(64); <answer> } 
struct <token> { <answer> xilinx_vdma_tx_segment 
<token> xilinx_vdma_desc_hw hw; <answer> struct 
struct list_head <token> <answer> node; 
<token> phys; <answer> dma_addr_t 
<token> __aligned(64); <answer> } 
struct <token> { <answer> xilinx_axidma_tx_segment 
struct xilinx_axidma_desc_hw <token> <answer> hw; 
struct list_head <token> <answer> node; 
<token> phys; <answer> dma_addr_t 
<token> __aligned(64); <answer> } 
struct <token> { <answer> xilinx_aximcdma_tx_segment 
struct <token> hw; <answer> xilinx_aximcdma_desc_hw 
<token> list_head node; <answer> struct 
<token> phys; <answer> dma_addr_t 
<token> __aligned(64); <answer> } 
<token> xilinx_cdma_tx_segment { <answer> struct 
struct xilinx_cdma_desc_hw <token> <answer> hw; 
struct <token> node; <answer> list_head 
<token> phys; <answer> dma_addr_t 
} <token> <answer> __aligned(64); 
<token> xilinx_dma_tx_descriptor { <answer> struct 
struct dma_async_tx_descriptor <token> <answer> async_tx; 
struct <token> segments; <answer> list_head 
<token> list_head node; <answer> struct 
bool <token> <answer> cyclic; 
<token> err; <answer> bool 
u32 <token> <answer> residue; 
struct <token> { <answer> xilinx_dma_chan 
struct <token> *xdev; <answer> xilinx_dma_device 
<token> ctrl_offset; <answer> u32 
<token> desc_offset; <answer> u32 
<token> lock; <answer> spinlock_t 
struct <token> pending_list; <answer> list_head 
struct list_head <token> <answer> active_list; 
struct list_head <token> <answer> done_list; 
struct <token> free_seg_list; <answer> list_head 
struct dma_chan <token> <answer> common; 
struct <token> *desc_pool; <answer> dma_pool 
struct device <token> <answer> *dev; 
<token> irq; <answer> int 
int <token> <answer> id; 
enum <token> direction; <answer> dma_transfer_direction 
int <token> <answer> num_frms; 
<token> has_sg; <answer> bool 
bool <token> <answer> cyclic; 
bool <token> <answer> genlock; 
bool <token> <answer> err; 
<token> idle; <answer> bool 
<token> terminating; <answer> bool 
struct tasklet_struct <token> <answer> tasklet; 
<token> xilinx_vdma_config config; <answer> struct 
bool <token> <answer> flush_on_fsync; 
<token> desc_pendingcount; <answer> u32 
bool <token> <answer> ext_addr; 
<token> desc_submitcount; <answer> u32 
<token> xilinx_axidma_tx_segment *seg_v; <answer> struct 
struct xilinx_aximcdma_tx_segment <token> <answer> *seg_mv; 
<token> seg_p; <answer> dma_addr_t 
<token> xilinx_axidma_tx_segment *cyclic_seg_v; <answer> struct 
<token> cyclic_seg_p; <answer> dma_addr_t 
<token> (*start_transfer)(struct xilinx_dma_chan *chan); <answer> void 
int (*stop_transfer)(struct <token> *chan); <answer> xilinx_dma_chan 
u16 <token> <answer> tdest; 
bool <token> <answer> has_vflip; 
u8 <token> <answer> irq_delay; 
enum <token> { <answer> xdma_ip_type 
<token> = 0, <answer> XDMA_TYPE_AXIDMA 
struct <token> { <answer> xilinx_dma_config 
enum xdma_ip_type <token> <answer> dmatype; 
int (*clk_init)(struct platform_device *pdev, <token> clk **axi_clk, <answer> struct 
struct clk **tx_clk, struct clk <token> <answer> **txs_clk, 
<token> clk **rx_clk, struct clk **rxs_clk); <answer> struct 
irqreturn_t (*irq_handler)(int irq, void <token> <answer> *data); 
const <token> max_channels; <answer> int 
struct <token> { <answer> xilinx_dma_device 
void __iomem <token> <answer> *regs; 
struct <token> *dev; <answer> device 
struct dma_device <token> <answer> common; 
struct <token> *chan[XILINX_MCDMA_MAX_CHANS_PER_DEVICE]; <answer> xilinx_dma_chan 
u32 <token> <answer> flush_on_fsync; 
<token> ext_addr; <answer> bool 
<token> platform_device *pdev; <answer> struct 
const struct xilinx_dma_config <token> <answer> *dma_config; 
struct <token> *axi_clk; <answer> clk 
struct clk <token> <answer> *tx_clk; 
struct clk <token> <answer> *txs_clk; 
<token> clk *rx_clk; <answer> struct 
<token> clk *rxs_clk; <answer> struct 
u32 <token> <answer> s2mm_chan_id; 
u32 <token> <answer> mm2s_chan_id; 
<token> max_buffer_len; <answer> u32 
<token> has_axistream_connected; <answer> bool 
<token> inline void vdma_desc_write_64(struct xilinx_dma_chan *chan, u32 reg, <answer> static 
<token> value_lsb, u32 value_msb) <answer> u32 
static void *xilinx_dma_get_metadata_ptr(struct dma_async_tx_descriptor <token> <answer> *tx, 
size_t *payload_len, size_t <token> <answer> *max_len) 
struct <token> *desc = to_dma_tx_descriptor(tx); <answer> xilinx_dma_tx_descriptor 
struct <token> *seg; <answer> xilinx_axidma_tx_segment 
*max_len = *payload_len <token> sizeof(u32) * XILINX_DMA_NUM_APP_WORDS; <answer> = 
seg <token> list_first_entry(&desc->segments, <answer> = 
struct xilinx_axidma_tx_segment, <token> <answer> node); 
<token> seg->hw.app; <answer> return 
static struct dma_descriptor_metadata_ops xilinx_dma_metadata_ops = <token> <answer> { 
.get_ptr = <token> <answer> xilinx_dma_get_metadata_ptr, 
<token> struct xilinx_vdma_tx_segment * <answer> static 
xilinx_vdma_alloc_tx_segment(struct xilinx_dma_chan <token> <answer> *chan) 
struct <token> *segment; <answer> xilinx_vdma_tx_segment 
<token> phys; <answer> dma_addr_t 
segment = dma_pool_zalloc(chan->desc_pool, GFP_ATOMIC, <token> <answer> &phys); 
if <token> <answer> (!segment) 
<token> NULL; <answer> return 
segment->phys = <token> <answer> phys; 
<token> segment; <answer> return 
static struct <token> * <answer> xilinx_cdma_tx_segment 
xilinx_cdma_alloc_tx_segment(struct xilinx_dma_chan <token> <answer> *chan) 
struct <token> *segment; <answer> xilinx_cdma_tx_segment 
<token> phys; <answer> dma_addr_t 
segment = dma_pool_zalloc(chan->desc_pool, <token> &phys); <answer> GFP_ATOMIC, 
if <token> <answer> (!segment) 
return <token> <answer> NULL; 
segment->phys <token> phys; <answer> = 
<token> segment; <answer> return 
static struct <token> * <answer> xilinx_axidma_tx_segment 
<token> xilinx_dma_chan *chan) <answer> xilinx_axidma_alloc_tx_segment(struct 
<token> xilinx_axidma_tx_segment *segment = NULL; <answer> struct 
unsigned long <token> <answer> flags; 
<token> flags); <answer> spin_lock_irqsave(&chan->lock, 
if <token> { <answer> (!list_empty(&chan->free_seg_list)) 
segment <token> list_first_entry(&chan->free_seg_list, <answer> = 
struct <token> <answer> xilinx_axidma_tx_segment, 
<token> flags); <answer> spin_unlock_irqrestore(&chan->lock, 
if <token> <answer> (!segment) 
dev_dbg(chan->dev, "Could not find free tx <token> <answer> segment\n"); 
return <token> <answer> segment; 
static struct xilinx_aximcdma_tx_segment <token> <answer> * 
xilinx_aximcdma_alloc_tx_segment(struct <token> *chan) <answer> xilinx_dma_chan 
struct <token> *segment = NULL; <answer> xilinx_aximcdma_tx_segment 
<token> long flags; <answer> unsigned 
spin_lock_irqsave(&chan->lock, <token> <answer> flags); 
if (!list_empty(&chan->free_seg_list)) <token> <answer> { 
<token> = list_first_entry(&chan->free_seg_list, <answer> segment 
<token> xilinx_aximcdma_tx_segment, <answer> struct 
<token> flags); <answer> spin_unlock_irqrestore(&chan->lock, 
<token> segment; <answer> return 
static <token> xilinx_dma_clean_hw_desc(struct xilinx_axidma_desc_hw *hw) <answer> void 
u32 next_desc = <token> <answer> hw->next_desc; 
u32 next_desc_msb <token> hw->next_desc_msb; <answer> = 
memset(hw, <token> sizeof(struct xilinx_axidma_desc_hw)); <answer> 0, 
<token> = next_desc; <answer> hw->next_desc 
hw->next_desc_msb <token> next_desc_msb; <answer> = 
static <token> xilinx_mcdma_clean_hw_desc(struct xilinx_aximcdma_desc_hw *hw) <answer> void 
u32 next_desc = <token> <answer> hw->next_desc; 
u32 next_desc_msb = <token> <answer> hw->next_desc_msb; 
memset(hw, 0, <token> xilinx_aximcdma_desc_hw)); <answer> sizeof(struct 
hw->next_desc <token> next_desc; <answer> = 
hw->next_desc_msb = <token> <answer> next_desc_msb; 
static <token> xilinx_dma_free_tx_segment(struct xilinx_dma_chan *chan, <answer> void 
struct <token> *segment) <answer> xilinx_axidma_tx_segment 
list_add_tail(&segment->node, <token> <answer> &chan->free_seg_list); 
static void xilinx_mcdma_free_tx_segment(struct xilinx_dma_chan <token> <answer> *chan, 
struct xilinx_aximcdma_tx_segment <token> <answer> * 
list_add_tail(&segment->node, <token> <answer> &chan->free_seg_list); 
static <token> xilinx_cdma_free_tx_segment(struct xilinx_dma_chan *chan, <answer> void 
struct xilinx_cdma_tx_segment <token> <answer> *segment) 
dma_pool_free(chan->desc_pool, <token> segment->phys); <answer> segment, 
static <token> xilinx_vdma_free_tx_segment(struct xilinx_dma_chan *chan, <answer> void 
struct <token> *segment) <answer> xilinx_vdma_tx_segment 
<token> segment, segment->phys); <answer> dma_pool_free(chan->desc_pool, 
<token> struct xilinx_dma_tx_descriptor * <answer> static 
<token> xilinx_dma_chan *chan) <answer> xilinx_dma_alloc_tx_descriptor(struct 
struct xilinx_dma_tx_descriptor <token> <answer> *desc; 
desc = <token> GFP_NOWAIT); <answer> kzalloc(sizeof(*desc), 
<token> (!desc) <answer> if 
return <token> <answer> NULL; 
return <token> <answer> desc; 
<token> void <answer> static 
xilinx_dma_free_tx_descriptor(struct <token> *chan, <answer> xilinx_dma_chan 
struct <token> *desc) <answer> xilinx_dma_tx_descriptor 
<token> xilinx_vdma_tx_segment *segment, *next; <answer> struct 
struct xilinx_cdma_tx_segment <token> *cdma_next; <answer> *cdma_segment, 
<token> xilinx_axidma_tx_segment *axidma_segment, *axidma_next; <answer> struct 
struct xilinx_aximcdma_tx_segment *aximcdma_segment, <token> <answer> *aximcdma_next; 
<token> (!desc) <answer> if 
if <token> == XDMA_TYPE_VDMA) { <answer> (chan->xdev->dma_config->dmatype 
list_for_each_entry_safe(segment, <token> &desc->segments, node) { <answer> next, 
xilinx_vdma_free_tx_segment(chan, <token> <answer> segment); 
} else <token> (chan->xdev->dma_config->dmatype == XDMA_TYPE_CDMA) { <answer> if 
list_for_each_entry_safe(cdma_segment, <token> <answer> cdma_next, 
&desc->segments, node) <token> <answer> { 
xilinx_cdma_free_tx_segment(chan, <token> <answer> cdma_segment); 
} <token> if (chan->xdev->dma_config->dmatype == XDMA_TYPE_AXIDMA) { <answer> else 
list_for_each_entry_safe(axidma_segment, <token> <answer> axidma_next, 
&desc->segments, <token> { <answer> node) 
<token> axidma_segment); <answer> xilinx_dma_free_tx_segment(chan, 
} <token> { <answer> else 
<token> aximcdma_next, <answer> list_for_each_entry_safe(aximcdma_segment, 
&desc->segments, <token> { <answer> node) 
<token> aximcdma_segment); <answer> xilinx_mcdma_free_tx_segment(chan, 
static void <token> xilinx_dma_chan *chan, <answer> xilinx_dma_free_desc_list(struct 
<token> list_head *list) <answer> struct 
struct xilinx_dma_tx_descriptor <token> *next; <answer> *desc, 
list_for_each_entry_safe(desc, next, list, <token> { <answer> node) 
<token> desc); <answer> xilinx_dma_free_tx_descriptor(chan, 
static <token> xilinx_dma_free_descriptors(struct xilinx_dma_chan *chan) <answer> void 
<token> long flags; <answer> unsigned 
<token> flags); <answer> spin_lock_irqsave(&chan->lock, 
xilinx_dma_free_desc_list(chan, <token> <answer> &chan->pending_list); 
<token> &chan->done_list); <answer> xilinx_dma_free_desc_list(chan, 
<token> &chan->active_list); <answer> xilinx_dma_free_desc_list(chan, 
<token> flags); <answer> spin_unlock_irqrestore(&chan->lock, 
static void xilinx_dma_free_chan_resources(struct <token> *dchan) <answer> dma_chan 
struct xilinx_dma_chan *chan <token> to_xilinx_chan(dchan); <answer> = 
unsigned <token> flags; <answer> long 
dev_dbg(chan->dev, <token> all channel resources.\n"); <answer> "Free 
if (chan->xdev->dma_config->dmatype == <token> { <answer> XDMA_TYPE_AXIDMA) 
<token> flags); <answer> spin_lock_irqsave(&chan->lock, 
spin_unlock_irqrestore(&chan->lock, <token> <answer> flags); 
static <token> xilinx_dma_get_residue(struct xilinx_dma_chan *chan, <answer> u32 
struct xilinx_dma_tx_descriptor <token> <answer> *desc) 
struct xilinx_cdma_tx_segment <token> <answer> *cdma_seg; 
struct <token> *axidma_seg; <answer> xilinx_axidma_tx_segment 
struct <token> *aximcdma_seg; <answer> xilinx_aximcdma_tx_segment 
struct xilinx_cdma_desc_hw <token> <answer> *cdma_hw; 
struct xilinx_axidma_desc_hw <token> <answer> *axidma_hw; 
struct xilinx_aximcdma_desc_hw <token> <answer> *aximcdma_hw; 
struct list_head <token> <answer> *entry; 
u32 residue = <token> <answer> 0; 
<token> &desc->segments) { <answer> list_for_each(entry, 
if (chan->xdev->dma_config->dmatype == <token> { <answer> XDMA_TYPE_CDMA) 
cdma_seg = <token> <answer> list_entry(entry, 
<token> xilinx_cdma_tx_segment, <answer> struct 
<token> = &cdma_seg->hw; <answer> cdma_hw 
residue += (cdma_hw->control <token> cdma_hw->status) & <answer> - 
} else if <token> == <answer> (chan->xdev->dma_config->dmatype 
<token> { <answer> XDMA_TYPE_AXIDMA) 
axidma_seg <token> list_entry(entry, <answer> = 
struct <token> <answer> xilinx_axidma_tx_segment, 
<token> = &axidma_seg->hw; <answer> axidma_hw 
residue += <token> - axidma_hw->status) & <answer> (axidma_hw->control 
} else <token> <answer> { 
aximcdma_seg <token> <answer> = 
struct <token> <answer> xilinx_aximcdma_tx_segment, 
aximcdma_hw <token> &aximcdma_seg->hw; <answer> = 
residue <token> <answer> += 
<token> - aximcdma_hw->status) & <answer> (aximcdma_hw->control 
<token> residue; <answer> return 
<token> void xilinx_dma_chan_handle_cyclic(struct xilinx_dma_chan *chan, <answer> static 
<token> xilinx_dma_tx_descriptor *desc, <answer> struct 
<token> long *flags) <answer> unsigned 
struct <token> cb; <answer> dmaengine_desc_callback 
<token> &cb); <answer> dmaengine_desc_get_callback(&desc->async_tx, 
if <token> { <answer> (dmaengine_desc_callback_valid(&cb)) 
<token> *flags); <answer> spin_unlock_irqrestore(&chan->lock, 
<token> NULL); <answer> dmaengine_desc_callback_invoke(&cb, 
<token> *flags); <answer> spin_lock_irqsave(&chan->lock, 
static <token> xilinx_dma_chan_desc_cleanup(struct xilinx_dma_chan *chan) <answer> void 
struct <token> *desc, *next; <answer> xilinx_dma_tx_descriptor 
unsigned long <token> <answer> flags; 
spin_lock_irqsave(&chan->lock, <token> <answer> flags); 
list_for_each_entry_safe(desc, next, &chan->done_list, node) <token> <answer> { 
struct <token> result; <answer> dmaengine_result 
if <token> { <answer> (desc->cyclic) 
<token> desc, &flags); <answer> xilinx_dma_chan_handle_cyclic(chan, 
if <token> <answer> (chan->terminating) 
spin_unlock_irqrestore(&chan->lock, <token> <answer> flags); 
static void xilinx_dma_do_tasklet(struct tasklet_struct <token> <answer> *t) 
struct xilinx_dma_chan <token> = from_tasklet(chan, t, tasklet); <answer> *chan 
static int <token> dma_chan *dchan) <answer> xilinx_dma_alloc_chan_resources(struct 
struct xilinx_dma_chan *chan <token> to_xilinx_chan(dchan); <answer> = 
<token> i; <answer> int 
<token> (chan->xdev->dma_config->dmatype == XDMA_TYPE_AXIDMA) { <answer> if 
chan->cyclic_seg_v = <token> <answer> dma_alloc_coherent(chan->dev, 
<token> (!chan->cyclic_seg_v) { <answer> if 
"unable to allocate desc segment <token> cyclic DMA\n"); <answer> for 
dma_free_coherent(chan->dev, <token> * <answer> sizeof(*chan->seg_v) 
<token> chan->seg_v, <answer> XILINX_DMA_NUM_DESCS, 
return <token> <answer> -ENOMEM; 
chan->cyclic_seg_v->phys = <token> <answer> chan->cyclic_seg_p; 
<token> (i = 0; i < XILINX_DMA_NUM_DESCS; i++) { <answer> for 
chan->seg_v[i].hw.next_desc <token> <answer> = 
lower_32_bits(chan->seg_p + sizeof(*chan->seg_v) <token> <answer> * 
((i + <token> % XILINX_DMA_NUM_DESCS)); <answer> 1) 
<token> = <answer> chan->seg_v[i].hw.next_desc_msb 
upper_32_bits(chan->seg_p + sizeof(*chan->seg_v) <token> <answer> * 
((i + <token> % XILINX_DMA_NUM_DESCS)); <answer> 1) 
chan->seg_v[i].phys = <token> + <answer> chan->seg_p 
sizeof(*chan->seg_v) * <token> <answer> i; 
} else if <token> == XDMA_TYPE_AXIMCDMA) { <answer> (chan->xdev->dma_config->dmatype 
<token> XILINX_DMA_REG_DMACR, <answer> dma_ctrl_set(chan, 
if ((chan->xdev->dma_config->dmatype == <token> && chan->has_sg) <answer> XDMA_TYPE_CDMA) 
<token> XILINX_DMA_REG_DMACR, <answer> dma_ctrl_set(chan, 
<token> 0; <answer> return 
static <token> xilinx_dma_calc_copysize(struct xilinx_dma_chan *chan, <answer> int 
int <token> int done) <answer> size, 
size_t <token> <answer> copy; 
copy = min_t(size_t, <token> - done, <answer> size 
<token> ((copy + done < size) && <answer> if 
<token> { <answer> chan->xdev->common.copy_align) 
copy = <token> <answer> rounddown(copy, 
<token> << chan->xdev->common.copy_align)); <answer> (1 
<token> copy; <answer> return 
static enum <token> xilinx_dma_tx_status(struct dma_chan *dchan, <answer> dma_status 
<token> cookie, <answer> dma_cookie_t 
<token> dma_tx_state *txstate) <answer> struct 
struct xilinx_dma_chan <token> = to_xilinx_chan(dchan); <answer> *chan 
struct xilinx_dma_tx_descriptor <token> <answer> *desc; 
enum <token> ret; <answer> dma_status 
unsigned long <token> <answer> flags; 
<token> residue = 0; <answer> u32 
ret = <token> cookie, txstate); <answer> dma_cookie_status(dchan, 
if (ret == <token> || !txstate) <answer> DMA_COMPLETE 
return <token> <answer> ret; 
spin_lock_irqsave(&chan->lock, <token> <answer> flags); 
if (!list_empty(&chan->active_list)) <token> <answer> { 
desc = <token> <answer> list_last_entry(&chan->active_list, 
<token> xilinx_dma_tx_descriptor, node); <answer> struct 
if (chan->has_sg && chan->xdev->dma_config->dmatype != <token> <answer> XDMA_TYPE_VDMA) 
residue = xilinx_dma_get_residue(chan, <token> <answer> desc); 
spin_unlock_irqrestore(&chan->lock, <token> <answer> flags); 
dma_set_residue(txstate, <token> <answer> residue); 
return <token> <answer> ret; 
static int xilinx_dma_stop_transfer(struct <token> *chan) <answer> xilinx_dma_chan 
u32 <token> <answer> val; 
<token> XILINX_DMA_REG_DMACR, XILINX_DMA_DMACR_RUNSTOP); <answer> dma_ctrl_clr(chan, 
<token> int xilinx_cdma_stop_transfer(struct xilinx_dma_chan *chan) <answer> static 
<token> val; <answer> u32 
return xilinx_dma_poll_timeout(chan, XILINX_DMA_REG_DMASR, <token> <answer> val, 
<token> & XILINX_DMA_DMASR_IDLE, 0, <answer> val 
<token> void xilinx_dma_start(struct xilinx_dma_chan *chan) <answer> static 
<token> err; <answer> int 
<token> val; <answer> u32 
dma_ctrl_set(chan, <token> XILINX_DMA_DMACR_RUNSTOP); <answer> XILINX_DMA_REG_DMACR, 
static void xilinx_vdma_start_transfer(struct <token> *chan) <answer> xilinx_dma_chan 
struct xilinx_vdma_config <token> = &chan->config; <answer> *config 
struct <token> *desc; <answer> xilinx_dma_tx_descriptor 
u32 <token> j; <answer> reg, 
<token> xilinx_vdma_tx_segment *segment, *last = NULL; <answer> struct 
int i <token> 0; <answer> = 
static void xilinx_cdma_start_transfer(struct xilinx_dma_chan <token> <answer> *chan) 
struct xilinx_dma_tx_descriptor *head_desc, <token> <answer> *tail_desc; 
<token> xilinx_cdma_tx_segment *tail_segment; <answer> struct 
u32 <token> = dma_read(chan, XILINX_DMA_REG_DMACR); <answer> ctrl_reg 
<token> (chan->err) <answer> if 
<token> (!chan->idle) <answer> if 
if <token> <answer> (list_empty(&chan->pending_list)) 
head_desc = <token> <answer> list_first_entry(&chan->pending_list, 
struct xilinx_dma_tx_descriptor, <token> <answer> node); 
tail_desc <token> list_last_entry(&chan->pending_list, <answer> = 
struct <token> node); <answer> xilinx_dma_tx_descriptor, 
tail_segment = <token> <answer> list_last_entry(&tail_desc->segments, 
struct xilinx_cdma_tx_segment, <token> <answer> node); 
if (chan->desc_pendingcount <= <token> { <answer> XILINX_DMA_COALESCE_MAX) 
<token> &= ~XILINX_DMA_CR_COALESCE_MAX; <answer> ctrl_reg 
<token> |= chan->desc_pendingcount << <answer> ctrl_reg 
<token> XILINX_DMA_REG_DMACR, ctrl_reg); <answer> dma_ctrl_write(chan, 
<token> (chan->has_sg) { <answer> if 
dma_ctrl_clr(chan, <token> <answer> XILINX_DMA_REG_DMACR, 
<token> XILINX_DMA_REG_DMACR, <answer> dma_ctrl_set(chan, 
<token> XILINX_DMA_REG_CURDESC, <answer> xilinx_write(chan, 
static void xilinx_dma_start_transfer(struct xilinx_dma_chan <token> <answer> *chan) 
struct xilinx_dma_tx_descriptor <token> *tail_desc; <answer> *head_desc, 
struct xilinx_axidma_tx_segment <token> <answer> *tail_segment; 
u32 <token> <answer> reg; 
if <token> <answer> (chan->err) 
<token> (list_empty(&chan->pending_list)) <answer> if 
if <token> <answer> (!chan->idle) 
head_desc = <token> <answer> list_first_entry(&chan->pending_list, 
struct <token> node); <answer> xilinx_dma_tx_descriptor, 
<token> = list_last_entry(&chan->pending_list, <answer> tail_desc 
struct <token> node); <answer> xilinx_dma_tx_descriptor, 
tail_segment <token> list_last_entry(&tail_desc->segments, <answer> = 
<token> xilinx_axidma_tx_segment, node); <answer> struct 
reg = <token> XILINX_DMA_REG_DMACR); <answer> dma_ctrl_read(chan, 
if (chan->desc_pendingcount <= XILINX_DMA_COALESCE_MAX) <token> <answer> { 
<token> &= ~XILINX_DMA_CR_COALESCE_MAX; <answer> reg 
reg |= chan->desc_pendingcount <token> <answer> << 
dma_ctrl_write(chan, XILINX_DMA_REG_DMACR, <token> <answer> reg); 
if <token> <answer> (chan->has_sg) 
<token> XILINX_DMA_REG_CURDESC, <answer> xilinx_write(chan, 
reg <token> ~XILINX_DMA_CR_DELAY_MAX; <answer> &= 
reg <token> chan->irq_delay << XILINX_DMA_CR_DELAY_SHIFT; <answer> |= 
dma_ctrl_write(chan, <token> reg); <answer> XILINX_DMA_REG_DMACR, 
<token> (chan->err) <answer> if 
static void xilinx_mcdma_start_transfer(struct <token> *chan) <answer> xilinx_dma_chan 
struct xilinx_dma_tx_descriptor *head_desc, <token> <answer> *tail_desc; 
struct <token> *tail_segment; <answer> xilinx_aximcdma_tx_segment 
<token> reg; <answer> u32 
if <token> <answer> (chan->err) 
<token> (!chan->idle) <answer> if 
if <token> <answer> (list_empty(&chan->pending_list)) 
head_desc <token> list_first_entry(&chan->pending_list, <answer> = 
struct <token> node); <answer> xilinx_dma_tx_descriptor, 
tail_desc = <token> <answer> list_last_entry(&chan->pending_list, 
<token> xilinx_dma_tx_descriptor, node); <answer> struct 
tail_segment = <token> <answer> list_last_entry(&tail_desc->segments, 
struct <token> node); <answer> xilinx_aximcdma_tx_segment, 
reg = dma_ctrl_read(chan, <token> <answer> XILINX_MCDMA_CHAN_CR_OFFSET(chan->tdest)); 
if <token> <= XILINX_MCDMA_COALESCE_MAX) { <answer> (chan->desc_pendingcount 
<token> &= ~XILINX_MCDMA_COALESCE_MASK; <answer> reg 
<token> |= chan->desc_pendingcount << <answer> reg 
<token> |= XILINX_MCDMA_IRQ_ALL_MASK; <answer> reg 
<token> XILINX_MCDMA_CHAN_CR_OFFSET(chan->tdest), reg); <answer> dma_ctrl_write(chan, 
<token> void xilinx_dma_issue_pending(struct dma_chan *dchan) <answer> static 
struct xilinx_dma_chan *chan <token> to_xilinx_chan(dchan); <answer> = 
unsigned <token> flags; <answer> long 
spin_lock_irqsave(&chan->lock, <token> <answer> flags); 
<token> flags); <answer> spin_unlock_irqrestore(&chan->lock, 
static <token> xilinx_dma_device_config(struct dma_chan *dchan, <answer> int 
struct dma_slave_config <token> <answer> *config) 
return <token> <answer> 0; 
<token> void xilinx_dma_complete_descriptor(struct xilinx_dma_chan *chan) <answer> static 
struct <token> *desc, *next; <answer> xilinx_dma_tx_descriptor 
static int <token> xilinx_dma_chan *chan) <answer> xilinx_dma_reset(struct 
int <token> <answer> err; 
u32 <token> <answer> tmp; 
dma_ctrl_set(chan, <token> XILINX_DMA_DMACR_RESET); <answer> XILINX_DMA_REG_DMACR, 
static int xilinx_dma_chan_reset(struct xilinx_dma_chan <token> <answer> *chan) 
<token> err; <answer> int 
static irqreturn_t xilinx_mcdma_irq_handler(int irq, <token> *data) <answer> void 
<token> xilinx_dma_chan *chan = data; <answer> struct 
u32 status, ser_offset, chan_sermask, <token> = 0, chan_id; <answer> chan_offset 
if (chan->direction <token> DMA_DEV_TO_MEM) <answer> == 
ser_offset <token> XILINX_MCDMA_RXINT_SER_OFFSET; <answer> = 
ser_offset <token> XILINX_MCDMA_TXINT_SER_OFFSET; <answer> = 
dev_dbg(chan->dev, "Inter-packet latency too <token> <answer> long\n"); 
<token> (status & XILINX_MCDMA_IRQ_IOC_MASK) { <answer> if 
<token> = true; <answer> chan->idle 
<token> IRQ_HANDLED; <answer> return 
static irqreturn_t <token> irq, void *data) <answer> xilinx_dma_irq_handler(int 
struct xilinx_dma_chan <token> = data; <answer> *chan 
u32 <token> <answer> status; 
u32 errors = status <token> XILINX_DMA_DMASR_ALL_ERR_MASK; <answer> & 
dma_ctrl_write(chan, <token> <answer> XILINX_DMA_REG_DMASR, 
errors <token> XILINX_DMA_DMASR_ERR_RECOVER_MASK); <answer> & 
<token> (!chan->flush_on_fsync || <answer> if 
(errors & ~XILINX_DMA_DMASR_ERR_RECOVER_MASK)) <token> <answer> { 
"Channel %p has errors %x, cdr <token> tdr %x\n", <answer> %x 
<token> errors, <answer> chan, 
<token> XILINX_DMA_REG_CURDESC), <answer> dma_ctrl_read(chan, 
dma_ctrl_read(chan, <token> <answer> XILINX_DMA_REG_TAILDESC)); 
chan->err <token> true; <answer> = 
if <token> & (XILINX_DMA_DMASR_FRM_CNT_IRQ | <answer> (status 
<token> { <answer> XILINX_DMA_DMASR_DLY_CNT_IRQ)) 
<token> = true; <answer> chan->idle 
return <token> <answer> IRQ_HANDLED; 
static void append_desc_queue(struct xilinx_dma_chan <token> <answer> *chan, 
struct xilinx_dma_tx_descriptor <token> <answer> *desc) 
struct xilinx_vdma_tx_segment <token> <answer> *tail_segment; 
<token> xilinx_dma_tx_descriptor *tail_desc; <answer> struct 
struct xilinx_axidma_tx_segment <token> <answer> *axidma_tail_segment; 
struct xilinx_aximcdma_tx_segment <token> <answer> *aximcdma_tail_segment; 
struct xilinx_cdma_tx_segment <token> <answer> *cdma_tail_segment; 
if <token> <answer> (list_empty(&chan->pending_list)) 
goto <token> <answer> append; 
<token> = list_last_entry(&chan->pending_list, <answer> tail_desc 
struct <token> node); <answer> xilinx_dma_tx_descriptor, 
if (chan->xdev->dma_config->dmatype == <token> { <answer> XDMA_TYPE_VDMA) 
tail_segment = <token> <answer> list_last_entry(&tail_desc->segments, 
struct <token> <answer> xilinx_vdma_tx_segment, 
tail_segment->hw.next_desc = <token> <answer> (u32)desc->async_tx.phys; 
} else if <token> == XDMA_TYPE_CDMA) { <answer> (chan->xdev->dma_config->dmatype 
cdma_tail_segment = <token> <answer> list_last_entry(&tail_desc->segments, 
struct <token> <answer> xilinx_cdma_tx_segment, 
<token> = (u32)desc->async_tx.phys; <answer> cdma_tail_segment->hw.next_desc 
} else if (chan->xdev->dma_config->dmatype <token> XDMA_TYPE_AXIDMA) { <answer> == 
<token> = list_last_entry(&tail_desc->segments, <answer> axidma_tail_segment 
struct <token> <answer> xilinx_axidma_tx_segment, 
axidma_tail_segment->hw.next_desc <token> (u32)desc->async_tx.phys; <answer> = 
<token> else { <answer> } 
<token> = <answer> aximcdma_tail_segment 
<token> xilinx_aximcdma_tx_segment, <answer> struct 
aximcdma_tail_segment->hw.next_desc = <token> <answer> (u32)desc->async_tx.phys; 
<token> &chan->pending_list); <answer> list_add_tail(&desc->node, 
if (chan->has_sg && (chan->xdev->dma_config->dmatype <token> XDMA_TYPE_VDMA) <answer> == 
<token> unlikely(chan->desc_pendingcount > chan->num_frms)) { <answer> && 
dev_dbg(chan->dev, "desc pendingcount <token> too high\n"); <answer> is 
<token> = chan->num_frms; <answer> chan->desc_pendingcount 
<token> dma_cookie_t xilinx_dma_tx_submit(struct dma_async_tx_descriptor *tx) <answer> static 
struct xilinx_dma_tx_descriptor *desc <token> to_dma_tx_descriptor(tx); <answer> = 
struct xilinx_dma_chan <token> = to_xilinx_chan(tx->chan); <answer> *chan 
<token> cookie; <answer> dma_cookie_t 
<token> long flags; <answer> unsigned 
int <token> <answer> err; 
if (chan->cyclic) <token> <answer> { 
xilinx_dma_free_tx_descriptor(chan, <token> <answer> desc); 
<token> -EBUSY; <answer> return 
if (chan->err) <token> <answer> { 
err <token> xilinx_dma_chan_reset(chan); <answer> = 
if (err < <token> <answer> 0) 
return <token> <answer> err; 
spin_lock_irqsave(&chan->lock, <token> <answer> flags); 
<token> = dma_cookie_assign(tx); <answer> cookie 
static struct <token> * <answer> dma_async_tx_descriptor 
xilinx_vdma_dma_prep_interleaved(struct dma_chan <token> <answer> *dchan, 
<token> dma_interleaved_template *xt, <answer> struct 
unsigned <token> flags) <answer> long 
struct xilinx_dma_chan *chan <token> to_xilinx_chan(dchan); <answer> = 
<token> xilinx_dma_tx_descriptor *desc; <answer> struct 
struct <token> *segment; <answer> xilinx_vdma_tx_segment 
struct <token> *hw; <answer> xilinx_vdma_desc_hw 
if <token> <answer> (!is_slave_direction(xt->dir)) 
return <token> <answer> NULL; 
if (!xt->numf || <token> <answer> !xt->sgl[0].size) 
return <token> <answer> NULL; 
if <token> & ~XILINX_DMA_VSIZE_MASK || <answer> (xt->numf 
xt->sgl[0].size & <token> <answer> ~XILINX_DMA_HSIZE_MASK) 
<token> NULL; <answer> return 
if (xt->frame_size != <token> <answer> 1) 
return <token> <answer> NULL; 
static struct <token> * <answer> dma_async_tx_descriptor 
xilinx_cdma_prep_memcpy(struct <token> *dchan, dma_addr_t dma_dst, <answer> dma_chan 
dma_addr_t <token> size_t len, unsigned long flags) <answer> dma_src, 
struct xilinx_dma_chan <token> = to_xilinx_chan(dchan); <answer> *chan 
struct <token> *desc; <answer> xilinx_dma_tx_descriptor 
<token> xilinx_cdma_tx_segment *segment; <answer> struct 
struct <token> *hw; <answer> xilinx_cdma_desc_hw 
if <token> || len > chan->xdev->max_buffer_len) <answer> (!len 
<token> NULL; <answer> return 
desc <token> xilinx_dma_alloc_tx_descriptor(chan); <answer> = 
<token> (!desc) <answer> if 
<token> NULL; <answer> return 
dma_async_tx_descriptor_init(&desc->async_tx, <token> <answer> &chan->common); 
desc->async_tx.tx_submit <token> xilinx_dma_tx_submit; <answer> = 
static struct <token> *xilinx_dma_prep_slave_sg( <answer> dma_async_tx_descriptor 
struct dma_chan <token> struct scatterlist *sgl, unsigned int sg_len, <answer> *dchan, 
enum dma_transfer_direction direction, unsigned <token> flags, <answer> long 
<token> *context) <answer> void 
struct xilinx_dma_chan <token> = to_xilinx_chan(dchan); <answer> *chan 
struct <token> *desc; <answer> xilinx_dma_tx_descriptor 
struct xilinx_axidma_tx_segment <token> = NULL; <answer> *segment 
u32 *app_w <token> (u32 *)context; <answer> = 
struct scatterlist <token> <answer> *sg; 
<token> copy; <answer> size_t 
size_t <token> <answer> sg_used; 
unsigned int <token> <answer> i; 
<token> (!is_slave_direction(direction)) <answer> if 
<token> NULL; <answer> return 
copy = <token> sg_dma_len(sg), <answer> xilinx_dma_calc_copysize(chan, 
hw <token> &segment->hw; <answer> = 
list_add_tail(&segment->node, <token> <answer> &desc->segments); 
segment = <token> <answer> list_first_entry(&desc->segments, 
<token> xilinx_axidma_tx_segment, node); <answer> struct 
<token> = segment->phys; <answer> desc->async_tx.phys 
static struct dma_async_tx_descriptor <token> <answer> *xilinx_dma_prep_dma_cyclic( 
struct dma_chan *dchan, dma_addr_t buf_addr, size_t <token> <answer> buf_len, 
size_t period_len, enum <token> direction, <answer> dma_transfer_direction 
unsigned <token> flags) <answer> long 
<token> xilinx_dma_chan *chan = to_xilinx_chan(dchan); <answer> struct 
<token> xilinx_dma_tx_descriptor *desc; <answer> struct 
struct xilinx_axidma_tx_segment *segment, *head_segment, *prev <token> NULL; <answer> = 
size_t copy, <token> <answer> sg_used; 
<token> int num_periods; <answer> unsigned 
<token> i; <answer> int 
<token> reg; <answer> u32 
if <token> <answer> (!period_len) 
return <token> <answer> NULL; 
num_periods = <token> / period_len; <answer> buf_len 
<token> (!num_periods) <answer> if 
return <token> <answer> NULL; 
<token> (!is_slave_direction(direction)) <answer> if 
<token> NULL; <answer> return 
copy = xilinx_dma_calc_copysize(chan, <token> <answer> period_len, 
hw = <token> <answer> &segment->hw; 
xilinx_axidma_buf(chan, hw, <token> sg_used, <answer> buf_addr, 
<token> * i); <answer> period_len 
hw->control = <token> <answer> copy; 
<token> (prev) <answer> if 
prev->hw.next_desc <token> segment->phys; <answer> = 
prev <token> segment; <answer> = 
<token> += copy; <answer> sg_used 
list_add_tail(&segment->node, <token> <answer> &desc->segments); 
<token> = list_first_entry(&desc->segments, <answer> head_segment 
struct <token> node); <answer> xilinx_axidma_tx_segment, 
<token> = head_segment->phys; <answer> desc->async_tx.phys 
<token> = true; <answer> desc->cyclic 
reg = <token> XILINX_DMA_REG_DMACR); <answer> dma_ctrl_read(chan, 
reg <token> XILINX_DMA_CR_CYCLIC_BD_EN_MASK; <answer> |= 
dma_ctrl_write(chan, <token> reg); <answer> XILINX_DMA_REG_DMACR, 
segment <token> list_last_entry(&desc->segments, <answer> = 
struct <token> <answer> xilinx_axidma_tx_segment, 
segment->hw.next_desc <token> (u32) head_segment->phys; <answer> = 
static struct dma_async_tx_descriptor <token> <answer> * 
xilinx_mcdma_prep_slave_sg(struct dma_chan *dchan, struct <token> *sgl, <answer> scatterlist 
unsigned int <token> <answer> sg_len, 
enum <token> direction, <answer> dma_transfer_direction 
unsigned <token> flags, void *context) <answer> long 
<token> xilinx_dma_chan *chan = to_xilinx_chan(dchan); <answer> struct 
struct <token> *desc; <answer> xilinx_dma_tx_descriptor 
struct xilinx_aximcdma_tx_segment *segment = <token> <answer> NULL; 
u32 *app_w <token> (u32 *)context; <answer> = 
struct <token> *sg; <answer> scatterlist 
<token> copy; <answer> size_t 
size_t <token> <answer> sg_used; 
<token> int i; <answer> unsigned 
<token> (!is_slave_direction(direction)) <answer> if 
<token> NULL; <answer> return 
copy <token> min_t(size_t, sg_dma_len(sg) - sg_used, <answer> = 
<token> = &segment->hw; <answer> hw 
<token> &desc->segments); <answer> list_add_tail(&segment->node, 
segment <token> list_first_entry(&desc->segments, <answer> = 
<token> xilinx_aximcdma_tx_segment, node); <answer> struct 
desc->async_tx.phys <token> segment->phys; <answer> = 
static int xilinx_dma_terminate_all(struct <token> *dchan) <answer> dma_chan 
struct xilinx_dma_chan <token> = to_xilinx_chan(dchan); <answer> *chan 
u32 <token> <answer> reg; 
int <token> <answer> err; 
if <token> { <answer> (!chan->cyclic) 
err <token> chan->stop_transfer(chan); <answer> = 
<token> (err) { <answer> if 
dev_err(chan->dev, "Cannot stop channel <token> %x\n", <answer> %p: 
<token> dma_ctrl_read(chan, <answer> chan, 
chan->err = <token> <answer> true; 
int xilinx_vdma_channel_set_config(struct <token> *dchan, <answer> dma_chan 
struct xilinx_vdma_config <token> <answer> *cfg) 
struct xilinx_dma_chan *chan <token> to_xilinx_chan(dchan); <answer> = 
<token> dmacr; <answer> u32 
if <token> <answer> (cfg->reset) 
return <token> <answer> xilinx_dma_chan_reset(chan); 
dmacr = <token> XILINX_DMA_REG_DMACR); <answer> dma_ctrl_read(chan, 
chan->config.frm_dly = <token> <answer> cfg->frm_dly; 
chan->config.park <token> cfg->park; <answer> = 
static void <token> xilinx_dma_chan *chan) <answer> xilinx_dma_chan_remove(struct 
static int <token> xilinx_dma_device *xdev, <answer> xilinx_dma_chan_probe(struct 
struct <token> *node) <answer> device_node 
struct <token> *chan; <answer> xilinx_dma_chan 
bool has_dre = <token> <answer> false; 
<token> value, width; <answer> u32 
int <token> <answer> err; 
chan->idle <token> true; <answer> = 
chan->common.device <token> &xdev->common; <answer> = 
<token> &xdev->common.channels); <answer> list_add_tail(&chan->common.device_node, 
xdev->chan[chan->id] <token> chan; <answer> = 
<token> int xilinx_dma_child_probe(struct xilinx_dma_device *xdev, <answer> static 
struct <token> *node) <answer> device_node 
<token> ret, i; <answer> int 
<token> nr_channels = 1; <answer> u32 
ret = of_property_read_u32(node, <token> &nr_channels); <answer> "dma-channels", 
if (xdev->dma_config->dmatype == XDMA_TYPE_AXIMCDMA && <token> < 0) <answer> ret 
dev_warn(xdev->dev, <token> dma-channels property\n"); <answer> "missing 
for (i = 0; i < nr_channels; <token> { <answer> i++) 
<token> = xilinx_dma_chan_probe(xdev, node); <answer> ret 
<token> (ret) <answer> if 
return <token> <answer> ret; 
<token> 0; <answer> return 
static struct dma_chan *of_dma_xilinx_xlate(struct <token> *dma_spec, <answer> of_phandle_args 
struct of_dma <token> <answer> *ofdma) 
struct <token> *xdev = ofdma->of_dma_data; <answer> xilinx_dma_device 
int <token> = dma_spec->args[0]; <answer> chan_id 
if (chan_id >= <token> || !xdev->chan[chan_id]) <answer> xdev->dma_config->max_channels 
<token> NULL; <answer> return 
<token> dma_get_slave_channel(&xdev->chan[chan_id]->common); <answer> return 
static const struct xilinx_dma_config axidma_config <token> { <answer> = 
.dmatype <token> XDMA_TYPE_AXIDMA, <answer> = 
.clk_init <token> axidma_clk_init, <answer> = 
.irq_handler = <token> <answer> xilinx_dma_irq_handler, 
<token> = XILINX_DMA_MAX_CHANS_PER_DEVICE, <answer> .max_channels 
static const struct xilinx_dma_config aximcdma_config = <token> <answer> { 
<token> = XDMA_TYPE_AXIMCDMA, <answer> .dmatype 
.clk_init = <token> <answer> axidma_clk_init, 
<token> = xilinx_mcdma_irq_handler, <answer> .irq_handler 
.max_channels <token> XILINX_MCDMA_MAX_CHANS_PER_DEVICE, <answer> = 
static const struct xilinx_dma_config axicdma_config <token> { <answer> = 
<token> = XDMA_TYPE_CDMA, <answer> .dmatype 
.clk_init <token> axicdma_clk_init, <answer> = 
.irq_handler = <token> <answer> xilinx_dma_irq_handler, 
.max_channels <token> XILINX_CDMA_MAX_CHANS_PER_DEVICE, <answer> = 
static const struct xilinx_dma_config axivdma_config <token> { <answer> = 
<token> = XDMA_TYPE_VDMA, <answer> .dmatype 
<token> = axivdma_clk_init, <answer> .clk_init 
<token> = xilinx_dma_irq_handler, <answer> .irq_handler 
.max_channels <token> XILINX_DMA_MAX_CHANS_PER_DEVICE, <answer> = 
static const <token> of_device_id xilinx_dma_of_ids[] = { <answer> struct 
{ .compatible = "xlnx,axi-dma-1.00.a", <token> = &axidma_config }, <answer> .data 
{ .compatible <token> "xlnx,axi-cdma-1.00.a", .data = &axicdma_config }, <answer> = 
<token> .compatible = "xlnx,axi-vdma-1.00.a", .data = &axivdma_config }, <answer> { 
{ <token> = "xlnx,axi-mcdma-1.00.a", .data = &aximcdma_config }, <answer> .compatible 
<token> xilinx_dma_of_ids); <answer> MODULE_DEVICE_TABLE(of, 
static int xilinx_dma_probe(struct platform_device <token> <answer> *pdev) 
int (*clk_init)(struct platform_device *, struct clk <token> struct clk **, <answer> **, 
struct clk **, struct clk <token> struct clk **) <answer> **, 
= <token> <answer> axivdma_clk_init; 
struct device_node <token> = pdev->dev.of_node; <answer> *node 
struct xilinx_dma_device <token> <answer> *xdev; 
struct device_node *child, <token> = pdev->dev.of_node; <answer> *np 
u32 num_frames, <token> len_width; <answer> addr_width, 
<token> i, err; <answer> int 
<token> void xilinx_dma_remove(struct platform_device *pdev) <answer> static 
struct <token> *xdev = platform_get_drvdata(pdev); <answer> xilinx_dma_device 
int <token> <answer> i; 
<token> (i = 0; i < xdev->dma_config->max_channels; i++) <answer> for 
<token> (xdev->chan[i]) <answer> if 
<token> struct platform_driver xilinx_vdma_driver = { <answer> static 
<token> = { <answer> .driver 
.name = <token> <answer> "xilinx-vdma", 
.of_match_table = <token> <answer> xilinx_dma_of_ids, 
.probe = <token> <answer> xilinx_dma_probe, 
<token> = xilinx_dma_remove, <answer> .remove_new 
MODULE_AUTHOR("Xilinx, <token> <answer> Inc."); 
MODULE_DESCRIPTION("Xilinx <token> driver"); <answer> VDMA 
<token> v2"); <answer> MODULE_LICENSE("GPL 
static int set_vmixer_gain(struct echoaudio *chip, <token> output, u16 pipe, <answer> u16 
<token> gain); <answer> int 
static int update_vmixer_level(struct <token> *chip); <answer> echoaudio 
static int init_hw(struct echoaudio *chip, u16 device_id, u16 <token> <answer> subdevice_id) 
int <token> <answer> err; 
if (snd_BUG_ON((subdevice_id <token> 0xfff0) != INDIGO)) <answer> & 
<token> -ENODEV; <answer> return 
err = <token> <answer> init_dsp_comm_page(chip); 
<token> (err) { <answer> if 
<token> - could not initialize DSP comm page\n"); <answer> "init_hw 
<token> err; <answer> return 
chip->device_id = <token> <answer> device_id; 
chip->subdevice_id = <token> <answer> subdevice_id; 
chip->bad_board = <token> <answer> true; 
<token> = FW_INDIGO_DSP; <answer> chip->dsp_code_to_load 
chip->asic_loaded = <token> <answer> true; 
chip->input_clock_types <token> ECHO_CLOCK_BIT_INTERNAL; <answer> = 
<token> = load_firmware(chip); <answer> err 
<token> (err < 0) <answer> if 
return <token> <answer> err; 
<token> = false; <answer> chip->bad_board 
return <token> <answer> err; 
static int set_mixer_defaults(struct echoaudio <token> <answer> *chip) 
<token> init_line_levels(chip); <answer> return 
static u32 detect_input_clocks(const struct <token> *chip) <answer> echoaudio 
<token> ECHO_CLOCK_BIT_INTERNAL; <answer> return 
int <token> <answer> e(void) 
return <token> <answer> 0; 
#include <token> <answer> <linux/vmalloc.h> 
<token> <linux/kvm_host.h> <answer> #include 
<token> <linux/bug.h> <answer> #include 
<token> <linux/list.h> <answer> #include 
#include <token> <answer> <linux/bitmap.h> 
#include <token> <answer> <linux/sched/signal.h> 
#include <token> <answer> <asm/gmap.h> 
<token> <asm/mmu_context.h> <answer> #include 
#include <token> <answer> <asm/sclp.h> 
<token> <asm/nmi.h> <answer> #include 
<token> <asm/dis.h> <answer> #include 
<token> <asm/facility.h> <answer> #include 
<token> "kvm-s390.h" <answer> #include 
<token> "gaccess.h" <answer> #include 
<token> vsie_page { <answer> struct 
<token> int setup_apcb00(struct kvm_vcpu *vcpu, unsigned long *apcb_s, <answer> static 
unsigned long crycb_gpa, <token> long *apcb_h) <answer> unsigned 
<token> long apcb_gpa; <answer> unsigned 
apcb_gpa = crycb_gpa <token> offsetof(struct kvm_s390_crypto_cb, apcb0); <answer> + 
<token> (read_guest_real(vcpu, apcb_gpa, apcb_s, <answer> if 
<token> kvm_s390_apcb0))) <answer> sizeof(struct 
return <token> <answer> -EFAULT; 
<token> apcb_s, apcb_h, <answer> bitmap_and(apcb_s, 
BITS_PER_BYTE * sizeof(struct <token> <answer> kvm_s390_apcb0)); 
return <token> <answer> 0; 
static int setup_apcb11(struct kvm_vcpu *vcpu, <token> long *apcb_s, <answer> unsigned 
unsigned <token> crycb_gpa, <answer> long 
unsigned <token> *apcb_h) <answer> long 
<token> long apcb_gpa; <answer> unsigned 
apcb_gpa = crycb_gpa + offsetof(struct kvm_s390_crypto_cb, <token> <answer> apcb1); 
<token> (read_guest_real(vcpu, apcb_gpa, apcb_s, <answer> if 
<token> kvm_s390_apcb1))) <answer> sizeof(struct 
<token> -EFAULT; <answer> return 
<token> apcb_s, apcb_h, <answer> bitmap_and(apcb_s, 
BITS_PER_BYTE * <token> kvm_s390_apcb1)); <answer> sizeof(struct 
<token> 0; <answer> return 
static int setup_apcb(struct kvm_vcpu <token> struct kvm_s390_crypto_cb *crycb_s, <answer> *vcpu, 
<token> u32 crycb_gpa, <answer> const 
struct kvm_s390_crypto_cb <token> <answer> *crycb_h, 
<token> fmt_o, int fmt_h) <answer> int 
switch (fmt_o) <token> <answer> { 
case <token> <answer> CRYCB_FORMAT2: 
if ((crycb_gpa & PAGE_MASK) != ((crycb_gpa + 256) & <token> <answer> PAGE_MASK)) 
<token> -EACCES; <answer> return 
if <token> != CRYCB_FORMAT2) <answer> (fmt_h 
<token> -EINVAL; <answer> return 
<token> setup_apcb11(vcpu, (unsigned long *)&crycb_s->apcb1, <answer> return 
(unsigned <token> *)&crycb_h->apcb1); <answer> long 
<token> CRYCB_FORMAT1: <answer> case 
<token> (fmt_h) { <answer> switch 
case <token> <answer> CRYCB_FORMAT2: 
<token> setup_apcb10(vcpu, &crycb_s->apcb1, <answer> return 
case <token> <answer> CRYCB_FORMAT1: 
return <token> <answer> setup_apcb00(vcpu, 
(unsigned long <token> &crycb_s->apcb0, <answer> *) 
(unsigned long <token> &crycb_h->apcb0); <answer> *) 
case <token> <answer> CRYCB_FORMAT0: 
if ((crycb_gpa & PAGE_MASK) != ((crycb_gpa + 32) & <token> <answer> PAGE_MASK)) 
<token> -EACCES; <answer> return 
<token> (fmt_h) { <answer> switch 
case <token> <answer> CRYCB_FORMAT2: 
<token> setup_apcb10(vcpu, &crycb_s->apcb1, <answer> return 
case <token> <answer> CRYCB_FORMAT1: 
<token> CRYCB_FORMAT0: <answer> case 
return <token> <answer> setup_apcb00(vcpu, 
(unsigned long *) <token> <answer> &crycb_s->apcb0, 
(unsigned long *) <token> <answer> &crycb_h->apcb0); 
<token> -EINVAL; <answer> return 
static int shadow_crycb(struct kvm_vcpu *vcpu, struct vsie_page <token> <answer> *vsie_page) 
struct kvm_s390_sie_block *scb_s <token> &vsie_page->scb_s; <answer> = 
<token> kvm_s390_sie_block *scb_o = vsie_page->scb_o; <answer> struct 
const <token> crycbd_o = READ_ONCE(scb_o->crycbd); <answer> uint32_t 
const <token> crycb_addr = crycbd_o & 0x7ffffff8U; <answer> u32 
<token> long *b1, *b2; <answer> unsigned 
u8 <token> <answer> ecb3_flags; 
<token> ecd_flags; <answer> u32 
int <token> <answer> apie_h; 
int <token> <answer> apie_s; 
<token> key_msk = test_kvm_facility(vcpu->kvm, 76); <answer> int 
int fmt_o <token> crycbd_o & CRYCB_FORMAT_MASK; <answer> = 
<token> fmt_h = vcpu->arch.sie_block->crycbd & CRYCB_FORMAT_MASK; <answer> int 
<token> ret = 0; <answer> int 
scb_s->crycbd = <token> <answer> 0; 
apie_h = vcpu->arch.sie_block->eca & <token> <answer> ECA_APIE; 
<token> = apie_h & scb_o->eca; <answer> apie_s 
<token> (!apie_s && (!key_msk || (fmt_o == CRYCB_FORMAT0))) <answer> if 
return <token> <answer> 0; 
if <token> <answer> (!crycb_addr) 
<token> set_validity_icpt(scb_s, 0x0039U); <answer> return 
if (fmt_o <token> CRYCB_FORMAT1) <answer> == 
if <token> & PAGE_MASK) != <answer> ((crycb_addr 
((crycb_addr + 128) & <token> <answer> PAGE_MASK)) 
<token> set_validity_icpt(scb_s, 0x003CU); <answer> return 
if <token> { <answer> (apie_s) 
ret <token> setup_apcb(vcpu, &vsie_page->crycb, crycb_addr, <answer> = 
<token> fmt_h); <answer> fmt_o, 
if <token> <answer> (ret) 
<token> end; <answer> goto 
scb_s->eca |= scb_o->eca <token> ECA_APIE; <answer> & 
static int shadow_scb(struct kvm_vcpu *vcpu, struct vsie_page <token> <answer> *vsie_page) 
struct <token> *scb_o = vsie_page->scb_o; <answer> kvm_s390_sie_block 
<token> kvm_s390_sie_block *scb_s = &vsie_page->scb_s; <answer> struct 
if (!(atomic_read(&scb_s->cpuflags) <token> CPUSTAT_KSS)) <answer> & 
scb_s->ictl |= ICTL_ISKE | ICTL_SSKE <token> ICTL_RRBE; <answer> | 
scb_s->icpua = <token> <answer> scb_o->icpua; 
if (!(atomic_read(&scb_s->cpuflags) <token> CPUSTAT_SM)) <answer> & 
new_mso <token> READ_ONCE(scb_o->mso) & 0xfffffffffff00000UL; <answer> = 
if (test_kvm_facility(vcpu->kvm, <token> <answer> 11)) 
<token> |= scb_o->ecb & ECB_PTF; <answer> scb_s->ecb 
for (i = 0; i <token> kvm->arch.vsie.page_count; i++) { <answer> < 
page <token> READ_ONCE(kvm->arch.vsie.pages[i]); <answer> = 
if <token> <answer> (!page) 
<token> = page_to_virt(page); <answer> cur 
if (READ_ONCE(cur->gmap) <token> gmap) <answer> != 
prefix = cur->scb_s.prefix << <token> <answer> GUEST_PREFIX_SHIFT; 
static int map_prefix(struct kvm_vcpu *vcpu, struct <token> *vsie_page) <answer> vsie_page 
struct kvm_s390_sie_block *scb_s = <token> <answer> &vsie_page->scb_s; 
u64 prefix = scb_s->prefix << <token> <answer> GUEST_PREFIX_SHIFT; 
<token> rc; <answer> int 
<token> (prefix_is_mapped(vsie_page)) <answer> if 
return <token> <answer> 0; 
<token> (rc) <answer> if 
if (rc > <token> || rc == -EFAULT) <answer> 0 
rc = set_validity_icpt(scb_s, <token> <answer> 0x0037U); 
<token> rc; <answer> return 
static int <token> kvm *kvm, gpa_t gpa, hpa_t *hpa) <answer> pin_guest_page(struct 
<token> page *page; <answer> struct 
<token> = gfn_to_page(kvm, gpa_to_gfn(gpa)); <answer> page 
if <token> <answer> (is_error_page(page)) 
return <token> <answer> -EINVAL; 
*hpa = <token> + (gpa & ~PAGE_MASK); <answer> (hpa_t)page_to_phys(page) 
<token> 0; <answer> return 
static int pin_blocks(struct <token> *vcpu, struct vsie_page *vsie_page) <answer> kvm_vcpu 
struct kvm_s390_sie_block <token> = vsie_page->scb_o; <answer> *scb_o 
<token> kvm_s390_sie_block *scb_s = &vsie_page->scb_s; <answer> struct 
hpa_t <token> <answer> hpa; 
<token> gpa; <answer> gpa_t 
int rc = <token> <answer> 0; 
gpa = READ_ONCE(scb_o->scaol) <token> ~0xfUL; <answer> & 
<token> (test_kvm_cpu_feat(vcpu->kvm, KVM_S390_VM_CPU_FEAT_64BSCAO)) <answer> if 
gpa |= (u64) READ_ONCE(scb_o->scaoh) <token> 32; <answer> << 
if (gpa) <token> <answer> { 
if (gpa < 2 <token> PAGE_SIZE) <answer> * 
<token> = set_validity_icpt(scb_s, 0x0038U); <answer> rc 
<token> if ((gpa & ~0x1fffUL) == kvm_s390_get_prefix(vcpu)) <answer> else 
rc = <token> 0x0011U); <answer> set_validity_icpt(scb_s, 
<token> if ((gpa & PAGE_MASK) != <answer> else 
((gpa + sizeof(struct bsca_block) - 1) <token> PAGE_MASK)) <answer> & 
rc = <token> 0x003bU); <answer> set_validity_icpt(scb_s, 
if (!rc) <token> <answer> { 
rc = <token> gpa, &hpa); <answer> pin_guest_page(vcpu->kvm, 
<token> (rc) <answer> if 
<token> = set_validity_icpt(scb_s, 0x0034U); <answer> rc 
<token> (rc) <answer> if 
<token> unpin; <answer> goto 
vsie_page->sca_gpa = <token> <answer> gpa; 
scb_s->scaoh = (u32)((u64)hpa >> <token> <answer> 32); 
<token> = (u32)(u64)hpa; <answer> scb_s->scaol 
gpa = READ_ONCE(scb_o->itdba) <token> ~0xffUL; <answer> & 
if (gpa && (scb_s->ecb & <token> { <answer> ECB_TE)) 
if (gpa < 2 <token> PAGE_SIZE) { <answer> * 
rc = <token> 0x0080U); <answer> set_validity_icpt(scb_s, 
<token> unpin; <answer> goto 
rc = <token> gpa, &hpa); <answer> pin_guest_page(vcpu->kvm, 
if <token> { <answer> (rc) 
<token> = set_validity_icpt(scb_s, 0x1310U); <answer> rc 
<token> unpin; <answer> goto 
<token> = gpa; <answer> vsie_page->gvrd_gpa 
scb_s->gvrd <token> hpa; <answer> = 
gpa = READ_ONCE(scb_o->riccbd) <token> ~0x3fUL; <answer> & 
if (gpa && <token> & ECB3_RI)) { <answer> (scb_s->ecb3 
if (gpa < 2 * PAGE_SIZE) <token> <answer> { 
rc <token> set_validity_icpt(scb_s, 0x0043U); <answer> = 
goto <token> <answer> unpin; 
rc <token> pin_guest_page(vcpu->kvm, gpa, &hpa); <answer> = 
if <token> { <answer> (rc) 
rc = set_validity_icpt(scb_s, <token> <answer> 0x10b0U); 
<token> unpin; <answer> goto 
vsie_page->sdnx_gpa = <token> <answer> gpa; 
<token> = hpa | sdnxc; <answer> scb_s->sdnxo 
<token> 0; <answer> return 
<token> vsie_page); <answer> unpin_blocks(vcpu, 
return <token> <answer> rc; 
static int <token> kvm_vcpu *vcpu, struct vsie_page *vsie_page, <answer> pin_scb(struct 
<token> gpa) <answer> gpa_t 
<token> hpa; <answer> hpa_t 
int <token> <answer> rc; 
rc = <token> gpa, &hpa); <answer> pin_guest_page(vcpu->kvm, 
<token> (rc) { <answer> if 
<token> = kvm_s390_inject_program_int(vcpu, PGM_ADDRESSING); <answer> rc 
<token> 1; <answer> return 
vsie_page->scb_o = <token> <answer> phys_to_virt(hpa); 
<token> 0; <answer> return 
static int inject_fault(struct kvm_vcpu *vcpu, __u16 code, <token> vaddr, <answer> __u64 
bool <token> <answer> write_flag) 
struct kvm_s390_pgm_info pgm = <token> <answer> { 
<token> = code, <answer> .code 
.trans_exc_code <token> <answer> = 
static int <token> kvm_vcpu *vcpu, struct vsie_page *vsie_page) <answer> handle_fault(struct 
<token> rc; <answer> int 
if <token> == PGM_PROTECTION) <answer> (current->thread.gmap_int_code 
static void handle_last_fault(struct kvm_vcpu <token> <answer> *vcpu, 
<token> vsie_page *vsie_page) <answer> struct 
<token> (vsie_page->fault_addr) <answer> if 
<token> vsie_page->gmap, <answer> kvm_s390_shadow_fault(vcpu, 
<token> NULL); <answer> vsie_page->fault_addr, 
vsie_page->fault_addr <token> 0; <answer> = 
static <token> void clear_vsie_icpt(struct vsie_page *vsie_page) <answer> inline 
vsie_page->scb_s.icptcode <token> 0; <answer> = 
static int handle_stfle(struct kvm_vcpu *vcpu, struct <token> *vsie_page) <answer> vsie_page 
struct kvm_s390_sie_block <token> = &vsie_page->scb_s; <answer> *scb_s 
__u32 <token> = READ_ONCE(vsie_page->scb_o->fac); <answer> fac 
if (fac <token> test_kvm_facility(vcpu->kvm, 7)) { <answer> && 
fac <token> fac & 0x7ffffff8U; <answer> = 
if (read_guest_real(vcpu, fac, <token> <answer> &vsie_page->fac, 
<token> * sizeof(u64))) <answer> stfle_size() 
return set_validity_icpt(scb_s, <token> <answer> 0x1090U); 
scb_s->fac = (__u32)(__u64) <token> <answer> &vsie_page->fac; 
return <token> <answer> 0; 
<token> u64 vsie_get_register(struct kvm_vcpu *vcpu, struct vsie_page *vsie_page, u8 reg) <answer> static 
if (rc_dest == -EAGAIN || rc_src == -EAGAIN <token> (!rc_dest && !rc_src)) { <answer> || 
<token> -EAGAIN; <answer> return 
<token> (edat) { <answer> if 
<token> = rc_dest == PGM_ASCE_TYPE ? rc_dest : 0; <answer> rc_dest 
rc_src = rc_src == PGM_ASCE_TYPE <token> rc_src : 0; <answer> ? 
} else <token> <answer> { 
rc_dest = <token> != PGM_PAGE_TRANSLATION ? rc_dest : 0; <answer> rc_dest 
rc_src = rc_src != PGM_PAGE_TRANSLATION <token> rc_src : 0; <answer> ? 
if (!rc_dest && <token> { <answer> !rc_src) 
<token> = pei_dest; <answer> pei_block[0] 
pei_block[1] <token> pei_src; <answer> = 
return <token> <answer> 1; 
<token> (rc_dest) <answer> if 
return inject_fault(vcpu, rc_dest, dest, <token> <answer> 1); 
return inject_fault(vcpu, rc_src, <token> 0); <answer> src, 
static int do_vsie_run(struct kvm_vcpu *vcpu, <token> vsie_page *vsie_page) <answer> struct 
struct kvm_s390_sie_block *scb_s <token> &vsie_page->scb_s; <answer> = 
struct kvm_s390_sie_block *scb_o <token> vsie_page->scb_o; <answer> = 
<token> guest_bp_isolation; <answer> int 
int rc = <token> <answer> 0; 
handle_last_fault(vcpu, <token> <answer> vsie_page); 
if (test_kvm_facility(vcpu->kvm, <token> && <answer> 82) 
vcpu->arch.sie_block->fpf <token> FPF_BPBC) <answer> & 
<token> |= PROG_IN_SIE; <answer> vcpu->arch.sie_block->prog0c 
if <token> <answer> (!kvm_s390_vcpu_sie_inhibited(vcpu)) 
rc = <token> vcpu->run->s.regs.gprs); <answer> sie64a(scb_s, 
<token> &= ~PROG_IN_SIE; <answer> vcpu->arch.sie_block->prog0c 
if (vsie_page->gmap && gmap_shadow_valid(vsie_page->gmap, <token> edat)) { <answer> asce, 
return <token> <answer> 0; 
static <token> register_shadow_scb(struct kvm_vcpu *vcpu, <answer> void 
<token> vsie_page *vsie_page) <answer> struct 
struct kvm_s390_sie_block *scb_s <token> &vsie_page->scb_s; <answer> = 
<token> &vsie_page->scb_s); <answer> WRITE_ONCE(vcpu->arch.vsie_block, 
<token> CPUSTAT_WAIT); <answer> kvm_s390_set_cpuflags(vcpu, 
scb_s->epoch <token> vcpu->kvm->arch.epoch; <answer> += 
if <token> & ECD_MEF) { <answer> (scb_s->ecd 
scb_s->epdx += <token> <answer> vcpu->kvm->arch.epdx; 
if (scb_s->epoch <token> vcpu->kvm->arch.epoch) <answer> < 
scb_s->epdx <token> 1; <answer> += 
static <token> unregister_shadow_scb(struct kvm_vcpu *vcpu) <answer> void 
kvm_s390_clear_cpuflags(vcpu, <token> <answer> CPUSTAT_WAIT); 
WRITE_ONCE(vcpu->arch.vsie_block, <token> <answer> NULL); 
<token> int vsie_run(struct kvm_vcpu *vcpu, struct vsie_page *vsie_page) <answer> static 
struct <token> *scb_s = &vsie_page->scb_s; <answer> kvm_s390_sie_block 
int rc = <token> <answer> 0; 
while <token> { <answer> (1) 
rc = <token> vsie_page); <answer> acquire_gmap_shadow(vcpu, 
<token> (!rc) <answer> if 
rc = <token> vsie_page); <answer> map_prefix(vcpu, 
if <token> { <answer> (!rc) 
rc = <token> vsie_page); <answer> do_vsie_run(vcpu, 
atomic_andnot(PROG_BLOCK_SIE, <token> <answer> &scb_s->prog20); 
<token> (rc == -EAGAIN) <answer> if 
rc = <token> <answer> 0; 
<token> (rc || scb_s->icptcode || signal_pending(current) || <answer> if 
kvm_s390_vcpu_has_irq(vcpu, <token> || <answer> 0) 
if (rc == -EFAULT) <token> <answer> { 
scb_s->icptcode <token> ICPT_PROGI; <answer> = 
scb_s->iprcc <token> PGM_ADDRESSING; <answer> = 
<token> = 4; <answer> scb_s->pgmilc 
scb_s->gpsw.addr = <token> 4); <answer> __rewind_psw(scb_s->gpsw, 
rc = <token> <answer> 1; 
return <token> <answer> rc; 
static struct <token> *get_vsie_page(struct kvm *kvm, unsigned long addr) <answer> vsie_page 
<token> vsie_page *vsie_page; <answer> struct 
struct <token> *page; <answer> page 
int <token> <answer> nr_vcpus; 
page = radix_tree_lookup(&kvm->arch.vsie.addr_to_page, addr >> <token> <answer> 9); 
<token> (page) { <answer> if 
if (page_ref_inc_return(page) <token> 2) <answer> == 
return <token> <answer> page_to_virt(page); 
<token> = atomic_read(&kvm->online_vcpus); <answer> nr_vcpus 
if (kvm->arch.vsie.page_count < nr_vcpus) <token> <answer> { 
page = <token> | __GFP_ZERO | GFP_DMA); <answer> alloc_page(GFP_KERNEL_ACCOUNT 
<token> (!page) { <answer> if 
<token> ERR_PTR(-ENOMEM); <answer> return 
<token> = page; <answer> kvm->arch.vsie.pages[kvm->arch.vsie.page_count] 
<token> else { <answer> } 
<token> (scb) { <answer> if 
<token> &scb->prog20); <answer> atomic_or(PROG_BLOCK_SIE, 
<token> (scb->prog0c & PROG_IN_SIE) <answer> if 
atomic_or(CPUSTAT_STOP_INT, <token> <answer> &scb->cpuflags); 
<token> <linux/debugfs.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/ktime.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/uaccess.h> 
<token> DEFAULT_ITERATIONS 100 <answer> #define 
#define <token> "udelay_test" <answer> DEBUGFS_FILENAME 
static <token> <answer> DEFINE_MUTEX(udelay_test_lock); 
<token> int udelay_test_usecs; <answer> static 
<token> int udelay_test_iterations = DEFAULT_ITERATIONS; <answer> static 
static int udelay_test_single(struct <token> *s, int usecs, uint32_t iters) <answer> seq_file 
int min = 0, max <token> 0, fail_count = 0; <answer> = 
<token> sum = 0; <answer> uint64_t 
<token> avg; <answer> uint64_t 
int <token> <answer> i; 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/cred.h> 
#include <token> <answer> <linux/nls.h> 
#include <token> <answer> <linux/ctype.h> 
#include <token> <answer> <linux/statfs.h> 
#include <token> <answer> <linux/cdrom.h> 
<token> <linux/parser.h> <answer> #include 
#include <token> <answer> <linux/mpage.h> 
<token> <linux/user_namespace.h> <answer> #include 
<token> <linux/seq_file.h> <answer> #include 
#include <token> <answer> <linux/blkdev.h> 
<token> "isofs.h" <answer> #include 
#include <token> <answer> "zisofs.h" 
<token> int isofs_remount(struct super_block *sb, int *flags, char *data) <answer> static 
<token> (!(*flags & SB_RDONLY)) <answer> if 
return <token> <answer> -EROFS; 
return <token> <answer> 0; 
static const struct super_operations isofs_sops <token> { <answer> = 
.alloc_inode <token> isofs_alloc_inode, <answer> = 
.free_inode <token> isofs_free_inode, <answer> = 
.put_super = <token> <answer> isofs_put_super, 
.statfs <token> isofs_statfs, <answer> = 
.remount_fs = <token> <answer> isofs_remount, 
.show_options = <token> <answer> isofs_show_options, 
static <token> struct dentry_operations isofs_dentry_ops[] = { <answer> const 
<token> = isofs_hashi, <answer> .d_hash 
.d_compare <token> isofs_dentry_cmpi, <answer> = 
#ifdef <token> <answer> CONFIG_JOLIET 
.d_hash = <token> <answer> isofs_hash_ms, 
.d_compare <token> isofs_dentry_cmp_ms, <answer> = 
.d_hash = <token> <answer> isofs_hashi_ms, 
.d_compare <token> isofs_dentry_cmpi_ms, <answer> = 
<token> iso9660_options{ <answer> struct 
unsigned <token> rock:1; <answer> int 
<token> int joliet:1; <answer> unsigned 
unsigned int <token> <answer> cruft:1; 
unsigned <token> hide:1; <answer> int 
<token> int showassoc:1; <answer> unsigned 
unsigned <token> nocompress:1; <answer> int 
unsigned <token> overriderockperm:1; <answer> int 
unsigned int <token> <answer> uid_set:1; 
unsigned int <token> <answer> gid_set:1; 
<token> char map; <answer> unsigned 
unsigned <token> check; <answer> char 
<token> int blocksize; <answer> unsigned 
umode_t <token> <answer> fmode; 
<token> dmode; <answer> umode_t 
kgid_t <token> <answer> gid; 
<token> uid; <answer> kuid_t 
char <token> <answer> *iocharset; 
<token> int <answer> static 
isofs_hashi_common(const struct dentry *dentry, struct qstr *qstr, <token> ms) <answer> int 
<token> char *name; <answer> const 
<token> len; <answer> int 
<token> c; <answer> char 
<token> long hash; <answer> unsigned 
len = <token> <answer> qstr->len; 
<token> = qstr->name; <answer> name 
<token> (ms) { <answer> if 
while (len <token> name[len-1] == '.') <answer> && 
hash <token> init_name_hash(dentry); <answer> = 
while <token> { <answer> (len--) 
c = <token> <answer> tolower(*name++); 
hash <token> partial_name_hash(c, hash); <answer> = 
qstr->hash <token> end_name_hash(hash); <answer> = 
<token> 0; <answer> return 
<token> int isofs_dentry_cmp_common( <answer> static 
unsigned int len, const char <token> <answer> *str, 
const struct qstr *name, int <token> int ci) <answer> ms, 
int alen, <token> <answer> blen; 
<token> int <answer> static 
isofs_hash_common(const <token> dentry *dentry, struct qstr *qstr, int ms) <answer> struct 
const char <token> <answer> *name; 
int <token> <answer> len; 
len = <token> <answer> qstr->len; 
<token> = qstr->name; <answer> name 
if <token> { <answer> (ms) 
while (len && name[len-1] <token> '.') <answer> == 
<token> = full_name_hash(dentry, name, len); <answer> qstr->hash 
return <token> <answer> 0; 
<token> int <answer> static 
<token> struct dentry *dentry, struct qstr *qstr) <answer> isofs_hash_ms(const 
<token> isofs_hash_common(dentry, qstr, 1); <answer> return 
static <token> <answer> int 
isofs_hashi_ms(const struct dentry <token> struct qstr *qstr) <answer> *dentry, 
<token> isofs_hashi_common(dentry, qstr, 1); <answer> return 
<token> int <answer> static 
<token> struct dentry *dentry, <answer> isofs_dentry_cmp_ms(const 
unsigned int len, const char *str, const struct <token> *name) <answer> qstr 
return isofs_dentry_cmp_common(len, str, <token> 1, 0); <answer> name, 
<token> int <answer> static 
isofs_dentry_cmpi_ms(const struct <token> *dentry, <answer> dentry 
unsigned <token> len, const char *str, const struct qstr *name) <answer> int 
<token> isofs_dentry_cmp_common(len, str, name, 1, 1); <answer> return 
enum <token> <answer> { 
Opt_block, Opt_check_r, Opt_check_s, <token> Opt_gid, Opt_ignore, <answer> Opt_cruft, 
<token> Opt_map_a, Opt_map_n, Opt_map_o, Opt_mode, Opt_nojoliet, <answer> Opt_iocharset, 
Opt_norock, Opt_sb, Opt_session, Opt_uid, <token> Opt_utf8, Opt_err, <answer> Opt_unhide, 
Opt_nocompress, Opt_hide, Opt_showassoc, <token> Opt_overriderockperm, <answer> Opt_dmode, 
static const match_table_t tokens <token> { <answer> = 
{Opt_norock, <token> <answer> "norock"}, 
{Opt_nojoliet, <token> <answer> "nojoliet"}, 
{Opt_unhide, <token> <answer> "unhide"}, 
{Opt_hide, <token> <answer> "hide"}, 
<token> "showassoc"}, <answer> {Opt_showassoc, 
{Opt_cruft, <token> <answer> "cruft"}, 
{Opt_utf8, <token> <answer> "utf8"}, 
<token> "iocharset=%s"}, <answer> {Opt_iocharset, 
<token> "map=acorn"}, <answer> {Opt_map_a, 
{Opt_map_a, <token> <answer> "map=a"}, 
{Opt_map_n, <token> <answer> "map=normal"}, 
{Opt_map_n, <token> <answer> "map=n"}, 
<token> "map=off"}, <answer> {Opt_map_o, 
{Opt_map_o, <token> <answer> "map=o"}, 
<token> "session=%u"}, <answer> {Opt_session, 
<token> "sbsector=%u"}, <answer> {Opt_sb, 
{Opt_check_r, <token> <answer> "check=relaxed"}, 
{Opt_check_r, <token> <answer> "check=r"}, 
<token> "check=strict"}, <answer> {Opt_check_s, 
{Opt_check_s, <token> <answer> "check=s"}, 
{Opt_uid, <token> <answer> "uid=%u"}, 
{Opt_gid, <token> <answer> "gid=%u"}, 
<token> "mode=%u"}, <answer> {Opt_mode, 
<token> "dmode=%u"}, <answer> {Opt_dmode, 
{Opt_overriderockperm, <token> <answer> "overriderockperm"}, 
<token> "block=%u"}, <answer> {Opt_block, 
{Opt_ignore, <token> <answer> "conv=binary"}, 
<token> "conv=b"}, <answer> {Opt_ignore, 
<token> "conv=text"}, <answer> {Opt_ignore, 
<token> "conv=t"}, <answer> {Opt_ignore, 
{Opt_ignore, <token> <answer> "conv=mtext"}, 
<token> "conv=m"}, <answer> {Opt_ignore, 
{Opt_ignore, <token> <answer> "conv=auto"}, 
{Opt_ignore, <token> <answer> "conv=a"}, 
{Opt_nocompress, <token> <answer> "nocompress"}, 
<token> NULL} <answer> {Opt_err, 
static int parse_options(char <token> struct iso9660_options *popt) <answer> *options, 
<token> *p; <answer> char 
int <token> <answer> option; 
<token> int uv; <answer> unsigned 
<token> = 'n'; <answer> popt->map 
<token> = 1; <answer> popt->rock 
<token> = 1; <answer> popt->joliet 
popt->cruft = <token> <answer> 0; 
popt->hide = <token> <answer> 0; 
<token> = 0; <answer> popt->showassoc 
if (n >= <token> <answer> 99) 
return <token> <answer> 0; 
<token> = n + 1; <answer> popt->session 
case <token> <answer> Opt_sb: 
<token> (match_int(&args[0], &option)) <answer> if 
return <token> <answer> 0; 
<token> = option; <answer> popt->sbsector 
<token> Opt_check_r: <answer> case 
popt->check = <token> <answer> 'r'; 
case <token> <answer> Opt_check_s: 
<token> = 's'; <answer> popt->check 
case <token> <answer> Opt_ignore: 
case <token> <answer> Opt_uid: 
<token> (match_uint(&args[0], &uv)) <answer> if 
<token> 0; <answer> return 
popt->uid = <token> uv); <answer> make_kuid(current_user_ns(), 
<token> (!uid_valid(popt->uid)) <answer> if 
<token> 0; <answer> return 
<token> = 1; <answer> popt->uid_set 
case <token> <answer> Opt_gid: 
if (match_uint(&args[0], <token> <answer> &uv)) 
return <token> <answer> 0; 
<token> = make_kgid(current_user_ns(), uv); <answer> popt->gid 
<token> (!gid_valid(popt->gid)) <answer> if 
return <token> <answer> 0; 
popt->gid_set = <token> <answer> 1; 
<token> Opt_mode: <answer> case 
if (match_int(&args[0], <token> <answer> &option)) 
return <token> <answer> 0; 
popt->fmode <token> option; <answer> = 
case <token> <answer> Opt_dmode: 
if (match_int(&args[0], <token> <answer> &option)) 
<token> 0; <answer> return 
popt->dmode <token> option; <answer> = 
<token> Opt_overriderockperm: <answer> case 
popt->overriderockperm = <token> <answer> 1; 
case <token> <answer> Opt_block: 
if (match_int(&args[0], <token> <answer> &option)) 
return <token> <answer> 0; 
n = <token> <answer> option; 
if (n != 512 && n <token> 1024 && n != 2048) <answer> != 
return <token> <answer> 0; 
popt->blocksize <token> n; <answer> = 
case <token> <answer> Opt_nocompress: 
popt->nocompress <token> 1; <answer> = 
<token> 0; <answer> return 
return <token> <answer> 1; 
static int isofs_show_options(struct seq_file *m, struct <token> *root) <answer> dentry 
struct <token> *sbi = ISOFS_SB(root->d_sb); <answer> isofs_sb_info 
if <token> seq_puts(m, ",norock"); <answer> (!sbi->s_rock) 
else if <token> seq_puts(m, ",nojoliet"); <answer> (!sbi->s_joliet_level) 
if (sbi->s_cruft) <token> ",cruft"); <answer> seq_puts(m, 
<token> (sbi->s_hide) seq_puts(m, ",hide"); <answer> if 
<token> (sbi->s_nocompress) seq_puts(m, ",nocompress"); <answer> if 
<token> (sbi->s_overriderockperm) seq_puts(m, ",overriderockperm"); <answer> if 
<token> (sbi->s_showassoc) seq_puts(m, ",showassoc"); <answer> if 
if <token> seq_printf(m, ",check=%c", sbi->s_check); <answer> (sbi->s_check) 
<token> (sbi->s_mapping) seq_printf(m, ",map=%c", sbi->s_mapping); <answer> if 
if (sbi->s_session != 255) <token> ",session=%u", sbi->s_session - 1); <answer> seq_printf(m, 
if (sbi->s_sbsector != -1) <token> ",sbsector=%u", sbi->s_sbsector); <answer> seq_printf(m, 
if <token> != 1024) <answer> (root->d_sb->s_blocksize 
seq_printf(m, ",blocksize=%lu", <token> <answer> root->d_sb->s_blocksize); 
<token> (sbi->s_uid_set) <answer> if 
seq_printf(m, <token> <answer> ",uid=%u", 
<token> sbi->s_uid)); <answer> from_kuid_munged(&init_user_ns, 
<token> (sbi->s_gid_set) <answer> if 
seq_printf(m, <token> <answer> ",gid=%u", 
<token> sbi->s_gid)); <answer> from_kgid_munged(&init_user_ns, 
if (sbi->s_dmode <token> ISOFS_INVALID_MODE) <answer> != 
seq_printf(m, <token> sbi->s_dmode); <answer> ",dmode=%o", 
if (sbi->s_fmode != <token> <answer> ISOFS_INVALID_MODE) 
seq_printf(m, <token> sbi->s_fmode); <answer> ",fmode=%o", 
#ifdef <token> <answer> CONFIG_JOLIET 
if <token> <answer> (sbi->s_nls_iocharset) 
seq_printf(m, <token> sbi->s_nls_iocharset->charset); <answer> ",iocharset=%s", 
<token> ",iocharset=utf8"); <answer> seq_puts(m, 
<token> 0; <answer> return 
#define <token> 1 <answer> WE_OBEY_THE_WRITTEN_STANDARDS 
static unsigned int isofs_get_last_session(struct super_block <token> s32 session) <answer> *sb, 
struct cdrom_device_info *cdi <token> disk_to_cdi(sb->s_bdev->bd_disk); <answer> = 
unsigned int <token> = 0; <answer> vol_desc_start 
if (session > 0) <token> <answer> { 
struct cdrom_tocentry <token> <answer> te; 
<token> (!cdi) <answer> if 
return <token> <answer> 0; 
<token> = session; <answer> te.cdte_track 
te.cdte_format <token> CDROM_LBA; <answer> = 
if <token> &te) == 0) { <answer> (cdrom_read_tocentry(cdi, 
printk(KERN_DEBUG "ISOFS: <token> %d start %d type %d\n", <answer> Session 
<token> te.cdte_addr.lba, <answer> session, 
<token> & CDROM_DATA_TRACK); <answer> te.cdte_ctrl 
if ((te.cdte_ctrl & <token> == 4) <answer> CDROM_DATA_TRACK) 
return <token> <answer> te.cdte_addr.lba; 
printk(KERN_ERR "ISOFS: Invalid session number <token> type of track\n"); <answer> or 
<token> (cdi) { <answer> if 
<token> cdrom_multisession ms_info; <answer> struct 
ms_info.addr_format <token> CDROM_LBA; <answer> = 
if (cdrom_multisession(cdi, <token> == 0) { <answer> &ms_info) 
#if <token> <answer> WE_OBEY_THE_WRITTEN_STANDARDS 
static bool <token> super_block *sb, unsigned long block) <answer> rootdir_empty(struct 
int offset = 0, files = <token> de_len; <answer> 0, 
<token> iso_directory_record *de; <answer> struct 
struct buffer_head <token> <answer> *bh; 
bh = <token> block); <answer> sb_bread(sb, 
if <token> <answer> (!bh) 
<token> true; <answer> return 
while (files <token> 3) { <answer> < 
de = (struct iso_directory_record <token> (bh->b_data + offset); <answer> *) 
de_len <token> *(unsigned char *) de; <answer> = 
<token> (de_len == 0) <answer> if 
<token> += de_len; <answer> offset 
return files <token> 3; <answer> < 
static int <token> super_block *s, void *data, int silent) <answer> isofs_fill_super(struct 
struct buffer_head *bh = NULL, *pri_bh = <token> <answer> NULL; 
struct <token> *h_pri = NULL; <answer> hs_primary_descriptor 
struct iso_primary_descriptor *pri <token> NULL; <answer> = 
struct <token> *sec = NULL; <answer> iso_supplementary_descriptor 
struct iso_directory_record <token> <answer> *rootp; 
struct <token> *inode; <answer> inode 
<token> iso9660_options opt; <answer> struct 
struct isofs_sb_info <token> <answer> *sbi; 
<token> long first_data_zone; <answer> unsigned 
int <token> = 0; <answer> joliet_level 
<token> iso_blknum, block; <answer> int 
<token> orig_zonesize; <answer> int 
<token> table, error = -EINVAL; <answer> int 
unsigned int <token> <answer> vol_desc_start; 
sbi = kzalloc(sizeof(*sbi), <token> <answer> GFP_KERNEL); 
<token> (!sbi) <answer> if 
return <token> <answer> -ENOMEM; 
s->s_fs_info = <token> <answer> sbi; 
if (!parse_options((char <token> &opt)) <answer> *)data, 
<token> out_freesbi; <answer> goto 
if (bdev_logical_block_size(s->s_bdev) > 2048) <token> <answer> { 
"ISOFS: unsupported/invalid hardware sector size <token> <answer> %d\n", 
<token> out_freesbi; <answer> goto 
opt.blocksize = <token> opt.blocksize); <answer> sb_min_blocksize(s, 
<token> (strncmp (vdp->id, ISO_STANDARD_ID, sizeof vdp->id) == 0) { <answer> if 
if <token> == ISO_VD_END) <answer> (isonum_711(vdp->type) 
if (isonum_711(vdp->type) == ISO_VD_PRIMARY) <token> <answer> { 
<token> (!pri) { <answer> if 
pri = (struct iso_primary_descriptor <token> <answer> *)vdp; 
if <token> <answer> (!pri) 
goto <token> <answer> out_unknown_format; 
bh = <token> <answer> pri_bh; 
pri_bh = <token> <answer> NULL; 
pri = (struct iso_primary_descriptor <token> sec; <answer> *) 
<token> = (struct iso_directory_record *) h_pri->root_directory_record; <answer> rootp 
<token> = isonum_733(h_pri->volume_space_size); <answer> sbi->s_nzones 
sbi->s_log_zone_size <token> isonum_723(h_pri->logical_block_size); <answer> = 
sbi->s_max_size = <token> <answer> isonum_733(h_pri->volume_space_size); 
<token> else { <answer> } 
<token> (!pri) <answer> if 
goto <token> <answer> out_freebh; 
rootp = (struct <token> *) pri->root_directory_record; <answer> iso_directory_record 
sbi->s_nzones <token> isonum_733(pri->volume_space_size); <answer> = 
sbi->s_log_zone_size <token> isonum_723(pri->logical_block_size); <answer> = 
<token> = isonum_733(pri->volume_space_size); <answer> sbi->s_max_size 
<token> (orig_zonesize < opt.blocksize) <answer> if 
<token> out_bad_size; <answer> goto 
s->s_maxbytes <token> 0x80000000000LL; <answer> = 
first_data_zone <token> isonum_733(rootp->extent) + <answer> = 
<token> = first_data_zone; <answer> sbi->s_firstdatazone 
<token> BEQUIET <answer> #ifndef 
printk(KERN_DEBUG "ISOFS: Max <token> Log zone size:%ld\n", <answer> size:%ld 
sbi->s_max_size, 1UL << <token> <answer> sbi->s_log_zone_size); 
<token> "ISOFS: First datazone:%ld\n", sbi->s_firstdatazone); <answer> printk(KERN_DEBUG 
printk(KERN_DEBUG "ISOFS: Disc in <token> Sierra format.\n"); <answer> High 
if (joliet_level) <token> <answer> { 
pri <token> (struct iso_primary_descriptor *) sec; <answer> = 
rootp = (struct <token> *) <answer> iso_directory_record 
first_data_zone = <token> + <answer> isonum_733(rootp->extent) 
sb_set_blocksize(s, <token> <answer> orig_zonesize); 
sbi->s_nls_iocharset = <token> <answer> NULL; 
#ifdef <token> <answer> CONFIG_JOLIET 
if (joliet_level) <token> <answer> { 
char *p = <token> ? opt.iocharset : CONFIG_NLS_DEFAULT; <answer> opt.iocharset 
if (strcmp(p, "utf8") != <token> { <answer> 0) 
sbi->s_nls_iocharset <token> opt.iocharset ? <answer> = 
<token> : load_nls_default(); <answer> load_nls(opt.iocharset) 
if <token> <answer> (!sbi->s_nls_iocharset) 
<token> out_freesbi; <answer> goto 
s->s_op = <token> <answer> &isofs_sops; 
s->s_export_op = <token> <answer> &isofs_export_ops; 
sbi->s_mapping = <token> <answer> opt.map; 
sbi->s_rock = (opt.rock ? 2 <token> 0); <answer> : 
<token> (opt.fmode != ISOFS_INVALID_MODE) <answer> if 
sbi->s_fmode = opt.fmode & <token> <answer> 0777; 
sbi->s_fmode = <token> <answer> ISOFS_INVALID_MODE; 
if <token> != ISOFS_INVALID_MODE) <answer> (opt.dmode 
sbi->s_dmode = opt.dmode <token> 0777; <answer> & 
sbi->s_dmode = <token> <answer> ISOFS_INVALID_MODE; 
inode <token> isofs_iget(s, sbi->s_firstdatazone, 0); <answer> = 
<token> (IS_ERR(inode)) { <answer> if 
if (joliet_level <token> sbi->s_firstdatazone != first_data_zone) { <answer> && 
"ISOFS: root inode <token> unusable. " <answer> is 
"Disabling Rock <token> and switching to Joliet."); <answer> Ridge 
sbi->s_rock <token> 0; <answer> = 
inode <token> NULL; <answer> = 
<token> else { <answer> } 
<token> out_no_root; <answer> goto 
if (sbi->s_rock == 1 && <token> && <answer> joliet_level 
rootdir_empty(s, sbi->s_firstdatazone)) <token> <answer> { 
"ISOFS: primary root <token> is empty. " <answer> directory 
<token> Rock Ridge and switching to Joliet."); <answer> "Disabling 
<token> = 0; <answer> sbi->s_rock 
if (sbi->s_rock <token> 1) { <answer> == 
joliet_level = <token> <answer> 0; 
} else <token> (joliet_level) { <answer> if 
sbi->s_rock = <token> <answer> 0; 
if (sbi->s_firstdatazone != <token> { <answer> first_data_zone) 
sbi->s_firstdatazone = <token> <answer> first_data_zone; 
"ISOFS: changing to <token> root\n"); <answer> secondary 
inode = isofs_iget(s, sbi->s_firstdatazone, <token> <answer> 0); 
if <token> <answer> (IS_ERR(inode)) 
<token> out_no_root; <answer> goto 
<token> (opt.check == 'u') { <answer> if 
goto <token> <answer> out_no_inode; 
error <token> PTR_ERR(inode); <answer> = 
if (error != <token> <answer> -ENOMEM) 
printk(KERN_WARNING "%s: get root inode <token> __func__); <answer> failed\n", 
<token> CONFIG_JOLIET <answer> #ifdef 
goto <token> <answer> out_freesbi; 
printk(KERN_WARNING "%s: bread failed, dev=%s, <token> block=%d\n", <answer> iso_blknum=%d, 
<token> s->s_id, iso_blknum, block); <answer> __func__, 
<token> out_freebh; <answer> goto 
<token> "ISOFS: Bad logical zone size %ld\n", <answer> printk(KERN_WARNING 
goto <token> <answer> out_freebh; 
printk(KERN_WARNING "ISOFS: Logical zone size(%d) < hardware <token> <answer> blocksize(%u)\n", 
orig_zonesize, <token> <answer> opt.blocksize); 
<token> out_freebh; <answer> goto 
<token> (!silent) <answer> if 
printk(KERN_WARNING "ISOFS: Unable <token> identify CD-ROM format.\n"); <answer> to 
<token> = NULL; <answer> s->s_fs_info 
return <token> <answer> error; 
<token> int isofs_statfs (struct dentry *dentry, struct kstatfs *buf) <answer> static 
struct super_block <token> = dentry->d_sb; <answer> *sb 
u64 id <token> huge_encode_dev(sb->s_bdev->bd_dev); <answer> = 
<token> = ISOFS_SUPER_MAGIC; <answer> buf->f_type 
buf->f_bsize <token> sb->s_blocksize; <answer> = 
buf->f_blocks <token> (ISOFS_SB(sb)->s_nzones <answer> = 
<< (ISOFS_SB(sb)->s_log_zone_size - <token> <answer> sb->s_blocksize_bits)); 
buf->f_bfree = <token> <answer> 0; 
<token> = 0; <answer> buf->f_bavail 
buf->f_files = <token> <answer> ISOFS_SB(sb)->s_ninodes; 
buf->f_ffree = <token> <answer> 0; 
buf->f_fsid = <token> <answer> u64_to_fsid(id); 
buf->f_namelen = <token> <answer> NAME_MAX; 
return <token> <answer> 0; 
<token> isofs_get_blocks(struct inode *inode, sector_t iblock, <answer> int 
struct buffer_head **bh, unsigned <token> nblocks) <answer> long 
unsigned long <token> = iblock; <answer> b_off 
<token> offset, sect_size; <answer> unsigned 
<token> int firstext; <answer> unsigned 
<token> long nextblk, nextoff; <answer> unsigned 
int section, rv, <token> <answer> error; 
struct iso_inode_info *ei <token> ISOFS_I(inode); <answer> = 
error = <token> <answer> -EIO; 
rv <token> 0; <answer> = 
if (iblock != b_off) <token> <answer> { 
printk(KERN_DEBUG "%s: block number too <token> __func__); <answer> large\n", 
goto <token> <answer> abort; 
offset <token> 0; <answer> = 
firstext = <token> <answer> ei->i_first_extent; 
sect_size = ei->i_section_size <token> ISOFS_BUFFER_BITS(inode); <answer> >> 
<token> = ei->i_next_section_block; <answer> nextblk 
<token> = ei->i_next_section_offset; <answer> nextoff 
section <token> 0; <answer> = 
<token> (nblocks) { <answer> while 
if (b_off > ((inode->i_size + PAGE_SIZE <token> 1) >> ISOFS_BUFFER_BITS(inode))) { <answer> - 
printk(KERN_DEBUG "%s: block <token> EOF (%lu, %llu)\n", <answer> >= 
<token> b_off, <answer> __func__, 
<token> long long)inode->i_size); <answer> (unsigned 
goto <token> <answer> abort; 
while (nextblk && <token> >= (offset + sect_size))) { <answer> (b_off 
<token> inode *ninode; <answer> struct 
offset += <token> <answer> sect_size; 
ninode = isofs_iget(inode->i_sb, <token> nextoff); <answer> nextblk, 
<token> (IS_ERR(ninode)) { <answer> if 
<token> = PTR_ERR(ninode); <answer> error 
goto <token> <answer> abort; 
<token> = ISOFS_I(ninode)->i_first_extent; <answer> firstext 
sect_size = <token> >> ISOFS_BUFFER_BITS(ninode); <answer> ISOFS_I(ninode)->i_section_size 
nextblk = <token> <answer> ISOFS_I(ninode)->i_next_section_block; 
<token> = ISOFS_I(ninode)->i_next_section_offset; <answer> nextoff 
if (++section > 100) <token> <answer> { 
printk(KERN_DEBUG "%s: More than 100 file sections <token> <answer> ?!?" 
" aborting...\n", <token> <answer> __func__); 
printk(KERN_DEBUG "%s: block=%lu <token> sect_size=%u " <answer> firstext=%u 
<token> nextoff=%lu\n", __func__, <answer> "nextblk=%lu 
b_off, firstext, (unsigned) <token> <answer> sect_size, 
nextblk, <token> <answer> nextoff); 
goto <token> <answer> abort; 
if <token> { <answer> (*bh) 
map_bh(*bh, inode->i_sb, <token> + b_off - offset); <answer> firstext 
<token> else { <answer> } 
*bh = <token> firstext+b_off-offset); <answer> sb_getblk(inode->i_sb, 
if <token> <answer> (!*bh) 
goto <token> <answer> abort; 
<token> int isofs_get_block(struct inode *inode, sector_t iblock, <answer> static 
struct buffer_head <token> int create) <answer> *bh_result, 
int <token> <answer> ret; 
if <token> { <answer> (create) 
printk(KERN_DEBUG "%s: Kernel <token> to allocate a block\n", __func__); <answer> tries 
return <token> <answer> -EROFS; 
ret = isofs_get_blocks(inode, <token> &bh_result, 1); <answer> iblock, 
return ret < 0 ? <token> : 0; <answer> ret 
static int isofs_bmap(struct <token> *inode, sector_t block) <answer> inode 
<token> buffer_head dummy; <answer> struct 
<token> error; <answer> int 
dummy.b_state = <token> <answer> 0; 
dummy.b_blocknr = <token> <answer> -1000; 
<token> = isofs_get_block(inode, block, &dummy, 0); <answer> error 
if <token> <answer> (!error) 
return <token> <answer> dummy.b_blocknr; 
return <token> <answer> 0; 
struct buffer_head *isofs_bread(struct inode <token> sector_t block) <answer> *inode, 
sector_t blknr = <token> block); <answer> isofs_bmap(inode, 
if <token> <answer> (!blknr) 
<token> NULL; <answer> return 
return sb_bread(inode->i_sb, <token> <answer> blknr); 
static <token> isofs_read_folio(struct file *file, struct folio *folio) <answer> int 
return mpage_read_folio(folio, <token> <answer> isofs_get_block); 
static <token> isofs_readahead(struct readahead_control *rac) <answer> void 
<token> isofs_get_block); <answer> mpage_readahead(rac, 
static sector_t _isofs_bmap(struct address_space *mapping, <token> block) <answer> sector_t 
<token> generic_block_bmap(mapping,block,isofs_get_block); <answer> return 
<token> const struct address_space_operations isofs_aops = { <answer> static 
<token> = isofs_read_folio, <answer> .read_folio 
<token> = isofs_readahead, <answer> .readahead 
.bmap = <token> <answer> _isofs_bmap 
static <token> isofs_read_level3_size(struct inode *inode) <answer> int 
unsigned long <token> = ISOFS_BUFFER_SIZE(inode); <answer> bufsize 
int high_sierra = <token> <answer> ISOFS_SB(inode->i_sb)->s_high_sierra; 
<token> buffer_head *bh = NULL; <answer> struct 
unsigned long <token> offset, block_saved, offset_saved; <answer> block, 
int i = <token> <answer> 0; 
<token> more_entries = 0; <answer> int 
struct <token> *tmpde = NULL; <answer> iso_directory_record 
struct <token> *ei = ISOFS_I(inode); <answer> iso_inode_info 
inode->i_size <token> 0; <answer> = 
ei->i_next_section_block = <token> <answer> 0; 
<token> = 0; <answer> ei->i_next_section_offset 
block = <token> <answer> ei->i_iget5_block; 
offset <token> ei->i_iget5_offset; <answer> = 
do <token> <answer> { 
<token> iso_directory_record *de; <answer> struct 
unsigned int <token> <answer> de_len; 
if <token> { <answer> (!bh) 
bh = <token> block); <answer> sb_bread(inode->i_sb, 
<token> (!bh) <answer> if 
goto <token> <answer> out_noread; 
<token> = (struct iso_directory_record *) (bh->b_data + offset); <answer> de 
de_len = *(unsigned char <token> de; <answer> *) 
if (de_len == 0) <token> <answer> { 
bh <token> NULL; <answer> = 
offset = <token> <answer> 0; 
block_saved = <token> <answer> block; 
<token> = offset; <answer> offset_saved 
offset <token> de_len; <answer> += 
} else <token> <answer> { 
if <token> != ISOFS_INVALID_MODE) { <answer> (sbi->s_fmode 
inode->i_mode = S_IFREG | <token> <answer> sbi->s_fmode; 
} <token> { <answer> else 
inode->i_mode = <token> | S_IRUGO | S_IXUGO; <answer> S_IFREG 
set_nlink(inode, <token> <answer> 1); 
<token> = sbi->s_uid; <answer> inode->i_uid 
inode->i_gid <token> sbi->s_gid; <answer> = 
inode->i_blocks <token> 0; <answer> = 
ei->i_format_parm[0] <token> 0; <answer> = 
<token> = 0; <answer> ei->i_format_parm[1] 
ei->i_format_parm[2] = <token> <answer> 0; 
<token> = isonum_733(de->size); <answer> ei->i_section_size 
if (de->flags[-high_sierra] & 0x80) <token> <answer> { 
ret <token> isofs_read_level3_size(inode); <answer> = 
<token> (ret < 0) <answer> if 
goto <token> <answer> fail; 
<token> = -EIO; <answer> ret 
} else <token> <answer> { 
ei->i_next_section_block <token> 0; <answer> = 
ei->i_next_section_offset <token> 0; <answer> = 
inode->i_size <token> isonum_733(de->size); <answer> = 
if <token> <answer> (sbi->s_cruft) 
inode->i_size <token> 0x00ffffff; <answer> &= 
<token> (de->interleave[0]) { <answer> if 
printk(KERN_DEBUG <token> Interleaved files not (yet) supported.\n"); <answer> "ISOFS: 
inode->i_size = <token> <answer> 0; 
if <token> != 0) { <answer> (de->file_unit_size[0] 
printk(KERN_DEBUG <token> File unit size != 0 for ISO file (%ld).\n", <answer> "ISOFS: 
#ifdef <token> <answer> DEBUG 
if((de->flags[-high_sierra] & <token> 0){ <answer> ~2)!= 
<token> "ISOFS: Unusual flag settings for ISO file " <answer> printk(KERN_DEBUG 
"(%ld <token> <answer> %x).\n", 
<token> de->flags[-high_sierra]); <answer> inode->i_ino, 
inode_set_atime_to_ts(inode, inode_set_ctime(inode, iso_date(de->date, high_sierra), <token> <answer> 0))); 
ei->i_first_extent = <token> + <answer> (isonum_733(de->extent) 
if <token> { <answer> (!high_sierra) 
<token> inode, relocated); <answer> parse_rock_ridge_inode(de, 
<token> inode *__isofs_iget(struct super_block *sb, <answer> struct 
unsigned <token> block, <answer> long 
unsigned long <token> <answer> offset, 
<token> relocated) <answer> int 
<token> long hashval; <answer> unsigned 
struct <token> *inode; <answer> inode 
<token> isofs_iget5_callback_data data; <answer> struct 
<token> ret; <answer> long 
if (offset <token> 1ul << sb->s_blocksize_bits) <answer> >= 
return <token> <answer> ERR_PTR(-EINVAL); 
data.block <token> block; <answer> = 
data.offset <token> offset; <answer> = 
hashval = (block <token> sb->s_blocksize_bits) | offset; <answer> << 
inode <token> iget5_locked(sb, hashval, &isofs_iget5_test, <answer> = 
<token> &data); <answer> &isofs_iget5_set, 
if <token> <answer> (!inode) 
<token> ERR_PTR(-ENOMEM); <answer> return 
if (inode->i_state & <token> { <answer> I_NEW) 
<token> = isofs_read_inode(inode, relocated); <answer> ret 
if (ret < <token> { <answer> 0) 
<token> = ERR_PTR(ret); <answer> inode 
} else <token> <answer> { 
<token> inode; <answer> return 
static struct <token> *isofs_mount(struct file_system_type *fs_type, <answer> dentry 
int <token> const char *dev_name, void *data) <answer> flags, 
return mount_bdev(fs_type, flags, dev_name, data, <token> <answer> isofs_fill_super); 
<token> struct file_system_type iso9660_fs_type = { <answer> static 
.owner = <token> <answer> THIS_MODULE, 
.name <token> "iso9660", <answer> = 
.mount <token> isofs_mount, <answer> = 
.kill_sb <token> kill_block_super, <answer> = 
<token> = FS_REQUIRES_DEV, <answer> .fs_flags 
<token> int __init init_iso9660_fs(void) <answer> static 
int err <token> init_inodecache(); <answer> = 
<token> (err) <answer> if 
goto <token> <answer> out; 
#ifdef <token> <answer> CONFIG_ZISOFS 
err <token> zisofs_init(); <answer> = 
if <token> <answer> (err) 
<token> out1; <answer> goto 
err <token> register_filesystem(&iso9660_fs_type); <answer> = 
<token> (err) <answer> if 
goto <token> <answer> out2; 
return <token> <answer> 0; 
<token> CONFIG_ZISOFS <answer> #ifdef 
<token> err; <answer> return 
<token> void __exit exit_iso9660_fs(void) <answer> static 
#ifdef <token> <answer> CONFIG_ZISOFS 
#include <token> <answer> <linux/init.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/pinctrl/pinctrl.h> 
<token> "pinctrl-sunxi.h" <answer> #include 
static const struct sunxi_desc_pin sun4i_a10_pins[] <token> { <answer> = 
<token> 0), <answer> SUNXI_PIN(SUNXI_PINCTRL_PIN(A, 
<token> "gpio_in"), <answer> SUNXI_FUNCTION(0x0, 
SUNXI_FUNCTION(0x1, <token> <answer> "gpio_out"), 
<token> <linux/module.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/string.h> 
<token> <linux/gpio/driver.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/i2c.h> 
<token> <linux/platform_data/max732x.h> <answer> #include 
if <token> & chip->dir_output)) <answer> ((mask 
max732x_gpio_set_value(gc, <token> 1); <answer> off, 
return <token> <answer> 0; 
static int max732x_gpio_direction_output(struct gpio_chip <token> <answer> *gc, 
unsigned off, <token> val) <answer> int 
struct <token> *chip = gpiochip_get_data(gc); <answer> max732x_chip 
unsigned int mask = 1u << <token> <answer> off; 
if ((mask & chip->dir_output) <token> 0) { <answer> == 
dev_dbg(&chip->client->dev, "%s <token> %d is input only\n", <answer> port 
chip->client->name, <token> <answer> off); 
<token> -EACCES; <answer> return 
<token> off, val); <answer> max732x_gpio_set_value(gc, 
return <token> <answer> 0; 
#ifdef <token> <answer> CONFIG_GPIO_MAX732X_IRQ 
<token> int max732x_writew(struct max732x_chip *chip, uint16_t val) <answer> static 
<token> ret; <answer> int 
val = <token> <answer> cpu_to_le16(val); 
ret = i2c_master_send(chip->client_group_a, (char *)&val, <token> <answer> 2); 
<token> (ret < 0) { <answer> if 
dev_err(&chip->client_group_a->dev, "failed <token> <answer> writing\n"); 
return <token> <answer> ret; 
return <token> <answer> 0; 
static int max732x_readw(struct max732x_chip <token> uint16_t *val) <answer> *chip, 
int <token> <answer> ret; 
ret = <token> (char *)val, 2); <answer> i2c_master_recv(chip->client_group_a, 
if <token> < 0) { <answer> (ret 
dev_err(&chip->client_group_a->dev, <token> reading\n"); <answer> "failed 
<token> ret; <answer> return 
*val <token> le16_to_cpu(*val); <answer> = 
<token> 0; <answer> return 
<token> void max732x_irq_update_mask(struct max732x_chip *chip) <answer> static 
uint16_t <token> <answer> msg; 
if (chip->irq_mask == <token> <answer> chip->irq_mask_cur) 
chip->irq_mask <token> chip->irq_mask_cur; <answer> = 
if (chip->irq_features == <token> <answer> INT_NO_MASK) 
switch <token> { <answer> (chip->irq_features) 
<token> INT_INDEP_MASK: <answer> case 
msg = (chip->irq_mask << 8) | <token> <answer> chip->reg_out[0]; 
max732x_writew(chip, <token> <answer> msg); 
<token> INT_MERGED_MASK: <answer> case 
<token> = chip->irq_mask | chip->reg_out[0]; <answer> msg 
max732x_writeb(chip, 1, <token> <answer> (uint8_t)msg); 
static void max732x_irq_mask(struct irq_data <token> <answer> *d) 
<token> gpio_chip *gc = irq_data_get_irq_chip_data(d); <answer> struct 
struct max732x_chip *chip = <token> <answer> gpiochip_get_data(gc); 
chip->irq_mask_cur &= ~(1 <token> d->hwirq); <answer> << 
gpiochip_disable_irq(gc, <token> <answer> irqd_to_hwirq(d)); 
static void max732x_irq_unmask(struct irq_data <token> <answer> *d) 
struct gpio_chip *gc = <token> <answer> irq_data_get_irq_chip_data(d); 
struct <token> *chip = gpiochip_get_data(gc); <answer> max732x_chip 
<token> irqd_to_hwirq(d)); <answer> gpiochip_enable_irq(gc, 
chip->irq_mask_cur <token> 1 << d->hwirq; <answer> |= 
static void max732x_irq_bus_lock(struct irq_data <token> <answer> *d) 
struct gpio_chip <token> = irq_data_get_irq_chip_data(d); <answer> *gc 
struct max732x_chip *chip = <token> <answer> gpiochip_get_data(gc); 
chip->irq_mask_cur = <token> <answer> chip->irq_mask; 
static <token> max732x_irq_bus_sync_unlock(struct irq_data *d) <answer> void 
struct gpio_chip <token> = irq_data_get_irq_chip_data(d); <answer> *gc 
struct max732x_chip <token> = gpiochip_get_data(gc); <answer> *chip 
uint16_t <token> <answer> new_irqs; 
uint16_t <token> <answer> level; 
new_irqs = chip->irq_trig_fall | <token> <answer> chip->irq_trig_raise; 
while <token> { <answer> (new_irqs) 
level = <token> <answer> __ffs(new_irqs); 
max732x_gpio_direction_input(&chip->gpio_chip, <token> <answer> level); 
new_irqs &= ~(1 << <token> <answer> level); 
static int <token> irq_data *d, unsigned int type) <answer> max732x_irq_set_type(struct 
struct gpio_chip *gc <token> irq_data_get_irq_chip_data(d); <answer> = 
struct max732x_chip *chip <token> gpiochip_get_data(gc); <answer> = 
uint16_t off <token> d->hwirq; <answer> = 
uint16_t mask = 1 <token> off; <answer> << 
if (!(mask <token> chip->dir_input)) { <answer> & 
dev_dbg(&chip->client->dev, "%s port %d <token> output only\n", <answer> is 
chip->client->name, <token> <answer> off); 
return <token> <answer> -EACCES; 
if <token> & IRQ_TYPE_EDGE_BOTH)) { <answer> (!(type 
dev_err(&chip->client->dev, "irq %d: <token> type %d\n", <answer> unsupported 
d->irq, <token> <answer> type); 
return <token> <answer> -EINVAL; 
if (type & <token> <answer> IRQ_TYPE_EDGE_FALLING) 
chip->irq_trig_fall |= <token> <answer> mask; 
chip->irq_trig_fall <token> ~mask; <answer> &= 
<token> (type & IRQ_TYPE_EDGE_RISING) <answer> if 
<token> |= mask; <answer> chip->irq_trig_raise 
chip->irq_trig_raise &= <token> <answer> ~mask; 
return <token> <answer> 0; 
static int max732x_irq_set_wake(struct <token> *data, unsigned int on) <answer> irq_data 
struct max732x_chip *chip <token> irq_data_get_irq_chip_data(data); <answer> = 
irq_set_irq_wake(chip->client->irq, <token> <answer> on); 
<token> 0; <answer> return 
static const struct irq_chip max732x_irq_chip = <token> <answer> { 
.name = <token> <answer> "max732x", 
.irq_mask <token> max732x_irq_mask, <answer> = 
<token> = max732x_irq_unmask, <answer> .irq_unmask 
<token> = max732x_irq_bus_lock, <answer> .irq_bus_lock 
<token> = max732x_irq_bus_sync_unlock, <answer> .irq_bus_sync_unlock 
.irq_set_type <token> max732x_irq_set_type, <answer> = 
<token> = max732x_irq_set_wake, <answer> .irq_set_wake 
.flags <token> IRQCHIP_IMMUTABLE, <answer> = 
static uint8_t max732x_irq_pending(struct max732x_chip <token> <answer> *chip) 
<token> cur_stat; <answer> uint8_t 
<token> old_stat; <answer> uint8_t 
<token> trigger; <answer> uint8_t 
<token> pending; <answer> uint8_t 
uint16_t <token> <answer> status; 
int <token> <answer> ret; 
ret = max732x_readw(chip, <token> <answer> &status); 
if <token> <answer> (ret) 
<token> 0; <answer> return 
trigger = status >> <token> <answer> 8; 
trigger <token> chip->irq_mask; <answer> &= 
if <token> <answer> (!trigger) 
<token> 0; <answer> return 
<token> = status & 0xFF; <answer> cur_stat 
cur_stat &= <token> <answer> chip->irq_mask; 
old_stat = cur_stat ^ <token> <answer> trigger; 
pending = <token> & chip->irq_trig_fall) | <answer> (old_stat 
(cur_stat <token> chip->irq_trig_raise); <answer> & 
pending &= <token> <answer> trigger; 
<token> pending; <answer> return 
static irqreturn_t <token> irq, void *devid) <answer> max732x_irq_handler(int 
struct <token> *chip = devid; <answer> max732x_chip 
<token> pending; <answer> uint8_t 
uint8_t <token> <answer> level; 
pending <token> max732x_irq_pending(chip); <answer> = 
if <token> <answer> (!pending) 
<token> IRQ_HANDLED; <answer> return 
do <token> <answer> { 
level = <token> <answer> __ffs(pending); 
pending <token> ~(1 << level); <answer> &= 
} <token> (pending); <answer> while 
return <token> <answer> IRQ_HANDLED; 
static int max732x_irq_setup(struct max732x_chip <token> <answer> *chip, 
const struct <token> *id) <answer> i2c_device_id 
<token> i2c_client *client = chip->client; <answer> struct 
int has_irq = max732x_features[id->driver_data] <token> 32; <answer> >> 
<token> irq_base = 0; <answer> int 
int <token> <answer> ret; 
if (client->irq && has_irq != <token> { <answer> INT_NONE) 
struct <token> *girq; <answer> gpio_irq_chip 
chip->irq_features <token> has_irq; <answer> = 
ret <token> devm_request_threaded_irq(&client->dev, client->irq, <answer> = 
NULL, max732x_irq_handler, <token> | <answer> IRQF_ONESHOT 
<token> | IRQF_SHARED, <answer> IRQF_TRIGGER_FALLING 
dev_name(&client->dev), <token> <answer> chip); 
if <token> { <answer> (ret) 
<token> "failed to request irq %d\n", <answer> dev_err(&client->dev, 
return <token> <answer> ret; 
<token> = &chip->gpio_chip.irq; <answer> girq 
<token> &max732x_irq_chip); <answer> gpio_irq_chip_set_chip(girq, 
static void __exit <token> <answer> max732x_exit(void) 
MODULE_AUTHOR("Eric Miao <token> <answer> <eric.miao@marvell.com>"); 
MODULE_DESCRIPTION("GPIO <token> driver for MAX732X"); <answer> expander 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/io.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/videodev2.h> <answer> #include 
#include <token> <answer> <linux/kthread.h> 
#include <token> <answer> <media/v4l2-device.h> 
#include <token> <answer> <media/v4l2-ioctl.h> 
<token> <media/v4l2-ctrls.h> <answer> #include 
#include <token> <answer> <media/v4l2-fh.h> 
<token> <media/v4l2-event.h> <answer> #include 
<token> <sound/aci.h> <answer> #include 
return i <token> byte : -1; <answer> ? 
<token> int rds_rawwrite(struct snd_miro_aci *aci, u8 byte) <answer> static 
if (rds_waitread(aci) >= <token> { <answer> 0) 
outb(byte, aci->aci_port + <token> <answer> ACI_REG_RDS); 
return <token> <answer> 0; 
<token> -1; <answer> return 
static int rds_write(struct snd_miro_aci *aci, <token> byte) <answer> u8 
<token> sendbuffer[8]; <answer> u8 
int <token> <answer> i; 
for (i = 7; i >= <token> i--) <answer> 0; 
sendbuffer[7 - i] = (byte & (1 << i)) ? RDS_DATAMASK <token> 0; <answer> : 
sendbuffer[0] <token> RDS_CLOCKMASK; <answer> |= 
for (i <token> 0; i < 8; i++) <answer> = 
<token> sendbuffer[i]); <answer> rds_rawwrite(aci, 
<token> 0; <answer> return 
static int rds_readcycle_nowait(struct snd_miro_aci <token> <answer> *aci) 
outb(0, <token> + ACI_REG_RDS); <answer> aci->aci_port 
return <token> <answer> rds_waitread(aci); 
static <token> rds_readcycle(struct snd_miro_aci *aci) <answer> int 
if (rds_rawwrite(aci, <token> < 0) <answer> 0) 
<token> -1; <answer> return 
return <token> <answer> rds_waitread(aci); 
<token> int rds_ack(struct snd_miro_aci *aci) <answer> static 
<token> i = rds_readcycle(aci); <answer> int 
if (i <token> 0) <answer> < 
return <token> <answer> -1; 
if <token> & RDS_DATAMASK) <answer> (i 
<token> (rds_waitread(aci) < 0) <answer> if 
return <token> <answer> -1; 
<token> 0, datasize); <answer> memset(databuffer, 
for (i = 0; i < 8 * <token> i++) { <answer> datasize; 
j = <token> <answer> rds_readcycle_nowait(aci); 
if (j < <token> <answer> 0) 
<token> -EIO; <answer> return 
databuffer[i / 8] |= RDS_DATA(j) << (7 - <token> % 8)); <answer> (i 
return <token> <answer> 0; 
static int pcm20_setfreq(struct pcm20 <token> unsigned long freq) <answer> *dev, 
<token> char freql; <answer> unsigned 
unsigned char <token> <answer> freqh; 
struct snd_miro_aci *aci <token> dev->aci; <answer> = 
<token> /= 160; <answer> freq 
if (!(aci->aci_version == 0x07 || aci->aci_version <token> 0xb0)) <answer> >= 
<token> = freq & 0xff; <answer> freql 
freqh <token> freq >> 8; <answer> = 
rds_cmd(aci, <token> NULL, 0); <answer> RDS_RESET, 
return snd_aci_cmd(aci, ACI_WRITE_TUNE, freql, <token> <answer> freqh); 
static int vidioc_querycap(struct file *file, void <token> <answer> *priv, 
struct v4l2_capability <token> <answer> *v) 
strscpy(v->driver, <token> PCM20", sizeof(v->driver)); <answer> "Miro 
strscpy(v->card, "Miro PCM20", <token> <answer> sizeof(v->card)); 
<token> "ISA:radio-miropcm20", sizeof(v->bus_info)); <answer> strscpy(v->bus_info, 
<token> 0; <answer> return 
static <token> sanitize(char *p, int size) <answer> bool 
int <token> <answer> i; 
bool ret <token> true; <answer> = 
for (i = 0; i < size; i++) <token> <answer> { 
if <token> < 32) { <answer> (p[i] 
p[i] = <token> '; <answer> ' 
ret <token> false; <answer> = 
<token> ret; <answer> return 
static int vidioc_g_tuner(struct file *file, <token> *priv, <answer> void 
struct v4l2_tuner <token> <answer> *v) 
struct <token> *dev = video_drvdata(file); <answer> pcm20 
<token> res; <answer> int 
<token> buf; <answer> u8 
<token> (v->index) <answer> if 
return <token> <answer> -EINVAL; 
strscpy(v->name, "FM", <token> <answer> sizeof(v->name)); 
v->type <token> V4L2_TUNER_RADIO; <answer> = 
v->rangelow = <token> <answer> 87*16000; 
v->rangehigh <token> 108*16000; <answer> = 
res = snd_aci_cmd(dev->aci, ACI_READ_TUNERSTATION, -1, <token> <answer> -1); 
v->signal <token> (res & 0x80) ? 0 : 0xffff; <answer> = 
res = <token> ACI_READ_TUNERSTEREO, -1, -1); <answer> snd_aci_cmd(dev->aci, 
v->rxsubchans <token> (res & 0x40) ? V4L2_TUNER_SUB_MONO : <answer> = 
v->capability = V4L2_TUNER_CAP_LOW | V4L2_TUNER_CAP_STEREO <token> <answer> | 
<token> | V4L2_TUNER_CAP_RDS_CONTROLS; <answer> V4L2_TUNER_CAP_RDS 
v->audmode <token> dev->audmode; <answer> = 
<token> = rds_cmd(dev->aci, RDS_RXVALUE, &buf, 1); <answer> res 
<token> (res >= 0 && buf) <answer> if 
v->rxsubchans |= <token> <answer> V4L2_TUNER_SUB_RDS; 
<token> 0; <answer> return 
static int vidioc_s_tuner(struct file <token> void *priv, <answer> *file, 
const <token> v4l2_tuner *v) <answer> struct 
struct pcm20 *dev = <token> <answer> video_drvdata(file); 
if <token> <answer> (v->index) 
<token> -EINVAL; <answer> return 
if (v->audmode <token> V4L2_TUNER_MODE_STEREO) <answer> > 
dev->audmode <token> V4L2_TUNER_MODE_STEREO; <answer> = 
dev->audmode = <token> <answer> v->audmode; 
snd_aci_cmd(dev->aci, <token> <answer> ACI_SET_TUNERMONO, 
dev->audmode == <token> -1); <answer> V4L2_TUNER_MODE_MONO, 
<token> 0; <answer> return 
static int vidioc_g_frequency(struct file *file, void <token> <answer> *priv, 
struct v4l2_frequency <token> <answer> *f) 
<token> pcm20 *dev = video_drvdata(file); <answer> struct 
<token> (f->tuner != 0) <answer> if 
return <token> <answer> -EINVAL; 
f->type <token> V4L2_TUNER_RADIO; <answer> = 
f->frequency <token> dev->freq; <answer> = 
return <token> <answer> 0; 
static int vidioc_s_frequency(struct <token> *file, void *priv, <answer> file 
<token> struct v4l2_frequency *f) <answer> const 
struct pcm20 *dev <token> video_drvdata(file); <answer> = 
if (f->tuner != 0 || <token> != V4L2_TUNER_RADIO) <answer> f->type 
return <token> <answer> -EINVAL; 
dev->freq = clamp_t(u32, f->frequency, 87 * 16000U, 108 * <token> <answer> 16000U); 
pcm20_setfreq(dev, <token> <answer> dev->freq); 
<token> 0; <answer> return 
static int pcm20_s_ctrl(struct <token> *ctrl) <answer> v4l2_ctrl 
struct pcm20 *dev = container_of(ctrl->handler, <token> pcm20, ctrl_handler); <answer> struct 
<token> (ctrl->id) { <answer> switch 
<token> V4L2_CID_AUDIO_MUTE: <answer> case 
snd_aci_cmd(dev->aci, ACI_SET_TUNERMUTE, ctrl->val, <token> <answer> -1); 
<token> 0; <answer> return 
return <token> <answer> -EINVAL; 
static <token> pcm20_thread(void *data) <answer> int 
struct pcm20 *dev <token> data; <answer> = 
const unsigned no_rds_start_counter <token> 5; <answer> = 
const unsigned sleep_msecs <token> 2000; <answer> = 
unsigned no_rds_counter = <token> <answer> no_rds_start_counter; 
for <token> { <answer> (;;) 
char <token> <answer> text_buffer[66]; 
<token> buf; <answer> u8 
int <token> <answer> res; 
<token> (kthread_should_stop()) <answer> if 
res = rds_cmd(dev->aci, RDS_RXVALUE, <token> 1); <answer> &buf, 
if <token> <answer> (res) 
if <token> == 0) { <answer> (buf 
<token> (no_rds_counter == 0) <answer> if 
if <token> <answer> (no_rds_counter) 
<token> ""); <answer> v4l2_ctrl_s_ctrl_string(dev->rds_ps_name, 
<token> 1); <answer> v4l2_ctrl_s_ctrl(dev->rds_ms, 
<token> 0); <answer> v4l2_ctrl_s_ctrl(dev->rds_ta, 
<token> 0); <answer> v4l2_ctrl_s_ctrl(dev->rds_tp, 
<token> 0); <answer> v4l2_ctrl_s_ctrl(dev->rds_pty, 
<token> ""); <answer> v4l2_ctrl_s_ctrl_string(dev->rds_radio_test, 
<token> = no_rds_start_counter; <answer> no_rds_counter 
res = rds_cmd(dev->aci, RDS_STATUS, &buf, <token> <answer> 1); 
if <token> <answer> (res) 
if ((buf >> <token> & 1) { <answer> 3) 
res = rds_cmd(dev->aci, <token> text_buffer, 8); <answer> RDS_STATIONNAME, 
text_buffer[8] = <token> <answer> 0; 
if (!res && sanitize(text_buffer, <token> <answer> 8)) 
<token> text_buffer); <answer> v4l2_ctrl_s_ctrl_string(dev->rds_ps_name, 
<token> ((buf >> 6) & 1) { <answer> if 
<token> pty; <answer> u8 
res = rds_cmd(dev->aci, RDS_PTYTATP, &pty, <token> <answer> 1); 
<token> (!res) { <answer> if 
v4l2_ctrl_s_ctrl(dev->rds_ms, !!(pty & <token> <answer> 0x01)); 
v4l2_ctrl_s_ctrl(dev->rds_ta, <token> & 0x02)); <answer> !!(pty 
v4l2_ctrl_s_ctrl(dev->rds_tp, !!(pty <token> 0x80)); <answer> & 
<token> (pty >> 2) & 0x1f); <answer> v4l2_ctrl_s_ctrl(dev->rds_pty, 
if ((buf >> 4) & <token> { <answer> 1) 
res = <token> RDS_TEXT, text_buffer, 65); <answer> rds_cmd(dev->aci, 
text_buffer[65] <token> 0; <answer> = 
if (!res && sanitize(text_buffer <token> 1, 64)) <answer> + 
v4l2_ctrl_s_ctrl_string(dev->rds_radio_test, text_buffer <token> 1); <answer> + 
<token> 0; <answer> return 
static int <token> file *file) <answer> pcm20_open(struct 
struct pcm20 <token> = video_drvdata(file); <answer> *dev 
int <token> = v4l2_fh_open(file); <answer> res 
if (!res <token> v4l2_fh_is_singular_file(file) && <answer> && 
IS_ERR_OR_NULL(dev->kthread)) <token> <answer> { 
dev->kthread = kthread_run(pcm20_thread, <token> "%s", <answer> dev, 
if (IS_ERR(dev->kthread)) <token> <answer> { 
<token> "kernel_thread() failed\n"); <answer> v4l2_err(&dev->v4l2_dev, 
return <token> <answer> PTR_ERR(dev->kthread); 
<token> res; <answer> return 
static <token> pcm20_release(struct file *file) <answer> int 
struct pcm20 *dev <token> video_drvdata(file); <answer> = 
if (v4l2_fh_is_singular_file(file) <token> !IS_ERR_OR_NULL(dev->kthread)) { <answer> && 
dev->kthread = <token> <answer> NULL; 
<token> v4l2_fh_release(file); <answer> return 
static <token> struct v4l2_file_operations pcm20_fops = { <answer> const 
.owner <token> THIS_MODULE, <answer> = 
<token> = pcm20_open, <answer> .open 
.poll <token> v4l2_ctrl_poll, <answer> = 
.release = <token> <answer> pcm20_release, 
<token> = video_ioctl2, <answer> .unlocked_ioctl 
static const struct <token> pcm20_ioctl_ops = { <answer> v4l2_ioctl_ops 
<token> = vidioc_querycap, <answer> .vidioc_querycap 
.vidioc_g_tuner <token> vidioc_g_tuner, <answer> = 
.vidioc_s_tuner <token> vidioc_s_tuner, <answer> = 
<token> = vidioc_g_frequency, <answer> .vidioc_g_frequency 
.vidioc_s_frequency = <token> <answer> vidioc_s_frequency, 
<token> = v4l2_ctrl_log_status, <answer> .vidioc_log_status 
.vidioc_subscribe_event <token> v4l2_ctrl_subscribe_event, <answer> = 
<token> = v4l2_event_unsubscribe, <answer> .vidioc_unsubscribe_event 
static <token> struct v4l2_ctrl_ops pcm20_ctrl_ops = { <answer> const 
.s_ctrl <token> pcm20_s_ctrl, <answer> = 
<token> int __init pcm20_init(void) <answer> static 
struct pcm20 *dev = <token> <answer> &pcm20_card; 
struct v4l2_device *v4l2_dev <token> &dev->v4l2_dev; <answer> = 
<token> v4l2_ctrl_handler *hdl; <answer> struct 
int <token> <answer> res; 
<token> = snd_aci_get_aci(); <answer> dev->aci 
if <token> == NULL) { <answer> (dev->aci 
"you must <token> the snd-miro driver first!\n"); <answer> load 
<token> -ENODEV; <answer> return 
<token> "radio-miropcm20", sizeof(v4l2_dev->name)); <answer> strscpy(v4l2_dev->name, 
res = <token> v4l2_dev); <answer> v4l2_device_register(NULL, 
if (res < <token> { <answer> 0) 
v4l2_err(v4l2_dev, "could <token> register v4l2_device\n"); <answer> not 
<token> -EINVAL; <answer> return 
<token> = &dev->ctrl_handler; <answer> hdl 
v4l2_ctrl_handler_init(hdl, <token> <answer> 7); 
<token> &pcm20_ctrl_ops, <answer> v4l2_ctrl_new_std(hdl, 
V4L2_CID_AUDIO_MUTE, 0, 1, 1, <token> <answer> 1); 
<token> = v4l2_ctrl_new_std(hdl, NULL, <answer> dev->rds_pty 
<token> 0, 0x1f, 1, 0); <answer> V4L2_CID_RDS_RX_PTY, 
<token> = v4l2_ctrl_new_std(hdl, NULL, <answer> dev->rds_ps_name 
V4L2_CID_RDS_RX_PS_NAME, 0, 8, <token> 0); <answer> 8, 
<token> = v4l2_ctrl_new_std(hdl, NULL, <answer> dev->rds_radio_test 
V4L2_CID_RDS_RX_RADIO_TEXT, 0, 64, <token> 0); <answer> 64, 
<token> = v4l2_ctrl_new_std(hdl, NULL, <answer> dev->rds_ta 
V4L2_CID_RDS_RX_TRAFFIC_ANNOUNCEMENT, <token> 1, 1, 0); <answer> 0, 
dev->rds_tp = v4l2_ctrl_new_std(hdl, <token> <answer> NULL, 
V4L2_CID_RDS_RX_TRAFFIC_PROGRAM, 0, 1, <token> 0); <answer> 1, 
dev->rds_ms = v4l2_ctrl_new_std(hdl, <token> <answer> NULL, 
V4L2_CID_RDS_RX_MUSIC_SPEECH, 0, 1, <token> 1); <answer> 1, 
v4l2_dev->ctrl_handler = <token> <answer> hdl; 
if <token> { <answer> (hdl->error) 
res = <token> <answer> hdl->error; 
v4l2_err(v4l2_dev, "Could <token> register control\n"); <answer> not 
<token> err_hdl; <answer> goto 
strscpy(dev->vdev.name, v4l2_dev->name, <token> <answer> sizeof(dev->vdev.name)); 
<token> = v4l2_dev; <answer> dev->vdev.v4l2_dev 
dev->vdev.fops <token> &pcm20_fops; <answer> = 
dev->vdev.ioctl_ops <token> &pcm20_ioctl_ops; <answer> = 
dev->vdev.release <token> video_device_release_empty; <answer> = 
dev->vdev.lock = <token> <answer> &dev->lock; 
dev->vdev.device_caps = V4L2_CAP_TUNER | <token> | <answer> V4L2_CAP_RADIO 
<token> dev); <answer> video_set_drvdata(&dev->vdev, 
snd_aci_cmd(dev->aci, <token> <answer> ACI_SET_TUNERMONO, 
dev->audmode <token> V4L2_TUNER_MODE_MONO, -1); <answer> == 
pcm20_setfreq(dev, <token> <answer> dev->freq); 
if (video_register_device(&dev->vdev, VFL_TYPE_RADIO, radio_nr) <token> 0) <answer> < 
<token> err_hdl; <answer> goto 
v4l2_info(v4l2_dev, <token> PCM20 Radio tuner\n"); <answer> "Mirosound 
<token> 0; <answer> return 
return <token> <answer> -EINVAL; 
<token> Reitsma, Krzysztof Helt"); <answer> MODULE_AUTHOR("Ruurd 
MODULE_DESCRIPTION("A driver <token> the Miro PCM20 radio card."); <answer> for 
static void <token> pcm20_cleanup(void) <answer> __exit 
struct <token> *dev = &pcm20_card; <answer> pcm20 
<token> ACI_SET_TUNERMUTE, 1, -1); <answer> snd_aci_cmd(dev->aci, 
<token> "devl_internal.h" <answer> #include 
struct devlink_linecard <token> <answer> { 
struct list_head <token> <answer> list; 
struct devlink <token> <answer> *devlink; 
unsigned <token> index; <answer> int 
const struct devlink_linecard_ops <token> <answer> *ops; 
void <token> <answer> *priv; 
<token> devlink_linecard_state state; <answer> enum 
if (ops->same_provision <token> <answer> && 
<token> linecard->priv, <answer> ops->same_provision(linecard, 
<token> = 0; <answer> err 
goto <token> <answer> out; 
linecard->state = <token> <answer> DEVLINK_LINECARD_STATE_PROVISIONING; 
linecard->type = <token> <answer> linecard_type->type; 
devlink_linecard_notify(linecard, <token> <answer> DEVLINK_CMD_LINECARD_NEW); 
<token> = ops->provision(linecard, linecard->priv, linecard_type->type, <answer> err 
linecard_type->priv, <token> <answer> extack); 
<token> (err) { <answer> if 
linecard->state = <token> <answer> DEVLINK_LINECARD_STATE_UNPROVISIONED; 
linecard->type = <token> <answer> NULL; 
devlink_linecard_notify(linecard, <token> <answer> DEVLINK_CMD_LINECARD_NEW); 
<token> err; <answer> return 
return <token> <answer> err; 
static int devlink_linecard_type_unset(struct devlink_linecard <token> <answer> *linecard, 
struct <token> *extack) <answer> netlink_ext_ack 
int <token> <answer> err; 
<token> (linecard->state == DEVLINK_LINECARD_STATE_PROVISIONING) { <answer> if 
NL_SET_ERR_MSG(extack, "Line card is <token> being provisioned"); <answer> currently 
err <token> -EBUSY; <answer> = 
<token> out; <answer> goto 
if (linecard->state <token> DEVLINK_LINECARD_STATE_UNPROVISIONING) { <answer> == 
NL_SET_ERR_MSG(extack, "Line card is currently being <token> <answer> unprovisioned"); 
err <token> -EBUSY; <answer> = 
<token> out; <answer> goto 
if (linecard->state <token> DEVLINK_LINECARD_STATE_PROVISIONING_FAILED) { <answer> == 
linecard->state = <token> <answer> DEVLINK_LINECARD_STATE_UNPROVISIONED; 
linecard->type = <token> <answer> NULL; 
<token> DEVLINK_CMD_LINECARD_NEW); <answer> devlink_linecard_notify(linecard, 
err = <token> <answer> 0; 
goto <token> <answer> out; 
if (linecard->state <token> DEVLINK_LINECARD_STATE_UNPROVISIONED) { <answer> == 
NL_SET_ERR_MSG(extack, <token> card is not provisioned"); <answer> "Line 
err = <token> <answer> 0; 
<token> out; <answer> goto 
linecard->state <token> DEVLINK_LINECARD_STATE_UNPROVISIONING; <answer> = 
devlink_linecard_notify(linecard, <token> <answer> DEVLINK_CMD_LINECARD_NEW); 
err = linecard->ops->unprovision(linecard, <token> <answer> linecard->priv, 
<token> (err) { <answer> if 
linecard->state = <token> <answer> DEVLINK_LINECARD_STATE_UNPROVISIONED; 
linecard->type <token> NULL; <answer> = 
devlink_linecard_notify(linecard, <token> <answer> DEVLINK_CMD_LINECARD_NEW); 
<token> err; <answer> return 
return <token> <answer> err; 
int devlink_nl_linecard_set_doit(struct sk_buff *skb, struct <token> *info) <answer> genl_info 
<token> netlink_ext_ack *extack = info->extack; <answer> struct 
<token> devlink *devlink = info->user_ptr[0]; <answer> struct 
struct devlink_linecard <token> <answer> *linecard; 
int <token> <answer> err; 
<token> = devlink_linecard_get_from_info(devlink, info); <answer> linecard 
if <token> <answer> (IS_ERR(linecard)) 
return <token> <answer> PTR_ERR(linecard); 
if (info->attrs[DEVLINK_ATTR_LINECARD_TYPE]) <token> <answer> { 
const <token> *type; <answer> char 
type = <token> <answer> nla_data(info->attrs[DEVLINK_ATTR_LINECARD_TYPE]); 
if (strcmp(type, "")) <token> <answer> { 
err = <token> type, extack); <answer> devlink_linecard_type_set(linecard, 
<token> (err) <answer> if 
return <token> <answer> err; 
} <token> { <answer> else 
err = <token> extack); <answer> devlink_linecard_type_unset(linecard, 
<token> (err) <answer> if 
<token> err; <answer> return 
<token> 0; <answer> return 
static int <token> devlink_linecard *linecard) <answer> devlink_linecard_types_init(struct 
struct <token> *linecard_type; <answer> devlink_linecard_type 
unsigned <token> count; <answer> int 
<token> i; <answer> int 
count = <token> linecard->priv); <answer> linecard->ops->types_count(linecard, 
linecard->types = kmalloc_array(count, <token> <answer> sizeof(*linecard_type), 
<token> (!linecard->types) <answer> if 
<token> -ENOMEM; <answer> return 
<token> = count; <answer> linecard->types_count 
for <token> = 0; i < count; i++) { <answer> (i 
<token> = &linecard->types[i]; <answer> linecard_type 
linecard->ops->types_get(linecard, linecard->priv, <token> <answer> i, 
return <token> <answer> 0; 
static void devlink_linecard_types_fini(struct <token> *linecard) <answer> devlink_linecard 
<token> devlink_linecard * <answer> struct 
devl_linecard_create(struct devlink *devlink, unsigned int <token> <answer> linecard_index, 
const struct devlink_linecard_ops <token> void *priv) <answer> *ops, 
struct devlink_linecard <token> <answer> *linecard; 
int <token> <answer> err; 
if <token> || !ops->provision || !ops->unprovision || <answer> (WARN_ON(!ops 
!ops->types_count || <token> <answer> !ops->types_get)) 
return <token> <answer> ERR_PTR(-EINVAL); 
<token> (devlink_linecard_index_exists(devlink, linecard_index)) <answer> if 
<token> ERR_PTR(-EEXIST); <answer> return 
linecard <token> kzalloc(sizeof(*linecard), GFP_KERNEL); <answer> = 
if <token> <answer> (!linecard) 
<token> ERR_PTR(-ENOMEM); <answer> return 
linecard->devlink = <token> <answer> devlink; 
linecard->index = <token> <answer> linecard_index; 
<token> = ops; <answer> linecard->ops 
<token> = priv; <answer> linecard->priv 
<token> = DEVLINK_LINECARD_STATE_UNPROVISIONED; <answer> linecard->state 
<token> = devlink_linecard_types_init(linecard); <answer> err 
<token> (err) { <answer> if 
<token> ERR_PTR(err); <answer> return 
<token> &devlink->linecard_list); <answer> list_add_tail(&linecard->list, 
devlink_linecard_notify(linecard, <token> <answer> DEVLINK_CMD_LINECARD_NEW); 
<token> linecard; <answer> return 
void <token> devlink_linecard *linecard) <answer> devl_linecard_destroy(struct 
devlink_linecard_notify(linecard, <token> <answer> DEVLINK_CMD_LINECARD_DEL); 
void devlink_linecard_provision_set(struct devlink_linecard <token> <answer> *linecard, 
const <token> *type) <answer> char 
WARN_ON(linecard->type && <token> type)); <answer> strcmp(linecard->type, 
linecard->state <token> DEVLINK_LINECARD_STATE_PROVISIONED; <answer> = 
<token> = type; <answer> linecard->type 
<token> DEVLINK_CMD_LINECARD_NEW); <answer> devlink_linecard_notify(linecard, 
void devlink_linecard_provision_clear(struct devlink_linecard <token> <answer> *linecard) 
<token> = DEVLINK_LINECARD_STATE_UNPROVISIONED; <answer> linecard->state 
linecard->type <token> NULL; <answer> = 
<token> DEVLINK_CMD_LINECARD_NEW); <answer> devlink_linecard_notify(linecard, 
void <token> devlink_linecard *linecard) <answer> devlink_linecard_provision_fail(struct 
linecard->state = <token> <answer> DEVLINK_LINECARD_STATE_PROVISIONING_FAILED; 
devlink_linecard_notify(linecard, <token> <answer> DEVLINK_CMD_LINECARD_NEW); 
void devlink_linecard_activate(struct devlink_linecard <token> <answer> *linecard) 
WARN_ON(linecard->state <token> DEVLINK_LINECARD_STATE_PROVISIONED); <answer> != 
linecard->state <token> DEVLINK_LINECARD_STATE_ACTIVE; <answer> = 
devlink_linecard_notify(linecard, <token> <answer> DEVLINK_CMD_LINECARD_NEW); 
void <token> devlink_linecard *linecard) <answer> devlink_linecard_deactivate(struct 
<token> (linecard->state) { <answer> switch 
<token> DEVLINK_LINECARD_STATE_ACTIVE: <answer> case 
<token> = DEVLINK_LINECARD_STATE_PROVISIONED; <answer> linecard->state 
<token> DEVLINK_CMD_LINECARD_NEW); <answer> devlink_linecard_notify(linecard, 
case <token> <answer> DEVLINK_LINECARD_STATE_UNPROVISIONING: 
static void devlink_linecard_rel_notify_cb(struct devlink <token> <answer> *devlink, 
<token> linecard_index) <answer> u32 
<token> devlink_linecard *linecard; <answer> struct 
linecard = <token> linecard_index); <answer> devlink_linecard_get_by_index(devlink, 
if <token> <answer> (!linecard) 
devlink_linecard_notify(linecard, <token> <answer> DEVLINK_CMD_LINECARD_NEW); 
static void devlink_linecard_rel_cleanup_cb(struct <token> *devlink, <answer> devlink 
u32 linecard_index, u32 <token> <answer> rel_index) 
struct <token> *linecard; <answer> devlink_linecard 
linecard = devlink_linecard_get_by_index(devlink, <token> <answer> linecard_index); 
if (linecard <token> linecard->rel_index == rel_index) <answer> && 
linecard->rel_index = <token> <answer> 0; 
int <token> devlink_linecard *linecard, <answer> devlink_linecard_nested_dl_set(struct 
struct devlink <token> <answer> *nested_devlink) 
<token> devlink_rel_nested_in_add(&linecard->rel_index, <answer> return 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
<token> <linux/types.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/wait.h> 
<token> <linux/uaccess.h> <answer> #include 
<token> <linux/i2c.h> <answer> #include 
#include <token> <answer> <linux/videodev2.h> 
<token> <media/v4l2-device.h> <answer> #include 
#include <token> <answer> <media/v4l2-ctrls.h> 
<token> SAA7110 video decoder driver"); <answer> MODULE_DESCRIPTION("Philips 
MODULE_AUTHOR("Pauline <token> <answer> Middelink"); 
static <token> debug; <answer> int 
module_param(debug, <token> 0); <answer> int, 
MODULE_PARM_DESC(debug, "Debug level <token> <answer> (0-1)"); 
if (i2c_check_functionality(client->adapter, I2C_FUNC_I2C)) <token> <answer> { 
ret = i2c_master_send(client, <token> len); <answer> data, 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/init.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/ioport.h> <answer> #include 
<token> <linux/serial_core.h> <answer> #include 
#include <token> <answer> <linux/serial_s3c.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/reboot.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
<token> <linux/clk/samsung.h> <answer> #include 
#include <token> <answer> <linux/dma-mapping.h> 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/irqchip/arm-vic.h> 
#include <token> <answer> <clocksource/samsung_pwm.h> 
<token> <asm/mach/arch.h> <answer> #include 
#include <token> <answer> <asm/mach/map.h> 
#include <token> <answer> <asm/system_misc.h> 
<token> "map.h" <answer> #include 
<token> "irqs.h" <answer> #include 
#include <token> <answer> "regs-gpio.h" 
#include <token> <answer> "gpio-samsung.h" 
#include <token> <answer> "cpu.h" 
#include <token> <answer> "devs.h" 
<token> "pm.h" <answer> #include 
<token> "gpio-cfg.h" <answer> #include 
#include <token> <answer> "pwm-core.h" 
#include <token> <answer> "regs-irqtype.h" 
#include <token> <answer> "s3c64xx.h" 
<token> "irq-uart-s3c64xx.h" <answer> #include 
#define UART_OFFS (S3C_PA_UART <token> 0xfffff) <answer> & 
static struct map_desc s3c_iodesc[] <token> = { <answer> __initdata 
.virtual = (unsigned <token> <answer> long)S3C_VA_SYS, 
<token> = __phys_to_pfn(S3C64XX_PA_SYSCON), <answer> .pfn 
<token> = SZ_4K, <answer> .length 
<token> = MT_DEVICE, <answer> .type 
}, <token> <answer> { 
.virtual <token> (unsigned long)S3C_VA_MEM, <answer> = 
<token> = __phys_to_pfn(S3C64XX_PA_SROM), <answer> .pfn 
<token> = SZ_4K, <answer> .length 
.type <token> MT_DEVICE, <answer> = 
}, <token> <answer> { 
.virtual = (unsigned <token> + UART_OFFS), <answer> long)(S3C_VA_UART 
.pfn <token> __phys_to_pfn(S3C_PA_UART), <answer> = 
<token> = SZ_4K, <answer> .length 
.type = <token> <answer> MT_DEVICE, 
<token> { <answer> }, 
.virtual = (unsigned <token> <answer> long)VA_VIC0, 
.pfn <token> __phys_to_pfn(S3C64XX_PA_VIC0), <answer> = 
.length = <token> <answer> SZ_16K, 
<token> = MT_DEVICE, <answer> .type 
}, <token> <answer> { 
<token> = (unsigned long)VA_VIC1, <answer> .virtual 
<token> = __phys_to_pfn(S3C64XX_PA_VIC1), <answer> .pfn 
.length = <token> <answer> SZ_16K, 
.type = <token> <answer> MT_DEVICE, 
}, <token> <answer> { 
.virtual <token> (unsigned long)S3C_VA_TIMER, <answer> = 
<token> = __phys_to_pfn(S3C_PA_TIMER), <answer> .pfn 
.length = <token> <answer> SZ_16K, 
<token> = MT_DEVICE, <answer> .type 
<token> { <answer> }, 
.virtual = <token> long)S3C64XX_VA_GPIO, <answer> (unsigned 
.pfn = <token> <answer> __phys_to_pfn(S3C64XX_PA_GPIO), 
.length <token> SZ_4K, <answer> = 
.type <token> MT_DEVICE, <answer> = 
}, <token> <answer> { 
.virtual <token> (unsigned long)S3C64XX_VA_MODEM, <answer> = 
.pfn = <token> <answer> __phys_to_pfn(S3C64XX_PA_MODEM), 
.length = <token> <answer> SZ_4K, 
.type = <token> <answer> MT_DEVICE, 
}, <token> <answer> { 
.virtual = (unsigned <token> <answer> long)S3C_VA_WATCHDOG, 
<token> = __phys_to_pfn(S3C64XX_PA_WATCHDOG), <answer> .pfn 
<token> = SZ_4K, <answer> .length 
.type <token> MT_DEVICE, <answer> = 
}, <token> <answer> { 
.virtual = <token> long)S3C_VA_USB_HSPHY, <answer> (unsigned 
<token> = __phys_to_pfn(S3C64XX_PA_USB_HSPHY), <answer> .pfn 
<token> = SZ_1K, <answer> .length 
.type <token> MT_DEVICE, <answer> = 
static const struct bus_type <token> = { <answer> s3c64xx_subsys 
<token> = "s3c64xx-core", <answer> .name 
.dev_name <token> "s3c64xx-core", <answer> = 
static struct device <token> = { <answer> s3c64xx_dev 
<token> = &s3c64xx_subsys, <answer> .bus 
static struct samsung_pwm_variant s3c64xx_pwm_variant = <token> <answer> { 
.bits <token> 32, <answer> = 
.div_base <token> 0, <answer> = 
<token> = true, <answer> .has_tint_cstat 
.tclk_mask = (1 << 7) <token> (1 << 6) | (1 << 5), <answer> | 
void __init s3c64xx_set_timer_source(enum s3c64xx_timer_mode <token> <answer> event, 
enum <token> source) <answer> s3c64xx_timer_mode 
s3c64xx_pwm_variant.output_mask = BIT(SAMSUNG_PWM_NUM) - <token> <answer> 1; 
s3c64xx_pwm_variant.output_mask &= ~(BIT(event) | <token> <answer> BIT(source)); 
void __init <token> <answer> s3c64xx_timer_init(void) 
<token> int timer_irqs[SAMSUNG_PWM_NUM] = { <answer> unsigned 
IRQ_TIMER0_VIC, <token> IRQ_TIMER2_VIC, <answer> IRQ_TIMER1_VIC, 
IRQ_TIMER3_VIC, <token> <answer> IRQ_TIMER4_VIC, 
<token> &s3c64xx_pwm_variant); <answer> timer_irqs, 
#define IRQ_VIC0_RESUME (1 << (IRQ_RTC_TIC <token> IRQ_VIC0_BASE)) <answer> - 
#define IRQ_VIC1_RESUME (1 << (IRQ_RTC_ALARM - IRQ_VIC1_BASE) | <token> <answer> \ 
<token> << (IRQ_PENDN - IRQ_VIC1_BASE) | \ <answer> 1 
<token> << (IRQ_HSMMC0 - IRQ_VIC1_BASE) | \ <answer> 1 
1 <token> (IRQ_HSMMC1 - IRQ_VIC1_BASE) | \ <answer> << 
1 <token> (IRQ_HSMMC2 - IRQ_VIC1_BASE)) <answer> << 
void __init s3c64xx_init_irq(u32 vic0_valid, <token> vic1_valid) <answer> u32 
<token> xtal_f, xusbxti_f, soc_is_s3c6400(), S3C_VA_SYS); <answer> s3c64xx_clk_init(NULL, 
<token> "%s: initialising interrupts\n", __func__); <answer> printk(KERN_DEBUG 
static <token> void s3c_irq_demux_eint(unsigned int start, unsigned int end) <answer> inline 
u32 status <token> __raw_readl(S3C64XX_EINT0PEND); <answer> = 
u32 <token> = __raw_readl(S3C64XX_EINT0MASK); <answer> mask 
unsigned <token> irq; <answer> int 
<token> &= ~mask; <answer> status 
status <token> start; <answer> >>= 
status &= (1 << (end - start <token> 1)) - 1; <answer> + 
for (irq = IRQ_EINT(start); irq <= IRQ_EINT(end); irq++) <token> <answer> { 
<token> (status & 1) <answer> if 
status >>= <token> <answer> 1; 
static void s3c_irq_demux_eint0_3(struct <token> *desc) <answer> irq_desc 
<token> 3); <answer> s3c_irq_demux_eint(0, 
static void <token> irq_desc *desc) <answer> s3c_irq_demux_eint4_11(struct 
<token> 11); <answer> s3c_irq_demux_eint(4, 
static <token> s3c_irq_demux_eint12_19(struct irq_desc *desc) <answer> void 
<token> 19); <answer> s3c_irq_demux_eint(12, 
static void s3c_irq_demux_eint20_27(struct irq_desc <token> <answer> *desc) 
s3c_irq_demux_eint(20, <token> <answer> 27); 
static <token> __init s3c64xx_init_irq_eint(void) <answer> int 
<token> irq; <answer> int 
<token> <linux/cpu_pm.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/of_irq.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> "soc.h" 
<token> "iomap.h" <answer> #include 
<token> "common.h" <answer> #include 
#include <token> <answer> "vp.h" 
<token> "prm44xx.h" <answer> #include 
#include <token> <answer> "prcm43xx.h" 
<token> "prm-regbits-44xx.h" <answer> #include 
<token> "prcm44xx.h" <answer> #include 
#include <token> <answer> "prminst44xx.h" 
#include <token> <answer> "powerdomain.h" 
<token> "pm.h" <answer> #include 
<token> struct prm_reset_src_map omap44xx_prm_reset_src_map[] = { <answer> static 
{ <token> <answer> OMAP4430_GLOBAL_WARM_SW_RST_SHIFT, 
OMAP_GLOBAL_WARM_RST_SRC_ID_SHIFT <token> <answer> }, 
<token> OMAP4430_GLOBAL_COLD_RST_SHIFT, <answer> { 
OMAP_GLOBAL_COLD_RST_SRC_ID_SHIFT <token> <answer> }, 
{ <token> <answer> OMAP4430_MPU_SECURITY_VIOL_RST_SHIFT, 
<token> }, <answer> OMAP_SECU_VIOL_RST_SRC_ID_SHIFT 
<token> OMAP4430_MPU_WDT_RST_SHIFT, OMAP_MPU_WD_RST_SRC_ID_SHIFT }, <answer> { 
{ OMAP4430_SECURE_WDT_RST_SHIFT, <token> }, <answer> OMAP_SECU_WD_RST_SRC_ID_SHIFT 
<token> OMAP4430_EXTERNAL_WARM_RST_SHIFT, OMAP_EXTWARM_RST_SRC_ID_SHIFT }, <answer> { 
{ <token> <answer> OMAP4430_VDD_MPU_VOLT_MGR_RST_SHIFT, 
<token> }, <answer> OMAP_VDD_MPU_VM_RST_SRC_ID_SHIFT 
<token> OMAP4430_VDD_IVA_VOLT_MGR_RST_SHIFT, <answer> { 
<token> }, <answer> OMAP_VDD_IVA_VM_RST_SRC_ID_SHIFT 
{ <token> <answer> OMAP4430_VDD_CORE_VOLT_MGR_RST_SHIFT, 
<token> }, <answer> OMAP_VDD_CORE_VM_RST_SRC_ID_SHIFT 
<token> OMAP4430_ICEPICK_RST_SHIFT, OMAP_ICEPICK_RST_SRC_ID_SHIFT }, <answer> { 
{ OMAP4430_C2C_RST_SHIFT, <token> }, <answer> OMAP_C2C_RST_SRC_ID_SHIFT 
{ -1, <token> }, <answer> -1 
struct omap4_vp <token> <answer> { 
u32 <token> <answer> irqstatus_mpu; 
u32 <token> <answer> tranxdone_status; 
static <token> omap4_vp omap4_vp[] = { <answer> struct 
[OMAP4_VP_VDD_MPU_ID] = <token> <answer> { 
.irqstatus_mpu = <token> <answer> OMAP4_PRM_IRQSTATUS_MPU_2_OFFSET, 
.tranxdone_status <token> OMAP4430_VP_MPU_TRANXDONE_ST_MASK, <answer> = 
[OMAP4_VP_VDD_IVA_ID] <token> { <answer> = 
<token> = OMAP4_PRM_IRQSTATUS_MPU_OFFSET, <answer> .irqstatus_mpu 
.tranxdone_status = <token> <answer> OMAP4430_VP_IVA_TRANXDONE_ST_MASK, 
[OMAP4_VP_VDD_CORE_ID] = <token> <answer> { 
.irqstatus_mpu <token> OMAP4_PRM_IRQSTATUS_MPU_OFFSET, <answer> = 
.tranxdone_status = <token> <answer> OMAP4430_VP_CORE_TRANXDONE_ST_MASK, 
<token> u32 omap4_prm_vp_check_txdone(u8 vp_id) <answer> static 
struct omap4_vp <token> = &omap4_vp[vp_id]; <answer> *vp 
<token> irqstatus; <answer> u32 
irqstatus = <token> <answer> omap4_prminst_read_inst_reg(OMAP4430_PRM_PARTITION, 
return irqstatus <token> vp->tranxdone_status; <answer> & 
static void <token> vp_id) <answer> omap4_prm_vp_clear_txdone(u8 
<token> omap4_vp *vp = &omap4_vp[vp_id]; <answer> struct 
u32 omap4_prm_vcvp_read(u8 <token> <answer> offset) 
<token> inst = omap4_prmst_get_prm_dev_inst(); <answer> s32 
<token> (inst == PRM_INSTANCE_UNKNOWN) <answer> if 
return <token> <answer> 0; 
return <token> <answer> omap4_prminst_read_inst_reg(OMAP4430_PRM_PARTITION, 
<token> offset); <answer> inst, 
<token> omap4_prm_vcvp_write(u32 val, u8 offset) <answer> void 
<token> inst = omap4_prmst_get_prm_dev_inst(); <answer> s32 
<token> (inst == PRM_INSTANCE_UNKNOWN) <answer> if 
omap4_prminst_write_inst_reg(val, <token> <answer> OMAP4430_PRM_PARTITION, 
inst, <token> <answer> offset); 
u32 omap4_prm_vcvp_rmw(u32 mask, u32 <token> u8 offset) <answer> bits, 
<token> inst = omap4_prmst_get_prm_dev_inst(); <answer> s32 
if <token> == PRM_INSTANCE_UNKNOWN) <answer> (inst 
<token> 0; <answer> return 
return omap4_prminst_rmw_inst_reg_bits(mask, <token> <answer> bits, 
static inline u32 _read_pending_irq_reg(u16 irqen_offs, <token> irqst_offs) <answer> u16 
u32 <token> st; <answer> mask, 
<token> void omap44xx_prm_read_pending_irqs(unsigned long *events) <answer> static 
int <token> <answer> i; 
for (i = 0; i < <token> i++) <answer> omap4_prcm_irq_setup.nr_regs; 
events[i] = <token> + <answer> _read_pending_irq_reg(omap4_prcm_irq_setup.mask 
i * <token> omap4_prcm_irq_setup.ack + i * 4); <answer> 4, 
<token> void omap44xx_prm_ocp_barrier(void) <answer> static 
static void omap44xx_prm_save_and_clear_irqen(u32 <token> <answer> *saved_mask) 
int <token> <answer> i; 
u16 <token> <answer> reg; 
<token> (i = 0; i < omap4_prcm_irq_setup.nr_regs; i++) { <answer> for 
reg = omap4_prcm_irq_setup.mask + i <token> 4; <answer> * 
saved_mask[i] <token> <answer> = 
omap4_prm_write_inst_reg(0, <token> reg); <answer> OMAP4430_PRM_OCP_SOCKET_INST, 
static <token> omap44xx_prm_restore_irqen(u32 *saved_mask) <answer> void 
int <token> <answer> i; 
for (i <token> 0; i < omap4_prcm_irq_setup.nr_regs; i++) <answer> = 
omap4_prcm_irq_setup.mask + i * <token> <answer> 4); 
static void <token> <answer> omap44xx_prm_reconfigure_io_chain(void) 
int <token> = 0; <answer> i 
s32 inst = <token> <answer> omap4_prmst_get_prm_dev_inst(); 
<token> (inst == PRM_INSTANCE_UNKNOWN) <answer> if 
<token> void omap44xx_prm_enable_io_wakeup(void) <answer> static 
<token> inst = omap4_prmst_get_prm_dev_inst(); <answer> s32 
if (inst <token> PRM_INSTANCE_UNKNOWN) <answer> == 
static u32 <token> <answer> omap44xx_prm_read_reset_sources(void) 
struct <token> *p; <answer> prm_reset_src_map 
u32 <token> = 0; <answer> r 
u32 <token> <answer> v; 
<token> inst = omap4_prmst_get_prm_dev_inst(); <answer> s32 
if (inst == <token> <answer> PRM_INSTANCE_UNKNOWN) 
return <token> <answer> 0; 
v <token> omap4_prm_read_inst_reg(inst, <answer> = 
p = <token> <answer> omap44xx_prm_reset_src_map; 
while <token> >= 0 && p->std_shift >= 0) { <answer> (p->reg_shift 
if <token> & (1 << p->reg_shift)) <answer> (v 
r <token> 1 << p->std_shift; <answer> |= 
return <token> <answer> r; 
static bool omap44xx_prm_was_any_context_lost_old(u8 part, <token> inst, u16 idx) <answer> s16 
return (omap4_prminst_read_inst_reg(part, inst, idx)) ? 1 : <token> <answer> 0; 
static void omap44xx_prm_clear_context_loss_flags_old(u8 part, <token> inst, <answer> s16 
u16 <token> <answer> idx) 
omap4_prminst_write_inst_reg(0xffffffff, <token> inst, idx); <answer> part, 
static int omap4_pwrdm_read_prev_logic_pwrst(struct powerdomain <token> <answer> *pwrdm) 
int <token> <answer> state; 
<token> = omap4_pwrdm_read_prev_pwrst(pwrdm); <answer> state 
if (state <token> PWRDM_POWER_OFF) <answer> == 
return <token> <answer> PWRDM_POWER_OFF; 
if (state != <token> <answer> PWRDM_POWER_RET) 
return <token> <answer> PWRDM_POWER_RET; 
return <token> <answer> omap4_pwrdm_read_logic_retst(pwrdm); 
static <token> omap4_pwrdm_read_mem_pwrst(struct powerdomain *pwrdm, u8 bank) <answer> int 
u32 m, <token> <answer> v; 
<token> = omap2_pwrdm_get_mem_bank_stst_mask(bank); <answer> m 
v <token> omap4_prminst_read_inst_reg(pwrdm->prcm_partition, pwrdm->prcm_offs, <answer> = 
v &= <token> <answer> m; 
v >>= <token> <answer> __ffs(m); 
return <token> <answer> v; 
static int omap4_pwrdm_read_mem_retst(struct powerdomain *pwrdm, <token> bank) <answer> u8 
<token> m, v; <answer> u32 
<token> = omap2_pwrdm_get_mem_bank_retst_mask(bank); <answer> m 
v = omap4_prminst_read_inst_reg(pwrdm->prcm_partition, <token> <answer> pwrdm->prcm_offs, 
v &= <token> <answer> m; 
v <token> __ffs(m); <answer> >>= 
<token> v; <answer> return 
<token> int omap4_pwrdm_read_prev_mem_pwrst(struct powerdomain *pwrdm, u8 bank) <answer> static 
<token> state; <answer> int 
<token> = omap4_pwrdm_read_prev_pwrst(pwrdm); <answer> state 
<token> (state == PWRDM_POWER_OFF) <answer> if 
<token> PWRDM_POWER_OFF; <answer> return 
if (state != <token> <answer> PWRDM_POWER_RET) 
return <token> <answer> PWRDM_POWER_RET; 
return <token> bank); <answer> omap4_pwrdm_read_mem_retst(pwrdm, 
static <token> omap4_pwrdm_wait_transition(struct powerdomain *pwrdm) <answer> int 
<token> c = 0; <answer> u32 
<token> void omap4_pwrdm_save_context(struct powerdomain *pwrdm) <answer> static 
pwrdm->context <token> omap4_prminst_read_inst_reg(pwrdm->prcm_partition, <answer> = 
pwrdm->context &= <token> <answer> ~OMAP4430_LOWPOWERSTATECHANGE_MASK; 
static <token> omap4_pwrdm_restore_context(struct powerdomain *pwrdm) <answer> void 
<token> st, ctrl; <answer> int 
<token> = omap4_prminst_read_inst_reg(pwrdm->prcm_partition, <answer> st 
<token> struct prm_ll_data omap44xx_prm_ll_data = { <answer> static 
.read_reset_sources = <token> <answer> &omap44xx_prm_read_reset_sources, 
<token> = &omap44xx_prm_was_any_context_lost_old, <answer> .was_any_context_lost_old 
.clear_context_loss_flags_old <token> &omap44xx_prm_clear_context_loss_flags_old, <answer> = 
.late_init <token> &omap44xx_prm_late_init, <answer> = 
.assert_hardreset <token> omap4_prminst_assert_hardreset, <answer> = 
.deassert_hardreset = <token> <answer> omap4_prminst_deassert_hardreset, 
<token> = omap4_prminst_is_hardreset_asserted, <answer> .is_hardreset_asserted 
.reset_system = <token> <answer> omap4_prminst_global_warm_sw_reset, 
.vp_check_txdone <token> omap4_prm_vp_check_txdone, <answer> = 
.vp_clear_txdone <token> omap4_prm_vp_clear_txdone, <answer> = 
<token> const struct omap_prcm_init_data *prm_init_data; <answer> static 
int <token> omap44xx_prm_init(const struct omap_prcm_init_data *data) <answer> __init 
static struct notifier_block <token> <answer> nb; 
prm_init_data = <token> <answer> data; 
if (data->flags & <token> <answer> PRM_HAS_IO_WAKEUP) 
prm_features |= <token> <answer> PRM_HAS_IO_WAKEUP; 
if (data->flags <token> PRM_HAS_VOLTAGE) <answer> & 
prm_features |= <token> <answer> PRM_HAS_VOLTAGE; 
#include <token> <answer> <uapi/drm/i915_drm.h> 
<token> "intel_memory_region.h" <answer> #include 
<token> "i915_gem_region.h" <answer> #include 
#include <token> <answer> "i915_drv.h" 
<token> "i915_trace.h" <answer> #include 
void <token> drm_i915_gem_object *obj, <answer> i915_gem_object_init_memory_region(struct 
<token> intel_memory_region *mem) <answer> struct 
obj->mm.region = <token> <answer> mem; 
<token> &mem->objects.list); <answer> list_add(&obj->mm.region_link, 
<token> i915_gem_object_release_memory_region(struct drm_i915_gem_object *obj) <answer> void 
struct intel_memory_region *mem <token> obj->mm.region; <answer> = 
static struct <token> * <answer> drm_i915_gem_object 
<token> intel_memory_region *mem, <answer> __i915_gem_object_create_region(struct 
resource_size_t <token> <answer> offset, 
resource_size_t <token> <answer> size, 
<token> page_size, <answer> resource_size_t 
unsigned int <token> <answer> flags) 
<token> drm_i915_gem_object *obj; <answer> struct 
<token> default_page_size; <answer> resource_size_t 
int <token> <answer> err; 
<token> & ~I915_BO_ALLOC_FLAGS); <answer> GEM_BUG_ON(flags 
if (WARN_ON_ONCE(flags & I915_BO_ALLOC_GPU_ONLY <token> <answer> && 
(flags & <token> || <answer> I915_BO_ALLOC_CPU_CLEAR 
flags <token> I915_BO_ALLOC_PM_EARLY))) <answer> & 
return <token> <answer> ERR_PTR(-EINVAL); 
if <token> <answer> (!mem) 
return <token> <answer> ERR_PTR(-ENODEV); 
default_page_size = <token> <answer> mem->min_page_size; 
<token> (page_size) <answer> if 
default_page_size = <token> <answer> page_size; 
if (default_page_size <token> mem->min_page_size) <answer> < 
flags |= <token> <answer> I915_BO_ALLOC_PM_EARLY; 
err = <token> obj, offset, size, page_size, flags); <answer> mem->ops->init_object(mem, 
if <token> <answer> (err) 
goto <token> <answer> err_object_free; 
return <token> <answer> obj; 
<token> ERR_PTR(err); <answer> return 
struct <token> * <answer> drm_i915_gem_object 
i915_gem_object_create_region(struct intel_memory_region <token> <answer> *mem, 
<token> size, <answer> resource_size_t 
<token> page_size, <answer> resource_size_t 
unsigned <token> flags) <answer> int 
<token> __i915_gem_object_create_region(mem, I915_BO_INVALID_OFFSET, <answer> return 
size, <token> flags); <answer> page_size, 
struct <token> * <answer> drm_i915_gem_object 
i915_gem_object_create_region_at(struct intel_memory_region <token> <answer> *mem, 
resource_size_t <token> <answer> offset, 
<token> size, <answer> resource_size_t 
unsigned int <token> <answer> flags) 
GEM_BUG_ON(offset <token> I915_BO_INVALID_OFFSET); <answer> == 
if (GEM_WARN_ON(!IS_ALIGNED(size, <token> || <answer> mem->min_page_size)) 
GEM_WARN_ON(!IS_ALIGNED(offset, <token> <answer> mem->min_page_size))) 
return <token> <answer> ERR_PTR(-EINVAL); 
if (range_overflows(offset, <token> resource_size(&mem->region))) <answer> size, 
return <token> <answer> ERR_PTR(-EINVAL); 
if <token> & I915_BO_ALLOC_GPU_ONLY) && <answer> (!(flags 
offset <token> size > resource_size(&mem->io) && <answer> + 
<token> ERR_PTR(-ENOSPC); <answer> return 
return __i915_gem_object_create_region(mem, offset, size, <token> <answer> 0, 
<token> | I915_BO_ALLOC_CONTIGUOUS); <answer> flags 
int i915_gem_process_region(struct intel_memory_region <token> <answer> *mr, 
struct i915_gem_apply_to_region <token> <answer> *apply) 
const struct i915_gem_apply_to_region_ops <token> = apply->ops; <answer> *ops 
struct drm_i915_gem_object <token> <answer> *obj; 
struct list_head <token> <answer> still_in_list; 
int ret <token> 0; <answer> = 
for (;;) <token> <answer> { 
struct <token> ww; <answer> i915_gem_ww_ctx 
obj <token> list_first_entry_or_null(&mr->objects.list, typeof(*obj), <answer> = 
if <token> <answer> (!obj) 
list_move_tail(&obj->mm.region_link, <token> <answer> &still_in_list); 
if <token> <answer> (!kref_get_unless_zero(&obj->base.refcount)) 
apply->ww <token> &ww; <answer> = 
for_i915_gem_ww(&ww, ret, apply->interruptible) <token> <answer> { 
ret <token> i915_gem_object_lock(obj, apply->ww); <answer> = 
if <token> <answer> (ret) 
if (obj->mm.region == <token> <answer> mr) 
ret = ops->process_obj(apply, <token> <answer> obj); 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> "fbtft.h" 
#define <token> "fb_ssd1289" <answer> DRVNAME 
#define <token> 240 <answer> WIDTH 
<token> HEIGHT 320 <answer> #define 
#define DEFAULT_GAMMA "02 03 2 <token> 7 7 4 2 4 2\n" \ <answer> 5 
"02 03 2 <token> 7 5 4 2 4 2" <answer> 5 
<token> unsigned int reg11 = 0x6040; <answer> static 
module_param(reg11, <token> 0000); <answer> uint, 
MODULE_PARM_DESC(reg11, "Register 11h <token> <answer> value"); 
static int init_display(struct <token> *par) <answer> fbtft_par 
<token> 0x00, 0x0001); <answer> write_reg(par, 
write_reg(par, <token> 0xA8A4); <answer> 0x03, 
<token> 0x0C, 0x0000); <answer> write_reg(par, 
<token> 0x0D, 0x080C); <answer> write_reg(par, 
write_reg(par, 0x0E, <token> <answer> 0x2B00); 
<token> 0x1E, 0x00B7); <answer> write_reg(par, 
write_reg(par, <token> <answer> 0x01, 
BIT(13) <token> (par->bgr << 11) | BIT(9) | (HEIGHT - 1)); <answer> | 
write_reg(par, <token> 0x0600); <answer> 0x02, 
write_reg(par, 0x10, <token> <answer> 0x0000); 
write_reg(par, 0x05, <token> <answer> 0x0000); 
write_reg(par, <token> 0x0000); <answer> 0x06, 
write_reg(par, 0x16, <token> <answer> 0xEF1C); 
write_reg(par, 0x17, <token> <answer> 0x0003); 
write_reg(par, <token> 0x0233); <answer> 0x07, 
write_reg(par, 0x0B, <token> <answer> 0x0000); 
<token> 0x0F, 0x0000); <answer> write_reg(par, 
<token> 0x41, 0x0000); <answer> write_reg(par, 
<token> 0x42, 0x0000); <answer> write_reg(par, 
<token> 0x48, 0x0000); <answer> write_reg(par, 
<token> 0x49, 0x013F); <answer> write_reg(par, 
<token> 0x4A, 0x0000); <answer> write_reg(par, 
write_reg(par, <token> 0x0000); <answer> 0x4B, 
write_reg(par, <token> 0xEF00); <answer> 0x44, 
<token> 0x45, 0x0000); <answer> write_reg(par, 
write_reg(par, 0x46, <token> <answer> 0x013F); 
write_reg(par, <token> 0x0000); <answer> 0x23, 
write_reg(par, 0x24, <token> <answer> 0x0000); 
write_reg(par, 0x25, <token> <answer> 0x8000); 
write_reg(par, <token> 0x0000); <answer> 0x4f, 
write_reg(par, 0x4e, <token> <answer> 0x0000); 
<token> 0x22); <answer> write_reg(par, 
<token> 0; <answer> return 
static void set_addr_win(struct fbtft_par *par, int xs, int ys, int xe, <token> ye) <answer> int 
switch <token> { <answer> (par->info->var.rotate) 
#define CURVE(num, idx) curves[(num) * par->gamma.num_values <token> (idx)] <answer> + 
static int set_gamma(struct <token> *par, u32 *curves) <answer> fbtft_par 
static const unsigned long mask[] = <token> <answer> { 
0x1f, <token> 0x07, 0x07, 0x07, 0x07, 0x07, 0x07, 0x07, 0x07, <answer> 0x1f, 
0x1f, 0x1f, 0x07, 0x07, 0x07, 0x07, <token> 0x07, 0x07, 0x07, <answer> 0x07, 
int <token> j; <answer> i, 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/i2c.h> 
<token> <linux/iio/iio.h> <answer> #include 
<token> <linux/iio/sysfs.h> <answer> #include 
#include <token> <answer> <linux/iio/buffer.h> 
#include <token> <answer> <linux/iio/trigger.h> 
<token> <linux/iio/trigger_consumer.h> <answer> #include 
<token> <linux/iio/triggered_buffer.h> <answer> #include 
<token> <linux/iio/events.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/of_irq.h> 
<token> <linux/pm_runtime.h> <answer> #include 
<token> <linux/regulator/consumer.h> <answer> #include 
<token> MMA8452_STATUS 0x00 <answer> #define 
#define MMA8452_STATUS_DRDY (BIT(2) | BIT(1) <token> BIT(0)) <answer> | 
struct mma8452_event_regs <token> <answer> { 
<token> ev_cfg; <answer> u8 
<token> ev_cfg_ele; <answer> u8 
<token> ev_cfg_chan_shift; <answer> u8 
<token> ev_src; <answer> u8 
u8 <token> <answer> ev_ths; 
u8 <token> <answer> ev_ths_mask; 
<token> ev_count; <answer> u8 
static const struct <token> ff_mt_ev_regs = { <answer> mma8452_event_regs 
<token> = MMA8452_FF_MT_CFG, <answer> .ev_cfg 
<token> = MMA8452_FF_MT_CFG_ELE, <answer> .ev_cfg_ele 
.ev_cfg_chan_shift = <token> <answer> MMA8452_FF_MT_CHAN_SHIFT, 
.ev_src <token> MMA8452_FF_MT_SRC, <answer> = 
<token> = MMA8452_FF_MT_THS, <answer> .ev_ths 
.ev_ths_mask <token> MMA8452_FF_MT_THS_MASK, <answer> = 
.ev_count = <token> <answer> MMA8452_FF_MT_COUNT 
<token> const struct mma8452_event_regs trans_ev_regs = { <answer> static 
.ev_cfg <token> MMA8452_TRANSIENT_CFG, <answer> = 
.ev_cfg_ele <token> MMA8452_TRANSIENT_CFG_ELE, <answer> = 
.ev_cfg_chan_shift = <token> <answer> MMA8452_TRANSIENT_CHAN_SHIFT, 
.ev_src <token> MMA8452_TRANSIENT_SRC, <answer> = 
.ev_ths = <token> <answer> MMA8452_TRANSIENT_THS, 
<token> = MMA8452_TRANSIENT_THS_MASK, <answer> .ev_ths_mask 
<token> = MMA8452_TRANSIENT_COUNT, <answer> .ev_count 
<token> mma_chip_info { <answer> struct 
<token> char *name; <answer> const 
u8 <token> <answer> chip_id; 
const struct iio_chan_spec <token> <answer> *channels; 
int <token> <answer> num_channels; 
<token> int mma_scales[3][2]; <answer> const 
int <token> <answer> all_events; 
int <token> <answer> enabled_events; 
<token> { <answer> enum 
static int <token> mma8452_data *data) <answer> mma8452_drdy(struct 
int tries = <token> <answer> 150; 
while (tries-- > 0) <token> <answer> { 
int ret <token> i2c_smbus_read_byte_data(data->client, <answer> = 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
if <token> & MMA8452_STATUS_DRDY) == MMA8452_STATUS_DRDY) <answer> ((ret 
<token> 0; <answer> return 
if (data->sleep_val <token> 20) <answer> <= 
usleep_range(data->sleep_val * <token> <answer> 250, 
<token> * 500); <answer> data->sleep_val 
dev_err(&data->client->dev, "data <token> ready\n"); <answer> not 
<token> -EIO; <answer> return 
static int mma8452_set_runtime_pm_state(struct i2c_client *client, bool <token> <answer> on) 
#ifdef <token> <answer> CONFIG_PM 
int <token> <answer> ret; 
if <token> { <answer> (on) 
<token> = pm_runtime_resume_and_get(&client->dev); <answer> ret 
} else <token> <answer> { 
ret = <token> <answer> pm_runtime_put_autosuspend(&client->dev); 
if (ret < 0) <token> <answer> { 
"failed to <token> power state to %d\n", on); <answer> change 
<token> ret; <answer> return 
return <token> <answer> 0; 
static int mma8452_read(struct <token> *data, __be16 buf[3]) <answer> mma8452_data 
int ret <token> mma8452_drdy(data); <answer> = 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
ret <token> mma8452_set_runtime_pm_state(data->client, true); <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> = i2c_smbus_read_i2c_block_data(data->client, MMA8452_OUT_X, <answer> ret 
3 * sizeof(__be16), <token> *)buf); <answer> (u8 
ret = mma8452_set_runtime_pm_state(data->client, <token> <answer> false); 
return <token> <answer> ret; 
static ssize_t mma8452_show_int_plus_micros(char *buf, const <token> (*vals)[2], <answer> int 
int <token> <answer> n) 
<token> len = 0; <answer> size_t 
while (n-- > <token> <answer> 0) 
len += scnprintf(buf + len, <token> - len, "%d.%06d ", <answer> PAGE_SIZE 
<token> vals[n][1]); <answer> vals[n][0], 
static IIO_CONST_ATTR_NAMED(accel_transient_scale, in_accel_scale, <token> <answer> "0.617742"); 
<token> struct attribute *mma8452_event_attributes[] = { <answer> static 
static const struct attribute_group <token> = { <answer> mma8452_event_attribute_group 
.attrs <token> mma8452_event_attributes, <answer> = 
static const <token> iio_mount_matrix * <answer> struct 
mma8452_get_mount_matrix(const struct <token> *indio_dev, <answer> iio_dev 
<token> struct iio_chan_spec *chan) <answer> const 
struct mma8452_data <token> = iio_priv(indio_dev); <answer> *data 
return <token> <answer> &data->orientation; 
static const struct iio_chan_spec_ext_info <token> = { <answer> mma8452_ext_info[] 
IIO_MOUNT_MATRIX(IIO_SHARED_BY_TYPE, <token> <answer> mma8452_get_mount_matrix), 
<token> } <answer> { 
#define <token> { \ <answer> MMA8452_FREEFALL_CHANNEL(modifier) 
.type = IIO_ACCEL, <token> <answer> \ 
<token> = 1, \ <answer> .modified 
.channel2 = modifier, <token> <answer> \ 
.scan_index <token> -1, \ <answer> = 
.event_spec = mma8452_freefall_event, <token> <answer> \ 
<token> = ARRAY_SIZE(mma8452_freefall_event), \ <answer> .num_event_specs 
#define MMA8652_FREEFALL_CHANNEL(modifier) { <token> <answer> \ 
.type = IIO_ACCEL, <token> <answer> \ 
<token> = 1, \ <answer> .modified 
<token> = modifier, \ <answer> .channel2 
<token> = -1, \ <answer> .scan_index 
.event_spec = mma8652_freefall_event, <token> <answer> \ 
.num_event_specs = <token> \ <answer> ARRAY_SIZE(mma8652_freefall_event), 
#define MMA8452_CHANNEL(axis, idx, bits) { <token> <answer> \ 
<token> = IIO_ACCEL, \ <answer> .type 
.modified <token> 1, \ <answer> = 
.channel2 <token> IIO_MOD_##axis, \ <answer> = 
<token> = BIT(IIO_CHAN_INFO_RAW) | \ <answer> .info_mask_separate 
<token> \ <answer> BIT(IIO_CHAN_INFO_CALIBBIAS), 
.info_mask_shared_by_type = <token> | \ <answer> BIT(IIO_CHAN_INFO_SAMP_FREQ) 
BIT(IIO_CHAN_INFO_SCALE) <token> \ <answer> | 
<token> | \ <answer> BIT(IIO_CHAN_INFO_HIGH_PASS_FILTER_3DB_FREQUENCY) 
BIT(IIO_CHAN_INFO_OVERSAMPLING_RATIO), <token> <answer> \ 
<token> = idx, \ <answer> .scan_index 
<token> = { \ <answer> .scan_type 
<token> = 's', \ <answer> .sign 
.realbits = (bits), <token> <answer> \ 
<token> = 16, \ <answer> .storagebits 
.shift = 16 - (bits), <token> <answer> \ 
.endianness = <token> \ <answer> IIO_BE, 
}, <token> <answer> \ 
.event_spec = <token> \ <answer> mma8452_transient_event, 
.num_event_specs = ARRAY_SIZE(mma8452_transient_event), <token> <answer> \ 
<token> = mma8452_ext_info, \ <answer> .ext_info 
#define MMA8652_CHANNEL(axis, <token> bits) { \ <answer> idx, 
.type = <token> \ <answer> IIO_ACCEL, 
.modified <token> 1, \ <answer> = 
.channel2 <token> IIO_MOD_##axis, \ <answer> = 
<token> = BIT(IIO_CHAN_INFO_RAW) | \ <answer> .info_mask_separate 
<token> \ <answer> BIT(IIO_CHAN_INFO_CALIBBIAS), 
.info_mask_shared_by_type = BIT(IIO_CHAN_INFO_SAMP_FREQ) <token> \ <answer> | 
BIT(IIO_CHAN_INFO_SCALE) | <token> <answer> \ 
BIT(IIO_CHAN_INFO_OVERSAMPLING_RATIO), <token> <answer> \ 
.scan_index = <token> \ <answer> idx, 
.scan_type <token> { \ <answer> = 
.sign <token> 's', \ <answer> = 
.realbits = (bits), <token> <answer> \ 
.storagebits <token> 16, \ <answer> = 
.shift = 16 - <token> \ <answer> (bits), 
.endianness <token> IIO_BE, \ <answer> = 
<token> \ <answer> }, 
.event_spec = <token> \ <answer> mma8452_motion_event, 
<token> = ARRAY_SIZE(mma8452_motion_event), \ <answer> .num_event_specs 
.ext_info = mma8452_ext_info, <token> <answer> \ 
static const struct iio_chan_spec mma8451_channels[] = <token> <answer> { 
MMA8452_CHANNEL(X, <token> 14), <answer> idx_x, 
<token> idx_y, 14), <answer> MMA8452_CHANNEL(Y, 
MMA8452_CHANNEL(Z, idx_z, <token> <answer> 14), 
static const struct <token> mma8452_channels[] = { <answer> iio_chan_spec 
MMA8452_CHANNEL(X, idx_x, <token> <answer> 12), 
<token> idx_y, 12), <answer> MMA8452_CHANNEL(Y, 
MMA8452_CHANNEL(Z, <token> 12), <answer> idx_z, 
static const struct iio_chan_spec mma8453_channels[] <token> { <answer> = 
<token> idx_x, 10), <answer> MMA8452_CHANNEL(X, 
MMA8452_CHANNEL(Y, <token> 10), <answer> idx_y, 
MMA8452_CHANNEL(Z, <token> 10), <answer> idx_z, 
static const struct <token> mma8652_channels[] = { <answer> iio_chan_spec 
<token> idx_x, 12), <answer> MMA8652_CHANNEL(X, 
MMA8652_CHANNEL(Y, idx_y, <token> <answer> 12), 
<token> idx_z, 12), <answer> MMA8652_CHANNEL(Z, 
static const struct iio_chan_spec <token> = { <answer> mma8653_channels[] 
MMA8652_CHANNEL(X, <token> 10), <answer> idx_x, 
<token> idx_y, 10), <answer> MMA8652_CHANNEL(Y, 
MMA8652_CHANNEL(Z, idx_z, <token> <answer> 10), 
enum <token> <answer> { 
static const <token> mma_chip_info mma_chip_info_table[] = { <answer> struct 
<token> = { <answer> [mma8451] 
<token> = "mma8451", <answer> .name 
.chip_id <token> MMA8451_DEVICE_ID, <answer> = 
<token> = mma8451_channels, <answer> .channels 
.num_channels <token> ARRAY_SIZE(mma8451_channels), <answer> = 
.mma_scales <token> { {0, 2394}, {0, 4788}, {0, 9577} }, <answer> = 
.all_events = <token> | <answer> MMA8452_INT_DRDY 
<token> | <answer> MMA8452_INT_TRANS 
.enabled_events = MMA8452_INT_TRANS <token> <answer> | 
[mma8452] = <token> <answer> { 
.name = <token> <answer> "mma8452", 
.chip_id = <token> <answer> MMA8452_DEVICE_ID, 
.channels <token> mma8452_channels, <answer> = 
.num_channels <token> ARRAY_SIZE(mma8452_channels), <answer> = 
<token> = { {0, 9577}, {0, 19154}, {0, 38307} }, <answer> .mma_scales 
<token> = MMA8452_INT_DRDY | <answer> .all_events 
<token> | <answer> MMA8452_INT_TRANS 
.enabled_events <token> MMA8452_INT_TRANS | <answer> = 
[mma8453] <token> { <answer> = 
<token> = "mma8453", <answer> .name 
<token> = MMA8453_DEVICE_ID, <answer> .chip_id 
<token> = mma8453_channels, <answer> .channels 
<token> = ARRAY_SIZE(mma8453_channels), <answer> .num_channels 
.mma_scales = { {0, 38307}, {0, 76614}, {0, <token> }, <answer> 153228} 
.all_events = MMA8452_INT_DRDY <token> <answer> | 
<token> | <answer> MMA8452_INT_TRANS 
.enabled_events <token> MMA8452_INT_TRANS | <answer> = 
<token> = { <answer> [mma8652] 
<token> = "mma8652", <answer> .name 
.chip_id <token> MMA8652_DEVICE_ID, <answer> = 
<token> = mma8652_channels, <answer> .channels 
.num_channels <token> ARRAY_SIZE(mma8652_channels), <answer> = 
<token> = { {0, 9577}, {0, 19154}, {0, 38307} }, <answer> .mma_scales 
.all_events <token> MMA8452_INT_DRDY | <answer> = 
<token> = MMA8452_INT_FF_MT, <answer> .enabled_events 
[mma8653] = <token> <answer> { 
<token> = "mma8653", <answer> .name 
.chip_id <token> MMA8653_DEVICE_ID, <answer> = 
.channels = <token> <answer> mma8653_channels, 
.num_channels <token> ARRAY_SIZE(mma8653_channels), <answer> = 
.mma_scales = { {0, 38307}, {0, 76614}, {0, <token> }, <answer> 153228} 
.all_events = <token> | <answer> MMA8452_INT_DRDY 
.enabled_events = <token> <answer> MMA8452_INT_FF_MT, 
[fxls8471] = <token> <answer> { 
.name = <token> <answer> "fxls8471", 
.chip_id <token> FXLS8471_DEVICE_ID, <answer> = 
.channels <token> mma8451_channels, <answer> = 
.num_channels <token> ARRAY_SIZE(mma8451_channels), <answer> = 
.mma_scales <token> { {0, 2394}, {0, 4788}, {0, 9577} }, <answer> = 
<token> = MMA8452_INT_DRDY | <answer> .all_events 
MMA8452_INT_TRANS <token> <answer> | 
.enabled_events = MMA8452_INT_TRANS <token> <answer> | 
static <token> attribute *mma8452_attributes[] = { <answer> struct 
static const struct attribute_group mma8452_group = <token> <answer> { 
.attrs = <token> <answer> mma8452_attributes, 
static const struct iio_info mma8452_info <token> { <answer> = 
.attrs <token> &mma8452_group, <answer> = 
.read_raw = <token> <answer> &mma8452_read_raw, 
<token> = &mma8452_write_raw, <answer> .write_raw 
.event_attrs <token> &mma8452_event_attribute_group, <answer> = 
.read_event_value = <token> <answer> &mma8452_read_event_value, 
.write_event_value <token> &mma8452_write_event_value, <answer> = 
.read_event_config <token> &mma8452_read_event_config, <answer> = 
.write_event_config = <token> <answer> &mma8452_write_event_config, 
.debugfs_reg_access = <token> <answer> &mma8452_reg_access_dbg, 
static const <token> long mma8452_scan_masks[] = {0x7, 0}; <answer> unsigned 
static int <token> iio_trigger *trig, <answer> mma8452_data_rdy_trigger_set_state(struct 
bool <token> <answer> state) 
struct iio_dev *indio_dev = <token> <answer> iio_trigger_get_drvdata(trig); 
<token> mma8452_data *data = iio_priv(indio_dev); <answer> struct 
int reg, <token> <answer> ret; 
ret = mma8452_set_runtime_pm_state(data->client, <token> <answer> state); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
reg = i2c_smbus_read_byte_data(data->client, <token> <answer> MMA8452_CTRL_REG4); 
<token> (reg < 0) <answer> if 
return <token> <answer> reg; 
<token> (state) <answer> if 
reg |= <token> <answer> MMA8452_INT_DRDY; 
reg <token> ~MMA8452_INT_DRDY; <answer> &= 
return mma8452_change_config(data, <token> reg); <answer> MMA8452_CTRL_REG4, 
static const struct iio_trigger_ops <token> = { <answer> mma8452_trigger_ops 
.set_trigger_state = <token> <answer> mma8452_data_rdy_trigger_set_state, 
.validate_device <token> iio_trigger_validate_own_device, <answer> = 
static int mma8452_trigger_setup(struct iio_dev <token> <answer> *indio_dev) 
struct <token> *data = iio_priv(indio_dev); <answer> mma8452_data 
<token> iio_trigger *trig; <answer> struct 
int <token> <answer> ret; 
trig = <token> "%s-dev%d", <answer> devm_iio_trigger_alloc(&data->client->dev, 
if <token> <answer> (!trig) 
<token> -ENOMEM; <answer> return 
<token> = &mma8452_trigger_ops; <answer> trig->ops 
<token> indio_dev); <answer> iio_trigger_set_drvdata(trig, 
ret = <token> <answer> iio_trigger_register(trig); 
if <token> <answer> (ret) 
<token> ret; <answer> return 
indio_dev->trig <token> iio_trigger_get(trig); <answer> = 
<token> 0; <answer> return 
<token> void mma8452_trigger_cleanup(struct iio_dev *indio_dev) <answer> static 
<token> (indio_dev->trig) <answer> if 
static <token> mma8452_reset(struct i2c_client *client) <answer> int 
<token> i; <answer> int 
<token> ret; <answer> int 
i2c_smbus_write_byte_data(client, <token> <answer> MMA8452_CTRL_REG2, 
for (i = 0; <token> < 10; i++) { <answer> i 
<token> 200); <answer> usleep_range(100, 
ret = <token> MMA8452_CTRL_REG2); <answer> i2c_smbus_read_byte_data(client, 
if (ret <token> -EIO) <answer> == 
ret <token> i2c_smbus_write_byte_data(client, MMA8452_TRANSIENT_THS, <answer> = 
if <token> < 0) <answer> (ret 
<token> disable_regulators; <answer> goto 
if <token> { <answer> (client->irq) 
int <token> <answer> irq2; 
<token> = of_irq_get_byname(client->dev.of_node, "INT2"); <answer> irq2 
if (irq2 == client->irq) <token> <answer> { 
<token> "using interrupt line INT2\n"); <answer> dev_dbg(&client->dev, 
} else <token> <answer> { 
ret <token> i2c_smbus_write_byte_data(client, <answer> = 
<token> (ret < 0) <answer> if 
<token> disable_regulators; <answer> goto 
dev_dbg(&client->dev, "using interrupt line <token> <answer> INT1\n"); 
ret <token> i2c_smbus_write_byte_data(client, <answer> = 
if (ret < <token> <answer> 0) 
<token> disable_regulators; <answer> goto 
ret <token> mma8452_trigger_setup(indio_dev); <answer> = 
if (ret < <token> <answer> 0) 
<token> disable_regulators; <answer> goto 
data->ctrl_reg1 = MMA8452_CTRL_ACTIVE <token> <answer> | 
(MMA8452_CTRL_DR_DEFAULT << <token> <answer> MMA8452_CTRL_DR_SHIFT); 
<token> = mma8452_calculate_sleep(data); <answer> data->sleep_val 
<token> = i2c_smbus_write_byte_data(client, MMA8452_CTRL_REG1, <answer> ret 
if <token> < 0) <answer> (ret 
<token> trigger_cleanup; <answer> goto 
ret = iio_triggered_buffer_setup(indio_dev, <token> <answer> NULL, 
mma8452_trigger_handler, <token> <answer> NULL); 
if (ret < <token> <answer> 0) 
<token> trigger_cleanup; <answer> goto 
if (client->irq) <token> <answer> { 
ret <token> devm_request_threaded_irq(&client->dev, <answer> = 
<token> mma8452_interrupt, <answer> NULL, 
IRQF_TRIGGER_LOW | <token> <answer> IRQF_ONESHOT, 
<token> indio_dev); <answer> client->name, 
<token> (ret) <answer> if 
<token> buffer_cleanup; <answer> goto 
<token> = pm_runtime_set_active(&client->dev); <answer> ret 
if <token> < 0) <answer> (ret 
goto <token> <answer> buffer_cleanup; 
<token> = iio_device_register(indio_dev); <answer> ret 
if (ret < <token> <answer> 0) 
<token> buffer_cleanup; <answer> goto 
ret = mma8452_set_freefall_mode(data, <token> <answer> false); 
if (ret < <token> <answer> 0) 
goto <token> <answer> unregister_device; 
return <token> <answer> 0; 
return <token> <answer> ret; 
static void <token> i2c_client *client) <answer> mma8452_remove(struct 
<token> iio_dev *indio_dev = i2c_get_clientdata(client); <answer> struct 
struct mma8452_data *data <token> iio_priv(indio_dev); <answer> = 
#ifdef <token> <answer> CONFIG_PM 
static <token> mma8452_runtime_suspend(struct device *dev) <answer> int 
struct iio_dev *indio_dev <token> i2c_get_clientdata(to_i2c_client(dev)); <answer> = 
struct <token> *data = iio_priv(indio_dev); <answer> mma8452_data 
int <token> <answer> ret; 
ret <token> mma8452_standby(data); <answer> = 
if <token> < 0) { <answer> (ret 
dev_err(&data->client->dev, "powering <token> device failed\n"); <answer> off 
return <token> <answer> -EAGAIN; 
ret = <token> <answer> regulator_disable(data->vddio_reg); 
if <token> { <answer> (ret) 
dev_err(dev, "failed <token> disable VDDIO regulator\n"); <answer> to 
<token> ret; <answer> return 
ret <token> regulator_disable(data->vdd_reg); <answer> = 
if (ret) <token> <answer> { 
<token> "failed to disable VDD regulator\n"); <answer> dev_err(dev, 
return <token> <answer> ret; 
<token> 0; <answer> return 
static int <token> device *dev) <answer> mma8452_runtime_resume(struct 
<token> iio_dev *indio_dev = i2c_get_clientdata(to_i2c_client(dev)); <answer> struct 
struct mma8452_data *data <token> iio_priv(indio_dev); <answer> = 
int ret, <token> <answer> sleep_val; 
ret <token> regulator_enable(data->vdd_reg); <answer> = 
<token> (ret) { <answer> if 
dev_err(dev, <token> to enable VDD regulator\n"); <answer> "failed 
<token> ret; <answer> return 
<token> = regulator_enable(data->vddio_reg); <answer> ret 
if <token> { <answer> (ret) 
dev_err(dev, <token> to enable VDDIO regulator\n"); <answer> "failed 
<token> ret; <answer> return 
<token> = mma8452_active(data); <answer> ret 
if <token> < 0) <answer> (ret 
goto <token> <answer> runtime_resume_failed; 
ret = <token> <answer> mma8452_get_odr_index(data); 
sleep_val = 1000 <token> mma8452_samp_freq[ret][0]; <answer> / 
if (sleep_val < <token> <answer> 20) 
usleep_range(sleep_val * <token> 20000); <answer> 1000, 
return <token> <answer> 0; 
return <token> <answer> ret; 
static <token> struct dev_pm_ops mma8452_pm_ops = { <answer> const 
<token> pm_runtime_force_resume) <answer> SET_SYSTEM_SLEEP_PM_OPS(pm_runtime_force_suspend, 
mma8452_runtime_resume, <token> <answer> NULL) 
<token> const struct i2c_device_id mma8452_id[] = { <answer> static 
{ "fxls8471", <token> }, <answer> (kernel_ulong_t)&mma_chip_info_table[fxls8471] 
{ <token> (kernel_ulong_t)&mma_chip_info_table[mma8451] }, <answer> "mma8451", 
<token> "mma8452", (kernel_ulong_t)&mma_chip_info_table[mma8452] }, <answer> { 
{ "mma8453", <token> }, <answer> (kernel_ulong_t)&mma_chip_info_table[mma8453] 
{ "mma8652", <token> }, <answer> (kernel_ulong_t)&mma_chip_info_table[mma8652] 
{ "mma8653", <token> }, <answer> (kernel_ulong_t)&mma_chip_info_table[mma8653] 
<token> } <answer> { 
<token> mma8452_id); <answer> MODULE_DEVICE_TABLE(i2c, 
static struct i2c_driver <token> = { <answer> mma8452_driver 
.driver <token> { <answer> = 
<token> = "mma8452", <answer> .name 
.of_match_table <token> mma8452_dt_ids, <answer> = 
.pm <token> &mma8452_pm_ops, <answer> = 
<token> = mma8452_probe, <answer> .probe 
.remove = <token> <answer> mma8452_remove, 
.id_table = <token> <answer> mma8452_id, 
MODULE_AUTHOR("Peter <token> <pmeerw@pmeerw.net>"); <answer> Meerwald 
MODULE_DESCRIPTION("Freescale / NXP MMA8452 <token> driver"); <answer> accelerometer 
<token> "reg_helper.h" <answer> #include 
<token> "core_types.h" <answer> #include 
#include <token> <answer> "link_encoder.h" 
#include <token> <answer> "dcn10_link_encoder.h" 
#include <token> <answer> "stream_encoder.h" 
#include <token> <answer> "dc_bios_types.h" 
<token> "gpio_service_interface.h" <answer> #include 
#define <token> \ <answer> CTX 
#define <token> \ <answer> DC_LOGGER 
#define <token> <answer> REG(reg)\ 
<token> FN <answer> #undef 
#define <token> field_name) \ <answer> FN(reg_name, 
enc10->link_shift->field_name, <token> <answer> enc10->link_mask->field_name 
#define <token> 0x0 <answer> DCN10_DIG_FE_SOURCE_SELECT_INVALID 
#define DCN10_DIG_FE_SOURCE_SELECT_DIGA <token> <answer> 0x1 
#define DCN10_DIG_FE_SOURCE_SELECT_DIGB <token> <answer> 0x2 
#define <token> 0x4 <answer> DCN10_DIG_FE_SOURCE_SELECT_DIGC 
#define <token> 0x08 <answer> DCN10_DIG_FE_SOURCE_SELECT_DIGD 
#define <token> 0x10 <answer> DCN10_DIG_FE_SOURCE_SELECT_DIGE 
#define <token> 0x20 <answer> DCN10_DIG_FE_SOURCE_SELECT_DIGF 
<token> DCN10_DIG_FE_SOURCE_SELECT_DIGG 0x40 <answer> #define 
enum <token> <answer> { 
DP_MST_UPDATE_MAX_RETRY = <token> <answer> 50 
<token> const struct link_encoder_funcs dcn10_lnk_enc_funcs = { <answer> static 
<token> = <answer> .validate_output_with_stream 
.hw_init <token> dcn10_link_encoder_hw_init, <answer> = 
.setup = <token> <answer> dcn10_link_encoder_setup, 
.enable_tmds_output <token> dcn10_link_encoder_enable_tmds_output, <answer> = 
<token> = dcn10_link_encoder_enable_dp_output, <answer> .enable_dp_output 
.enable_dp_mst_output <token> dcn10_link_encoder_enable_dp_mst_output, <answer> = 
.disable_output = <token> <answer> dcn10_link_encoder_disable_output, 
.dp_set_lane_settings = <token> <answer> dcn10_link_encoder_dp_set_lane_settings, 
.dp_set_phy_pattern = <token> <answer> dcn10_link_encoder_dp_set_phy_pattern, 
.update_mst_stream_allocation_table <token> <answer> = 
<token> = <answer> .psr_program_dp_dphy_fast_training 
.psr_program_secondary_packet <token> dcn10_psr_program_secondary_packet, <answer> = 
.connect_dig_be_to_fe = <token> <answer> dcn10_link_encoder_connect_dig_be_to_fe, 
.enable_hpd = <token> <answer> dcn10_link_encoder_enable_hpd, 
<token> = dcn10_link_encoder_disable_hpd, <answer> .disable_hpd 
.is_dig_enabled <token> dcn10_is_dig_enabled, <answer> = 
.get_dig_frontend = <token> <answer> dcn10_get_dig_frontend, 
<token> = dcn10_get_dig_mode, <answer> .get_dig_mode 
<token> = dcn10_link_encoder_destroy, <answer> .destroy 
.get_max_link_cap = <token> <answer> dcn10_link_encoder_get_max_link_cap, 
<token> enum bp_result link_transmitter_control( <answer> static 
<token> dcn10_link_encoder *enc10, <answer> struct 
<token> bp_transmitter_control *cntl) <answer> struct 
enum <token> result; <answer> bp_result 
struct dc_bios *bp = <token> <answer> enc10->base.ctx->dc_bios; 
result = bp->funcs->transmitter_control(bp, <token> <answer> cntl); 
<token> result; <answer> return 
<token> void enable_phy_bypass_mode( <answer> static 
struct dcn10_link_encoder <token> <answer> *enc10, 
bool <token> <answer> enable) 
<token> DPHY_BYPASS, enable); <answer> REG_UPDATE(DP_DPHY_CNTL, 
static <token> disable_prbs_symbols( <answer> void 
struct dcn10_link_encoder <token> <answer> *enc10, 
bool <token> <answer> disable) 
DPHY_ATEST_SEL_LANE0, <token> <answer> disable, 
<token> disable, <answer> DPHY_ATEST_SEL_LANE1, 
DPHY_ATEST_SEL_LANE2, <token> <answer> disable, 
DPHY_ATEST_SEL_LANE3, <token> <answer> disable); 
<token> void disable_prbs_mode( <answer> static 
struct dcn10_link_encoder <token> <answer> *enc10) 
<token> DPHY_PRBS_EN, 0); <answer> REG_UPDATE(DP_DPHY_PRBS_CNTL, 
static void <token> <answer> program_pattern_symbols( 
struct <token> *enc10, <answer> dcn10_link_encoder 
uint16_t <token> <answer> pattern_symbols[8]) 
<token> 0, <answer> REG_SET_3(DP_DPHY_SYM0, 
<token> pattern_symbols[0], <answer> DPHY_SYM1, 
<token> pattern_symbols[1], <answer> DPHY_SYM2, 
DPHY_SYM3, <token> <answer> pattern_symbols[2]); 
REG_SET_3(DP_DPHY_SYM1, <token> <answer> 0, 
DPHY_SYM4, <token> <answer> pattern_symbols[3], 
DPHY_SYM5, <token> <answer> pattern_symbols[4], 
<token> pattern_symbols[5]); <answer> DPHY_SYM6, 
REG_SET_2(DP_DPHY_SYM2, <token> <answer> 0, 
DPHY_SYM7, <token> <answer> pattern_symbols[6], 
<token> pattern_symbols[7]); <answer> DPHY_SYM8, 
static void <token> <answer> set_dp_phy_pattern_d102( 
struct <token> *enc10) <answer> dcn10_link_encoder 
<token> true); <answer> disable_prbs_symbols(enc10, 
REG_UPDATE(DP_LINK_CNTL, DP_LINK_TRAINING_COMPLETE, <token> <answer> complete); 
<token> dcn10_link_encoder_set_dp_phy_pattern_training_pattern( <answer> void 
struct link_encoder <token> <answer> *enc, 
uint32_t <token> <answer> index) 
struct dcn10_link_encoder *enc10 <token> TO_DCN10_LINK_ENC(enc); <answer> = 
DP_IDLE_BS_INTERVAL, <token> <answer> 0xFC, 
<token> 1, <answer> DP_VBID_DISABLE, 
<token> 1); <answer> DP_VID_ENHANCED_FRAME_MODE, 
<token> 0x2000, <answer> DP_IDLE_BS_INTERVAL, 
DP_VBID_DISABLE, <token> <answer> 0, 
DP_VID_ENHANCED_FRAME_MODE, <token> <answer> 1); 
REG_UPDATE(DP_DPHY_SCRAM_CNTL, DPHY_SCRAMBLER_BS_COUNT, <token> <answer> 0x1FF); 
<token> DPHY_LOAD_BS_COUNT, 0x5); <answer> REG_UPDATE(DP_DPHY_BS_SR_SWAP_CNTL, 
void dcn10_psr_program_secondary_packet(struct <token> *enc, <answer> link_encoder 
unsigned int <token> <answer> sdp_transmit_line_num_deadline) 
struct dcn10_link_encoder *enc10 = <token> <answer> TO_DCN10_LINK_ENC(enc); 
<token> sdp_transmit_line_num_deadline, <answer> DP_SEC_GSP0_LINE_NUM, 
<token> 1); <answer> DP_SEC_GSP0_PRIORITY, 
bool dcn10_is_dig_enabled(struct <token> *enc) <answer> link_encoder 
struct <token> *enc10 = TO_DCN10_LINK_ENC(enc); <answer> dcn10_link_encoder 
<token> value; <answer> uint32_t 
<token> DIG_ENABLE, &value); <answer> REG_GET(DIG_BE_EN_CNTL, 
return <token> <answer> value; 
static void link_encoder_disable(struct dcn10_link_encoder <token> <answer> *enc10) 
if (connector_signal != <token> && <answer> SIGNAL_TYPE_DVI_DUAL_LINK 
connector_signal <token> SIGNAL_TYPE_DVI_SINGLE_LINK) <answer> != 
max_pixel_clock = <token> <answer> enc10->base.features.max_hdmi_pixel_clock; 
enc10->base.output_signals <token> <answer> = 
<token> | <answer> SIGNAL_TYPE_DVI_SINGLE_LINK 
<token> | <answer> SIGNAL_TYPE_DVI_DUAL_LINK 
<token> | <answer> SIGNAL_TYPE_LVDS 
SIGNAL_TYPE_DISPLAY_PORT <token> <answer> | 
<token> | <answer> SIGNAL_TYPE_DISPLAY_PORT_MST 
SIGNAL_TYPE_EDP <token> <answer> | 
enc10->link_regs <token> link_regs; <answer> = 
enc10->aux_regs = <token> <answer> aux_regs; 
enc10->hpd_regs <token> hpd_regs; <answer> = 
enc10->link_shift = <token> <answer> link_shift; 
enc10->link_mask <token> link_mask; <answer> = 
switch (enc10->base.transmitter) <token> <answer> { 
<token> TRANSMITTER_UNIPHY_A: <answer> case 
enc10->base.preferred_engine <token> ENGINE_ID_DIGA; <answer> = 
case <token> <answer> TRANSMITTER_UNIPHY_B: 
<token> = ENGINE_ID_DIGB; <answer> enc10->base.preferred_engine 
case <token> <answer> TRANSMITTER_UNIPHY_C: 
enc10->base.preferred_engine <token> ENGINE_ID_DIGC; <answer> = 
case <token> <answer> TRANSMITTER_UNIPHY_D: 
enc10->base.preferred_engine <token> ENGINE_ID_DIGD; <answer> = 
<token> TRANSMITTER_UNIPHY_E: <answer> case 
<token> = ENGINE_ID_DIGE; <answer> enc10->base.preferred_engine 
case <token> <answer> TRANSMITTER_UNIPHY_F: 
enc10->base.preferred_engine <token> ENGINE_ID_DIGF; <answer> = 
<token> TRANSMITTER_UNIPHY_G: <answer> case 
enc10->base.preferred_engine = <token> <answer> ENGINE_ID_DIGG; 
enc10->base.preferred_engine <token> ENGINE_ID_UNKNOWN; <answer> = 
void <token> link_encoder **enc) <answer> dcn10_link_encoder_destroy(struct 
*enc = <token> <answer> NULL; 
<token> dcn10_link_encoder_setup( <answer> void 
struct <token> *enc, <answer> link_encoder 
enum <token> signal) <answer> signal_type 
struct dcn10_link_encoder *enc10 <token> TO_DCN10_LINK_ENC(enc); <answer> = 
<token> (signal) { <answer> switch 
case <token> <answer> SIGNAL_TYPE_EDP: 
<token> SIGNAL_TYPE_DISPLAY_PORT: <answer> case 
<token> link_settings); <answer> enc1_configure_encoder(enc10, 
<token> = TRANSMITTER_CONTROL_ENABLE; <answer> cntl.action 
cntl.engine_id <token> enc->preferred_engine; <answer> = 
cntl.transmitter = <token> <answer> enc10->base.transmitter; 
<token> = clock_source; <answer> cntl.pll_id 
cntl.signal <token> SIGNAL_TYPE_DISPLAY_PORT; <answer> = 
cntl.lanes_number <token> link_settings->lane_count; <answer> = 
cntl.hpd_sel <token> enc10->base.hpd_source; <answer> = 
cntl.pixel_clock = <token> <answer> link_settings->link_rate 
<token> LINK_RATE_REF_FREQ_IN_KHZ; <answer> * 
enc1_configure_encoder(enc10, <token> <answer> link_settings); 
cntl.action <token> TRANSMITTER_CONTROL_ENABLE; <answer> = 
cntl.engine_id = <token> <answer> ENGINE_ID_UNKNOWN; 
cntl.transmitter = <token> <answer> enc10->base.transmitter; 
cntl.pll_id <token> clock_source; <answer> = 
cntl.signal = <token> <answer> SIGNAL_TYPE_DISPLAY_PORT_MST; 
cntl.lanes_number = <token> <answer> link_settings->lane_count; 
cntl.hpd_sel <token> enc10->base.hpd_source; <answer> = 
cntl.pixel_clock = <token> <answer> link_settings->link_rate 
* <token> <answer> LINK_RATE_REF_FREQ_IN_KHZ; 
void <token> <answer> dcn10_link_encoder_disable_output( 
<token> link_encoder *enc, <answer> struct 
<token> signal_type signal) <answer> enum 
struct dcn10_link_encoder *enc10 <token> TO_DCN10_LINK_ENC(enc); <answer> = 
struct bp_transmitter_control cntl = <token> 0 }; <answer> { 
<token> bp_result result; <answer> enum 
if (enc->funcs->is_dig_enabled && <token> { <answer> !enc->funcs->is_dig_enabled(enc)) 
training_lane_set.bits.POST_CURSOR2_SET <token> <answer> = 
cntl.lane_select = <token> <answer> lane; 
<token> = training_lane_set.raw; <answer> cntl.lane_settings 
DP_MSE_SAT_UPDATE, <token> <answer> 1); 
do <token> <answer> { 
DP_MSE_SAT_UPDATE, <token> <answer> &value1); 
DP_MSE_16_MTP_KEEPOUT, <token> <answer> &value2); 
#include <token> <answer> <linux/etherdevice.h> 
<token> <linux/timekeeping.h> <answer> #include 
#include <token> <answer> "mt7603.h" 
#include <token> <answer> "mac.h" 
#include <token> <answer> "../trace.h" 
#define <token> 128 <answer> MT_PSE_PAGE_SIZE 
static <token> <answer> u32 
mt7603_ac_queue_mask0(u32 <token> <answer> mask) 
<token> ret = 0; <answer> u32 
ret |= GENMASK(3, 0) * !!(mask <token> BIT(0)); <answer> & 
ret |= GENMASK(8, 5) * !!(mask & <token> <answer> BIT(1)); 
ret <token> GENMASK(13, 10) * !!(mask & BIT(2)); <answer> |= 
ret |= GENMASK(19, <token> * !!(mask & BIT(3)); <answer> 16) 
<token> ret; <answer> return 
static <token> <answer> void 
mt76_stop_tx_ac(struct mt7603_dev <token> u32 mask) <answer> *dev, 
mt76_set(dev, <token> mt7603_ac_queue_mask0(mask)); <answer> MT_WF_ARB_TX_STOP_0, 
static <token> <answer> void 
mt76_start_tx_ac(struct mt7603_dev *dev, <token> mask) <answer> u32 
mt76_set(dev, MT_WF_ARB_TX_START_0, <token> <answer> mt7603_ac_queue_mask0(mask)); 
void <token> mt7603_dev *dev) <answer> mt7603_mac_reset_counters(struct 
int <token> <answer> i; 
<token> (i = 0; i < 2; i++) <answer> for 
mt76_rr(dev, <token> <answer> MT_TX_AGG_CNT(i)); 
<token> 0, sizeof(dev->mphy.aggr_stats)); <answer> memset(dev->mphy.aggr_stats, 
void <token> mt7603_dev *dev) <answer> mt7603_mac_set_timing(struct 
u32 cck <token> FIELD_PREP(MT_TIMEOUT_VAL_PLCP, 231) | <answer> = 
FIELD_PREP(MT_TIMEOUT_VAL_CCA, <token> <answer> 48); 
u32 ofdm <token> FIELD_PREP(MT_TIMEOUT_VAL_PLCP, 60) | <answer> = 
<token> 24); <answer> FIELD_PREP(MT_TIMEOUT_VAL_CCA, 
int offset <token> 3 * dev->coverage_class; <answer> = 
u32 reg_offset <token> FIELD_PREP(MT_TIMEOUT_VAL_PLCP, offset) | <answer> = 
FIELD_PREP(MT_TIMEOUT_VAL_CCA, <token> <answer> offset); 
bool is_5ghz = dev->mphy.chandef.chan->band == <token> <answer> NL80211_BAND_5GHZ; 
<token> sifs; <answer> int 
<token> val; <answer> u32 
<token> (is_5ghz) <answer> if 
sifs = <token> <answer> 16; 
<token> = 10; <answer> sifs 
mt76_set(dev, <token> <answer> MT_ARB_SCR, 
<token> | MT_ARB_SCR_RX_DISABLE); <answer> MT_ARB_SCR_TX_DISABLE 
mt76_wr(dev, <token> cck + reg_offset); <answer> MT_TIMEOUT_CCK, 
mt76_wr(dev, MT_TIMEOUT_OFDM, <token> + reg_offset); <answer> ofdm 
mt76_wr(dev, <token> <answer> MT_IFS, 
FIELD_PREP(MT_IFS_EIFS, 360) <token> <answer> | 
FIELD_PREP(MT_IFS_RIFS, <token> | <answer> 2) 
FIELD_PREP(MT_IFS_SIFS, <token> | <answer> sifs) 
FIELD_PREP(MT_IFS_SLOT, <token> <answer> dev->slottime)); 
<token> (dev->slottime < 20 || is_5ghz) <answer> if 
val <token> MT7603_CFEND_RATE_DEFAULT; <answer> = 
val = <token> <answer> MT7603_CFEND_RATE_11B; 
<token> MT_AGG_CONTROL, MT_AGG_CONTROL_CFEND_RATE, val); <answer> mt76_rmw_field(dev, 
<token> MT_ARB_SCR, <answer> mt76_clear(dev, 
MT_ARB_SCR_TX_DISABLE <token> MT_ARB_SCR_RX_DISABLE); <answer> | 
<token> void <answer> static 
mt7603_wtbl_update(struct mt7603_dev *dev, <token> idx, u32 mask) <answer> int 
mt76_rmw(dev, MT_WTBL_UPDATE, <token> <answer> MT_WTBL_UPDATE_WLAN_IDX, 
FIELD_PREP(MT_WTBL_UPDATE_WLAN_IDX, idx) | <token> <answer> mask); 
mt76_poll(dev, MT_WTBL_UPDATE, MT_WTBL_UPDATE_BUSY, 0, <token> <answer> 5000); 
static <token> <answer> u32 
mt7603_wtbl1_addr(int <token> <answer> idx) 
return MT_WTBL1_BASE + idx * <token> <answer> MT_WTBL1_SIZE; 
static <token> <answer> u32 
mt7603_wtbl2_addr(int <token> <answer> idx) 
<token> ((ref->flags ^ rates[i].flags) & IEEE80211_TX_RC_SHORT_GI) <answer> if 
<token> ^= IEEE80211_TX_RC_SHORT_GI; <answer> rates[i].flags 
<token> (k = 0; k < i; k++) { <answer> for 
if (rates[i].idx <token> rates[k].idx) <answer> != 
if <token> ^ rates[k].flags) & <answer> ((rates[i].flags 
if <token> <answer> (!rates[i].idx) 
<token> &= MT_WTBL2_W9_SHORT_GI_20 | MT_WTBL2_W9_SHORT_GI_40 | <answer> w9 
val[0] = mt7603_mac_tx_rate_val(dev, &rates[0], <token> &bw); <answer> stbc, 
bw_prev = <token> <answer> bw; 
<token> (probe_rate) { <answer> if 
probe_val = mt7603_mac_tx_rate_val(dev, <token> stbc, &bw); <answer> probe_rate, 
if <token> <answer> (bw) 
bw_idx = <token> <answer> 1; 
bw_prev = <token> <answer> 0; 
} <token> { <answer> else 
<token> = val[0]; <answer> probe_val 
<token> |= FIELD_PREP(MT_WTBL2_W9_CC_BW_SEL, bw); <answer> w9 
w9 |= <token> bw); <answer> FIELD_PREP(MT_WTBL2_W9_BW_CAP, 
val[1] = mt7603_mac_tx_rate_val(dev, &rates[1], <token> &bw); <answer> stbc, 
if <token> { <answer> (bw_prev) 
bw_idx <token> 3; <answer> = 
bw_prev = <token> <answer> bw; 
val[2] = mt7603_mac_tx_rate_val(dev, <token> stbc, &bw); <answer> &rates[2], 
<token> (bw_prev) { <answer> if 
bw_idx = <token> <answer> 5; 
bw_prev <token> bw; <answer> = 
val[3] = mt7603_mac_tx_rate_val(dev, <token> stbc, &bw); <answer> &rates[3], 
if <token> <answer> (bw_prev) 
bw_idx = <token> <answer> 7; 
w9 |= <token> <answer> FIELD_PREP(MT_WTBL2_W9_CHANGE_BW_RATE, 
<token> ? bw_idx - 1 : 7); <answer> bw_idx 
mt76_wr(dev, <token> w9); <answer> MT_WTBL_RIUCR0, 
mt76_wr(dev, <token> <answer> MT_WTBL_RIUCR1, 
FIELD_PREP(MT_WTBL_RIUCR1_RATE0, probe_val) <token> <answer> | 
FIELD_PREP(MT_WTBL_RIUCR1_RATE1, <token> | <answer> val[0]) 
FIELD_PREP(MT_WTBL_RIUCR1_RATE2_LO, <token> <answer> val[1])); 
<token> MT_WTBL_RIUCR2, <answer> mt76_wr(dev, 
FIELD_PREP(MT_WTBL_RIUCR2_RATE2_HI, val[1] >> <token> | <answer> 8) 
FIELD_PREP(MT_WTBL_RIUCR2_RATE3, val[1]) <token> <answer> | 
FIELD_PREP(MT_WTBL_RIUCR2_RATE4, <token> | <answer> val[2]) 
<token> val[2])); <answer> FIELD_PREP(MT_WTBL_RIUCR2_RATE5_LO, 
<token> MT_WTBL_RIUCR3, <answer> mt76_wr(dev, 
FIELD_PREP(MT_WTBL_RIUCR3_RATE5_HI, val[2] >> <token> | <answer> 4) 
FIELD_PREP(MT_WTBL_RIUCR3_RATE6, val[3]) <token> <answer> | 
<token> val[3])); <answer> FIELD_PREP(MT_WTBL_RIUCR3_RATE7, 
#include <token> <answer> <stdlib.h> 
<token> <string.h> <answer> #include 
#include <token> <answer> <unistd.h> 
#include <token> <answer> <arpa/inet.h> 
<token> <net/if.h> <answer> #include 
<token> <netinet/in.h> <answer> #include 
#include <token> <answer> <sys/socket.h> 
<token> <sys/types.h> <answer> #include 
#include <token> <answer> <bpf/bpf.h> 
#include <token> <answer> <bpf/libbpf.h> 
<token> "cgroup_helpers.h" <answer> #include 
#define CGROUP_PATH <token> <answer> "/skb_cgroup_test" 
<token> NUM_CGROUP_LEVELS 4 <answer> #define 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <dt-bindings/power/r8a7794-sysc.h> 
#include <token> <answer> "rcar-sysc.h" 
static const struct <token> r8a7794_areas[] __initconst = { <answer> rcar_sysc_area 
{ "always-on", <token> 0, R8A7794_PD_ALWAYS_ON, -1, PD_ALWAYS_ON }, <answer> 0, 
{ <token> 0x100, 0, R8A7794_PD_CA7_SCU, R8A7794_PD_ALWAYS_ON, <answer> "ca7-scu", 
<token> }, <answer> PD_SCU 
{ "ca7-cpu0", 0x1c0, 0, R8A7794_PD_CA7_CPU0, <token> <answer> R8A7794_PD_CA7_SCU, 
<token> }, <answer> PD_CPU_NOCR 
{ "ca7-cpu1", 0x1c0, 1, R8A7794_PD_CA7_CPU1, <token> <answer> R8A7794_PD_CA7_SCU, 
PD_CPU_NOCR <token> <answer> }, 
{ "sh-4a", 0x80, 0, R8A7794_PD_SH_4A, R8A7794_PD_ALWAYS_ON <token> <answer> }, 
{ <token> 0xc0, 0, R8A7794_PD_SGX, R8A7794_PD_ALWAYS_ON }, <answer> "sgx", 
<token> struct rcar_sysc_info r8a7794_sysc_info __initconst = { <answer> const 
.areas <token> r8a7794_areas, <answer> = 
<token> = ARRAY_SIZE(r8a7794_areas), <answer> .num_areas 
#include <token> <answer> <linux/ptrace.h> 
#include <token> <answer> <linux/kdebug.h> 
<token> <linux/bug.h> <answer> #include 
#include <token> <answer> <linux/kgdb.h> 
#include <token> <answer> <linux/irqflags.h> 
#include <token> <answer> <linux/string.h> 
#include <token> <answer> <asm/cacheflush.h> 
<token> <asm/gdb_xml.h> <answer> #include 
#include <token> <answer> <asm/insn.h> 
enum <token> <answer> { 
NOT_KGDB_BREAK = <token> <answer> 0, 
static unsigned long <token> <answer> stepped_address; 
static unsigned <token> stepped_opcode; <answer> int 
static int decode_register_index(unsigned <token> opcode, int offset) <answer> long 
<token> (opcode >> offset) & 0x1F; <answer> return 
static int decode_register_index_short(unsigned long opcode, int <token> <answer> offset) 
return ((opcode >> offset) & <token> + 8; <answer> 0x7) 
<token> CONFIG_RISCV_ISA_C <answer> #ifdef 
const struct kgdb_arch arch_kgdb_ops <token> { <answer> = 
static int show_version(struct seq_file <token> void *unused) <answer> *m, 
struct <token> *sb = m->private; <answer> super_block 
char <token> <answer> *format; 
if (REISERFS_SB(sb)->s_properties <token> (1 << REISERFS_3_6)) { <answer> & 
format <token> "3.6"; <answer> = 
} else if (REISERFS_SB(sb)->s_properties & <token> << REISERFS_3_5)) { <answer> (1 
format <token> "3.5"; <answer> = 
} else <token> <answer> { 
<token> = "unknown"; <answer> format 
seq_printf(m, "%s format\twith checks %s\n", <token> <answer> format, 
#if <token> CONFIG_REISERFS_CHECK ) <answer> defined( 
<token> 0; <answer> return 
#define SF( x ) ( r <token> x ) <answer> -> 
#define SFP( x ) SF( <token> ) <answer> s_proc_info_data.x 
#define SFPL( x ) SFP( x[ <token> ] ) <answer> level 
<token> SFPF( x ) SFP( scan_bitmap.x ) <answer> #define 
#define SFPJ( <token> ) SFP( journal.x ) <answer> x 
#define D2C( <token> ) le16_to_cpu( x ) <answer> x 
#define D4C( x ) le32_to_cpu( <token> ) <answer> x 
#define DF( x <token> D2C( rs -> s_v1.x ) <answer> ) 
<token> DFL( x ) D4C( rs -> s_v1.x ) <answer> #define 
#define objectid_map( s, <token> ) (old_format_only (s) ? \ <answer> rs 
(__le32 <token> reiserfs_super_block_v1 *)rs + 1) : \ <answer> *)((struct 
(__le32 *)(rs <token> 1)) <answer> + 
#define MAP( i ) D4C( objectid_map( sb, rs <token> i ] ) <answer> )[ 
#define DJF( x ) le32_to_cpu( <token> -> x ) <answer> rs 
<token> DJP( x ) le32_to_cpu( jp -> x ) <answer> #define 
#define JF( x ) ( <token> -> s_journal -> x ) <answer> r 
static int show_super(struct seq_file *m, void <token> <answer> *unused) 
<token> super_block *sb = m->private; <answer> struct 
struct reiserfs_sb_info *r <token> REISERFS_SB(sb); <answer> = 
seq_printf(m, "state: <token> <answer> \t%s\n" 
"mount <token> \t%s%s%s%s%s%s%s%s%s%s%s\n" <answer> options: 
"gen. <token> \t%i\n" <answer> counter: 
"s_disk_reads: <token> <answer> \t%i\n" 
"s_disk_writes: <token> <answer> \t%i\n" 
"s_fix_nodes: <token> <answer> \t%i\n" 
<token> \t%i\n" <answer> "s_do_balance: 
"s_unneeded_left_neighbor: <token> <answer> \t%i\n" 
<token> \t%i\n" <answer> "s_good_search_by_key_reada: 
"s_bmaps: <token> <answer> \t%i\n" 
"s_bmaps_without_search: <token> <answer> \t%i\n" 
<token> \t%i\n" <answer> "s_direct2indirect: 
<token> \t%i\n" <answer> "s_indirect2direct: 
<token> \t%i\n" <answer> "max_hash_collisions: 
"breads: <token> <answer> \t%lu\n" 
"bread_misses: <token> <answer> \t%lu\n" 
<token> \t%lu\n" <answer> "search_by_key: 
<token> \t%lu\n" <answer> "search_by_key_fs_changed: 
"search_by_key_restarted: <token> <answer> \t%lu\n" 
<token> \t%lu\n" <answer> "insert_item_restarted: 
<token> \t%lu\n" <answer> "paste_into_item_restarted: 
"cut_from_item_restarted: <token> <answer> \t%lu\n" 
<token> \t%lu\n" <answer> "delete_solid_item_restarted: 
<token> \t%lu\n" <answer> "delete_item_restarted: 
"leaked_oid: <token> <answer> \t%lu\n" 
"leaves_removable: <token> <answer> \t%lu\n", 
SF(s_mount_state) == <token> ? <answer> REISERFS_VALID_FS 
"REISERFS_VALID_FS" : <token> <answer> "REISERFS_ERROR_FS", 
reiserfs_r5_hash(sb) ? <token> " : "", <answer> "FORCE_R5 
<token> ? "FORCE_RUPASOV " : "", <answer> reiserfs_rupasov_hash(sb) 
reiserfs_tea_hash(sb) ? "FORCE_TEA " <token> "", <answer> : 
reiserfs_hash_detect(sb) <token> "DETECT_HASH " : "", <answer> ? 
reiserfs_no_border(sb) ? "NO_BORDER " <token> "BORDER ", <answer> : 
reiserfs_no_unhashed_relocation(sb) <token> <answer> ? 
"NO_UNHASHED_RELOCATION " : <token> <answer> "", 
reiserfs_hashed_relocation(sb) ? <token> " : "", <answer> "UNHASHED_RELOCATION 
reiserfs_test4(sb) ? "TEST4 " <token> "", <answer> : 
have_large_tails(sb) ? "TAILS <token> : have_small_tails(sb) ? <answer> " 
"SMALL_TAILS " : <token> ", <answer> "NO_TAILS 
<token> ? "REPLAY_ONLY " : "", <answer> replay_only(sb) 
convert_reiserfs(sb) ? <token> " : "", <answer> "CONV 
SF(s_disk_reads), <token> SF(s_fix_nodes), <answer> SF(s_disk_writes), 
<token> SF(s_unneeded_left_neighbor), <answer> SF(s_do_balance), 
<token> SF(s_bmaps), <answer> SF(s_good_search_by_key_reada), 
<token> SF(s_direct2indirect), <answer> SF(s_bmaps_without_search), 
SF(s_indirect2direct), <token> SFP(breads), <answer> SFP(max_hash_collisions), 
<token> SFP(search_by_key), <answer> SFP(bread_miss), 
SFP(search_by_key_fs_changed), <token> <answer> SFP(search_by_key_restarted), 
SFP(insert_item_restarted), <token> <answer> SFP(paste_into_item_restarted), 
SFP(delete_solid_item_restarted), <token> <answer> SFP(delete_item_restarted), 
SFP(leaked_oid), <token> <answer> SFP(leaves_removable)); 
return <token> <answer> 0; 
<token> int show_per_level(struct seq_file *m, void *unused) <answer> static 
struct <token> *sb = m->private; <answer> super_block 
<token> reiserfs_sb_info *r = REISERFS_SB(sb); <answer> struct 
int <token> <answer> level; 
seq_printf(m, <token> <answer> "level\t" 
" <token> <answer> balances" 
" [sbk: <token> <answer> reads" 
" <token> <answer> fs_changed" 
<token> restarted]" <answer> " 
" free <token> <answer> space" 
" <token> <answer> items" 
<token> can_remove" <answer> " 
<token> lnum" <answer> " 
" <token> <answer> rnum" 
<token> lbytes" <answer> " 
" <token> <answer> rbytes" 
<token> get_neig" <answer> " 
" get_neig_res" <token> need_l_neig" " need_r_neig" "\n"); <answer> " 
for (level = 0; level < <token> ++level) { <answer> MAX_HEIGHT; 
seq_printf(m, <token> <answer> "%i\t" 
" <token> <answer> %12lu" 
<token> %12lu" <answer> " 
<token> %12lu" <answer> " 
<token> %12lu" <answer> " 
<token> %12lu" <answer> " 
<token> %12lu" <answer> " 
" <token> <answer> %12lu" 
" <token> <answer> %12li" 
" <token> <answer> %12li" 
" <token> <answer> %12li" 
" <token> <answer> %12li" 
<token> %12lu" <answer> " 
" <token> <answer> %12lu" 
" <token> <answer> %12lu" 
<token> %12lu" <answer> " 
<token> SFPL(need_r_neighbor) <answer> SFPL(need_l_neighbor), 
return <token> <answer> 0; 
static int <token> seq_file *m, void *unused) <answer> show_bitmap(struct 
struct super_block *sb <token> m->private; <answer> = 
struct reiserfs_sb_info *r <token> REISERFS_SB(sb); <answer> = 
seq_printf(m, <token> %lu\n" <answer> "free_block: 
<token> scan_bitmap:" <answer> " 
" <token> <answer> wait" 
<token> bmap" <answer> " 
<token> retry" <answer> " 
<token> stolen" <answer> " 
" <token> <answer> journal_hint" 
" <token> <answer> %14lu" 
<token> %14lu" <answer> " 
" <token> <answer> %14lu" 
<token> %14lu" <answer> " 
" <token> <answer> %14lu" 
" <token> <answer> %14lu" 
<token> %14lu" <answer> " 
SFPF(in_journal_hint), <token> <answer> SFPF(in_journal_nohint)); 
return <token> <answer> 0; 
static int show_on_disk_super(struct seq_file *m, void <token> <answer> *unused) 
struct super_block *sb <token> m->private; <answer> = 
struct reiserfs_sb_info *sb_info = <token> <answer> REISERFS_SB(sb); 
struct reiserfs_super_block <token> = sb_info->s_rs; <answer> *rs 
int <token> = DFL(s_hash_function_code); <answer> hash_code 
__u32 <token> = DJF(s_flags); <answer> flags 
seq_printf(m, "block_count: <token> <answer> \t%i\n" 
<token> \t%i\n" <answer> "free_blocks: 
"root_block: <token> <answer> \t%i\n" 
<token> \t%i\n" <answer> "blocksize: 
"oid_maxsize: <token> <answer> \t%i\n" 
"oid_cursize: <token> <answer> \t%i\n" 
<token> \t%i\n" <answer> "umount_state: 
<token> \t%10.10s\n" <answer> "magic: 
<token> \t%i\n" <answer> "fs_state: 
"hash: <token> <answer> \t%s\n" 
<token> \t%i\n" <answer> "tree_height: 
<token> \t%i\n" <answer> "bmap_nr: 
"version: <token> <answer> \t%i\n" 
"flags: <token> <answer> \t%x[%s]\n" 
<token> \t%i\n", <answer> "reserved_for_journal: 
hash_code == TEA_HASH <token> "tea" : <answer> ? 
<token> == YURA_HASH) ? "rupasov" : <answer> (hash_code 
(hash_code == R5_HASH) ? <token> : <answer> "r5" 
<token> == UNSET_HASH) ? "unset" : "unknown", <answer> (hash_code 
<token> flags, (flags & reiserfs_attrs_cleared) <answer> DF(s_version), 
? <token> : "", DF(s_reserved_for_journal)); <answer> "attrs_cleared" 
return <token> <answer> 0; 
static int show_oidmap(struct seq_file <token> void *unused) <answer> *m, 
struct <token> *sb = m->private; <answer> super_block 
<token> reiserfs_sb_info *sb_info = REISERFS_SB(sb); <answer> struct 
<token> reiserfs_super_block *rs = sb_info->s_rs; <answer> struct 
unsigned int mapsize <token> le16_to_cpu(rs->s_v1.s_oid_cursize); <answer> = 
<token> long total_used = 0; <answer> unsigned 
int <token> <answer> i; 
for (i = 0; <token> < mapsize; ++i) { <answer> i 
<token> right; <answer> __u32 
right = (i == mapsize - 1) <token> MAX_KEY_OBJECTID : MAP(i + 1); <answer> ? 
<token> "%s: [ %x .. %x )\n", <answer> seq_printf(m, 
(i & 1) ? "free" : "used", MAP(i), <token> <answer> right); 
if (!(i & <token> { <answer> 1)) 
<token> += right - MAP(i); <answer> total_used 
#if defined( REISERFS_USE_OIDMAPF <token> <answer> ) 
<token> (sb_info->oidmap.use_file && (sb_info->oidmap.mapf != NULL)) { <answer> if 
loff_t size = <token> <answer> file_inode(sb_info->oidmap.mapf)->i_size; 
total_used += size <token> sizeof(reiserfs_oidinterval_d_t); <answer> / 
seq_printf(m, "total: <token> [%i/%i] used: %lu [exact]\n", <answer> \t%i 
mapsize, le16_to_cpu(rs->s_v1.s_oid_maxsize), <token> <answer> total_used); 
return <token> <answer> 0; 
static <token> ktime_mono_to_real_seconds(time64_t mono) <answer> time64_t 
ktime_t <token> = ktime_set(mono, NSEC_PER_SEC/2); <answer> kt 
<token> ktime_divns(ktime_mono_to_real(kt), NSEC_PER_SEC); <answer> return 
static <token> show_journal(struct seq_file *m, void *unused) <answer> int 
<token> super_block *sb = m->private; <answer> struct 
struct reiserfs_sb_info *r <token> REISERFS_SB(sb); <answer> = 
struct reiserfs_super_block <token> = r->s_rs; <answer> *rs 
struct journal_params *jp = <token> <answer> &rs->s_v1.s_journal; 
<token> <linux/delay.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/rtc.h> 
<token> RTC_STATUS 0x0 <answer> #define 
#define <token> BIT(0) <answer> RTC_STATUS_ALARM1 
#define <token> BIT(1) <answer> RTC_STATUS_ALARM2 
<token> RTC_IRQ1_CONF 0x4 <answer> #define 
<token> RTC_IRQ2_CONF 0x8 <answer> #define 
<token> RTC_IRQ_AL_EN BIT(0) <answer> #define 
#define <token> BIT(1) <answer> RTC_IRQ_FREQ_EN 
#define <token> BIT(2) <answer> RTC_IRQ_FREQ_1HZ 
#define <token> 0x18 <answer> RTC_CCR 
#define <token> BIT(15) <answer> RTC_CCR_MODE 
#define <token> 0x1C <answer> RTC_CONF_TEST 
#define <token> BIT(13) <answer> RTC_NOMINAL_TIMING 
<token> RTC_TIME 0xC <answer> #define 
<token> RTC_ALARM1 0x10 <answer> #define 
<token> RTC_ALARM2 0x14 <answer> #define 
static void rtc_delayed_write(u32 val, <token> armada38x_rtc *rtc, int offset) <answer> struct 
writel(0, <token> + RTC_STATUS); <answer> rtc->regs 
<token> rtc->regs + RTC_STATUS); <answer> writel(0, 
writel(val, rtc->regs + <token> <answer> offset); 
if (max <token> SAMPLE_NR / 2) <answer> > 
return <token> <answer> rtc->val_to_freq[index_max].value; 
static void armada38x_clear_isr(struct <token> *rtc) <answer> armada38x_rtc 
<token> val = readl(rtc->regs_soc + SOC_RTC_INTERRUPT); <answer> u32 
writel(val & ~SOC_RTC_ALARM1, <token> + SOC_RTC_INTERRUPT); <answer> rtc->regs_soc 
static void armada38x_unmask_interrupt(struct <token> *rtc) <answer> armada38x_rtc 
u32 val = <token> + SOC_RTC_INTERRUPT); <answer> readl(rtc->regs_soc 
<token> | SOC_RTC_ALARM1_MASK, rtc->regs_soc + SOC_RTC_INTERRUPT); <answer> writel(val 
<token> void armada8k_clear_isr(struct armada38x_rtc *rtc) <answer> static 
writel(RTC_8K_ALARM2, <token> + RTC_8K_ISR); <answer> rtc->regs_soc 
static void armada8k_unmask_interrupt(struct armada38x_rtc <token> <answer> *rtc) 
writel(RTC_8K_ALARM2, rtc->regs_soc + <token> <answer> RTC_8K_IMR); 
static <token> armada38x_rtc_read_time(struct device *dev, struct rtc_time *tm) <answer> int 
struct armada38x_rtc *rtc <token> dev_get_drvdata(dev); <answer> = 
<token> long time, flags; <answer> unsigned 
<token> flags); <answer> spin_lock_irqsave(&rtc->lock, 
time = rtc->data->read_rtc_reg(rtc, <token> <answer> RTC_TIME); 
spin_unlock_irqrestore(&rtc->lock, <token> <answer> flags); 
rtc_time64_to_tm(time, <token> <answer> tm); 
<token> 0; <answer> return 
static void armada38x_rtc_reset(struct armada38x_rtc <token> <answer> *rtc) 
<token> reg; <answer> u32 
reg <token> rtc->data->read_rtc_reg(rtc, RTC_CONF_TEST); <answer> = 
static <token> armada38x_ppb_convert(long ppb) <answer> long 
<token> div = ppb + 1000000000L; <answer> long 
return div_s64(1000000000000000000LL + div / <token> div) - 1000000000L; <answer> 2, 
static int armada38x_rtc_read_offset(struct <token> *dev, long *offset) <answer> device 
struct armada38x_rtc *rtc <token> dev_get_drvdata(dev); <answer> = 
<token> long ccr, flags; <answer> unsigned 
long <token> <answer> ppb_cor; 
spin_lock_irqsave(&rtc->lock, <token> <answer> flags); 
ccr <token> rtc->data->read_rtc_reg(rtc, RTC_CCR); <answer> = 
<token> flags); <answer> spin_unlock_irqrestore(&rtc->lock, 
ppb_cor = (ccr & RTC_CCR_MODE ? 3815 : 954) * <token> <answer> (s8)ccr; 
offset <token> clamp(offset, -484270L, 488558L); <answer> = 
ppb_cor <token> armada38x_ppb_convert(offset); <answer> = 
<token> = DIV_ROUND_CLOSEST(ppb_cor, 954); <answer> off 
if (off > 127 || off < -128) <token> <answer> { 
ccr = <token> <answer> RTC_CCR_MODE; 
<token> = DIV_ROUND_CLOSEST(ppb_cor, 3815); <answer> off 
<token> |= (off & 0x3fff) ^ 0x2000; <answer> ccr 
rtc_delayed_write(ccr, <token> RTC_CCR); <answer> rtc, 
<token> 0; <answer> return 
static const struct rtc_class_ops armada38x_rtc_ops <token> { <answer> = 
<token> = armada38x_rtc_read_time, <answer> .read_time 
.set_time = <token> <answer> armada38x_rtc_set_time, 
.read_alarm = <token> <answer> armada38x_rtc_read_alarm, 
<token> = armada38x_rtc_set_alarm, <answer> .set_alarm 
<token> = armada38x_rtc_alarm_irq_enable, <answer> .alarm_irq_enable 
.read_offset = <token> <answer> armada38x_rtc_read_offset, 
.set_offset = <token> <answer> armada38x_rtc_set_offset, 
static const <token> armada38x_rtc_data armada38x_data = { <answer> struct 
.update_mbus_timing = <token> <answer> rtc_update_38x_mbus_timing_params, 
<token> = read_rtc_register_38x_wa, <answer> .read_rtc_reg 
.clear_isr <token> armada38x_clear_isr, <answer> = 
.unmask_interrupt <token> armada38x_unmask_interrupt, <answer> = 
<token> = ALARM1, <answer> .alarm 
static const struct armada38x_rtc_data armada8k_data <token> { <answer> = 
<token> = rtc_update_8k_mbus_timing_params, <answer> .update_mbus_timing 
.read_rtc_reg <token> read_rtc_register, <answer> = 
<token> = armada8k_clear_isr, <answer> .clear_isr 
<token> = armada8k_unmask_interrupt, <answer> .unmask_interrupt 
.alarm = <token> <answer> ALARM2, 
static const struct of_device_id armada38x_rtc_of_match_table[] = <token> <answer> { 
<token> = "marvell,armada-380-rtc", <answer> .compatible 
<token> = &armada38x_data, <answer> .data 
.compatible <token> "marvell,armada-8k-rtc", <answer> = 
.data = <token> <answer> &armada8k_data, 
MODULE_DEVICE_TABLE(of, <token> <answer> armada38x_rtc_of_match_table); 
static __init <token> armada38x_rtc_probe(struct platform_device *pdev) <answer> int 
<token> armada38x_rtc *rtc; <answer> struct 
rtc = devm_kzalloc(&pdev->dev, <token> armada38x_rtc), <answer> sizeof(struct 
<token> (!rtc) <answer> if 
return <token> <answer> -ENOMEM; 
rtc->data <token> of_device_get_match_data(&pdev->dev); <answer> = 
rtc->val_to_freq = <token> SAMPLE_NR, <answer> devm_kcalloc(&pdev->dev, 
<token> value_to_freq), GFP_KERNEL); <answer> sizeof(struct 
<token> (!rtc->val_to_freq) <answer> if 
return <token> <answer> -ENOMEM; 
rtc->regs <token> devm_platform_ioremap_resource_byname(pdev, "rtc"); <answer> = 
if <token> <answer> (IS_ERR(rtc->regs)) 
<token> PTR_ERR(rtc->regs); <answer> return 
rtc->regs_soc <token> devm_platform_ioremap_resource_byname(pdev, "rtc-soc"); <answer> = 
if <token> <answer> (IS_ERR(rtc->regs_soc)) 
return <token> <answer> PTR_ERR(rtc->regs_soc); 
rtc->irq = <token> 0); <answer> platform_get_irq(pdev, 
if (rtc->irq < <token> <answer> 0) 
return <token> <answer> rtc->irq; 
rtc->rtc_dev <token> devm_rtc_allocate_device(&pdev->dev); <answer> = 
if <token> <answer> (IS_ERR(rtc->rtc_dev)) 
return <token> <answer> PTR_ERR(rtc->rtc_dev); 
if (devm_request_irq(&pdev->dev, <token> armada38x_rtc_alarm_irq, <answer> rtc->irq, 
0, pdev->name, rtc) <token> 0) { <answer> < 
<token> "Interrupt not available.\n"); <answer> dev_warn(&pdev->dev, 
<token> = -1; <answer> rtc->irq 
<token> rtc); <answer> platform_set_drvdata(pdev, 
if (rtc->irq != <token> <answer> -1) 
<token> 1); <answer> device_init_wakeup(&pdev->dev, 
clear_bit(RTC_FEATURE_ALARM, <token> <answer> rtc->rtc_dev->features); 
#define <token> <answer> CREATE_TRACE_POINTS 
#include <token> <answer> "trace.h" 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/ctype.h> 
#include <token> <answer> <linux/netdevice.h> 
#include <token> <answer> <linux/etherdevice.h> 
<token> <linux/ethtool.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/mii.h> 
<token> <linux/usb.h> <answer> #include 
#include <token> <answer> <linux/usb/usbnet.h> 
<token> INT51X1_VENDOR_ID 0x09e1 <answer> #define 
<token> INT51X1_PRODUCT_ID 0x5121 <answer> #define 
else <token> (!(pack_with_header_len % dev->maxpacket)) <answer> if 
<token> = 1; <answer> need_tail 
<token> (!skb_cloned(skb) && <answer> if 
(headroom + tailroom <token> need_tail + INT51X1_HEADER_SIZE)) { <answer> >= 
<token> (headroom < INT51X1_HEADER_SIZE || tailroom < need_tail) { <answer> if 
skb->data <token> memmove(skb->head + INT51X1_HEADER_SIZE, <answer> = 
<token> skb->len); <answer> skb->data, 
skb_set_tail_pointer(skb, <token> <answer> skb->len); 
<token> else { <answer> } 
struct sk_buff <token> <answer> *skb2; 
skb2 = <token> <answer> skb_copy_expand(skb, 
if <token> <answer> (!skb2) 
<token> NULL; <answer> return 
skb = <token> <answer> skb2; 
pack_len <token> need_tail; <answer> += 
pack_len &= <token> <answer> 0x07ff; 
len = __skb_push(skb, <token> <answer> INT51X1_HEADER_SIZE); 
<token> = cpu_to_le16(pack_len); <answer> *len 
<token> need_tail); <answer> __skb_put_zero(skb, 
return <token> <answer> skb; 
static void <token> net_device *netdev) <answer> int51x1_set_multicast(struct 
struct usbnet *dev = <token> <answer> netdev_priv(netdev); 
u16 filter = <token> | PACKET_TYPE_BROADCAST; <answer> PACKET_TYPE_DIRECTED 
if (netdev->flags <token> IFF_PROMISC) { <answer> & 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/clk.h> 
<token> <linux/clk-provider.h> <answer> #include 
<token> <linux/clkdev.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/types.h> <answer> #include 
<token> <asm/mach-au1x00/au1000.h> <answer> #include 
#define <token> 12000000 <answer> ALCHEMY_ROOTCLK_RATE 
static <token> char * const alchemy_au1300_intclknames[] = { <answer> const 
"lcd_intclk", <token> "maempe_clk", "maebsa_clk", <answer> "gpemgp_clk", 
"EXTCLK0", <token> <answer> "EXTCLK1" 
static const char * const alchemy_au1200_intclknames[] <token> { <answer> = 
"lcd_intclk", <token> NULL, NULL, "EXTCLK0", "EXTCLK1" <answer> NULL, 
<token> const char * const alchemy_au1550_intclknames[] = { <answer> static 
<token> "psc0_intclk", "psc1_intclk", "pci_clko", <answer> "usb_clk", 
"EXTCLK0", <token> <answer> "EXTCLK1" 
static const char * <token> alchemy_au1100_intclknames[] = { <answer> const 
"usb_clk", "lcd_intclk", NULL, <token> "EXTCLK0", "EXTCLK1" <answer> "i2s_clk", 
static const char <token> const alchemy_au1500_intclknames[] = { <answer> * 
NULL, "usbd_clk", "usbh_clk", "pci_clko", <token> "EXTCLK1" <answer> "EXTCLK0", 
static const char * const <token> = { <answer> alchemy_au1000_intclknames[] 
"irda_clk", <token> "usbh_clk", "i2s_clk", "EXTCLK0", <answer> "usbd_clk", 
static struct clk_aliastable <token> <answer> { 
<token> *alias; <answer> char 
char <token> <answer> *base; 
<token> cputype; <answer> int 
} alchemy_clk_aliases[] __initdata = <token> <answer> { 
{ "usbh_clk", "usb_clk", <token> }, <answer> ALCHEMY_CPU_AU1100 
<token> "usbd_clk", "usb_clk", ALCHEMY_CPU_AU1100 }, <answer> { 
<token> "irda_clk", "usb_clk", ALCHEMY_CPU_AU1100 }, <answer> { 
<token> "usbh_clk", "usb_clk", ALCHEMY_CPU_AU1550 }, <answer> { 
{ "usbd_clk", "usb_clk", ALCHEMY_CPU_AU1550 <token> <answer> }, 
{ "psc2_intclk", <token> ALCHEMY_CPU_AU1550 }, <answer> "usb_clk", 
{ "psc3_intclk", "EXTCLK0", ALCHEMY_CPU_AU1550 <token> <answer> }, 
{ <token> "EXTCLK0", ALCHEMY_CPU_AU1200 }, <answer> "psc0_intclk", 
{ "psc1_intclk", "EXTCLK1", ALCHEMY_CPU_AU1200 <token> <answer> }, 
{ "psc0_intclk", "EXTCLK0", ALCHEMY_CPU_AU1300 <token> <answer> }, 
{ "psc2_intclk", "EXTCLK0", ALCHEMY_CPU_AU1300 <token> <answer> }, 
{ "psc1_intclk", "EXTCLK1", <token> }, <answer> ALCHEMY_CPU_AU1300 
{ "psc3_intclk", <token> ALCHEMY_CPU_AU1300 }, <answer> "EXTCLK1", 
<token> NULL, NULL, 0 }, <answer> { 
#define IOMEM(x) ((void __iomem <token> <answer> *)(KSEG1ADDR(CPHYSADDR(x)))) 
if <token> <answer> (unlikely(au1xxx_cpu_has_pll_wo())) 
<token> = 396000000; <answer> t 
<token> { <answer> else 
t = alchemy_rdsys(AU1000_SYS_CPUPLL) & <token> <answer> 0x7f; 
<token> (alchemy_get_cputype() < ALCHEMY_CPU_AU1300) <answer> if 
t &= <token> <answer> 0x3f; 
<token> *= parent_rate; <answer> t 
return <token> <answer> t; 
void <token> alchemy_set_lpj(void) <answer> __init 
preset_lpj = <token> ALCHEMY_ROOTCLK_RATE); <answer> alchemy_clk_cpu_recalc(NULL, 
preset_lpj /= <token> * HZ; <answer> 2 
<token> const struct clk_ops alchemy_clkops_cpu = { <answer> static 
.recalc_rate <token> alchemy_clk_cpu_recalc, <answer> = 
static struct clk __init *alchemy_clk_setup_cpu(const char <token> <answer> *parent_name, 
<token> ctype) <answer> int 
struct clk_init_data <token> <answer> id; 
<token> clk_hw *h; <answer> struct 
<token> clk *clk; <answer> struct 
h = kzalloc(sizeof(*h), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!h) 
return <token> <answer> ERR_PTR(-ENOMEM); 
id.name <token> ALCHEMY_CPU_CLK; <answer> = 
id.parent_names = <token> <answer> &parent_name; 
id.num_parents = <token> <answer> 1; 
id.flags <token> 0; <answer> = 
id.ops <token> &alchemy_clkops_cpu; <answer> = 
h->init <token> &id; <answer> = 
clk = <token> h); <answer> clk_register(NULL, 
<token> (IS_ERR(clk)) { <answer> if 
pr_err("failed to <token> clock\n"); <answer> register 
<token> clk; <answer> return 
struct clk <token> <answer> *c; 
unsigned long v = <token> <answer> alchemy_rdsmem(AU1000_MEM_STCFG0); 
<token> (t) { <answer> switch 
case <token> <answer> ALCHEMY_CPU_AU1000: 
<token> ALCHEMY_CPU_AU1500: <answer> case 
v = 4 + ((v >> <token> & 1); <answer> 11) 
for (j = 0; j < 7; <token> { <answer> j++) 
<token> = clk_hw_get_parent_by_index(hw, j); <answer> pc 
<token> (!pc) <answer> if 
if <token> { <answer> (!clk_hw_is_prepared(pc)) 
<token> (!free) <answer> if 
free = <token> <answer> pc; 
<token> = clk_hw_get_rate(pc); <answer> pr 
if <token> < req->rate) <answer> (pr 
if (lastdiff && free) <token> <answer> { 
for (j = (maxdiv == 4) ? 1 : scale; j <= maxdiv; j += <token> { <answer> scale) 
tpr = req->rate <token> j; <answer> * 
if <token> < 0) <answer> (tpr 
<token> = clk_hw_round_rate(free, tpr); <answer> pr 
tdv = <token> pr, scale, maxdiv, <answer> alchemy_calc_div(req->rate, 
nr <token> pr / tdv; <answer> = 
diff = <token> - nr; <answer> req->rate 
<token> (nr > req->rate) <answer> if 
if (diff < <token> { <answer> lastdiff) 
lastdiff = <token> <answer> diff; 
bpr = <token> <answer> pr; 
bpc = <token> <answer> free; 
br <token> nr; <answer> = 
if (diff <token> 0) <answer> == 
if (br < <token> <answer> 0) 
<token> br; <answer> return 
req->best_parent_rate = <token> <answer> bpr; 
<token> = bpc; <answer> req->best_parent_hw 
req->rate = <token> <answer> br; 
return <token> <answer> 0; 
static int alchemy_clk_fgv1_en(struct clk_hw <token> <answer> *hw) 
struct <token> *c = to_fgcs_clk(hw); <answer> alchemy_fgcs_clk 
unsigned <token> v, flags; <answer> long 
spin_lock_irqsave(c->reglock, <token> <answer> flags); 
v = <token> <answer> alchemy_rdsys(c->reg); 
v |= (1 <token> 1) << c->shift; <answer> << 
<token> c->reg); <answer> alchemy_wrsys(v, 
spin_unlock_irqrestore(c->reglock, <token> <answer> flags); 
return <token> <answer> 0; 
static int alchemy_clk_fgv1_isen(struct <token> *hw) <answer> clk_hw 
<token> alchemy_fgcs_clk *c = to_fgcs_clk(hw); <answer> struct 
unsigned long v = alchemy_rdsys(c->reg) >> (c->shift <token> 1); <answer> + 
return v <token> 1; <answer> & 
static void <token> clk_hw *hw) <answer> alchemy_clk_fgv1_dis(struct 
struct alchemy_fgcs_clk *c <token> to_fgcs_clk(hw); <answer> = 
<token> long v, flags; <answer> unsigned 
spin_lock_irqsave(c->reglock, <token> <answer> flags); 
v <token> alchemy_rdsys(c->reg); <answer> = 
v &= ~((1 << 1) <token> c->shift); <answer> << 
<token> c->reg); <answer> alchemy_wrsys(v, 
<token> flags); <answer> spin_unlock_irqrestore(c->reglock, 
static int alchemy_clk_fgv1_setp(struct clk_hw *hw, <token> index) <answer> u8 
struct alchemy_fgcs_clk *c <token> to_fgcs_clk(hw); <answer> = 
unsigned long v, <token> <answer> flags; 
spin_lock_irqsave(c->reglock, <token> <answer> flags); 
v = <token> <answer> alchemy_rdsys(c->reg); 
if <token> <answer> (index) 
v |= (1 <token> c->shift); <answer> << 
v &= ~(1 <token> c->shift); <answer> << 
alchemy_wrsys(v, <token> <answer> c->reg); 
<token> flags); <answer> spin_unlock_irqrestore(c->reglock, 
<token> 0; <answer> return 
static <token> alchemy_clk_fgv1_getp(struct clk_hw *hw) <answer> u8 
struct <token> *c = to_fgcs_clk(hw); <answer> alchemy_fgcs_clk 
return (alchemy_rdsys(c->reg) >> c->shift) & <token> <answer> 1; 
static int alchemy_clk_fgv1_setr(struct clk_hw *hw, unsigned <token> rate, <answer> long 
unsigned long <token> <answer> parent_rate) 
struct alchemy_fgcs_clk *c <token> to_fgcs_clk(hw); <answer> = 
unsigned long div, <token> flags, ret; <answer> v, 
int <token> = c->shift + 2; <answer> sh 
if (!rate || !parent_rate || rate > (parent_rate / <token> <answer> 2)) 
<token> -EINVAL; <answer> return 
ret = alchemy_calc_div(rate, <token> 2, 512, &div); <answer> parent_rate, 
spin_lock_irqsave(c->reglock, <token> <answer> flags); 
<token> = alchemy_rdsys(c->reg); <answer> v 
<token> &= ~(0xff << sh); <answer> v 
v <token> div << sh; <answer> |= 
<token> c->reg); <answer> alchemy_wrsys(v, 
<token> flags); <answer> spin_unlock_irqrestore(c->reglock, 
<token> 0; <answer> return 
static unsigned long <token> clk_hw *hw, <answer> alchemy_clk_fgv1_recalc(struct 
unsigned long <token> <answer> parent_rate) 
struct alchemy_fgcs_clk *c = <token> <answer> to_fgcs_clk(hw); 
unsigned long v = alchemy_rdsys(c->reg) >> (c->shift <token> 2); <answer> + 
v = ((v <token> 0xff) + 1) * 2; <answer> & 
<token> parent_rate / v; <answer> return 
static int alchemy_clk_fgv1_detr(struct <token> *hw, <answer> clk_hw 
struct <token> *req) <answer> clk_rate_request 
return alchemy_clk_fgcs_detr(hw, req, 2, <token> <answer> 512); 
static <token> alchemy_clk_fgv2_setr(struct clk_hw *hw, unsigned long rate, <answer> int 
<token> long parent_rate) <answer> unsigned 
struct <token> *c = to_fgcs_clk(hw); <answer> alchemy_fgcs_clk 
int sh <token> c->shift + 2; <answer> = 
unsigned long div, v, <token> ret; <answer> flags, 
if (!rate || !parent_rate || rate > <token> <answer> parent_rate) 
return <token> <answer> -EINVAL; 
if (ctype == ALCHEMY_CPU_AU1300) <token> <answer> { 
v <token> alchemy_rdsys(a->reg); <answer> = 
a->parent = (v >> <token> & 3; <answer> a->shift) 
<token> (!a->parent) { <answer> if 
a->parent <token> 1; <answer> = 
<token> = 0; <answer> a->isen 
<token> else <answer> } 
a->isen = <token> <answer> 1; 
a->hw.init = <token> <answer> &id; 
c = clk_register(NULL, <token> <answer> &a->hw); 
if <token> <answer> (IS_ERR(c)) 
clk_register_clkdev(c, <token> NULL); <answer> id.name, 
<token> ret; <answer> return 
<token> = alchemy_rdsys(a->reg); <answer> v 
a->parent = ((v >> a->shift) >> 2) <token> 7; <answer> & 
if (!a->parent) <token> <answer> { 
a->parent = <token> <answer> 1; 
a->isen <token> 0; <answer> = 
<token> else <answer> } 
<token> = 1; <answer> a->isen 
a->hw.init = <token> <answer> &id; 
c <token> clk_register(NULL, &a->hw); <answer> = 
if <token> <answer> (IS_ERR(c)) 
clk_register_clkdev(c, id.name, <token> <answer> NULL); 
return <token> <answer> ret; 
#include <token> <answer> <linux/completion.h> 
<token> <linux/ip.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/sched/signal.h> <answer> #include 
<token> <linux/sunrpc/svc.h> <answer> #include 
#include <token> <answer> <linux/sunrpc/svcsock.h> 
#include <token> <answer> <linux/nfs_fs.h> 
<token> <linux/errno.h> <answer> #include 
<token> <linux/mutex.h> <answer> #include 
<token> <linux/freezer.h> <answer> #include 
#include <token> <answer> <linux/sunrpc/svcauth_gss.h> 
#include <token> <answer> <linux/sunrpc/bc_xprt.h> 
<token> <net/inet_sock.h> <answer> #include 
<token> "nfs4_fs.h" <answer> #include 
#include <token> <answer> "callback.h" 
<token> "internal.h" <answer> #include 
#include <token> <answer> "netns.h" 
#define NFSDBG_FACILITY <token> <answer> NFSDBG_CALLBACK 
<token> nfs_callback_data { <answer> struct 
unsigned <token> users; <answer> int 
struct <token> *serv; <answer> svc_serv 
static struct <token> nfs_callback_info[NFS4_MAX_MINOR_VERSION + 1]; <answer> nfs_callback_data 
static <token> <answer> DEFINE_MUTEX(nfs_callback_mutex); 
static struct svc_program <token> <answer> nfs4_callback_program; 
static int nfs4_callback_up_net(struct svc_serv *serv, struct <token> *net) <answer> net 
const struct cred *cred = <token> <answer> current_cred(); 
<token> ret; <answer> int 
struct nfs_net *nn <token> net_generic(net, nfs_net_id); <answer> = 
ret <token> svc_xprt_create(serv, "tcp", net, PF_INET, <answer> = 
<token> SVC_SOCK_ANONYMOUS, <answer> nfs_callback_set_tcpport, 
if (ret <= <token> <answer> 0) 
goto <token> <answer> out_err; 
<token> = ret; <answer> nn->nfs_callback_tcpport 
<token> Callback listener port = %u (af %u, net %x)\n", <answer> dprintk("NFS: 
<token> PF_INET, net->ns.inum); <answer> nn->nfs_callback_tcpport, 
<token> = svc_xprt_create(serv, "tcp", net, PF_INET6, <answer> ret 
nfs_callback_set_tcpport, <token> <answer> SVC_SOCK_ANONYMOUS, 
if (ret > <token> { <answer> 0) 
<token> = ret; <answer> nn->nfs_callback_tcpport6 
dprintk("NFS: Callback listener <token> = %u (af %u, net %x)\n", <answer> port 
nn->nfs_callback_tcpport6, <token> net->ns.inum); <answer> PF_INET6, 
} else <token> (ret != -EAFNOSUPPORT) <answer> if 
<token> out_err; <answer> goto 
<token> 0; <answer> return 
return (ret) ? ret : <token> <answer> -ENOMEM; 
static <token> <answer> int 
<token> *vrqstp) <answer> nfs4_callback_svc(void 
struct <token> *rqstp = vrqstp; <answer> svc_rqst 
while <token> <answer> (!svc_thread_should_stop(rqstp)) 
<token> 0; <answer> return 
<token> defined(CONFIG_NFS_V4_1) <answer> #if 
static inline void nfs_callback_bc_serv(u32 <token> struct rpc_xprt *xprt, <answer> minorversion, 
struct svc_serv <token> <answer> *serv) 
<token> (minorversion) <answer> if 
<token> = serv; <answer> xprt->bc_serv 
static <token> void nfs_callback_bc_serv(u32 minorversion, struct rpc_xprt *xprt, <answer> inline 
<token> svc_serv *serv) <answer> struct 
if <token> <answer> (cb_info->serv) 
return <token> <answer> cb_info->serv; 
if <token> <answer> (cb_info->users) 
printk(KERN_WARNING "nfs_callback_create_svc: no kthread, <token> users??\n", <answer> %d 
threadfn <token> nfs4_callback_svc; <answer> = 
<token> !defined(CONFIG_NFS_V4_1) <answer> #if 
if <token> <answer> (minorversion) 
return <token> <answer> ERR_PTR(-ENOTSUPP); 
<token> = svc_create(&nfs4_callback_program, NFS4_CALLBACK_BUFSIZE, <answer> serv 
if <token> { <answer> (!serv) 
printk(KERN_ERR "nfs_callback_create_svc: create service <token> <answer> failed\n"); 
return <token> <answer> ERR_PTR(-ENOMEM); 
cb_info->serv <token> serv; <answer> = 
<token> = 1024; <answer> serv->sv_maxconn 
dprintk("nfs_callback_create_svc: service <token> <answer> created\n"); 
return <token> <answer> serv; 
int nfs_callback_up(u32 <token> struct rpc_xprt *xprt) <answer> minorversion, 
<token> svc_serv *serv; <answer> struct 
<token> nfs_callback_data *cb_info = &nfs_callback_info[minorversion]; <answer> struct 
int <token> <answer> ret; 
struct net *net = <token> <answer> xprt->xprt_net; 
serv <token> nfs_callback_create_svc(minorversion); <answer> = 
if (IS_ERR(serv)) <token> <answer> { 
<token> = PTR_ERR(serv); <answer> ret 
goto <token> <answer> err_create; 
<token> = nfs_callback_up_net(minorversion, serv, net, xprt); <answer> ret 
if (ret < <token> <answer> 0) 
<token> err_net; <answer> goto 
ret = <token> xprt, serv); <answer> nfs_callback_start_svc(minorversion, 
if <token> < 0) <answer> (ret 
<token> err_start; <answer> goto 
if (!cb_info->users) <token> <answer> { 
svc_set_num_threads(cb_info->serv, <token> 0); <answer> NULL, 
return <token> <answer> ret; 
<token> serv, net); <answer> nfs_callback_down_net(minorversion, 
dprintk("NFS: Couldn't create server thread; <token> = %d\n", ret); <answer> err 
<token> err_net; <answer> goto 
<token> nfs_callback_down(int minorversion, struct net *net) <answer> void 
struct nfs_callback_data *cb_info <token> &nfs_callback_info[minorversion]; <answer> = 
struct <token> *serv; <answer> svc_serv 
serv <token> cb_info->serv; <answer> = 
nfs_callback_down_net(minorversion, serv, <token> <answer> net); 
if (cb_info->users <token> 0) { <answer> == 
svc_set_num_threads(serv, NULL, <token> <answer> 0); 
<token> service destroyed\n"); <answer> dprintk("nfs_callback_down: 
<token> (p == NULL) <answer> if 
return <token> <answer> 0; 
if <token> <answer> (clp->cl_acceptor) 
return <token> clp->cl_acceptor); <answer> !strcmp(p, 
<token> enum svc_auth_status nfs_callback_authenticate(struct svc_rqst *rqstp) <answer> static 
<token> = rpc_autherr_badcred; <answer> rqstp->rq_auth_stat 
<token> (rqstp->rq_authop->flavour) { <answer> switch 
<token> RPC_AUTH_NULL: <answer> case 
if <token> != CB_NULL) <answer> (rqstp->rq_proc 
<token> SVC_DENIED; <answer> return 
<token> RPC_AUTH_GSS: <answer> case 
static const struct svc_version *nfs4_callback_version[] = <token> <answer> { 
<token> = &nfs4_callback_version1, <answer> [1] 
[4] <token> &nfs4_callback_version4, <answer> = 
static <token> svc_program nfs4_callback_program = { <answer> struct 
#include <token> <answer> <linux/bits.h> 
<token> <linux/completion.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
<token> <linux/device.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
<token> <linux/i2c.h> <answer> #include 
<token> <linux/input.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/mod_devicetable.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/mutex.h> <answer> #include 
#include <token> <answer> <linux/property.h> 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#define IQS269_VER_INFO <token> <answer> 0x00 
#define IQS269_VER_INFO_PROD_NUM <token> <answer> 0x4F 
#define <token> 0x03 <answer> IQS269_VER_INFO_FW_NUM_2 
#define <token> 0x10 <answer> IQS269_VER_INFO_FW_NUM_3 
#define <token> 0x02 <answer> IQS269_SYS_FLAGS 
#define IQS269_SYS_FLAGS_SHOW_RESET <token> <answer> BIT(15) 
#define IQS269_SYS_FLAGS_PWR_MODE_MASK <token> 11) <answer> GENMASK(12, 
<token> IQS269_SYS_FLAGS_PWR_MODE_SHIFT 11 <answer> #define 
#define <token> BIT(10) <answer> IQS269_SYS_FLAGS_IN_ATI 
<token> IQS269_CHx_COUNTS 0x08 <answer> #define 
#define IQS269_SLIDER_X <token> <answer> 0x30 
#define IQS269_CAL_DATA_A <token> <answer> 0x35 
#define IQS269_CAL_DATA_A_HALL_BIN_L_MASK <token> 12) <answer> GENMASK(15, 
#define <token> 12 <answer> IQS269_CAL_DATA_A_HALL_BIN_L_SHIFT 
#define IQS269_CAL_DATA_A_HALL_BIN_R_MASK <token> 8) <answer> GENMASK(11, 
<token> IQS269_CAL_DATA_A_HALL_BIN_R_SHIFT 8 <answer> #define 
<token> IQS269_SYS_SETTINGS 0x80 <answer> #define 
<token> IQS269_SYS_SETTINGS_CLK_DIV BIT(15) <answer> #define 
#define IQS269_SYS_SETTINGS_ULP_AUTO <token> <answer> BIT(14) 
#define <token> BIT(13) <answer> IQS269_SYS_SETTINGS_DIS_AUTO 
#define IQS269_SYS_SETTINGS_PWR_MODE_MASK GENMASK(12, <token> <answer> 11) 
#define <token> 11 <answer> IQS269_SYS_SETTINGS_PWR_MODE_SHIFT 
<token> IQS269_SYS_SETTINGS_PWR_MODE_MAX 3 <answer> #define 
<token> IQS269_SYS_SETTINGS_ULP_UPDATE_MASK GENMASK(10, 8) <answer> #define 
#define <token> 8 <answer> IQS269_SYS_SETTINGS_ULP_UPDATE_SHIFT 
#define IQS269_SYS_SETTINGS_ULP_UPDATE_MAX <token> <answer> 7 
#define <token> BIT(7) <answer> IQS269_SYS_SETTINGS_SLIDER_SWIPE 
#define <token> BIT(6) <answer> IQS269_SYS_SETTINGS_RESEED_OFFSET 
#define IQS269_SYS_SETTINGS_EVENT_MODE <token> <answer> BIT(5) 
#define IQS269_SYS_SETTINGS_EVENT_MODE_LP <token> <answer> BIT(4) 
#define <token> BIT(2) <answer> IQS269_SYS_SETTINGS_REDO_ATI 
<token> IQS269_SYS_SETTINGS_ACK_RESET BIT(0) <answer> #define 
#define IQS269_FILT_STR_LP_LTA_MASK GENMASK(7, <token> <answer> 6) 
<token> IQS269_FILT_STR_LP_LTA_SHIFT 6 <answer> #define 
#define IQS269_FILT_STR_LP_CNT_MASK GENMASK(5, <token> <answer> 4) 
<token> IQS269_FILT_STR_LP_CNT_SHIFT 4 <answer> #define 
#define IQS269_FILT_STR_NP_LTA_MASK <token> 2) <answer> GENMASK(3, 
<token> IQS269_FILT_STR_NP_LTA_SHIFT 2 <answer> #define 
<token> IQS269_FILT_STR_NP_CNT_MASK GENMASK(1, 0) <answer> #define 
#define <token> 3 <answer> IQS269_FILT_STR_MAX 
<token> IQS269_EVENT_MASK_SYS BIT(6) <answer> #define 
<token> IQS269_EVENT_MASK_GESTURE BIT(3) <answer> #define 
<token> IQS269_EVENT_MASK_DEEP BIT(2) <answer> #define 
#define IQS269_EVENT_MASK_TOUCH <token> <answer> BIT(1) 
<token> IQS269_EVENT_MASK_PROX BIT(0) <answer> #define 
#define IQS269_RATE_NP_MS_MAX <token> <answer> 255 
#define <token> 255 <answer> IQS269_RATE_LP_MS_MAX 
#define IQS269_RATE_ULP_MS_MAX <token> <answer> 4080 
<token> IQS269_TIMEOUT_PWR_MS_MAX 130560 <answer> #define 
<token> IQS269_TIMEOUT_LTA_MS_MAX 130560 <answer> #define 
#define <token> BIT(15) <answer> IQS269_MISC_A_ATI_BAND_DISABLE 
<token> IQS269_MISC_A_ATI_LP_ONLY BIT(14) <answer> #define 
<token> IQS269_MISC_A_ATI_BAND_TIGHTEN BIT(13) <answer> #define 
#define <token> BIT(12) <answer> IQS269_MISC_A_FILT_DISABLE 
#define <token> GENMASK(10, 8) <answer> IQS269_MISC_A_GPIO3_SELECT_MASK 
#define IQS269_MISC_A_GPIO3_SELECT_SHIFT <token> <answer> 8 
<token> IQS269_MISC_A_DUAL_DIR BIT(6) <answer> #define 
#define IQS269_MISC_A_TX_FREQ_MASK <token> 4) <answer> GENMASK(5, 
#define <token> 4 <answer> IQS269_MISC_A_TX_FREQ_SHIFT 
#define IQS269_MISC_A_TX_FREQ_MAX <token> <answer> 3 
#define <token> BIT(0) <answer> IQS269_MISC_A_GLOBAL_CAP_SIZE 
<token> IQS269_MISC_B_RESEED_UI_SEL_MASK GENMASK(7, 6) <answer> #define 
<token> IQS269_MISC_B_RESEED_UI_SEL_SHIFT 6 <answer> #define 
#define <token> 3 <answer> IQS269_MISC_B_RESEED_UI_SEL_MAX 
#define <token> BIT(4) <answer> IQS269_MISC_B_TRACKING_UI_ENABLE 
#define <token> GENMASK(1, 0) <answer> IQS269_MISC_B_FILT_STR_SLIDER 
#define IQS269_TOUCH_HOLD_SLIDER_SEL <token> <answer> 0x89 
#define <token> 0x14 <answer> IQS269_TOUCH_HOLD_DEFAULT 
#define <token> 256 <answer> IQS269_TOUCH_HOLD_MS_MIN 
<token> IQS269_TOUCH_HOLD_MS_MAX 65280 <answer> #define 
#define <token> 4080 <answer> IQS269_TIMEOUT_TAP_MS_MAX 
#define IQS269_TIMEOUT_SWIPE_MS_MAX <token> <answer> 4080 
<token> IQS269_THRESH_SWIPE_MAX 255 <answer> #define 
#define IQS269_CHx_ENG_A_MEAS_CAP_SIZE <token> <answer> BIT(15) 
<token> IQS269_CHx_ENG_A_RX_GND_INACTIVE BIT(13) <answer> #define 
#define IQS269_CHx_ENG_A_LOCAL_CAP_SIZE <token> <answer> BIT(12) 
<token> IQS269_CHx_ENG_A_ATI_MODE_MASK GENMASK(9, 8) <answer> #define 
#define <token> 8 <answer> IQS269_CHx_ENG_A_ATI_MODE_SHIFT 
#define IQS269_CHx_ENG_A_ATI_MODE_MAX <token> <answer> 3 
<token> IQS269_CHx_ENG_A_INV_LOGIC BIT(7) <answer> #define 
<token> IQS269_CHx_ENG_A_PROJ_BIAS_MASK GENMASK(6, 5) <answer> #define 
<token> IQS269_CHx_ENG_A_PROJ_BIAS_SHIFT 5 <answer> #define 
#define <token> 3 <answer> IQS269_CHx_ENG_A_PROJ_BIAS_MAX 
<token> IQS269_CHx_ENG_A_SENSE_MODE_MASK GENMASK(3, 0) <answer> #define 
<token> IQS269_CHx_ENG_A_SENSE_MODE_MAX 15 <answer> #define 
#define <token> BIT(13) <answer> IQS269_CHx_ENG_B_LOCAL_CAP_ENABLE 
<token> IQS269_CHx_ENG_B_SENSE_FREQ_MASK GENMASK(10, 9) <answer> #define 
#define <token> 9 <answer> IQS269_CHx_ENG_B_SENSE_FREQ_SHIFT 
#define <token> 3 <answer> IQS269_CHx_ENG_B_SENSE_FREQ_MAX 
<token> IQS269_CHx_ENG_B_STATIC_ENABLE BIT(8) <answer> #define 
#define <token> GENMASK(7, 6) <answer> IQS269_CHx_ENG_B_ATI_BASE_MASK 
#define IQS269_CHx_ENG_B_ATI_BASE_75 <token> <answer> 0x00 
<token> IQS269_CHx_ENG_B_ATI_BASE_100 0x40 <answer> #define 
<token> IQS269_CHx_ENG_B_ATI_BASE_150 0x80 <answer> #define 
#define <token> 0xC0 <answer> IQS269_CHx_ENG_B_ATI_BASE_200 
#define IQS269_CHx_ENG_B_ATI_TARGET_MASK <token> 0) <answer> GENMASK(5, 
<token> IQS269_CHx_ENG_B_ATI_TARGET_MAX 2016 <answer> #define 
<token> IQS269_CHx_WEIGHT_MAX 255 <answer> #define 
<token> IQS269_CHx_THRESH_MAX 255 <answer> #define 
#define IQS269_CHx_HYST_DEEP_MASK GENMASK(7, <token> <answer> 4) 
<token> IQS269_CHx_HYST_DEEP_SHIFT 4 <answer> #define 
#define <token> GENMASK(3, 0) <answer> IQS269_CHx_HYST_TOUCH_MASK 
#define IQS269_CHx_HYST_MAX <token> <answer> 15 
#define IQS269_CHx_HALL_INACTIVE <token> <answer> 6 
#define IQS269_CHx_HALL_ACTIVE <token> <answer> 7 
#define <token> BIT(0) <answer> IQS269_HALL_PAD_R 
#define IQS269_HALL_PAD_L <token> <answer> BIT(1) 
#define <token> BIT(6) <answer> IQS269_HALL_PAD_INV 
#define IQS269_HALL_UI <token> <answer> 0xF5 
#define IQS269_HALL_UI_ENABLE <token> <answer> BIT(15) 
#define IQS269_MAX_REG <token> <answer> 0xFF 
#define IQS269_OTP_OPTION_DEFAULT <token> <answer> 0x00 
<token> IQS269_OTP_OPTION_TWS 0xD0 <answer> #define 
#define <token> BIT(7) <answer> IQS269_OTP_OPTION_HOLD 
#define IQS269_NUM_CH <token> <answer> 8 
#define <token> 2 <answer> IQS269_NUM_SL 
#define <token> usleep_range(200, 250) <answer> iqs269_irq_wait() 
<token> iqs269_local_cap_size { <answer> enum 
enum <token> { <answer> iqs269_st_offs 
enum iqs269_th_offs <token> <answer> { 
enum <token> { <answer> iqs269_event_id 
enum <token> { <answer> iqs269_slider_id 
enum iqs269_gesture_id <token> <answer> { 
<token> iqs269_switch_desc { <answer> struct 
unsigned <token> code; <answer> int 
<token> enabled; <answer> bool 
struct <token> { <answer> iqs269_event_desc 
const <token> *name; <answer> char 
enum <token> st_offs; <answer> iqs269_st_offs 
<token> iqs269_th_offs th_offs; <answer> enum 
bool <token> <answer> dir_up; 
u8 <token> <answer> mask; 
static const <token> iqs269_event_desc iqs269_events[] = { <answer> struct 
[IQS269_EVENT_PROX_DN] = <token> <answer> { 
.name <token> "event-prox", <answer> = 
.st_offs = <token> <answer> IQS269_ST_OFFS_PROX, 
.th_offs <token> IQS269_TH_OFFS_PROX, <answer> = 
.mask = <token> <answer> IQS269_EVENT_MASK_PROX, 
[IQS269_EVENT_PROX_UP] = <token> <answer> { 
.name = <token> <answer> "event-prox-alt", 
.st_offs = <token> <answer> IQS269_ST_OFFS_PROX, 
.th_offs = <token> <answer> IQS269_TH_OFFS_PROX, 
.dir_up = <token> <answer> true, 
<token> = IQS269_EVENT_MASK_PROX, <answer> .mask 
[IQS269_EVENT_TOUCH_DN] <token> { <answer> = 
<token> = "event-touch", <answer> .name 
<token> = IQS269_ST_OFFS_TOUCH, <answer> .st_offs 
<token> = IQS269_TH_OFFS_TOUCH, <answer> .th_offs 
<token> = IQS269_EVENT_MASK_TOUCH, <answer> .mask 
[IQS269_EVENT_TOUCH_UP] = <token> <answer> { 
.name = <token> <answer> "event-touch-alt", 
<token> = IQS269_ST_OFFS_TOUCH, <answer> .st_offs 
.th_offs = <token> <answer> IQS269_TH_OFFS_TOUCH, 
.dir_up = <token> <answer> true, 
.mask <token> IQS269_EVENT_MASK_TOUCH, <answer> = 
[IQS269_EVENT_DEEP_DN] = <token> <answer> { 
<token> = "event-deep", <answer> .name 
.st_offs <token> IQS269_ST_OFFS_DEEP, <answer> = 
.th_offs = <token> <answer> IQS269_TH_OFFS_DEEP, 
.mask = <token> <answer> IQS269_EVENT_MASK_DEEP, 
[IQS269_EVENT_DEEP_UP] = <token> <answer> { 
.name = <token> <answer> "event-deep-alt", 
.st_offs = <token> <answer> IQS269_ST_OFFS_DEEP, 
.th_offs <token> IQS269_TH_OFFS_DEEP, <answer> = 
<token> = true, <answer> .dir_up 
.mask <token> IQS269_EVENT_MASK_DEEP, <answer> = 
struct <token> { <answer> iqs269_ver_info 
<token> prod_num; <answer> u8 
<token> sw_num; <answer> u8 
u8 <token> <answer> hw_num; 
<token> fw_num; <answer> u8 
<token> __packed; <answer> } 
<token> iqs269_ch_reg { <answer> struct 
<token> rx_enable; <answer> u8 
u8 <token> <answer> tx_enable; 
<token> engine_a; <answer> __be16 
<token> engine_b; <answer> __be16 
<token> ati_comp; <answer> __be16 
<token> thresh[3]; <answer> u8 
u8 <token> <answer> hyst; 
<token> assoc_select; <answer> u8 
u8 <token> <answer> assoc_weight; 
} <token> <answer> __packed; 
<token> iqs269_sys_reg { <answer> struct 
__be16 <token> <answer> general; 
u8 <token> <answer> active; 
u8 <token> <answer> filter; 
u8 <token> <answer> reseed; 
u8 <token> <answer> event_mask; 
<token> rate_np; <answer> u8 
<token> rate_lp; <answer> u8 
u8 <token> <answer> rate_ulp; 
u8 <token> <answer> timeout_pwr; 
u8 <token> <answer> timeout_rdy; 
<token> timeout_lta; <answer> u8 
__be16 <token> <answer> misc_a; 
<token> misc_b; <answer> __be16 
<token> blocking; <answer> u8 
u8 <token> <answer> padding; 
u8 <token> <answer> slider_select[IQS269_NUM_SL]; 
u8 <token> <answer> timeout_tap; 
<token> timeout_swipe; <answer> u8 
<token> thresh_swipe; <answer> u8 
u8 <token> <answer> redo_ati; 
<token> iqs269_ch_reg ch_reg[IQS269_NUM_CH]; <answer> struct 
<token> __packed; <answer> } 
struct iqs269_flags <token> <answer> { 
__be16 <token> <answer> system; 
u8 <token> <answer> gesture; 
<token> padding; <answer> u8 
u8 <token> <answer> states[4]; 
<token> __packed; <answer> } 
struct iqs269_private <token> <answer> { 
<token> i2c_client *client; <answer> struct 
struct <token> *regmap; <answer> regmap 
<token> mutex lock; <answer> struct 
struct iqs269_switch_desc <token> <answer> switches[ARRAY_SIZE(iqs269_events)]; 
struct iqs269_ver_info <token> <answer> ver_info; 
struct <token> sys_reg; <answer> iqs269_sys_reg 
struct <token> ati_done; <answer> completion 
<token> input_dev *keypad; <answer> struct 
struct input_dev <token> <answer> *slider[IQS269_NUM_SL]; 
unsigned <token> keycode[ARRAY_SIZE(iqs269_events) * IQS269_NUM_CH]; <answer> int 
<token> int sl_code[IQS269_NUM_SL][IQS269_NUM_GESTURES]; <answer> unsigned 
unsigned int <token> <answer> otp_option; 
<token> int ch_num; <answer> unsigned 
bool <token> <answer> hall_enable; 
<token> ati_current; <answer> bool 
static enum iqs269_slider_id iqs269_slider_type(struct <token> *iqs269, <answer> iqs269_private 
<token> slider_num) <answer> int 
int <token> <answer> i; 
if (slider_num <token> (iqs269->otp_option & IQS269_OTP_OPTION_HOLD)) <answer> && 
<token> IQS269_SLIDER_NONE; <answer> return 
<token> (!iqs269->sys_reg.slider_select[slider_num]) <answer> if 
return <token> <answer> IQS269_SLIDER_NONE; 
for (i = 0; <token> < IQS269_NUM_GESTURES; i++) <answer> i 
if (iqs269->sl_code[slider_num][i] <token> KEY_RESERVED) <answer> != 
return <token> <answer> IQS269_SLIDER_KEY; 
return <token> <answer> IQS269_SLIDER_RAW; 
static int iqs269_ati_mode_set(struct iqs269_private <token> <answer> *iqs269, 
unsigned int <token> unsigned int mode) <answer> ch_num, 
<token> iqs269_ch_reg *ch_reg = iqs269->sys_reg.ch_reg; <answer> struct 
u16 <token> <answer> engine_a; 
if <token> >= IQS269_NUM_CH) <answer> (ch_num 
return <token> <answer> -EINVAL; 
<token> (mode > IQS269_CHx_ENG_A_ATI_MODE_MAX) <answer> if 
<token> -EINVAL; <answer> return 
engine_a = <token> <answer> be16_to_cpu(ch_reg[ch_num].engine_a); 
<token> &= ~IQS269_CHx_ENG_A_ATI_MODE_MASK; <answer> engine_a 
engine_a |= <token> << IQS269_CHx_ENG_A_ATI_MODE_SHIFT); <answer> (mode 
ch_reg[ch_num].engine_a = <token> <answer> cpu_to_be16(engine_a); 
iqs269->ati_current <token> false; <answer> = 
return <token> <answer> 0; 
static <token> iqs269_ati_mode_get(struct iqs269_private *iqs269, <answer> int 
unsigned <token> ch_num, unsigned int *mode) <answer> int 
<token> iqs269_ch_reg *ch_reg = iqs269->sys_reg.ch_reg; <answer> struct 
u16 <token> <answer> engine_a; 
if (ch_num <token> IQS269_NUM_CH) <answer> >= 
return <token> <answer> -EINVAL; 
<token> = be16_to_cpu(ch_reg[ch_num].engine_a); <answer> engine_a 
<token> &= IQS269_CHx_ENG_A_ATI_MODE_MASK; <answer> engine_a 
*mode <token> (engine_a >> IQS269_CHx_ENG_A_ATI_MODE_SHIFT); <answer> = 
return <token> <answer> 0; 
static int iqs269_ati_base_set(struct <token> *iqs269, <answer> iqs269_private 
unsigned int ch_num, unsigned int <token> <answer> base) 
struct iqs269_ch_reg *ch_reg = <token> <answer> iqs269->sys_reg.ch_reg; 
<token> engine_b; <answer> u16 
if <token> >= IQS269_NUM_CH) <answer> (ch_num 
<token> -EINVAL; <answer> return 
switch <token> { <answer> (base) 
case <token> <answer> 75: 
base = <token> <answer> IQS269_CHx_ENG_B_ATI_BASE_75; 
case <token> <answer> 100: 
base = <token> <answer> IQS269_CHx_ENG_B_ATI_BASE_100; 
case <token> <answer> 150: 
base <token> IQS269_CHx_ENG_B_ATI_BASE_150; <answer> = 
case <token> <answer> 200: 
base <token> IQS269_CHx_ENG_B_ATI_BASE_200; <answer> = 
return <token> <answer> -EINVAL; 
engine_b = <token> <answer> be16_to_cpu(ch_reg[ch_num].engine_b); 
<token> &= ~IQS269_CHx_ENG_B_ATI_BASE_MASK; <answer> engine_b 
<token> |= base; <answer> engine_b 
<token> = cpu_to_be16(engine_b); <answer> ch_reg[ch_num].engine_b 
<token> = false; <answer> iqs269->ati_current 
return <token> <answer> 0; 
static int iqs269_ati_base_get(struct iqs269_private <token> <answer> *iqs269, 
unsigned int <token> unsigned int *base) <answer> ch_num, 
struct iqs269_ch_reg *ch_reg = <token> <answer> iqs269->sys_reg.ch_reg; 
u16 <token> <answer> engine_b; 
if <token> >= IQS269_NUM_CH) <answer> (ch_num 
<token> -EINVAL; <answer> return 
engine_b = <token> <answer> be16_to_cpu(ch_reg[ch_num].engine_b); 
<token> (engine_b & IQS269_CHx_ENG_B_ATI_BASE_MASK) { <answer> switch 
<token> IQS269_CHx_ENG_B_ATI_BASE_75: <answer> case 
*base = <token> <answer> 75; 
<token> 0; <answer> return 
<token> IQS269_CHx_ENG_B_ATI_BASE_100: <answer> case 
*base = <token> <answer> 100; 
return <token> <answer> 0; 
case <token> <answer> IQS269_CHx_ENG_B_ATI_BASE_150: 
*base = <token> <answer> 150; 
return <token> <answer> 0; 
case <token> <answer> IQS269_CHx_ENG_B_ATI_BASE_200: 
*base <token> 200; <answer> = 
return <token> <answer> 0; 
<token> -EINVAL; <answer> return 
static int iqs269_ati_target_set(struct <token> *iqs269, <answer> iqs269_private 
unsigned <token> ch_num, unsigned int target) <answer> int 
<token> iqs269_ch_reg *ch_reg = iqs269->sys_reg.ch_reg; <answer> struct 
<token> engine_b; <answer> u16 
if (ch_num >= <token> <answer> IQS269_NUM_CH) 
return <token> <answer> -EINVAL; 
if (target <token> IQS269_CHx_ENG_B_ATI_TARGET_MAX) <answer> > 
<token> -EINVAL; <answer> return 
<token> = be16_to_cpu(ch_reg[ch_num].engine_b); <answer> engine_b 
<token> &= ~IQS269_CHx_ENG_B_ATI_TARGET_MASK; <answer> engine_b 
engine_b <token> target / 32; <answer> |= 
<token> = cpu_to_be16(engine_b); <answer> ch_reg[ch_num].engine_b 
iqs269->ati_current <token> false; <answer> = 
<token> 0; <answer> return 
static int iqs269_ati_target_get(struct <token> *iqs269, <answer> iqs269_private 
unsigned int ch_num, <token> int *target) <answer> unsigned 
<token> iqs269_ch_reg *ch_reg = iqs269->sys_reg.ch_reg; <answer> struct 
u16 <token> <answer> engine_b; 
<token> (ch_num >= IQS269_NUM_CH) <answer> if 
<token> -EINVAL; <answer> return 
engine_b = <token> <answer> be16_to_cpu(ch_reg[ch_num].engine_b); 
*target = (engine_b & IQS269_CHx_ENG_B_ATI_TARGET_MASK) * <token> <answer> 32; 
<token> 0; <answer> return 
static int iqs269_parse_mask(const <token> fwnode_handle *fwnode, <answer> struct 
const char *propname, <token> *mask) <answer> u8 
unsigned int <token> <answer> val[IQS269_NUM_CH]; 
<token> count, error, i; <answer> int 
count = <token> propname); <answer> fwnode_property_count_u32(fwnode, 
if <token> < 0) <answer> (count 
<token> 0; <answer> return 
if (count > <token> <answer> IQS269_NUM_CH) 
return <token> <answer> -EINVAL; 
<token> = fwnode_property_read_u32_array(fwnode, propname, val, count); <answer> error 
<token> (error) <answer> if 
return <token> <answer> error; 
*mask <token> 0; <answer> = 
for (i = 0; i < count; i++) <token> <answer> { 
if <token> >= IQS269_NUM_CH) <answer> (val[i] 
return <token> <answer> -EINVAL; 
*mask |= <token> <answer> BIT(val[i]); 
return <token> <answer> 0; 
static int iqs269_parse_chan(struct <token> *iqs269, <answer> iqs269_private 
const <token> fwnode_handle *ch_node) <answer> struct 
struct <token> *client = iqs269->client; <answer> i2c_client 
struct <token> *ev_node; <answer> fwnode_handle 
struct iqs269_ch_reg <token> <answer> *ch_reg; 
u16 engine_a, <token> <answer> engine_b; 
unsigned int reg, <token> <answer> val; 
<token> error, i; <answer> int 
error <token> fwnode_property_read_u32(ch_node, "reg", &reg); <answer> = 
if (error) <token> <answer> { 
dev_err(&client->dev, "Failed to <token> channel number: %d\n", <answer> read 
return <token> <answer> error; 
<token> else if (reg >= IQS269_NUM_CH) { <answer> } 
dev_err(&client->dev, "Invalid channel <token> %u\n", reg); <answer> number: 
<token> -EINVAL; <answer> return 
iqs269->sys_reg.active |= <token> <answer> BIT(reg); 
if (!fwnode_property_present(ch_node, <token> <answer> "azoteq,reseed-disable")) 
iqs269->sys_reg.reseed <token> BIT(reg); <answer> |= 
<token> (fwnode_property_present(ch_node, "azoteq,blocking-enable")) <answer> if 
<token> |= BIT(reg); <answer> iqs269->sys_reg.blocking 
if <token> "azoteq,slider0-select")) <answer> (fwnode_property_present(ch_node, 
<token> |= BIT(reg); <answer> iqs269->sys_reg.slider_select[0] 
if <token> "azoteq,slider1-select") && <answer> (fwnode_property_present(ch_node, 
<token> & IQS269_OTP_OPTION_HOLD)) <answer> !(iqs269->otp_option 
iqs269->sys_reg.slider_select[1] <token> BIT(reg); <answer> |= 
ch_reg <token> &iqs269->sys_reg.ch_reg[reg]; <answer> = 
error = <token> "azoteq,rx-enable", <answer> iqs269_parse_mask(ch_node, 
<token> (error) { <answer> if 
dev_err(&client->dev, "Invalid channel %u <token> enable mask: %d\n", <answer> RX 
<token> error); <answer> reg, 
return <token> <answer> error; 
error = <token> "azoteq,tx-enable", <answer> iqs269_parse_mask(ch_node, 
<token> (error) { <answer> if 
dev_err(&client->dev, "Invalid channel %u TX enable <token> %d\n", <answer> mask: 
reg, <token> <answer> error); 
<token> error; <answer> return 
<token> = be16_to_cpu(ch_reg->engine_a); <answer> engine_a 
<token> = be16_to_cpu(ch_reg->engine_b); <answer> engine_b 
engine_a <token> IQS269_CHx_ENG_A_MEAS_CAP_SIZE; <answer> |= 
<token> (fwnode_property_present(ch_node, "azoteq,meas-cap-decrease")) <answer> if 
<token> &= ~IQS269_CHx_ENG_A_MEAS_CAP_SIZE; <answer> engine_a 
engine_a |= <token> <answer> IQS269_CHx_ENG_A_RX_GND_INACTIVE; 
if (fwnode_property_present(ch_node, <token> <answer> "azoteq,rx-float-inactive")) 
<token> &= ~IQS269_CHx_ENG_A_RX_GND_INACTIVE; <answer> engine_a 
engine_a &= <token> <answer> ~IQS269_CHx_ENG_A_LOCAL_CAP_SIZE; 
engine_b &= <token> <answer> ~IQS269_CHx_ENG_B_LOCAL_CAP_ENABLE; 
if (!fwnode_property_read_u32(ch_node, "azoteq,local-cap-size", &val)) <token> <answer> { 
switch <token> { <answer> (val) 
<token> IQS269_LOCAL_CAP_SIZE_0: <answer> case 
<token> IQS269_LOCAL_CAP_SIZE_GLOBAL_0pF5: <answer> case 
engine_a <token> IQS269_CHx_ENG_A_LOCAL_CAP_SIZE; <answer> |= 
<token> IQS269_LOCAL_CAP_SIZE_GLOBAL_ONLY: <answer> case 
engine_b <token> IQS269_CHx_ENG_B_LOCAL_CAP_ENABLE; <answer> |= 
"Invalid channel %u local cap. size: <token> reg, <answer> %u\n", 
return <token> <answer> -EINVAL; 
engine_a &= <token> <answer> ~IQS269_CHx_ENG_A_INV_LOGIC; 
if <token> "azoteq,invert-enable")) <answer> (fwnode_property_present(ch_node, 
engine_a |= <token> <answer> IQS269_CHx_ENG_A_INV_LOGIC; 
if (!fwnode_property_read_u32(ch_node, <token> &val)) { <answer> "azoteq,proj-bias", 
if (val <token> IQS269_CHx_ENG_A_PROJ_BIAS_MAX) { <answer> > 
"Invalid <token> %u bias current: %u\n", reg, <answer> channel 
return <token> <answer> -EINVAL; 
engine_a &= <token> <answer> ~IQS269_CHx_ENG_A_PROJ_BIAS_MASK; 
<token> |= (val << IQS269_CHx_ENG_A_PROJ_BIAS_SHIFT); <answer> engine_a 
if (!fwnode_property_read_u32(ch_node, "azoteq,sense-mode", &val)) <token> <answer> { 
if (val <token> IQS269_CHx_ENG_A_SENSE_MODE_MAX) { <answer> > 
<token> channel %u sensing mode: %u\n", reg, <answer> "Invalid 
return <token> <answer> -EINVAL; 
engine_a &= <token> <answer> ~IQS269_CHx_ENG_A_SENSE_MODE_MASK; 
engine_a |= <token> <answer> val; 
if (!fwnode_property_read_u32(ch_node, <token> &val)) { <answer> "azoteq,sense-freq", 
if (val <token> IQS269_CHx_ENG_B_SENSE_FREQ_MAX) { <answer> > 
"Invalid channel %u sensing <token> %u\n", <answer> frequency: 
<token> val); <answer> reg, 
<token> -EINVAL; <answer> return 
engine_b <token> ~IQS269_CHx_ENG_B_SENSE_FREQ_MASK; <answer> &= 
engine_b |= (val <token> IQS269_CHx_ENG_B_SENSE_FREQ_SHIFT); <answer> << 
engine_b &= <token> <answer> ~IQS269_CHx_ENG_B_STATIC_ENABLE; 
<token> (fwnode_property_present(ch_node, "azoteq,static-enable")) <answer> if 
engine_b <token> IQS269_CHx_ENG_B_STATIC_ENABLE; <answer> |= 
ch_reg->engine_a = <token> <answer> cpu_to_be16(engine_a); 
ch_reg->engine_b <token> cpu_to_be16(engine_b); <answer> = 
if <token> "azoteq,ati-mode", &val)) { <answer> (!fwnode_property_read_u32(ch_node, 
error = <token> reg, val); <answer> iqs269_ati_mode_set(iqs269, 
if (error) <token> <answer> { 
"Invalid channel <token> ATI mode: %u\n", reg, val); <answer> %u 
<token> error; <answer> return 
if <token> "azoteq,ati-base", &val)) { <answer> (!fwnode_property_read_u32(ch_node, 
<token> = iqs269_ati_base_set(iqs269, reg, val); <answer> error 
<token> (error) { <answer> if 
"Invalid channel %u ATI <token> %u\n", reg, val); <answer> base: 
return <token> <answer> error; 
if (!fwnode_property_read_u32(ch_node, "azoteq,ati-target", &val)) <token> <answer> { 
<token> = iqs269_ati_target_set(iqs269, reg, val); <answer> error 
if (error) <token> <answer> { 
"Invalid channel %u <token> target: %u\n", reg, <answer> ATI 
return <token> <answer> error; 
<token> = iqs269_parse_mask(ch_node, "azoteq,assoc-select", <answer> error 
<token> (error) { <answer> if 
dev_err(&client->dev, "Invalid channel <token> association: %d\n", <answer> %u 
<token> error); <answer> reg, 
<token> error; <answer> return 
<token> (!fwnode_property_read_u32(ch_node, "azoteq,assoc-weight", &val)) { <answer> if 
if (val <token> IQS269_CHx_WEIGHT_MAX) { <answer> > 
"Invalid <token> %u associated weight: %u\n", <answer> channel 
<token> val); <answer> reg, 
return <token> <answer> -EINVAL; 
ch_reg->assoc_weight <token> val; <answer> = 
for (i = 0; i <token> ARRAY_SIZE(iqs269_events); i++) { <answer> < 
ev_node = <token> <answer> fwnode_get_named_child_node(ch_node, 
<token> (!ev_node) <answer> if 
if (!fwnode_property_read_u32(ev_node, "azoteq,thresh", &val)) <token> <answer> { 
if (val <token> IQS269_CHx_THRESH_MAX) { <answer> > 
<token> channel %u threshold: %u\n", <answer> "Invalid 
reg, <token> <answer> val); 
<token> -EINVAL; <answer> return 
ch_reg->thresh[iqs269_events[i].th_offs] <token> val; <answer> = 
if (!fwnode_property_read_u32(ev_node, "azoteq,hyst", <token> { <answer> &val)) 
u8 *hyst <token> &ch_reg->hyst; <answer> = 
if (val > <token> { <answer> IQS269_CHx_HYST_MAX) 
"Invalid <token> %u hysteresis: %u\n", <answer> channel 
<token> val); <answer> reg, 
<token> -EINVAL; <answer> return 
if (i == IQS269_EVENT_DEEP_DN <token> <answer> || 
i == IQS269_EVENT_DEEP_UP) <token> <answer> { 
*hyst <token> ~IQS269_CHx_HYST_DEEP_MASK; <answer> &= 
*hyst |= (val << <token> <answer> IQS269_CHx_HYST_DEEP_SHIFT); 
} else if (i == IQS269_EVENT_TOUCH_DN <token> <answer> || 
i == <token> { <answer> IQS269_EVENT_TOUCH_UP) 
<token> &= ~IQS269_CHx_HYST_TOUCH_MASK; <answer> *hyst 
*hyst |= <token> <answer> val; 
<token> = fwnode_property_read_u32(ev_node, "linux,code", &val); <answer> error 
<token> (error == -EINVAL) { <answer> if 
} else if (error) <token> <answer> { 
"Failed to read channel <token> code: %d\n", reg, <answer> %u 
<token> error; <answer> return 
switch (reg) <token> <answer> { 
<token> IQS269_CHx_HALL_ACTIVE: <answer> case 
<token> (iqs269->hall_enable) { <answer> if 
iqs269->switches[i].code <token> val; <answer> = 
<token> = true; <answer> iqs269->switches[i].enabled 
case <token> <answer> IQS269_CHx_HALL_INACTIVE: 
<token> (iqs269->hall_enable) <answer> if 
iqs269->keycode[i * <token> + reg] = val; <answer> IQS269_NUM_CH 
<token> &= ~iqs269_events[i].mask; <answer> iqs269->sys_reg.event_mask 
return <token> <answer> 0; 
static int <token> iqs269_private *iqs269) <answer> iqs269_parse_prop(struct 
struct iqs269_sys_reg *sys_reg <token> &iqs269->sys_reg; <answer> = 
struct i2c_client <token> = iqs269->client; <answer> *client 
struct fwnode_handle <token> <answer> *ch_node; 
u16 general, <token> misc_b; <answer> misc_a, 
unsigned int <token> <answer> val; 
int <token> <answer> error; 
<token> = device_property_present(&client->dev, <answer> iqs269->hall_enable 
error = regmap_raw_read(iqs269->regmap, IQS269_SYS_SETTINGS, <token> <answer> sys_reg, 
<token> (error) <answer> if 
<token> error; <answer> return 
if (!device_property_read_u32(&client->dev, <token> <answer> "azoteq,filt-str-lp-lta", 
<token> { <answer> &val)) 
if <token> > IQS269_FILT_STR_MAX) { <answer> (val 
<token> "Invalid filter strength: %u\n", <answer> dev_err(&client->dev, 
<token> -EINVAL; <answer> return 
<token> &= ~IQS269_FILT_STR_LP_LTA_MASK; <answer> sys_reg->filter 
sys_reg->filter |= <token> << IQS269_FILT_STR_LP_LTA_SHIFT); <answer> (val 
if (!device_property_read_u32(&client->dev, <token> <answer> "azoteq,filt-str-lp-cnt", 
<token> { <answer> &val)) 
if (val > IQS269_FILT_STR_MAX) <token> <answer> { 
<token> "Invalid filter strength: %u\n", <answer> dev_err(&client->dev, 
<token> -EINVAL; <answer> return 
<token> &= ~IQS269_FILT_STR_LP_CNT_MASK; <answer> sys_reg->filter 
<token> |= (val << IQS269_FILT_STR_LP_CNT_SHIFT); <answer> sys_reg->filter 
<token> (!device_property_read_u32(&client->dev, "azoteq,filt-str-np-lta", <answer> if 
<token> { <answer> &val)) 
<token> (val > IQS269_FILT_STR_MAX) { <answer> if 
dev_err(&client->dev, "Invalid filter strength: <token> <answer> %u\n", 
return <token> <answer> -EINVAL; 
<token> &= ~IQS269_FILT_STR_NP_LTA_MASK; <answer> sys_reg->filter 
<token> |= (val << IQS269_FILT_STR_NP_LTA_SHIFT); <answer> sys_reg->filter 
<token> (!device_property_read_u32(&client->dev, "azoteq,filt-str-np-cnt", <answer> if 
&val)) <token> <answer> { 
if <token> > IQS269_FILT_STR_MAX) { <answer> (val 
dev_err(&client->dev, <token> filter strength: %u\n", <answer> "Invalid 
return <token> <answer> -EINVAL; 
sys_reg->filter <token> ~IQS269_FILT_STR_NP_CNT_MASK; <answer> &= 
sys_reg->filter <token> val; <answer> |= 
if <token> "azoteq,rate-np-ms", <answer> (!device_property_read_u32(&client->dev, 
<token> { <answer> &val)) 
<token> (val > IQS269_RATE_NP_MS_MAX) { <answer> if 
<token> "Invalid report rate: %u\n", val); <answer> dev_err(&client->dev, 
<token> -EINVAL; <answer> return 
sys_reg->rate_np = <token> <answer> val; 
if (!device_property_read_u32(&client->dev, <token> <answer> "azoteq,rate-lp-ms", 
&val)) <token> <answer> { 
if (val > IQS269_RATE_LP_MS_MAX) <token> <answer> { 
dev_err(&client->dev, "Invalid report <token> %u\n", val); <answer> rate: 
<token> -EINVAL; <answer> return 
sys_reg->rate_lp <token> val; <answer> = 
if <token> "azoteq,rate-ulp-ms", <answer> (!device_property_read_u32(&client->dev, 
&val)) <token> <answer> { 
if (val > IQS269_RATE_ULP_MS_MAX) <token> <answer> { 
dev_err(&client->dev, "Invalid report rate: <token> val); <answer> %u\n", 
<token> -EINVAL; <answer> return 
sys_reg->rate_ulp = val <token> 16; <answer> / 
<token> (!device_property_read_u32(&client->dev, "azoteq,timeout-pwr-ms", <answer> if 
&val)) <token> <answer> { 
<token> (val > IQS269_TIMEOUT_PWR_MS_MAX) { <answer> if 
<token> "Invalid timeout: %u\n", val); <answer> dev_err(&client->dev, 
<token> -EINVAL; <answer> return 
sys_reg->timeout_pwr = val / <token> <answer> 512; 
if (!device_property_read_u32(&client->dev, <token> <answer> "azoteq,timeout-lta-ms", 
&val)) <token> <answer> { 
if <token> > IQS269_TIMEOUT_LTA_MS_MAX) { <answer> (val 
dev_err(&client->dev, <token> timeout: %u\n", val); <answer> "Invalid 
return <token> <answer> -EINVAL; 
<token> = val / 512; <answer> sys_reg->timeout_lta 
misc_a = <token> <answer> be16_to_cpu(sys_reg->misc_a); 
<token> = be16_to_cpu(sys_reg->misc_b); <answer> misc_b 
<token> &= ~IQS269_MISC_A_ATI_BAND_DISABLE; <answer> misc_a 
if <token> "azoteq,ati-band-disable")) <answer> (device_property_present(&client->dev, 
misc_a |= <token> <answer> IQS269_MISC_A_ATI_BAND_DISABLE; 
misc_a &= <token> <answer> ~IQS269_MISC_A_ATI_LP_ONLY; 
if <token> "azoteq,ati-lp-only")) <answer> (device_property_present(&client->dev, 
misc_a <token> IQS269_MISC_A_ATI_LP_ONLY; <answer> |= 
<token> &= ~IQS269_MISC_A_ATI_BAND_TIGHTEN; <answer> misc_a 
<token> (device_property_present(&client->dev, "azoteq,ati-band-tighten")) <answer> if 
misc_a <token> IQS269_MISC_A_ATI_BAND_TIGHTEN; <answer> |= 
misc_a &= <token> <answer> ~IQS269_MISC_A_FILT_DISABLE; 
if <token> "azoteq,filt-disable")) <answer> (device_property_present(&client->dev, 
<token> |= IQS269_MISC_A_FILT_DISABLE; <answer> misc_a 
if (!device_property_read_u32(&client->dev, <token> <answer> "azoteq,gpio3-select", 
&val)) <token> <answer> { 
if (val <token> IQS269_NUM_CH) { <answer> >= 
dev_err(&client->dev, "Invalid GPIO3 selection: <token> <answer> %u\n", 
<token> -EINVAL; <answer> return 
misc_a &= <token> <answer> ~IQS269_MISC_A_GPIO3_SELECT_MASK; 
misc_a |= (val <token> IQS269_MISC_A_GPIO3_SELECT_SHIFT); <answer> << 
<token> &= ~IQS269_MISC_A_DUAL_DIR; <answer> misc_a 
if (device_property_present(&client->dev, <token> <answer> "azoteq,dual-direction")) 
<token> |= IQS269_MISC_A_DUAL_DIR; <answer> misc_a 
if (!device_property_read_u32(&client->dev, "azoteq,tx-freq", &val)) <token> <answer> { 
if <token> > IQS269_MISC_A_TX_FREQ_MAX) { <answer> (val 
"Invalid excitation frequency: <token> val); <answer> %u\n", 
<token> -EINVAL; <answer> return 
<token> &= ~IQS269_MISC_A_TX_FREQ_MASK; <answer> misc_a 
misc_a |= (val <token> IQS269_MISC_A_TX_FREQ_SHIFT); <answer> << 
misc_a &= <token> <answer> ~IQS269_MISC_A_GLOBAL_CAP_SIZE; 
if <token> "azoteq,global-cap-increase")) <answer> (device_property_present(&client->dev, 
misc_a <token> IQS269_MISC_A_GLOBAL_CAP_SIZE; <answer> |= 
if <token> "azoteq,reseed-select", <answer> (!device_property_read_u32(&client->dev, 
<token> { <answer> &val)) 
if (val <token> IQS269_MISC_B_RESEED_UI_SEL_MAX) { <answer> > 
dev_err(&client->dev, "Invalid reseed <token> %u\n", <answer> selection: 
return <token> <answer> -EINVAL; 
misc_b &= <token> <answer> ~IQS269_MISC_B_RESEED_UI_SEL_MASK; 
misc_b |= (val <token> IQS269_MISC_B_RESEED_UI_SEL_SHIFT); <answer> << 
misc_b &= <token> <answer> ~IQS269_MISC_B_TRACKING_UI_ENABLE; 
<token> (device_property_present(&client->dev, "azoteq,tracking-enable")) <answer> if 
<token> |= IQS269_MISC_B_TRACKING_UI_ENABLE; <answer> misc_b 
<token> (!device_property_read_u32(&client->dev, "azoteq,filt-str-slider", <answer> if 
<token> { <answer> &val)) 
if (val > <token> { <answer> IQS269_FILT_STR_MAX) 
dev_err(&client->dev, "Invalid <token> strength: %u\n", <answer> filter 
<token> -EINVAL; <answer> return 
<token> &= ~IQS269_MISC_B_FILT_STR_SLIDER; <answer> misc_b 
<token> |= val; <answer> misc_b 
sys_reg->misc_a <token> cpu_to_be16(misc_a); <answer> = 
sys_reg->misc_b <token> cpu_to_be16(misc_b); <answer> = 
<token> = 0; <answer> sys_reg->active 
sys_reg->reseed = <token> <answer> 0; 
sys_reg->blocking = <token> <answer> 0; 
<token> = 0; <answer> sys_reg->slider_select[0] 
if <token> & IQS269_OTP_OPTION_HOLD) { <answer> (iqs269->otp_option 
<token> (!device_property_read_u32(&client->dev, <answer> if 
<token> &val)) { <answer> "azoteq,touch-hold-ms", 
if (val < <token> || <answer> IQS269_TOUCH_HOLD_MS_MIN 
val > <token> { <answer> IQS269_TOUCH_HOLD_MS_MAX) 
"Invalid <token> ceiling: %u\n", <answer> touch-and-hold 
return <token> <answer> -EINVAL; 
<token> = val / 256; <answer> sys_reg->slider_select[1] 
} else <token> (iqs269->ver_info.fw_num < IQS269_VER_INFO_FW_NUM_3) { <answer> if 
sys_reg->slider_select[1] <token> IQS269_TOUCH_HOLD_DEFAULT; <answer> = 
} <token> { <answer> else 
sys_reg->slider_select[1] = <token> <answer> 0; 
sys_reg->event_mask <token> ~((u8)IQS269_EVENT_MASK_SYS); <answer> = 
device_for_each_child_node(&client->dev, <token> { <answer> ch_node) 
error <token> iqs269_parse_chan(iqs269, ch_node); <answer> = 
<token> (error) { <answer> if 
return <token> <answer> error; 
sys_reg->redo_ati = <token> <answer> sys_reg->active; 
general = <token> <answer> be16_to_cpu(sys_reg->general); 
if <token> "azoteq,clk-div")) <answer> (device_property_present(&client->dev, 
general |= <token> <answer> IQS269_SYS_SETTINGS_CLK_DIV; 
general &= <token> <answer> ~IQS269_SYS_SETTINGS_ULP_AUTO; 
<token> &= ~IQS269_SYS_SETTINGS_DIS_AUTO; <answer> general 
<token> &= ~IQS269_SYS_SETTINGS_PWR_MODE_MASK; <answer> general 
<token> (!device_property_read_u32(&client->dev, "azoteq,suspend-mode", <answer> if 
&val)) <token> <answer> { 
if <token> > IQS269_SYS_SETTINGS_PWR_MODE_MAX) { <answer> (val 
dev_err(&client->dev, "Invalid suspend mode: <token> <answer> %u\n", 
<token> -EINVAL; <answer> return 
general <token> (val << IQS269_SYS_SETTINGS_PWR_MODE_SHIFT); <answer> |= 
if (!device_property_read_u32(&client->dev, <token> <answer> "azoteq,ulp-update", 
<token> { <answer> &val)) 
if (val <token> IQS269_SYS_SETTINGS_ULP_UPDATE_MAX) { <answer> > 
<token> "Invalid update rate: %u\n", val); <answer> dev_err(&client->dev, 
return <token> <answer> -EINVAL; 
general &= <token> <answer> ~IQS269_SYS_SETTINGS_ULP_UPDATE_MASK; 
general |= (val << <token> <answer> IQS269_SYS_SETTINGS_ULP_UPDATE_SHIFT); 
if (device_property_present(&client->dev, "linux,keycodes")) <token> <answer> { 
<token> scale = 1; <answer> int 
int count <token> device_property_count_u32(&client->dev, <answer> = 
if <token> > IQS269_NUM_GESTURES * IQS269_NUM_SL) { <answer> (count 
dev_err(&client->dev, "Too many keycodes <token> <answer> present\n"); 
<token> -EINVAL; <answer> return 
} else if (count <token> 0) { <answer> < 
dev_err(&client->dev, "Failed to <token> keycodes: %d\n", <answer> count 
return <token> <answer> count; 
error = <token> <answer> device_property_read_u32_array(&client->dev, 
*iqs269->sl_code, <token> <answer> count); 
if <token> { <answer> (error) 
dev_err(&client->dev, "Failed <token> read keycodes: %d\n", <answer> to 
return <token> <answer> error; 
if <token> <answer> (device_property_present(&client->dev, 
<token> |= IQS269_SYS_SETTINGS_SLIDER_SWIPE; <answer> general 
if (iqs269->ver_info.fw_num < <token> <answer> IQS269_VER_INFO_FW_NUM_3) 
scale = <token> <answer> 4; 
<token> (!device_property_read_u32(&client->dev, <answer> if 
"azoteq,timeout-tap-ms", <token> { <answer> &val)) 
if (val > <token> / scale) { <answer> IQS269_TIMEOUT_TAP_MS_MAX 
dev_err(&client->dev, "Invalid <token> %u\n", <answer> timeout: 
<token> -EINVAL; <answer> return 
sys_reg->timeout_tap = val / <token> / scale); <answer> (16 
<token> (!device_property_read_u32(&client->dev, <answer> if 
&val)) <token> <answer> { 
if (val > <token> / scale) { <answer> IQS269_TIMEOUT_SWIPE_MS_MAX 
dev_err(&client->dev, "Invalid timeout: <token> <answer> %u\n", 
<token> -EINVAL; <answer> return 
sys_reg->timeout_swipe = val / (16 / <token> <answer> scale); 
if <token> <answer> (!device_property_read_u32(&client->dev, 
"azoteq,thresh-swipe", &val)) <token> <answer> { 
if <token> > IQS269_THRESH_SWIPE_MAX) { <answer> (val 
dev_err(&client->dev, <token> threshold: %u\n", <answer> "Invalid 
<token> -EINVAL; <answer> return 
<token> = val; <answer> sys_reg->thresh_swipe 
sys_reg->event_mask &= <token> <answer> ~IQS269_EVENT_MASK_GESTURE; 
<token> &= ~IQS269_SYS_SETTINGS_RESEED_OFFSET; <answer> general 
if (device_property_present(&client->dev, <token> <answer> "azoteq,reseed-offset")) 
general <token> IQS269_SYS_SETTINGS_RESEED_OFFSET; <answer> |= 
<token> |= IQS269_SYS_SETTINGS_EVENT_MODE; <answer> general 
<token> (iqs269_slider_type(iqs269, 0) == IQS269_SLIDER_RAW || <answer> if 
iqs269_slider_type(iqs269, 1) <token> IQS269_SLIDER_RAW) <answer> == 
general <token> IQS269_SYS_SETTINGS_EVENT_MODE_LP; <answer> |= 
general |= <token> <answer> IQS269_SYS_SETTINGS_REDO_ATI; 
general |= <token> <answer> IQS269_SYS_SETTINGS_ACK_RESET; 
sys_reg->general = <token> <answer> cpu_to_be16(general); 
return <token> <answer> 0; 
static const <token> reg_sequence iqs269_tws_init[] = { <answer> struct 
{ IQS269_TOUCH_HOLD_SLIDER_SEL, <token> }, <answer> IQS269_TOUCH_HOLD_DEFAULT 
{ <token> 0x580F }, <answer> 0xF0, 
{ 0xF0, <token> }, <answer> 0x59EF 
static int iqs269_dev_init(struct <token> *iqs269) <answer> iqs269_private 
<token> error; <answer> int 
if <token> == IQS269_OTP_OPTION_TWS && <answer> (iqs269->otp_option 
iqs269->ver_info.fw_num < <token> { <answer> IQS269_VER_INFO_FW_NUM_3) 
<token> = regmap_multi_reg_write(iqs269->regmap, iqs269_tws_init, <answer> error 
<token> (error) <answer> if 
<token> err_mutex; <answer> goto 
error = regmap_update_bits(iqs269->regmap, <token> <answer> IQS269_HALL_UI, 
iqs269->hall_enable ? ~0 <token> 0); <answer> : 
if <token> <answer> (error) 
<token> err_mutex; <answer> goto 
<token> = regmap_raw_write(iqs269->regmap, IQS269_SYS_SETTINGS, <answer> error 
<token> sizeof(iqs269->sys_reg)); <answer> &iqs269->sys_reg, 
if <token> <answer> (error) 
<token> err_mutex; <answer> goto 
<token> 2100); <answer> usleep_range(2000, 
<token> = true; <answer> iqs269->ati_current 
return <token> <answer> error; 
static int <token> iqs269_private *iqs269) <answer> iqs269_input_init(struct 
struct i2c_client *client = <token> <answer> iqs269->client; 
unsigned <token> sw_code, keycode; <answer> int 
int <token> i, j; <answer> error, 
iqs269->keypad = <token> <answer> devm_input_allocate_device(&client->dev); 
if <token> <answer> (!iqs269->keypad) 
<token> -ENOMEM; <answer> return 
<token> = ARRAY_SIZE(iqs269->keycode); <answer> iqs269->keypad->keycodemax 
iqs269->keypad->keycode = <token> <answer> iqs269->keycode; 
<token> = sizeof(*iqs269->keycode); <answer> iqs269->keypad->keycodesize 
iqs269->keypad->name <token> "iqs269a_keypad"; <answer> = 
iqs269->keypad->id.bustype = <token> <answer> BUS_I2C; 
for (i = 0; <token> < ARRAY_SIZE(iqs269_events); i++) { <answer> i 
sw_code = <token> <answer> iqs269->switches[i].code; 
for (j <token> 0; j < IQS269_NUM_CH; j++) { <answer> = 
<token> = iqs269->keycode[i * IQS269_NUM_CH + j]; <answer> keycode 
switch <token> { <answer> (j) 
case <token> <answer> IQS269_CHx_HALL_ACTIVE: 
if <token> && <answer> (iqs269->hall_enable 
EV_SW, <token> <answer> sw_code); 
<token> IQS269_CHx_HALL_INACTIVE: <answer> case 
if <token> <answer> (iqs269->hall_enable) 
if (keycode != <token> <answer> KEY_RESERVED) 
<token> keycode); <answer> EV_KEY, 
for (i = 0; i <token> IQS269_NUM_SL; i++) { <answer> < 
<token> (iqs269_slider_type(iqs269, i) == IQS269_SLIDER_NONE) <answer> if 
<token> = devm_input_allocate_device(&client->dev); <answer> iqs269->slider[i] 
<token> (!iqs269->slider[i]) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = ARRAY_SIZE(iqs269->sl_code[i]); <answer> iqs269->slider[i]->keycodemax 
iqs269->slider[i]->keycode <token> iqs269->sl_code[i]; <answer> = 
<token> = sizeof(**iqs269->sl_code); <answer> iqs269->slider[i]->keycodesize 
iqs269->slider[i]->name = i ? <token> <answer> "iqs269a_slider_1" 
: <token> <answer> "iqs269a_slider_0"; 
iqs269->slider[i]->id.bustype = <token> <answer> BUS_I2C; 
for (j = 0; j < <token> j++) <answer> IQS269_NUM_GESTURES; 
if (iqs269->sl_code[i][j] != <token> <answer> KEY_RESERVED) 
input_set_capability(iqs269->slider[i], <token> <answer> EV_KEY, 
if (iqs269_slider_type(iqs269, i) <token> IQS269_SLIDER_RAW) { <answer> == 
EV_KEY, <token> <answer> BTN_TOUCH); 
<token> 0, 255, 0, 0); <answer> ABS_X, 
error <token> input_register_device(iqs269->slider[i]); <answer> = 
if <token> { <answer> (error) 
"Failed to register slider %d: %d\n", i, <token> <answer> error); 
<token> error; <answer> return 
<token> 0; <answer> return 
<token> int iqs269_report(struct iqs269_private *iqs269) <answer> static 
struct i2c_client <token> = iqs269->client; <answer> *client 
struct iqs269_flags <token> <answer> flags; 
unsigned int sw_code, <token> <answer> keycode; 
<token> error, i, j; <answer> int 
u8 <token> <answer> slider_x[IQS269_NUM_SL]; 
u8 dir_mask, <token> <answer> state; 
error = regmap_raw_read(iqs269->regmap, <token> &flags, <answer> IQS269_SYS_FLAGS, 
if <token> { <answer> (error) 
dev_err(&client->dev, "Failed to read device status: <token> <answer> %d\n", 
return <token> <answer> error; 
<token> (be16_to_cpu(flags.system) & IQS269_SYS_FLAGS_SHOW_RESET) { <answer> if 
dev_err(&client->dev, "Unexpected device <token> <answer> reset\n"); 
error <token> iqs269_dev_init(iqs269); <answer> = 
if <token> <answer> (error) 
"Failed to re-initialize device: <token> error); <answer> %d\n", 
<token> error; <answer> return 
<token> (be16_to_cpu(flags.system) & IQS269_SYS_FLAGS_IN_ATI) <answer> if 
return <token> <answer> 0; 
if (iqs269_slider_type(iqs269, <token> == IQS269_SLIDER_RAW || <answer> 0) 
iqs269_slider_type(iqs269, 1) <token> IQS269_SLIDER_RAW) { <answer> == 
error <token> regmap_raw_read(iqs269->regmap, IQS269_SLIDER_X, <answer> = 
<token> sizeof(slider_x)); <answer> slider_x, 
<token> (error) { <answer> if 
"Failed to read slider position: <token> error); <answer> %d\n", 
<token> error; <answer> return 
for (i = 0; i < IQS269_NUM_SL; i++) <token> <answer> { 
flags.gesture >>= (i * <token> <answer> IQS269_NUM_GESTURES); 
switch <token> i)) { <answer> (iqs269_slider_type(iqs269, 
case <token> <answer> IQS269_SLIDER_NONE: 
<token> IQS269_SLIDER_KEY: <answer> case 
for (j = <token> j < IQS269_NUM_GESTURES; j++) <answer> 0; 
flags.gesture <token> BIT(j)); <answer> & 
if (!(flags.gesture <token> (BIT(IQS269_GESTURE_FLICK_NEG) | <answer> & 
BIT(IQS269_GESTURE_FLICK_POS) <token> <answer> | 
for (j = <token> j < IQS269_NUM_GESTURES; j++) <answer> 0; 
<token> (j != IQS269_GESTURE_HOLD) <answer> if 
case <token> <answer> IQS269_SLIDER_RAW: 
state = <token> <answer> flags.states[IQS269_ST_OFFS_TOUCH]; 
<token> &= iqs269->sys_reg.slider_select[i]; <answer> state 
<token> BTN_TOUCH, state); <answer> input_report_key(iqs269->slider[i], 
if <token> <answer> (state) 
ABS_X, <token> <answer> slider_x[i]); 
for (i = 0; i < <token> i++) { <answer> ARRAY_SIZE(iqs269_events); 
dir_mask <token> flags.states[IQS269_ST_OFFS_DIR]; <answer> = 
<token> (!iqs269_events[i].dir_up) <answer> if 
dir_mask <token> ~dir_mask; <answer> = 
<token> = flags.states[iqs269_events[i].st_offs] & dir_mask; <answer> state 
<token> = iqs269->switches[i].code; <answer> sw_code 
for (j = 0; <token> < IQS269_NUM_CH; j++) { <answer> j 
keycode = <token> * IQS269_NUM_CH + j]; <answer> iqs269->keycode[i 
switch <token> { <answer> (j) 
case <token> <answer> IQS269_CHx_HALL_ACTIVE: 
if (iqs269->hall_enable <token> <answer> && 
state & <token> <answer> BIT(j)); 
<token> IQS269_CHx_HALL_INACTIVE: <answer> case 
if <token> <answer> (iqs269->hall_enable) 
<token> keycode, <answer> input_report_key(iqs269->keypad, 
state <token> BIT(j)); <answer> & 
<token> 0; <answer> return 
static irqreturn_t <token> irq, void *context) <answer> iqs269_irq(int 
struct iqs269_private *iqs269 = <token> <answer> context; 
<token> (iqs269_report(iqs269)) <answer> if 
<token> IRQ_NONE; <answer> return 
<token> IRQ_HANDLED; <answer> return 
static ssize_t counts_show(struct <token> *dev, <answer> device 
struct device_attribute *attr, <token> *buf) <answer> char 
struct iqs269_private <token> = dev_get_drvdata(dev); <answer> *iqs269 
struct <token> *client = iqs269->client; <answer> i2c_client 
__le16 <token> <answer> counts; 
<token> error; <answer> int 
if (!iqs269->ati_current <token> iqs269->hall_enable) <answer> || 
<token> -EPERM; <answer> return 
<token> (!completion_done(&iqs269->ati_done)) <answer> if 
return <token> <answer> -EBUSY; 
error = <token> <answer> regmap_raw_read(iqs269->regmap, 
IQS269_CHx_COUNTS <token> iqs269->ch_num * 2, <answer> + 
&counts, <token> <answer> sizeof(counts)); 
if <token> <answer> (error) 
<token> error; <answer> return 
return sysfs_emit(buf, <token> le16_to_cpu(counts)); <answer> "%u\n", 
static ssize_t hall_bin_show(struct device <token> <answer> *dev, 
struct device_attribute <token> char *buf) <answer> *attr, 
struct <token> *iqs269 = dev_get_drvdata(dev); <answer> iqs269_private 
struct iqs269_ch_reg <token> = iqs269->sys_reg.ch_reg; <answer> *ch_reg 
struct i2c_client *client = <token> <answer> iqs269->client; 
unsigned int <token> <answer> val; 
int <token> <answer> error; 
error <token> regmap_read(iqs269->regmap, IQS269_CAL_DATA_A, &val); <answer> = 
if <token> <answer> (error) 
<token> error; <answer> return 
<token> (ch_reg[IQS269_CHx_HALL_ACTIVE].rx_enable & <answer> switch 
ch_reg[IQS269_CHx_HALL_INACTIVE].rx_enable) <token> <answer> { 
<token> IQS269_HALL_PAD_R: <answer> case 
<token> &= IQS269_CAL_DATA_A_HALL_BIN_R_MASK; <answer> val 
val >>= <token> <answer> IQS269_CAL_DATA_A_HALL_BIN_R_SHIFT; 
<token> IQS269_HALL_PAD_L: <answer> case 
val <token> IQS269_CAL_DATA_A_HALL_BIN_L_MASK; <answer> &= 
val <token> IQS269_CAL_DATA_A_HALL_BIN_L_SHIFT; <answer> >>= 
<token> -EINVAL; <answer> return 
return <token> "%u\n", val); <answer> sysfs_emit(buf, 
static ssize_t <token> device *dev, <answer> hall_enable_show(struct 
struct device_attribute *attr, <token> *buf) <answer> char 
<token> iqs269_private *iqs269 = dev_get_drvdata(dev); <answer> struct 
<token> sysfs_emit(buf, "%u\n", iqs269->hall_enable); <answer> return 
static ssize_t hall_enable_store(struct <token> *dev, <answer> device 
struct device_attribute *attr, const <token> *buf, <answer> char 
<token> count) <answer> size_t 
<token> iqs269_private *iqs269 = dev_get_drvdata(dev); <answer> struct 
unsigned int <token> <answer> val; 
<token> error; <answer> int 
error = <token> 10, &val); <answer> kstrtouint(buf, 
<token> (error) <answer> if 
<token> error; <answer> return 
iqs269->hall_enable <token> val; <answer> = 
<token> = false; <answer> iqs269->ati_current 
return <token> <answer> count; 
static ssize_t ch_number_show(struct <token> *dev, <answer> device 
struct device_attribute *attr, <token> *buf) <answer> char 
struct iqs269_private *iqs269 <token> dev_get_drvdata(dev); <answer> = 
<token> sysfs_emit(buf, "%u\n", iqs269->ch_num); <answer> return 
static <token> ch_number_store(struct device *dev, <answer> ssize_t 
struct device_attribute *attr, const char <token> <answer> *buf, 
<token> count) <answer> size_t 
struct iqs269_private *iqs269 <token> dev_get_drvdata(dev); <answer> = 
unsigned <token> val; <answer> int 
int <token> <answer> error; 
error = <token> 10, &val); <answer> kstrtouint(buf, 
if <token> <answer> (error) 
<token> error; <answer> return 
<token> (val >= IQS269_NUM_CH) <answer> if 
<token> -EINVAL; <answer> return 
iqs269->ch_num = <token> <answer> val; 
return <token> <answer> count; 
static ssize_t rx_enable_show(struct <token> *dev, <answer> device 
struct device_attribute *attr, <token> *buf) <answer> char 
struct iqs269_private *iqs269 <token> dev_get_drvdata(dev); <answer> = 
struct <token> *ch_reg = iqs269->sys_reg.ch_reg; <answer> iqs269_ch_reg 
return sysfs_emit(buf, <token> ch_reg[iqs269->ch_num].rx_enable); <answer> "%u\n", 
static ssize_t rx_enable_store(struct device <token> <answer> *dev, 
struct device_attribute *attr, <token> char *buf, <answer> const 
<token> count) <answer> size_t 
struct iqs269_private *iqs269 <token> dev_get_drvdata(dev); <answer> = 
struct iqs269_ch_reg *ch_reg = <token> <answer> iqs269->sys_reg.ch_reg; 
<token> int val; <answer> unsigned 
int <token> <answer> error; 
error = kstrtouint(buf, 10, <token> <answer> &val); 
if <token> <answer> (error) 
return <token> <answer> error; 
if (val > <token> <answer> 0xFF) 
return <token> <answer> -EINVAL; 
ch_reg[iqs269->ch_num].rx_enable <token> val; <answer> = 
iqs269->ati_current = <token> <answer> false; 
<token> count; <answer> return 
<token> ssize_t ati_mode_show(struct device *dev, <answer> static 
struct device_attribute *attr, <token> *buf) <answer> char 
struct iqs269_private <token> = dev_get_drvdata(dev); <answer> *iqs269 
unsigned <token> val; <answer> int 
<token> error; <answer> int 
error = iqs269_ati_mode_get(iqs269, <token> &val); <answer> iqs269->ch_num, 
<token> (error) <answer> if 
return <token> <answer> error; 
return sysfs_emit(buf, <token> val); <answer> "%u\n", 
static <token> ati_mode_store(struct device *dev, <answer> ssize_t 
struct device_attribute *attr, const <token> *buf, <answer> char 
size_t <token> <answer> count) 
struct iqs269_private *iqs269 <token> dev_get_drvdata(dev); <answer> = 
<token> int val; <answer> unsigned 
int <token> <answer> error; 
error = kstrtouint(buf, 10, <token> <answer> &val); 
<token> (error) <answer> if 
<token> error; <answer> return 
<token> = iqs269_ati_mode_set(iqs269, iqs269->ch_num, val); <answer> error 
<token> (error) <answer> if 
return <token> <answer> error; 
<token> count; <answer> return 
static ssize_t ati_base_show(struct <token> *dev, <answer> device 
struct <token> *attr, char *buf) <answer> device_attribute 
struct iqs269_private *iqs269 = <token> <answer> dev_get_drvdata(dev); 
<token> int val; <answer> unsigned 
int <token> <answer> error; 
error = iqs269_ati_base_get(iqs269, <token> &val); <answer> iqs269->ch_num, 
<token> (error) <answer> if 
<token> error; <answer> return 
<token> sysfs_emit(buf, "%u\n", val); <answer> return 
static ssize_t <token> device *dev, <answer> ati_base_store(struct 
struct device_attribute *attr, <token> char *buf, <answer> const 
size_t <token> <answer> count) 
struct iqs269_private <token> = dev_get_drvdata(dev); <answer> *iqs269 
unsigned <token> val; <answer> int 
int <token> <answer> error; 
error <token> kstrtouint(buf, 10, &val); <answer> = 
<token> (error) <answer> if 
return <token> <answer> error; 
error <token> iqs269_ati_base_set(iqs269, iqs269->ch_num, val); <answer> = 
if <token> <answer> (error) 
<token> error; <answer> return 
<token> count; <answer> return 
static <token> ati_target_show(struct device *dev, <answer> ssize_t 
struct device_attribute *attr, <token> *buf) <answer> char 
struct iqs269_private *iqs269 = <token> <answer> dev_get_drvdata(dev); 
unsigned <token> val; <answer> int 
<token> error; <answer> int 
<token> = iqs269_ati_target_get(iqs269, iqs269->ch_num, &val); <answer> error 
if <token> <answer> (error) 
<token> error; <answer> return 
return sysfs_emit(buf, <token> val); <answer> "%u\n", 
static ssize_t ati_target_store(struct <token> *dev, <answer> device 
struct device_attribute <token> const char *buf, <answer> *attr, 
size_t <token> <answer> count) 
<token> iqs269_private *iqs269 = dev_get_drvdata(dev); <answer> struct 
unsigned int <token> <answer> val; 
<token> error; <answer> int 
error <token> kstrtouint(buf, 10, &val); <answer> = 
#include <token> <answer> <sound/soc-acpi.h> 
#include <token> <answer> <sound/soc-acpi-intel-match.h> 
<token> "soc-acpi-intel-sdw-mockup-match.h" <answer> #include 
static const <token> snd_soc_acpi_endpoint sdw_mockup_single_endpoint = { <answer> struct 
.num = <token> <answer> 0, 
.aggregated <token> 0, <answer> = 
.group_position <token> 0, <answer> = 
<token> = 0, <answer> .group_id 
static const struct snd_soc_acpi_endpoint sdw_mockup_l_endpoint <token> { <answer> = 
.num = <token> <answer> 0, 
<token> = 1, <answer> .aggregated 
<token> = 0, <answer> .group_position 
.group_id = <token> <answer> 1, 
static const struct <token> sdw_mockup_r_endpoint = { <answer> snd_soc_acpi_endpoint 
.num <token> 0, <answer> = 
.aggregated = <token> <answer> 1, 
.group_position <token> 1, <answer> = 
.group_id <token> 1, <answer> = 
static const struct snd_soc_acpi_adr_device <token> = { <answer> sdw_mockup_headset_0_adr[] 
<token> = 0x0000000105AA5500ull, <answer> .adr 
.num_endpoints = <token> <answer> 1, 
<token> = &sdw_mockup_single_endpoint, <answer> .endpoints 
.name_prefix <token> "sdw_mockup_headset0" <answer> = 
static const struct <token> sdw_mockup_headset_1_adr[] = { <answer> snd_soc_acpi_adr_device 
.adr = <token> <answer> 0x0001000105AA5500ull, 
<token> = 1, <answer> .num_endpoints 
.endpoints = <token> <answer> &sdw_mockup_single_endpoint, 
.name_prefix = <token> <answer> "sdw_mockup_headset1" 
static <token> struct snd_soc_acpi_adr_device sdw_mockup_amp_1_adr[] = { <answer> const 
.adr <token> 0x000100010555AA00ull, <answer> = 
<token> = 1, <answer> .num_endpoints 
.endpoints <token> &sdw_mockup_single_endpoint, <answer> = 
.name_prefix = <token> <answer> "sdw_mockup_amp1" 
static const struct <token> sdw_mockup_amp_2_adr[] = { <answer> snd_soc_acpi_adr_device 
.adr <token> 0x000200010555AA00ull, <answer> = 
.num_endpoints <token> 1, <answer> = 
.endpoints <token> &sdw_mockup_single_endpoint, <answer> = 
.name_prefix = <token> <answer> "sdw_mockup_amp2" 
<token> const struct snd_soc_acpi_adr_device sdw_mockup_mic_0_adr[] = { <answer> static 
.adr <token> 0x0000000105555500ull, <answer> = 
.num_endpoints = <token> <answer> 1, 
.endpoints = <token> <answer> &sdw_mockup_single_endpoint, 
.name_prefix <token> "sdw_mockup_mic0" <answer> = 
static <token> struct snd_soc_acpi_adr_device sdw_mockup_mic_3_adr[] = { <answer> const 
.adr <token> 0x0003000105555500ull, <answer> = 
<token> = 1, <answer> .num_endpoints 
.endpoints = <token> <answer> &sdw_mockup_single_endpoint, 
.name_prefix = <token> <answer> "sdw_mockup_mic3" 
static const struct snd_soc_acpi_adr_device sdw_mockup_amp_1_group1_adr[] = <token> <answer> { 
.adr = <token> <answer> 0x000100010555AA00ull, 
.num_endpoints <token> 1, <answer> = 
.endpoints <token> &sdw_mockup_l_endpoint, <answer> = 
.name_prefix <token> "sdw_mockup_amp1_l" <answer> = 
static const struct snd_soc_acpi_adr_device <token> = { <answer> sdw_mockup_amp_2_group1_adr[] 
<token> = 0x000200010555AA00ull, <answer> .adr 
<token> = 1, <answer> .num_endpoints 
<token> = &sdw_mockup_r_endpoint, <answer> .endpoints 
.name_prefix <token> "sdw_mockup_amp2_r" <answer> = 
const struct snd_soc_acpi_link_adr <token> = { <answer> sdw_mockup_headset_1amp_mic[] 
<token> = BIT(0), <answer> .mask 
<token> = ARRAY_SIZE(sdw_mockup_headset_0_adr), <answer> .num_adr 
.adr_d = <token> <answer> sdw_mockup_headset_0_adr, 
<token> = BIT(1), <answer> .mask 
.num_adr <token> ARRAY_SIZE(sdw_mockup_amp_1_adr), <answer> = 
.adr_d = <token> <answer> sdw_mockup_amp_1_adr, 
.mask <token> BIT(3), <answer> = 
.num_adr <token> ARRAY_SIZE(sdw_mockup_mic_3_adr), <answer> = 
.adr_d = <token> <answer> sdw_mockup_mic_3_adr, 
<token> struct snd_soc_acpi_link_adr sdw_mockup_headset_2amps_mic[] = { <answer> const 
.mask = <token> <answer> BIT(0), 
.num_adr <token> ARRAY_SIZE(sdw_mockup_headset_0_adr), <answer> = 
.adr_d <token> sdw_mockup_headset_0_adr, <answer> = 
<token> = BIT(1), <answer> .mask 
.num_adr = <token> <answer> ARRAY_SIZE(sdw_mockup_amp_1_group1_adr), 
.adr_d = <token> <answer> sdw_mockup_amp_1_group1_adr, 
.mask = <token> <answer> BIT(2), 
.num_adr <token> ARRAY_SIZE(sdw_mockup_amp_2_group1_adr), <answer> = 
.adr_d = <token> <answer> sdw_mockup_amp_2_group1_adr, 
<token> = BIT(3), <answer> .mask 
.num_adr = <token> <answer> ARRAY_SIZE(sdw_mockup_mic_3_adr), 
<token> = sdw_mockup_mic_3_adr, <answer> .adr_d 
<token> struct snd_soc_acpi_link_adr sdw_mockup_mic_headset_1amp[] = { <answer> const 
.mask <token> BIT(1), <answer> = 
.num_adr = <token> <answer> ARRAY_SIZE(sdw_mockup_headset_1_adr), 
.adr_d <token> sdw_mockup_headset_1_adr, <answer> = 
.mask = <token> <answer> BIT(2), 
<token> = ARRAY_SIZE(sdw_mockup_amp_2_adr), <answer> .num_adr 
.adr_d = <token> <answer> sdw_mockup_amp_2_adr, 
<token> = BIT(0), <answer> .mask 
.num_adr = <token> <answer> ARRAY_SIZE(sdw_mockup_mic_0_adr), 
.adr_d = <token> <answer> sdw_mockup_mic_0_adr, 
<token> KMSG_COMPONENT "smc" <answer> #define 
<token> pr_fmt(fmt) KMSG_COMPONENT ": " fmt <answer> #define 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/socket.h> 
#include <token> <answer> <linux/workqueue.h> 
<token> <linux/in.h> <answer> #include 
<token> <linux/sched/signal.h> <answer> #include 
<token> <linux/if_vlan.h> <answer> #include 
#include <token> <answer> <linux/rcupdate_wait.h> 
#include <token> <answer> <linux/ctype.h> 
<token> <linux/splice.h> <answer> #include 
#include <token> <answer> <net/sock.h> 
#include <token> <answer> <net/tcp.h> 
<token> <net/smc.h> <answer> #include 
<token> <asm/ioctls.h> <answer> #include 
#include <token> <answer> <net/net_namespace.h> 
<token> <net/netns/generic.h> <answer> #include 
<token> "smc_netns.h" <answer> #include 
<token> "smc.h" <answer> #include 
<token> "smc_clc.h" <answer> #include 
<token> "smc_llc.h" <answer> #include 
#include <token> <answer> "smc_cdc.h" 
<token> "smc_core.h" <answer> #include 
<token> "smc_ib.h" <answer> #include 
<token> "smc_ism.h" <answer> #include 
#include <token> <answer> "smc_pnet.h" 
<token> "smc_netlink.h" <answer> #include 
<token> "smc_tx.h" <answer> #include 
<token> "smc_rx.h" <answer> #include 
#include <token> <answer> "smc_close.h" 
<token> "smc_stats.h" <answer> #include 
<token> "smc_tracepoint.h" <answer> #include 
<token> "smc_sysctl.h" <answer> #include 
<token> void smc_release_cb(struct sock *sk) <answer> static 
struct smc_sock *smc <token> smc_sk(sk); <answer> = 
if (smc->conn.tx_in_release_sock) <token> <answer> { 
smc->conn.tx_in_release_sock = <token> <answer> false; 
struct <token> smc_proto = { <answer> proto 
.name = <token> <answer> "SMC", 
.owner <token> THIS_MODULE, <answer> = 
.keepalive <token> smc_set_keepalive, <answer> = 
.hash <token> smc_hash_sk, <answer> = 
.unhash = <token> <answer> smc_unhash_sk, 
<token> = smc_release_cb, <answer> .release_cb 
.obj_size = sizeof(struct <token> <answer> smc_sock), 
.h.smc_hash <token> &smc_v4_hashinfo, <answer> = 
<token> = SLAB_TYPESAFE_BY_RCU, <answer> .slab_flags 
<token> proto smc_proto6 = { <answer> struct 
<token> = "SMC6", <answer> .name 
.owner <token> THIS_MODULE, <answer> = 
.keepalive <token> smc_set_keepalive, <answer> = 
.hash = <token> <answer> smc_hash_sk, 
.unhash = <token> <answer> smc_unhash_sk, 
<token> = smc_release_cb, <answer> .release_cb 
.obj_size <token> sizeof(struct smc_sock), <answer> = 
.h.smc_hash <token> &smc_v6_hashinfo, <answer> = 
<token> = SLAB_TYPESAFE_BY_RCU, <answer> .slab_flags 
<token> void smc_fback_restore_callbacks(struct smc_sock *smc) <answer> static 
struct <token> *clcsk = smc->clcsock->sk; <answer> sock 
<token> = NULL; <answer> clcsk->sk_user_data 
<token> &smc->clcsk_state_change); <answer> smc_clcsock_restore_cb(&clcsk->sk_state_change, 
<token> &smc->clcsk_data_ready); <answer> smc_clcsock_restore_cb(&clcsk->sk_data_ready, 
<token> &smc->clcsk_write_space); <answer> smc_clcsock_restore_cb(&clcsk->sk_write_space, 
<token> &smc->clcsk_error_report); <answer> smc_clcsock_restore_cb(&clcsk->sk_error_report, 
static void smc_restore_fallback_changes(struct <token> *smc) <answer> smc_sock 
<token> SINGLE_DEPTH_NESTING); <answer> lock_sock_nested(sk, 
<token> (old_state == SMC_INIT && sk->sk_state == SMC_ACTIVE && <answer> if 
<token> = __smc_release(smc); <answer> rc 
#define SK_FLAGS_SMC_TO_CLC <token> << SOCK_URGINLINE) | \ <answer> ((1UL 
(1UL << SOCK_KEEPOPEN) <token> \ <answer> | 
(1UL << <token> | \ <answer> SOCK_LINGER) 
(1UL << <token> | \ <answer> SOCK_BROADCAST) 
(1UL <token> SOCK_TIMESTAMP) | \ <answer> << 
(1UL << <token> | \ <answer> SOCK_DBG) 
(1UL << SOCK_RCVTSTAMP) | <token> <answer> \ 
(1UL << SOCK_RCVTSTAMPNS) <token> \ <answer> | 
(1UL << SOCK_LOCALROUTE) | <token> <answer> \ 
(1UL <token> SOCK_TIMESTAMPING_RX_SOFTWARE) | \ <answer> << 
(1UL << <token> | \ <answer> SOCK_RXQ_OVFL) 
(1UL << <token> | \ <answer> SOCK_WIFI_STATUS) 
<token> << SOCK_NOFCS) | \ <answer> (1UL 
<token> << SOCK_FILTER_LOCKED) | \ <answer> (1UL 
<token> << SOCK_TSTAMP_NEW)) <answer> (1UL 
for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) <token> <answer> { 
<token> (!smc_link_active(&lgr->lnk[i])) <answer> if 
rc <token> smcr_link_reg_buf(&lgr->lnk[i], rmb_desc); <answer> = 
<token> (rc) <answer> if 
<token> out; <answer> goto 
qentry = <token> NULL, 2 * SMC_LLC_WAIT_TIME, <answer> smc_llc_wait(link->lgr, 
if (!qentry) <token> <answer> { 
struct <token> dclc; <answer> smc_clc_msg_decline 
rc = smc_clc_wait_msg(smc, <token> sizeof(dclc), <answer> &dclc, 
<token> CLC_WAIT_TIME_SHORT); <answer> SMC_CLC_DECLINE, 
return <token> == -EAGAIN ? SMC_CLC_DECL_TIMEOUT_CL : rc; <answer> rc 
<token> = smc_llc_eval_conf_link(qentry, SMC_LLC_REQ); <answer> rc 
<token> (rc) <answer> if 
<token> SMC_CLC_DECL_RMBE_EC; <answer> return 
<token> = smc_ib_modify_qp_rts(link); <answer> rc 
<token> (rc) <answer> if 
<token> SMC_CLC_DECL_ERR_RDYLNK; <answer> return 
return <token> <answer> rc; 
<token> ini); <answer> smc_pnet_find_roce_resource(smc->clcsock->sk, 
if (!ini->check_smcrv2 <token> !ini->ib_dev) <answer> && 
<token> SMC_CLC_DECL_NOSMCRDEV; <answer> return 
<token> (ini->check_smcrv2 && !ini->smcrv2.ib_dev_v2) <answer> if 
return <token> <answer> SMC_CLC_DECL_NOSMCRDEV; 
<token> 0; <answer> return 
static int smc_find_ism_v2_device_clnt(struct <token> *smc, <answer> smc_sock 
<token> smc_init_info *ini) <answer> struct 
int <token> = SMC_CLC_DECL_NOSMCDDEV; <answer> rc 
struct smcd_dev <token> <answer> *smcd; 
int i = 1, <token> = 1; <answer> entry 
<token> is_emulated; <answer> bool 
<token> chid; <answer> u16 
<token> (smcd_indicated(ini->smc_type_v1)) <answer> if 
ini->ism_dev[i] <token> smcd; <answer> = 
ini->ism_chid[i] <token> chid; <answer> = 
ini->is_smcd = <token> <answer> true; 
<token> = 0; <answer> rc 
entry = is_emulated ? entry + 2 : entry + <token> <answer> 1; 
<token> (entry > SMCD_CLC_MAX_V2_GID_ENTRIES) <answer> if 
ini->ism_offered_cnt <token> i - 1; <answer> = 
<token> (!ini->ism_dev[0] && !ini->ism_dev[1]) <answer> if 
ini->smcd_version = <token> <answer> 0; 
<token> rc; <answer> return 
static int smc_connect_ism_vlan_cleanup(struct <token> *smc, <answer> smc_sock 
struct <token> *ini) <answer> smc_init_info 
<token> (!smcd_indicated(ini->smc_type_v1)) <answer> if 
<token> 0; <answer> return 
if (ini->vlan_id <token> smc_ism_put_vlan(ini->ism_dev[0], ini->vlan_id)) <answer> && 
return <token> <answer> SMC_CLC_DECL_CNFERR; 
return <token> <answer> 0; 
#define SMC_CLC_MAX_ACCEPT_LEN <token> <answer> \ 
(sizeof(struct <token> + \ <answer> smc_clc_msg_accept_confirm) 
<token> smc_clc_first_contact_ext_v2x) + \ <answer> sizeof(struct 
sizeof(struct <token> <answer> smc_clc_msg_trail)) 
static <token> <answer> int 
<token> smc_clc_msg_accept_confirm *aclc, <answer> smc_v2_determine_accepted_chid(struct 
struct <token> *ini) <answer> smc_init_info 
int <token> <answer> i; 
for (i = 0; i <token> ini->ism_offered_cnt + 1; i++) { <answer> < 
if (ini->ism_chid[i] == <token> { <answer> ntohs(aclc->d1.chid)) 
<token> = i; <answer> ini->ism_selected 
<token> 0; <answer> return 
<token> -EPROTO; <answer> return 
new_clcsock->sk->sk_data_ready = <token> <answer> lsmc->clcsk_data_ready; 
if <token> { <answer> (lsmc->use_fallback) 
if <token> <answer> (lsmc->clcsk_state_change) 
<token> = lsmc->clcsk_state_change; <answer> new_clcsock->sk->sk_state_change 
<token> (lsmc->clcsk_write_space) <answer> if 
<token> = lsmc->clcsk_write_space; <answer> new_clcsock->sk->sk_write_space 
<token> (lsmc->clcsk_error_report) <answer> if 
new_clcsock->sk->sk_error_report = <token> <answer> lsmc->clcsk_error_report; 
(*new_smc)->clcsock = <token> <answer> new_clcsock; 
return <token> <answer> rc; 
static void smc_accept_enqueue(struct sock <token> struct sock *sk) <answer> *parent, 
struct smc_sock *par <token> smc_sk(parent); <answer> = 
struct sock <token> sock *parent, <answer> *smc_accept_dequeue(struct 
<token> socket *new_sock) <answer> struct 
<token> smc_sock *isk, *n; <answer> struct 
struct <token> *new_sk; <answer> sock 
list_for_each_entry_safe(isk, n, &smc_sk(parent)->accept_q, accept_q) <token> <answer> { 
new_sk = (struct <token> *)isk; <answer> sock 
if (new_sk->sk_state == <token> { <answer> SMC_CLOSED) 
<token> (isk->clcsock) { <answer> if 
<token> = NULL; <answer> isk->clcsock 
smcd_gid.gid = <token> <answer> ntohll(smcd_v2_ext->gidchid[i].gid); 
smcd_gid.gid_ext <token> 0; <answer> = 
chid = <token> <answer> ntohs(smcd_v2_ext->gidchid[i].chid); 
<token> (__smc_ism_is_emulated(chid)) { <answer> if 
if ((i <token> 1) == smc_v2_ext->hdr.ism_gid_cnt || <answer> + 
<token> != ntohs(smcd_v2_ext->gidchid[i + 1].chid)) <answer> chid 
<token> = <answer> smcd_gid.gid_ext 
<token> chid, &smcd_gid, &matches); <answer> smc_check_ism_v2_match(ini, 
<token> (!ini->ism_dev[0]) { <answer> if 
<token> ini); <answer> smc_find_ism_store_rc(SMC_CLC_DECL_NOSMCD2DEV, 
goto <token> <answer> not_found; 
if <token> smc_v2_ext, <answer> (!smc_clc_match_eid(ini->negotiated_eid, 
<token> eid)) <answer> smcd_v2_ext->system_eid, 
<token> not_found; <answer> goto 
buf <token> kzalloc(sizeof(*buf), GFP_KERNEL); <answer> = 
<token> (!buf) { <answer> if 
rc <token> SMC_CLC_DECL_MEM; <answer> = 
<token> out_decl; <answer> goto 
pclc = <token> smc_clc_msg_proposal *)buf; <answer> (struct 
rc = smc_clc_wait_msg(new_smc, <token> sizeof(*buf), <answer> pclc, 
SMC_CLC_PROPOSAL, <token> <answer> CLC_WAIT_TIME); 
<token> (rc) <answer> if 
<token> out_decl; <answer> goto 
if <token> > SMC_V1) <answer> (pclc->hdr.version 
<token> = SMC_V2; <answer> proposal_version 
smc_conn_save_peer_info_fce(new_smc, <token> <answer> cclc); 
if <token> <answer> (!smc->use_fallback) 
tcp_sk(smc->clcsock->sk)->syn_smc <token> 1; <answer> = 
smc->clcsock->sk->sk_user_data <token> <answer> = 
<token> *)((uintptr_t)smc | SK_USER_DATA_NOCOPY); <answer> (void 
smc_clcsock_data_ready, <token> <answer> &smc->clcsk_data_ready); 
if (!smc->clcsock) <token> <answer> { 
return <token> <answer> -EBADF; 
if <token> <answer> (unlikely(!smc->clcsock->ops->setsockopt)) 
rc = <token> <answer> -EOPNOTSUPP; 
rc = smc->clcsock->ops->setsockopt(smc->clcsock, level, <token> <answer> optname, 
<token> optlen); <answer> optval, 
<token> (smc->clcsock->sk->sk_err) { <answer> if 
<token> = smc->clcsock->sk->sk_err; <answer> sk->sk_err 
if (optlen < <token> <answer> sizeof(int)) 
<token> -EINVAL; <answer> return 
if (copy_from_sockptr(&val, <token> sizeof(int))) <answer> optval, 
return <token> <answer> -EFAULT; 
if (rc <token> smc->use_fallback) <answer> || 
goto <token> <answer> out; 
switch (optname) <token> <answer> { 
<token> TCP_FASTOPEN: <answer> case 
<token> TCP_FASTOPEN_CONNECT: <answer> case 
case <token> <answer> TCP_FASTOPEN_KEY: 
<token> TCP_FASTOPEN_NO_COOKIE: <answer> case 
static ssize_t smc_splice_read(struct <token> *sock, loff_t *ppos, <answer> socket 
struct pipe_inode_info *pipe, <token> len, <answer> size_t 
unsigned <token> flags) <answer> int 
struct sock *sk = <token> <answer> sock->sk; 
<token> smc_sock *smc; <answer> struct 
int rc <token> -ENOTCONN; <answer> = 
<token> = smc_sk(sk); <answer> smc 
if (sk->sk_state == SMC_CLOSED && (sk->sk_shutdown & RCV_SHUTDOWN)) <token> <answer> { 
<token> = smc->clcsock->sk; <answer> sk 
__netns_tracker_free(net, <token> false); <answer> &sk->ns_tracker, 
sk->sk_net_refcnt = <token> <answer> 1; 
get_net_track(net, &sk->ns_tracker, <token> <answer> GFP_KERNEL); 
sock_inuse_add(net, <token> <answer> 1); 
<token> else { <answer> } 
smc->clcsock <token> clcsock; <answer> = 
return <token> <answer> rc; 
static int smc_create(struct net *net, <token> socket *sock, int protocol, <answer> struct 
int <token> <answer> kern) 
return __smc_create(net, sock, protocol, <token> NULL); <answer> kern, 
static const struct net_proto_family smc_sock_family_ops <token> { <answer> = 
.family <token> PF_SMC, <answer> = 
.owner = <token> <answer> THIS_MODULE, 
.create <token> smc_create, <answer> = 
static int smc_ulp_init(struct sock <token> <answer> *sk) 
struct socket <token> = sk->sk_socket; <answer> *tcp 
struct net *net = <token> <answer> sock_net(sk); 
<token> socket *smcsock; <answer> struct 
int protocol, <token> <answer> ret; 
<token> <linux/pci.h> <answer> #include 
<token> <linux/reboot.h> <answer> #include 
<token> "hwmgr.h" <answer> #include 
#include <token> <answer> "pp_debug.h" 
#include <token> <answer> "ppatomctrl.h" 
#include <token> <answer> "ppsmc.h" 
<token> "atom.h" <answer> #include 
<token> "ivsrcid/thm/irqsrcs_thm_9_0.h" <answer> #include 
<token> "ivsrcid/smuio/irqsrcs_smuio_9_0.h" <answer> #include 
#include <token> <answer> "ivsrcid/ivsrcid_vislands30.h" 
uint8_t <token> vddc) <answer> convert_to_vid(uint16_t 
return (uint8_t) <token> - (vddc * VOLTAGE_SCALE)) / 25); <answer> ((6200 
uint16_t <token> vid) <answer> convert_to_vddc(uint8_t 
return (uint16_t) <token> - (vid * 25)) / VOLTAGE_SCALE); <answer> ((6200 
<token> phm_copy_clock_limits_array( <answer> int 
<token> pp_hwmgr *hwmgr, <answer> struct 
uint32_t <token> <answer> **pptable_info_array, 
const <token> *pptable_array, <answer> uint32_t 
<token> power_saving_clock_count) <answer> uint32_t 
uint32_t array_size, <token> <answer> i; 
<token> *table; <answer> uint32_t 
array_size = <token> * power_saving_clock_count; <answer> sizeof(uint32_t) 
table = kzalloc(array_size, <token> <answer> GFP_KERNEL); 
if (NULL <token> table) <answer> == 
<token> -ENOMEM; <answer> return 
for <token> = 0; i < power_saving_clock_count; i++) <answer> (i 
<token> = le32_to_cpu(pptable_array[i]); <answer> table[i] 
*pptable_info_array = <token> <answer> table; 
return <token> <answer> 0; 
int <token> <answer> phm_copy_overdrive_settings_limits_array( 
<token> pp_hwmgr *hwmgr, <answer> struct 
uint32_t <token> <answer> **pptable_info_array, 
const <token> *pptable_array, <answer> uint32_t 
<token> od_setting_count) <answer> uint32_t 
uint32_t <token> i; <answer> array_size, 
uint32_t <token> <answer> *table; 
array_size = sizeof(uint32_t) * <token> <answer> od_setting_count; 
table <token> kzalloc(array_size, GFP_KERNEL); <answer> = 
if (NULL <token> table) <answer> == 
<token> -ENOMEM; <answer> return 
for (i = 0; i < od_setting_count; <token> <answer> i++) 
<token> = le32_to_cpu(pptable_array[i]); <answer> table[i] 
<token> = table; <answer> *pptable_info_array 
return <token> <answer> 0; 
uint32_t phm_set_field_to_u32(u32 <token> u32 original_data, u32 field, u32 size) <answer> offset, 
<token> mask = 0; <answer> u32 
u32 shift = <token> <answer> 0; 
shift = <token> % 4) << 3; <answer> (offset 
if (size <token> sizeof(uint8_t)) <answer> == 
mask <token> 0xFF << shift; <answer> = 
else <token> (size == sizeof(uint16_t)) <answer> if 
mask = <token> << shift; <answer> 0xFFFF 
<token> &= ~mask; <answer> original_data 
original_data <token> (field << shift); <answer> |= 
<token> original_data; <answer> return 
<token> phm_wait_on_register(struct pp_hwmgr *hwmgr, uint32_t index, <answer> int 
uint32_t value, uint32_t <token> <answer> mask) 
uint32_t <token> <answer> i; 
<token> cur_value; <answer> uint32_t 
if (hwmgr == NULL || <token> == NULL) { <answer> hwmgr->device 
<token> Hardware Manager!"); <answer> pr_err("Invalid 
<token> -EINVAL; <answer> return 
for (i = 0; <token> < hwmgr->usec_timeout; i++) { <answer> i 
cur_value <token> cgs_read_register(hwmgr->device, index); <answer> = 
if ((cur_value & mask) == <token> & mask)) <answer> (value 
<token> phm_wait_on_indirect_register(struct pp_hwmgr *hwmgr, <answer> int 
<token> indirect_port, <answer> uint32_t 
<token> index, <answer> uint32_t 
uint32_t <token> <answer> value, 
uint32_t <token> <answer> mask) 
if (hwmgr == <token> || hwmgr->device == NULL) { <answer> NULL 
<token> Hardware Manager!"); <answer> pr_err("Invalid 
return <token> <answer> -EINVAL; 
cgs_write_register(hwmgr->device, indirect_port, <token> <answer> index); 
<token> phm_wait_on_register(hwmgr, indirect_port + 1, mask, value); <answer> return 
int phm_wait_for_register_unequal(struct pp_hwmgr <token> <answer> *hwmgr, 
<token> index, <answer> uint32_t 
uint32_t value, uint32_t <token> <answer> mask) 
<token> i; <answer> uint32_t 
uint32_t <token> <answer> cur_value; 
if (hwmgr == NULL || hwmgr->device <token> NULL) <answer> == 
return <token> <answer> -EINVAL; 
for (i = 0; <token> < hwmgr->usec_timeout; i++) { <answer> i 
cur_value = <token> <answer> cgs_read_register(hwmgr->device, 
if ((cur_value & mask) != (value & <token> <answer> mask)) 
int phm_initializa_dynamic_state_adjustment_rule_settings(struct <token> *hwmgr) <answer> pp_hwmgr 
<token> phm_clock_voltage_dependency_table *table_clk_vlt; <answer> struct 
struct phm_ppt_v1_information *pptable_info <token> (struct phm_ppt_v1_information *)(hwmgr->pptable); <answer> = 
dev_emerg(adev->dev, "ERROR: System is going to <token> due to GPU HW CTF!\n"); <answer> shutdown 
} else if (client_id == <token> { <answer> SOC15_IH_CLIENTID_THM) 
if (src_id <token> 0) <answer> == 
dev_emerg(adev->dev, "ERROR: <token> under temperature range detected!\n"); <answer> GPU 
} else if (client_id <token> SOC15_IH_CLIENTID_ROM_SMUIO) { <answer> == 
dev_emerg(adev->dev, "ERROR: GPU <token> Critical Temperature Fault(aka CTF) detected!\n"); <answer> HW 
dev_emerg(adev->dev, "ERROR: <token> is going to shutdown due to GPU HW CTF!\n"); <answer> System 
<token> 0; <answer> return 
static <token> struct amdgpu_irq_src_funcs smu9_irq_funcs = { <answer> const 
.process = <token> <answer> phm_irq_process, 
int smu9_register_irq_handlers(struct <token> *hwmgr) <answer> pp_hwmgr 
struct amdgpu_irq_src *source <token> <answer> = 
kzalloc(sizeof(struct <token> GFP_KERNEL); <answer> amdgpu_irq_src), 
<token> (!source) <answer> if 
<token> -ENOMEM; <answer> return 
source->funcs <token> &smu9_irq_funcs; <answer> = 
amdgpu_irq_add_id((struct amdgpu_device <token> <answer> *)(hwmgr->adev), 
<token> amdgpu_device *)(hwmgr->adev), <answer> amdgpu_irq_add_id((struct 
#include <token> <answer> <linux/of_gpio.h> 
#include <token> <answer> <linux/gpio.h> 
#include <token> <answer> "xgene_enet_main.h" 
<token> "xgene_enet_hw.h" <answer> #include 
<token> "xgene_enet_xgmac.h" <answer> #include 
static void <token> xgene_enet_pdata *pdata, <answer> xgene_enet_wr_csr(struct 
u32 <token> u32 val) <answer> offset, 
void <token> *addr = pdata->eth_csr_addr + offset; <answer> __iomem 
iowrite32(val, <token> <answer> addr); 
static void <token> xgene_enet_pdata *pdata, <answer> xgene_enet_wr_ring_if(struct 
<token> offset, u32 val) <answer> u32 
void __iomem *addr = <token> + offset; <answer> pdata->eth_ring_if_addr 
<token> addr); <answer> iowrite32(val, 
static void xgene_enet_wr_diag_csr(struct <token> *pdata, <answer> xgene_enet_pdata 
<token> offset, u32 val) <answer> u32 
void __iomem *addr = <token> + offset; <answer> pdata->eth_diag_csr_addr 
<token> addr); <answer> iowrite32(val, 
static bool xgene_enet_wr_indirect(void __iomem *addr, void <token> *wr, <answer> __iomem 
void __iomem *cmd, void __iomem <token> <answer> *cmd_done, 
u32 wr_addr, <token> wr_data) <answer> u32 
<token> done; <answer> u32 
u8 <token> = 10; <answer> wait 
<token> addr); <answer> iowrite32(wr_addr, 
<token> wr); <answer> iowrite32(wr_data, 
iowrite32(XGENE_ENET_WR_CMD, <token> <answer> cmd); 
#include <token> <answer> <linux/types.h> 
.spinlock <token> __SPIN_LOCK_UNLOCKED(speakup_info.spinlock), <answer> = 
.flushing = <token> <answer> 0, 
<token> int do_synth_init(struct spk_synth *in_synth); <answer> static 
static <token> _spk_do_catch_up(struct spk_synth *synth, int unicode) <answer> void 
<token> ch; <answer> u16 
unsigned <token> flags; <answer> long 
unsigned long <token> <answer> jiff_max; 
struct var_t <token> <answer> *delay_time; 
<token> var_t *full_time; <answer> struct 
struct var_t <token> <answer> *jiffy_delta; 
<token> jiffy_delta_val; <answer> int 
int <token> <answer> delay_time_val; 
<token> full_time_val; <answer> int 
int <token> <answer> ret; 
jiffy_delta = <token> <answer> spk_get_var(JIFFY); 
full_time = <token> <answer> spk_get_var(FULL); 
delay_time = <token> <answer> spk_get_var(DELAY); 
<token> flags); <answer> spin_lock_irqsave(&speakup_info.spinlock, 
<token> = jiffy_delta->u.n.value; <answer> jiffy_delta_val 
spin_unlock_irqrestore(&speakup_info.spinlock, <token> <answer> flags); 
jiff_max = <token> + jiffy_delta_val; <answer> jiffies 
while (!kthread_should_stop()) <token> <answer> { 
spin_lock_irqsave(&speakup_info.spinlock, <token> <answer> flags); 
<token> (speakup_info.flushing) { <answer> if 
speakup_info.flushing = <token> <answer> 0; 
spin_unlock_irqrestore(&speakup_info.spinlock, <token> <answer> flags); 
if <token> <answer> (!unicode) 
<token> (synth_buffer_empty()) { <answer> if 
spin_unlock_irqrestore(&speakup_info.spinlock, <token> <answer> flags); 
ch = <token> <answer> synth_buffer_peek(); 
full_time_val <token> full_time->u.n.value; <answer> = 
spin_unlock_irqrestore(&speakup_info.spinlock, <token> <answer> flags); 
<token> (ch == '\n') <answer> if 
ch <token> synth->procspeech; <answer> = 
if <token> <answer> (unicode) 
ret = synth->io_ops->synth_out_unicode(synth, <token> <answer> ch); 
ret = <token> ch); <answer> synth->io_ops->synth_out(synth, 
if <token> { <answer> (!ret) 
if (time_after_eq(jiffies, <token> && (ch == SPACE)) { <answer> jiff_max) 
<token> flags); <answer> spin_lock_irqsave(&speakup_info.spinlock, 
jiffy_delta_val <token> jiffy_delta->u.n.value; <answer> = 
delay_time_val = <token> <answer> delay_time->u.n.value; 
<token> = full_time->u.n.value; <answer> full_time_val 
<token> flags); <answer> spin_unlock_irqrestore(&speakup_info.spinlock, 
if <token> synth->procspeech)) <answer> (synth->io_ops->synth_out(synth, 
jiff_max <token> jiffies + jiffy_delta_val; <answer> = 
<token> flags); <answer> spin_lock_irqsave(&speakup_info.spinlock, 
<token> flags); <answer> spin_unlock_irqrestore(&speakup_info.spinlock, 
<token> synth->procspeech); <answer> synth->io_ops->synth_out(synth, 
void <token> spk_synth *synth) <answer> spk_do_catch_up(struct 
<token> 0); <answer> _spk_do_catch_up(synth, 
void spk_do_catch_up_unicode(struct <token> *synth) <answer> spk_synth 
_spk_do_catch_up(synth, <token> <answer> 1); 
void spk_synth_flush(struct spk_synth <token> <answer> *synth) 
synth->io_ops->synth_out(synth, <token> <answer> synth->clear); 
unsigned char spk_synth_get_index(struct spk_synth <token> <answer> *synth) 
<token> synth->io_ops->synth_in_nowait(synth); <answer> return 
<token> spk_synth_is_alive_nop(struct spk_synth *synth) <answer> int 
synth->alive = <token> <answer> 1; 
return <token> <answer> 1; 
int spk_synth_is_alive_restart(struct <token> *synth) <answer> spk_synth 
<token> (synth->alive) <answer> if 
<token> 1; <answer> return 
<token> (synth->io_ops->wait_for_xmitr(synth) > 0) { <answer> if 
#define pr_fmt(fmt) "mvebu-pmsu: " <token> <answer> fmt 
<token> <linux/clk.h> <answer> #include 
<token> <linux/cpu_pm.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/mbus.h> 
#include <token> <answer> <linux/mvebu-pmsu.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/of_address.h> 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/resource.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/smp.h> <answer> #include 
#include <token> <answer> <asm/cacheflush.h> 
<token> <asm/cp15.h> <answer> #include 
#include <token> <answer> <asm/smp_scu.h> 
#include <token> <answer> <asm/smp_plat.h> 
<token> <asm/suspend.h> <answer> #include 
<token> <asm/tlbflush.h> <answer> #include 
<token> "common.h" <answer> #include 
<token> "pmsu.h" <answer> #include 
#define <token> 0x100 <answer> PMSU_BASE_OFFSET 
<token> PMSU_REG_SIZE 0x1000 <answer> #define 
int mvebu_setup_boot_addr_wa(unsigned <token> crypto_eng_target, <answer> int 
unsigned <token> crypto_eng_attribute, <answer> int 
<token> resume_addr_reg) <answer> phys_addr_t 
void <token> *sram_virt_base; <answer> __iomem 
<token> code_len = mvebu_boot_wa_end - mvebu_boot_wa_start; <answer> u32 
mvebu_mbus_del_window(BOOTROM_BASE, <token> <answer> BOOTROM_SIZE); 
mvebu_mbus_add_window_by_id(crypto_eng_target, <token> <answer> crypto_eng_attribute, 
<token> SZ_64K); <answer> SRAM_PHYS_BASE, 
sram_virt_base = ioremap(SRAM_PHYS_BASE, <token> <answer> SZ_64K); 
<token> (!sram_virt_base) { <answer> if 
pr_err("Unable to map SRAM to setup the boot <token> WA\n"); <answer> address 
return <token> <answer> -ENOMEM; 
<token> &mvebu_boot_wa_start, code_len); <answer> memcpy(sram_virt_base, 
__raw_writel((unsigned <token> <answer> long)resume_addr_reg, 
sram_virt_base + <token> - 4); <answer> code_len 
return <token> <answer> 0; 
static int <token> mvebu_v7_pmsu_init(void) <answer> __init 
struct <token> *np; <answer> device_node 
struct <token> res; <answer> resource 
int ret <token> 0; <answer> = 
np = of_find_matching_node(NULL, <token> <answer> of_pmsu_table); 
<token> (!np) <answer> if 
<token> 0; <answer> return 
pr_info("Initializing <token> Management Service Unit\n"); <answer> Power 
if <token> 0, &res)) { <answer> (of_address_to_resource(np, 
pr_err("unable to get <token> <answer> resource\n"); 
<token> = -ENOENT; <answer> ret 
<token> out; <answer> goto 
if <token> "marvell,armada-370-xp-pmsu")) { <answer> (of_device_is_compatible(np, 
pr_warn(FW_WARN <token> pmsu binding\n"); <answer> "deprecated 
res.start = res.start <token> PMSU_BASE_OFFSET; <answer> - 
res.end = res.start + PMSU_REG_SIZE <token> 1; <answer> - 
if (!request_mem_region(res.start, <token> <answer> resource_size(&res), 
np->full_name)) <token> <answer> { 
pr_err("unable to request <token> <answer> region\n"); 
<token> = -EBUSY; <answer> ret 
<token> out; <answer> goto 
pmsu_mp_phys_base = <token> <answer> res.start; 
pmsu_mp_base <token> ioremap(res.start, resource_size(&res)); <answer> = 
<token> (!pmsu_mp_base) { <answer> if 
pr_err("unable to map <token> <answer> registers\n"); 
<token> resource_size(&res)); <answer> release_mem_region(res.start, 
ret = <token> <answer> -ENOMEM; 
<token> out; <answer> goto 
<token> ret; <answer> return 
static <token> mvebu_v7_pmsu_enable_l2_powerdown_onidle(void) <answer> void 
u32 <token> <answer> reg; 
if <token> == NULL) <answer> (pmsu_mp_base 
reg = <token> + PMSU_STATUS_AND_MASK(hw_cpu)); <answer> readl(pmsu_mp_base 
reg <token> PMSU_STATUS_AND_MASK_CPU_IDLE_WAIT | <answer> |= 
PMSU_STATUS_AND_MASK_IRQ_WAKEUP <token> <answer> | 
PMSU_STATUS_AND_MASK_FIQ_WAKEUP <token> <answer> | 
<token> | <answer> PMSU_STATUS_AND_MASK_SNP_Q_EMPTY_WAIT 
PMSU_STATUS_AND_MASK_IRQ_MASK <token> <answer> | 
writel(reg, <token> + PMSU_STATUS_AND_MASK(hw_cpu)); <answer> pmsu_mp_base 
reg = <token> + PMSU_CONTROL_AND_CONFIG(hw_cpu)); <answer> readl(pmsu_mp_base 
<token> SCU_PM_POWEROFF); <answer> scu_power_mode(mvebu_get_scu_base(), 
<token> 1; <answer> return 
static int <token> long deepidle) <answer> armada_38x_cpu_suspend(unsigned 
return <token> armada_38x_do_cpu_suspend); <answer> cpu_suspend(false, 
<token> = pmsu_mp_phys_base + PMSU_BOOT_ADDR_REDIRECT_OFFSET(0); <answer> redirect_reg 
mvebu_cpu_resume = <token> <answer> armada_370_xp_cpu_resume; 
<token> = armada_370_xp_cpu_suspend; <answer> mvebu_v7_cpuidle_device.dev.platform_data 
mvebu_v7_cpuidle_device.name <token> "cpuidle-armada-370"; <answer> = 
<token> 0; <answer> return 
<token> __init int armada_38x_cpuidle_init(void) <answer> static 
struct device_node <token> <answer> *np; 
void __iomem <token> <answer> *mpsoc_base; 
<token> reg; <answer> u32 
<token> idle is currently broken on Armada 38x: disabling\n"); <answer> pr_warn("CPU 
<token> 0; <answer> return 
<token> = of_find_compatible_node(NULL, NULL, <answer> np 
if <token> <answer> (!np) 
<token> -ENODEV; <answer> return 
if <token> <answer> (broken_idle(np)) 
goto <token> <answer> end; 
np <token> of_find_compatible_node(NULL, NULL, <answer> = 
if <token> <answer> (!np) 
<token> -ENODEV; <answer> return 
mpsoc_base <token> of_iomap(np, 0); <answer> = 
if (of_machine_is_compatible("marvell,armada380")) <token> <answer> { 
<token> hotplug support is currently broken on Armada 38x: disabling\n"); <answer> pr_warn("CPU 
<token> (of_machine_is_compatible("marvell,armadaxp")) <answer> if 
<token> = armada_xp_cpuidle_init(); <answer> ret 
<token> if (of_machine_is_compatible("marvell,armada370")) <answer> else 
<token> = armada_370_cpuidle_init(); <answer> ret 
<token> if (of_machine_is_compatible("marvell,armada380")) <answer> else 
ret <token> armada_38x_cpuidle_init(); <answer> = 
return <token> <answer> 0; 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> (mvebu_v7_cpuidle_device.name) <answer> if 
return <token> <answer> 0; 
<token> void mvebu_pmsu_dfs_request_local(void *data) <answer> static 
<token> reg; <answer> u32 
<token> cpu = smp_processor_id(); <answer> u32 
<token> long flags; <answer> unsigned 
reg <token> readl(pmsu_mp_base + PMSU_STATUS_AND_MASK(cpu)); <answer> = 
reg <token> ~PMSU_STATUS_AND_MASK_CPU_IDLE_WAIT; <answer> &= 
<token> pmsu_mp_base + PMSU_STATUS_AND_MASK(cpu)); <answer> writel(reg, 
<token> mvebu_pmsu_dfs_request(int cpu) <answer> int 
unsigned <token> timeout; <answer> long 
<token> hwcpu = cpu_logical_map(cpu); <answer> int 
u32 <token> <answer> reg; 
#include <token> <answer> <linux/crash_dump.h> 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/uio.h> 
ssize_t copy_oldmem_page(struct <token> *iter, unsigned long pfn, <answer> iov_iter 
size_t csize, <token> long offset) <answer> unsigned 
<token> *vaddr; <answer> void 
if <token> <answer> (!csize) 
<token> 0; <answer> return 
vaddr = <token> PAGE_SIZE, MEMREMAP_WB); <answer> memremap(__pfn_to_phys(pfn), 
if <token> <answer> (!vaddr) 
return <token> <answer> -ENOMEM; 
csize = copy_to_iter(vaddr + offset, <token> iter); <answer> csize, 
<token> csize; <answer> return 
#include <token> <answer> <linux/buffer_head.h> 
#include <token> <answer> <linux/gfp.h> 
<token> <linux/mpage.h> <answer> #include 
<token> <linux/pagemap.h> <answer> #include 
<token> <linux/writeback.h> <answer> #include 
<token> <linux/uio.h> <answer> #include 
<token> <linux/fiemap.h> <answer> #include 
<token> "nilfs.h" <answer> #include 
<token> "btnode.h" <answer> #include 
<token> "segment.h" <answer> #include 
<token> "page.h" <answer> #include 
<token> "mdt.h" <answer> #include 
#include <token> <answer> "cpfile.h" 
<token> "ifile.h" <answer> #include 
<token> nilfs_iget_args { <answer> struct 
u64 <token> <answer> ino; 
<token> cno; <answer> __u64 
struct <token> *root; <answer> nilfs_root 
<token> for_gc; <answer> bool 
<token> for_btnc; <answer> bool 
<token> for_shadow; <answer> bool 
static int nilfs_iget_test(struct inode *inode, <token> *opaque); <answer> void 
<token> nilfs_inode_add_blocks(struct inode *inode, int n) <answer> void 
<token> nilfs_root *root = NILFS_I(inode)->i_root; <answer> struct 
<token> i_blocksize(inode) * n); <answer> inode_add_bytes(inode, 
if <token> <answer> (root) 
<token> &root->blocks_count); <answer> atomic64_add(n, 
void nilfs_inode_sub_blocks(struct <token> *inode, int n) <answer> inode 
struct <token> *root = NILFS_I(inode)->i_root; <answer> nilfs_root 
inode_sub_bytes(inode, <token> * n); <answer> i_blocksize(inode) 
if <token> <answer> (root) 
<token> &root->blocks_count); <answer> atomic64_sub(n, 
int nilfs_get_block(struct inode *inode, sector_t <token> <answer> blkoff, 
<token> buffer_head *bh_result, int create) <answer> struct 
struct <token> *ii = NILFS_I(inode); <answer> nilfs_inode_info 
struct the_nilfs *nilfs = <token> <answer> inode->i_sb->s_fs_info; 
__u64 blknum <token> 0; <answer> = 
int err = 0, <token> <answer> ret; 
unsigned <token> maxblocks = bh_result->b_size >> inode->i_blkbits; <answer> int 
<token> = nilfs_bmap_lookup_contig(ii->i_bmap, blkoff, &blknum, maxblocks); <answer> ret 
<token> (ino=%lu): a race condition while inserting a data block at offset=%llu", <answer> "%s 
__func__, <token> <answer> inode->i_ino, 
(unsigned <token> long)blkoff); <answer> long 
err <token> -EAGAIN; <answer> = 
goto <token> <answer> out; 
} <token> { <answer> else 
err = <token> <answer> ret; 
return <token> <answer> err; 
<token> int nilfs_read_folio(struct file *file, struct folio *folio) <answer> static 
return mpage_read_folio(folio, <token> <answer> nilfs_get_block); 
static <token> nilfs_readahead(struct readahead_control *rac) <answer> void 
mpage_readahead(rac, <token> <answer> nilfs_get_block); 
static int nilfs_writepages(struct address_space <token> <answer> *mapping, 
<token> writeback_control *wbc) <answer> struct 
struct inode *inode <token> mapping->host; <answer> = 
int <token> = 0; <answer> err 
if <token> { <answer> (sb_rdonly(inode->i_sb)) 
nilfs_clear_dirty_pages(mapping, <token> <answer> false); 
<token> -EROFS; <answer> return 
if (wbc->sync_mode == <token> <answer> WB_SYNC_ALL) 
<token> = nilfs_construct_dsync_segment(inode->i_sb, inode, <answer> err 
<token> err; <answer> return 
static int nilfs_writepage(struct page <token> struct writeback_control *wbc) <answer> *page, 
struct folio *folio <token> page_folio(page); <answer> = 
<token> inode *inode = folio->mapping->host; <answer> struct 
<token> err; <answer> int 
<token> (sb_rdonly(inode->i_sb)) { <answer> if 
<token> false); <answer> nilfs_clear_folio_dirty(folio, 
<token> -EROFS; <answer> return 
<token> folio); <answer> folio_redirty_for_writepage(wbc, 
<token> (wbc->sync_mode == WB_SYNC_ALL) { <answer> if 
err = <token> <answer> nilfs_construct_segment(inode->i_sb); 
if <token> <answer> (unlikely(err)) 
<token> err; <answer> return 
} else if <token> <answer> (wbc->for_reclaim) 
nilfs_flush_segment(inode->i_sb, <token> <answer> inode->i_ino); 
<token> 0; <answer> return 
static bool <token> address_space *mapping, <answer> nilfs_dirty_folio(struct 
struct folio <token> <answer> *folio) 
struct <token> *inode = mapping->host; <answer> inode 
struct buffer_head <token> <answer> *head; 
unsigned <token> nr_dirty = 0; <answer> int 
bool ret = <token> folio); <answer> filemap_dirty_folio(mapping, 
head <token> folio_buffers(folio); <answer> = 
if <token> { <answer> (head) 
struct buffer_head *bh = <token> <answer> head; 
do <token> <answer> { 
goto <token> <answer> failed_after_creation; 
return <token> <answer> inode; 
if (inode->i_state <token> I_NEW) <answer> & 
goto <token> <answer> failed; 
return <token> <answer> ERR_PTR(err); 
void nilfs_set_inode_flags(struct <token> *inode) <answer> inode 
<token> int flags = NILFS_I(inode)->i_flags; <answer> unsigned 
unsigned <token> new_fl = 0; <answer> int 
if <token> & FS_SYNC_FL) <answer> (flags 
new_fl |= <token> <answer> S_SYNC; 
if (flags <token> FS_APPEND_FL) <answer> & 
new_fl <token> S_APPEND; <answer> |= 
<token> (flags & FS_IMMUTABLE_FL) <answer> if 
<token> |= S_IMMUTABLE; <answer> new_fl 
if (flags & <token> <answer> FS_NOATIME_FL) 
<token> |= S_NOATIME; <answer> new_fl 
if <token> & FS_DIRSYNC_FL) <answer> (flags 
new_fl <token> S_DIRSYNC; <answer> |= 
inode_set_flags(inode, new_fl, S_SYNC | S_APPEND <token> S_IMMUTABLE | <answer> | 
<token> | S_DIRSYNC); <answer> S_NOATIME 
int nilfs_read_inode_common(struct inode <token> <answer> *inode, 
struct <token> *raw_inode) <answer> nilfs_inode 
struct nilfs_inode_info *ii = <token> <answer> NILFS_I(inode); 
<token> err; <answer> int 
inode->i_mode <token> le16_to_cpu(raw_inode->i_mode); <answer> = 
i_uid_write(inode, <token> <answer> le32_to_cpu(raw_inode->i_uid)); 
i_gid_write(inode, <token> <answer> le32_to_cpu(raw_inode->i_gid)); 
set_nlink(inode, <token> <answer> le16_to_cpu(raw_inode->i_links_count)); 
inode->i_size <token> le64_to_cpu(raw_inode->i_size); <answer> = 
<token> le64_to_cpu(raw_inode->i_mtime), <answer> inode_set_atime(inode, 
inode_set_ctime(inode, <token> <answer> le64_to_cpu(raw_inode->i_ctime), 
inode_set_mtime(inode, <token> <answer> le64_to_cpu(raw_inode->i_mtime), 
if <token> && !S_ISREG(inode->i_mode)) <answer> (nilfs_is_metadata_file_inode(inode) 
int nilfs_attach_btree_node_cache(struct inode <token> <answer> *inode) 
struct nilfs_inode_info *ii <token> NILFS_I(inode); <answer> = 
struct <token> *btnc_inode; <answer> inode 
struct nilfs_iget_args <token> <answer> args; 
<token> (ii->i_assoc_inode) <answer> if 
return <token> <answer> 0; 
args.ino <token> inode->i_ino; <answer> = 
args.root = <token> <answer> ii->i_root; 
<token> = ii->i_cno; <answer> args.cno 
args.for_gc = test_bit(NILFS_I_GCINODE, &ii->i_state) <token> 0; <answer> != 
args.for_btnc <token> true; <answer> = 
args.for_shadow = <token> &ii->i_state) != 0; <answer> test_bit(NILFS_I_SHADOW, 
<token> = iget5_locked(inode->i_sb, inode->i_ino, nilfs_iget_test, <answer> btnc_inode 
nilfs_iget_set, <token> <answer> &args); 
if <token> <answer> (unlikely(!btnc_inode)) 
return <token> <answer> -ENOMEM; 
if (btnc_inode->i_state & <token> { <answer> I_NEW) 
<token> = inode; <answer> NILFS_I(btnc_inode)->i_assoc_inode 
NILFS_I(btnc_inode)->i_bmap <token> ii->i_bmap; <answer> = 
ii->i_assoc_inode <token> btnc_inode; <answer> = 
<token> 0; <answer> return 
void nilfs_detach_btree_node_cache(struct <token> *inode) <answer> inode 
struct nilfs_inode_info *ii = <token> <answer> NILFS_I(inode); 
struct inode <token> = ii->i_assoc_inode; <answer> *btnc_inode 
if (btnc_inode) <token> <answer> { 
NILFS_I(btnc_inode)->i_assoc_inode = <token> <answer> NULL; 
ii->i_assoc_inode <token> NULL; <answer> = 
struct <token> *nilfs_iget_for_shadow(struct inode *inode) <answer> inode 
struct nilfs_iget_args args <token> { <answer> = 
.ino = inode->i_ino, .root = NULL, .cno = <token> .for_gc = false, <answer> 0, 
<token> = false, .for_shadow = true <answer> .for_btnc 
struct <token> *s_inode; <answer> inode 
int <token> <answer> err; 
s_inode = iget5_locked(inode->i_sb, inode->i_ino, <token> <answer> nilfs_iget_test, 
nilfs_iget_set, <token> <answer> &args); 
<token> (unlikely(!s_inode)) <answer> if 
return <token> <answer> ERR_PTR(-ENOMEM); 
if (!(s_inode->i_state <token> I_NEW)) <answer> & 
<token> inode; <answer> return 
NILFS_I(s_inode)->i_flags = <token> <answer> 0; 
memset(NILFS_I(s_inode)->i_bmap, 0, sizeof(struct <token> <answer> nilfs_bmap)); 
mapping_set_gfp_mask(s_inode->i_mapping, <token> <answer> GFP_NOFS); 
err <token> nilfs_attach_btree_node_cache(s_inode); <answer> = 
if (unlikely(err)) <token> <answer> { 
return <token> <answer> ERR_PTR(err); 
return <token> <answer> s_inode; 
void <token> inode *inode, <answer> nilfs_write_inode_common(struct 
<token> nilfs_inode *raw_inode) <answer> struct 
struct nilfs_inode_info *ii = <token> <answer> NILFS_I(inode); 
raw_inode->i_mode = <token> <answer> cpu_to_le16(inode->i_mode); 
<token> = cpu_to_le32(i_uid_read(inode)); <answer> raw_inode->i_uid 
raw_inode->i_gid = <token> <answer> cpu_to_le32(i_gid_read(inode)); 
raw_inode->i_links_count = <token> <answer> cpu_to_le16(inode->i_nlink); 
<token> = cpu_to_le64(inode->i_size); <answer> raw_inode->i_size 
<token> = cpu_to_le64(inode_get_ctime_sec(inode)); <answer> raw_inode->i_ctime 
raw_inode->i_mtime <token> cpu_to_le64(inode_get_mtime_sec(inode)); <answer> = 
raw_inode->i_ctime_nsec = <token> <answer> cpu_to_le32(inode_get_ctime_nsec(inode)); 
raw_inode->i_mtime_nsec = <token> <answer> cpu_to_le32(inode_get_mtime_nsec(inode)); 
raw_inode->i_blocks <token> cpu_to_le64(inode->i_blocks); <answer> = 
raw_inode->i_flags <token> cpu_to_le32(ii->i_flags); <answer> = 
raw_inode->i_generation = <token> <answer> cpu_to_le32(inode->i_generation); 
void nilfs_update_inode(struct inode *inode, struct buffer_head *ibh, <token> flags) <answer> int 
<token> ino = inode->i_ino; <answer> ino_t 
struct nilfs_inode_info *ii = <token> <answer> NILFS_I(inode); 
struct inode *ifile = <token> <answer> ii->i_root->ifile; 
struct nilfs_inode <token> <answer> *raw_inode; 
raw_inode = <token> ino, ibh); <answer> nilfs_ifile_map_inode(ifile, 
if <token> &ii->i_state)) <answer> (test_and_clear_bit(NILFS_I_NEW, 
<token> 0, NILFS_MDT(ifile)->mi_entry_size); <answer> memset(raw_inode, 
<token> (flags & I_DIRTY_DATASYNC) <answer> if 
set_bit(NILFS_I_INODE_SYNC, <token> <answer> &ii->i_state); 
<token> raw_inode); <answer> nilfs_write_inode_common(inode, 
if (S_ISCHR(inode->i_mode) || <token> <answer> S_ISBLK(inode->i_mode)) 
raw_inode->i_device_code <token> <answer> = 
static void nilfs_clear_inode(struct <token> *inode) <answer> inode 
struct nilfs_inode_info *ii = <token> <answer> NILFS_I(inode); 
<token> = NULL; <answer> ii->i_bh 
<token> (nilfs_is_metadata_file_inode(inode)) <answer> if 
if (test_bit(NILFS_I_BMAP, <token> <answer> &ii->i_state)) 
<token> (!test_bit(NILFS_I_BTNC, &ii->i_state)) <answer> if 
if (ii->i_root && inode->i_ino == <token> <answer> NILFS_ROOT_INO) 
void nilfs_evict_inode(struct <token> *inode) <answer> inode 
<token> nilfs_transaction_info ti; <answer> struct 
struct super_block <token> = inode->i_sb; <answer> *sb 
<token> nilfs_inode_info *ii = NILFS_I(inode); <answer> struct 
struct the_nilfs <token> <answer> *nilfs; 
<token> ret; <answer> int 
if (inode->i_nlink <token> !ii->i_root || unlikely(is_bad_inode(inode))) { <answer> || 
int nilfs_setattr(struct mnt_idmap *idmap, struct dentry <token> <answer> *dentry, 
struct iattr <token> <answer> *iattr) 
struct <token> ti; <answer> nilfs_transaction_info 
struct <token> *inode = d_inode(dentry); <answer> inode 
struct <token> *sb = inode->i_sb; <answer> super_block 
<token> err; <answer> int 
<token> = setattr_prepare(&nop_mnt_idmap, dentry, iattr); <answer> err 
<token> (err) <answer> if 
<token> err; <answer> return 
err = nilfs_transaction_begin(sb, <token> 0); <answer> &ti, 
<token> (unlikely(err)) <answer> if 
<token> err; <answer> return 
<token> ((iattr->ia_valid & ATTR_SIZE) && <answer> if 
<token> != i_size_read(inode)) { <answer> iattr->ia_size 
truncate_setsize(inode, <token> <answer> iattr->ia_size); 
<token> inode, iattr); <answer> setattr_copy(&nop_mnt_idmap, 
if (iattr->ia_valid & ATTR_MODE) <token> <answer> { 
err <token> nilfs_acl_chmod(inode); <answer> = 
<token> (unlikely(err)) <answer> if 
goto <token> <answer> out_err; 
<token> nilfs_transaction_commit(sb); <answer> return 
<token> err; <answer> return 
int nilfs_permission(struct mnt_idmap *idmap, <token> inode *inode, <answer> struct 
int <token> <answer> mask) 
struct nilfs_root *root = <token> <answer> NILFS_I(inode)->i_root; 
if <token> & MAY_WRITE) && root && <answer> ((mask 
root->cno != <token> <answer> NILFS_CPTREE_CURRENT_CNO) 
if (list_empty(&ii->i_dirty) && <token> == NULL) { <answer> igrab(inode) 
"cannot set file <token> (ino=%lu): the file is being freed", <answer> dirty 
<token> &nilfs->ns_dirty_files); <answer> list_move_tail(&ii->i_dirty, 
set_bit(NILFS_I_QUEUED, <token> <answer> &ii->i_state); 
<token> 0; <answer> return 
int __nilfs_mark_inode_dirty(struct <token> *inode, int flags) <answer> inode 
struct the_nilfs *nilfs = <token> <answer> inode->i_sb->s_fs_info; 
<token> buffer_head *ibh; <answer> struct 
<token> err; <answer> int 
if <token> <answer> (unlikely(nilfs_purging(nilfs))) 
<token> 0; <answer> return 
err <token> nilfs_load_inode_block(inode, &ibh); <answer> = 
if <token> { <answer> (unlikely(err)) 
"cannot mark inode dirty (ino=%lu): <token> %d loading inode block", <answer> error 
inode->i_ino, <token> <answer> err); 
return <token> <answer> err; 
nilfs_update_inode(inode, <token> flags); <answer> ibh, 
<token> 0; <answer> return 
<token> nilfs_dirty_inode(struct inode *inode, int flags) <answer> void 
<token> nilfs_transaction_info ti; <answer> struct 
struct nilfs_mdt_info *mdi = <token> <answer> NILFS_MDT(inode); 
<token> (is_bad_inode(inode)) { <answer> if 
"tried to mark <token> dirty. ignored."); <answer> bad_inode 
if <token> { <answer> (mdi) 
nilfs_transaction_begin(inode->i_sb, &ti, <token> <answer> 0); 
<token> flags); <answer> __nilfs_mark_inode_dirty(inode, 
<token> = INT_MAX; <answer> maxblocks 
if <token> <answer> (delalloc_blklen) 
maxblocks = min_t(sector_t, delalloc_blkoff - <token> <answer> blkoff, 
blkphy <token> 0; <answer> = 
<token> = nilfs_bmap_lookup_contig( <answer> n 
NILFS_I(inode)->i_bmap, <token> &blkphy, maxblocks); <answer> blkoff, 
if (n < <token> { <answer> 0) 
<token> past_eof; <answer> int 
if <token> != -ENOENT)) <answer> (unlikely(n 
<token> <stdlib.h> <answer> #include 
<token> <stdio.h> <answer> #include 
#include <token> <answer> <string.h> 
#include <token> <answer> <signal.h> 
<token> <unistd.h> <answer> #include 
<token> <altivec.h> <answer> #include 
<token> "utils.h" <answer> #include 
<token> "tm.h" <answer> #include 
#define MAX_ATTEMPT <token> <answer> 500000 
<token> &ucp->uc_mcontext.fp_regs[FPR20 + i], 8); <answer> memcpy(vsx, 
<token> + 8, &vsx_ptr[VSX20 + i], 8); <answer> memcpy(vsx 
fail <token> memcmp(vsx, &vsxs[i], sizeof(vector int)); <answer> = 
<token> (fail) { <answer> if 
broken = <token> <answer> 1; 
printf("VSX%d (1st <token> == 0x", VSX20 + i); <answer> context) 
for <token> = 0; j < 16; j++) <answer> (j 
printf("%02x", <token> <answer> vsx[j]); 
printf(" <token> of 0x"); <answer> instead 
<token> (j = 0; j < 4; j++) <answer> for 
printf("%08x", <token> <answer> vsxs[i][j]); 
printf(" <token> <answer> (expected)\n"); 
memcpy(vsx_tm, &tm_ucp->uc_mcontext.fp_regs[FPR20 <token> i], 8); <answer> + 
memcpy(vsx_tm <token> 8, &tm_vsx_ptr[VSX20 + i], 8); <answer> + 
fail = memcmp(vsx_tm, <token> + i], sizeof(vector int)); <answer> &vsxs[NV_VSX_REGS 
if <token> { <answer> (fail) 
<token> = 1; <answer> broken 
printf("VSX%d (2nd context) <token> 0x", VSX20 + i); <answer> == 
for (j = 0; j < <token> j++) <answer> 16; 
printf("%02x", <token> <answer> vsx_tm[j]); 
printf(" instead of <token> <answer> 0x"); 
for (j = 0; <token> < 4; j++) <answer> j 
printf("%08x", vsxs[NV_VSX_REGS + <token> <answer> i][j]); 
<token> int tm_signal_context_chk() <answer> static 
struct <token> act; <answer> sigaction 
int <token> <answer> i; 
long <token> <answer> rc; 
pid_t pid <token> getpid(); <answer> = 
<token> = signal_usr1; <answer> act.sa_sigaction 
act.sa_flags <token> SA_SIGINFO; <answer> = 
if (sigaction(SIGUSR1, <token> NULL) < 0) { <answer> &act, 
<token> sigusr1"); <answer> perror("sigaction 
<token> = 0; <answer> i 
<token> (i < MAX_ATTEMPT && !broken) { <answer> while 
rc = <token> NULL, NULL, NULL, vsxs); <answer> tm_signal_self_context_load(pid, 
FAIL_IF(rc <token> pid); <answer> != 
return <token> <answer> (broken); 
int <token> <answer> main(void) 
<token> test_harness(tm_signal_context_chk, "tm_signal_context_chk_vsx"); <answer> return 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/printk.h> <answer> #include 
<token> <linux/skbuff.h> <answer> #include 
<token> <linux/netdevice.h> <answer> #include 
#include <token> <answer> <linux/udp.h> 
<token> <linux/ipv6.h> <answer> #include 
<token> <net/dst.h> <answer> #include 
#define <token> 256 <answer> SKB_SIZE 
<token> <linux/cpu_pm.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
<token> <linux/sched.h> <answer> #include 
<token> <linux/smp.h> <answer> #include 
#include <token> <answer> <linux/mm.h> 
#include <token> <answer> <linux/hugetlb.h> 
<token> <linux/export.h> <answer> #include 
#include <token> <answer> <asm/cpu.h> 
#include <token> <answer> <asm/cpu-type.h> 
#include <token> <answer> <asm/bootinfo.h> 
#include <token> <answer> <asm/hazards.h> 
<token> <asm/mmu_context.h> <answer> #include 
<token> <asm/tlb.h> <answer> #include 
<token> <asm/tlbex.h> <answer> #include 
#include <token> <answer> <asm/tlbmisc.h> 
<token> <asm/setup.h> <answer> #include 
static inline void <token> <answer> flush_micro_tlb(void) 
switch <token> { <answer> (current_cpu_type()) 
<token> CPU_LOONGSON2EF: <answer> case 
<token> CPU_LOONGSON64: <answer> case 
<token> | LOONGSON_DIAG_DTLB); <answer> write_c0_diag(LOONGSON_DIAG_ITLB 
static <token> void flush_micro_tlb_vm(struct vm_area_struct *vma) <answer> inline 
if <token> & VM_EXEC) <answer> (vma->vm_flags 
<token> local_flush_tlb_all(void) <answer> void 
unsigned <token> flags; <answer> long 
unsigned <token> old_ctx; <answer> long 
int <token> ftlbhighset; <answer> entry, 
if <token> && !entry) { <answer> (cpu_has_tlbinv 
if <token> { <answer> (current_cpu_data.tlbsizevtlb) 
void <token> long page) <answer> local_flush_tlb_one(unsigned 
<token> long flags; <answer> unsigned 
int <token> idx; <answer> oldpid, 
oldpid = <token> <answer> read_c0_entryhi(); 
page &= (PAGE_MASK <token> 1); <answer> << 
<token> = read_c0_index(); <answer> idx 
if (idx >= 0) <token> <answer> { 
void __update_tlb(struct vm_area_struct * vma, <token> long address, pte_t pte) <answer> unsigned 
<token> long flags; <answer> unsigned 
pgd_t <token> <answer> *pgdp; 
p4d_t <token> <answer> *p4dp; 
<token> *pudp; <answer> pud_t 
pmd_t <token> <answer> *pmdp; 
pte_t *ptep, *ptemap <token> NULL; <answer> = 
<token> idx, pid; <answer> int 
if (current->active_mm <token> vma->vm_mm) <answer> != 
address &= <token> << 1); <answer> (PAGE_MASK 
if <token> { <answer> (cpu_has_mmid) 
} else <token> <answer> { 
<token> = read_c0_entryhi() & cpu_asid_mask(&current_cpu_data); <answer> pid 
<token> | pid); <answer> write_c0_entryhi(address 
<token> = pgd_offset(vma->vm_mm, address); <answer> pgdp 
<token> = p4d_offset(pgdp, address); <answer> p4dp 
pudp <token> pud_offset(p4dp, address); <answer> = 
<token> = pmd_offset(pudp, address); <answer> pmdp 
idx = <token> <answer> read_c0_index(); 
<token> CONFIG_MIPS_HUGE_TLB_SUPPORT <answer> #ifdef 
#if defined(CONFIG_PHYS_ADDR_T_64BIT) <token> defined(CONFIG_CPU_MIPS32) <answer> && 
#ifdef <token> <answer> CONFIG_XPA 
<token> (cpu_has_xpa) <answer> if 
<token> & _PFNX_MASK); <answer> writex_c0_entrylo0(ptep->pte_low 
if <token> <answer> (cpu_has_xpa) 
<token> & _PFNX_MASK); <answer> writex_c0_entrylo1(ptep->pte_low 
<token> (idx < 0) <answer> if 
<token> (ptemap) <answer> if 
<token> add_wired_entry(unsigned long entrylo0, unsigned long entrylo1, <answer> void 
unsigned long entryhi, unsigned <token> pagemask) <answer> long 
<token> CONFIG_XPA <answer> #ifdef 
panic("Broken <token> XPA kernels"); <answer> for 
<token> int old_mmid; <answer> unsigned 
unsigned <token> flags; <answer> long 
<token> long wired; <answer> unsigned 
unsigned long <token> <answer> old_pagemask; 
unsigned long <token> <answer> old_ctx; 
if (cpu_has_mmid) <token> <answer> { 
old_mmid = <token> <answer> read_c0_memorymapid(); 
int <token> <answer> temp_tlb_entry; 
<token> CONFIG_64BIT <answer> #ifndef 
<token> int add_temporary_entry(unsigned long entrylo0, unsigned long entrylo1, <answer> __init 
<token> long entryhi, unsigned long pagemask) <answer> unsigned 
int ret = <token> <answer> 0; 
unsigned <token> flags; <answer> long 
unsigned <token> wired; <answer> long 
unsigned long <token> <answer> old_pagemask; 
<token> long old_ctx; <answer> unsigned 
<token> void r4k_tlb_configure(void) <answer> static 
if (read_c0_pagemask() != <token> <answer> PM_DEFAULT_MASK) 
panic("MMU doesn't <token> PAGE_SIZE=0x%lx", PAGE_SIZE); <answer> support 
if (current_cpu_type() == <token> || <answer> CPU_R10000 
<token> == CPU_R12000 || <answer> current_cpu_type() 
current_cpu_type() <token> CPU_R14000 || <answer> == 
current_cpu_type() == <token> <answer> CPU_R16000) 
if <token> { <answer> (cpu_has_rixi) 
#ifdef <token> <answer> CONFIG_64BIT 
set_c0_pagegrain(PG_RIE | PG_XIE | <token> <answer> PG_ELPA); 
<token> | PG_XIE); <answer> set_c0_pagegrain(PG_RIE 
<token> = current_cpu_data.tlbsize - 1; <answer> temp_tlb_entry 
#include <token> <answer> <linux/mm.h> 
<token> <linux/mmu_context.h> <answer> #include 
<token> <linux/mmu_notifier.h> <answer> #include 
#include <token> <answer> <linux/sched/mm.h> 
#include <token> <answer> <linux/slab.h> 
<token> "arm-smmu-v3.h" <answer> #include 
#include <token> <answer> "../../io-pgtable-arm.h" 
struct <token> { <answer> arm_smmu_mmu_notifier 
struct <token> mn; <answer> mmu_notifier 
<token> arm_smmu_ctx_desc *cd; <answer> struct 
<token> cleared; <answer> bool 
refcount_t <token> <answer> refs; 
struct list_head <token> <answer> list; 
struct <token> *domain; <answer> arm_smmu_domain 
#define <token> container_of(mn, struct arm_smmu_mmu_notifier, mn) <answer> mn_to_smmu(mn) 
struct <token> { <answer> arm_smmu_bond 
struct mm_struct <token> <answer> *mm; 
struct <token> *smmu_mn; <answer> arm_smmu_mmu_notifier 
struct list_head <token> <answer> list; 
#define <token> \ <answer> sva_to_bond(handle) 
container_of(handle, struct <token> sva) <answer> arm_smmu_bond, 
<token> DEFINE_MUTEX(sva_lock); <answer> static 
static void <token> arm_smmu_domain *smmu_domain, <answer> arm_smmu_update_ctx_desc_devices(struct 
int <token> <answer> ssid, 
<token> arm_smmu_ctx_desc *cd) <answer> struct 
struct <token> *master; <answer> arm_smmu_master 
unsigned long <token> <answer> flags; 
spin_lock_irqsave(&smmu_domain->devices_lock, <token> <answer> flags); 
<token> &smmu_domain->devices, domain_head) { <answer> list_for_each_entry(master, 
arm_smmu_write_ctx_desc(master, ssid, <token> <answer> cd); 
spin_unlock_irqrestore(&smmu_domain->devices_lock, <token> <answer> flags); 
static struct <token> * <answer> arm_smmu_ctx_desc 
arm_smmu_share_asid(struct mm_struct *mm, u16 <token> <answer> asid) 
<token> ret; <answer> int 
u32 <token> <answer> new_asid; 
struct <token> *cd; <answer> arm_smmu_ctx_desc 
struct <token> *smmu; <answer> arm_smmu_device 
struct <token> *smmu_domain; <answer> arm_smmu_domain 
cd = xa_load(&arm_smmu_asid_xa, <token> <answer> asid); 
if <token> <answer> (!cd) 
<token> NULL; <answer> return 
if <token> { <answer> (cd->mm) 
if (WARN_ON(cd->mm <token> mm)) <answer> != 
<token> ERR_PTR(-EINVAL); <answer> return 
cd->asid <token> new_asid; <answer> = 
arm_smmu_update_ctx_desc_devices(smmu_domain, IOMMU_NO_PASID, <token> <answer> cd); 
<token> = read_sysreg(mair_el1); <answer> cd->mair 
cd->asid = <token> <answer> asid; 
<token> = mm; <answer> cd->mm 
return <token> <answer> cd; 
return err < 0 ? <token> : ret; <answer> ERR_PTR(err) 
<token> void arm_smmu_free_shared_cd(struct arm_smmu_ctx_desc *cd) <answer> static 
<token> (arm_smmu_free_asid(cd)) { <answer> if 
#define <token> (1 << (PAGE_SHIFT - 3)) <answer> CMDQ_MAX_TLBI_OPS 
static void arm_smmu_mm_arch_invalidate_secondary_tlbs(struct mmu_notifier <token> <answer> *mn, 
struct <token> *mm, <answer> mm_struct 
<token> long start, <answer> unsigned 
unsigned long <token> <answer> end) 
struct arm_smmu_mmu_notifier <token> = mn_to_smmu(mn); <answer> *smmu_mn 
<token> arm_smmu_domain *smmu_domain = smmu_mn->domain; <answer> struct 
<token> size; <answer> size_t 
size <token> end - start; <answer> = 
if (!(smmu_domain->smmu->features & <token> { <answer> ARM_SMMU_FEAT_RANGE_INV)) 
if <token> >= CMDQ_MAX_TLBI_OPS * PAGE_SIZE) <answer> (size 
<token> = 0; <answer> size 
} else <token> <answer> { 
if <token> == ULONG_MAX) <answer> (size 
<token> = 0; <answer> size 
if <token> & ARM_SMMU_FEAT_BTM)) { <answer> (!(smmu_domain->smmu->features 
<token> (!size) <answer> if 
<token> size, <answer> arm_smmu_tlb_inv_range_asid(start, 
PAGE_SIZE, <token> <answer> false, 
arm_smmu_atc_inv_domain(smmu_domain, mm_get_enqcmd_pasid(mm), <token> <answer> start, 
static void arm_smmu_mm_release(struct <token> *mn, struct mm_struct *mm) <answer> mmu_notifier 
struct arm_smmu_mmu_notifier <token> = mn_to_smmu(mn); <answer> *smmu_mn 
struct <token> *smmu_domain = smmu_mn->domain; <answer> arm_smmu_domain 
<token> (smmu_mn->cleared) { <answer> if 
arm_smmu_update_ctx_desc_devices(smmu_domain, <token> <answer> mm_get_enqcmd_pasid(mm), 
<token> smmu_mn->cd->asid); <answer> arm_smmu_tlb_inv_asid(smmu_domain->smmu, 
arm_smmu_atc_inv_domain(smmu_domain, mm_get_enqcmd_pasid(mm), <token> 0); <answer> 0, 
smmu_mn->cleared <token> true; <answer> = 
static <token> arm_smmu_mmu_notifier_free(struct mmu_notifier *mn) <answer> void 
static const <token> mmu_notifier_ops arm_smmu_mmu_notifier_ops = { <answer> struct 
<token> = arm_smmu_mm_arch_invalidate_secondary_tlbs, <answer> .arch_invalidate_secondary_tlbs 
<token> = arm_smmu_mm_release, <answer> .release 
.free_notifier = <token> <answer> arm_smmu_mmu_notifier_free, 
if (!smmu_mn->cleared) <token> <answer> { 
<token> cd->asid); <answer> arm_smmu_tlb_inv_asid(smmu_domain->smmu, 
<token> mm_get_enqcmd_pasid(mm), 0, <answer> arm_smmu_atc_inv_domain(smmu_domain, 
<token> = read_sanitised_ftr_reg(SYS_ID_AA64MMFR0_EL1); <answer> reg 
<token> = cpuid_feature_extract_unsigned_field(reg, ID_AA64MMFR0_EL1_PARANGE_SHIFT); <answer> fld 
oas <token> id_aa64mmfr0_parange_to_phys_shift(fld); <answer> = 
<token> (smmu->oas < oas) <answer> if 
return <token> <answer> false; 
if <token> <answer> (arm64_kernel_unmapped_at_el0()) 
dev_dbg(smmu->dev, <token> shared contexts\n", (1 << asid_bits) - <answer> "%d 
<token> - 2); <answer> num_possible_cpus() 
<token> true; <answer> return 
<token> arm_smmu_master_iopf_supported(struct arm_smmu_master *master) <answer> bool 
<token> (!arm_smmu_master_iopf_supported(master)) <answer> if 
return <token> <answer> 0; 
<token> (!master->iopf_enabled) <answer> if 
return <token> <answer> -EINVAL; 
return iopf_queue_add_device(master->smmu->evtq.iopf, <token> <answer> dev); 
static void arm_smmu_master_sva_disable_iopf(struct <token> *master) <answer> arm_smmu_master 
struct device *dev = <token> <answer> master->dev; 
if <token> <answer> (!master->iopf_enabled) 
iopf_queue_remove_device(master->smmu->evtq.iopf, <token> <answer> dev); 
int <token> arm_smmu_master *master) <answer> arm_smmu_master_enable_sva(struct 
<token> ret; <answer> int 
<token> = arm_smmu_master_sva_enable_iopf(master); <answer> ret 
<token> (!ret) <answer> if 
master->sva_enabled <token> true; <answer> = 
return <token> <answer> ret; 
int arm_smmu_master_disable_sva(struct <token> *master) <answer> arm_smmu_master 
if <token> { <answer> (!list_empty(&master->bonds)) 
dev_err(master->dev, "cannot disable <token> device is bound\n"); <answer> SVA, 
return <token> <answer> -EBUSY; 
master->sva_enabled <token> false; <answer> = 
return <token> <answer> 0; 
void <token> <answer> arm_smmu_sva_notifier_synchronize(void) 
<token> arm_smmu_sva_remove_dev_pasid(struct iommu_domain *domain, <answer> void 
struct device <token> ioasid_t id) <answer> *dev, 
struct <token> *mm = domain->mm; <answer> mm_struct 
struct arm_smmu_bond *bond = NULL, <token> <answer> *t; 
struct arm_smmu_master <token> = dev_iommu_priv_get(dev); <answer> *master 
<token> id, NULL); <answer> arm_smmu_write_ctx_desc(master, 
list_for_each_entry(t, <token> list) { <answer> &master->bonds, 
if <token> == mm) { <answer> (t->mm 
<token> = t; <answer> bond 
if <token> { <answer> (!WARN_ON(!bond)) 
static <token> arm_smmu_sva_set_dev_pasid(struct iommu_domain *domain, <answer> int 
struct device *dev, <token> id) <answer> ioasid_t 
int ret = <token> <answer> 0; 
struct mm_struct *mm = <token> <answer> domain->mm; 
ret = <token> id, mm); <answer> __arm_smmu_sva_bind(dev, 
return <token> <answer> ret; 
static void <token> iommu_domain *domain) <answer> arm_smmu_sva_domain_free(struct 
static <token> struct iommu_domain_ops arm_smmu_sva_domain_ops = { <answer> const 
.set_dev_pasid = <token> <answer> arm_smmu_sva_set_dev_pasid, 
<token> = arm_smmu_sva_domain_free <answer> .free 
struct iommu_domain <token> <answer> *arm_smmu_sva_domain_alloc(void) 
<token> iommu_domain *domain; <answer> struct 
domain = kzalloc(sizeof(*domain), <token> <answer> GFP_KERNEL); 
<token> (!domain) <answer> if 
return <token> <answer> NULL; 
domain->ops <token> &arm_smmu_sva_domain_ops; <answer> = 
return <token> <answer> domain; 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/clk.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/dma-mapping.h> 
<token> <linux/gpio/consumer.h> <answer> #include 
<token> <linux/of_platform.h> <answer> #include 
#include <token> <answer> <linux/pm_runtime.h> 
<token> <linux/reset.h> <answer> #include 
#include <token> <answer> <linux/of_address.h> 
#include <token> <answer> <linux/delay.h> 
<token> <linux/firmware/xlnx-zynqmp.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/phy/phy.h> 
reg = readl(priv_data->regs <token> XLNX_USB_PHY_RST_EN); <answer> + 
if <token> <answer> (mask) 
reg &= <token> <answer> ~XLNX_PHY_RST_MASK; 
reg <token> XLNX_PHY_RST_MASK; <answer> |= 
writel(reg, priv_data->regs + <token> <answer> XLNX_USB_PHY_RST_EN); 
static int dwc3_xlnx_init_versal(struct dwc3_xlnx <token> <answer> *priv_data) 
struct device <token> = priv_data->dev; <answer> *dev 
struct reset_control <token> <answer> *crst; 
int <token> <answer> ret; 
crst = devm_reset_control_get_exclusive(dev, <token> <answer> NULL); 
if <token> <answer> (IS_ERR(crst)) 
return dev_err_probe(dev, <token> "failed to get reset signal\n"); <answer> PTR_ERR(crst), 
dwc3_xlnx_mask_phy_rst(priv_data, <token> <answer> false); 
if <token> <answer> (!priv_data->usb3_phy) 
goto <token> <answer> skip_usb3_phy; 
crst = devm_reset_control_get_exclusive(dev, <token> <answer> "usb_crst"); 
if <token> { <answer> (IS_ERR(crst)) 
ret <token> PTR_ERR(crst); <answer> = 
dev_err_probe(dev, <token> <answer> ret, 
"failed to get <token> reset signal\n"); <answer> core 
goto <token> <answer> err; 
hibrst = devm_reset_control_get_exclusive(dev, <token> <answer> "usb_hibrst"); 
<token> (IS_ERR(hibrst)) { <answer> if 
<token> = PTR_ERR(hibrst); <answer> ret 
dev_err_probe(dev, <token> <answer> ret, 
"failed <token> get hibernation reset signal\n"); <answer> to 
<token> err; <answer> goto 
apbrst = devm_reset_control_get_exclusive(dev, <token> <answer> "usb_apbrst"); 
if (IS_ERR(apbrst)) <token> <answer> { 
ret = <token> <answer> PTR_ERR(apbrst); 
<token> ret, <answer> dev_err_probe(dev, 
"failed to <token> APB reset signal\n"); <answer> get 
<token> err; <answer> goto 
<token> = reset_control_assert(crst); <answer> ret 
if (ret < <token> { <answer> 0) 
dev_err(dev, "Failed to assert core <token> <answer> reset\n"); 
<token> err; <answer> goto 
ret <token> reset_control_assert(hibrst); <answer> = 
if (ret < <token> { <answer> 0) 
dev_err(dev, "Failed to assert <token> reset\n"); <answer> hibernation 
goto <token> <answer> err; 
ret = <token> <answer> reset_control_assert(apbrst); 
if (ret <token> 0) { <answer> < 
dev_err(dev, "Failed <token> assert APB reset\n"); <answer> to 
<token> err; <answer> goto 
<token> = phy_init(priv_data->usb3_phy); <answer> ret 
if (ret <token> 0) { <answer> < 
<token> err; <answer> goto 
<token> = reset_control_deassert(apbrst); <answer> ret 
<token> (ret < 0) { <answer> if 
dev_err(dev, "Failed <token> release APB reset\n"); <answer> to 
goto <token> <answer> err; 
if (of_dma_is_coherent(dev->of_node) || <token> { <answer> device_iommu_mapped(dev)) 
reg = <token> + XLNX_USB_TRAFFIC_ROUTE_CONFIG); <answer> readl(priv_data->regs 
reg <token> XLNX_USB_TRAFFIC_ROUTE_FPD; <answer> |= 
writel(reg, <token> + XLNX_USB_TRAFFIC_ROUTE_CONFIG); <answer> priv_data->regs 
return <token> <answer> ret; 
static const struct of_device_id <token> = { <answer> dwc3_xlnx_of_match[] 
.compatible = <token> <answer> "xlnx,zynqmp-dwc3", 
.data <token> &dwc3_xlnx_init_zynqmp, <answer> = 
<token> = "xlnx,versal-dwc3", <answer> .compatible 
.data <token> &dwc3_xlnx_init_versal, <answer> = 
#include <token> <answer> "acpidump.h" 
<token> <unistd.h> <answer> #include 
<token> <sys/mman.h> <answer> #include 
#ifdef <token> <answer> _free_BSD 
#include <token> <answer> <sys/param.h> 
#define <token> ACPI_OS_SERVICES <answer> _COMPONENT 
<token> O_BINARY <answer> #ifndef 
#define <token> 0 <answer> O_BINARY 
#if <token> || defined(_free_BSD) || defined(_QNX) <answer> defined(_dragon_fly) 
<token> MMAP_FLAGS MAP_SHARED <answer> #define 
#define MMAP_FLAGS <token> <answer> MAP_PRIVATE 
#define SYSTEM_MEMORY <token> <answer> "/dev/mem" 
static acpi_size <token> <answer> acpi_os_get_page_size(void) 
<token> PAGE_SIZE <answer> #ifdef 
return <token> <answer> PAGE_SIZE; 
return <token> <answer> sysconf(_SC_PAGESIZE); 
<token> *acpi_os_map_memory(acpi_physical_address where, acpi_size length) <answer> void 
u8 <token> <answer> *mapped_memory; 
<token> offset; <answer> acpi_physical_address 
acpi_size <token> <answer> page_size; 
int <token> <answer> fd; 
fd = open(SYSTEM_MEMORY, O_RDONLY | <token> <answer> O_BINARY); 
if <token> < 0) { <answer> (fd 
fprintf(stderr, "Cannot open %s\n", <token> <answer> SYSTEM_MEMORY); 
<token> (NULL); <answer> return 
void acpi_os_unmap_memory(void <token> acpi_size length) <answer> *where, 
<token> offset; <answer> acpi_physical_address 
<token> page_size; <answer> acpi_size 
page_size <token> acpi_os_get_page_size(); <answer> = 
offset = ACPI_TO_INTEGER(where) % <token> <answer> page_size; 
munmap((u8 *)where - offset, <token> + offset)); <answer> (length 
#undef <token> <answer> DEBUG 
<token> DEBUG_LOW <answer> #undef 
#define pr_fmt(fmt) "hash-mmu: <token> fmt <answer> " 
#include <token> <answer> <linux/spinlock.h> 
<token> <linux/errno.h> <answer> #include 
<token> <linux/sched/mm.h> <answer> #include 
<token> <linux/proc_fs.h> <answer> #include 
<token> <linux/stat.h> <answer> #include 
#include <token> <answer> <linux/sysctl.h> 
<token> <linux/export.h> <answer> #include 
<token> <linux/ctype.h> <answer> #include 
<token> <linux/cache.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/signal.h> 
<token> <linux/memblock.h> <answer> #include 
<token> <linux/context_tracking.h> <answer> #include 
<token> <linux/libfdt.h> <answer> #include 
<token> <linux/pkeys.h> <answer> #include 
#include <token> <answer> <linux/hugetlb.h> 
#include <token> <answer> <linux/cpu.h> 
<token> <linux/pgtable.h> <answer> #include 
<token> <linux/debugfs.h> <answer> #include 
<token> <linux/random.h> <answer> #include 
<token> <linux/elf-randomize.h> <answer> #include 
#include <token> <answer> <linux/of_fdt.h> 
<token> <asm/interrupt.h> <answer> #include 
<token> <asm/processor.h> <answer> #include 
<token> <asm/mmu.h> <answer> #include 
<token> <asm/mmu_context.h> <answer> #include 
#include <token> <answer> <asm/page.h> 
#include <token> <answer> <asm/types.h> 
#include <token> <answer> <linux/uaccess.h> 
<token> <asm/machdep.h> <answer> #include 
<token> <asm/io.h> <answer> #include 
#include <token> <answer> <asm/eeh.h> 
<token> <asm/tlb.h> <answer> #include 
<token> <asm/cacheflush.h> <answer> #include 
<token> <asm/cputable.h> <answer> #include 
<token> <asm/sections.h> <answer> #include 
<token> <asm/copro.h> <answer> #include 
<token> <asm/udbg.h> <answer> #include 
#include <token> <answer> <asm/code-patching.h> 
#include <token> <answer> <asm/fadump.h> 
<token> <asm/firmware.h> <answer> #include 
<token> <asm/tm.h> <answer> #include 
#include <token> <answer> <asm/trace.h> 
#include <token> <answer> <asm/ps3.h> 
#include <token> <answer> <asm/pte-walk.h> 
#include <token> <answer> <asm/asm-prototypes.h> 
#include <token> <answer> <asm/ultravisor.h> 
<token> <mm/mmu_decl.h> <answer> #include 
#include <token> <answer> "internal.h" 
<token> DEBUG <answer> #ifdef 
#define <token> udbg_printf(fmt) <answer> DBG(fmt...) 
<token> DBG(fmt...) <answer> #define 
#ifdef <token> <answer> DEBUG_LOW 
#define DBG_LOW(fmt...) <token> <answer> udbg_printf(fmt) 
<token> DBG_LOW(fmt...) <answer> #define 
#define <token> (1024) <answer> KB 
#define <token> (1024*KB) <answer> MB 
#define <token> (1024L*MB) <answer> GB 
static unsigned long <token> <answer> _SDR1; 
u8 hpte_page_sizes[1 <token> LP_BITS]; <answer> << 
struct <token> *htab_address; <answer> hash_pte 
<token> long htab_size_bytes; <answer> unsigned 
unsigned long <token> <answer> htab_hash_mask; 
int <token> = MMU_PAGE_4K; <answer> mmu_linear_psize 
int <token> = MMU_PAGE_4K; <answer> mmu_virtual_psize 
int <token> = MMU_PAGE_4K; <answer> mmu_vmalloc_psize 
<token> mmu_io_psize = MMU_PAGE_4K; <answer> int 
int mmu_kernel_ssize = <token> <answer> MMU_SEGSIZE_256M; 
<token> mmu_highuser_ssize = MMU_SEGSIZE_256M; <answer> int 
u16 mmu_slb_size = <token> <answer> 64; 
<token> CONFIG_PPC_64K_PAGES <answer> #ifdef 
int <token> <answer> mmu_ci_restrictions; 
<token> u8 *linear_map_hash_slots; <answer> static 
static unsigned long <token> <answer> linear_map_hash_count; 
<token> mmu_hash_ops mmu_hash_ops; <answer> struct 
<token> struct mmu_psize_def mmu_psize_defaults[] = { <answer> static 
[MMU_PAGE_4K] <token> { <answer> = 
.shift = <token> <answer> 12, 
<token> = 0, <answer> .sllp 
.penc = {[MMU_PAGE_4K] <token> 0, [1 ... MMU_PAGE_COUNT - 1] = -1}, <answer> = 
<token> = 0, <answer> .avpnm 
.tlbiel = <token> <answer> 0, 
static struct <token> mmu_psize_defaults_gp[] = { <answer> mmu_psize_def 
<token> = { <answer> [MMU_PAGE_4K] 
.shift <token> 12, <answer> = 
<token> = 0, <answer> .sllp 
<token> = {[MMU_PAGE_4K] = 0, [1 ... MMU_PAGE_COUNT - 1] = -1}, <answer> .penc 
.avpnm <token> 0, <answer> = 
.tlbiel = <token> <answer> 1, 
[MMU_PAGE_16M] <token> { <answer> = 
.shift = <token> <answer> 24, 
.sllp <token> SLB_VSID_L, <answer> = 
.penc <token> {[0 ... MMU_PAGE_16M - 1] = -1, [MMU_PAGE_16M] = 0, <answer> = 
[MMU_PAGE_16M + 1 ... <token> - 1] = -1 }, <answer> MMU_PAGE_COUNT 
<token> = 0x1UL, <answer> .avpnm 
.tlbiel <token> 0, <answer> = 
static inline void tlbiel_hash_set_isa206(unsigned <token> set, unsigned int is) <answer> int 
unsigned long <token> <answer> rb; 
rb = (set << PPC_BITLSHIFT(51)) | (is << <token> <answer> PPC_BITLSHIFT(53)); 
asm volatile("tlbiel %0" <token> : "r" (rb)); <answer> : 
<token> __always_inline void tlbiel_hash_set_isa300(unsigned int set, unsigned int is, <answer> static 
unsigned <token> pid, <answer> int 
unsigned int ric, unsigned int <token> <answer> prs) 
unsigned long <token> <answer> rb; 
unsigned <token> rs; <answer> long 
<token> (early_cpu_has_feature(CPU_FTR_HVMODE)) <answer> if 
tlbiel_hash_set_isa300(0, is, 0, 2, <token> <answer> 0); 
tlbiel_hash_set_isa300(0, <token> 0, 2, 1); <answer> is, 
for (set = 0; set < <token> set++) <answer> num_sets; 
tlbiel_hash_set_isa300(set, is, <token> 0, 0); <answer> 0, 
asm volatile(PPC_ISA_3_0_INVALIDATE_ERAT <token> isync" : : :"memory"); <answer> "; 
<token> hash__tlbiel_all(unsigned int action) <answer> void 
unsigned <token> is; <answer> int 
<token> (action) { <answer> switch 
case <token> <answer> TLB_INVAL_SCOPE_GLOBAL: 
<token> = 3; <answer> is 
case <token> <answer> TLB_INVAL_SCOPE_LPID: 
<token> = 2; <answer> is 
<token> (early_cpu_has_feature(CPU_FTR_ARCH_300)) <answer> if 
tlbiel_all_isa300(POWER9_TLB_SETS_HASH, <token> <answer> is); 
<token> if (early_cpu_has_feature(CPU_FTR_ARCH_207S)) <answer> else 
tlbiel_all_isa206(POWER8_TLB_SETS, <token> <answer> is); 
else if <token> <answer> (early_cpu_has_feature(CPU_FTR_ARCH_206)) 
<token> is); <answer> tlbiel_all_isa206(POWER7_TLB_SETS, 
WARN(1, "%s called on pre-POWER7 <token> __func__); <answer> CPU\n", 
unsigned long htab_convert_pte_flags(unsigned long pteflags, <token> long flags) <answer> unsigned 
unsigned long rflags = <token> <answer> 0; 
if (pteflags <token> _PAGE_PRIVILEGED) { <answer> & 
if (!(pteflags <token> _PAGE_WRITE)) { <answer> & 
if <token> <answer> (mmu_has_feature(MMU_FTR_KERNEL_RO)) 
<token> |= (HPTE_R_PP0 | 0x2); <answer> rflags 
rflags <token> 0x3; <answer> |= 
VM_WARN_ONCE(!(pteflags & _PAGE_RWX), "no-access <token> request"); <answer> mapping 
<token> else { <answer> } 
if (pteflags <token> _PAGE_RWX) <answer> & 
rflags |= <token> <answer> 0x2; 
VM_WARN_ONCE(!(pteflags & _PAGE_RWX), "no-access mapping <token> <answer> request"); 
<token> (!((pteflags & _PAGE_WRITE) && (pteflags & _PAGE_DIRTY))) <answer> if 
rflags <token> 0x1; <answer> |= 
rflags |= <token> <answer> HPTE_R_R; 
<token> (pteflags & _PAGE_DIRTY) <answer> if 
rflags <token> HPTE_R_C; <answer> |= 
if ((pteflags & <token> == _PAGE_TOLERANT) <answer> _PAGE_CACHE_CTL) 
rflags <token> HPTE_R_I; <answer> |= 
else if ((pteflags & <token> == _PAGE_NON_IDEMPOTENT) <answer> _PAGE_CACHE_CTL) 
rflags <token> (HPTE_R_I | HPTE_R_G); <answer> |= 
else if ((pteflags & _PAGE_CACHE_CTL) <token> _PAGE_SAO) <answer> == 
rflags |= (HPTE_R_W | <token> | HPTE_R_M); <answer> HPTE_R_I 
<token> |= HPTE_R_M; <answer> rflags 
rflags |= <token> flags); <answer> pte_to_hpte_pkey_bits(pteflags, 
return <token> <answer> rflags; 
int htab_bolt_mapping(unsigned long <token> unsigned long vend, <answer> vstart, 
unsigned long pstart, unsigned long <token> <answer> prot, 
int psize, <token> ssize) <answer> int 
unsigned long <token> paddr; <answer> vaddr, 
unsigned <token> step, shift; <answer> int 
int ret = <token> <answer> 0; 
shift <token> mmu_psize_defs[psize].shift; <answer> = 
step <token> 1 << shift; <answer> = 
<token> = htab_convert_pte_flags(prot, HPTE_USE_KERNEL_KEY); <answer> prot 
<token> -> %lx (%lx,%d,%d)\n", <answer> DBG("htab_bolt_mapping(%lx..%lx 
<token> vend, pstart, prot, psize, ssize); <answer> vstart, 
<token> (!vsid) <answer> if 
return <token> <answer> -1; 
if ((PHYSICAL_START <token> MEMORY_START) && <answer> > 
overlaps_interrupt_vector_text(vaddr, <token> + step)) <answer> vaddr 
tprot <token> ~HPTE_R_N; <answer> &= 
hash = <token> shift, ssize); <answer> hpt_hash(vpn, 
hpteg = ((hash & htab_hash_mask) * <token> <answer> HPTES_PER_GROUP); 
ret <token> mmu_hash_ops.hpte_insert(hpteg, vpn, paddr, tprot, <answer> = 
HPTE_V_BOLTED, psize, <token> <answer> psize, 
if (ret <token> -1) { <answer> == 
ret <token> mmu_hash_ops.hpte_remove(hpteg); <answer> = 
if (ret != <token> <answer> -1) 
ret = mmu_hash_ops.hpte_insert(hpteg, vpn, paddr, <token> <answer> tprot, 
<token> psize, psize, <answer> HPTE_V_BOLTED, 
if (ret == -1 && !secondary_hash) <token> <answer> { 
<token> = true; <answer> secondary_hash 
hpteg = ((~hash & <token> * HPTES_PER_GROUP); <answer> htab_hash_mask) 
goto <token> <answer> repeat; 
<token> (ret < 0) <answer> if 
if (debug_pagealloc_enabled_or_kfence() <token> <answer> && 
(paddr >> <token> < linear_map_hash_count) <answer> PAGE_SHIFT) 
linear_map_hash_slots[paddr >> PAGE_SHIFT] <token> ret | 0x80; <answer> = 
return <token> < 0 ? ret : 0; <answer> ret 
int htab_remove_mapping(unsigned <token> vstart, unsigned long vend, <answer> long 
int psize, int <token> <answer> ssize) 
unsigned long vaddr, <token> <answer> time_limit; 
unsigned int step, <token> <answer> shift; 
<token> rc; <answer> int 
int ret <token> 0; <answer> = 
shift = <token> <answer> mmu_psize_defs[psize].shift; 
<token> = 1 << shift; <answer> step 
<token> (!mmu_hash_ops.hpte_removebolted) <answer> if 
<token> -ENODEV; <answer> return 
if <token> time_limit)) { <answer> (time_after(jiffies, 
time_limit <token> jiffies + HZ; <answer> = 
if (rc == <token> { <answer> -ENOENT) 
ret <token> -ENOENT; <answer> = 
<token> (rc < 0) <answer> if 
return <token> <answer> rc; 
return <token> <answer> ret; 
static bool <token> __ro_after_init; <answer> disable_1tb_segments 
<token> int __init parse_disable_1tb_segments(char *p) <answer> static 
disable_1tb_segments <token> true; <answer> = 
return <token> <answer> 0; 
<token> parse_disable_1tb_segments); <answer> early_param("disable_1tb_segments", 
bool stress_hpt_enabled <token> <answer> __initdata; 
static int <token> parse_stress_hpt(char *p) <answer> __init 
stress_hpt_enabled <token> true; <answer> = 
return <token> <answer> 0; 
<token> parse_stress_hpt); <answer> early_param("stress_hpt", 
<token> DEFINE_STATIC_KEY_FALSE(stress_hpt_key); <answer> __ro_after_init 
#define STRESS_MAX_GROUPS <token> <answer> 16 
struct stress_hpt_struct <token> <answer> { 
unsigned long <token> <answer> last_group[STRESS_MAX_GROUPS]; 
static inline <token> stress_nr_groups(void) <answer> int 
<token> (firmware_has_feature(FW_FEATURE_LPAR)) <answer> if 
return <token> <answer> STRESS_MAX_GROUPS; 
return <token> <answer> 1; 
static struct stress_hpt_struct <token> <answer> *stress_hpt_struct; 
static int <token> htab_dt_scan_seg_sizes(unsigned long node, <answer> __init 
const char <token> int depth, <answer> *uname, 
<token> *data) <answer> void 
<token> char *type = of_get_flat_dt_prop(node, "device_type", NULL); <answer> const 
const __be32 <token> <answer> *prop; 
<token> size = 0; <answer> int 
if <token> == MMU_PAGE_4K || base_idx == MMU_PAGE_64K) <answer> (base_idx 
def->tlbiel <token> 1; <answer> = 
def->tlbiel <token> 0; <answer> = 
while <token> > 0 && lpnum) { <answer> (size 
<token> int shift = be32_to_cpu(prop[0]); <answer> unsigned 
int <token> = be32_to_cpu(prop[1]); <answer> penc 
prop += 2; <token> -= 2; <answer> size 
idx <token> get_idx_from_shift(shift); <answer> = 
if <token> < 0) <answer> (idx 
if (penc <token> -1) <answer> == 
pr_err("Invalid penc for base_shift=%d <token> <answer> " 
"shift=%d\n", base_shift, <token> <answer> shift); 
def->penc[idx] = <token> <answer> penc; 
pr_info("base_shift=%d: <token> sllp=0x%04lx," <answer> shift=%d, 
<token> avpnm=0x%08lx, tlbiel=%d, penc=%d\n", <answer> " 
<token> shift, def->sllp, <answer> base_shift, 
def->avpnm, def->tlbiel, <token> <answer> def->penc[idx]); 
<token> 1; <answer> return 
<token> CONFIG_HUGETLB_PAGE <answer> #ifdef 
static int <token> htab_dt_scan_hugepage_blocks(unsigned long node, <answer> __init 
const char *uname, int <token> <answer> depth, 
<token> *data) { <answer> void 
const char *type <token> of_get_flat_dt_prop(node, "device_type", NULL); <answer> = 
<token> __be64 *addr_prop; <answer> const 
const <token> *page_count_prop; <answer> __be32 
unsigned int <token> <answer> expected_pages; 
long unsigned int <token> <answer> phys_addr; 
long <token> int block_size; <answer> unsigned 
page_count_prop = of_get_flat_dt_prop(node, <token> NULL); <answer> "ibm,expected#pages", 
<token> (page_count_prop == NULL) <answer> if 
<token> 0; <answer> return 
expected_pages = <token> << be32_to_cpu(page_count_prop[0])); <answer> (1 
addr_prop = of_get_flat_dt_prop(node, <token> NULL); <answer> "reg", 
<token> (addr_prop == NULL) <answer> if 
return <token> <answer> 0; 
phys_addr = <token> <answer> be64_to_cpu(addr_prop[0]); 
block_size <token> be64_to_cpu(addr_prop[1]); <answer> = 
if (block_size != <token> * GB)) <answer> (16 
return <token> <answer> 0; 
printk(KERN_INFO "Huge <token> memory: " <answer> page(16GB) 
"addr = 0x%lX size = 0x%lX pages = <token> <answer> %d\n", 
<token> block_size, expected_pages); <answer> phys_addr, 
if (phys_addr + block_size * expected_pages <= memblock_end_of_DRAM()) <token> <answer> { 
memblock_reserve(phys_addr, block_size * <token> <answer> expected_pages); 
pseries_add_gpage(phys_addr, block_size, <token> <answer> expected_pages); 
<token> 0; <answer> return 
#ifdef <token> <answer> CONFIG_IBMEBUS 
<token> !cpu_has_feature(CPU_FTR_ARCH_207S) && <answer> return 
<token> false; <answer> return 
<token> = of_scan_flat_dt(htab_dt_scan_page_sizes, NULL); <answer> rc 
if (rc == <token> && early_mmu_has_feature(MMU_FTR_16M_PAGE)) { <answer> 0 
<token> mmu_psize_defaults_gp, <answer> memcpy(mmu_psize_defs, 
#ifdef <token> <answer> CONFIG_HUGETLB_PAGE 
if (!hugetlb_disabled && !early_radix_enabled() ) <token> <answer> { 
static void <token> init_hpte_page_sizes(void) <answer> __init 
long int ap, <token> <answer> bp; 
long int shift, <token> <answer> penc; 
for (bp = <token> bp < MMU_PAGE_COUNT; ++bp) { <answer> 0; 
if <token> <answer> (!mmu_psize_defs[bp].shift) 
while (penc <token> (1 << LP_BITS)) { <answer> < 
hpte_page_sizes[penc] = (ap << 4) <token> bp; <answer> | 
penc += <token> << shift; <answer> 1 
static void <token> htab_init_page_sizes(void) <answer> __init 
bool aligned <token> true; <answer> = 
if <token> { <answer> (!debug_pagealloc_enabled_or_kfence()) 
if (IS_ENABLED(CONFIG_STRICT_KERNEL_RWX) <token> <answer> && 
(unsigned long)_stext <token> 0x1000000) { <answer> % 
<token> (mmu_psize_defs[MMU_PAGE_16M].shift) <answer> if 
pr_warn("Kernel not 16M aligned, <token> 16M linear map alignment\n"); <answer> disabling 
<token> = false; <answer> aligned 
<token> (mmu_psize_defs[MMU_PAGE_16M].shift && aligned) <answer> if 
<token> = MMU_PAGE_16M; <answer> mmu_linear_psize 
<token> if (mmu_psize_defs[MMU_PAGE_1M].shift) <answer> else 
mmu_linear_psize <token> MMU_PAGE_1M; <answer> = 
<token> CONFIG_PPC_64K_PAGES <answer> #ifdef 
<token> (mmu_psize_defs[MMU_PAGE_64K].shift) { <answer> if 
mmu_virtual_psize <token> MMU_PAGE_64K; <answer> = 
mmu_vmalloc_psize = <token> <answer> MMU_PAGE_64K; 
if (mmu_linear_psize == <token> <answer> MMU_PAGE_4K) 
<token> = MMU_PAGE_64K; <answer> mmu_linear_psize 
<token> (mmu_has_feature(MMU_FTR_CI_LARGE_PAGE)) { <answer> if 
<token> (!might_have_hea()) <answer> if 
mmu_io_psize <token> MMU_PAGE_64K; <answer> = 
<token> else <answer> } 
<token> = 1; <answer> mmu_ci_restrictions 
<token> (mmu_psize_defs[MMU_PAGE_16M].shift && <answer> if 
<token> >= 0x40000000) <answer> memblock_phys_mem_size() 
mmu_vmemmap_psize = <token> <answer> MMU_PAGE_16M; 
mmu_vmemmap_psize = <token> <answer> mmu_virtual_psize; 
return max(pteg_shift + 7, <token> <answer> 18U); 
static unsigned long <token> htab_get_table_size(void) <answer> __init 
if (ppc64_pft_size == <token> <answer> 0) 
of_scan_flat_dt(htab_dt_scan_pftsize, <token> <answer> NULL); 
<token> (ppc64_pft_size) <answer> if 
return 1UL <token> ppc64_pft_size; <answer> << 
return 1UL << <token> <answer> htab_shift_for_mem_size(memblock_phys_mem_size()); 
#ifdef <token> <answer> CONFIG_MEMORY_HOTPLUG 
static int resize_hpt_for_hotplug(unsigned <token> new_mem_size) <answer> long 
unsigned <token> <answer> target_hpt_shift; 
<token> (!mmu_hash_ops.resize_hpt) <answer> if 
return <token> <answer> 0; 
target_hpt_shift = <token> <answer> htab_shift_for_mem_size(new_mem_size); 
<token> (target_hpt_shift > ppc64_pft_size || <answer> if 
target_hpt_shift < ppc64_pft_size - <token> <answer> 1) 
<token> mmu_hash_ops.resize_hpt(target_hpt_shift); <answer> return 
<token> 0; <answer> return 
int hash__create_section_mapping(unsigned <token> start, unsigned long end, <answer> long 
<token> nid, pgprot_t prot) <answer> int 
int <token> <answer> rc; 
if <token> >= H_VMALLOC_START) { <answer> (end 
pr_warn("Outside the <token> range\n"); <answer> supported 
return <token> <answer> -1; 
rc = htab_bolt_mapping(start, end, <token> <answer> __pa(start), 
<token> mmu_linear_psize, <answer> pgprot_val(prot), 
if (rc < 0) <token> <answer> { 
int <token> = htab_remove_mapping(start, end, mmu_linear_psize, <answer> rc2 
BUG_ON(rc2 && (rc2 <token> -ENOENT)); <answer> != 
return <token> <answer> rc; 
int hash__remove_section_mapping(unsigned long <token> unsigned long end) <answer> start, 
int rc <token> htab_remove_mapping(start, end, mmu_linear_psize, <answer> = 
if (resize_hpt_for_hotplug(memblock_phys_mem_size()) <token> -ENOSPC) <answer> == 
pr_warn("Hash collision while resizing <token> <answer> HPT\n"); 
<token> rc; <answer> return 
htab_size = __ilog2(htab_size) <token> 18; <answer> - 
mmu_partition_table_set_entry(0, hash_table | htab_size, 0, <token> <answer> false); 
pr_info("Partition <token> %p\n", partition_tb); <answer> table 
<token> hpt_clear_stress(void); <answer> void 
<token> struct timer_list stress_hpt_timer; <answer> static 
<token> void stress_hpt_timer_fn(struct timer_list *timer) <answer> static 
<token> next_cpu; <answer> int 
if <token> <answer> (!firmware_has_feature(FW_FEATURE_LPAR)) 
next_cpu = <token> cpu_online_mask); <answer> cpumask_next(raw_smp_processor_id(), 
if (next_cpu <token> nr_cpu_ids) <answer> >= 
next_cpu <token> cpumask_first(cpu_online_mask); <answer> = 
stress_hpt_timer.expires <token> jiffies + msecs_to_jiffies(10); <answer> = 
<token> next_cpu); <answer> add_timer_on(&stress_hpt_timer, 
static void <token> htab_initialize(void) <answer> __init 
unsigned long <token> <answer> table; 
<token> long pteg_count; <answer> unsigned 
unsigned <token> prot; <answer> long 
phys_addr_t <token> = 0, size = 0, end; <answer> base 
u64 <token> <answer> i; 
<token> -> htab_initialize()\n"); <answer> DBG(" 
if <token> { <answer> (mmu_has_feature(MMU_FTR_1T_SEGMENT)) 
mmu_kernel_ssize <token> MMU_SEGSIZE_1T; <answer> = 
mmu_highuser_ssize <token> MMU_SEGSIZE_1T; <answer> = 
printk(KERN_INFO <token> 1TB segments\n"); <answer> "Using 
if <token> <answer> (stress_slb_enabled) 
<token> (stress_hpt_enabled) { <answer> if 
<token> long tmp; <answer> unsigned 
tmp = memblock_phys_alloc_range(sizeof(struct stress_hpt_struct) * <token> <answer> NR_CPUS, 
<token> stress_hpt_struct), <answer> __alignof__(struct 
<token> MEMBLOCK_ALLOC_ANYWHERE); <answer> 0, 
memset((void *)tmp, 0xff, sizeof(struct stress_hpt_struct) * <token> <answer> NR_CPUS); 
stress_hpt_struct = <token> <answer> __va(tmp); 
timer_setup(&stress_hpt_timer, <token> 0); <answer> stress_hpt_timer_fn, 
stress_hpt_timer.expires = <token> + msecs_to_jiffies(10); <answer> jiffies 
htab_size_bytes = <token> <answer> htab_get_table_size(); 
pteg_count = htab_size_bytes >> <token> <answer> 7; 
<token> = pteg_count - 1; <answer> htab_hash_mask 
if <token> || <answer> (firmware_has_feature(FW_FEATURE_LPAR) 
firmware_has_feature(FW_FEATURE_PS3_LV1)) <token> <answer> { 
if (is_fadump_active() <token> mmu_hash_ops.hpte_clear_all) <answer> && 
<token> else { <answer> } 
unsigned long limit <token> MEMBLOCK_ALLOC_ANYWHERE; <answer> = 
<token> CONFIG_PPC_CELL <answer> #ifdef 
if (fdt_subnode_offset(initial_boot_params, 0, <token> > 0) { <answer> "axon") 
limit <token> 0x80000000; <answer> = 
pr_info("Hash table forced <token> 2G for Axon IOMMU\n"); <answer> below 
<token> (tce_alloc_start) { <answer> if 
tce_alloc_start = <token> long)__va(tce_alloc_start); <answer> (unsigned 
<token> = (unsigned long)__va(tce_alloc_end); <answer> tce_alloc_end 
if <token> + size >= tce_alloc_start) <answer> (base 
tce_alloc_start <token> base + size + 1; <answer> = 
BUG_ON(htab_bolt_mapping(tce_alloc_start, <token> <answer> tce_alloc_end, 
__pa(tce_alloc_start), <token> <answer> prot, 
mmu_linear_psize, <token> <answer> mmu_kernel_ssize)); 
DBG(" <token> htab_initialize()\n"); <answer> <- 
#undef <token> <answer> KB 
<token> MB <answer> #undef 
void <token> hash__early_init_devtree(void) <answer> __init 
BUILD_BUG_ON(H_PAGE_F_SECOND != (1ul << <token> + 3))); <answer> (H_PAGE_F_GIX_SHIFT 
__pte_frag_nr <token> H_PTE_FRAG_NR; <answer> = 
__pte_frag_size_shift <token> H_PTE_FRAG_SIZE_SHIFT; <answer> = 
<token> = H_PMD_FRAG_NR; <answer> __pmd_frag_nr 
__pmd_frag_size_shift = <token> <answer> H_PMD_FRAG_SIZE_SHIFT; 
__pte_index_size <token> H_PTE_INDEX_SIZE; <answer> = 
__pmd_index_size <token> H_PMD_INDEX_SIZE; <answer> = 
__pud_index_size = <token> <answer> H_PUD_INDEX_SIZE; 
<token> = H_PGD_INDEX_SIZE; <answer> __pgd_index_size 
__pud_cache_index <token> H_PUD_CACHE_INDEX; <answer> = 
<token> = H_PTE_TABLE_SIZE; <answer> __pte_table_size 
<token> = H_PMD_TABLE_SIZE; <answer> __pmd_table_size 
__pud_table_size <token> H_PUD_TABLE_SIZE; <answer> = 
__pgd_table_size = <token> <answer> H_PGD_TABLE_SIZE; 
__pmd_val_bits <token> HASH_PMD_VAL_BITS; <answer> = 
__pud_val_bits = <token> <answer> HASH_PUD_VAL_BITS; 
<token> = HASH_PGD_VAL_BITS; <answer> __pgd_val_bits 
__kernel_virt_start = <token> <answer> H_KERN_VIRT_START; 
<token> = H_VMALLOC_START; <answer> __vmalloc_start 
__vmalloc_end = <token> <answer> H_VMALLOC_END; 
<token> = H_KERN_IO_START; <answer> __kernel_io_start 
__kernel_io_end = <token> <answer> H_KERN_IO_END; 
vmemmap <token> (struct page *)H_VMEMMAP_START; <answer> = 
ioremap_bot = <token> <answer> IOREMAP_BASE; 
<token> CONFIG_PCI <answer> #ifdef 
<token> = ISA_IO_BASE; <answer> pci_io_base 
init_mm.context.hash_context = <token> <answer> &init_hash_mm_context; 
<token> SLB_ADDR_LIMIT_DEFAULT); <answer> mm_ctx_set_slb_addr_limit(&init_mm.context, 
<token> hash mmu with SLB\n"); <answer> pr_info("Initializing 
<token> int hash_page_do_lazy_icache(unsigned int pp, pte_t pte, int trap) <answer> unsigned 
struct folio <token> <answer> *folio; 
<token> (!pfn_valid(pte_pfn(pte))) <answer> if 
return <token> <answer> pp; 
<token> = page_folio(pte_page(pte)); <answer> folio 
<token> CONFIG_PPC_64K_PAGES <answer> #ifdef 
<token> demote_segment_4k(struct mm_struct *mm, unsigned long addr) <answer> void 
if <token> addr) == MMU_PAGE_4K) <answer> (get_slice_psize(mm, 
slice_set_range_psize(mm, <token> 1, MMU_PAGE_4K); <answer> addr, 
if ((get_paca_psize(addr) != MMU_PAGE_4K) && (current->mm == mm)) <token> <answer> { 
static int <token> mm_struct *mm, unsigned long ea) <answer> subpage_protection(struct 
struct subpage_prot_table *spt <token> mm_ctx_subpage_prot(&mm->context); <answer> = 
u32 spp <token> 0; <answer> = 
u32 <token> *sbpp; <answer> **sbpm, 
<token> (!spt) <answer> if 
<token> 0; <answer> return 
<token> (ea >= spt->maxaddr) <answer> if 
<token> 0; <answer> return 
if (ea < 0x100000000UL) <token> <answer> { 
spp = ((spp & 2) ? _PAGE_RWX : 0) | ((spp & <token> ? _PAGE_WRITE : 0); <answer> 1) 
return <token> <answer> spp; 
int hash_page_mm(struct <token> *mm, unsigned long ea, <answer> mm_struct 
<token> long access, unsigned long trap, <answer> unsigned 
<token> long flags) <answer> unsigned 
<token> is_thp; <answer> bool 
pgd_t <token> <answer> *pgdir; 
unsigned <token> vsid; <answer> long 
pte_t <token> <answer> *ptep; 
<token> hugeshift; <answer> unsigned 
int rc, user_region <token> 0; <answer> = 
int <token> ssize; <answer> psize, 
DBG_LOW("hash_page(ea=%016lx, access=%lx, <token> <answer> trap=%lx\n", 
ea, access, <token> <answer> trap); 
trace_hash_fault(ea, <token> trap); <answer> access, 
<token> = 1; <answer> rc 
goto <token> <answer> bail; 
<token> mm=%p, mm->pgdir=%p, vsid=%016lx\n", mm, mm->pgd, vsid); <answer> DBG_LOW(" 
if (psize != <token> <answer> MMU_PAGE_4K) 
ea &= ~((1ul <token> mmu_psize_defs[psize].shift) - 1); <answer> << 
access <token> _PAGE_PRESENT | _PAGE_PTE; <answer> |= 
<token> (!check_pte_access(access, pte_val(*ptep))) { <answer> if 
DBG_LOW(" no access <token> <answer> !\n"); 
<token> = 1; <answer> rc 
<token> bail; <answer> goto 
<token> (hugeshift) { <answer> if 
<token> (is_thp) <answer> if 
rc = __hash_page_thp(ea, access, <token> (pmd_t *)ptep, <answer> vsid, 
<token> flags, ssize, psize); <answer> trap, 
<token> CONFIG_HUGETLB_PAGE <answer> #ifdef 
rc <token> __hash_page_huge(ea, access, vsid, ptep, trap, <answer> = 
<token> ssize, hugeshift, psize); <answer> flags, 
else <token> <answer> { 
<token> = 1; <answer> rc 
if (current->mm <token> mm) <answer> == 
<token> mm, psize, user_region); <answer> check_paca_psize(ea, 
goto <token> <answer> bail; 
#ifndef <token> <answer> CONFIG_PPC_64K_PAGES 
<token> i-pte: %016lx\n", pte_val(*ptep)); <answer> DBG_LOW(" 
DBG_LOW(" i-pte: %016lx <token> pte_val(*ptep), <answer> %016lx\n", 
pte_val(*(ptep <token> PTRS_PER_PTE))); <answer> + 
if (mmu_ci_restrictions && psize == <token> && pte_ci(*ptep)) { <answer> MMU_PAGE_64K 
<token> (user_region) { <answer> if 
<token> ea); <answer> demote_segment_4k(mm, 
psize = <token> <answer> MMU_PAGE_4K; 
} else if (ea < VMALLOC_END) <token> <answer> { 
printk(KERN_ALERT "Reducing vmalloc <token> " <answer> segment 
"to 4kB pages <token> of " <answer> because 
<token> mapping\n"); <answer> "non-cacheable 
psize = mmu_vmalloc_psize <token> MMU_PAGE_4K; <answer> = 
if (rc == <token> <answer> -1) 
hash_failure_debug(ea, access, vsid, <token> ssize, psize, <answer> trap, 
psize, <token> <answer> pte_val(*ptep)); 
<token> CONFIG_PPC_64K_PAGES <answer> #ifndef 
<token> o-pte: %016lx\n", pte_val(*ptep)); <answer> DBG_LOW(" 
DBG_LOW(" o-pte: %016lx %016lx\n", <token> <answer> pte_val(*ptep), 
<token> + PTRS_PER_PTE))); <answer> pte_val(*(ptep 
DBG_LOW(" <token> rc=%d\n", rc); <answer> -> 
return <token> <answer> rc; 
int hash_page(unsigned long ea, <token> long access, unsigned long trap, <answer> unsigned 
<token> long dsisr) <answer> unsigned 
unsigned long <token> = 0; <answer> flags 
struct <token> *mm = current->mm; <answer> mm_struct 
if ((get_region_id(ea) <token> VMALLOC_REGION_ID) || <answer> == 
<token> == IO_REGION_ID)) <answer> (get_region_id(ea) 
<token> = &init_mm; <answer> mm 
<token> (dsisr & DSISR_NOHPTE) <answer> if 
<token> |= HPTE_NOHPTE_UPDATE; <answer> flags 
<token> hash_page_mm(mm, ea, access, trap, flags); <answer> return 
unsigned long <token> = regs->dar; <answer> ea 
<token> long dsisr = regs->dsisr; <answer> unsigned 
unsigned long access = _PAGE_PRESENT <token> _PAGE_READ; <answer> | 
unsigned long flags = <token> <answer> 0; 
struct mm_struct <token> <answer> *mm; 
<token> int region_id; <answer> unsigned 
long <token> <answer> err; 
if (unlikely(dsisr & (DSISR_BAD_FAULT_64S <token> DSISR_KEYFAULT))) { <answer> | 
region_id <token> get_region_id(ea); <answer> = 
if ((region_id == <token> || (region_id == IO_REGION_ID)) <answer> VMALLOC_REGION_ID) 
<token> = &init_mm; <answer> mm 
mm <token> current->mm; <answer> = 
if (dsisr <token> DSISR_NOHPTE) <answer> & 
<token> |= HPTE_NOHPTE_UPDATE; <answer> flags 
<token> (dsisr & DSISR_ISSTORE) <answer> if 
access |= <token> <answer> _PAGE_WRITE; 
access |= <token> <answer> _PAGE_PRIVILEGED; 
if (user_mode(regs) || <token> == USER_REGION_ID)) <answer> (region_id 
access <token> ~_PAGE_PRIVILEGED; <answer> &= 
if (TRAP(regs) == <token> <answer> INTERRUPT_INST_STORAGE) 
<token> |= _PAGE_EXEC; <answer> access 
err = hash_page_mm(mm, <token> access, TRAP(regs), flags); <answer> ea, 
if (unlikely(err <token> 0)) { <answer> < 
if (user_mode(regs)) <token> <answer> { 
if <token> && err == -2) <answer> (IS_ENABLED(CONFIG_PPC_SUBPAGE_PROT) 
_exception(SIGSEGV, regs, <token> ea); <answer> SEGV_ACCERR, 
_exception(SIGBUS, regs, <token> ea); <answer> BUS_ADRERR, 
} <token> { <answer> else 
bad_page_fault(regs, <token> <answer> SIGBUS); 
err <token> 0; <answer> = 
} else <token> (err) { <answer> if 
static bool should_hash_preload(struct mm_struct *mm, unsigned <token> ea) <answer> long 
<token> psize = get_slice_psize(mm, ea); <answer> int 
if (unlikely((psize == <token> && subpage_protection(mm, ea))) <answer> MMU_PAGE_4K) 
<token> false; <answer> return 
<token> true; <answer> return 
static void hash_preload(struct mm_struct *mm, <token> *ptep, unsigned long ea, <answer> pte_t 
bool <token> unsigned long trap) <answer> is_exec, 
unsigned long <token> <answer> vsid; 
pgd_t <token> <answer> *pgdir; 
int rc, <token> update_flags = 0; <answer> ssize, 
unsigned long access = _PAGE_PRESENT | _PAGE_READ | (is_exec ? <token> : 0); <answer> _PAGE_EXEC 
<token> long flags; <answer> unsigned 
<token> != USER_REGION_ID); <answer> BUG_ON(get_region_id(ea) 
if <token> ea)) <answer> (!should_hash_preload(mm, 
DBG_LOW("hash_preload(mm=%p, mm->pgdir=%p, <token> access=%lx," <answer> ea=%016lx, 
<token> trap=%lx\n", mm, mm->pgd, ea, access, trap); <answer> " 
if ((pte_val(*ptep) & <token> || pte_ci(*ptep)) <answer> H_PAGE_4K_PFN) 
if (rc <token> -1) <answer> == 
hash_failure_debug(ea, access, vsid, trap, <token> <answer> ssize, 
<token> __update_mmu_cache(struct vm_area_struct *vma, unsigned long address, <answer> void 
<token> *ptep) <answer> pte_t 
<token> long trap; <answer> unsigned 
bool <token> <answer> is_exec; 
trap = current->thread.regs ? TRAP(current->thread.regs) <token> 0UL; <answer> : 
<token> (trap) { <answer> switch 
case <token> <answer> 0x300: 
is_exec <token> false; <answer> = 
<token> 0x400: <answer> case 
<token> = true; <answer> is_exec 
<token> ptep, address, is_exec, trap); <answer> hash_preload(vma->vm_mm, 
#ifdef <token> <answer> CONFIG_PPC_TRANSACTIONAL_MEM 
static <token> void tm_flush_hash_page(int local) <answer> inline 
if (local <token> cpu_has_feature(CPU_FTR_TM) && current->thread.regs && <answer> && 
MSR_TM_ACTIVE(current->thread.regs->msr)) <token> <answer> { 
<token> inline void tm_flush_hash_page(int local) <answer> static 
<token> long pte_get_hash_gslot(unsigned long vpn, unsigned long shift, <answer> unsigned 
int ssize, real_pte_t rpte, unsigned int <token> <answer> subpg_index) 
unsigned long <token> gslot, hidx; <answer> hash, 
hash = hpt_hash(vpn, shift, <token> <answer> ssize); 
hidx = <token> subpg_index); <answer> __rpte_to_hidx(rpte, 
<token> (hidx & _PTEIDX_SECONDARY) <answer> if 
hash = <token> <answer> ~hash; 
<token> = (hash & htab_hash_mask) * HPTES_PER_GROUP; <answer> gslot 
gslot += hidx & <token> <answer> _PTEIDX_GROUP_IX; 
<token> gslot; <answer> return 
<token> flush_hash_page(unsigned long vpn, real_pte_t pte, int psize, int ssize, <answer> void 
unsigned <token> flags) <answer> long 
<token> long index, shift, gslot; <answer> unsigned 
int local = <token> & HPTE_LOCAL_UPDATE; <answer> flags 
<token> vpn); <answer> DBG_LOW("flush_hash_page(vpn=%016lx)\n", 
pte_iterate_hashed_subpages(pte, psize, vpn, index, <token> { <answer> shift) 
gslot = <token> shift, ssize, pte, index); <answer> pte_get_hash_gslot(vpn, 
<token> sub %ld: gslot=%lx\n", index, gslot); <answer> DBG_LOW(" 
mmu_hash_ops.hpte_invalidate(gslot, <token> psize, psize, <answer> vpn, 
ssize, <token> <answer> local); 
} <token> <answer> pte_iterate_hashed_end(); 
<token> CONFIG_TRANSPARENT_HUGEPAGE <answer> #ifdef 
void flush_hash_hugepage(unsigned <token> vsid, unsigned long addr, <answer> long 
<token> *pmdp, unsigned int psize, int ssize, <answer> pmd_t 
unsigned <token> flags) <answer> long 
int <token> max_hpte_count, valid; <answer> i, 
<token> long s_addr; <answer> unsigned 
unsigned <token> *hpte_slot_array; <answer> char 
unsigned long hidx, shift, vpn, <token> slot; <answer> hash, 
int local <token> flags & HPTE_LOCAL_UPDATE; <answer> = 
<token> = addr & HPAGE_PMD_MASK; <answer> s_addr 
hpte_slot_array <token> get_hpte_slot_array(pmdp); <answer> = 
if <token> <answer> (!hpte_slot_array) 
if <token> { <answer> (mmu_hash_ops.hugepage_invalidate) 
mmu_hash_ops.hugepage_invalidate(vsid, <token> hpte_slot_array, <answer> s_addr, 
psize, <token> local); <answer> ssize, 
<token> tm_abort; <answer> goto 
shift = <token> <answer> mmu_psize_defs[psize].shift; 
max_hpte_count <token> HPAGE_PMD_SIZE >> shift; <answer> = 
for (i = 0; i < <token> i++) { <answer> max_hpte_count; 
valid <token> hpte_valid(hpte_slot_array, i); <answer> = 
<token> (!valid) <answer> if 
hidx <token> hpte_hash_index(hpte_slot_array, i); <answer> = 
for (i = 0; i < HPTES_PER_GROUP; <token> { <answer> i++) 
if (mmu_hash_ops.hpte_remove(last_group) == <token> <answer> -1) 
stress_hpt_struct[cpu].last_group[stress_nr_groups() - <token> = -1; <answer> 1] 
if (ea <token> PAGE_OFFSET) { <answer> >= 
(stress_nr_groups() <token> 1) * sizeof(unsigned long)); <answer> - 
stress_hpt_struct[cpu].last_group[0] <token> hpte_group; <answer> = 
#if defined(CONFIG_DEBUG_PAGEALLOC) <token> defined(CONFIG_KFENCE) <answer> || 
static <token> <answer> DEFINE_RAW_SPINLOCK(linear_map_hash_lock); 
static void kernel_map_linear_page(unsigned long vaddr, unsigned <token> lmi) <answer> long 
<token> long hash; <answer> unsigned 
unsigned long vsid <token> get_kernel_vsid(vaddr, mmu_kernel_ssize); <answer> = 
unsigned long vpn <token> hpt_vpn(vaddr, vsid, mmu_kernel_ssize); <answer> = 
unsigned long mode = <token> HPTE_USE_KERNEL_KEY); <answer> htab_convert_pte_flags(pgprot_val(PAGE_KERNEL), 
long <token> <answer> ret; 
hash = hpt_hash(vpn, PAGE_SHIFT, <token> <answer> mmu_kernel_ssize); 
<token> != 0); <answer> BUG_ON(first_memblock_base 
if (!early_cpu_has_feature(CPU_FTR_HVMODE)) <token> <answer> { 
<token> = first_memblock_size; <answer> ppc64_rma_size 
<token> (!early_cpu_has_feature(CPU_FTR_ARCH_300)) <answer> if 
ppc64_rma_size = min_t(u64, ppc64_rma_size, <token> <answer> 0x40000000); 
ppc64_rma_size <token> min_t(u64, ppc64_rma_size, <answer> = 
1UL << <token> <answer> SID_SHIFT_1T); 
<token> (is_32bit_task()) <answer> if 
<token> randomize_page(mm->brk, SZ_32M); <answer> return 
else <token> (!radix_enabled() && mmu_highuser_ssize == MMU_SEGSIZE_1T) <answer> if 
return randomize_page(max_t(unsigned long, <token> SZ_1T), SZ_1G); <answer> mm->brk, 
return randomize_page(mm->brk, <token> <answer> SZ_1G); 
if (unlikely(ppsc->rfpwr_state <token> ERFOFF)) <answer> == 
mac->p2p <token> 0; <answer> = 
<token> = NULL; <answer> mac->vif 
<token> = MAC80211_NOLINK; <answer> mac->link_state 
<token> = PEER_UNKNOWN; <answer> mac->vendor 
<token> = NL80211_IFTYPE_UNSPECIFIED; <answer> mac->opmode 
rtlpriv->cfg->ops->set_network_type(hw, <token> <answer> mac->opmode); 
static int <token> ieee80211_hw *hw, <answer> rtl_op_change_interface(struct 
struct ieee80211_vif <token> <answer> *vif, 
<token> nl80211_iftype new_type, bool p2p) <answer> enum 
struct <token> *rtlpriv = rtl_priv(hw); <answer> rtl_priv 
<token> ret; <answer> int 
<token> vif); <answer> rtl_op_remove_interface(hw, 
<token> = new_type; <answer> vif->type 
<token> = p2p; <answer> vif->p2p 
<token> = rtl_op_add_interface(hw, vif); <answer> ret 
rtl_dbg(rtlpriv, <token> DBG_LOUD, <answer> COMP_MAC80211, 
"p2p %x\n", <token> <answer> p2p); 
return <token> <answer> ret; 
#ifdef <token> <answer> CONFIG_PM 
static u16 <token> data, u16 crc) <answer> crc16_ccitt(u8 
u8 shift_in, <token> crc_bit11, crc_bit4, crc_bit15; <answer> data_bit, 
u8 <token> <answer> i; 
u16 <token> <answer> result; 
for (i = 0; i <token> 8; i++) { <answer> < 
crc_bit15 = ((crc & BIT(15)) ? 1 <token> 0); <answer> : 
data_bit = (data & (BIT(0) << <token> ? 1 : 0); <answer> i) 
shift_in = crc_bit15 <token> data_bit; <answer> ^ 
result = crc <token> 1; <answer> << 
<token> (shift_in == 0) <answer> if 
<token> &= (~BIT(0)); <answer> result 
result |= <token> <answer> BIT(0); 
<token> = ((crc & BIT(11)) ? 1 : 0) ^ shift_in; <answer> crc_bit11 
<token> (crc_bit11 == 0) <answer> if 
<token> &= (~BIT(12)); <answer> result 
<token> |= BIT(12); <answer> result 
crc_bit4 = ((crc & BIT(4)) ? <token> : 0) ^ shift_in; <answer> 1 
<token> (crc_bit4 == 0) <answer> if 
<token> &= (~BIT(5)); <answer> result 
result |= <token> <answer> BIT(5); 
<token> = result; <answer> crc 
return <token> <answer> crc; 
<token> u16 _calculate_wol_pattern_crc(u8 *pattern, u16 len) <answer> static 
u16 crc <token> 0xffff; <answer> = 
<token> i; <answer> u32 
for (i = 0; <token> < len; i++) <answer> i 
<token> = crc16_ccitt(pattern[i], crc); <answer> crc 
crc = <token> <answer> ~crc; 
return <token> <answer> crc; 
static void _rtl_add_wowlan_patterns(struct <token> *hw, <answer> ieee80211_hw 
struct <token> *wow) <answer> cfg80211_wowlan 
struct rtl_priv *rtlpriv = <token> <answer> rtl_priv(hw); 
struct rtl_mac *mac <token> &rtlpriv->mac80211; <answer> = 
struct cfg80211_pkt_pattern *patterns = <token> <answer> wow->patterns; 
struct rtl_wow_pattern <token> <answer> rtl_pattern; 
const <token> *pattern_os, *mask_os; <answer> u8 
<token> mask[MAX_WOL_BIT_MASK_SIZE] = {0}; <answer> u8 
u8 <token> = {0}; <answer> content[MAX_WOL_PATTERN_SIZE] 
u8 broadcast_addr[6] = {0xff, <token> 0xff, 0xff, 0xff, 0xff}; <answer> 0xff, 
u8 multicast_addr1[2] = {0x33, <token> <answer> 0x33}; 
u8 <token> = {0x01, 0x00, 0x5e}; <answer> multicast_addr2[3] 
<token> i, mask_len; <answer> u8 
u16 j, <token> <answer> len; 
<token> (i = 0; i < wow->n_patterns; i++) { <answer> for 
memset(&rtl_pattern, <token> sizeof(struct rtl_wow_pattern)); <answer> 0, 
memset(mask, 0, <token> <answer> MAX_WOL_BIT_MASK_SIZE); 
if (patterns[i].pattern_len <token> 0 || <answer> < 
patterns[i].pattern_len > <token> { <answer> MAX_WOL_PATTERN_SIZE) 
rtl_dbg(rtlpriv, <token> DBG_WARNING, <answer> COMP_POWER, 
"Pattern[%d] <token> too long\n", i); <answer> is 
<token> = patterns[i].pattern; <answer> pattern_os 
<token> = DIV_ROUND_UP(patterns[i].pattern_len, 8); <answer> mask_len 
<token> = patterns[i].mask; <answer> mask_os 
RT_PRINT_DATA(rtlpriv, COMP_POWER, <token> <answer> DBG_TRACE, 
"pattern <token> pattern_os, <answer> content\n", 
RT_PRINT_DATA(rtlpriv, <token> DBG_TRACE, <answer> COMP_POWER, 
"mask <token> mask_os, mask_len); <answer> content\n", 
len <token> 0; <answer> = 
for <token> = 12; j < patterns[i].pattern_len; j++) { <answer> (j 
if ((mask_os[j / 8] >> (j % 8)) <token> 0x01) { <answer> & 
content[len] <token> pattern_os[j]; <answer> = 
<token> COMP_POWER, DBG_TRACE, <answer> RT_PRINT_DATA(rtlpriv, 
"pattern to hw\n", content, <token> <answer> len); 
if <token> == ERFOFF)) <answer> (unlikely(ppsc->rfpwr_state 
if <token> <answer> (!rtlpriv->psc.multi_buffered) 
<token> else { <answer> } 
<token> = false; <answer> rtlpriv->psc.sw_ps_enabled 
if <token> & IEEE80211_CONF_CHANGE_RETRY_LIMITS) { <answer> (changed 
rtl_dbg(rtlpriv, <token> DBG_LOUD, <answer> COMP_MAC80211, 
<token> %x\n", <answer> "IEEE80211_CONF_CHANGE_RETRY_LIMITS 
if (changed != ~0) <token> <answer> { 
<token> = hw->conf.long_frame_max_tx_count; <answer> mac->retry_long 
<token> = hw->conf.long_frame_max_tx_count; <answer> mac->retry_short 
rtlpriv->cfg->ops->set_hw_reg(hw, <token> <answer> HW_VAR_RETRY_LIMIT, 
(u8 <token> <answer> *)(&hw->conf.long_frame_max_tx_count)); 
if <token> & IEEE80211_CONF_CHANGE_CHANNEL && <answer> (changed 
!rtlpriv->proximity.proxim_on) <token> <answer> { 
struct ieee80211_channel *channel = <token> <answer> hw->conf.chandef.chan; 
enum nl80211_chan_width width <token> hw->conf.chandef.width; <answer> = 
enum nl80211_channel_type channel_type = <token> <answer> NL80211_CHAN_NO_HT; 
u8 wide_chan = (u8) <token> <answer> channel->hw_value; 
<token> (width >= NL80211_CHAN_WIDTH_80) { <answer> if 
if <token> == NL80211_CHAN_WIDTH_80) { <answer> (width 
u32 center = <token> <answer> hw->conf.chandef.center_freq1; 
u32 <token> = <answer> primary 
rtlphy->current_chan_bw <token> <answer> = 
mac->bw_80 = <token> <answer> true; 
mac->bw_40 = <token> <answer> true; 
if <token> > primary) { <answer> (center 
mac->cur_80_prime_sc <token> <answer> = 
if <token> - primary == 10) { <answer> (center 
mac->cur_40_prime_sc <token> <answer> = 
wide_chan += <token> <answer> 2; 
} else if (center - <token> == 30) { <answer> primary 
<token> = <answer> mac->cur_40_prime_sc 
wide_chan <token> 6; <answer> += 
<token> else { <answer> } 
<token> = <answer> mac->cur_80_prime_sc 
if <token> - center == 10) { <answer> (primary 
<token> = <answer> mac->cur_40_prime_sc 
<token> -= 2; <answer> wide_chan 
} else if <token> - center == 30) { <answer> (primary 
mac->cur_40_prime_sc <token> <answer> = 
wide_chan -= <token> <answer> 6; 
} <token> { <answer> else 
<token> (channel_type) { <answer> switch 
<token> NL80211_CHAN_HT20: <answer> case 
case <token> <answer> NL80211_CHAN_NO_HT: 
if <token> { <answer> (rtlpriv->mac80211.offchan_delay) 
<token> = false; <answer> rtlpriv->mac80211.offchan_delay 
rtlphy->current_channel <token> wide_chan; <answer> = 
<token> channel_type); <answer> rtlpriv->cfg->ops->set_bw_mode(hw, 
<token> 0; <answer> return 
static void rtl_op_configure_filter(struct <token> *hw, <answer> ieee80211_hw 
unsigned int <token> <answer> changed_flags, 
unsigned int *new_flags, <token> multicast) <answer> u64 
bool <token> = false; <answer> update_rcr 
struct <token> *rtlpriv = rtl_priv(hw); <answer> rtl_priv 
struct rtl_mac <token> = rtl_mac(rtl_priv(hw)); <answer> *mac 
<token> &= RTL_SUPPORTED_FILTERS; <answer> *new_flags 
if <token> == changed_flags) <answer> (0 
if <token> & FIF_BCN_PRBRESP_PROMISC && <answer> (changed_flags 
mac->link_state >= MAC80211_LINKED) <token> <answer> { 
<token> (mac->opmode != NL80211_IFTYPE_AP && <answer> if 
mac->opmode != <token> { <answer> NL80211_IFTYPE_MESH_POINT) 
if (*new_flags <token> FIF_BCN_PRBRESP_PROMISC) <answer> & 
<token> false); <answer> rtlpriv->cfg->ops->set_chk_bssid(hw, 
rtlpriv->cfg->ops->set_chk_bssid(hw, <token> <answer> true); 
<token> (update_rcr) <answer> if 
update_rcr = <token> <answer> false; 
if (changed_flags & <token> { <answer> FIF_CONTROL) 
if <token> & FIF_CONTROL) { <answer> (*new_flags 
<token> |= rtlpriv->cfg->maps[MAC_RCR_ACF]; <answer> mac->rx_conf 
<token> COMP_MAC80211, DBG_LOUD, <answer> rtl_dbg(rtlpriv, 
"Enable receive <token> frame.\n"); <answer> control 
} <token> { <answer> else 
mac->rx_conf &= <token> <answer> ~rtlpriv->cfg->maps[MAC_RCR_ACF]; 
rtl_dbg(rtlpriv, <token> DBG_LOUD, <answer> COMP_MAC80211, 
<token> receive control frame.\n"); <answer> "Disable 
<token> (!update_rcr) <answer> if 
<token> = true; <answer> update_rcr 
if (changed_flags & <token> { <answer> FIF_OTHER_BSS) 
if (*new_flags & <token> { <answer> FIF_OTHER_BSS) 
mac->rx_conf <token> rtlpriv->cfg->maps[MAC_RCR_AAP]; <answer> |= 
<token> COMP_MAC80211, DBG_LOUD, <answer> rtl_dbg(rtlpriv, 
"Enable receive <token> BSS's frame.\n"); <answer> other 
<token> else { <answer> } 
mac->rx_conf <token> ~rtlpriv->cfg->maps[MAC_RCR_AAP]; <answer> &= 
rtl_dbg(rtlpriv, <token> DBG_LOUD, <answer> COMP_MAC80211, 
"Disable receive <token> BSS's frame.\n"); <answer> other 
if <token> <answer> (!update_rcr) 
update_rcr = <token> <answer> true; 
<token> (update_rcr) <answer> if 
rtlpriv->cfg->ops->set_hw_reg(hw, <token> <answer> HW_VAR_RCR, 
<token> *)(&mac->rx_conf)); <answer> (u8 
static int <token> ieee80211_hw *hw, <answer> rtl_op_sta_add(struct 
struct <token> *vif, <answer> ieee80211_vif 
<token> ieee80211_sta *sta) <answer> struct 
struct rtl_priv *rtlpriv = <token> <answer> rtl_priv(hw); 
struct rtl_hal *rtlhal = <token> <answer> rtl_hal(rtl_priv(hw)); 
struct <token> *mac = rtl_mac(rtl_priv(hw)); <answer> rtl_mac 
struct rtl_sta_info <token> <answer> *sta_entry; 
<token> (sta) { <answer> if 
sta_entry = (struct rtl_sta_info <token> <answer> *)sta->drv_priv; 
list_add_tail(&sta_entry->list, <token> <answer> &rtlpriv->entry_list); 
if (rtlhal->current_bandtype <token> BAND_ON_2_4G) { <answer> == 
sta_entry->wireless_mode <token> WIRELESS_MODE_G; <answer> = 
if (sta->deflink.supp_rates[0] <token> 0xf) <answer> <= 
sta_entry->wireless_mode <token> WIRELESS_MODE_B; <answer> = 
<token> (sta->deflink.ht_cap.ht_supported) <answer> if 
sta_entry->wireless_mode <token> WIRELESS_MODE_N_24G; <answer> = 
if (vif->type <token> NL80211_IFTYPE_ADHOC) <answer> == 
sta_entry->wireless_mode <token> WIRELESS_MODE_G; <answer> = 
<token> else if (rtlhal->current_bandtype == BAND_ON_5G) { <answer> } 
sta_entry->wireless_mode = <token> <answer> WIRELESS_MODE_A; 
<token> (sta->deflink.ht_cap.ht_supported) <answer> if 
sta_entry->wireless_mode <token> WIRELESS_MODE_N_5G; <answer> = 
<token> (sta->deflink.vht_cap.vht_supported) <answer> if 
sta_entry->wireless_mode = <token> <answer> WIRELESS_MODE_AC_5G; 
<token> (vif->type == NL80211_IFTYPE_ADHOC) <answer> if 
sta_entry->wireless_mode <token> WIRELESS_MODE_A; <answer> = 
static <token> rtl_op_conf_tx(struct ieee80211_hw *hw, <answer> int 
struct <token> *vif, <answer> ieee80211_vif 
unsigned int link_id, u16 <token> <answer> queue, 
const struct <token> *param) <answer> ieee80211_tx_queue_params 
<token> rtl_priv *rtlpriv = rtl_priv(hw); <answer> struct 
<token> rtl_mac *mac = rtl_mac(rtl_priv(hw)); <answer> struct 
int <token> <answer> aci; 
if (queue >= AC_MAX) <token> <answer> { 
<token> COMP_ERR, DBG_WARNING, <answer> rtl_dbg(rtlpriv, 
"queue number <token> is incorrect!\n", queue); <answer> %d 
return <token> <answer> -EINVAL; 
aci = <token> <answer> _rtl_get_hal_qnum(queue); 
<token> = param->aifs; <answer> mac->ac[aci].aifs 
mac->ac[aci].cw_min = <token> <answer> cpu_to_le16(param->cw_min); 
<token> = cpu_to_le16(param->cw_max); <answer> mac->ac[aci].cw_max 
mac->ac[aci].tx_op = <token> <answer> cpu_to_le16(param->txop); 
memcpy(&mac->edca_param[aci], <token> sizeof(*param)); <answer> param, 
rtlpriv->cfg->ops->set_qos(hw, <token> <answer> aci); 
return <token> <answer> 0; 
static void send_beacon_frame(struct <token> *hw, <answer> ieee80211_hw 
struct ieee80211_vif <token> <answer> *vif) 
struct <token> *rtlpriv = rtl_priv(hw); <answer> rtl_priv 
struct sk_buff *skb <token> ieee80211_beacon_get(hw, vif, 0); <answer> = 
struct rtl_tcb_desc <token> <answer> tcb_desc; 
if (skb) <token> <answer> { 
memset(&tcb_desc, 0, sizeof(struct <token> <answer> rtl_tcb_desc)); 
rtlpriv->intf_ops->adapter_tx(hw, <token> skb, &tcb_desc); <answer> NULL, 
<token> rtl_update_beacon_work_callback(struct work_struct *work) <answer> void 
<token> rtl_works *rtlworks = <answer> struct 
container_of(work, <token> rtl_works, update_beacon_work); <answer> struct 
struct ieee80211_hw *hw = <token> <answer> rtlworks->hw; 
<token> rtl_priv *rtlpriv = rtl_priv(hw); <answer> struct 
struct ieee80211_vif *vif = <token> <answer> rtlpriv->mac80211.vif; 
if (!vif) <token> <answer> { 
<token> "no vif to update beacon\n"); <answer> WARN_ONCE(true, 
send_beacon_frame(hw, <token> <answer> vif); 
static void rtl_op_bss_info_changed(struct <token> *hw, <answer> ieee80211_hw 
struct <token> *vif, <answer> ieee80211_vif 
struct ieee80211_bss_conf <token> <answer> *bss_conf, 
<token> changed) <answer> u64 
struct rtl_priv *rtlpriv = <token> <answer> rtl_priv(hw); 
struct <token> *rtlhal = rtl_hal(rtlpriv); <answer> rtl_hal 
struct rtl_mac *mac = <token> <answer> rtl_mac(rtl_priv(hw)); 
struct <token> *ppsc = rtl_psc(rtl_priv(hw)); <answer> rtl_ps_ctl 
if <token> == NL80211_IFTYPE_ADHOC || <answer> (vif->type 
vif->type == NL80211_IFTYPE_AP <token> <answer> || 
<token> == NL80211_IFTYPE_MESH_POINT) { <answer> vif->type 
if (changed & <token> || <answer> BSS_CHANGED_BEACON 
<token> & BSS_CHANGED_BEACON_ENABLED && <answer> (changed 
<token> { <answer> bss_conf->enable_beacon)) 
<token> (mac->beacon_enabled == 0) { <answer> if 
rtl_dbg(rtlpriv, COMP_MAC80211, <token> <answer> DBG_DMESG, 
<token> = MAC80211_LINKED; <answer> mac->link_state 
mac->cnt_after_linked <token> 0; <answer> = 
mac->assoc_id <token> vif->cfg.aid; <answer> = 
memcpy(mac->bssid, bss_conf->bssid, <token> <answer> ETH_ALEN); 
if <token> <answer> (rtlpriv->cfg->ops->linked_set_reg) 
<token> = ieee80211_find_sta(vif, (u8 *)bss_conf->bssid); <answer> sta 
if (!sta) <token> <answer> { 
goto <token> <answer> out; 
<token> COMP_EASY_CONCURRENT, DBG_LOUD, <answer> rtl_dbg(rtlpriv, 
"send <token> STATIC frame\n"); <answer> PS 
if <token> { <answer> (rtlpriv->dm.supp_phymode_switch) 
if <token> <answer> (sta->deflink.ht_cap.ht_supported) 
rtl_send_smps_action(hw, <token> <answer> sta, 
<token> (rtlhal->current_bandtype == BAND_ON_5G) { <answer> if 
mac->mode <token> WIRELESS_MODE_A; <answer> = 
} <token> { <answer> else 
if (sta->deflink.supp_rates[0] <= <token> <answer> 0xf) 
<token> = WIRELESS_MODE_B; <answer> mac->mode 
mac->mode = <token> <answer> WIRELESS_MODE_G; 
if (sta->deflink.ht_cap.ht_supported) <token> <answer> { 
if <token> == BAND_ON_2_4G) <answer> (rtlhal->current_bandtype 
<token> = WIRELESS_MODE_N_24G; <answer> mac->mode 
mac->mode <token> WIRELESS_MODE_N_5G; <answer> = 
<token> (sta->deflink.vht_cap.vht_supported) { <answer> if 
if (rtlhal->current_bandtype <token> BAND_ON_5G) <answer> == 
mac->mode = <token> <answer> WIRELESS_MODE_AC_5G; 
mac->mode <token> WIRELESS_MODE_AC_24G; <answer> = 
if <token> == NL80211_IFTYPE_STATION) <answer> (vif->type 
rtlpriv->cfg->ops->update_rate_tbl(hw, <token> 0, <answer> sta, 
<token> *)(&mstatus)); <answer> (u8 
<token> = (mstatus == RT_MEDIA_CONNECT) ? <answer> ppsc->report_linked 
true : <token> <answer> false; 
if <token> <answer> (rtlpriv->cfg->ops->get_btc_status()) 
<token> mstatus); <answer> rtlpriv, 
if (changed <token> BSS_CHANGED_ERP_CTS_PROT) { <answer> & 
<token> COMP_MAC80211, DBG_TRACE, <answer> rtl_dbg(rtlpriv, 
<token> = bss_conf->use_cts_prot; <answer> mac->use_cts_protect 
if (changed & BSS_CHANGED_ERP_PREAMBLE) <token> <answer> { 
rtl_dbg(rtlpriv, COMP_MAC80211, <token> <answer> DBG_LOUD, 
"BSS_CHANGED_ERP_PREAMBLE <token> short preamble:%x\n", <answer> use 
mac->short_preamble = <token> <answer> bss_conf->use_short_preamble; 
<token> HW_VAR_ACK_PREAMBLE, <answer> rtlpriv->cfg->ops->set_hw_reg(hw, 
(u8 <token> <answer> *)(&mac->short_preamble)); 
if (changed & <token> { <answer> BSS_CHANGED_ERP_SLOT) 
<token> COMP_MAC80211, DBG_TRACE, <answer> rtl_dbg(rtlpriv, 
if <token> <answer> (bss_conf->use_short_slot) 
<token> = RTL_SLOT_TIME_9; <answer> mac->slot_time 
<token> = RTL_SLOT_TIME_20; <answer> mac->slot_time 
rtlpriv->cfg->ops->set_hw_reg(hw, <token> <answer> HW_VAR_SLOT_TIME, 
<token> *)(&mac->slot_time)); <answer> (u8 
if (changed & BSS_CHANGED_HT) <token> <answer> { 
struct ieee80211_sta *sta <token> NULL; <answer> = 
<token> COMP_MAC80211, DBG_TRACE, <answer> rtl_dbg(rtlpriv, 
sta <token> ieee80211_find_sta(vif, (u8 *)bss_conf->bssid); <answer> = 
if <token> { <answer> (sta) 
<token> (sta->deflink.ht_cap.ampdu_density > <answer> if 
<token> = <answer> mac->current_ampdu_density 
<token> (sta->deflink.ht_cap.ampdu_factor < <answer> if 
mac->current_ampdu_factor <token> <answer> = 
<token> HW_VAR_SHORTGI_DENSITY, <answer> rtlpriv->cfg->ops->set_hw_reg(hw, 
<token> *)(&mac->max_mss_density)); <answer> (u8 
rtlpriv->cfg->ops->set_hw_reg(hw, <token> <answer> HW_VAR_AMPDU_FACTOR, 
rtlpriv->cfg->ops->set_hw_reg(hw, <token> <answer> HW_VAR_AMPDU_MIN_SPACE, 
if (changed & BSS_CHANGED_BSSID) <token> <answer> { 
u32 <token> <answer> basic_rates; 
struct ieee80211_sta *sta = <token> <answer> NULL; 
rtlpriv->cfg->ops->set_hw_reg(hw, <token> <answer> HW_VAR_BSSID, 
<token> *)bss_conf->bssid); <answer> (u8 
rtl_dbg(rtlpriv, COMP_MAC80211, <token> <answer> DBG_DMESG, 
"bssid: <token> bss_conf->bssid); <answer> %pM\n", 
mac->vendor = <token> <answer> PEER_UNKNOWN; 
<token> bss_conf->bssid, ETH_ALEN); <answer> memcpy(mac->bssid, 
sta <token> ieee80211_find_sta(vif, (u8 *)bss_conf->bssid); <answer> = 
if (!sta) <token> <answer> { 
goto <token> <answer> out; 
if (rtlhal->current_bandtype <token> BAND_ON_5G) { <answer> == 
mac->mode <token> WIRELESS_MODE_A; <answer> = 
<token> else { <answer> } 
if (sta->deflink.supp_rates[0] <token> 0xf) <answer> <= 
<token> = WIRELESS_MODE_B; <answer> mac->mode 
mac->mode = <token> <answer> WIRELESS_MODE_G; 
if (sta->deflink.ht_cap.ht_supported) <token> <answer> { 
if <token> == BAND_ON_2_4G) <answer> (rtlhal->current_bandtype 
mac->mode = <token> <answer> WIRELESS_MODE_N_24G; 
mac->mode <token> WIRELESS_MODE_N_5G; <answer> = 
if <token> { <answer> (sta->deflink.vht_cap.vht_supported) 
if (rtlhal->current_bandtype <token> BAND_ON_5G) <answer> == 
<token> = WIRELESS_MODE_AC_5G; <answer> mac->mode 
<token> = WIRELESS_MODE_AC_24G; <answer> mac->mode 
if <token> == NL80211_IFTYPE_STATION) { <answer> (vif->type 
struct rtl_sta_info <token> <answer> *sta_entry; 
sta_entry = <token> rtl_sta_info *)sta->drv_priv; <answer> (struct 
<token> = mac->mode; <answer> sta_entry->wireless_mode 
if (sta->deflink.ht_cap.ht_supported) <token> <answer> { 
<token> = true; <answer> mac->ht_enable 
<token> (sta->deflink.vht_cap.vht_supported) <answer> if 
<token> = true; <answer> mac->vht_enable 
<token> (changed & BSS_CHANGED_BASIC_RATES) { <answer> if 
if (rtlhal->current_bandtype == <token> <answer> BAND_ON_5G) 
basic_rates = <token> << 4; <answer> sta->deflink.supp_rates[1] 
basic_rates = <token> <answer> sta->deflink.supp_rates[0]; 
<token> = basic_rates; <answer> mac->basic_rates 
rtlpriv->cfg->ops->set_hw_reg(hw, <token> <answer> HW_VAR_BASIC_RATE, 
(u8 <token> <answer> *)(&basic_rates)); 
static <token> rtl_op_get_tsf(struct ieee80211_hw *hw, struct ieee80211_vif *vif) <answer> u64 
<token> rtl_priv *rtlpriv = rtl_priv(hw); <answer> struct 
<token> tsf; <answer> u64 
rtlpriv->cfg->ops->get_hw_reg(hw, <token> (u8 *)(&tsf)); <answer> HW_VAR_CORRECT_TSF, 
return <token> <answer> tsf; 
static void rtl_op_set_tsf(struct ieee80211_hw <token> <answer> *hw, 
struct ieee80211_vif *vif, <token> tsf) <answer> u64 
struct rtl_priv *rtlpriv <token> rtl_priv(hw); <answer> = 
struct rtl_mac <token> = rtl_mac(rtl_priv(hw)); <answer> *mac 
u8 <token> = (mac->opmode == NL80211_IFTYPE_ADHOC) ? 1 : 0; <answer> bibss 
<token> = tsf; <answer> mac->tsf 
<token> HW_VAR_CORRECT_TSF, (u8 *)(&bibss)); <answer> rtlpriv->cfg->ops->set_hw_reg(hw, 
<token> void rtl_op_reset_tsf(struct ieee80211_hw *hw, struct ieee80211_vif *vif) <answer> static 
struct rtl_priv *rtlpriv = <token> <answer> rtl_priv(hw); 
u8 <token> = 0; <answer> tmp 
rtlpriv->cfg->ops->set_hw_reg(hw, HW_VAR_DUAL_TSF_RST, <token> *)(&tmp)); <answer> (u8 
static void rtl_op_sta_notify(struct <token> *hw, <answer> ieee80211_hw 
<token> ieee80211_vif *vif, <answer> struct 
enum sta_notify_cmd <token> <answer> cmd, 
<token> ieee80211_sta *sta) <answer> struct 
switch (cmd) <token> <answer> { 
case <token> <answer> STA_NOTIFY_SLEEP: 
<token> STA_NOTIFY_AWAKE: <answer> case 
static int rtl_op_ampdu_action(struct <token> *hw, <answer> ieee80211_hw 
struct <token> *vif, <answer> ieee80211_vif 
struct <token> *params) <answer> ieee80211_ampdu_params 
<token> rtl_priv *rtlpriv = rtl_priv(hw); <answer> struct 
struct <token> *sta = params->sta; <answer> ieee80211_sta 
enum ieee80211_ampdu_mlme_action action = <token> <answer> params->action; 
u16 tid <token> params->tid; <answer> = 
u16 <token> = &params->ssn; <answer> *ssn 
switch (action) <token> <answer> { 
<token> IEEE80211_AMPDU_TX_START: <answer> case 
<token> COMP_MAC80211, DBG_TRACE, <answer> rtl_dbg(rtlpriv, 
<token> TID:%d\n", tid); <answer> "IEEE80211_AMPDU_TX_START: 
<token> rtl_tx_agg_start(hw, vif, sta, tid, ssn); <answer> return 
<token> IEEE80211_AMPDU_TX_STOP_CONT: <answer> case 
<token> IEEE80211_AMPDU_TX_STOP_FLUSH: <answer> case 
<token> IEEE80211_AMPDU_TX_STOP_FLUSH_CONT: <answer> case 
rtl_dbg(rtlpriv, <token> DBG_TRACE, <answer> COMP_MAC80211, 
"IEEE80211_AMPDU_TX_STOP: <token> tid); <answer> TID:%d\n", 
return rtl_tx_agg_stop(hw, <token> sta, tid); <answer> vif, 
case <token> <answer> IEEE80211_AMPDU_TX_OPERATIONAL: 
<token> COMP_MAC80211, DBG_TRACE, <answer> rtl_dbg(rtlpriv, 
"IEEE80211_AMPDU_TX_OPERATIONAL:TID:%d\n", <token> <answer> tid); 
<token> sta, tid); <answer> rtl_tx_agg_oper(hw, 
case <token> <answer> IEEE80211_AMPDU_RX_START: 
rtl_dbg(rtlpriv, <token> DBG_TRACE, <answer> COMP_MAC80211, 
"IEEE80211_AMPDU_RX_START:TID:%d\n", <token> <answer> tid); 
return <token> sta, tid); <answer> rtl_rx_agg_start(hw, 
<token> IEEE80211_AMPDU_RX_STOP: <answer> case 
<token> COMP_MAC80211, DBG_TRACE, <answer> rtl_dbg(rtlpriv, 
<token> tid); <answer> "IEEE80211_AMPDU_RX_STOP:TID:%d\n", 
return rtl_rx_agg_stop(hw, sta, <token> <answer> tid); 
return <token> <answer> -EOPNOTSUPP; 
<token> 0; <answer> return 
static <token> rtl_op_sw_scan_start(struct ieee80211_hw *hw, <answer> void 
struct <token> *vif, <answer> ieee80211_vif 
const u8 <token> <answer> *mac_addr) 
<token> rtl_priv *rtlpriv = rtl_priv(hw); <answer> struct 
struct <token> *mac = rtl_mac(rtl_priv(hw)); <answer> rtl_mac 
rtl_dbg(rtlpriv, <token> DBG_LOUD, "\n"); <answer> COMP_MAC80211, 
mac->act_scanning = <token> <answer> true; 
<token> (rtlpriv->link_info.higher_busytraffic) { <answer> if 
mac->skip_scan <token> true; <answer> = 
if <token> <answer> (rtlpriv->cfg->ops->get_btc_status()) 
<token> 1); <answer> rtlpriv->btcoexist.btc_ops->btc_scan_notify(rtlpriv, 
<token> if (rtlpriv->btcoexist.btc_ops) <answer> else 
if (mac->link_state == <token> { <answer> MAC80211_LINKED) 
<token> true); <answer> rtl_lps_leave(hw, 
<token> = MAC80211_LINKED_SCANNING; <answer> mac->link_state 
<token> else { <answer> } 
<token> = AESCMAC_ENCRYPTION; <answer> key_type 
rtl_dbg(rtlpriv, <token> DBG_DMESG, "alg:CMAC\n"); <answer> COMP_SEC, 
rtl_dbg(rtlpriv, COMP_SEC, <token> <answer> DBG_DMESG, 
"HW don't support <token> encryption, use software CMAC encryption\n"); <answer> CMAC 
err = <token> <answer> -EOPNOTSUPP; 
<token> out_unlock; <answer> goto 
pr_err("alg_err:%x!!!!:\n", <token> <answer> key->cipher); 
<token> out_unlock; <answer> goto 
if (key_type <token> WEP40_ENCRYPTION || <answer> == 
<token> == WEP104_ENCRYPTION || <answer> key_type 
vif->type <token> NL80211_IFTYPE_ADHOC) <answer> == 
rtlpriv->sec.use_defaultkey = <token> <answer> true; 
<token> (vif->type == NL80211_IFTYPE_AP || <answer> if 
vif->type == <token> { <answer> NL80211_IFTYPE_MESH_POINT) 
if <token> || key_type == WEP40_ENCRYPTION || <answer> (!group_key 
key_type <token> WEP104_ENCRYPTION) { <answer> == 
if <token> <answer> (group_key) 
<token> = true; <answer> wep_only 
<token> else { <answer> } 
if (!group_key || vif->type == NL80211_IFTYPE_ADHOC <token> <answer> || 
rtlpriv->sec.pairwise_enc_algorithm == NO_ENCRYPTION) <token> <answer> { 
if <token> == <answer> (rtlpriv->sec.pairwise_enc_algorithm 
NO_ENCRYPTION <token> <answer> && 
(key_type <token> WEP40_ENCRYPTION || <answer> == 
<token> == WEP104_ENCRYPTION)) <answer> key_type 
wep_only = <token> <answer> true; 
rtlpriv->sec.pairwise_enc_algorithm <token> key_type; <answer> = 
rtl_dbg(rtlpriv, COMP_SEC, <token> <answer> DBG_DMESG, 
<token> enable_hw_sec, key_type:%x(OPEN:0 WEP40:1 TKIP:2 AES:4 WEP104:5)\n", <answer> "set 
static void rtl_op_flush(struct <token> *hw, <answer> ieee80211_hw 
<token> ieee80211_vif *vif, <answer> struct 
u32 <token> <answer> queues, 
<token> drop) <answer> bool 
<token> rtl_priv *rtlpriv = rtl_priv(hw); <answer> struct 
<token> (rtlpriv->intf_ops->flush) <answer> if 
<token> queues, drop); <answer> rtlpriv->intf_ops->flush(hw, 
static int <token> ieee80211_hw *hw, struct ieee80211_sta *sta, <answer> rtl_op_set_tim(struct 
<token> set) <answer> bool 
<token> rtl_priv *rtlpriv = rtl_priv(hw); <answer> struct 
struct rtl_hal <token> = rtl_hal(rtl_priv(hw)); <answer> *rtlhal 
if <token> == HARDWARE_TYPE_RTL8192CU) <answer> (rtlhal->hw_type 
<token> 0; <answer> return 
bool <token> rtl_priv *rtlpriv, u8 cut_version, <answer> rtl_hal_pwrseqcmdparsing(struct 
u8 faversion, <token> interface_type, <answer> u8 
<token> wlan_pwr_cfg pwrcfgcmd[]) <answer> struct 
struct <token> cfg_cmd; <answer> wlan_pwr_cfg 
bool polling_bit = <token> <answer> false; 
u32 ary_idx = <token> <answer> 0; 
u8 value = <token> <answer> 0; 
u32 offset <token> 0; <answer> = 
u32 polling_count = <token> <answer> 0; 
u32 max_polling_cnt = <token> <answer> 5000; 
<token> { <answer> do 
cfg_cmd <token> pwrcfgcmd[ary_idx]; <answer> = 
rtl_dbg(rtlpriv, COMP_INIT, <token> <answer> DBG_TRACE, 
"%s: <token> famsk(%#x), interface_msk(%#x), base(%#x), cmd(%#x), msk(%#x), value(%#x)\n", <answer> offset(%#x),cut_msk(%#x), 
GET_PWR_CFG_BASE(cfg_cmd), <token> <answer> GET_PWR_CFG_CMD(cfg_cmd), 
<token> GET_PWR_CFG_VALUE(cfg_cmd)); <answer> GET_PWR_CFG_MASK(cfg_cmd), 
if ((GET_PWR_CFG_FAB_MASK(cfg_cmd)&faversion) <token> <answer> && 
(GET_PWR_CFG_CUT_MASK(cfg_cmd)&cut_version) <token> <answer> && 
<token> { <answer> (GET_PWR_CFG_INTF_MASK(cfg_cmd)&interface_type)) 
switch (GET_PWR_CFG_CMD(cfg_cmd)) <token> <answer> { 
<token> PWR_CMD_READ: <answer> case 
<token> COMP_INIT, DBG_TRACE, <answer> rtl_dbg(rtlpriv, 
"rtl_hal_pwrseqcmdparsing(): <token> <answer> PWR_CMD_READ\n"); 
case <token> <answer> PWR_CMD_WRITE: 
rtl_dbg(rtlpriv, <token> DBG_TRACE, <answer> COMP_INIT, 
<token> PWR_CMD_WRITE\n", __func__); <answer> "%s(): 
offset = <token> <answer> GET_PWR_CFG_OFFSET(cfg_cmd); 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/in.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/vmalloc.h> 
<token> <linux/ratelimit.h> <answer> #include 
<token> <net/addrconf.h> <answer> #include 
#include <token> <answer> <rdma/ib_cm.h> 
<token> "rds_single_path.h" <answer> #include 
<token> "rds.h" <answer> #include 
<token> "ib.h" <answer> #include 
<token> "ib_mr.h" <answer> #include 
static void rds_ib_set_protocol(struct rds_connection *conn, unsigned <token> version) <answer> int 
<token> = version; <answer> conn->c_version 
static <token> rds_ib_set_flow_control(struct rds_connection *conn, u32 credits) <answer> void 
struct rds_ib_connection *ic = <token> <answer> conn->c_transport_data; 
if (rds_ib_sysctl_flow_control && credits <token> 0) { <answer> != 
void <token> rds_connection *conn, struct rdma_cm_event *event) <answer> rds_ib_cm_connect_complete(struct 
struct rds_ib_connection <token> = conn->c_transport_data; <answer> *ic 
const union rds_ib_conn_priv *dp <token> NULL; <answer> = 
__be64 <token> = 0; <answer> ack_seq 
<token> credit = 0; <answer> __be32 
u8 major = <token> <answer> 0; 
u8 minor = <token> <answer> 0; 
int <token> <answer> err; 
dp = <token> <answer> event->param.conn.private_data; 
if (conn->c_isv6) <token> <answer> { 
if <token> >= <answer> (event->param.conn.private_data_len 
<token> rds6_ib_connect_private)) { <answer> sizeof(struct 
major = <token> <answer> dp->ricp_v6.dp_protocol_major; 
<token> = dp->ricp_v6.dp_protocol_minor; <answer> minor 
credit <token> dp->ricp_v6.dp_credit; <answer> = 
ack_seq = <token> <answer> get_unaligned(&dp->ricp_v6.dp_ack_seq); 
<token> else if (event->param.conn.private_data_len >= <answer> } 
sizeof(struct <token> { <answer> rds_ib_connect_private)) 
major = <token> <answer> dp->ricp_v4.dp_protocol_major; 
<token> = dp->ricp_v4.dp_protocol_minor; <answer> minor 
credit <token> dp->ricp_v4.dp_credit; <answer> = 
ack_seq <token> get_unaligned(&dp->ricp_v4.dp_ack_seq); <answer> = 
rds_ib_recv_refill(conn, 1, <token> <answer> GFP_KERNEL); 
if (dp) <token> <answer> { 
<token> (ack_seq) <answer> if 
rds_send_drop_acked(conn, <token> <answer> be64_to_cpu(ack_seq), 
<token> = conn->c_version; <answer> conn->c_proposed_version 
static void <token> rds_connection *conn, <answer> rds_ib_cm_fill_conn_param(struct 
<token> rdma_conn_param *conn_param, <answer> struct 
union <token> *dp, <answer> rds_ib_conn_priv 
u32 <token> <answer> protocol_version, 
u32 <token> <answer> max_responder_resources, 
<token> max_initiator_depth, <answer> u32 
bool <token> <answer> isv6) 
struct rds_ib_connection *ic = <token> <answer> conn->c_transport_data; 
<token> rds_ib_device *rds_ibdev = ic->rds_ibdev; <answer> struct 
<token> 0, sizeof(struct rdma_conn_param)); <answer> memset(conn_param, 
<token> = <answer> conn_param->responder_resources 
min_t(u32, rds_ibdev->max_responder_resources, <token> <answer> max_responder_resources); 
<token> = <answer> conn_param->initiator_depth 
min_t(u32, <token> max_initiator_depth); <answer> rds_ibdev->max_initiator_depth, 
conn_param->retry_count = min_t(unsigned <token> rds_ib_retry_count, 7); <answer> int, 
conn_param->rnr_retry_count <token> 7; <answer> = 
if (dp) <token> <answer> { 
memset(dp, <token> sizeof(*dp)); <answer> 0, 
if <token> { <answer> (isv6) 
dp->ricp_v6.dp_saddr <token> conn->c_laddr; <answer> = 
dp->ricp_v6.dp_daddr = <token> <answer> conn->c_faddr; 
<token> = <answer> dp->ricp_v6.dp_protocol_major 
<token> = <answer> dp->ricp_v6.dp_protocol_minor 
dp->ricp_v6.dp_protocol_minor_mask <token> <answer> = 
dp->ricp_v6.dp_ack_seq <token> <answer> = 
<token> = conn->c_tos; <answer> dp->ricp_v6.dp_cmn.ricpc_dp_toss 
conn_param->private_data <token> &dp->ricp_v6; <answer> = 
conn_param->private_data_len = <token> <answer> sizeof(dp->ricp_v6); 
} else <token> <answer> { 
dp->ricp_v4.dp_saddr <token> conn->c_laddr.s6_addr32[3]; <answer> = 
<token> = conn->c_faddr.s6_addr32[3]; <answer> dp->ricp_v4.dp_daddr 
<token> = <answer> dp->ricp_v4.dp_protocol_major 
dp->ricp_v4.dp_protocol_minor <token> <answer> = 
dp->ricp_v4.dp_protocol_minor_mask <token> <answer> = 
dp->ricp_v4.dp_ack_seq <token> <answer> = 
dp->ricp_v4.dp_cmn.ricpc_dp_toss = <token> <answer> conn->c_tos; 
conn_param->private_data = <token> <answer> &dp->ricp_v4; 
conn_param->private_data_len <token> sizeof(dp->ricp_v4); <answer> = 
static void rds_ib_cq_comp_handler_recv(struct ib_cq <token> void *context) <answer> *cq, 
struct <token> *conn = context; <answer> rds_connection 
struct rds_ib_connection *ic = <token> <answer> conn->c_transport_data; 
rdsdebug("conn <token> cq %p\n", conn, cq); <answer> %p 
static void poll_scq(struct rds_ib_connection *ic, <token> ib_cq *cq, <answer> struct 
struct ib_wc <token> <answer> *wcs) 
<token> nr, i; <answer> int 
struct <token> *wc; <answer> ib_wc 
while ((nr = ib_poll_cq(cq, <token> wcs)) > 0) { <answer> RDS_IB_WC_MAX, 
for (i = 0; i <token> nr; i++) { <answer> < 
wc <token> wcs + i; <answer> = 
rdsdebug("wc wr_id <token> status %u byte_len %u imm_data %u\n", <answer> 0x%llx 
<token> long long)wc->wr_id, wc->status, <answer> (unsigned 
wc->byte_len, <token> <answer> be32_to_cpu(wc->ex.imm_data)); 
if (wc->wr_id <token> ic->i_send_ring.w_nr || <answer> <= 
wc->wr_id <token> RDS_IB_ACK_WR_ID) <answer> == 
rds_ib_send_cqe_handler(ic, <token> <answer> wc); 
<token> wc); <answer> rds_ib_mr_cqe_handler(ic, 
static void rds_ib_tasklet_fn_send(unsigned <token> data) <answer> long 
struct rds_ib_connection *ic = (struct <token> *)data; <answer> rds_ib_connection 
<token> rds_connection *conn = ic->conn; <answer> struct 
static void rds_dma_hdrs_free(struct rds_ib_device <token> <answer> *dev, 
struct rds_header **hdrs, dma_addr_t <token> u32 num_hdrs, <answer> *dma_addrs, 
enum dma_data_direction <token> <answer> dir) 
u32 <token> <answer> i; 
for <token> = 0; i < num_hdrs; i++) <answer> (i 
rds_dma_hdr_free(dev->dev, hdrs[i], dma_addrs[i], <token> <answer> dir); 
static struct rds_header <token> rds_ib_device *dev, <answer> **rds_dma_hdrs_alloc(struct 
dma_addr_t <token> u32 num_hdrs, <answer> **dma_addrs, 
enum dma_data_direction <token> <answer> dir) 
struct rds_header <token> <answer> **hdrs; 
<token> *hdr_daddrs; <answer> dma_addr_t 
u32 <token> <answer> i; 
hdrs = <token> * num_hdrs, GFP_KERNEL, <answer> kvmalloc_node(sizeof(*hdrs) 
<token> (!hdrs) <answer> if 
return <token> <answer> NULL; 
hdr_daddrs = kvmalloc_node(sizeof(*hdr_daddrs) * <token> GFP_KERNEL, <answer> num_hdrs, 
<token> (!hdr_daddrs) { <answer> if 
return <token> <answer> NULL; 
for <token> = 0; i < num_hdrs; i++) { <answer> (i 
hdrs[i] = rds_dma_hdr_alloc(dev->dev, &hdr_daddrs[i], <token> <answer> dir); 
if <token> { <answer> (!hdrs[i]) 
rds_dma_hdrs_free(dev, hdrs, hdr_daddrs, i, <token> <answer> dir); 
return <token> <answer> NULL; 
*dma_addrs = <token> <answer> hdr_daddrs; 
<token> hdrs; <answer> return 
<token> int rds_ib_setup_qp(struct rds_connection *conn) <answer> static 
struct rds_ib_connection *ic = <token> <answer> conn->c_transport_data; 
<token> ib_device *dev = ic->i_cm_id->device; <answer> struct 
struct <token> attr; <answer> ib_qp_init_attr 
struct ib_cq_init_attr cq_attr = <token> <answer> {}; 
struct <token> *rds_ibdev; <answer> rds_ib_device 
<token> long max_wrs; <answer> unsigned 
int <token> fr_queue_space; <answer> ret, 
rds_ibdev <token> rds_ib_get_client_data(dev); <answer> = 
if <token> <answer> (!rds_ibdev) 
<token> -EOPNOTSUPP; <answer> return 
<token> = RDS_IB_DEFAULT_FR_WR; <answer> fr_queue_space 
<token> = rdma_create_qp(ic->i_cm_id, ic->i_pd, &attr); <answer> ret 
if <token> { <answer> (ret) 
<token> failed: %d\n", ret); <answer> rdsdebug("rdma_create_qp 
goto <token> <answer> recv_cq_out; 
ic->i_send_hdrs <token> rds_dma_hdrs_alloc(rds_ibdev, &ic->i_send_hdrs_dma, <answer> = 
if (!ic->i_send_hdrs) <token> <answer> { 
ret <token> -ENOMEM; <answer> = 
rdsdebug("DMA send hdrs <token> failed\n"); <answer> alloc 
<token> qp_out; <answer> goto 
<token> = rds_dma_hdrs_alloc(rds_ibdev, &ic->i_recv_hdrs_dma, <answer> ic->i_recv_hdrs 
if <token> { <answer> (!ic->i_recv_hdrs) 
<token> = -ENOMEM; <answer> ret 
rdsdebug("DMA recv hdrs alloc <token> <answer> failed\n"); 
goto <token> <answer> send_hdrs_dma_out; 
ic->i_ack = rds_dma_hdr_alloc(rds_ibdev->dev, <token> <answer> &ic->i_ack_dma, 
if <token> { <answer> (!ic->i_ack) 
<token> = -ENOMEM; <answer> ret 
rdsdebug("DMA <token> header alloc failed\n"); <answer> ack 
goto <token> <answer> recv_hdrs_dma_out; 
ic->i_sends = vzalloc_node(array_size(sizeof(struct <token> <answer> rds_ib_send_work), 
<token> (!ic->i_sends) { <answer> if 
ret = <token> <answer> -ENOMEM; 
rdsdebug("send allocation <token> <answer> failed\n"); 
<token> ack_dma_out; <answer> goto 
ic->i_recvs = <token> rds_ib_recv_work), <answer> vzalloc_node(array_size(sizeof(struct 
if (!ic->i_recvs) <token> <answer> { 
ret = <token> <answer> -ENOMEM; 
rdsdebug("recv <token> failed\n"); <answer> allocation 
<token> sends_out; <answer> goto 
rdsdebug("conn %p pd %p cq %p %p\n", <token> ic->i_pd, <answer> conn, 
<token> ic->i_recv_cq); <answer> ic->i_send_cq, 
<token> out; <answer> goto 
<token> ic->i_ack, ic->i_ack_dma, <answer> rds_dma_hdr_free(rds_ibdev->dev, 
ic->i_ack = <token> <answer> NULL; 
rds_dma_hdrs_free(rds_ibdev, <token> ic->i_recv_hdrs_dma, <answer> ic->i_recv_hdrs, 
<token> DMA_FROM_DEVICE); <answer> ic->i_recv_ring.w_nr, 
<token> = NULL; <answer> ic->i_recv_hdrs 
<token> = NULL; <answer> ic->i_recv_hdrs_dma 
rds_dma_hdrs_free(rds_ibdev, ic->i_send_hdrs, <token> <answer> ic->i_send_hdrs_dma, 
<token> DMA_TO_DEVICE); <answer> ic->i_send_ring.w_nr, 
ic->i_send_hdrs = <token> <answer> NULL; 
ic->i_send_hdrs_dma <token> NULL; <answer> = 
ic->i_recv_cq = <token> <answer> NULL; 
<token> = NULL; <answer> ic->i_send_cq 
<token> conn); <answer> rds_ib_remove_conn(rds_ibdev, 
<token> ret; <answer> return 
static u32 rds_ib_protocol_compatible(struct rdma_cm_event *event, <token> isv6) <answer> bool 
const union <token> *dp = event->param.conn.private_data; <answer> rds_ib_conn_priv 
u8 <token> major, minor; <answer> data_len, 
u32 <token> = 0; <answer> version 
<token> mask; <answer> __be16 
u16 <token> <answer> common; 
static u32 <token> net *net, const struct in6_addr *addr) <answer> __rds_find_ifindex(struct 
<token> net_device *dev; <answer> struct 
int <token> = 0; <answer> idx 
for_each_netdev_rcu(net, <token> { <answer> dev) 
if (ipv6_chk_addr(net, addr, <token> 1)) { <answer> dev, 
idx = <token> <answer> dev->ifindex; 
<token> idx; <answer> return 
<token> rds_ib_cm_handle_connect(struct rdma_cm_id *cm_id, <answer> int 
<token> rdma_cm_event *event, bool isv6) <answer> struct 
__be64 lguid = <token> <answer> cm_id->route.path_rec->sgid.global.interface_id; 
__be64 <token> = cm_id->route.path_rec->dgid.global.interface_id; <answer> fguid 
const <token> rds_ib_conn_priv_cmn *dp_cmn; <answer> struct 
struct <token> *conn = NULL; <answer> rds_connection 
struct rds_ib_connection *ic = <token> <answer> NULL; 
<token> rdma_conn_param conn_param; <answer> struct 
const union <token> *dp; <answer> rds_ib_conn_priv 
<token> rds_ib_conn_priv dp_rep; <answer> union 
struct in6_addr <token> <answer> s_mapped_addr; 
<token> in6_addr d_mapped_addr; <answer> struct 
const struct <token> *saddr6; <answer> in6_addr 
const struct <token> *daddr6; <answer> in6_addr 
int <token> = 1; <answer> destroy 
u32 ifindex <token> 0; <answer> = 
u32 <token> <answer> version; 
int <token> = 1; <answer> err 
if (ipv6_addr_type(daddr6) <token> IPV6_ADDR_LINKLOCAL) { <answer> & 
if <token> RDS_CONN_DOWN, RDS_CONN_CONNECTING)) { <answer> (!rds_conn_transition(conn, 
<token> (rds_conn_state(conn) == RDS_CONN_UP) { <answer> if 
<token> connect while connecting\n"); <answer> rdsdebug("incoming 
} <token> <answer> else 
if (rds_conn_state(conn) == RDS_CONN_CONNECTING) <token> <answer> { 
<token> (dp_cmn->ricpc_ack_seq) <answer> if 
<token> be64_to_cpu(dp_cmn->ricpc_ack_seq), <answer> rds_send_drop_acked(conn, 
<token> = cm_id; <answer> ic->i_cm_id 
<token> = conn; <answer> cm_id->context 
<token> = 0; <answer> destroy 
err <token> rds_ib_setup_qp(conn); <answer> = 
if (err) <token> <answer> { 
rds_ib_conn_error(conn, "rds_ib_setup_qp failed (%d)\n", <token> <answer> err); 
goto <token> <answer> out; 
rds_ib_cm_fill_conn_param(conn, &conn_param, &dp_rep, <token> <answer> version, 
event->param.conn.initiator_depth, <token> <answer> isv6); 
<token> IB_RNR_TIMER_000_32); <answer> rdma_set_min_rnr_timer(cm_id, 
<token> RDS_PROTOCOL_4_1); <answer> rds_ib_set_protocol(conn, 
<token> (ret) { <answer> if 
if (ic->i_cm_id == <token> <answer> cm_id) 
ret = <token> <answer> 0; 
ic->i_active_side <token> true; <answer> = 
<token> ret; <answer> return 
<token> rds_ib_conn_path_connect(struct rds_conn_path *cp) <answer> int 
struct rds_connection *conn <token> cp->cp_conn; <answer> = 
struct <token> src, dest; <answer> sockaddr_storage 
rdma_cm_event_handler <token> <answer> handler; 
<token> rds_ib_connection *ic; <answer> struct 
<token> ret; <answer> int 
ic <token> conn->c_transport_data; <answer> = 
void <token> rds_conn_path *cp) <answer> rds_ib_conn_path_shutdown(struct 
struct <token> *conn = cp->cp_conn; <answer> rds_connection 
struct rds_ib_connection <token> = conn->c_transport_data; <answer> *ic 
int err <token> 0; <answer> = 
rdsdebug("cm %p pd %p cq <token> %p qp %p\n", ic->i_cm_id, <answer> %p 
ic->i_pd, ic->i_send_cq, <token> <answer> ic->i_recv_cq, 
ic->i_cm_id <token> ic->i_cm_id->qp : NULL); <answer> ? 
<token> (ic->i_cm_id) { <answer> if 
<token> cm %p\n", ic->i_cm_id); <answer> rdsdebug("disconnecting 
err <token> rdma_disconnect(ic->i_cm_id); <answer> = 
if (err) <token> <answer> { 
rdsdebug("failed to disconnect, <token> %p err %d\n", <answer> cm: 
ic->i_cm_id, <token> <answer> err); 
rds_ib_ring_empty(&ic->i_recv_ring) <token> <answer> && 
(atomic_read(&ic->i_signaled_sends) == <token> && <answer> 0) 
(atomic_read(&ic->i_fastreg_inuse_count) <token> 0) && <answer> == 
(atomic_read(&ic->i_fastreg_wrs) == <token> <answer> RDS_IB_DEFAULT_FR_WR)); 
<token> 1); <answer> atomic_set(&ic->i_cq_quiesce, 
if <token> <answer> (ic->rds_ibdev) 
<token> conn); <answer> rds_ib_remove_conn(ic->rds_ibdev, 
<token> = NULL; <answer> ic->i_cm_id 
<token> = NULL; <answer> ic->i_pd 
ic->i_send_cq = <token> <answer> NULL; 
<token> = NULL; <answer> ic->i_recv_cq 
rds_ib_ring_init(&ic->i_send_ring, <token> <answer> 0); 
rds_ib_ring_init(&ic->i_recv_ring, <token> <answer> 0); 
<token> = conn; <answer> ic->conn 
conn->c_transport_data = <token> <answer> ic; 
<token> flags); <answer> spin_lock_irqsave(&ib_nodev_conns_lock, 
<token> &ib_nodev_conns); <answer> list_add_tail(&ic->ib_node, 
spin_unlock_irqrestore(&ib_nodev_conns_lock, <token> <answer> flags); 
rdsdebug("conn %p <token> ic %p\n", conn, conn->c_transport_data); <answer> conn 
<token> 0; <answer> return 
void rds_ib_conn_free(void <token> <answer> *arg) 
struct rds_ib_connection <token> = arg; <answer> *ic 
spinlock_t <token> <answer> *lock_ptr; 
rdsdebug("ic %p\n", <token> <answer> ic); 
lock_ptr = ic->rds_ibdev ? &ic->rds_ibdev->spinlock : <token> <answer> &ib_nodev_conns_lock; 
__rds_ib_conn_error(struct rds_connection *conn, <token> char *fmt, ...) <answer> const 
<token> ap; <answer> va_list 
<token> fmt); <answer> va_start(ap, 
vprintk(fmt, <token> <answer> ap); 
#include <token> <answer> <linux/xarray.h> 
#include <token> <answer> "uverbs.h" 
#include <token> <answer> "core_priv.h" 
<token> rdma_umap_priv_init(struct rdma_umap_priv *priv, <answer> void 
<token> vm_area_struct *vma, <answer> struct 
struct <token> *entry) <answer> rdma_user_mmap_entry 
<token> ib_uverbs_file *ufile = vma->vm_file->private_data; <answer> struct 
<token> = vma; <answer> priv->vma 
if (entry) <token> <answer> { 
priv->entry = <token> <answer> entry; 
vma->vm_private_data <token> priv; <answer> = 
int rdma_user_mmap_io(struct ib_ucontext *ucontext, struct <token> *vma, <answer> vm_area_struct 
unsigned long <token> unsigned long size, pgprot_t prot, <answer> pfn, 
struct <token> *entry) <answer> rdma_user_mmap_entry 
struct ib_uverbs_file *ufile <token> ucontext->ufile; <answer> = 
struct <token> *priv; <answer> rdma_umap_priv 
if <token> & VM_SHARED)) <answer> (!(vma->vm_flags 
return <token> <answer> -EINVAL; 
if (vma->vm_end - vma->vm_start != <token> <answer> size) 
<token> -EINVAL; <answer> return 
struct rdma_user_mmap_entry <token> <answer> * 
<token> ib_ucontext *ucontext, <answer> rdma_user_mmap_entry_get_pgoff(struct 
unsigned long <token> <answer> pgoff) 
<token> rdma_user_mmap_entry *entry; <answer> struct 
if (pgoff > <token> <answer> U32_MAX) 
<token> NULL; <answer> return 
entry = <token> pgoff); <answer> xa_load(&ucontext->mmap_xa, 
if <token> || entry->start_pgoff != pgoff || entry->driver_removed || <answer> (!entry 
goto <token> <answer> err; 
ibdev_dbg(ucontext->device, "mmap: pgoff[%#lx] npages[%#zx] <token> <answer> returned\n", 
<token> entry->npages); <answer> pgoff, 
return <token> <answer> entry; 
<token> NULL; <answer> return 
struct rdma_user_mmap_entry <token> <answer> * 
<token> ib_ucontext *ucontext, <answer> rdma_user_mmap_entry_get(struct 
<token> vm_area_struct *vma) <answer> struct 
struct <token> *entry; <answer> rdma_user_mmap_entry 
if (!(vma->vm_flags <token> VM_SHARED)) <answer> & 
return <token> <answer> NULL; 
entry <token> rdma_user_mmap_entry_get_pgoff(ucontext, vma->vm_pgoff); <answer> = 
if <token> <answer> (!entry) 
<token> NULL; <answer> return 
if (entry->npages * <token> != vma->vm_end - vma->vm_start) { <answer> PAGE_SIZE 
return <token> <answer> NULL; 
return <token> <answer> entry; 
<token> void rdma_user_mmap_entry_free(struct kref *kref) <answer> static 
struct <token> *entry = <answer> rdma_user_mmap_entry 
<token> struct rdma_user_mmap_entry, ref); <answer> container_of(kref, 
<token> ib_ucontext *ucontext = entry->ucontext; <answer> struct 
unsigned long <token> <answer> i; 
for (i = 0; i < <token> i++) <answer> entry->npages; 
__xa_erase(&ucontext->mmap_xa, entry->start_pgoff <token> i); <answer> + 
ibdev_dbg(ucontext->device, "mmap: pgoff[%#lx] npages[%#zx] <token> <answer> removed\n", 
<token> entry->npages); <answer> entry->start_pgoff, 
<token> (ucontext->device->ops.mmap_free) <answer> if 
void rdma_user_mmap_entry_put(struct <token> *entry) <answer> rdma_user_mmap_entry 
kref_put(&entry->ref, <token> <answer> rdma_user_mmap_entry_free); 
void rdma_user_mmap_entry_remove(struct <token> *entry) <answer> rdma_user_mmap_entry 
if <token> <answer> (!entry) 
entry->driver_removed <token> true; <answer> = 
<token> rdma_user_mmap_entry_free); <answer> kref_put(&entry->ref, 
int rdma_user_mmap_entry_insert_range(struct ib_ucontext <token> <answer> *ucontext, 
struct <token> *entry, <answer> rdma_user_mmap_entry 
size_t length, <token> min_pgoff, <answer> u32 
<token> max_pgoff) <answer> u32 
struct ib_uverbs_file *ufile <token> ucontext->ufile; <answer> = 
XA_STATE(xas, &ucontext->mmap_xa, <token> <answer> min_pgoff); 
u32 <token> xa_last, npages; <answer> xa_first, 
int <token> <answer> err; 
<token> i; <answer> u32 
<token> (!entry) <answer> if 
<token> -EINVAL; <answer> return 
entry->ucontext <token> ucontext; <answer> = 
xas_next_entry(&xas, xa_last - <token> <answer> 1); 
if <token> == XAS_BOUNDS || xas.xa_index >= xa_last) <answer> (xas.xa_node 
for (i = xa_first; <token> < xa_last; i++) { <answer> i 
err = <token> i, entry, GFP_KERNEL); <answer> __xa_insert(&ucontext->mmap_xa, 
if <token> <answer> (err) 
goto <token> <answer> err_undo; 
entry->start_pgoff <token> xa_first; <answer> = 
ibdev_dbg(ucontext->device, "mmap: <token> npages[%#x] inserted\n", <answer> pgoff[%#lx] 
entry->start_pgoff, <token> <answer> npages); 
<token> 0; <answer> return 
for (; i > xa_first; <token> <answer> i--) 
__xa_erase(&ucontext->mmap_xa, i - <token> <answer> 1); 
<token> -ENOMEM; <answer> return 
<token> rdma_user_mmap_entry_insert(struct ib_ucontext *ucontext, <answer> int 
struct <token> *entry, <answer> rdma_user_mmap_entry 
<token> length) <answer> size_t 
return rdma_user_mmap_entry_insert_range(ucontext, entry, length, <token> <answer> 0, 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> "fmdrv.h" 
#include <token> <answer> "fmdrv_common.h" 
<token> "fmdrv_tx.h" <answer> #include 
int fm_tx_set_stereo_mono(struct fmdev *fmdev, u16 <token> <answer> mode) 
u16 <token> <answer> payload; 
int <token> <answer> ret; 
if (fmdev->tx_data.aud_mode == <token> <answer> mode) 
<token> 0; <answer> return 
fmdbg("stereo mode: <token> mode); <answer> %d\n", 
payload = (FM_PWR_LVL_HIGH - <token> <answer> new_pwr_lvl); 
ret = fmc_send_cmd(fmdev, POWER_LEV_SET, <token> &payload, <answer> REG_WR, 
sizeof(payload), <token> NULL); <answer> NULL, 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
<token> fm_tx_set_preemph_filter(struct fmdev *fmdev, u32 preemphasis) <answer> int 
struct fmtx_data <token> = &fmdev->tx_data; <answer> *tx 
<token> payload; <answer> u16 
<token> ret; <answer> int 
if (fmdev->curr_fmmode <token> FM_MODE_TX) <answer> != 
<token> -EPERM; <answer> return 
switch <token> { <answer> (preemphasis) 
<token> V4L2_PREEMPHASIS_DISABLED: <answer> case 
payload <token> FM_TX_PREEMPH_OFF; <answer> = 
<token> V4L2_PREEMPHASIS_50_uS: <answer> case 
payload <token> FM_TX_PREEMPH_50US; <answer> = 
case <token> <answer> V4L2_PREEMPHASIS_75_uS: 
payload = <token> <answer> FM_TX_PREEMPH_75US; 
ret = fmc_send_cmd(fmdev, PREMPH_SET, <token> &payload, <answer> REG_WR, 
sizeof(payload), NULL, <token> <answer> NULL); 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
tx->preemph = <token> <answer> payload; 
return <token> <answer> ret; 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_address.h> <answer> #include 
#include <token> <answer> "common.h" 
static void __iomem <token> char *comp) <answer> *zynq_pm_ioremap(const 
<token> device_node *np; <answer> struct 
void __iomem *base <token> NULL; <answer> = 
<token> = of_find_compatible_node(NULL, NULL, comp); <answer> np 
if (np) <token> <answer> { 
<token> = of_iomap(np, 0); <answer> base 
<token> else { <answer> } 
pr_warn("%s: no compatible node found <token> '%s'\n", __func__, <answer> for 
return <token> <answer> base; 
void __init <token> <answer> zynq_pm_late_init(void) 
<token> reg; <answer> u32 
<token> = zynq_pm_ioremap("xlnx,zynq-ddrc-a05"); <answer> ddrc_base 
<token> (!ddrc_base) { <answer> if 
pr_warn("%s: Unable to map DDRC IO <token> __func__); <answer> memory.\n", 
} <token> { <answer> else 
<token> = readl(ddrc_base + DDRC_DRAM_PARAM_REG3_OFFS); <answer> reg 
<token> |= DDRC_CLOCKSTOP_MASK; <answer> reg 
<token> ddrc_base + DDRC_DRAM_PARAM_REG3_OFFS); <answer> writel(reg, 
#define BITS_PER_U128 (sizeof(u64) * BITS_PER_BYTE * <token> <answer> 2) 
#define BITS_PER_BYTE_MASK <token> - 1) <answer> (BITS_PER_BYTE 
#define BITS_PER_BYTE_MASKED(bits) <token> & BITS_PER_BYTE_MASK) <answer> ((bits) 
#define BITS_ROUNDDOWN_BYTES(bits) <token> >> 3) <answer> ((bits) 
#define <token> \ <answer> BITS_ROUNDUP_BYTES(bits) 
<token> + !!BITS_PER_BYTE_MASKED(bits)) <answer> (BITS_ROUNDDOWN_BYTES(bits) 
#define <token> 0x9f00ffff <answer> BTF_INFO_MASK 
#define <token> 0x0fffffff <answer> BTF_INT_MASK 
#define BTF_TYPE_ID_VALID(type_id) ((type_id) <token> BTF_MAX_TYPE) <answer> <= 
#define BTF_STR_OFFSET_VALID(name_off) ((name_off) <token> BTF_MAX_NAME_OFFSET) <answer> <= 
#define <token> (16 * 1024 * 1024) <answer> BTF_MAX_SIZE 
<token> for_each_member_from(i, from, struct_type, member) \ <answer> #define 
for (i = <token> member = btf_type_member(struct_type) + from; \ <answer> from, 
<token> < btf_type_vlen(struct_type); \ <answer> i 
<token> member++) <answer> i++, 
#define for_each_vsi_from(i, from, struct_type, member) <token> <answer> \ 
<token> (i = from, member = btf_type_var_secinfo(struct_type) + from; \ <answer> for 
i < <token> \ <answer> btf_type_vlen(struct_type); 
i++, <token> <answer> member++) 
enum btf_kfunc_hook <token> <answer> { 
enum <token> <answer> { 
BTF_KFUNC_SET_MAX_CNT = <token> <answer> 256, 
<token> = 256, <answer> BTF_DTOR_KFUNC_MAX_CNT 
<token> = 16, <answer> BTF_KFUNC_FILTER_MAX_CNT 
<token> btf_kfunc_hook_filter { <answer> struct 
<token> filters[BTF_KFUNC_FILTER_MAX_CNT]; <answer> btf_kfunc_filter_t 
u32 <token> <answer> nr_filters; 
struct btf_kfunc_set_tab <token> <answer> { 
struct btf_id_set8 <token> <answer> *sets[BTF_KFUNC_HOOK_MAX]; 
<token> btf_kfunc_hook_filter hook_filters[BTF_KFUNC_HOOK_MAX]; <answer> struct 
struct <token> { <answer> btf_id_dtor_kfunc_tab 
<token> cnt; <answer> u32 
struct <token> dtors[]; <answer> btf_id_dtor_kfunc 
<token> btf_struct_ops_tab { <answer> struct 
u32 <token> <answer> cnt; 
u32 <token> <answer> capacity; 
struct bpf_struct_ops_desc <token> <answer> ops[]; 
<token> btf { <answer> struct 
void <token> <answer> *data; 
struct btf_type <token> <answer> **types; 
u32 <token> <answer> *resolved_ids; 
<token> *resolved_sizes; <answer> u32 
const char <token> <answer> *strings; 
void <token> <answer> *nohdr_data; 
struct btf_header <token> <answer> hdr; 
#define MAX_RESOLVE_DEPTH <token> <answer> 32 
<token> btf_sec_info { <answer> struct 
u32 <token> <answer> off; 
u32 <token> <answer> len; 
struct btf_verifier_env <token> <answer> { 
<token> btf *btf; <answer> struct 
<token> *visit_states; <answer> u8 
<token> resolve_vertex stack[MAX_RESOLVE_DEPTH]; <answer> struct 
struct bpf_verifier_log <token> <answer> log; 
u32 <token> <answer> log_type_id; 
u32 <token> <answer> top_stack; 
<token> verifier_phase phase; <answer> enum 
enum <token> resolve_mode; <answer> resolve_mode 
static const char * const btf_kind_str[NR_BTF_KINDS] = <token> <answer> { 
<token> = "UNKNOWN", <answer> [BTF_KIND_UNKN] 
[BTF_KIND_INT] = <token> <answer> "INT", 
[BTF_KIND_PTR] = <token> <answer> "PTR", 
[BTF_KIND_ARRAY] = <token> <answer> "ARRAY", 
[BTF_KIND_STRUCT] = <token> <answer> "STRUCT", 
[BTF_KIND_UNION] <token> "UNION", <answer> = 
<token> = "ENUM", <answer> [BTF_KIND_ENUM] 
<token> = "FWD", <answer> [BTF_KIND_FWD] 
[BTF_KIND_TYPEDEF] = <token> <answer> "TYPEDEF", 
[BTF_KIND_VOLATILE] = <token> <answer> "VOLATILE", 
[BTF_KIND_CONST] <token> "CONST", <answer> = 
<token> = "RESTRICT", <answer> [BTF_KIND_RESTRICT] 
<token> = "FUNC", <answer> [BTF_KIND_FUNC] 
[BTF_KIND_FUNC_PROTO] <token> "FUNC_PROTO", <answer> = 
<token> = "VAR", <answer> [BTF_KIND_VAR] 
[BTF_KIND_DATASEC] <token> "DATASEC", <answer> = 
[BTF_KIND_FLOAT] <token> "FLOAT", <answer> = 
<token> = "DECL_TAG", <answer> [BTF_KIND_DECL_TAG] 
[BTF_KIND_TYPE_TAG] = <token> <answer> "TYPE_TAG", 
[BTF_KIND_ENUM64] <token> "ENUM64", <answer> = 
const char *btf_type_str(const struct btf_type <token> <answer> *t) 
<token> btf_kind_str[BTF_INFO_KIND(t->info)]; <answer> return 
<token> BTF_SHOW_OBJ_BASE_TYPE_SIZE 16 <answer> #define 
#define NOCAST_ALIAS_SUFFIX <token> <answer> "___init" 
<token> btf_show { <answer> struct 
u64 <token> <answer> flags; 
switch <token> { <answer> (BTF_INFO_KIND(t->info)) 
<token> BTF_KIND_TYPEDEF: <answer> case 
case <token> <answer> BTF_KIND_VOLATILE: 
<token> BTF_KIND_CONST: <answer> case 
<token> BTF_KIND_RESTRICT: <answer> case 
case <token> <answer> BTF_KIND_TYPE_TAG: 
return <token> <answer> true; 
<token> false; <answer> return 
bool <token> struct btf_type *t) <answer> btf_type_is_void(const 
return t == <token> <answer> &btf_void; 
static bool btf_type_is_fwd(const <token> btf_type *t) <answer> struct 
return BTF_INFO_KIND(t->info) <token> BTF_KIND_FWD; <answer> == 
static bool btf_type_is_datasec(const struct btf_type <token> <answer> *t) 
return <token> == BTF_KIND_DATASEC; <answer> BTF_INFO_KIND(t->info) 
static bool btf_type_is_decl_tag(const <token> btf_type *t) <answer> struct 
return BTF_INFO_KIND(t->info) <token> BTF_KIND_DECL_TAG; <answer> == 
static <token> btf_type_nosize(const struct btf_type *t) <answer> bool 
return btf_type_is_void(t) || btf_type_is_fwd(t) <token> <answer> || 
<token> || btf_type_is_func_proto(t) || <answer> btf_type_is_func(t) 
static <token> btf_type_nosize_or_null(const struct btf_type *t) <answer> bool 
return !t || <token> <answer> btf_type_nosize(t); 
static bool btf_type_is_decl_tag_target(const <token> btf_type *t) <answer> struct 
return <token> || btf_type_is_struct(t) || <answer> btf_type_is_func(t) 
btf_type_is_var(t) || <token> <answer> btf_type_is_typedef(t); 
u32 btf_nr_types(const struct <token> *btf) <answer> btf 
u32 <token> = 0; <answer> total 
while (btf) <token> <answer> { 
total += <token> <answer> btf->nr_types; 
btf <token> btf->base_btf; <answer> = 
return <token> <answer> total; 
s32 btf_find_by_name_kind(const struct btf *btf, const char *name, <token> kind) <answer> u8 
<token> struct btf_type *t; <answer> const 
const <token> *tname; <answer> char 
u32 <token> total; <answer> i, 
<token> = btf_nr_types(btf); <answer> total 
for (i = 1; <token> < total; i++) { <answer> i 
t = <token> i); <answer> btf_type_by_id(btf, 
<token> (BTF_INFO_KIND(t->info) != kind) <answer> if 
<token> = btf_name_by_offset(btf, t->name_off); <answer> tname 
if (!strcmp(tname, <token> <answer> name)) 
<token> i; <answer> return 
<token> -ENOENT; <answer> return 
s32 bpf_find_btf_id(const char *name, u32 kind, <token> btf **btf_p) <answer> struct 
struct btf <token> <answer> *btf; 
s32 <token> <answer> ret; 
int <token> <answer> id; 
btf = <token> <answer> bpf_get_btf_vmlinux(); 
<token> (IS_ERR(btf)) <answer> if 
<token> PTR_ERR(btf); <answer> return 
if <token> <answer> (!btf) 
return <token> <answer> -EINVAL; 
<token> = btf_find_by_name_kind(btf, name, kind); <answer> ret 
if <token> > 0) { <answer> (ret 
<token> = btf; <answer> *btf_p 
return <token> <answer> ret; 
ret = btf_find_by_name_kind(btf, <token> kind); <answer> name, 
if (ret > 0) <token> <answer> { 
*btf_p = <token> <answer> btf; 
<token> ret; <answer> return 
<token> ret; <answer> return 
const struct btf_type *btf_type_skip_modifiers(const <token> btf *btf, <answer> struct 
u32 id, u32 <token> <answer> *res_id) 
<token> struct btf_type *t = btf_type_by_id(btf, id); <answer> const 
while <token> { <answer> (btf_type_is_modifier(t)) 
id = <token> <answer> t->type; 
t <token> btf_type_by_id(btf, t->type); <answer> = 
if <token> <answer> (res_id) 
<token> = id; <answer> *res_id 
<token> t; <answer> return 
const struct btf_type *btf_type_resolve_ptr(const <token> btf *btf, <answer> struct 
u32 id, <token> *res_id) <answer> u32 
const struct btf_type <token> <answer> *t; 
t = btf_type_skip_modifiers(btf, id, <token> <answer> NULL); 
<token> (!btf_type_is_ptr(t)) <answer> if 
return <token> <answer> NULL; 
return <token> t->type, res_id); <answer> btf_type_skip_modifiers(btf, 
const <token> btf_type *btf_type_resolve_func_ptr(const struct btf *btf, <answer> struct 
<token> id, u32 *res_id) <answer> u32 
const struct btf_type <token> <answer> *ptype; 
<token> = btf_type_resolve_ptr(btf, id, res_id); <answer> ptype 
if (ptype && <token> <answer> btf_type_is_func_proto(ptype)) 
return <token> <answer> ptype; 
<token> NULL; <answer> return 
static bool btf_type_is_resolve_source_only(const <token> btf_type *t) <answer> struct 
<token> btf_type_is_var(t) || <answer> return 
btf_type_is_decl_tag(t) <token> <answer> || 
static bool btf_type_needs_resolve(const struct <token> *t) <answer> btf_type 
<token> btf_type_is_modifier(t) || <answer> return 
<token> || <answer> btf_type_is_ptr(t) 
<token> || <answer> btf_type_is_struct(t) 
<token> || <answer> btf_type_is_array(t) 
btf_type_is_var(t) <token> <answer> || 
btf_type_is_func(t) <token> <answer> || 
<token> || <answer> btf_type_is_decl_tag(t) 
<token> bool btf_type_int_is_regular(const struct btf_type *t) <answer> static 
<token> nr_bits, nr_bytes; <answer> u8 
u32 <token> <answer> int_data; 
int_data <token> btf_type_int(t); <answer> = 
nr_bits = <token> <answer> BTF_INT_BITS(int_data); 
<token> = BITS_ROUNDUP_BYTES(nr_bits); <answer> nr_bytes 
if (BITS_PER_BYTE_MASKED(nr_bits) <token> <answer> || 
BTF_INT_OFFSET(int_data) <token> <answer> || 
(nr_bytes != sizeof(u8) && nr_bytes != sizeof(u16) <token> <answer> && 
nr_bytes != sizeof(u32) && nr_bytes != <token> && <answer> sizeof(u64) 
nr_bytes <token> (2 * sizeof(u64)))) { <answer> != 
return <token> <answer> false; 
<token> true; <answer> return 
<token> btf_member_is_reg_int(const struct btf *btf, const struct btf_type *s, <answer> bool 
<token> struct btf_member *m, <answer> const 
u32 expected_offset, u32 <token> <answer> expected_size) 
<token> struct btf_type *t; <answer> const 
u32 id, <token> <answer> int_data; 
u8 <token> <answer> nr_bits; 
<token> = m->type; <answer> id 
<token> = btf_type_id_size(btf, &id, NULL); <answer> t 
if (!t || <token> <answer> !btf_type_is_int(t)) 
<token> false; <answer> return 
int_data <token> btf_type_int(t); <answer> = 
nr_bits = <token> <answer> BTF_INT_BITS(int_data); 
if <token> { <answer> (btf_type_kflag(s)) 
<token> bitfield_size = BTF_MEMBER_BITFIELD_SIZE(m->offset); <answer> u32 
u32 bit_offset = <token> <answer> BTF_MEMBER_BIT_OFFSET(m->offset); 
return !bitfield_size <token> <answer> && 
BITS_ROUNDUP_BYTES(bit_offset) == <token> && <answer> expected_offset 
BITS_ROUNDUP_BYTES(nr_bits) <token> expected_size; <answer> == 
if (BTF_INT_OFFSET(int_data) <token> <answer> || 
<token> || <answer> BITS_PER_BYTE_MASKED(m->offset) 
<token> != expected_offset || <answer> BITS_ROUNDUP_BYTES(m->offset) 
BITS_PER_BYTE_MASKED(nr_bits) <token> <answer> || 
BITS_ROUNDUP_BYTES(nr_bits) != <token> <answer> expected_size) 
<token> false; <answer> return 
<token> true; <answer> return 
<token> const char *btf_show_name(struct btf_show *show) <answer> static 
if <token> <answer> (show->state.array_member) 
return <token> <answer> ""; 
t <token> btf_type_by_id(show->btf, id); <answer> = 
if <token> <answer> (!t) 
<token> ""; <answer> return 
for (i <token> 0; i < BTF_SHOW_MAX_ITER; i++) { <answer> = 
<token> (BTF_INFO_KIND(t->info)) { <answer> switch 
case <token> <answer> BTF_KIND_TYPEDEF: 
if <token> <answer> (!name) 
name = <token> <answer> btf_name_by_offset(show->btf, 
kinds |= <token> <answer> BTF_KIND_BIT(BTF_KIND_TYPEDEF); 
id <token> t->type; <answer> = 
<token> BTF_KIND_ARRAY: <answer> case 
kinds |= <token> <answer> BTF_KIND_BIT(BTF_KIND_ARRAY); 
<token> = "["; <answer> parens 
if <token> <answer> (!t) 
return <token> <answer> ""; 
array = <token> <answer> btf_type_array(t); 
if <token> > array_suffixes) <answer> (array_suffix 
array_suffix <token> 2; <answer> -= 
id <token> array->type; <answer> = 
case <token> <answer> BTF_KIND_PTR: 
kinds |= <token> <answer> BTF_KIND_BIT(BTF_KIND_PTR); 
if (ptr_suffix > <token> <answer> ptr_suffixes) 
ptr_suffix <token> 1; <answer> -= 
id = <token> <answer> t->type; 
id = <token> <answer> 0; 
<token> (!id) <answer> if 
t = <token> id); <answer> btf_type_skip_qualifiers(show->btf, 
#define btf_show_type_value(show, fmt, value) <token> <answer> \ 
do { <token> <answer> \ 
if ((value) != <token> || \ <answer> (__typeof__(value))0 
<token> & BTF_SHOW_ZERO) || \ <answer> (show->flags 
show->state.depth == 0) { <token> <answer> \ 
btf_show(show, "%s%s" fmt "%s%s", <token> <answer> \ 
btf_show_indent(show), <token> <answer> \ 
<token> \ <answer> btf_show_name(show), 
value, btf_show_delim(show), <token> <answer> \ 
btf_show_newline(show)); <token> <answer> \ 
if (show->state.depth > show->state.depth_to_show) <token> <answer> \ 
show->state.depth_to_show = <token> \ <answer> show->state.depth; 
<token> \ <answer> } 
} while <token> <answer> (0) 
#define btf_show_type_values(show, fmt, <token> \ <answer> ...) 
<token> { \ <answer> do 
btf_show(show, "%s%s" fmt "%s%s", btf_show_indent(show), <token> <answer> \ 
btf_show_name(show), <token> <answer> \ 
__VA_ARGS__, <token> \ <answer> btf_show_delim(show), 
<token> \ <answer> btf_show_newline(show)); 
if (show->state.depth <token> show->state.depth_to_show) \ <answer> > 
show->state.depth_to_show = <token> \ <answer> show->state.depth; 
} <token> (0) <answer> while 
static void *__btf_show_obj_safe(struct btf_show <token> void *data, int size) <answer> *show, 
<token> (btf_show_obj_is_safe(show, data, size)) <answer> if 
return show->obj.safe + (data - <token> <answer> show->obj.data); 
<token> NULL; <answer> return 
<token> void *btf_show_obj_safe(struct btf_show *show, <answer> static 
const struct <token> *t, <answer> btf_type 
void <token> <answer> *data) 
<token> struct btf_type *rt; <answer> const 
int size_left, <token> <answer> size; 
void <token> = NULL; <answer> *safe 
<token> (show->flags & BTF_SHOW_UNSAFE) <answer> if 
<token> data; <answer> return 
<token> = btf_resolve_size(show->btf, t, &size); <answer> rt 
<token> (IS_ERR(rt)) { <answer> if 
show->state.status <token> PTR_ERR(rt); <answer> = 
return <token> <answer> NULL; 
if (show->state.depth <token> 0) { <answer> == 
show->obj.size <token> size; <answer> = 
<token> = data; <answer> show->obj.head 
} <token> { <answer> else 
safe = <token> data, <answer> __btf_show_obj_safe(show, 
if <token> { <answer> (!safe) 
size_left = btf_show_obj_size_left(show, <token> <answer> data); 
if <token> > BTF_SHOW_OBJ_SAFE_SIZE) <answer> (size_left 
<token> = BTF_SHOW_OBJ_SAFE_SIZE; <answer> size_left 
show->state.status = <token> <answer> copy_from_kernel_nofault(show->obj.safe, 
data, <token> <answer> size_left); 
if <token> { <answer> (!show->state.status) 
show->obj.data <token> data; <answer> = 
<token> = show->obj.safe; <answer> safe 
<token> safe; <answer> return 
<token> void *btf_show_start_type(struct btf_show *show, <answer> static 
const struct <token> *t, <answer> btf_type 
u32 type_id, void <token> <answer> *data) 
show->state.type <token> t; <answer> = 
<token> = type_id; <answer> show->state.type_id 
show->state.name[0] <token> '\0'; <answer> = 
<token> btf_show_obj_safe(show, t, data); <answer> return 
static void btf_show_end_type(struct btf_show <token> <answer> *show) 
<token> = NULL; <answer> show->state.type 
show->state.type_id <token> 0; <answer> = 
show->state.name[0] <token> '\0'; <answer> = 
<token> void *btf_show_start_aggr_type(struct btf_show *show, <answer> static 
const struct <token> *t, <answer> btf_type 
u32 type_id, void <token> <answer> *data) 
void <token> = btf_show_start_type(show, t, type_id, data); <answer> *safe_data 
<token> (!safe_data) <answer> if 
<token> safe_data; <answer> return 
<token> "%s%s%s", btf_show_indent(show), <answer> btf_show(show, 
return <token> <answer> safe_data; 
<token> void btf_show_end_aggr_type(struct btf_show *show, <answer> static 
const char <token> <answer> *suffix) 
<token> "%s%s%s%s", btf_show_indent(show), suffix, <answer> btf_show(show, 
btf_show_delim(show), <token> <answer> btf_show_newline(show)); 
static void btf_show_start_member(struct btf_show <token> <answer> *show, 
const struct <token> *m) <answer> btf_member 
show->state.member <token> m; <answer> = 
static <token> btf_show_start_array_member(struct btf_show *show) <answer> void 
show->state.array_member = <token> <answer> 1; 
btf_show_start_member(show, <token> <answer> NULL); 
<token> void btf_show_end_member(struct btf_show *show) <answer> static 
<token> = NULL; <answer> show->state.member 
static void btf_show_end_array_member(struct <token> *show) <answer> btf_show 
<token> = 0; <answer> show->state.array_member 
static void *btf_show_start_array_type(struct <token> *show, <answer> btf_show 
const struct <token> *t, <answer> btf_type 
<token> type_id, <answer> u32 
u16 <token> <answer> array_encoding, 
<token> *data) <answer> void 
show->state.array_encoding <token> array_encoding; <answer> = 
<token> = 0; <answer> show->state.array_terminated 
return btf_show_start_aggr_type(show, t, <token> data); <answer> type_id, 
static void btf_show_end_array_type(struct btf_show <token> <answer> *show) 
show->state.array_encoding <token> 0; <answer> = 
show->state.array_terminated <token> 0; <answer> = 
<token> "]"); <answer> btf_show_end_aggr_type(show, 
<token> void *btf_show_start_struct_type(struct btf_show *show, <answer> static 
<token> struct btf_type *t, <answer> const 
<token> type_id, <answer> u32 
<token> *data) <answer> void 
<token> btf_show_start_aggr_type(show, t, type_id, data); <answer> return 
static void <token> btf_show *show) <answer> btf_show_end_struct_type(struct 
<token> "}"); <answer> btf_show_end_aggr_type(show, 
__printf(2, 3) static void __btf_verifier_log(struct <token> *log, <answer> bpf_verifier_log 
const char <token> ...) <answer> *fmt, 
<token> args; <answer> va_list 
va_start(args, <token> <answer> fmt); 
<token> fmt, args); <answer> bpf_verifier_vlog(log, 
__printf(2, 3) <token> void btf_verifier_log(struct btf_verifier_env *env, <answer> static 
const char <token> ...) <answer> *fmt, 
<token> bpf_verifier_log *log = &env->log; <answer> struct 
va_list <token> <answer> args; 
if <token> <answer> (!bpf_verifier_log_needed(log)) 
va_start(args, <token> <answer> fmt); 
bpf_verifier_vlog(log, <token> args); <answer> fmt, 
<token> 5) static void __btf_verifier_log_type(struct btf_verifier_env *env, <answer> __printf(4, 
<token> struct btf_type *t, <answer> const 
<token> log_details, <answer> bool 
<token> char *fmt, ...) <answer> const 
struct bpf_verifier_log *log <token> &env->log; <answer> = 
struct btf <token> = env->btf; <answer> *btf 
va_list <token> <answer> args; 
<token> (!bpf_verifier_log_needed(log)) <answer> if 
if (log->level <token> BPF_LOG_KERNEL) { <answer> == 
<token> (!fmt) <answer> if 
if (env->phase <token> CHECK_META) <answer> != 
btf_verifier_log_type(env, <token> NULL); <answer> struct_type, 
if <token> <answer> (btf_type_kflag(struct_type)) 
"\t%s type_id=%u <token> bits_offset=%u", <answer> bitfield_size=%u 
__btf_name_by_offset(btf, <token> <answer> member->name_off), 
__btf_verifier_log(log, "\t%s type_id=%u <token> <answer> bits_offset=%u", 
<token> member->name_off), <answer> __btf_name_by_offset(btf, 
<token> member->offset); <answer> member->type, 
if (fmt && *fmt) <token> <answer> { 
<token> " "); <answer> __btf_verifier_log(log, 
va_start(args, <token> <answer> fmt); 
bpf_verifier_vlog(log, <token> args); <answer> fmt, 
<token> "\n"); <answer> __btf_verifier_log(log, 
<token> 5) <answer> __printf(4, 
static void <token> btf_verifier_env *env, <answer> btf_verifier_log_vsi(struct 
const <token> btf_type *datasec_type, <answer> struct 
const struct btf_var_secinfo <token> <answer> *vsi, 
const char <token> ...) <answer> *fmt, 
struct bpf_verifier_log *log <token> &env->log; <answer> = 
<token> args; <answer> va_list 
if <token> <answer> (!bpf_verifier_log_needed(log)) 
if (log->level == BPF_LOG_KERNEL <token> !fmt) <answer> && 
if (env->phase <token> CHECK_META) <answer> != 
btf_verifier_log_type(env, datasec_type, <token> <answer> NULL); 
__btf_verifier_log(log, "\t <token> offset=%u size=%u", <answer> type_id=%u 
vsi->type, <token> vsi->size); <answer> vsi->offset, 
if (fmt <token> *fmt) { <answer> && 
<token> " "); <answer> __btf_verifier_log(log, 
<token> fmt); <answer> va_start(args, 
bpf_verifier_vlog(log, <token> args); <answer> fmt, 
<token> "\n"); <answer> __btf_verifier_log(log, 
static <token> btf_verifier_log_hdr(struct btf_verifier_env *env, <answer> void 
<token> btf_data_size) <answer> u32 
<token> bpf_verifier_log *log = &env->log; <answer> struct 
const struct <token> *btf = env->btf; <answer> btf 
const struct <token> *hdr; <answer> btf_header 
if <token> <answer> (!bpf_verifier_log_needed(log)) 
if (log->level <token> BPF_LOG_KERNEL) <answer> == 
<token> = &btf->hdr; <answer> hdr 
__btf_verifier_log(log, <token> 0x%x\n", hdr->magic); <answer> "magic: 
__btf_verifier_log(log, <token> %u\n", hdr->version); <answer> "version: 
__btf_verifier_log(log, "flags: 0x%x\n", <token> <answer> hdr->flags); 
__btf_verifier_log(log, "hdr_len: %u\n", <token> <answer> hdr->hdr_len); 
__btf_verifier_log(log, "type_off: %u\n", <token> <answer> hdr->type_off); 
__btf_verifier_log(log, "type_len: %u\n", <token> <answer> hdr->type_len); 
<token> "str_off: %u\n", hdr->str_off); <answer> __btf_verifier_log(log, 
<token> "str_len: %u\n", hdr->str_len); <answer> __btf_verifier_log(log, 
__btf_verifier_log(log, "btf_total_size: %u\n", <token> <answer> btf_data_size); 
static int btf_add_type(struct btf_verifier_env *env, struct btf_type <token> <answer> *t) 
struct btf <token> = env->btf; <answer> *btf 
if (btf->types_size <token> btf->nr_types) { <answer> == 
spin_lock_irqsave(&btf_idr_lock, <token> <answer> flags); 
<token> btf->id); <answer> idr_remove(&btf_idr, 
<token> flags); <answer> spin_unlock_irqrestore(&btf_idr_lock, 
static void btf_free_kfunc_set_tab(struct <token> *btf) <answer> btf 
struct <token> *tab = btf->kfunc_set_tab; <answer> btf_kfunc_set_tab 
int <token> <answer> hook; 
if <token> <answer> (!tab) 
<token> (btf_is_module(btf)) <answer> if 
goto <token> <answer> free_tab; 
<token> (hook = 0; hook < ARRAY_SIZE(tab->sets); hook++) <answer> for 
btf->kfunc_set_tab <token> NULL; <answer> = 
<token> void btf_free_dtor_kfunc_tab(struct btf *btf) <answer> static 
<token> btf_id_dtor_kfunc_tab *tab = btf->dtor_kfunc_tab; <answer> struct 
if <token> <answer> (!tab) 
btf->dtor_kfunc_tab <token> NULL; <answer> = 
static <token> btf_struct_metas_free(struct btf_struct_metas *tab) <answer> void 
int <token> <answer> i; 
<token> (!tab) <answer> if 
for (i = 0; i < tab->cnt; <token> <answer> i++) 
static void <token> btf *btf) <answer> btf_free_struct_meta_tab(struct 
struct <token> *tab = btf->struct_meta_tab; <answer> btf_struct_metas 
btf->struct_meta_tab = <token> <answer> NULL; 
<token> void btf_free_struct_ops_tab(struct btf *btf) <answer> static 
struct btf_struct_ops_tab *tab <token> btf->struct_ops_tab; <answer> = 
<token> i; <answer> u32 
if <token> <answer> (!tab) 
for (i = 0; i < <token> i++) <answer> tab->cnt; 
btf->struct_ops_tab = <token> <answer> NULL; 
static <token> btf_free(struct btf *btf) <answer> void 
static void btf_free_rcu(struct rcu_head <token> <answer> *rcu) 
struct btf <token> = container_of(rcu, struct btf, rcu); <answer> *btf 
const <token> *btf_get_name(const struct btf *btf) <answer> char 
return <token> <answer> btf->name; 
void <token> btf *btf) <answer> btf_get(struct 
<token> btf_put(struct btf *btf) <answer> void 
if <token> && refcount_dec_and_test(&btf->refcnt)) { <answer> (btf 
<token> btf_free_rcu); <answer> call_rcu(&btf->rcu, 
static int env_resolve_init(struct btf_verifier_env <token> <answer> *env) 
<token> btf *btf = env->btf; <answer> struct 
u32 <token> = btf->nr_types; <answer> nr_types 
<token> *resolved_sizes = NULL; <answer> u32 
u32 *resolved_ids <token> NULL; <answer> = 
u8 <token> = NULL; <answer> *visit_states 
resolved_sizes = <token> sizeof(*resolved_sizes), <answer> kvcalloc(nr_types, 
GFP_KERNEL | <token> <answer> __GFP_NOWARN); 
if <token> <answer> (!resolved_sizes) 
<token> nomem; <answer> goto 
resolved_ids = kvcalloc(nr_types, <token> <answer> sizeof(*resolved_ids), 
GFP_KERNEL | <token> <answer> __GFP_NOWARN); 
<token> (!resolved_ids) <answer> if 
<token> nomem; <answer> goto 
visit_states = kvcalloc(nr_types, <token> <answer> sizeof(*visit_states), 
GFP_KERNEL | <token> <answer> __GFP_NOWARN); 
if <token> <answer> (!visit_states) 
<token> nomem; <answer> goto 
btf->resolved_sizes <token> resolved_sizes; <answer> = 
<token> = resolved_ids; <answer> btf->resolved_ids 
env->visit_states = <token> <answer> visit_states; 
return <token> <answer> 0; 
<token> -ENOMEM; <answer> return 
static void btf_verifier_env_free(struct btf_verifier_env <token> <answer> *env) 
<token> bool env_type_is_resolve_sink(const struct btf_verifier_env *env, <answer> static 
const struct <token> *next_type) <answer> btf_type 
switch <token> { <answer> (env->resolve_mode) 
case <token> <answer> RESOLVE_TBD: 
return <token> && <answer> !btf_type_is_modifier(next_type) 
<token> RESOLVE_STRUCT_OR_ARRAY: <answer> case 
<token> !btf_type_is_modifier(next_type) && <answer> return 
!btf_type_is_array(next_type) <token> <answer> && 
static <token> env_type_is_resolved(const struct btf_verifier_env *env, <answer> bool 
<token> type_id) <answer> u32 
static <token> struct btf_type * <answer> const 
__btf_resolve_size(const <token> btf *btf, const struct btf_type *type, <answer> struct 
<token> *type_size, const struct btf_type **elem_type, <answer> u32 
u32 <token> u32 *total_nelems, u32 *type_id) <answer> *elem_id, 
const struct btf_type *array_type <token> NULL; <answer> = 
const struct btf_array <token> = NULL; <answer> *array 
u32 i, <token> nelems = 1, id = 0; <answer> size, 
for (i <token> 0; i < MAX_RESOLVE_DEPTH; i++) { <answer> = 
<token> (BTF_INFO_KIND(type->info)) { <answer> switch 
static int <token> btf_verifier_env *env, <answer> btf_generic_check_kflag_member(struct 
<token> struct btf_type *struct_type, <answer> const 
const struct btf_member <token> <answer> *member, 
<token> struct btf_type *member_type) <answer> const 
if <token> { <answer> (BTF_MEMBER_BITFIELD_SIZE(member->offset)) 
<token> struct_type, member, <answer> btf_verifier_log_member(env, 
"Invalid <token> bitfield_size"); <answer> member 
<token> -EINVAL; <answer> return 
return btf_type_ops(member_type)->check_member(env, <token> <answer> struct_type, 
static int btf_df_resolve(struct <token> *env, <answer> btf_verifier_env 
const struct <token> *v) <answer> resolve_vertex 
btf_verifier_log_basic(env, v->t, "Unsupported <token> <answer> resolve"); 
<token> -EINVAL; <answer> return 
static void btf_df_show(const struct btf *btf, const struct <token> *t, <answer> btf_type 
u32 type_id, <token> *data, u8 bits_offsets, <answer> void 
<token> btf_show *show) <answer> struct 
btf_show(show, "<unsupported <token> BTF_INFO_KIND(t->info)); <answer> kind:%u>", 
static int btf_int_check_member(struct btf_verifier_env <token> <answer> *env, 
const <token> btf_type *struct_type, <answer> struct 
<token> struct btf_member *member, <answer> const 
const <token> btf_type *member_type) <answer> struct 
<token> int_data = btf_type_int(member_type); <answer> u32 
u32 struct_bits_off = <token> <answer> member->offset; 
u32 struct_size <token> struct_type->size; <answer> = 
<token> nr_copy_bits; <answer> u32 
<token> bytes_offset; <answer> u32 
if (U32_MAX - <token> < BTF_INT_OFFSET(int_data)) { <answer> struct_bits_off 
btf_verifier_log_member(env, struct_type, <token> <answer> member, 
"bits_offset exceeds <token> <answer> U32_MAX"); 
<token> -EINVAL; <answer> return 
struct_bits_off += <token> <answer> BTF_INT_OFFSET(int_data); 
bytes_offset = <token> <answer> BITS_ROUNDDOWN_BYTES(struct_bits_off); 
nr_copy_bits <token> BTF_INT_BITS(int_data) + <answer> = 
<token> (nr_copy_bits > BITS_PER_U128) { <answer> if 
btf_verifier_log_member(env, struct_type, <token> <answer> member, 
"nr_copy_bits <token> 128"); <answer> exceeds 
return <token> <answer> -EINVAL; 
<token> (struct_size < bytes_offset || <answer> if 
<token> - bytes_offset < BITS_ROUNDUP_BYTES(nr_copy_bits)) { <answer> struct_size 
btf_verifier_log_member(env, struct_type, <token> <answer> member, 
"Member exceeds <token> <answer> struct_size"); 
return <token> <answer> -EINVAL; 
<token> 0; <answer> return 
<token> int btf_int_check_kflag_member(struct btf_verifier_env *env, <answer> static 
const <token> btf_type *struct_type, <answer> struct 
const struct btf_member <token> <answer> *member, 
const struct btf_type <token> <answer> *member_type) 
u32 struct_bits_off, <token> nr_int_data_bits, bytes_offset; <answer> nr_bits, 
u32 <token> = btf_type_int(member_type); <answer> int_data 
u32 struct_size <token> struct_type->size; <answer> = 
<token> nr_copy_bits; <answer> u32 
if (BITS_PER_BYTE_MASKED(struct_bits_off)) <token> <answer> { 
<token> struct_type, member, <answer> btf_verifier_log_member(env, 
"Invalid member <token> <answer> offset"); 
return <token> <answer> -EINVAL; 
<token> = nr_int_data_bits; <answer> nr_bits 
} else if (nr_bits > nr_int_data_bits) <token> <answer> { 
btf_verifier_log_member(env, struct_type, <token> <answer> member, 
"Invalid member <token> <answer> bitfield_size"); 
return <token> <answer> -EINVAL; 
<token> = BITS_ROUNDDOWN_BYTES(struct_bits_off); <answer> bytes_offset 
nr_copy_bits <token> nr_bits + BITS_PER_BYTE_MASKED(struct_bits_off); <answer> = 
<token> (nr_copy_bits > BITS_PER_U128) { <answer> if 
btf_verifier_log_member(env, struct_type, <token> <answer> member, 
<token> exceeds 128"); <answer> "nr_copy_bits 
<token> -EINVAL; <answer> return 
if (struct_size < <token> || <answer> bytes_offset 
struct_size - bytes_offset < <token> { <answer> BITS_ROUNDUP_BYTES(nr_copy_bits)) 
<token> struct_type, member, <answer> btf_verifier_log_member(env, 
"Member exceeds <token> <answer> struct_size"); 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
static s32 <token> btf_verifier_env *env, <answer> btf_int_check_meta(struct 
const <token> btf_type *t, <answer> struct 
<token> meta_left) <answer> u32 
u32 <token> nr_bits, meta_needed = sizeof(int_data); <answer> int_data, 
u16 <token> <answer> encoding; 
if (meta_left < <token> { <answer> meta_needed) 
<token> t, <answer> btf_verifier_log_basic(env, 
<token> meta_needed:%u", <answer> "meta_left:%u 
<token> meta_needed); <answer> meta_left, 
<token> -EINVAL; <answer> return 
<token> (btf_type_vlen(t)) { <answer> if 
btf_verifier_log_type(env, <token> "vlen != 0"); <answer> t, 
<token> -EINVAL; <answer> return 
<token> (btf_type_kflag(t)) { <answer> if 
btf_verifier_log_type(env, t, "Invalid btf_info <token> <answer> kind_flag"); 
<token> -EINVAL; <answer> return 
<token> = btf_type_int(t); <answer> int_data 
<token> (int_data & ~BTF_INT_MASK) { <answer> if 
<token> t, "Invalid int_data:%x", <answer> btf_verifier_log_basic(env, 
<token> -EINVAL; <answer> return 
<token> = BTF_INT_BITS(int_data) + BTF_INT_OFFSET(int_data); <answer> nr_bits 
if (nr_bits <token> BITS_PER_U128) { <answer> > 
btf_verifier_log_type(env, t, "nr_bits <token> %zu", <answer> exceeds 
<token> -EINVAL; <answer> return 
<token> (BITS_ROUNDUP_BYTES(nr_bits) > t->size) { <answer> if 
<token> t, "nr_bits exceeds type_size"); <answer> btf_verifier_log_type(env, 
return <token> <answer> -EINVAL; 
<token> = BTF_INT_ENCODING(int_data); <answer> encoding 
if <token> && <answer> (encoding 
<token> != BTF_INT_SIGNED && <answer> encoding 
<token> != BTF_INT_CHAR && <answer> encoding 
encoding != BTF_INT_BOOL) <token> <answer> { 
btf_verifier_log_type(env, <token> "Unsupported encoding"); <answer> t, 
return <token> <answer> -ENOTSUPP; 
<token> t, NULL); <answer> btf_verifier_log_type(env, 
return <token> <answer> meta_needed; 
static void <token> btf_verifier_env *env, <answer> btf_int_log(struct 
const <token> btf_type *t) <answer> struct 
int <token> = btf_type_int(t); <answer> int_data 
"size=%u bits_offset=%u nr_bits=%u <token> <answer> encoding=%s", 
<token> BTF_INT_OFFSET(int_data), <answer> t->size, 
static <token> btf_int128_print(struct btf_show *show, void *data) <answer> void 
u64 <token> lower_num; <answer> upper_num, 
<token> __BIG_ENDIAN_BITFIELD <answer> #ifdef 
upper_num <token> *(u64 *)data; <answer> = 
lower_num = *(u64 *)(data + <token> <answer> 8); 
upper_num = *(u64 *)(data <token> 8); <answer> + 
lower_num = <token> *)data; <answer> *(u64 
if <token> == 0) <answer> (upper_num 
<token> "0x%llx", lower_num); <answer> btf_show_type_value(show, 
btf_show_type_values(show, <token> upper_num, <answer> "0x%llx%016llx", 
static void btf_int128_shift(u64 <token> u16 left_shift_bits, <answer> *print_num, 
<token> right_shift_bits) <answer> u16 
u64 <token> lower_num; <answer> upper_num, 
<token> __BIG_ENDIAN_BITFIELD <answer> #ifdef 
upper_num = <token> <answer> print_num[0]; 
<token> = print_num[1]; <answer> lower_num 
<token> = print_num[1]; <answer> upper_num 
<token> = print_num[0]; <answer> lower_num 
total_bits_offset = <token> + BTF_INT_OFFSET(int_data); <answer> bits_offset 
<token> += BITS_ROUNDDOWN_BYTES(total_bits_offset); <answer> data 
<token> = BITS_PER_BYTE_MASKED(total_bits_offset); <answer> bits_offset 
btf_bitfield_show(data, <token> nr_bits, show); <answer> bits_offset, 
static <token> btf_int_show(const struct btf *btf, const struct btf_type *t, <answer> void 
u32 type_id, void *data, u8 <token> <answer> bits_offset, 
<token> btf_show *show) <answer> struct 
u32 <token> = btf_type_int(t); <answer> int_data 
u8 encoding = <token> <answer> BTF_INT_ENCODING(int_data); 
bool sign = <token> & BTF_INT_SIGNED; <answer> encoding 
u8 nr_bits <token> BTF_INT_BITS(int_data); <answer> = 
<token> *safe_data; <answer> void 
<token> = btf_show_start_type(show, t, type_id, data); <answer> safe_data 
if <token> <answer> (!safe_data) 
if (bits_offset || <token> || <answer> BTF_INT_OFFSET(int_data) 
BITS_PER_BYTE_MASKED(nr_bits)) <token> <answer> { 
btf_int_bits_show(btf, <token> safe_data, bits_offset, show); <answer> t, 
goto <token> <answer> out; 
<token> (nr_bits) { <answer> switch 
case <token> <answer> 128: 
<token> safe_data); <answer> btf_int128_print(show, 
case <token> <answer> 64: 
<token> (sign) <answer> if 
btf_show_type_value(show, <token> *(s64 *)safe_data); <answer> "%lld", 
btf_show_type_value(show, "%llu", *(u64 <token> <answer> *)safe_data); 
case <token> <answer> 32: 
if <token> <answer> (sign) 
btf_show_type_value(show, <token> *(s32 *)safe_data); <answer> "%d", 
btf_show_type_value(show, <token> *(u32 *)safe_data); <answer> "%u", 
case <token> <answer> 16: 
<token> (sign) <answer> if 
btf_show_type_value(show, "%d", <token> *)safe_data); <answer> *(s16 
btf_show_type_value(show, "%u", <token> *)safe_data); <answer> *(u16 
<token> 8: <answer> case 
if (show->state.array_encoding == <token> { <answer> BTF_INT_CHAR) 
if (BTF_INFO_KIND(t->info) == BTF_KIND_TYPEDEF) <token> <answer> { 
<token> (!t->name_off || <answer> if 
!btf_name_valid_identifier(env->btf, <token> { <answer> t->name_off)) 
btf_verifier_log_type(env, <token> "Invalid name"); <answer> t, 
<token> -EINVAL; <answer> return 
} <token> if (BTF_INFO_KIND(t->info) == BTF_KIND_TYPE_TAG) { <answer> else 
value = btf_name_by_offset(env->btf, <token> <answer> t->name_off); 
if (!value || <token> { <answer> !value[0]) 
<token> t, "Invalid name"); <answer> btf_verifier_log_type(env, 
return <token> <answer> -EINVAL; 
<token> else { <answer> } 
if (t->name_off) <token> <answer> { 
<token> t, "Invalid name"); <answer> btf_verifier_log_type(env, 
<token> -EINVAL; <answer> return 
<token> t, NULL); <answer> btf_verifier_log_type(env, 
<token> 0; <answer> return 
static <token> btf_modifier_resolve(struct btf_verifier_env *env, <answer> int 
const struct resolve_vertex <token> <answer> *v) 
const struct btf_type *t <token> v->t; <answer> = 
<token> struct btf_type *next_type; <answer> const 
u32 <token> = t->type; <answer> next_type_id 
struct btf <token> = env->btf; <answer> *btf 
next_type <token> btf_type_by_id(btf, next_type_id); <answer> = 
if <token> || btf_type_is_resolve_source_only(next_type)) { <answer> (!next_type 
btf_verifier_log_type(env, v->t, <token> type_id"); <answer> "Invalid 
return <token> <answer> -EINVAL; 
if (!env_type_is_resolve_sink(env, <token> && <answer> next_type) 
<token> next_type_id)) <answer> !env_type_is_resolved(env, 
return <token> next_type, next_type_id); <answer> env_stack_push(env, 
if (!btf_type_id_size(btf, <token> NULL)) { <answer> &next_type_id, 
if (env_type_is_resolved(env, <token> <answer> next_type_id)) 
<token> = btf_type_id_resolve(btf, &next_type_id); <answer> next_type 
<token> (!btf_type_id_size(btf, &next_type_id, NULL)) { <answer> if 
btf_verifier_log_type(env, v->t, "Invalid <token> <answer> type_id"); 
return <token> <answer> -EINVAL; 
env_stack_pop_resolved(env, next_type_id, <token> <answer> 0); 
<token> 0; <answer> return 
<token> int btf_ptr_resolve(struct btf_verifier_env *env, <answer> static 
const <token> resolve_vertex *v) <answer> struct 
const struct btf_type <token> <answer> *next_type; 
const <token> btf_type *t = v->t; <answer> struct 
u32 next_type_id = <token> <answer> t->type; 
<token> btf *btf = env->btf; <answer> struct 
<token> = btf_type_by_id(btf, next_type_id); <answer> next_type 
<token> (!next_type || btf_type_is_resolve_source_only(next_type)) { <answer> if 
btf_verifier_log_type(env, v->t, <token> type_id"); <answer> "Invalid 
return <token> <answer> -EINVAL; 
if (!env_type_is_resolve_sink(env, next_type) <token> <answer> && 
!env_type_is_resolved(env, <token> <answer> next_type_id)) 
return env_stack_push(env, next_type, <token> <answer> next_type_id); 
if <token> { <answer> (btf_type_is_modifier(next_type)) 
<token> struct btf_type *resolved_type; <answer> const 
<token> resolved_type_id; <answer> u32 
resolved_type_id <token> next_type_id; <answer> = 
resolved_type = btf_type_id_resolve(btf, <token> <answer> &resolved_type_id); 
if (btf_type_is_ptr(resolved_type) <token> <answer> && 
!env_type_is_resolve_sink(env, resolved_type) <token> <answer> && 
!env_type_is_resolved(env, <token> <answer> resolved_type_id)) 
<token> env_stack_push(env, resolved_type, <answer> return 
if (!btf_type_id_size(btf, &next_type_id, NULL)) <token> <answer> { 
<token> (env_type_is_resolved(env, next_type_id)) <answer> if 
<token> = btf_type_id_resolve(btf, &next_type_id); <answer> next_type 
if (!btf_type_is_void(next_type) <token> <answer> && 
!btf_type_is_fwd(next_type) <token> <answer> && 
<token> { <answer> !btf_type_is_func_proto(next_type)) 
btf_verifier_log_type(env, v->t, <token> type_id"); <answer> "Invalid 
<token> -EINVAL; <answer> return 
env_stack_pop_resolved(env, <token> 0); <answer> next_type_id, 
return <token> <answer> 0; 
static void btf_modifier_show(const struct btf <token> <answer> *btf, 
const struct btf_type <token> <answer> *t, 
u32 type_id, <token> *data, <answer> void 
u8 bits_offset, struct <token> *show) <answer> btf_show 
<token> (btf->resolved_ids) <answer> if 
<token> = btf_type_id_resolve(btf, &type_id); <answer> t 
t <token> btf_type_skip_modifiers(btf, type_id, NULL); <answer> = 
btf_type_ops(t)->show(btf, t, type_id, data, bits_offset, <token> <answer> show); 
<token> void btf_var_show(const struct btf *btf, const struct btf_type *t, <answer> static 
u32 type_id, void <token> u8 bits_offset, <answer> *data, 
struct btf_show <token> <answer> *show) 
t = <token> &type_id); <answer> btf_type_id_resolve(btf, 
<token> t, type_id, data, bits_offset, show); <answer> btf_type_ops(t)->show(btf, 
static void btf_ptr_show(const <token> btf *btf, const struct btf_type *t, <answer> struct 
u32 <token> void *data, u8 bits_offset, <answer> type_id, 
<token> btf_show *show) <answer> struct 
<token> *safe_data; <answer> void 
safe_data = <token> t, type_id, data); <answer> btf_show_start_type(show, 
<token> (!safe_data) <answer> if 
if (!array->type || <token> { <answer> !BTF_TYPE_ID_VALID(array->type)) 
btf_verifier_log_type(env, t, <token> elem"); <answer> "Invalid 
<token> -EINVAL; <answer> return 
if <token> || !BTF_TYPE_ID_VALID(array->index_type)) { <answer> (!array->index_type 
<token> t, "Invalid index"); <answer> btf_verifier_log_type(env, 
<token> -EINVAL; <answer> return 
<token> t, NULL); <answer> btf_verifier_log_type(env, 
<token> meta_needed; <answer> return 
static int btf_array_resolve(struct <token> *env, <answer> btf_verifier_env 
const <token> resolve_vertex *v) <answer> struct 
const struct <token> *array = btf_type_array(v->t); <answer> btf_array 
const struct btf_type *elem_type, <token> <answer> *index_type; 
u32 <token> index_type_id; <answer> elem_type_id, 
struct btf *btf <token> env->btf; <answer> = 
u32 <token> <answer> elem_size; 
if (elem_size <token> 1) <answer> == 
encoding = <token> <answer> BTF_INT_CHAR; 
if (!btf_show_start_array_type(show, <token> type_id, encoding, data)) <answer> t, 
if <token> <answer> (!elem_type) 
goto <token> <answer> out; 
elem_ops = <token> <answer> btf_type_ops(elem_type); 
for (i = 0; i < <token> i++) { <answer> array->nelems; 
elem_ops->show(btf, <token> elem_type_id, data, <answer> elem_type, 
<token> show); <answer> bits_offset, 
<token> += elem_size; <answer> data 
<token> (show->state.array_terminated) <answer> if 
static <token> btf_array_show(const struct btf *btf, const struct btf_type *t, <answer> void 
u32 type_id, void *data, u8 <token> <answer> bits_offset, 
struct <token> *show) <answer> btf_show 
const struct <token> *m = show->state.member; <answer> btf_member 
if (show->state.depth > 0 && !(show->flags & <token> { <answer> BTF_SHOW_ZERO)) 
<token> (!show->state.depth_check) { <answer> if 
<token> = show->state.depth + 1; <answer> show->state.depth_check 
show->state.depth_to_show <token> 0; <answer> = 
__btf_array_show(btf, t, type_id, <token> bits_offset, show); <answer> data, 
show->state.member <token> m; <answer> = 
if (show->state.depth_check <token> show->state.depth + 1) <answer> != 
show->state.depth_check = <token> <answer> 0; 
if <token> <= show->state.depth) <answer> (show->state.depth_to_show 
__btf_array_show(btf, t, type_id, <token> bits_offset, show); <answer> data, 
static struct btf_kind_operations array_ops = <token> <answer> { 
<token> = btf_array_check_meta, <answer> .check_meta 
.resolve = <token> <answer> btf_array_resolve, 
.check_member = <token> <answer> btf_array_check_member, 
<token> = btf_generic_check_kflag_member, <answer> .check_kflag_member 
.log_details <token> btf_array_log, <answer> = 
.show <token> btf_array_show, <answer> = 
static <token> btf_struct_check_member(struct btf_verifier_env *env, <answer> int 
const struct <token> *struct_type, <answer> btf_type 
const <token> btf_member *member, <answer> struct 
<token> struct btf_type *member_type) <answer> const 
u32 struct_bits_off = <token> <answer> member->offset; 
<token> struct_size, bytes_offset; <answer> u32 
if (BITS_PER_BYTE_MASKED(struct_bits_off)) <token> <answer> { 
btf_verifier_log_member(env, struct_type, <token> <answer> member, 
"Member is <token> byte aligned"); <answer> not 
<token> -EINVAL; <answer> return 
struct_size <token> struct_type->size; <answer> = 
<token> = BITS_ROUNDDOWN_BYTES(struct_bits_off); <answer> bytes_offset 
if (struct_size - bytes_offset < member_type->size) <token> <answer> { 
btf_verifier_log_member(env, struct_type, <token> <answer> member, 
"Member <token> struct_size"); <answer> exceeds 
<token> -EINVAL; <answer> return 
<token> 0; <answer> return 
static s32 <token> btf_verifier_env *env, <answer> btf_struct_check_meta(struct 
const struct <token> *t, <answer> btf_type 
u32 <token> <answer> meta_left) 
bool is_union = <token> == BTF_KIND_UNION; <answer> BTF_INFO_KIND(t->info) 
const struct btf_member <token> <answer> *member; 
u32 meta_needed, <token> <answer> last_offset; 
struct <token> *btf = env->btf; <answer> btf 
u32 <token> = t->size; <answer> struct_size 
<token> offset; <answer> u32 
u16 <token> <answer> i; 
meta_needed = btf_type_vlen(t) <token> sizeof(*member); <answer> * 
if (meta_left <token> meta_needed) { <answer> < 
btf_verifier_log_basic(env, <token> <answer> t, 
<token> meta_needed:%u", <answer> "meta_left:%u 
<token> meta_needed); <answer> meta_left, 
<token> -EINVAL; <answer> return 
if (last_offset <token> offset) { <answer> > 
<token> t, member, <answer> btf_verifier_log_member(env, 
"Invalid member <token> <answer> bits_offset"); 
<token> -EINVAL; <answer> return 
<token> (BITS_ROUNDUP_BYTES(offset) > struct_size) { <answer> if 
btf_verifier_log_member(env, <token> member, <answer> t, 
"Member bits_offset <token> its struct size"); <answer> exceeds 
return <token> <answer> -EINVAL; 
btf_verifier_log_member(env, t, member, <token> <answer> NULL); 
<token> = offset; <answer> last_offset 
<token> meta_needed; <answer> return 
static int btf_struct_resolve(struct <token> *env, <answer> btf_verifier_env 
const struct <token> *v) <answer> resolve_vertex 
<token> struct btf_member *member; <answer> const 
int <token> <answer> err; 
<token> i; <answer> u16 
if <token> { <answer> (v->next_member) 
const <token> btf_type *last_member_type; <answer> struct 
<token> struct btf_member *last_member; <answer> const 
<token> last_member_type_id; <answer> u32 
last_member = btf_type_member(v->t) + <token> - 1; <answer> v->next_member 
last_member_type_id = <token> <answer> last_member->type; 
<token> (WARN_ON_ONCE(!env_type_is_resolved(env, <answer> if 
<token> -EINVAL; <answer> return 
<token> = btf_type_by_id(env->btf, <answer> last_member_type 
<token> (btf_type_kflag(v->t)) <answer> if 
err = <token> v->t, <answer> btf_type_ops(last_member_type)->check_kflag_member(env, 
<token> = btf_type_ops(last_member_type)->check_member(env, v->t, <answer> err 
if <token> <answer> (err) 
return <token> <answer> err; 
<token> v->next_member, v->t, member) { <answer> for_each_member_from(i, 
u32 <token> = member->type; <answer> member_type_id 
const struct <token> *member_type = btf_type_by_id(env->btf, <answer> btf_type 
if (btf_type_nosize_or_null(member_type) <token> <answer> || 
btf_type_is_resolve_source_only(member_type)) <token> <answer> { 
<token> v->t, member, <answer> btf_verifier_log_member(env, 
<token> member"); <answer> "Invalid 
return <token> <answer> -EINVAL; 
if (!env_type_is_resolve_sink(env, member_type) <token> <answer> && 
!env_type_is_resolved(env, <token> { <answer> member_type_id)) 
env_stack_set_next_member(env, i <token> 1); <answer> + 
return <token> member_type, member_type_id); <answer> env_stack_push(env, 
<token> (btf_type_kflag(v->t)) <answer> if 
err = btf_type_ops(member_type)->check_kflag_member(env, <token> <answer> v->t, 
err = btf_type_ops(member_type)->check_member(env, <token> <answer> v->t, 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> 0, 0); <answer> env_stack_pop_resolved(env, 
return <token> <answer> 0; 
static void btf_struct_log(struct btf_verifier_env <token> <answer> *env, 
const <token> btf_type *t) <answer> struct 
<token> "size=%u vlen=%u", t->size, btf_type_vlen(t)); <answer> btf_verifier_log(env, 
<token> { <answer> enum 
BTF_FIELD_IGNORE <token> 0, <answer> = 
<token> = 1, <answer> BTF_FIELD_FOUND 
struct <token> { <answer> btf_field_info 
enum btf_field_type <token> <answer> type; 
u32 <token> <answer> off; 
union <token> <answer> { 
<token> { <answer> struct 
<token> type_id; <answer> u32 
<token> kptr; <answer> } 
<token> { <answer> struct 
const char <token> <answer> *node_name; 
<token> value_btf_id; <answer> u32 
<token> graph_root; <answer> } 
<token> int btf_find_struct(const struct btf *btf, const struct btf_type *t, <answer> static 
u32 off, int sz, enum <token> field_type, <answer> btf_field_type 
<token> btf_field_info *info) <answer> struct 
if <token> <answer> (!__btf_type_is_struct(t)) 
return <token> <answer> BTF_FIELD_IGNORE; 
if (t->size <token> sz) <answer> != 
return <token> <answer> BTF_FIELD_IGNORE; 
<token> = field_type; <answer> info->type 
info->off <token> off; <answer> = 
return <token> <answer> BTF_FIELD_FOUND; 
static int btf_find_kptr(const struct btf *btf, <token> struct btf_type *t, <answer> const 
u32 off, int sz, struct <token> *info) <answer> btf_field_info 
enum btf_field_type <token> <answer> type; 
u32 <token> <answer> res_id; 
<token> btf *kptr_btf; <answer> struct 
int <token> <answer> ret; 
<token> id; <answer> s32 
t <token> btf_type_by_id(btf, info->kptr.type_id); <answer> = 
id = bpf_find_btf_id(__btf_name_by_offset(btf, <token> BTF_INFO_KIND(t->info), <answer> t->name_off), 
<token> (id == -ENOENT) { <answer> if 
<token> = NULL; <answer> field->kptr.dtor 
id <token> info->kptr.type_id; <answer> = 
<token> = (struct btf *)btf; <answer> kptr_btf 
<token> found_dtor; <answer> goto 
if <token> < 0) <answer> (id 
return <token> <answer> id; 
if <token> == BPF_KPTR_REF) { <answer> (info->type 
<token> struct btf_type *dtor_func; <answer> const 
const <token> *dtor_func_name; <answer> char 
<token> long addr; <answer> unsigned 
s32 <token> <answer> dtor_btf_id; 
dtor_btf_id = btf_find_dtor_kfunc(kptr_btf, <token> <answer> id); 
<token> (dtor_btf_id < 0) { <answer> if 
ret = <token> <answer> dtor_btf_id; 
<token> end_btf; <answer> goto 
<token> = btf_type_by_id(kptr_btf, dtor_btf_id); <answer> dtor_func 
if <token> { <answer> (!dtor_func) 
<token> = -ENOENT; <answer> ret 
<token> end_btf; <answer> goto 
<token> (btf_is_module(kptr_btf)) { <answer> if 
mod = <token> <answer> btf_try_get_module(kptr_btf); 
if (!mod) <token> <answer> { 
ret <token> -ENXIO; <answer> = 
<token> end_btf; <answer> goto 
dtor_func_name <token> __btf_name_by_offset(kptr_btf, dtor_func->name_off); <answer> = 
addr <token> kallsyms_lookup_name(dtor_func_name); <answer> = 
if (!addr) <token> <answer> { 
ret <token> -EINVAL; <answer> = 
goto <token> <answer> end_mod; 
field->kptr.dtor <token> (void *)addr; <answer> = 
<token> = id; <answer> field->kptr.btf_id 
<token> = kptr_btf; <answer> field->kptr.btf 
field->kptr.module = <token> <answer> mod; 
<token> 0; <answer> return 
<token> ret; <answer> return 
<token> int btf_parse_graph_root(const struct btf *btf, <answer> static 
<token> btf_field *field, <answer> struct 
struct <token> *info, <answer> btf_field_info 
<token> char *node_type_name, <answer> const 
<token> node_type_align) <answer> size_t 
const struct <token> *t, *n = NULL; <answer> btf_type 
const struct btf_member <token> <answer> *member; 
u32 <token> <answer> offset; 
<token> i; <answer> int 
t = <token> info->graph_root.value_btf_id); <answer> btf_type_by_id(btf, 
for_each_member(i, t, member) <token> <answer> { 
<token> (strcmp(info->graph_root.node_name, <answer> if 
<token> member->name_off))) <answer> __btf_name_by_offset(btf, 
rec = kzalloc(offsetof(struct btf_record, fields[cnt]), <token> | __GFP_NOWARN); <answer> GFP_KERNEL 
if <token> <answer> (!rec) 
return <token> <answer> ERR_PTR(-ENOMEM); 
rec->spin_lock_off <token> -EINVAL; <answer> = 
rec->timer_off <token> -EINVAL; <answer> = 
rec->refcount_off <token> -EINVAL; <answer> = 
for (i = <token> i < cnt; i++) { <answer> 0; 
field_type_size = <token> <answer> btf_field_type_size(info_arr[i].type); 
if <token> + field_type_size > value_size) { <answer> (info_arr[i].off 
WARN_ONCE(1, "verifier bug off %d size %d", info_arr[i].off, <token> <answer> value_size); 
ret = <token> <answer> -EFAULT; 
goto <token> <answer> end; 
<token> (info_arr[i].off < next_off) { <answer> if 
ret <token> -EEXIST; <answer> = 
<token> end; <answer> goto 
<token> = info_arr[i].off + field_type_size; <answer> next_off 
rec->field_mask <token> info_arr[i].type; <answer> |= 
<token> = info_arr[i].off; <answer> rec->fields[i].offset 
<token> = info_arr[i].type; <answer> rec->fields[i].type 
<token> = field_type_size; <answer> rec->fields[i].size 
switch (info_arr[i].type) <token> <answer> { 
<token> BPF_SPIN_LOCK: <answer> case 
WARN_ON_ONCE(rec->spin_lock_off <token> 0); <answer> >= 
if (IS_ERR_OR_NULL(rec) <token> !(rec->field_mask & BPF_GRAPH_ROOT)) <answer> || 
<token> 0; <answer> return 
for (i = 0; i < rec->cnt; i++) <token> <answer> { 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <media/i2c/tvp514x.h> 
<token> <media/i2c/adv7343.h> <answer> #include 
#include <token> <answer> "common.h" 
#include <token> <answer> "da8xx.h" 
struct pdata_init <token> <answer> { 
const <token> *compatible; <answer> char 
void <token> <answer> (*fn)(void); 
<token> TVP5147_CH0 "tvp514x-0" <answer> #define 
<token> TVP5147_CH1 "tvp514x-1" <answer> #define 
<token> <linux/module.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/list.h> 
#include <token> <answer> <linux/mutex.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/mtd/ubi.h> 
#include <token> <answer> <linux/blkdev.h> 
#include <token> <answer> <linux/blk-mq.h> 
#include <token> <answer> <linux/hdreg.h> 
<token> <linux/scatterlist.h> <answer> #include 
<token> <linux/idr.h> <answer> #include 
#include <token> <answer> <asm/div64.h> 
#include <token> <answer> "ubi-media.h" 
<token> "ubi.h" <answer> #include 
blk_rq_map_sg(req->q, <token> pdu->usgl.sg); <answer> req, 
while <token> { <answer> (bytes_left) 
if (offset + to_read <token> dev->leb_size) <answer> > 
<token> = dev->leb_size - offset; <answer> to_read 
ret = ubi_read_sg(dev->desc, leb, &pdu->usgl, offset, <token> <answer> to_read); 
if (ret < <token> <answer> 0) 
<token> -= to_read; <answer> bytes_left 
to_read = <token> <answer> bytes_left; 
<token> += 1; <answer> leb 
<token> = 0; <answer> offset 
rq_for_each_segment(bvec, <token> iter) <answer> req, 
blk_mq_end_request(req, <token> <answer> errno_to_blk_status(ret)); 
return <token> <answer> BLK_STS_OK; 
<token> int ubiblock_open(struct gendisk *disk, blk_mode_t mode) <answer> static 
struct ubiblock *dev = <token> <answer> disk->private_data; 
<token> ret; <answer> int 
if <token> > 0) { <answer> (dev->refcnt 
<token> out_done; <answer> goto 
if (mode <token> BLK_OPEN_WRITE) { <answer> & 
ret = <token> <answer> -EROFS; 
goto <token> <answer> out_unlock; 
dev->desc <token> ubi_open_volume(dev->ubi_num, dev->vol_id, UBI_READONLY); <answer> = 
<token> (IS_ERR(dev->desc)) { <answer> if 
dev_err(disk_to_dev(dev->gd), "failed to <token> ubi volume %d_%d", <answer> open 
dev->ubi_num, <token> <answer> dev->vol_id); 
ret = <token> <answer> PTR_ERR(dev->desc); 
dev->desc = <token> <answer> NULL; 
<token> out_unlock; <answer> goto 
<token> 0; <answer> return 
return <token> <answer> ret; 
static void ubiblock_release(struct gendisk <token> <answer> *gd) 
struct ubiblock <token> = gd->private_data; <answer> *dev 
if (dev->refcnt == <token> { <answer> 0) 
<token> = NULL; <answer> dev->desc 
static int ubiblock_getgeo(struct <token> *bdev, struct hd_geometry *geo) <answer> block_device 
<token> = find_dev_nolock(vi->ubi_num, vi->vol_id); <answer> dev 
if <token> { <answer> (!dev) 
return <token> <answer> -ENODEV; 
ret <token> calc_disk_capacity(vi, &disk_capacity); <answer> = 
if (ret) <token> <answer> { 
if (ret == <token> { <answer> -EFBIG) 
"the volume <token> too big (%d LEBs), cannot resize", <answer> is 
return <token> <answer> ret; 
if (get_capacity(dev->gd) != <token> { <answer> disk_capacity) 
set_capacity(dev->gd, <token> <answer> disk_capacity); 
<token> "resized to %lld bytes", <answer> dev_info(disk_to_dev(dev->gd), 
return <token> <answer> 0; 
<token> bool <answer> static 
match_volume_desc(struct ubi_volume_info *vi, const char *name, int ubi_num, int <token> <answer> vol_id) 
<token> err, len, cur_ubi_num, cur_vol_id; <answer> int 
if (ubi_num == <token> { <answer> -1) 
for <token> = 0; i < ubiblock_devs; i++) { <answer> (i 
p <token> &ubiblock_param[i]; <answer> = 
if <token> p->name, p->ubi_num, p->vol_id)) <answer> (!match_volume_desc(vi, 
<token> = ubiblock_create(vi); <answer> ret 
if <token> { <answer> (ret) 
"UBI: <token> can't add '%s' volume on ubi%d_%d, err=%d\n", <answer> block: 
vi->name, p->ubi_num, p->vol_id, <token> <answer> ret); 
<token> int ubiblock_notify(struct notifier_block *nb, <answer> static 
unsigned long notification_type, <token> *ns_ptr) <answer> void 
<token> ubi_notification *nt = ns_ptr; <answer> struct 
switch (notification_type) <token> <answer> { 
case <token> <answer> UBI_VOLUME_ADDED: 
case <token> <answer> UBI_VOLUME_REMOVED: 
case <token> <answer> UBI_VOLUME_RESIZED: 
<token> UBI_VOLUME_UPDATED: <answer> case 
if <token> == UBI_STATIC_VOLUME) <answer> (nt->vi.vol_type 
<token> NOTIFY_OK; <answer> return 
static struct notifier_block <token> = { <answer> ubiblock_notifier 
.notifier_call <token> ubiblock_notify, <answer> = 
<token> void ubiblock_remove_all(void) <answer> static 
struct ubiblock <token> <answer> *next; 
struct <token> *dev; <answer> ubiblock 
list_for_each_entry_safe(dev, next, &ubiblock_devices, list) <token> <answer> { 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/mempool.h> 
<token> <linux/string.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/errno.h> 
<token> <linux/init.h> <answer> #include 
<token> <linux/pci.h> <answer> #include 
#include <token> <answer> <linux/skbuff.h> 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/spinlock.h> 
<token> <linux/workqueue.h> <answer> #include 
<token> <linux/if_ether.h> <answer> #include 
#include <token> <answer> <linux/blk-mq-pci.h> 
<token> <scsi/fc/fc_fip.h> <answer> #include 
#include <token> <answer> <scsi/scsi_host.h> 
#include <token> <answer> <scsi/scsi_transport.h> 
#include <token> <answer> <scsi/scsi_transport_fc.h> 
#include <token> <answer> <scsi/scsi_tcq.h> 
#include <token> <answer> <scsi/libfc.h> 
#include <token> <answer> <scsi/fc_frame.h> 
<token> "vnic_dev.h" <answer> #include 
<token> "vnic_intr.h" <answer> #include 
#include <token> <answer> "vnic_stats.h" 
#include <token> <answer> "fnic_io.h" 
<token> "fnic_fip.h" <answer> #include 
#include <token> <answer> "fnic.h" 
#define <token> 0x0045 <answer> PCI_DEVICE_ID_CISCO_FNIC 
void <token> Scsi_Host *host, <answer> fnic_dump_fchost_stats(struct 
struct <token> *stats) <answer> fc_host_statistics 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
"fnic: seconds since <token> reset = %llu\n", <answer> last 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
<token> tx frames = %llu\n", <answer> "fnic: 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
"fnic: <token> words = %llu\n", <answer> tx 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
"fnic: rx <token> = %llu\n", <answer> frames 
FNIC_MAIN_NOTE(KERN_NOTICE, <token> <answer> host, 
"fnic: <token> words = %llu\n", <answer> rx 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
"fnic: lip count = <token> <answer> %llu\n", 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
"fnic: nos count = <token> <answer> %llu\n", 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
"fnic: error <token> = %llu\n", <answer> frames 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
"fnic: <token> frames = %llu\n", <answer> dumped 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
"fnic: link failure count = <token> <answer> %llu\n", 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
"fnic: loss <token> sync count = %llu\n", <answer> of 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
<token> loss of signal count = %llu\n", <answer> "fnic: 
FNIC_MAIN_NOTE(KERN_NOTICE, <token> <answer> host, 
"fnic: prim seq protocol err <token> = %llu\n", <answer> count 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
"fnic: invalid <token> word count= %llu\n", <answer> tx 
FNIC_MAIN_NOTE(KERN_NOTICE, <token> <answer> host, 
"fnic: <token> crc count = %llu\n", <answer> invalid 
FNIC_MAIN_NOTE(KERN_NOTICE, <token> <answer> host, 
<token> fcp input requests = %llu\n", <answer> "fnic: 
FNIC_MAIN_NOTE(KERN_NOTICE, <token> <answer> host, 
"fnic: <token> output requests = %llu\n", <answer> fcp 
FNIC_MAIN_NOTE(KERN_NOTICE, <token> <answer> host, 
"fnic: fcp control requests = <token> <answer> %llu\n", 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
"fnic: <token> input megabytes = %llu\n", <answer> fcp 
<token> host, <answer> FNIC_MAIN_NOTE(KERN_NOTICE, 
<token> fcp output megabytes = %llu\n", <answer> "fnic: 
static void <token> Scsi_Host *host) <answer> fnic_reset_host_stats(struct 
<token> ret; <answer> int 
struct fc_lport <token> = shost_priv(host); <answer> *lp 
<token> fnic *fnic = lport_priv(lp); <answer> struct 
struct fc_host_statistics <token> <answer> *stats; 
unsigned <token> flags; <answer> long 
mod_timer(&fnic->notify_timer, <token> <answer> jiffies); 
<token> = jiffies + (HZ * 2); <answer> time 
do <token> <answer> { 
<token> = finished(vdev, &done); <answer> err 
<token> (err) <answer> if 
<token> err; <answer> return 
if <token> <answer> (done) 
return <token> <answer> 0; 
schedule_timeout_uninterruptible(HZ / <token> <answer> 10); 
} while (time_after(time, jiffies) || (count <token> 3)); <answer> < 
return <token> <answer> -ETIMEDOUT; 
static int fnic_cleanup(struct <token> *fnic) <answer> fnic 
unsigned <token> i; <answer> int 
<token> err; <answer> int 
int <token> <answer> raw_wq_rq_counts; 
for (i <token> 0; i < fnic->intr_count; i++) <answer> = 
for <token> = 0; i < fnic->rq_count; i++) { <answer> (i 
err <token> vnic_rq_disable(&fnic->rq[i]); <answer> = 
<token> (err) <answer> if 
<token> err; <answer> return 
for (i <token> 0; i < fnic->raw_wq_count; i++) { <answer> = 
err <token> vnic_wq_disable(&fnic->wq[i]); <answer> = 
<token> (err) <answer> if 
return <token> <answer> err; 
for (i = 0; i <token> fnic->wq_copy_count; i++) { <answer> < 
<token> = vnic_wq_copy_disable(&fnic->hw_copy_wq[i]); <answer> err 
if <token> <answer> (err) 
return <token> <answer> err; 
raw_wq_rq_counts <token> fnic->raw_wq_count + fnic->rq_count; <answer> = 
<token> -1, i + raw_wq_rq_counts); <answer> fnic_wq_copy_cmpl_handler(fnic, 
static u8 *fnic_get_mac(struct <token> *lport) <answer> fc_lport 
struct fnic *fnic = <token> <answer> lport_priv(lport); 
<token> fnic->data_src_addr; <answer> return 
<token> void fnic_set_vlan(struct fnic *fnic, u16 vlan_id) <answer> static 
<token> vlan_id); <answer> vnic_dev_set_default_vlan(fnic->vdev, 
static <token> fnic_scsi_drv_init(struct fnic *fnic) <answer> int 
<token> Scsi_Host *host = fnic->lport->host; <answer> struct 
lp = <token> sizeof(struct fnic)); <answer> libfc_host_alloc(&fnic_host_template, 
if <token> { <answer> (!lp) 
printk(KERN_ERR PFX "Unable to alloc <token> local port\n"); <answer> libfc 
err = <token> <answer> -ENOMEM; 
<token> err_out; <answer> goto 
<token> = lp->host; <answer> host 
fnic <token> lport_priv(lp); <answer> = 
<token> = ida_alloc(&fnic_ida, GFP_KERNEL); <answer> fnic_id 
if (fnic_id <token> 0) { <answer> < 
<token> to alloc fnic ID\n"); <answer> pr_err("Unable 
<token> = fnic_id; <answer> err 
goto <token> <answer> err_out_ida_alloc; 
fnic->lport = <token> <answer> lp; 
fnic->ctlr.lp <token> lp; <answer> = 
fnic->link_events <token> 0; <answer> = 
fnic->pdev = <token> <answer> pdev; 
snprintf(fnic->name, sizeof(fnic->name) <token> 1, "%s%d", DRV_NAME, <answer> - 
host->transportt <token> fnic_fc_transport; <answer> = 
fnic->fnic_num = <token> <answer> fnic_id; 
err <token> pci_enable_device(pdev); <answer> = 
<token> (err) { <answer> if 
shost_printk(KERN_ERR, <token> <answer> fnic->lport->host, 
"Cannot enable <token> device, aborting.\n"); <answer> PCI 
<token> err_out_free_hba; <answer> goto 
err = <token> DRV_NAME); <answer> pci_request_regions(pdev, 
if <token> { <answer> (err) 
shost_printk(KERN_ERR, <token> <answer> fnic->lport->host, 
"Cannot <token> PCI resources, aborting\n"); <answer> enable 
goto <token> <answer> err_out_disable_device; 
err <token> dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(47)); <answer> = 
<token> (err) { <answer> if 
err <token> dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32)); <answer> = 
<token> (err) { <answer> if 
<token> fnic->lport->host, <answer> shost_printk(KERN_ERR, 
"No usable <token> configuration " <answer> DMA 
goto <token> <answer> err_out_release_regions; 
err <token> scsi_add_host(lp->host, &pdev->dev); <answer> = 
if <token> { <answer> (err) 
shost_printk(KERN_ERR, <token> <answer> fnic->lport->host, 
"fnic: scsi_add_host <token> <answer> failed...exiting\n"); 
<token> err_out_scsi_add_host; <answer> goto 
<token> flags); <answer> spin_lock_irqsave(&fnic->fnic_lock, 
fnic->stop_rx_link_events = <token> <answer> 1; 
<token> flags); <answer> spin_unlock_irqrestore(&fnic->fnic_lock, 
if (vnic_dev_get_intr_mode(fnic->vdev) <token> VNIC_DEV_INTR_MODE_MSI) <answer> == 
if (fnic->config.flags <token> VFCF_FIP_CAPABLE) { <answer> & 
<token> flags); <answer> spin_lock_irqsave(&fnic->fnic_lock, 
<token> = 1; <answer> fnic->in_remove 
spin_unlock_irqrestore(&fnic->fnic_lock, <token> <answer> flags); 
<token> flags); <answer> spin_lock_irqsave(&fnic_list_lock, 
spin_unlock_irqrestore(&fnic_list_lock, <token> <answer> flags); 
for (hwq = 0; hwq < fnic->wq_copy_count; <token> <answer> hwq++) 
<token> fnic->fnic_num); <answer> ida_free(&fnic_ida, 
static struct pci_driver fnic_driver = <token> <answer> { 
.name = <token> <answer> DRV_NAME, 
.id_table = <token> <answer> fnic_id_table, 
<token> = fnic_probe, <answer> .probe 
.remove <token> fnic_remove, <answer> = 
static int <token> fnic_init_module(void) <answer> __init 
<token> len; <answer> size_t 
int <token> = 0; <answer> err 
printk(KERN_INFO PFX "%s, ver %s\n", <token> DRV_VERSION); <answer> DRV_DESCRIPTION, 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/device.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <dt-bindings/memory/tegra124-mc.h> 
<token> "mc.h" <answer> #include 
static const <token> tegra_mc_client tegra124_mc_clients[] = { <answer> struct 
.id <token> 0x00, <answer> = 
<token> = "ptcr", <answer> .name 
.swgroup <token> TEGRA_SWGROUP_PTC, <answer> = 
.regs <token> { <answer> = 
.la <token> { <answer> = 
.reg <token> 0x34c, <answer> = 
.shift <token> 0, <answer> = 
.mask <token> 0xff, <answer> = 
.def <token> 0x0, <answer> = 
<token> { <answer> }, 
.id = <token> <answer> 0x01, 
<token> = "display0a", <answer> .name 
<token> = TEGRA_SWGROUP_DC, <answer> .swgroup 
.regs <token> { <answer> = 
<token> = { <answer> .smmu 
.reg = <token> <answer> 0x228, 
.bit = <token> <answer> 1, 
.la = <token> <answer> { 
.reg = <token> <answer> 0x2e8, 
<token> = 0, <answer> .shift 
<token> = 0xff, <answer> .mask 
.def <token> 0xc2, <answer> = 
}, <token> <answer> { 
<token> = 0x02, <answer> .id 
.name = <token> <answer> "display0ab", 
.swgroup = <token> <answer> TEGRA_SWGROUP_DCB, 
.regs = <token> <answer> { 
.smmu = <token> <answer> { 
.reg <token> 0x228, <answer> = 
.bit <token> 2, <answer> = 
.la = <token> <answer> { 
<token> = 0x2f4, <answer> .reg 
.shift <token> 0, <answer> = 
.mask <token> 0xff, <answer> = 
.def <token> 0xc6, <answer> = 
<token> { <answer> }, 
.id = <token> <answer> 0x03, 
.name <token> "display0b", <answer> = 
<token> = TEGRA_SWGROUP_DC, <answer> .swgroup 
<token> = { <answer> .regs 
<token> = { <answer> .smmu 
.reg <token> 0x228, <answer> = 
.bit <token> 3, <answer> = 
.la = <token> <answer> { 
<token> = 0x2e8, <answer> .reg 
.shift <token> 16, <answer> = 
.mask = <token> <answer> 0xff, 
<token> = 0x50, <answer> .def 
}, <token> <answer> { 
.id <token> 0x04, <answer> = 
<token> = "display0bb", <answer> .name 
.swgroup <token> TEGRA_SWGROUP_DCB, <answer> = 
.regs = <token> <answer> { 
.smmu <token> { <answer> = 
<token> = 0x228, <answer> .reg 
.bit <token> 4, <answer> = 
.la = <token> <answer> { 
.reg <token> 0x2f4, <answer> = 
.shift = <token> <answer> 16, 
.mask = <token> <answer> 0xff, 
.def = <token> <answer> 0x50, 
}, <token> <answer> { 
.id = <token> <answer> 0x05, 
<token> = "display0c", <answer> .name 
.swgroup <token> TEGRA_SWGROUP_DC, <answer> = 
.regs = <token> <answer> { 
.smmu <token> { <answer> = 
<token> = 0x228, <answer> .reg 
.bit = <token> <answer> 5, 
.la = <token> <answer> { 
.reg <token> 0x2ec, <answer> = 
<token> = 0, <answer> .shift 
<token> = 0xff, <answer> .mask 
<token> = 0x50, <answer> .def 
<token> { <answer> }, 
.id <token> 0x06, <answer> = 
<token> = "display0cb", <answer> .name 
.swgroup <token> TEGRA_SWGROUP_DCB, <answer> = 
.regs <token> { <answer> = 
<token> = { <answer> .smmu 
.reg <token> 0x228, <answer> = 
.bit <token> 6, <answer> = 
.la = <token> <answer> { 
.reg <token> 0x2f8, <answer> = 
.shift <token> 0, <answer> = 
<token> = 0xff, <answer> .mask 
<token> = 0x50, <answer> .def 
}, <token> <answer> { 
.id <token> 0x0e, <answer> = 
<token> = "afir", <answer> .name 
<token> = TEGRA_SWGROUP_AFI, <answer> .swgroup 
.regs <token> { <answer> = 
.smmu = <token> <answer> { 
.reg = <token> <answer> 0x228, 
.bit = <token> <answer> 14, 
<token> = { <answer> .la 
<token> = 0x2e0, <answer> .reg 
.shift <token> 0, <answer> = 
.mask = <token> <answer> 0xff, 
.def = <token> <answer> 0x13, 
<token> { <answer> }, 
.id = <token> <answer> 0x0f, 
.name = <token> <answer> "avpcarm7r", 
.swgroup = <token> <answer> TEGRA_SWGROUP_AVPC, 
.regs = <token> <answer> { 
.smmu = <token> <answer> { 
.reg <token> 0x228, <answer> = 
.bit <token> 15, <answer> = 
.la = <token> <answer> { 
.reg = <token> <answer> 0x2e4, 
.shift = <token> <answer> 0, 
<token> = 0xff, <answer> .mask 
<token> = 0x04, <answer> .def 
}, <token> <answer> { 
<token> = 0x10, <answer> .id 
<token> = "displayhc", <answer> .name 
.swgroup <token> TEGRA_SWGROUP_DC, <answer> = 
.regs = <token> <answer> { 
.smmu = <token> <answer> { 
.reg <token> 0x228, <answer> = 
<token> = 16, <answer> .bit 
<token> = { <answer> .la 
<token> = 0x2f0, <answer> .reg 
<token> = 0, <answer> .shift 
.mask <token> 0xff, <answer> = 
.def = <token> <answer> 0x50, 
<token> { <answer> }, 
.id <token> 0x11, <answer> = 
<token> = "displayhcb", <answer> .name 
.swgroup <token> TEGRA_SWGROUP_DCB, <answer> = 
<token> = { <answer> .regs 
.smmu = <token> <answer> { 
.reg = <token> <answer> 0x228, 
<token> = 17, <answer> .bit 
.la = <token> <answer> { 
.reg = <token> <answer> 0x2fc, 
<token> = 0, <answer> .shift 
.mask <token> 0xff, <answer> = 
<token> = 0x50, <answer> .def 
<token> { <answer> }, 
.id = <token> <answer> 0x15, 
.name <token> "hdar", <answer> = 
<token> = TEGRA_SWGROUP_HDA, <answer> .swgroup 
.regs = <token> <answer> { 
.smmu <token> { <answer> = 
<token> = 0x228, <answer> .reg 
<token> = 21, <answer> .bit 
.la = <token> <answer> { 
.reg = <token> <answer> 0x318, 
.shift = <token> <answer> 0, 
.mask = <token> <answer> 0xff, 
.def <token> 0x24, <answer> = 
<token> { <answer> }, 
.id = <token> <answer> 0x16, 
.name = <token> <answer> "host1xdmar", 
<token> = TEGRA_SWGROUP_HC, <answer> .swgroup 
.regs <token> { <answer> = 
.smmu <token> { <answer> = 
<token> = 0x228, <answer> .reg 
<token> = 22, <answer> .bit 
.la = <token> <answer> { 
.reg = <token> <answer> 0x310, 
.shift <token> 0, <answer> = 
.mask <token> 0xff, <answer> = 
<token> = 0x1e, <answer> .def 
}, <token> <answer> { 
<token> = 0x17, <answer> .id 
.name <token> "host1xr", <answer> = 
.swgroup = <token> <answer> TEGRA_SWGROUP_HC, 
.regs <token> { <answer> = 
<token> = { <answer> .smmu 
.reg = <token> <answer> 0x228, 
.bit <token> 23, <answer> = 
.la <token> { <answer> = 
.reg = <token> <answer> 0x310, 
.shift = <token> <answer> 16, 
.mask = <token> <answer> 0xff, 
.def <token> 0x50, <answer> = 
<token> { <answer> }, 
<token> = 0x1c, <answer> .id 
.name = <token> <answer> "msencsrd", 
<token> = TEGRA_SWGROUP_MSENC, <answer> .swgroup 
<token> = { <answer> .regs 
.smmu = <token> <answer> { 
.reg = <token> <answer> 0x228, 
<token> = 28, <answer> .bit 
.la = <token> <answer> { 
.reg = <token> <answer> 0x328, 
<token> = 0, <answer> .shift 
<token> = 0xff, <answer> .mask 
.def = <token> <answer> 0x23, 
}, <token> <answer> { 
.id = <token> <answer> 0x1d, 
<token> = "ppcsahbdmar", <answer> .name 
<token> = TEGRA_SWGROUP_PPCS, <answer> .swgroup 
.regs <token> { <answer> = 
<token> = { <answer> .smmu 
<token> = 0x228, <answer> .reg 
.bit <token> 29, <answer> = 
.la = <token> <answer> { 
.reg = <token> <answer> 0x344, 
.shift <token> 0, <answer> = 
.mask <token> 0xff, <answer> = 
<token> = 0x49, <answer> .def 
<token> { <answer> }, 
<token> = 0x1e, <answer> .id 
.name <token> "ppcsahbslvr", <answer> = 
<token> = TEGRA_SWGROUP_PPCS, <answer> .swgroup 
<token> = { <answer> .regs 
.smmu <token> { <answer> = 
.reg = <token> <answer> 0x228, 
.bit = <token> <answer> 30, 
<token> = { <answer> .la 
.reg = <token> <answer> 0x344, 
<token> = 16, <answer> .shift 
<token> = 0xff, <answer> .mask 
.def <token> 0x1a, <answer> = 
<token> { <answer> }, 
.id <token> 0x1f, <answer> = 
<token> = "satar", <answer> .name 
.swgroup = <token> <answer> TEGRA_SWGROUP_SATA, 
.regs = <token> <answer> { 
.smmu <token> { <answer> = 
<token> = 0x228, <answer> .reg 
<token> = 31, <answer> .bit 
.la <token> { <answer> = 
<token> = 0x350, <answer> .reg 
<token> = 0, <answer> .shift 
.mask = <token> <answer> 0xff, 
<token> = 0x65, <answer> .def 
}, <token> <answer> { 
.id <token> 0x22, <answer> = 
.name = <token> <answer> "vdebsevr", 
.swgroup <token> TEGRA_SWGROUP_VDE, <answer> = 
.regs = <token> <answer> { 
.smmu <token> { <answer> = 
.reg = <token> <answer> 0x22c, 
.bit = <token> <answer> 2, 
.la <token> { <answer> = 
<token> = 0x354, <answer> .reg 
.shift = <token> <answer> 0, 
.mask <token> 0xff, <answer> = 
<token> = 0x4f, <answer> .def 
}, <token> <answer> { 
.id <token> 0x23, <answer> = 
.name = <token> <answer> "vdember", 
.swgroup <token> TEGRA_SWGROUP_VDE, <answer> = 
.regs = <token> <answer> { 
<token> = { <answer> .smmu 
.reg <token> 0x22c, <answer> = 
<token> = 3, <answer> .bit 
.la <token> { <answer> = 
<token> = 0x354, <answer> .reg 
.shift <token> 16, <answer> = 
<token> = 0xff, <answer> .mask 
.def = <token> <answer> 0x3d, 
<token> { <answer> }, 
.id = <token> <answer> 0x24, 
.name <token> "vdemcer", <answer> = 
<token> = TEGRA_SWGROUP_VDE, <answer> .swgroup 
.regs = <token> <answer> { 
.smmu <token> { <answer> = 
.reg = <token> <answer> 0x22c, 
.bit <token> 4, <answer> = 
.la = <token> <answer> { 
.reg = <token> <answer> 0x358, 
.shift <token> 0, <answer> = 
.mask <token> 0xff, <answer> = 
<token> = 0x66, <answer> .def 
}, <token> <answer> { 
<token> = 0x25, <answer> .id 
.name = <token> <answer> "vdetper", 
.swgroup = <token> <answer> TEGRA_SWGROUP_VDE, 
<token> = { <answer> .regs 
.smmu <token> { <answer> = 
.reg <token> 0x22c, <answer> = 
.bit <token> 5, <answer> = 
<token> = { <answer> .la 
<token> = 0x358, <answer> .reg 
.shift = <token> <answer> 16, 
.mask = <token> <answer> 0xff, 
.def = <token> <answer> 0xa5, 
<token> { <answer> }, 
.id <token> 0x26, <answer> = 
.name = <token> <answer> "mpcorelpr", 
.swgroup = <token> <answer> TEGRA_SWGROUP_MPCORELP, 
.regs = <token> <answer> { 
.la = <token> <answer> { 
.reg <token> 0x324, <answer> = 
.shift = <token> <answer> 0, 
<token> = 0xff, <answer> .mask 
.def <token> 0x04, <answer> = 
<token> { <answer> }, 
.id = <token> <answer> 0x27, 
.name <token> "mpcorer", <answer> = 
.swgroup = <token> <answer> TEGRA_SWGROUP_MPCORE, 
.regs <token> { <answer> = 
.la <token> { <answer> = 
<token> = 0x320, <answer> .reg 
.shift <token> 0, <answer> = 
<token> = 0xff, <answer> .mask 
.def = <token> <answer> 0x04, 
<token> { <answer> }, 
.id = <token> <answer> 0x2b, 
.name = <token> <answer> "msencswr", 
.swgroup <token> TEGRA_SWGROUP_MSENC, <answer> = 
.regs = <token> <answer> { 
<token> = { <answer> .smmu 
.reg = <token> <answer> 0x22c, 
<token> = 11, <answer> .bit 
.la <token> { <answer> = 
.reg = <token> <answer> 0x328, 
.shift <token> 16, <answer> = 
<token> = 0xff, <answer> .mask 
<token> = 0x80, <answer> .def 
<token> { <answer> }, 
.id = <token> <answer> 0x31, 
.name <token> "afiw", <answer> = 
.swgroup = <token> <answer> TEGRA_SWGROUP_AFI, 
<token> = { <answer> .regs 
.smmu = <token> <answer> { 
<token> = 0x22c, <answer> .reg 
<token> = 17, <answer> .bit 
.la = <token> <answer> { 
.reg = <token> <answer> 0x2e0, 
<token> = 16, <answer> .shift 
.mask <token> 0xff, <answer> = 
.def <token> 0x80, <answer> = 
}, <token> <answer> { 
.id <token> 0x32, <answer> = 
.name = <token> <answer> "avpcarm7w", 
<token> = TEGRA_SWGROUP_AVPC, <answer> .swgroup 
.regs <token> { <answer> = 
.smmu = <token> <answer> { 
<token> = 0x22c, <answer> .reg 
<token> = 18, <answer> .bit 
.la = <token> <answer> { 
<token> = 0x2e4, <answer> .reg 
.shift <token> 16, <answer> = 
.mask = <token> <answer> 0xff, 
.def = <token> <answer> 0x80, 
}, <token> <answer> { 
<token> = 0x35, <answer> .id 
.name = <token> <answer> "hdaw", 
.swgroup <token> TEGRA_SWGROUP_HDA, <answer> = 
<token> = { <answer> .regs 
<token> = { <answer> .smmu 
.reg = <token> <answer> 0x22c, 
<token> = 21, <answer> .bit 
.la <token> { <answer> = 
.reg <token> 0x318, <answer> = 
.shift = <token> <answer> 16, 
.mask <token> 0xff, <answer> = 
<token> = 0x80, <answer> .def 
}, <token> <answer> { 
.id <token> 0x36, <answer> = 
<token> = "host1xw", <answer> .name 
.swgroup = <token> <answer> TEGRA_SWGROUP_HC, 
.regs <token> { <answer> = 
.smmu = <token> <answer> { 
.reg <token> 0x22c, <answer> = 
.bit <token> 22, <answer> = 
.la <token> { <answer> = 
<token> = 0x314, <answer> .reg 
<token> = 0, <answer> .shift 
<token> = 0xff, <answer> .mask 
.def <token> 0x80, <answer> = 
<token> { <answer> }, 
.id = <token> <answer> 0x38, 
.name <token> "mpcorelpw", <answer> = 
.swgroup <token> TEGRA_SWGROUP_MPCORELP, <answer> = 
.regs = <token> <answer> { 
.la = <token> <answer> { 
<token> = 0x324, <answer> .reg 
.shift = <token> <answer> 16, 
<token> = 0xff, <answer> .mask 
.def = <token> <answer> 0x80, 
}, <token> <answer> { 
.id <token> 0x39, <answer> = 
.name = <token> <answer> "mpcorew", 
<token> = TEGRA_SWGROUP_MPCORE, <answer> .swgroup 
<token> = { <answer> .regs 
.la = <token> <answer> { 
<token> = 0x320, <answer> .reg 
<token> = 16, <answer> .shift 
<token> = 0xff, <answer> .mask 
.def <token> 0x80, <answer> = 
<token> { <answer> }, 
.id = <token> <answer> 0x3b, 
<token> = "ppcsahbdmaw", <answer> .name 
<token> = TEGRA_SWGROUP_PPCS, <answer> .swgroup 
.regs = <token> <answer> { 
.smmu <token> { <answer> = 
.reg <token> 0x22c, <answer> = 
.bit = <token> <answer> 27, 
<token> = { <answer> .la 
.reg = <token> <answer> 0x348, 
<token> = 0, <answer> .shift 
<token> = 0xff, <answer> .mask 
<token> = 0x80, <answer> .def 
<token> { <answer> }, 
<token> = 0x3c, <answer> .id 
.name = <token> <answer> "ppcsahbslvw", 
<token> = TEGRA_SWGROUP_PPCS, <answer> .swgroup 
.regs = <token> <answer> { 
<token> = { <answer> .smmu 
.reg = <token> <answer> 0x22c, 
.bit = <token> <answer> 28, 
.la <token> { <answer> = 
<token> = 0x348, <answer> .reg 
.shift = <token> <answer> 16, 
.mask = <token> <answer> 0xff, 
<token> = 0x80, <answer> .def 
}, <token> <answer> { 
.id <token> 0x3d, <answer> = 
.name <token> "sataw", <answer> = 
<token> = TEGRA_SWGROUP_SATA, <answer> .swgroup 
.regs = <token> <answer> { 
.smmu <token> { <answer> = 
<token> = 0x22c, <answer> .reg 
<token> = 29, <answer> .bit 
.la <token> { <answer> = 
.reg <token> 0x350, <answer> = 
<token> = 16, <answer> .shift 
.mask <token> 0xff, <answer> = 
<token> = 0x65, <answer> .def 
<token> { <answer> }, 
<token> = 0x3e, <answer> .id 
.name = <token> <answer> "vdebsevw", 
.swgroup = <token> <answer> TEGRA_SWGROUP_VDE, 
.regs = <token> <answer> { 
<token> = { <answer> .smmu 
.reg = <token> <answer> 0x22c, 
<token> = 30, <answer> .bit 
.la <token> { <answer> = 
.reg <token> 0x35c, <answer> = 
.shift = <token> <answer> 0, 
.mask <token> 0xff, <answer> = 
.def = <token> <answer> 0x80, 
}, <token> <answer> { 
<token> = 0x3f, <answer> .id 
<token> = "vdedbgw", <answer> .name 
.swgroup <token> TEGRA_SWGROUP_VDE, <answer> = 
.regs <token> { <answer> = 
.smmu = <token> <answer> { 
.reg <token> 0x22c, <answer> = 
.bit <token> 31, <answer> = 
.la <token> { <answer> = 
.reg <token> 0x35c, <answer> = 
<token> = 16, <answer> .shift 
.mask = <token> <answer> 0xff, 
<token> = 0x80, <answer> .def 
<token> { <answer> }, 
.id <token> 0x40, <answer> = 
<token> = "vdembew", <answer> .name 
.swgroup <token> TEGRA_SWGROUP_VDE, <answer> = 
.regs <token> { <answer> = 
<token> = { <answer> .smmu 
.reg = <token> <answer> 0x230, 
.bit <token> 0, <answer> = 
<token> = { <answer> .la 
.reg <token> 0x360, <answer> = 
.shift <token> 0, <answer> = 
.mask <token> 0xff, <answer> = 
.def <token> 0x80, <answer> = 
}, <token> <answer> { 
.id = <token> <answer> 0x41, 
<token> = "vdetpmw", <answer> .name 
.swgroup <token> TEGRA_SWGROUP_VDE, <answer> = 
<token> = { <answer> .regs 
.smmu = <token> <answer> { 
.reg = <token> <answer> 0x230, 
.bit <token> 1, <answer> = 
<token> = { <answer> .la 
.reg = <token> <answer> 0x360, 
.shift = <token> <answer> 16, 
<token> = 0xff, <answer> .mask 
<token> = 0x80, <answer> .def 
<token> { <answer> }, 
.id = <token> <answer> 0x44, 
.name <token> "ispra", <answer> = 
.swgroup = <token> <answer> TEGRA_SWGROUP_ISP2, 
.regs = <token> <answer> { 
<token> = { <answer> .smmu 
.reg = <token> <answer> 0x230, 
.bit <token> 4, <answer> = 
.la = <token> <answer> { 
.reg = <token> <answer> 0x370, 
<token> = 0, <answer> .shift 
.mask = <token> <answer> 0xff, 
<token> = 0x18, <answer> .def 
}, <token> <answer> { 
<token> = 0x46, <answer> .id 
.name = <token> <answer> "ispwa", 
.swgroup <token> TEGRA_SWGROUP_ISP2, <answer> = 
.regs = <token> <answer> { 
.smmu = <token> <answer> { 
.reg = <token> <answer> 0x230, 
.bit <token> 6, <answer> = 
.la <token> { <answer> = 
<token> = 0x374, <answer> .reg 
<token> = 0, <answer> .shift 
<token> = 0xff, <answer> .mask 
<token> = 0x80, <answer> .def 
<token> { <answer> }, 
.id <token> 0x47, <answer> = 
.name = <token> <answer> "ispwb", 
.swgroup = <token> <answer> TEGRA_SWGROUP_ISP2, 
.regs = <token> <answer> { 
.smmu <token> { <answer> = 
<token> = 0x230, <answer> .reg 
.bit <token> 7, <answer> = 
<token> = { <answer> .la 
.reg = <token> <answer> 0x374, 
.shift <token> 16, <answer> = 
.mask = <token> <answer> 0xff, 
.def = <token> <answer> 0x80, 
<token> { <answer> }, 
.id = <token> <answer> 0x4a, 
.name <token> "xusb_hostr", <answer> = 
.swgroup = <token> <answer> TEGRA_SWGROUP_XUSB_HOST, 
<token> = { <answer> .regs 
<token> = { <answer> .smmu 
.reg <token> 0x230, <answer> = 
.bit = <token> <answer> 10, 
.la = <token> <answer> { 
.reg = <token> <answer> 0x37c, 
<token> = 0, <answer> .shift 
<token> = 0xff, <answer> .mask 
.def = <token> <answer> 0x39, 
}, <token> <answer> { 
.id <token> 0x4b, <answer> = 
.name <token> "xusb_hostw", <answer> = 
<token> = TEGRA_SWGROUP_XUSB_HOST, <answer> .swgroup 
.regs <token> { <answer> = 
.smmu <token> { <answer> = 
.reg = <token> <answer> 0x230, 
.bit <token> 11, <answer> = 
.la <token> { <answer> = 
.reg <token> 0x37c, <answer> = 
.shift = <token> <answer> 16, 
.mask = <token> <answer> 0xff, 
.def = <token> <answer> 0x80, 
<token> { <answer> }, 
<token> = 0x4c, <answer> .id 
<token> = "xusb_devr", <answer> .name 
<token> = TEGRA_SWGROUP_XUSB_DEV, <answer> .swgroup 
.regs <token> { <answer> = 
<token> = { <answer> .smmu 
.reg <token> 0x230, <answer> = 
.bit <token> 12, <answer> = 
.la <token> { <answer> = 
.reg <token> 0x380, <answer> = 
.shift = <token> <answer> 0, 
.mask = <token> <answer> 0xff, 
.def = <token> <answer> 0x39, 
<token> { <answer> }, 
.id = <token> <answer> 0x4d, 
.name <token> "xusb_devw", <answer> = 
.swgroup <token> TEGRA_SWGROUP_XUSB_DEV, <answer> = 
.regs <token> { <answer> = 
.smmu <token> { <answer> = 
.reg <token> 0x230, <answer> = 
<token> = 13, <answer> .bit 
.la <token> { <answer> = 
<token> = 0x380, <answer> .reg 
<token> = 16, <answer> .shift 
<token> = 0xff, <answer> .mask 
.def <token> 0x80, <answer> = 
<token> { <answer> }, 
<token> = 0x4e, <answer> .id 
<token> = "isprab", <answer> .name 
.swgroup = <token> <answer> TEGRA_SWGROUP_ISP2B, 
<token> = { <answer> .regs 
.smmu <token> { <answer> = 
<token> = 0x230, <answer> .reg 
.bit = <token> <answer> 14, 
.la <token> { <answer> = 
.reg <token> 0x384, <answer> = 
.shift = <token> <answer> 0, 
<token> = 0xff, <answer> .mask 
<token> = 0x18, <answer> .def 
}, <token> <answer> { 
.id = <token> <answer> 0x50, 
.name = <token> <answer> "ispwab", 
<token> = TEGRA_SWGROUP_ISP2B, <answer> .swgroup 
.regs = <token> <answer> { 
.smmu = <token> <answer> { 
.reg = <token> <answer> 0x230, 
.bit = <token> <answer> 16, 
<token> = { <answer> .la 
.reg = <token> <answer> 0x388, 
