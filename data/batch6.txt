<token> <linux/init.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/clkdev.h> 
<token> <asm/clock.h> <answer> #include 
#include <token> <answer> <asm/freq.h> 
static struct clk <token> = { <answer> extal_clk 
.rate <token> 16666666, <answer> = 
static unsigned long pll_recalc(struct <token> *clk) <answer> clk 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
<token> "powerdomain.h" <answer> #include 
<token> "prcm-common.h" <answer> #include 
#include <token> <answer> "prcm44xx.h" 
#include <token> <answer> "prm54xx.h" 
<token> "prcm_mpu54xx.h" <answer> #include 
<token> "priv.h" <answer> #include 
#include <token> <answer> <core/gpuobj.h> 
<token> <core/object.h> <answer> #include 
<token> <subdev/timer.h> <answer> #include 
<token> <nvif/class.h> <answer> #include 
<token> int <answer> static 
nv50_mpeg_cclass_bind(struct nvkm_object *object, <token> nvkm_gpuobj *parent, <answer> struct 
int align, struct nvkm_gpuobj <token> <answer> **pgpuobj) 
<token> ret = nvkm_gpuobj_new(object->engine->subdev.device, 128 * 4, <answer> int 
align, true, parent, <token> <answer> pgpuobj); 
if (ret == <token> { <answer> 0) 
nvkm_wo32(*pgpuobj, 0x70, <token> <answer> 0x00801ec1); 
<token> 0x7c, 0x0000037c); <answer> nvkm_wo32(*pgpuobj, 
return <token> <answer> ret; 
<token> struct nvkm_object_func <answer> const 
nv50_mpeg_cclass = <token> <answer> { 
.bind = <token> <answer> nv50_mpeg_cclass_bind, 
nv50_mpeg_intr(struct <token> *mpeg) <answer> nvkm_engine 
struct nvkm_subdev *subdev = <token> <answer> &mpeg->subdev; 
struct <token> *device = subdev->device; <answer> nvkm_device 
<token> stat = nvkm_rd32(device, 0x00b100); <answer> u32 
<token> type = nvkm_rd32(device, 0x00b230); <answer> u32 
<token> mthd = nvkm_rd32(device, 0x00b234); <answer> u32 
<token> data = nvkm_rd32(device, 0x00b238); <answer> u32 
<token> show = stat; <answer> u32 
if (stat & <token> { <answer> 0x01000000) 
<token> _GNU_SOURCE <answer> #define 
#include <token> <answer> <stdio.h> 
<token> <stdlib.h> <answer> #include 
#include <token> <answer> <unistd.h> 
#include <token> <answer> <inttypes.h> 
#include <token> <answer> <sched.h> 
<token> <sys/types.h> <answer> #include 
<token> <signal.h> <answer> #include 
<token> "tm.h" <answer> #include 
int <token> <answer> tm_poison_test(void) 
<token> cpu, pid; <answer> int 
<token> cpuset; <answer> cpu_set_t 
uint64_t <token> = 0xdeadbeefc0dec0fe; <answer> poison 
uint64_t unknown = <token> <answer> 0; 
bool <token> = false; <answer> fail_fp 
bool <token> = false; <answer> fail_vr 
cpu <token> pick_online_cpu(); <answer> = 
FAIL_IF(cpu <token> 0); <answer> < 
CPU_SET(cpu, <token> <answer> &cpuset); 
<token> sizeof(cpuset), &cpuset) != 0); <answer> FAIL_IF(sched_setaffinity(0, 
pid = <token> <answer> fork(); 
if <token> { <answer> (!pid) 
while <token> { <answer> (1) 
asm <token> <answer> ( 
"mtvsrd <token> %[poison];" <answer> 31, 
"mtvsrd 63, <token> <answer> %[poison];" 
<token> : [poison] "r" (poison) : ); <answer> : 
<token> ( <answer> asm 
" li 3, 0x1 <token> <answer> ;" 
" li <token> 0x1 ;" <answer> 4, 
" mtvsrd 31, <token> ;" <answer> 4 
<token> lis 5, 14 ;" <answer> " 
<token> ori 5, 5, 19996 ;" <answer> " 
" sldi 5, 5, <token> ;" <answer> 16 
" mfspr 6, <token> ;" <answer> 268 
<token> mfspr 7, 268 ;" <answer> "1: 
" subf 7, 6, 7 <token> <answer> ;" 
" cmpd <token> 5 ;" <answer> 7, 
" bgt 3f <token> <answer> ;" 
<token> tbegin. ;" <answer> " 
" <token> 1b ;" <answer> beq 
" <token> 3, 31 ;" <answer> mfvsrd 
" cmpd 3, <token> ;" <answer> 4 
" <token> 2f ;" <answer> bne 
<token> tabort. 3 ;" <answer> " 
<token> tend. ;" <answer> "2: 
"3: <token> %[unknown], 3 ;" <answer> mr 
: <token> "=r" (unknown) <answer> [unknown] 
: "cr0", <token> "r4", "r5", "r6", "r7", "vs31" <answer> "r3", 
fail_fp <token> unknown != 0x1; <answer> = 
<token> (fail_fp) <answer> if 
printf("Unknown value %#"PRIx64" <token> into f31!\n", unknown); <answer> leaked 
printf("Good, no poison or leaked value <token> FP registers\n"); <answer> into 
asm <token> <answer> ( 
" li 3, 0x1 <token> <answer> ;" 
" li 4, <token> ;" <answer> 0x1 
" mtvsrd <token> 4 ;" <answer> 63, 
" <token> 5, 14 ;" <answer> lis 
" ori 5, <token> 19996 ;" <answer> 5, 
" sldi <token> 5, 16 ;" <answer> 5, 
" mfspr 6, <token> ;" <answer> 268 
<token> mfspr 7, 268 ;" <answer> "1: 
" <token> 7, 6, 7 ;" <answer> subf 
" cmpd <token> 5 ;" <answer> 7, 
" <token> 3f ;" <answer> bgt 
<token> tbegin. ;" <answer> " 
" <token> 1b ;" <answer> beq 
" mfvsrd <token> 63 ;" <answer> 3, 
" cmpd 3, 4 <token> <answer> ;" 
<token> bne 2f ;" <answer> " 
" tabort. 3 <token> <answer> ;" 
"2: tend. <token> <answer> ;" 
<token> mr %[unknown], 3 ;" <answer> "3: 
<token> [unknown] "=r" (unknown) <answer> : 
: "cr0", "r3", "r4", "r5", "r6", <token> "vs63" <answer> "r7", 
fail_vr <token> unknown != 0x1; <answer> = 
<token> (fail_vr) <answer> if 
printf("Unknown value %#"PRIx64" leaked into <token> unknown); <answer> vr31!\n", 
printf("Good, no poison <token> leaked value into VEC registers\n"); <answer> or 
<token> SIGKILL); <answer> kill(pid, 
return (fail_fp <token> fail_vr); <answer> | 
int main(int argc, <token> *argv[]) <answer> char 
<token> <linux/clk-provider.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <dt-bindings/clock/mt8186-clk.h> 
<token> "clk-gate.h" <answer> #include 
<token> "clk-mtk.h" <answer> #include 
static const <token> mtk_gate_regs img_cg_regs = { <answer> struct 
.set_ofs = <token> <answer> 0x4, 
.clr_ofs = <token> <answer> 0x8, 
.sta_ofs = <token> <answer> 0x0, 
#define GATE_IMG(_id, <token> _parent, _shift) \ <answer> _name, 
<token> _name, _parent, &img_cg_regs, _shift, &mtk_clk_gate_ops_setclr) <answer> GATE_MTK(_id, 
<token> const struct mtk_gate img1_clks[] = { <answer> static 
<token> "img1_larb9_img1", "top_img1", 0), <answer> GATE_IMG(CLK_IMG1_LARB9_IMG1, 
GATE_IMG(CLK_IMG1_LARB10_IMG1, "img1_larb10_img1", "top_img1", <token> <answer> 1), 
<token> "img1_dip", "top_img1", 2), <answer> GATE_IMG(CLK_IMG1_DIP, 
GATE_IMG(CLK_IMG1_GALS_IMG1, "img1_gals_img1", <token> 12), <answer> "top_img1", 
static const struct <token> img2_clks[] = { <answer> mtk_gate 
GATE_IMG(CLK_IMG2_LARB9_IMG2, "img2_larb9_img2", <token> 0), <answer> "top_img1", 
GATE_IMG(CLK_IMG2_LARB10_IMG2, <token> "top_img1", 1), <answer> "img2_larb10_img2", 
GATE_IMG(CLK_IMG2_MFB, "img2_mfb", <token> 6), <answer> "top_img1", 
GATE_IMG(CLK_IMG2_WPE, <token> "top_img1", 7), <answer> "img2_wpe", 
GATE_IMG(CLK_IMG2_MSS, <token> "top_img1", 8), <answer> "img2_mss", 
<token> "img2_gals_img2", "top_img1", 12), <answer> GATE_IMG(CLK_IMG2_GALS_IMG2, 
static const <token> mtk_clk_desc img1_desc = { <answer> struct 
.clks <token> img1_clks, <answer> = 
<token> = ARRAY_SIZE(img1_clks), <answer> .num_clks 
static const struct mtk_clk_desc img2_desc <token> { <answer> = 
.clks = <token> <answer> img2_clks, 
<token> = ARRAY_SIZE(img2_clks), <answer> .num_clks 
static const struct of_device_id <token> = { <answer> of_match_clk_mt8186_img[] 
<token> = "mediatek,mt8186-imgsys1", <answer> .compatible 
.data <token> &img1_desc, <answer> = 
}, <token> <answer> { 
.compatible = <token> <answer> "mediatek,mt8186-imgsys2", 
.data = <token> <answer> &img2_desc, 
<token> { <answer> }, 
#include <token> <answer> <linux/clk.h> 
<token> <linux/device.h> <answer> #include 
#include <token> <answer> <linux/math64.h> 
<token> <linux/mod_devicetable.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/pm_runtime.h> <answer> #include 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> <sound/core.h> 
#include <token> <answer> <sound/pcm_params.h> 
<token> <sound/soc.h> <answer> #include 
<token> "tegra210_dmic.h" <answer> #include 
<token> "tegra_cif.h" <answer> #include 
<token> const struct reg_default tegra210_dmic_reg_defaults[] = { <answer> static 
<token> TEGRA210_DMIC_TX_INT_MASK, 0x00000001 }, <answer> { 
{ TEGRA210_DMIC_TX_CIF_CTRL, <token> }, <answer> 0x00007700 
{ <token> 0x1 }, <answer> TEGRA210_DMIC_CG, 
<token> TEGRA210_DMIC_CTRL, 0x00000301 }, <answer> { 
clk_rate = <token> << dmic->osr_val) * srate; <answer> (DMIC_OSR_FACTOR 
err = <token> clk_rate); <answer> clk_set_rate(dmic->clk_dmic, 
if <token> { <answer> (err) 
dev_err(dai->dev, "can't <token> DMIC clock rate %u, err: %d\n", <answer> set 
<token> err); <answer> clk_rate, 
<token> err; <answer> return 
if <token> <answer> (dmic->boost_gain) 
gain_q23 = div_u64(gain_q23 * dmic->boost_gain, <token> <answer> 100); 
regmap_write(dmic->regmap, <token> <answer> TEGRA210_DMIC_LP_FILTER_GAIN, 
(unsigned <token> <answer> int)gain_q23); 
<token> (params_format(params)) { <answer> switch 
case <token> <answer> SNDRV_PCM_FORMAT_S16_LE: 
cif_conf.audio_bits <token> TEGRA_ACIF_BITS_16; <answer> = 
case <token> <answer> SNDRV_PCM_FORMAT_S32_LE: 
cif_conf.audio_bits = <token> <answer> TEGRA_ACIF_BITS_32; 
<token> "unsupported format!\n"); <answer> dev_err(dai->dev, 
return <token> <answer> -EOPNOTSUPP; 
<token> = TEGRA_ACIF_BITS_24; <answer> cif_conf.client_bits 
cif_conf.mono_conv <token> dmic->mono_to_stereo; <answer> = 
<token> = dmic->stereo_to_mono; <answer> cif_conf.stereo_conv 
tegra_set_cif(dmic->regmap, TEGRA210_DMIC_TX_CIF_CTRL, <token> <answer> &cif_conf); 
return <token> <answer> 0; 
static int tegra210_dmic_get_boost_gain(struct snd_kcontrol <token> <answer> *kcontrol, 
<token> snd_ctl_elem_value *ucontrol) <answer> struct 
struct <token> *comp = snd_soc_kcontrol_component(kcontrol); <answer> snd_soc_component 
struct tegra210_dmic <token> = snd_soc_component_get_drvdata(comp); <answer> *dmic 
ucontrol->value.integer.value[0] <token> dmic->boost_gain; <answer> = 
return <token> <answer> 0; 
<token> int tegra210_dmic_put_boost_gain(struct snd_kcontrol *kcontrol, <answer> static 
struct snd_ctl_elem_value <token> <answer> *ucontrol) 
struct snd_soc_component <token> = snd_soc_kcontrol_component(kcontrol); <answer> *comp 
<token> tegra210_dmic *dmic = snd_soc_component_get_drvdata(comp); <answer> struct 
<token> value = ucontrol->value.integer.value[0]; <answer> int 
if (value == <token> <answer> dmic->boost_gain) 
<token> 0; <answer> return 
dmic->boost_gain = <token> <answer> value; 
return <token> <answer> 1; 
static <token> tegra210_dmic_get_ch_select(struct snd_kcontrol *kcontrol, <answer> int 
struct snd_ctl_elem_value <token> <answer> *ucontrol) 
struct snd_soc_component *comp <token> snd_soc_kcontrol_component(kcontrol); <answer> = 
struct tegra210_dmic <token> = snd_soc_component_get_drvdata(comp); <answer> *dmic 
ucontrol->value.enumerated.item[0] <token> dmic->ch_select; <answer> = 
<token> 0; <answer> return 
<token> int tegra210_dmic_put_ch_select(struct snd_kcontrol *kcontrol, <answer> static 
struct <token> *ucontrol) <answer> snd_ctl_elem_value 
<token> snd_soc_component *comp = snd_soc_kcontrol_component(kcontrol); <answer> struct 
struct tegra210_dmic <token> = snd_soc_component_get_drvdata(comp); <answer> *dmic 
unsigned int value = <token> <answer> ucontrol->value.enumerated.item[0]; 
if (value == <token> <answer> dmic->ch_select) 
<token> 0; <answer> return 
dmic->ch_select <token> value; <answer> = 
<token> 1; <answer> return 
static int <token> snd_kcontrol *kcontrol, <answer> tegra210_dmic_get_mono_to_stereo(struct 
<token> snd_ctl_elem_value *ucontrol) <answer> struct 
struct snd_soc_component *comp <token> snd_soc_kcontrol_component(kcontrol); <answer> = 
struct tegra210_dmic *dmic = <token> <answer> snd_soc_component_get_drvdata(comp); 
ucontrol->value.enumerated.item[0] = <token> <answer> dmic->mono_to_stereo; 
<token> 0; <answer> return 
static <token> tegra210_dmic_put_mono_to_stereo(struct snd_kcontrol *kcontrol, <answer> int 
struct <token> *ucontrol) <answer> snd_ctl_elem_value 
struct snd_soc_component *comp <token> snd_soc_kcontrol_component(kcontrol); <answer> = 
struct <token> *dmic = snd_soc_component_get_drvdata(comp); <answer> tegra210_dmic 
unsigned int <token> = ucontrol->value.enumerated.item[0]; <answer> value 
if (value <token> dmic->mono_to_stereo) <answer> == 
return <token> <answer> 0; 
<token> = value; <answer> dmic->mono_to_stereo 
<token> 1; <answer> return 
<token> int tegra210_dmic_get_stereo_to_mono(struct snd_kcontrol *kcontrol, <answer> static 
struct <token> *ucontrol) <answer> snd_ctl_elem_value 
struct snd_soc_component *comp = <token> <answer> snd_soc_kcontrol_component(kcontrol); 
struct tegra210_dmic <token> = snd_soc_component_get_drvdata(comp); <answer> *dmic 
ucontrol->value.enumerated.item[0] = <token> <answer> dmic->stereo_to_mono; 
return <token> <answer> 0; 
static <token> tegra210_dmic_put_stereo_to_mono(struct snd_kcontrol *kcontrol, <answer> int 
struct <token> *ucontrol) <answer> snd_ctl_elem_value 
struct <token> *comp = snd_soc_kcontrol_component(kcontrol); <answer> snd_soc_component 
<token> tegra210_dmic *dmic = snd_soc_component_get_drvdata(comp); <answer> struct 
<token> int value = ucontrol->value.enumerated.item[0]; <answer> unsigned 
if <token> == dmic->stereo_to_mono) <answer> (value 
return <token> <answer> 0; 
dmic->stereo_to_mono = <token> <answer> value; 
return <token> <answer> 1; 
<token> int tegra210_dmic_get_osr_val(struct snd_kcontrol *kcontrol, <answer> static 
<token> snd_ctl_elem_value *ucontrol) <answer> struct 
struct snd_soc_component *comp <token> snd_soc_kcontrol_component(kcontrol); <answer> = 
struct <token> *dmic = snd_soc_component_get_drvdata(comp); <answer> tegra210_dmic 
ucontrol->value.enumerated.item[0] = <token> <answer> dmic->osr_val; 
<token> 0; <answer> return 
static int tegra210_dmic_put_osr_val(struct <token> *kcontrol, <answer> snd_kcontrol 
struct <token> *ucontrol) <answer> snd_ctl_elem_value 
<token> snd_soc_component *comp = snd_soc_kcontrol_component(kcontrol); <answer> struct 
struct tegra210_dmic *dmic = <token> <answer> snd_soc_component_get_drvdata(comp); 
unsigned int value <token> ucontrol->value.enumerated.item[0]; <answer> = 
if (value == <token> <answer> dmic->osr_val) 
<token> 0; <answer> return 
<token> = value; <answer> dmic->osr_val 
return <token> <answer> 1; 
static int tegra210_dmic_get_pol_sel(struct snd_kcontrol <token> <answer> *kcontrol, 
<token> snd_ctl_elem_value *ucontrol) <answer> struct 
struct snd_soc_component *comp = <token> <answer> snd_soc_kcontrol_component(kcontrol); 
struct tegra210_dmic *dmic = <token> <answer> snd_soc_component_get_drvdata(comp); 
<token> = dmic->lrsel; <answer> ucontrol->value.enumerated.item[0] 
return <token> <answer> 0; 
<token> int tegra210_dmic_put_pol_sel(struct snd_kcontrol *kcontrol, <answer> static 
<token> snd_ctl_elem_value *ucontrol) <answer> struct 
<token> snd_soc_component *comp = snd_soc_kcontrol_component(kcontrol); <answer> struct 
struct tegra210_dmic *dmic <token> snd_soc_component_get_drvdata(comp); <answer> = 
unsigned int value = <token> <answer> ucontrol->value.enumerated.item[0]; 
if (value <token> dmic->lrsel) <answer> == 
<token> 0; <answer> return 
dmic->lrsel <token> value; <answer> = 
return <token> <answer> 1; 
static const struct snd_soc_dai_ops tegra210_dmic_dai_ops <token> { <answer> = 
.hw_params <token> tegra210_dmic_hw_params, <answer> = 
<token> struct snd_soc_dai_driver tegra210_dmic_dais[] = { <answer> static 
<token> = "DMIC-CIF", <answer> .name 
.capture = <token> <answer> { 
<token> = "CIF-Capture", <answer> .stream_name 
.channels_min <token> 1, <answer> = 
<token> = 2, <answer> .channels_max 
.rates <token> SNDRV_PCM_RATE_8000_48000, <answer> = 
.formats = <token> | <answer> SNDRV_PCM_FMTBIT_S16_LE 
<token> = "DMIC-DAP", <answer> .name 
<token> = { <answer> .capture 
.stream_name <token> "DAP-Capture", <answer> = 
<token> = 1, <answer> .channels_min 
<token> = 2, <answer> .channels_max 
<token> = SNDRV_PCM_RATE_8000_48000, <answer> .rates 
.formats = <token> | <answer> SNDRV_PCM_FMTBIT_S16_LE 
<token> = &tegra210_dmic_dai_ops, <answer> .ops 
.symmetric_rate <token> 1, <answer> = 
static <token> struct snd_soc_dapm_widget tegra210_dmic_widgets[] = { <answer> const 
SND_SOC_DAPM_AIF_OUT("TX", NULL, 0, <token> 0, 0), <answer> TEGRA210_DMIC_ENABLE, 
<token> NULL), <answer> SND_SOC_DAPM_MIC("MIC", 
static const struct snd_soc_dapm_route <token> = { <answer> tegra210_dmic_routes[] 
{ "XBAR-RX", NULL, <token> }, <answer> "XBAR-Capture" 
{ "XBAR-Capture", NULL, <token> }, <answer> "CIF-Capture" 
{ "CIF-Capture", <token> "TX" }, <answer> NULL, 
{ <token> NULL, "DAP-Capture" }, <answer> "TX", 
{ <token> NULL, "MIC" }, <answer> "DAP-Capture", 
static const char <token> const tegra210_dmic_ch_select[] = { <answer> * 
<token> "Right", "Stereo", <answer> "Left", 
static const struct soc_enum tegra210_dmic_ch_enum <token> <answer> = 
SOC_ENUM_SINGLE(0, 0, <token> <answer> ARRAY_SIZE(tegra210_dmic_ch_select), 
static const char <token> const tegra210_dmic_mono_conv_text[] = { <answer> * 
"Zero", <token> <answer> "Copy", 
static const char * const tegra210_dmic_stereo_conv_text[] <token> { <answer> = 
<token> "CH1", "AVG", <answer> "CH0", 
<token> const struct soc_enum tegra210_dmic_mono_conv_enum = <answer> static 
<token> 0, ARRAY_SIZE(tegra210_dmic_mono_conv_text), <answer> SOC_ENUM_SINGLE(0, 
static const struct soc_enum tegra210_dmic_stereo_conv_enum <token> <answer> = 
SOC_ENUM_SINGLE(0, 0, <token> <answer> ARRAY_SIZE(tegra210_dmic_stereo_conv_text), 
static const char * const tegra210_dmic_osr_text[] <token> { <answer> = 
"OSR_64", "OSR_128", <token> <answer> "OSR_256", 
static const struct soc_enum <token> = <answer> tegra210_dmic_osr_enum 
<token> 0, ARRAY_SIZE(tegra210_dmic_osr_text), <answer> SOC_ENUM_SINGLE(0, 
static const char * <token> tegra210_dmic_lrsel_text[] = { <answer> const 
<token> "Right", <answer> "Left", 
static const struct soc_enum <token> = <answer> tegra210_dmic_lrsel_enum 
SOC_ENUM_SINGLE(0, <token> ARRAY_SIZE(tegra210_dmic_lrsel_text), <answer> 0, 
static const struct <token> tegra210_dmic_controls[] = { <answer> snd_kcontrol_new 
SOC_SINGLE_EXT("Boost Gain Volume", 0, 0, <token> 0, <answer> MAX_BOOST_GAIN, 
SOC_ENUM_EXT("Channel <token> tegra210_dmic_ch_enum, <answer> Select", 
tegra210_dmic_get_ch_select, <token> <answer> tegra210_dmic_put_ch_select), 
SOC_ENUM_EXT("Mono To <token> <answer> Stereo", 
SOC_ENUM_EXT("Stereo To <token> <answer> Mono", 
SOC_ENUM_EXT("OSR Value", <token> <answer> tegra210_dmic_osr_enum, 
<token> tegra210_dmic_put_osr_val), <answer> tegra210_dmic_get_osr_val, 
SOC_ENUM_EXT("LR Polarity <token> tegra210_dmic_lrsel_enum, <answer> Select", 
tegra210_dmic_get_pol_sel, <token> <answer> tegra210_dmic_put_pol_sel), 
static const struct snd_soc_component_driver <token> = { <answer> tegra210_dmic_compnt 
<token> = tegra210_dmic_widgets, <answer> .dapm_widgets 
.num_dapm_widgets = <token> <answer> ARRAY_SIZE(tegra210_dmic_widgets), 
.dapm_routes = <token> <answer> tegra210_dmic_routes, 
.num_dapm_routes = <token> <answer> ARRAY_SIZE(tegra210_dmic_routes), 
.controls = <token> <answer> tegra210_dmic_controls, 
.num_controls = <token> <answer> ARRAY_SIZE(tegra210_dmic_controls), 
static bool <token> device *dev, unsigned int reg) <answer> tegra210_dmic_wr_reg(struct 
switch (reg) <token> <answer> { 
case TEGRA210_DMIC_TX_INT_MASK ... <token> <answer> TEGRA210_DMIC_TX_CIF_CTRL: 
case TEGRA210_DMIC_ENABLE <token> TEGRA210_DMIC_CG: <answer> ... 
case <token> <answer> TEGRA210_DMIC_CTRL: 
case <token> <answer> TEGRA210_DMIC_DBG_CTRL: 
<token> TEGRA210_DMIC_DCR_BIQUAD_0_COEF_4 ... TEGRA210_DMIC_LP_BIQUAD_1_COEF_4: <answer> case 
return <token> <answer> true; 
<token> false; <answer> return 
static bool tegra210_dmic_rd_reg(struct device *dev, <token> int reg) <answer> unsigned 
if (tegra210_dmic_wr_reg(dev, <token> <answer> reg)) 
return <token> <answer> true; 
<token> (reg) { <answer> switch 
case <token> <answer> TEGRA210_DMIC_TX_STATUS: 
<token> TEGRA210_DMIC_TX_INT_STATUS: <answer> case 
case <token> <answer> TEGRA210_DMIC_STATUS: 
case <token> <answer> TEGRA210_DMIC_INT_STATUS: 
return <token> <answer> true; 
return <token> <answer> false; 
static <token> tegra210_dmic_volatile_reg(struct device *dev, unsigned int reg) <answer> bool 
<token> (reg) { <answer> switch 
case <token> <answer> TEGRA210_DMIC_TX_STATUS: 
<token> TEGRA210_DMIC_TX_INT_STATUS: <answer> case 
<token> TEGRA210_DMIC_TX_INT_SET: <answer> case 
case <token> <answer> TEGRA210_DMIC_SOFT_RESET: 
case <token> <answer> TEGRA210_DMIC_STATUS: 
<token> TEGRA210_DMIC_INT_STATUS: <answer> case 
<token> true; <answer> return 
<token> false; <answer> return 
static const struct regmap_config <token> = { <answer> tegra210_dmic_regmap_config 
.reg_bits <token> 32, <answer> = 
<token> = 4, <answer> .reg_stride 
<token> = 32, <answer> .val_bits 
<token> = TEGRA210_DMIC_LP_BIQUAD_1_COEF_4, <answer> .max_register 
<token> = tegra210_dmic_wr_reg, <answer> .writeable_reg 
<token> = tegra210_dmic_rd_reg, <answer> .readable_reg 
.volatile_reg <token> tegra210_dmic_volatile_reg, <answer> = 
<token> = tegra210_dmic_reg_defaults, <answer> .reg_defaults 
.num_reg_defaults <token> ARRAY_SIZE(tegra210_dmic_reg_defaults), <answer> = 
.cache_type = <token> <answer> REGCACHE_FLAT, 
static int tegra210_dmic_probe(struct platform_device <token> <answer> *pdev) 
struct device <token> = &pdev->dev; <answer> *dev 
struct tegra210_dmic <token> <answer> *dmic; 
void __iomem <token> <answer> *regs; 
int <token> <answer> err; 
dmic = <token> sizeof(*dmic), GFP_KERNEL); <answer> devm_kzalloc(dev, 
<token> (!dmic) <answer> if 
<token> -ENOMEM; <answer> return 
dmic->osr_val = <token> <answer> DMIC_OSR_64; 
dmic->ch_select <token> DMIC_CH_SELECT_STEREO; <answer> = 
dmic->lrsel <token> DMIC_LRSEL_LEFT; <answer> = 
<token> = 0; <answer> dmic->boost_gain 
#include <token> <answer> <linux/netdevice.h> 
<token> "brcmu_wifi.h" <answer> #include 
#include <token> <answer> "brcmu_utils.h" 
<token> "cfg80211.h" <answer> #include 
<token> "core.h" <answer> #include 
<token> "debug.h" <answer> #include 
#include <token> <answer> "tracepoint.h" 
<token> "fweh.h" <answer> #include 
#include <token> <answer> "fwil.h" 
#include <token> <answer> "proto.h" 
<token> "bus.h" <answer> #include 
<token> "fwvid.h" <answer> #include 
struct brcmf_fweh_queue_item <token> <answer> { 
<token> list_head q; <answer> struct 
u32 <token> <answer> code; 
u8 <token> <answer> ifidx; 
<token> ifaddr[ETH_ALEN]; <answer> u8 
struct <token> emsg; <answer> brcmf_event_msg_be 
<token> datalen; <answer> u32 
u8 <token> __counted_by(datalen); <answer> data[] 
struct brcmf_fweh_event_name <token> <answer> { 
enum <token> code; <answer> brcmf_fweh_event_code 
const char <token> <answer> *name; 
<token> DEBUG <answer> #ifdef 
#define BRCMF_ENUM_DEF(id, val) <token> <answer> \ 
{ val, #id <token> <answer> }, 
const char <token> brcmf_fweh_event_code code) <answer> *brcmf_fweh_event_name(enum 
<token> i; <answer> int 
for <token> = 0; i < ARRAY_SIZE(fweh_event_names); i++) { <answer> (i 
if <token> == code) <answer> (fweh_event_names[i].code 
return <token> <answer> fweh_event_names[i].name; 
return <token> <answer> "unknown"; 
const char *brcmf_fweh_event_name(enum brcmf_fweh_event_code <token> <answer> code) 
return <token> <answer> "nodebug"; 
static <token> brcmf_fweh_queue_event(struct brcmf_fweh_info *fweh, <answer> void 
<token> brcmf_fweh_queue_item *event) <answer> struct 
ulong <token> <answer> flags; 
spin_lock_irqsave(&fweh->evt_q_lock, <token> <answer> flags); 
list_add_tail(&event->q, <token> <answer> &fweh->event_q); 
<token> flags); <answer> spin_unlock_irqrestore(&fweh->evt_q_lock, 
static <token> brcmf_fweh_call_event_handler(struct brcmf_pub *drvr, <answer> int 
<token> brcmf_if *ifp, <answer> struct 
u32 <token> <answer> fwcode, 
struct <token> *emsg, <answer> brcmf_event_msg 
void <token> <answer> *data) 
struct brcmf_fweh_info <token> <answer> *fweh; 
int err = <token> <answer> -EINVAL; 
if (ifp) <token> <answer> { 
fweh <token> ifp->drvr->fweh; <answer> = 
static void brcmf_fweh_handle_if_event(struct <token> *drvr, <answer> brcmf_pub 
struct brcmf_event_msg <token> <answer> *emsg, 
void <token> <answer> *data) 
<token> brcmf_if_event *ifevent = data; <answer> struct 
<token> brcmf_if *ifp; <answer> struct 
<token> is_p2pdev; <answer> bool 
brcmf_dbg(EVENT, "action: %u ifidx: %u bsscfgidx: %u flags: <token> role: %u\n", <answer> %u 
ifevent->action, <token> ifevent->bsscfgidx, <answer> ifevent->ifidx, 
ifevent->flags, <token> <answer> ifevent->role); 
is_p2pdev = ((ifevent->flags <token> BRCMF_E_IF_FLAG_NOIF) && <answer> & 
(ifevent->role == <token> || <answer> BRCMF_E_IF_ROLE_P2P_CLIENT 
((ifevent->role <token> BRCMF_E_IF_ROLE_STA) && <answer> == 
if <token> && (ifevent->flags & BRCMF_E_IF_FLAG_NOIF)) { <answer> (!is_p2pdev 
brcmf_dbg(EVENT, "event can <token> ignored\n"); <answer> be 
if (ifevent->ifidx >= <token> { <answer> BRCMF_MAX_IFS) 
bphy_err(drvr, "invalid interface index: <token> ifevent->ifidx); <answer> %u\n", 
ifp = <token> <answer> drvr->iflist[ifevent->bsscfgidx]; 
if <token> == BRCMF_E_IF_ADD) { <answer> (ifevent->action 
<token> "adding %s (%pM)\n", emsg->ifname, <answer> brcmf_dbg(EVENT, 
ifp = brcmf_add_if(drvr, <token> ifevent->ifidx, <answer> ifevent->bsscfgidx, 
<token> emsg->ifname, emsg->addr); <answer> is_p2pdev, 
if <token> <answer> (IS_ERR(ifp)) 
if <token> <answer> (!is_p2pdev) 
brcmf_proto_add_if(drvr, <token> <answer> ifp); 
if <token> <answer> (!drvr->fweh->evt_handler[BRCMF_E_IF]) 
<token> (brcmf_net_attach(ifp, false) < 0) <answer> if 
if (ifp && <token> == BRCMF_E_IF_CHANGE) <answer> ifevent->action 
<token> ifp); <answer> brcmf_proto_reset_if(drvr, 
brcmf_fweh_call_event_handler(drvr, <token> emsg->event_code, emsg, <answer> ifp, 
if (ifp && <token> == BRCMF_E_IF_DEL) { <answer> ifevent->action 
<token> armed = brcmf_cfg80211_vif_event_armed(drvr->config); <answer> bool 
static struct brcmf_fweh_queue_item <token> <answer> * 
brcmf_fweh_dequeue_event(struct <token> *fweh) <answer> brcmf_fweh_info 
struct brcmf_fweh_queue_item <token> = NULL; <answer> *event 
<token> flags; <answer> ulong 
spin_lock_irqsave(&fweh->evt_q_lock, <token> <answer> flags); 
<token> (!list_empty(&fweh->event_q)) { <answer> if 
event = <token> <answer> list_first_entry(&fweh->event_q, 
struct <token> q); <answer> brcmf_fweh_queue_item, 
<token> flags); <answer> spin_unlock_irqrestore(&fweh->evt_q_lock, 
return <token> <answer> event; 
<token> void brcmf_fweh_event_worker(struct work_struct *work) <answer> static 
struct <token> *drvr; <answer> brcmf_pub 
<token> brcmf_if *ifp; <answer> struct 
struct <token> *fweh; <answer> brcmf_fweh_info 
struct <token> *event; <answer> brcmf_fweh_queue_item 
<token> err = 0; <answer> int 
<token> brcmf_event_msg_be *emsg_be; <answer> struct 
struct <token> emsg; <answer> brcmf_event_msg 
fweh = container_of(work, struct brcmf_fweh_info, <token> <answer> event_work); 
drvr <token> fweh->drvr; <answer> = 
while <token> = brcmf_fweh_dequeue_event(fweh))) { <answer> ((event 
enum <token> code; <answer> brcmf_fweh_event_code 
<token> event->code, &code); <answer> brcmf_fweh_map_fwevt_code(fweh, 
brcmf_dbg(EVENT, "event %s (%u:%u) ifidx %u bsscfg <token> addr %pM\n", <answer> %u 
brcmf_fweh_event_name(code), <token> event->code, <answer> code, 
<token> event->emsg.bsscfgidx, <answer> event->emsg.ifidx, 
if (event->emsg.bsscfgidx >= BRCMF_MAX_IFS) <token> <answer> { 
bphy_err(drvr, "invalid bsscfg <token> %u\n", <answer> index: 
goto <token> <answer> event_free; 
void brcmf_fweh_p2pdev_setup(struct brcmf_if *ifp, <token> ongoing) <answer> bool 
ifp->drvr->fweh->p2pdev_setup_ongoing = <token> <answer> ongoing; 
int <token> brcmf_pub *drvr) <answer> brcmf_fweh_attach(struct 
<token> brcmf_fweh_info *fweh; <answer> struct 
int <token> <answer> err; 
err = <token> <answer> brcmf_fwvid_alloc_fweh_info(drvr); 
if (err <token> 0) <answer> < 
<token> err; <answer> return 
fweh <token> drvr->fweh; <answer> = 
<token> = drvr; <answer> fweh->drvr 
fweh->event_mask_len = DIV_ROUND_UP(fweh->num_event_codes, <token> <answer> 8); 
fweh->event_mask = <token> GFP_KERNEL); <answer> kzalloc(fweh->event_mask_len, 
if <token> <answer> (!fweh->event_mask) 
return <token> <answer> -ENOMEM; 
<token> brcmf_fweh_event_worker); <answer> INIT_WORK(&fweh->event_work, 
return <token> <answer> 0; 
void brcmf_fweh_detach(struct brcmf_pub <token> <answer> *drvr) 
struct brcmf_fweh_info *fweh <token> drvr->fweh; <answer> = 
<token> (!fweh) <answer> if 
int brcmf_fweh_register(struct brcmf_pub *drvr, <token> brcmf_fweh_event_code code, <answer> enum 
<token> handler) <answer> brcmf_fweh_handler_t 
struct brcmf_fweh_info <token> = drvr->fweh; <answer> *fweh 
<token> evt_handler_idx; <answer> u32 
brcmf_fweh_map_event_code(fweh, code, <token> <answer> &evt_handler_idx); 
if (fweh->evt_handler[evt_handler_idx]) <token> <answer> { 
bphy_err(drvr, "event code %d <token> registered\n", code); <answer> already 
return <token> <answer> -ENOSPC; 
<token> = handler; <answer> fweh->evt_handler[evt_handler_idx] 
brcmf_dbg(TRACE, <token> handler registered for %s\n", <answer> "event 
<token> 0; <answer> return 
<token> brcmf_fweh_unregister(struct brcmf_pub *drvr, <answer> void 
<token> brcmf_fweh_event_code code) <answer> enum 
<token> evt_handler_idx; <answer> u32 
brcmf_dbg(TRACE, <token> handler cleared for %s\n", <answer> "event 
brcmf_fweh_map_event_code(drvr->fweh, code, <token> <answer> &evt_handler_idx); 
drvr->fweh->evt_handler[evt_handler_idx] <token> NULL; <answer> = 
int brcmf_fweh_activate_events(struct <token> *ifp) <answer> brcmf_if 
struct brcmf_fweh_info <token> = ifp->drvr->fweh; <answer> *fweh 
<token> brcmf_fweh_event_code code; <answer> enum 
int i, <token> <answer> err; 
memset(fweh->event_mask, <token> fweh->event_mask_len); <answer> 0, 
for (i = 0; <token> < fweh->num_event_codes; i++) { <answer> i 
if (fweh->evt_handler[i]) <token> <answer> { 
brcmf_fweh_map_fwevt_code(fweh, i, <token> <answer> &code); 
brcmf_dbg(EVENT, "enable event <token> <answer> %s\n", 
<token> i); <answer> setbit(fweh->event_mask, 
<token> brcmf_fweh_process_event(struct brcmf_pub *drvr, <answer> void 
struct <token> *event_packet, <answer> brcmf_event 
u32 packet_len, gfp_t <token> <answer> gfp) 
<token> fwevt_idx; <answer> u32 
struct brcmf_fweh_info *fweh = <token> <answer> drvr->fweh; 
struct <token> *event; <answer> brcmf_fweh_queue_item 
<token> *data; <answer> void 
<token> datalen; <answer> u32 
#include <token> <answer> "i915_selftest.h" 
#include <token> <answer> "huge_gem_object.h" 
#include <token> <answer> "selftests/igt_flush_test.h" 
#include <token> <answer> "selftests/mock_gem_device.h" 
<token> int igt_gem_object(void *arg) <answer> static 
struct drm_i915_private <token> = arg; <answer> *i915 
struct <token> *obj; <answer> drm_i915_gem_object 
int <token> <answer> err; 
<token> CONFIG_X86_32 <answer> #ifdef 
#include <token> <answer> <linux/raid/pq.h> 
<token> "x86.h" <answer> #include 
static void <token> disks, size_t bytes, void **ptrs) <answer> raid6_sse11_gen_syndrome(int 
u8 <token> = (u8 **)ptrs; <answer> **dptr 
u8 <token> *q; <answer> *p, 
int d, <token> z0; <answer> z, 
static void raid6_sse12_gen_syndrome(int <token> size_t bytes, void **ptrs) <answer> disks, 
u8 <token> = (u8 **)ptrs; <answer> **dptr 
u8 *p, <token> <answer> *q; 
<token> d, z, z0; <answer> int 
<token> int _open_kvm_dev_path_or_exit(int flags) <answer> static 
return <token> flags); <answer> open_path_or_exit(KVM_DEV_PATH, 
int <token> <answer> open_kvm_dev_path_or_exit(void) 
return <token> <answer> _open_kvm_dev_path_or_exit(O_RDONLY); 
static ssize_t get_module_param(const <token> *module_name, const char *param, <answer> char 
void *buffer, size_t <token> <answer> buffer_size) 
<token> int path_size = 128; <answer> const 
char <token> <answer> path[path_size]; 
ssize_t <token> <answer> bytes_read; 
int <token> r; <answer> fd, 
r <token> snprintf(path, path_size, "/sys/module/%s/parameters/%s", <answer> = 
<token> param); <answer> module_name, 
TEST_ASSERT(r < <token> <answer> path_size, 
"Failed to construct sysfs path in %d bytes.", <token> <answer> path_size); 
fd = <token> O_RDONLY); <answer> open_path_or_exit(path, 
bytes_read = <token> buffer, buffer_size); <answer> read(fd, 
TEST_ASSERT(bytes_read > <token> "read(%s) returned %ld, wanted %ld bytes", <answer> 0, 
path, <token> buffer_size); <answer> bytes_read, 
r = <token> <answer> close(fd); 
TEST_ASSERT(!r, <token> failed", path); <answer> "close(%s) 
<token> bytes_read; <answer> return 
static int get_module_param_integer(const char *module_name, const <token> *param) <answer> char 
char value[16 + 1 <token> 1]; <answer> + 
ssize_t <token> <answer> r; 
memset(value, '\0', <token> <answer> sizeof(value)); 
r = get_module_param(module_name, param, <token> sizeof(value)); <answer> value, 
TEST_ASSERT(value[r - 1] == <token> <answer> '\n', 
"Expected trailing newline, got <token> '%c'", value[r - 1]); <answer> char 
value[r - 1] = <token> <answer> '\0'; 
return <token> <answer> atoi_paranoid(value); 
static bool get_module_param_bool(const <token> *module_name, const char *param) <answer> char 
char <token> <answer> value; 
ssize_t <token> <answer> r; 
r = get_module_param(module_name, <token> &value, sizeof(value)); <answer> param, 
<token> 1); <answer> TEST_ASSERT_EQ(r, 
if <token> == 'Y') <answer> (value 
<token> true; <answer> return 
else if (value <token> 'N') <answer> == 
<token> false; <answer> return 
TEST_FAIL("Unrecognized value <token> for boolean module param", value); <answer> '%c' 
bool get_kvm_param_bool(const char <token> <answer> *param) 
<token> get_module_param_bool("kvm", param); <answer> return 
bool <token> char *param) <answer> get_kvm_intel_param_bool(const 
<token> get_module_param_bool("kvm_intel", param); <answer> return 
bool get_kvm_amd_param_bool(const char <token> <answer> *param) 
<token> get_module_param_bool("kvm_amd", param); <answer> return 
<token> get_kvm_param_integer(const char *param) <answer> int 
<token> get_module_param_integer("kvm", param); <answer> return 
int get_kvm_intel_param_integer(const <token> *param) <answer> char 
return get_module_param_integer("kvm_intel", <token> <answer> param); 
int <token> char *param) <answer> get_kvm_amd_param_integer(const 
<token> get_module_param_integer("kvm_amd", param); <answer> return 
unsigned int kvm_check_cap(long <token> <answer> cap) 
<token> ret; <answer> int 
<token> kvm_fd; <answer> int 
kvm_fd <token> open_kvm_dev_path_or_exit(); <answer> = 
<token> = __kvm_ioctl(kvm_fd, KVM_CHECK_EXTENSION, (void *)cap); <answer> ret 
TEST_ASSERT(ret <token> 0, KVM_IOCTL_ERROR(KVM_CHECK_EXTENSION, ret)); <answer> >= 
<token> (unsigned int)ret; <answer> return 
void vm_enable_dirty_ring(struct kvm_vm <token> uint32_t ring_size) <answer> *vm, 
if (vm_check_cap(vm, <token> <answer> KVM_CAP_DIRTY_LOG_RING_ACQ_REL)) 
vm_enable_cap(vm, KVM_CAP_DIRTY_LOG_RING_ACQ_REL, <token> <answer> ring_size); 
vm_enable_cap(vm, KVM_CAP_DIRTY_LOG_RING, <token> <answer> ring_size); 
vm->dirty_ring_size <token> ring_size; <answer> = 
<token> void vm_open(struct kvm_vm *vm) <answer> static 
vm->kvm_fd = <token> <answer> _open_kvm_dev_path_or_exit(O_RDWR); 
vm->fd = <token> KVM_CREATE_VM, (void *)vm->type); <answer> __kvm_ioctl(vm->kvm_fd, 
<token> >= 0, KVM_IOCTL_ERROR(KVM_CREATE_VM, vm->fd)); <answer> TEST_ASSERT(vm->fd 
const <token> *vm_guest_mode_string(uint32_t i) <answer> char 
static <token> char * const strings[] = { <answer> const 
[VM_MODE_P52V48_4K] = "PA-bits:52, VA-bits:48, 4K <token> <answer> pages", 
[VM_MODE_P52V48_16K] <token> "PA-bits:52, VA-bits:48, 16K pages", <answer> = 
[VM_MODE_P52V48_64K] <token> "PA-bits:52, VA-bits:48, 64K pages", <answer> = 
[VM_MODE_P48V48_4K] = "PA-bits:48, VA-bits:48, 4K <token> <answer> pages", 
[VM_MODE_P48V48_16K] = "PA-bits:48, VA-bits:48, <token> pages", <answer> 16K 
[VM_MODE_P48V48_64K] = <token> VA-bits:48, 64K pages", <answer> "PA-bits:48, 
[VM_MODE_P40V48_4K] = "PA-bits:40, VA-bits:48, 4K <token> <answer> pages", 
[VM_MODE_P40V48_16K] = <token> VA-bits:48, 16K pages", <answer> "PA-bits:40, 
[VM_MODE_P40V48_64K] = "PA-bits:40, <token> 64K pages", <answer> VA-bits:48, 
[VM_MODE_PXXV48_4K] = "PA-bits:ANY, VA-bits:48, <token> pages", <answer> 4K 
<token> = "PA-bits:47, VA-bits:64, 4K pages", <answer> [VM_MODE_P47V64_4K] 
<token> = "PA-bits:44, VA-bits:64, 4K pages", <answer> [VM_MODE_P44V64_4K] 
[VM_MODE_P36V48_4K] <token> "PA-bits:36, VA-bits:48, 4K pages", <answer> = 
[VM_MODE_P36V48_16K] <token> "PA-bits:36, VA-bits:48, 16K pages", <answer> = 
[VM_MODE_P36V48_64K] = "PA-bits:36, VA-bits:48, <token> pages", <answer> 64K 
[VM_MODE_P36V47_16K] = <token> VA-bits:47, 16K pages", <answer> "PA-bits:36, 
_Static_assert(sizeof(strings)/sizeof(char *) == <token> <answer> NUM_VM_MODES, 
<token> new mode strings?"); <answer> "Missing 
TEST_ASSERT(i < NUM_VM_MODES, "Guest mode ID %d too <token> i); <answer> big", 
<token> strings[i]; <answer> return 
const struct vm_guest_mode_params vm_guest_mode_params[] <token> { <answer> = 
<token> = { 52, 48, 0x1000, 12 }, <answer> [VM_MODE_P52V48_4K] 
<token> = { 52, 48, 0x4000, 14 }, <answer> [VM_MODE_P52V48_16K] 
[VM_MODE_P52V48_64K] = { 52, 48, <token> 16 }, <answer> 0x10000, 
[VM_MODE_P48V48_4K] = { 48, 48, <token> 12 }, <answer> 0x1000, 
<token> = { 48, 48, 0x4000, 14 }, <answer> [VM_MODE_P48V48_16K] 
[VM_MODE_P48V48_64K] = <token> 48, 48, 0x10000, 16 }, <answer> { 
[VM_MODE_P40V48_4K] = { <token> 48, 0x1000, 12 }, <answer> 40, 
[VM_MODE_P40V48_16K] = { 40, 48, 0x4000, <token> }, <answer> 14 
[VM_MODE_P40V48_64K] = { <token> 48, 0x10000, 16 }, <answer> 40, 
[VM_MODE_PXXV48_4K] = { 0, 0, 0x1000, <token> }, <answer> 12 
[VM_MODE_P47V64_4K] = { 47, 64, <token> 12 }, <answer> 0x1000, 
[VM_MODE_P44V64_4K] = { 44, 64, <token> 12 }, <answer> 0x1000, 
[VM_MODE_P36V48_4K] = { 36, 48, 0x1000, 12 <token> <answer> }, 
[VM_MODE_P36V48_16K] = { 36, 48, 0x4000, <token> }, <answer> 14 
[VM_MODE_P36V48_64K] = <token> 36, 48, 0x10000, 16 }, <answer> { 
<token> = { 36, 47, 0x4000, 14 }, <answer> [VM_MODE_P36V47_16K] 
_Static_assert(sizeof(vm_guest_mode_params)/sizeof(struct vm_guest_mode_params) == <token> <answer> NUM_VM_MODES, 
"Missing new <token> params?"); <answer> mode 
<token> void vm_vaddr_populate_bitmap(struct kvm_vm *vm) <answer> __weak 
0, (1ULL <token> (vm->va_bits - 1)) >> vm->page_shift); <answer> << 
(~((1ULL << <token> - 1)) - 1)) >> vm->page_shift, <answer> (vm->va_bits 
(1ULL << (vm->va_bits - 1)) <token> vm->page_shift); <answer> >> 
struct kvm_vm *____vm_create(struct <token> shape) <answer> vm_shape 
struct kvm_vm <token> <answer> *vm; 
vm = calloc(1, <token> <answer> sizeof(*vm)); 
TEST_ASSERT(vm != <token> "Insufficient Memory"); <answer> NULL, 
vm->regions.gpa_tree <token> RB_ROOT; <answer> = 
<token> = RB_ROOT; <answer> vm->regions.hva_tree 
<token> = shape.mode; <answer> vm->mode 
vm->type <token> shape.type; <answer> = 
<token> = shape.subtype; <answer> vm->subtype 
<token> = vm_guest_mode_params[vm->mode].pa_bits; <answer> vm->pa_bits 
<token> = vm_guest_mode_params[vm->mode].va_bits; <answer> vm->va_bits 
vm->page_size <token> vm_guest_mode_params[vm->mode].page_size; <answer> = 
vm->page_shift = <token> <answer> vm_guest_mode_params[vm->mode].page_shift; 
TEST_ASSERT(vm->va_bits == 48 || <token> == 57, <answer> vm->va_bits 
<token> address width (%d bits) not supported", <answer> "Linear 
pr_debug("Guest <token> address width detected: %d\n", <answer> physical 
<token> = 4; <answer> vm->pgtable_levels 
<token> = 48; <answer> vm->va_bits 
TEST_FAIL("VM_MODE_PXXV48_4K not <token> on non-x86 platforms"); <answer> supported 
case <token> <answer> VM_MODE_P47V64_4K: 
<token> = 5; <answer> vm->pgtable_levels 
case <token> <answer> VM_MODE_P44V64_4K: 
vm->pgtable_levels <token> 5; <answer> = 
TEST_FAIL("Unknown <token> mode: 0x%x", vm->mode); <answer> guest 
<token> __aarch64__ <answer> #ifdef 
TEST_ASSERT(!vm->type, "ARM <token> support test-provided types"); <answer> doesn't 
if <token> != 40) <answer> (vm->pa_bits 
vm->type = <token> <answer> KVM_VM_TYPE_ARM_IPA_SIZE(vm->pa_bits); 
nr_pages <token> 512; <answer> = 
nr_pages += (nr_pages + extra_mem_pages) / <token> * 2; <answer> PTES_PER_MIN_PAGE 
<token> = memslot2region(vm, 0); <answer> slot0 
ucall_init(vm, slot0->region.guest_phys_addr + <token> <answer> slot0->region.memory_size); 
return <token> <answer> vm; 
struct kvm_vm *__vm_create_with_vcpus(struct <token> shape, uint32_t nr_vcpus, <answer> vm_shape 
uint64_t <token> <answer> extra_mem_pages, 
<token> *guest_code, struct kvm_vcpu *vcpus[]) <answer> void 
struct <token> *vm; <answer> kvm_vm 
<token> i; <answer> int 
TEST_ASSERT(!nr_vcpus || vcpus, "Must provide <token> array"); <answer> vCPU 
vm = __vm_create(shape, nr_vcpus, <token> <answer> extra_mem_pages); 
for (i = 0; <token> < nr_vcpus; ++i) <answer> i 
vcpus[i] = <token> i, guest_code); <answer> vm_vcpu_add(vm, 
<token> vm; <answer> return 
struct <token> *__vm_create_shape_with_one_vcpu(struct vm_shape shape, <answer> kvm_vm 
struct <token> **vcpu, <answer> kvm_vcpu 
<token> extra_mem_pages, <answer> uint64_t 
void <token> <answer> *guest_code) 
<token> kvm_vcpu *vcpus[1]; <answer> struct 
struct <token> *vm; <answer> kvm_vm 
vm = __vm_create_with_vcpus(shape, <token> extra_mem_pages, guest_code, vcpus); <answer> 1, 
*vcpu <token> vcpus[0]; <answer> = 
<token> vm; <answer> return 
void <token> kvm_vm *vmp) <answer> kvm_vm_restart(struct 
int <token> <answer> ctr; 
struct userspace_mem_region <token> <answer> *region; 
<token> (vmp->has_irqchip) <answer> if 
hash_for_each(vmp->regions.slot_hash, ctr, region, slot_node) <token> <answer> { 
int ret = <token> KVM_SET_USER_MEMORY_REGION2, &region->region); <answer> ioctl(vmp->fd, 
TEST_ASSERT(ret == <token> "KVM_SET_USER_MEMORY_REGION2 IOCTL failed,\n" <answer> 0, 
<token> rc: %i errno: %i\n" <answer> " 
" slot: %u flags: <token> <answer> 0x%x\n" 
" guest_phys_addr: <token> size: 0x%llx", <answer> 0x%llx 
ret, errno, <token> <answer> region->region.slot, 
__weak <token> kvm_vcpu *vm_arch_vcpu_recreate(struct kvm_vm *vm, <answer> struct 
uint32_t <token> <answer> vcpu_id) 
<token> __vm_vcpu_add(vm, vcpu_id); <answer> return 
struct kvm_vcpu *vm_recreate_with_one_vcpu(struct kvm_vm <token> <answer> *vm) 
return <token> 0); <answer> vm_vcpu_recreate(vm, 
void kvm_pin_this_task_to_pcpu(uint32_t <token> <answer> pcpu) 
cpu_set_t <token> <answer> mask; 
int <token> <answer> r; 
<token> &mask); <answer> CPU_SET(pcpu, 
<token> = sched_setaffinity(0, sizeof(mask), &mask); <answer> r 
TEST_ASSERT(!r, "sched_setaffinity() failed for pCPU <token> pcpu); <answer> '%u'.", 
static uint32_t parse_pcpu(const char <token> const cpu_set_t *allowed_mask) <answer> *cpu_str, 
<token> pcpu = atoi_non_negative("CPU number", cpu_str); <answer> uint32_t 
<token> allowed_mask), <answer> TEST_ASSERT(CPU_ISSET(pcpu, 
"Not allowed <token> run on pCPU '%d', check cgroups?", pcpu); <answer> to 
return <token> <answer> pcpu; 
void <token> <answer> kvm_print_vcpu_pinning_help(void) 
const char <token> = program_invocation_name; <answer> *name 
printf(" -c: Pin tasks to physical CPUs. <token> a list of comma separated\n" <answer> Takes 
" <token> (target pCPU), one for each vCPU, plus an optional\n" <answer> values 
" entry for the main <token> task (specified via entry\n" <answer> application 
" <nr_vcpus + 1>). If used, <token> must be provided for all\n" <answer> entries 
" vCPUs, <token> pinning vCPUs is all or nothing.\n\n" <answer> i.e. 
" E.g. to create 3 vCPUs, pin <token> vCPU1=>pCPU23,\n" <answer> vCPU0=>pCPU22, 
" <token> and pin the application task to pCPU50:\n\n" <answer> vCPU2=>pCPU24, 
<token> %s -v 3 -c 22,23,24,50\n\n" <answer> " 
" To leave the application task unpinned, <token> the final entry:\n\n" <answer> drop 
" %s <token> 3 -c 22,23,24\n\n" <answer> -v 
<token> (default: no pinning)\n", name, name); <answer> " 
void kvm_parse_vcpu_pinning(const char *pcpus_string, <token> vcpu_to_pcpu[], <answer> uint32_t 
int <token> <answer> nr_vcpus) 
<token> allowed_mask; <answer> cpu_set_t 
char <token> *cpu_list; <answer> *cpu, 
char <token> = ","; <answer> delim[2] 
<token> i, r; <answer> int 
<token> = strdup(pcpus_string); <answer> cpu_list 
TEST_ASSERT(cpu_list, "strdup() allocation <token> <answer> failed."); 
<token> = sched_getaffinity(0, sizeof(allowed_mask), &allowed_mask); <answer> r 
TEST_ASSERT(!r, "sched_getaffinity() <token> <answer> failed"); 
cpu = <token> delim); <answer> strtok(cpu_list, 
static struct <token> * <answer> userspace_mem_region 
userspace_mem_region_find(struct kvm_vm *vm, uint64_t <token> uint64_t end) <answer> start, 
struct <token> *node; <answer> rb_node 
for (node = <token> node; ) { <answer> vm->regions.gpa_tree.rb_node; 
struct userspace_mem_region <token> = <answer> *region 
container_of(node, <token> userspace_mem_region, gpa_node); <answer> struct 
uint64_t existing_start = <token> <answer> region->region.guest_phys_addr; 
uint64_t existing_end <token> region->region.guest_phys_addr <answer> = 
+ region->region.memory_size <token> 1; <answer> - 
if (start <= existing_end && <token> >= existing_start) <answer> end 
return <token> <answer> region; 
if (start < <token> <answer> existing_start) 
<token> = node->rb_left; <answer> node 
node <token> node->rb_right; <answer> = 
return <token> <answer> NULL; 
__weak void vcpu_arch_free(struct kvm_vcpu <token> <answer> *vcpu) 
static void vm_vcpu_rm(struct kvm_vm *vm, struct kvm_vcpu <token> <answer> *vcpu) 
int <token> <answer> ret; 
<token> (vcpu->dirty_gfns) { <answer> if 
<token> = munmap(vcpu->dirty_gfns, vm->dirty_ring_size); <answer> ret 
TEST_ASSERT(!ret, <token> ret)); <answer> __KVM_SYSCALL_ERROR("munmap()", 
vcpu->dirty_gfns = <token> <answer> NULL; 
ret <token> munmap(vcpu->run, vcpu_mmap_sz()); <answer> = 
TEST_ASSERT(!ret, <token> ret)); <answer> __KVM_SYSCALL_ERROR("munmap()", 
ret = <token> <answer> close(vcpu->fd); 
TEST_ASSERT(!ret, __KVM_SYSCALL_ERROR("close()", <token> <answer> ret)); 
<token> kvm_vm_release(struct kvm_vm *vmp) <answer> void 
struct <token> *vcpu, *tmp; <answer> kvm_vcpu 
int <token> <answer> ret; 
list_for_each_entry_safe(vcpu, tmp, &vmp->vcpus, <token> <answer> list) 
<token> vcpu); <answer> vm_vcpu_rm(vmp, 
ret <token> close(vmp->fd); <answer> = 
TEST_ASSERT(!ret, <token> ret)); <answer> __KVM_SYSCALL_ERROR("close()", 
<token> = close(vmp->kvm_fd); <answer> ret 
TEST_ASSERT(!ret, __KVM_SYSCALL_ERROR("close()", <token> <answer> ret)); 
static void <token> kvm_vm *vm, <answer> __vm_mem_region_delete(struct 
<token> userspace_mem_region *region, <answer> struct 
bool <token> <answer> unlink) 
<token> ret; <answer> int 
if (unlink) <token> <answer> { 
<token> &vm->regions.gpa_tree); <answer> rb_erase(&region->gpa_node, 
rb_erase(&region->hva_node, <token> <answer> &vm->regions.hva_tree); 
region->region.memory_size <token> 0; <answer> = 
<token> KVM_SET_USER_MEMORY_REGION2, &region->region); <answer> vm_ioctl(vm, 
<token> = munmap(region->mmap_start, region->mmap_size); <answer> ret 
TEST_ASSERT(!ret, __KVM_SYSCALL_ERROR("munmap()", <token> <answer> ret)); 
if (region->fd <token> 0) { <answer> >= 
<token> kvm_vm_free(struct kvm_vm *vmp) <answer> void 
int <token> <answer> ctr; 
struct <token> *node; <answer> hlist_node 
struct userspace_mem_region <token> <answer> *region; 
<token> (vmp == NULL) <answer> if 
int kvm_memcmp_hva_gva(void *hva, struct kvm_vm *vm, vm_vaddr_t gva, size_t <token> <answer> len) 
size_t <token> <answer> amt; 
for (uintptr_t offset = 0; offset <token> len; offset += amt) { <answer> < 
uintptr_t ptr1 = <token> + offset; <answer> (uintptr_t)hva 
uintptr_t ptr2 <token> (uintptr_t)addr_gva2hva(vm, gva + offset); <answer> = 
amt = len <token> offset; <answer> - 
if ((ptr1 >> vm->page_shift) <token> ((ptr1 + amt) >> vm->page_shift)) <answer> != 
amt = vm->page_size - (ptr1 % <token> <answer> vm->page_size); 
if ((ptr2 >> vm->page_shift) != ((ptr2 + <token> >> vm->page_shift)) <answer> amt) 
amt = vm->page_size - (ptr2 <token> vm->page_size); <answer> % 
assert((ptr1 >> vm->page_shift) == ((ptr1 + amt - 1) >> <token> <answer> vm->page_shift)); 
assert((ptr2 >> vm->page_shift) == ((ptr2 + <token> - 1) >> vm->page_shift)); <answer> amt 
<token> ret = memcmp((void *)ptr1, (void *)ptr2, amt); <answer> int 
<token> (ret != 0) <answer> if 
<token> ret; <answer> return 
<token> 0; <answer> return 
static void <token> rb_root *gpa_tree, <answer> vm_userspace_mem_region_gpa_insert(struct 
<token> userspace_mem_region *region) <answer> struct 
<token> rb_node **cur, *parent; <answer> struct 
for (cur = &gpa_tree->rb_node, parent <token> NULL; *cur; ) { <answer> = 
struct userspace_mem_region <token> <answer> *cregion; 
cregion = container_of(*cur, <token> gpa_node); <answer> typeof(*cregion), 
parent <token> *cur; <answer> = 
if <token> < <answer> (region->region.guest_phys_addr 
<token> = &(*cur)->rb_left; <answer> cur 
else <token> <answer> { 
TEST_ASSERT(region->region.guest_phys_addr <token> <answer> != 
<token> GPA in region tree"); <answer> "Duplicate 
<token> = &(*cur)->rb_right; <answer> cur 
<token> parent, cur); <answer> rb_link_node(&region->gpa_node, 
rb_insert_color(&region->gpa_node, <token> <answer> gpa_tree); 
static void vm_userspace_mem_region_hva_insert(struct <token> *hva_tree, <answer> rb_root 
<token> userspace_mem_region *region) <answer> struct 
struct rb_node <token> *parent; <answer> **cur, 
for <token> = &hva_tree->rb_node, parent = NULL; *cur; ) { <answer> (cur 
struct <token> *cregion; <answer> userspace_mem_region 
cregion = container_of(*cur, typeof(*cregion), <token> <answer> hva_node); 
<token> = *cur; <answer> parent 
if (region->host_mem <token> cregion->host_mem) <answer> < 
cur <token> &(*cur)->rb_left; <answer> = 
<token> { <answer> else 
TEST_ASSERT(region->host_mem <token> <answer> != 
"Duplicate HVA in <token> tree"); <answer> region 
<token> = &(*cur)->rb_right; <answer> cur 
rb_link_node(&region->hva_node, <token> cur); <answer> parent, 
rb_insert_color(&region->hva_node, <token> <answer> hva_tree); 
int <token> kvm_vm *vm, uint32_t slot, uint32_t flags, <answer> __vm_set_user_memory_region(struct 
uint64_t gpa, uint64_t size, void <token> <answer> *hva) 
struct kvm_userspace_memory_region <token> = { <answer> region 
<token> = slot, <answer> .slot 
<token> = flags, <answer> .flags 
.guest_phys_addr = <token> <answer> gpa, 
<token> = size, <answer> .memory_size 
.userspace_addr = <token> <answer> (uintptr_t)hva, 
<token> ioctl(vm->fd, KVM_SET_USER_MEMORY_REGION, &region); <answer> return 
void vm_set_user_memory_region(struct kvm_vm *vm, uint32_t slot, <token> flags, <answer> uint32_t 
uint64_t gpa, uint64_t <token> void *hva) <answer> size, 
int ret = __vm_set_user_memory_region(vm, slot, <token> gpa, size, hva); <answer> flags, 
TEST_ASSERT(!ret, "KVM_SET_USER_MEMORY_REGION failed, errno <token> %d (%s)", <answer> = 
errno, <token> <answer> strerror(errno)); 
int __vm_set_user_memory_region2(struct kvm_vm *vm, uint32_t slot, <token> flags, <answer> uint32_t 
uint64_t <token> uint64_t size, void *hva, <answer> gpa, 
uint32_t guest_memfd, <token> guest_memfd_offset) <answer> uint64_t 
struct kvm_userspace_memory_region2 <token> = { <answer> region 
.slot = <token> <answer> slot, 
.flags = <token> <answer> flags, 
.guest_phys_addr = <token> <answer> gpa, 
.memory_size = <token> <answer> size, 
.userspace_addr <token> (uintptr_t)hva, <answer> = 
.guest_memfd <token> guest_memfd, <answer> = 
.guest_memfd_offset = <token> <answer> guest_memfd_offset, 
<token> ioctl(vm->fd, KVM_SET_USER_MEMORY_REGION2, &region); <answer> return 
void vm_set_user_memory_region2(struct <token> *vm, uint32_t slot, uint32_t flags, <answer> kvm_vm 
uint64_t gpa, uint64_t size, <token> *hva, <answer> void 
uint32_t <token> uint64_t guest_memfd_offset) <answer> guest_memfd, 
int ret = <token> slot, flags, gpa, size, hva, <answer> __vm_set_user_memory_region2(vm, 
<token> guest_memfd_offset); <answer> guest_memfd, 
TEST_ASSERT(!ret, "KVM_SET_USER_MEMORY_REGION2 failed, errno = <token> (%s)", <answer> %d 
errno, <token> <answer> strerror(errno)); 
region = (struct <token> *) userspace_mem_region_find( <answer> userspace_mem_region 
vm, guest_paddr, (guest_paddr + npages * vm->page_size) <token> 1); <answer> - 
if (region <token> NULL) <answer> != 
<token> userspace_mem_region already " <answer> TEST_FAIL("overlapping 
" <token> guest_paddr: 0x%lx npages: 0x%lx " <answer> requested 
<token> 0x%x\n" <answer> "page_size: 
" existing guest_paddr: <token> size: 0x%lx", <answer> 0x%lx 
guest_paddr, npages, <token> <answer> vm->page_size, 
(uint64_t) <token> <answer> region->region.guest_phys_addr, 
<token> region->region.memory_size); <answer> (uint64_t) 
if (src_type <token> VM_MEM_SRC_ANONYMOUS_THP) <answer> == 
alignment = max(backing_src_pagesz, <token> <answer> alignment); 
TEST_ASSERT_EQ(guest_paddr, align_up(guest_paddr, <token> <answer> backing_src_pagesz)); 
<token> = dup(guest_memfd); <answer> guest_memfd 
TEST_ASSERT(guest_memfd >= <token> __KVM_SYSCALL_ERROR("dup()", guest_memfd)); <answer> 0, 
region->region.guest_memfd = <token> <answer> guest_memfd; 
region->region.guest_memfd_offset <token> guest_memfd_offset; <answer> = 
<token> else { <answer> } 
region->region.guest_memfd <token> -1; <answer> = 
region->unused_phy_pages = <token> <answer> sparsebit_alloc(); 
if <token> <answer> (vm_arch_has_protected_memory(vm)) 
<token> = sparsebit_alloc(); <answer> region->protected_phy_pages 
guest_paddr <token> vm->page_shift, npages); <answer> >> 
region->region.slot = <token> <answer> slot; 
region->region.flags = <token> <answer> flags; 
region->region.guest_phys_addr <token> guest_paddr; <answer> = 
region->region.memory_size = npages * <token> <answer> vm->page_size; 
region->region.userspace_addr = (uintptr_t) <token> <answer> region->host_mem; 
ret = <token> KVM_SET_USER_MEMORY_REGION2, &region->region); <answer> __vm_ioctl(vm, 
TEST_ASSERT(ret == 0, "KVM_SET_USER_MEMORY_REGION2 IOCTL <token> <answer> failed,\n" 
<token> rc: %i errno: %i\n" <answer> " 
" slot: <token> flags: 0x%x\n" <answer> %u 
<token> guest_phys_addr: 0x%lx size: 0x%lx guest_memfd: %d", <answer> " 
ret, errno, <token> flags, <answer> slot, 
<token> (uint64_t) region->region.memory_size, <answer> guest_paddr, 
<token> userspace_mem_region * <answer> struct 
<token> kvm_vm *vm, uint32_t memslot) <answer> memslot2region(struct 
<token> userspace_mem_region *region; <answer> struct 
hash_for_each_possible(vm->regions.slot_hash, region, <token> <answer> slot_node, 
if (region->region.slot <token> memslot) <answer> == 
<token> region; <answer> return 
fprintf(stderr, "No mem region <token> the requested slot found,\n" <answer> with 
" requested <token> %u\n", memslot); <answer> slot: 
fputs("---- vm dump <token> stderr); <answer> ----\n", 
vm_dump(stderr, <token> 2); <answer> vm, 
TEST_FAIL("Mem region <token> found"); <answer> not 
return <token> <answer> NULL; 
void vm_mem_region_set_flags(struct kvm_vm *vm, uint32_t slot, <token> flags) <answer> uint32_t 
<token> ret; <answer> int 
struct userspace_mem_region <token> <answer> *region; 
region <token> memslot2region(vm, slot); <answer> = 
region->region.flags = <token> <answer> flags; 
<token> = __vm_ioctl(vm, KVM_SET_USER_MEMORY_REGION2, &region->region); <answer> ret 
TEST_ASSERT(ret == 0, "KVM_SET_USER_MEMORY_REGION2 <token> failed,\n" <answer> IOCTL 
<token> rc: %i errno: %i slot: %u flags: 0x%x", <answer> " 
ret, errno, <token> flags); <answer> slot, 
void vm_mem_region_move(struct <token> *vm, uint32_t slot, uint64_t new_gpa) <answer> kvm_vm 
struct <token> *region; <answer> userspace_mem_region 
int <token> <answer> ret; 
region <token> memslot2region(vm, slot); <answer> = 
region->region.guest_phys_addr <token> new_gpa; <answer> = 
ret = <token> KVM_SET_USER_MEMORY_REGION2, &region->region); <answer> __vm_ioctl(vm, 
<token> "KVM_SET_USER_MEMORY_REGION2 failed\n" <answer> TEST_ASSERT(!ret, 
"ret: %i errno: <token> slot: %u new_gpa: 0x%lx", <answer> %i 
<token> errno, slot, new_gpa); <answer> ret, 
void vm_mem_region_delete(struct kvm_vm <token> uint32_t slot) <answer> *vm, 
__vm_mem_region_delete(vm, <token> slot), true); <answer> memslot2region(vm, 
void vm_guest_mem_fallocate(struct <token> *vm, uint64_t base, uint64_t size, <answer> kvm_vm 
<token> punch_hole) <answer> bool 
const int mode = <token> | (punch_hole ? FALLOC_FL_PUNCH_HOLE : 0); <answer> FALLOC_FL_KEEP_SIZE 
struct userspace_mem_region <token> <answer> *region; 
uint64_t end = base <token> size; <answer> + 
<token> gpa, len; <answer> uint64_t 
off_t <token> <answer> fd_offset; 
int <token> <answer> ret; 
for (gpa = base; <token> < end; gpa += len) { <answer> gpa 
uint64_t <token> <answer> offset; 
region = userspace_mem_region_find(vm, gpa, <token> <answer> gpa); 
<token> && region->region.flags & KVM_MEM_GUEST_MEMFD, <answer> TEST_ASSERT(region 
"Private memory region not found for GPA 0x%lx", <token> <answer> gpa); 
offset = gpa <token> region->region.guest_phys_addr; <answer> - 
fd_offset <token> region->region.guest_memfd_offset + offset; <answer> = 
<token> = min_t(uint64_t, end - gpa, region->region.memory_size - offset); <answer> len 
ret = fallocate(region->region.guest_memfd, <token> fd_offset, len); <answer> mode, 
TEST_ASSERT(!ret, "fallocate() failed to <token> at %lx (len = %lu), fd = %d, mode = %x, offset = %lx", <answer> %s 
punch_hole ? "punch hole" : "allocate", <token> len, <answer> gpa, 
<token> mode, fd_offset); <answer> region->region.guest_memfd, 
struct kvm_vcpu *__vm_vcpu_add(struct kvm_vm *vm, uint32_t <token> <answer> vcpu_id) 
struct <token> *vcpu; <answer> kvm_vcpu 
vm_vaddr_t vm_vaddr_unused_gap(struct kvm_vm *vm, size_t <token> <answer> sz, 
<token> vaddr_min) <answer> vm_vaddr_t 
uint64_t pages = (sz + vm->page_size - 1) >> <token> <answer> vm->page_shift; 
if <token> <answer> (sparsebit_is_clear_num(vm->vpages_mapped, 
<token> pages)) <answer> pgidx_start, 
<token> va_found; <answer> goto 
<token> = sparsebit_next_clear_num(vm->vpages_mapped, <answer> pgidx_start 
pgidx_start, <token> <answer> pages); 
<token> (pgidx_start == 0) <answer> if 
goto <token> <answer> no_va_found; 
<token> (!sparsebit_is_set_num(vm->vpages_valid, <answer> if 
pgidx_start, <token> { <answer> pages)) 
pgidx_start = <token> <answer> sparsebit_next_set_num( 
vm->vpages_valid, <token> pages); <answer> pgidx_start, 
<token> (pgidx_start == 0) <answer> if 
<token> no_va_found; <answer> goto 
} while (pgidx_start <token> 0); <answer> != 
TEST_FAIL("No vaddr of specified pages available, <token> 0x%lx", pages); <answer> pages: 
vm_vaddr_t vaddr_start = <token> sz, vaddr_min); <answer> vm_vaddr_unused_gap(vm, 
vm_vaddr_t vm_vaddr_alloc(struct <token> *vm, size_t sz, vm_vaddr_t vaddr_min) <answer> kvm_vm 
<token> __vm_vaddr_alloc(vm, sz, vaddr_min, MEM_REGION_TEST_DATA); <answer> return 
vm_vaddr_t vm_vaddr_alloc_pages(struct kvm_vm *vm, int <token> <answer> nr_pages) 
<token> vm_vaddr_alloc(vm, nr_pages * getpagesize(), KVM_UTIL_MIN_VADDR); <answer> return 
vm_vaddr_t <token> kvm_vm *vm, enum kvm_mem_region_type type) <answer> __vm_vaddr_alloc_page(struct 
return __vm_vaddr_alloc(vm, getpagesize(), <token> type); <answer> KVM_UTIL_MIN_VADDR, 
<token> vm_vaddr_alloc_page(struct kvm_vm *vm) <answer> vm_vaddr_t 
return vm_vaddr_alloc_pages(vm, <token> <answer> 1); 
void virt_map(struct <token> *vm, uint64_t vaddr, uint64_t paddr, <answer> kvm_vm 
<token> int npages) <answer> unsigned 
<token> page_size = vm->page_size; <answer> size_t 
size_t size = <token> * page_size; <answer> npages 
<token> + size > vaddr, "Vaddr overflow"); <answer> TEST_ASSERT(vaddr 
<token> + size > paddr, "Paddr overflow"); <answer> TEST_ASSERT(paddr 
while <token> { <answer> (npages--) 
virt_pg_map(vm, <token> paddr); <answer> vaddr, 
sparsebit_set(vm->vpages_mapped, <token> >> vm->page_shift); <answer> vaddr 
vaddr <token> page_size; <answer> += 
paddr <token> page_size; <answer> += 
void *addr_gpa2hva(struct kvm_vm *vm, <token> gpa) <answer> vm_paddr_t 
<token> userspace_mem_region *region; <answer> struct 
gpa = <token> gpa); <answer> vm_untag_gpa(vm, 
<token> = userspace_mem_region_find(vm, gpa, gpa); <answer> region 
if (!region) <token> <answer> { 
TEST_FAIL("No <token> physical memory at 0x%lx", gpa); <answer> vm 
<token> NULL; <answer> return 
return <token> *)((uintptr_t)region->host_mem <answer> (void 
+ (gpa <token> region->region.guest_phys_addr)); <answer> - 
<token> addr_hva2gpa(struct kvm_vm *vm, void *hva) <answer> vm_paddr_t 
<token> rb_node *node; <answer> struct 
for (node = vm->regions.hva_tree.rb_node; node; ) <token> <answer> { 
struct <token> *region = <answer> userspace_mem_region 
<token> struct userspace_mem_region, hva_node); <answer> container_of(node, 
<token> (hva >= region->host_mem) { <answer> if 
if (hva <token> (region->host_mem <answer> <= 
<token> region->region.memory_size - 1)) <answer> + 
return <token> <answer> (vm_paddr_t)((uintptr_t) 
+ (hva - <token> <answer> (uintptr_t)region->host_mem)); 
node <token> node->rb_right; <answer> = 
} <token> <answer> else 
node = <token> <answer> node->rb_left; 
TEST_FAIL("No mapping to <token> guest physical address, hva: %p", hva); <answer> a 
return <token> <answer> -1; 
void *addr_gpa2alias(struct kvm_vm *vm, <token> gpa) <answer> vm_paddr_t 
<token> userspace_mem_region *region; <answer> struct 
uintptr_t <token> <answer> offset; 
region = <token> gpa, gpa); <answer> userspace_mem_region_find(vm, 
<token> (!region) <answer> if 
return <token> <answer> NULL; 
<token> (!region->host_alias) <answer> if 
<token> NULL; <answer> return 
offset = gpa - <token> <answer> region->region.guest_phys_addr; 
return (void *) ((uintptr_t) region->host_alias <token> offset); <answer> + 
<token> vcpu_run(struct kvm_vcpu *vcpu) <answer> void 
int ret <token> _vcpu_run(vcpu); <answer> = 
TEST_ASSERT(!ret, KVM_IOCTL_ERROR(KVM_RUN, <token> <answer> ret)); 
void vcpu_run_complete_io(struct kvm_vcpu <token> <answer> *vcpu) 
int <token> <answer> ret; 
<token> = 1; <answer> vcpu->run->immediate_exit 
ret = <token> <answer> __vcpu_run(vcpu); 
<token> = 0; <answer> vcpu->run->immediate_exit 
TEST_ASSERT(ret == -1 && <token> == EINTR, <answer> errno 
"KVM_RUN IOCTL didn't exit immediately, rc: %i, errno: <token> <answer> %i", 
<token> errno); <answer> ret, 
struct kvm_reg_list *vcpu_get_reg_list(struct <token> *vcpu) <answer> kvm_vcpu 
struct kvm_reg_list reg_list_n = { .n = <token> }, *reg_list; <answer> 0 
int <token> <answer> ret; 
ret = __vcpu_ioctl(vcpu, KVM_GET_REG_LIST, <token> <answer> &reg_list_n); 
TEST_ASSERT(ret == -1 && errno == <token> "KVM_GET_REG_LIST n=0"); <answer> E2BIG, 
reg_list <token> calloc(1, sizeof(*reg_list) + reg_list_n.n * sizeof(__u64)); <answer> = 
reg_list->n = <token> <answer> reg_list_n.n; 
vcpu_ioctl(vcpu, KVM_GET_REG_LIST, <token> <answer> reg_list); 
return <token> <answer> reg_list; 
void <token> kvm_vcpu *vcpu) <answer> *vcpu_map_dirty_ring(struct 
uint32_t <token> = getpagesize(); <answer> page_size 
<token> size = vcpu->vm->dirty_ring_size; <answer> uint32_t 
TEST_ASSERT(size > 0, "Should enable dirty <token> first"); <answer> ring 
if (!vcpu->dirty_gfns) <token> <answer> { 
<token> *addr; <answer> void 
<token> = mmap(NULL, size, PROT_READ, MAP_PRIVATE, vcpu->fd, <answer> addr 
<token> * KVM_DIRTY_LOG_PAGE_OFFSET); <answer> page_size 
<token> == MAP_FAILED, "Dirty ring mapped private"); <answer> TEST_ASSERT(addr 
addr = <token> size, PROT_READ | PROT_EXEC, MAP_PRIVATE, vcpu->fd, <answer> mmap(NULL, 
page_size * <token> <answer> KVM_DIRTY_LOG_PAGE_OFFSET); 
TEST_ASSERT(addr == MAP_FAILED, "Dirty ring mapped <token> <answer> exec"); 
addr = mmap(NULL, size, PROT_READ | PROT_WRITE, <token> vcpu->fd, <answer> MAP_SHARED, 
page_size <token> KVM_DIRTY_LOG_PAGE_OFFSET); <answer> * 
TEST_ASSERT(addr <token> MAP_FAILED, "Dirty ring map failed"); <answer> != 
<token> = addr; <answer> vcpu->dirty_gfns 
vcpu->dirty_gfns_count = size / <token> kvm_dirty_gfn); <answer> sizeof(struct 
<token> vcpu->dirty_gfns; <answer> return 
<token> __kvm_has_device_attr(int dev_fd, uint32_t group, uint64_t attr) <answer> int 
struct <token> attribute = { <answer> kvm_device_attr 
.group <token> group, <answer> = 
.attr <token> attr, <answer> = 
<token> = 0, <answer> .flags 
return <token> KVM_HAS_DEVICE_ATTR, &attribute); <answer> ioctl(dev_fd, 
int __kvm_test_create_device(struct kvm_vm *vm, <token> type) <answer> uint64_t 
<token> kvm_create_device create_dev = { <answer> struct 
.type = <token> <answer> type, 
.flags <token> KVM_CREATE_DEVICE_TEST, <answer> = 
<token> __vm_ioctl(vm, KVM_CREATE_DEVICE, &create_dev); <answer> return 
int __kvm_create_device(struct kvm_vm *vm, <token> type) <answer> uint64_t 
struct kvm_create_device create_dev = <token> <answer> { 
.type <token> type, <answer> = 
.fd = <token> <answer> -1, 
.flags = <token> <answer> 0, 
<token> err; <answer> int 
err = __vm_ioctl(vm, <token> &create_dev); <answer> KVM_CREATE_DEVICE, 
TEST_ASSERT(err <= 0, "KVM_CREATE_DEVICE shouldn't return a positive <token> <answer> value"); 
return err ? : <token> <answer> create_dev.fd; 
int __kvm_device_attr_get(int dev_fd, uint32_t group, uint64_t attr, <token> *val) <answer> void 
struct kvm_device_attr kvmattr <token> { <answer> = 
.group = <token> <answer> group, 
.attr <token> attr, <answer> = 
.flags = <token> <answer> 0, 
.addr <token> (uintptr_t)val, <answer> = 
return <token> KVM_GET_DEVICE_ATTR, &kvmattr); <answer> __kvm_ioctl(dev_fd, 
int __kvm_device_attr_set(int dev_fd, uint32_t group, uint64_t <token> void *val) <answer> attr, 
struct kvm_device_attr <token> = { <answer> kvmattr 
.group = <token> <answer> group, 
.attr <token> attr, <answer> = 
.flags = <token> <answer> 0, 
.addr = <token> <answer> (uintptr_t)val, 
return <token> KVM_SET_DEVICE_ATTR, &kvmattr); <answer> __kvm_ioctl(dev_fd, 
int _kvm_irq_line(struct kvm_vm *vm, uint32_t <token> int level) <answer> irq, 
struct kvm_irq_level irq_level = <token> <answer> { 
.irq = <token> <answer> irq, 
.level = <token> <answer> level, 
return <token> KVM_IRQ_LINE, &irq_level); <answer> __vm_ioctl(vm, 
void kvm_irq_line(struct kvm_vm *vm, uint32_t <token> int level) <answer> irq, 
int ret = _kvm_irq_line(vm, <token> level); <answer> irq, 
TEST_ASSERT(ret <token> 0, KVM_IOCTL_ERROR(KVM_IRQ_LINE, ret)); <answer> >= 
struct kvm_irq_routing <token> <answer> *kvm_gsi_routing_create(void) 
<token> kvm_irq_routing *routing; <answer> struct 
<token> size; <answer> size_t 
size <token> sizeof(struct kvm_irq_routing); <answer> = 
void vm_dump(FILE <token> struct kvm_vm *vm, uint8_t indent) <answer> *stream, 
<token> ctr; <answer> int 
struct <token> *region; <answer> userspace_mem_region 
struct <token> *vcpu; <answer> kvm_vcpu 
fprintf(stream, "%*smode: 0x%x\n", <token> "", vm->mode); <answer> indent, 
fprintf(stream, "%*sfd: %i\n", <token> "", vm->fd); <answer> indent, 
fprintf(stream, "%*spage_size: <token> indent, "", vm->page_size); <answer> 0x%x\n", 
fprintf(stream, <token> Regions:\n", indent, ""); <answer> "%*sMem 
hash_for_each(vm->regions.slot_hash, ctr, region, slot_node) <token> <answer> { 
fprintf(stream, "%*sguest_phys: 0x%lx <token> 0x%lx " <answer> size: 
"host_virt: %p\n", <token> + 2, "", <answer> indent 
(uint64_t) <token> <answer> region->region.guest_phys_addr, 
<token> region->region.memory_size, <answer> (uint64_t) 
fprintf(stream, "%*sunused_phy_pages: <token> indent + 2, ""); <answer> ", 
sparsebit_dump(stream, region->unused_phy_pages, <token> <answer> 0); 
<token> (region->protected_phy_pages) { <answer> if 
fprintf(stream, "%*sprotected_phy_pages: <token> indent + 2, ""); <answer> ", 
sparsebit_dump(stream, <token> 0); <answer> region->protected_phy_pages, 
fprintf(stream, "%*sMapped Virtual Pages:\n", indent, <token> <answer> ""); 
sparsebit_dump(stream, <token> indent + 2); <answer> vm->vpages_mapped, 
fprintf(stream, <token> %u\n", indent, "", <answer> "%*spgd_created: 
if <token> { <answer> (vm->pgd_created) 
fprintf(stream, "%*sVirtual <token> Tables:\n", <answer> Translation 
<token> + 2, ""); <answer> indent 
<token> vm, indent + 4); <answer> virt_dump(stream, 
fprintf(stream, <token> indent, ""); <answer> "%*sVCPUs:\n", 
list_for_each_entry(vcpu, <token> list) <answer> &vm->vcpus, 
vcpu_dump(stream, vcpu, indent <token> 2); <answer> + 
#define KVM_EXIT_STRING(x) {KVM_EXIT_##x, <token> <answer> #x} 
const char *exit_reason_str(unsigned int <token> <answer> exit_reason) 
unsigned int <token> <answer> n1; 
for (n1 = 0; n1 <token> ARRAY_SIZE(exit_reasons_known); n1++) { <answer> < 
if (exit_reason <token> exit_reasons_known[n1].reason) <answer> == 
return <token> <answer> exit_reasons_known[n1].name; 
return <token> <answer> "Unknown"; 
<token> __vm_phy_pages_alloc(struct kvm_vm *vm, size_t num, <answer> vm_paddr_t 
<token> paddr_min, uint32_t memslot, <answer> vm_paddr_t 
<token> protected) <answer> bool 
<token> userspace_mem_region *region; <answer> struct 
<token> pg, base; <answer> sparsebit_idx_t 
TEST_ASSERT(num > <token> "Must allocate at least one page"); <answer> 0, 
TEST_ASSERT((paddr_min % <token> == 0, "Min physical address " <answer> vm->page_size) 
<token> divisible by page size.\n" <answer> "not 
<token> paddr_min: 0x%lx page_size: 0x%x", <answer> " 
<token> vm->page_size); <answer> paddr_min, 
region <token> memslot2region(vm, memslot); <answer> = 
TEST_ASSERT(!protected || <token> <answer> region->protected_phy_pages, 
"Region <token> support protected memory"); <answer> doesn't 
base = pg <token> paddr_min >> vm->page_shift; <answer> = 
<token> { <answer> do 
for (; pg < <token> + num; ++pg) { <answer> base 
if (!sparsebit_is_set(region->unused_phy_pages, <token> { <answer> pg)) 
base = pg = sparsebit_next_set(region->unused_phy_pages, <token> <answer> pg); 
} while (pg && pg != base <token> num); <answer> + 
if <token> == 0) { <answer> (pg 
<token> "No guest physical page available, " <answer> fprintf(stderr, 
<token> 0x%lx page_size: 0x%x memslot: %u\n", <answer> "paddr_min: 
<token> vm->page_size, memslot); <answer> paddr_min, 
<token> vm dump ----\n", stderr); <answer> fputs("---- 
vm_dump(stderr, <token> 2); <answer> vm, 
for (pg = base; pg < base + num; ++pg) <token> <answer> { 
sparsebit_clear(region->unused_phy_pages, <token> <answer> pg); 
<token> (protected) <answer> if 
sparsebit_set(region->protected_phy_pages, <token> <answer> pg); 
return base <token> vm->page_size; <answer> * 
vm_paddr_t vm_phy_page_alloc(struct kvm_vm *vm, vm_paddr_t <token> <answer> paddr_min, 
uint32_t <token> <answer> memslot) 
return <token> 1, paddr_min, memslot); <answer> vm_phy_pages_alloc(vm, 
vm_paddr_t vm_alloc_page_table(struct kvm_vm <token> <answer> *vm) 
return <token> KVM_GUEST_PAGE_TABLE_MIN_PADDR, <answer> vm_phy_page_alloc(vm, 
void *addr_gva2hva(struct kvm_vm <token> vm_vaddr_t gva) <answer> *vm, 
return addr_gpa2hva(vm, <token> gva)); <answer> addr_gva2gpa(vm, 
unsigned <token> __weak vm_compute_max_gfn(struct kvm_vm *vm) <answer> long 
return <token> << vm->pa_bits) >> vm->page_shift) - 1; <answer> ((1ULL 
static unsigned int vm_calc_num_pages(unsigned <token> num_pages, <answer> int 
<token> int page_shift, <answer> unsigned 
unsigned <token> new_page_shift, <answer> int 
bool <token> <answer> ceil) 
unsigned <token> n = 1 << (new_page_shift - page_shift); <answer> int 
if <token> >= new_page_shift) <answer> (page_shift 
return num_pages * (1 <token> (page_shift - new_page_shift)); <answer> << 
return num_pages / n + !!(ceil && num_pages <token> n); <answer> % 
static inline <token> getpageshift(void) <answer> int 
return __builtin_ffs(getpagesize()) - <token> <answer> 1; 
<token> int <answer> unsigned 
<token> vm_guest_mode mode, unsigned int num_guest_pages) <answer> vm_num_host_pages(enum 
return <token> <answer> vm_calc_num_pages(num_guest_pages, 
getpageshift(), <token> <answer> true); 
unsigned <token> <answer> int 
<token> vm_guest_mode mode, unsigned int num_host_pages) <answer> vm_num_guest_pages(enum 
return <token> getpageshift(), <answer> vm_calc_num_pages(num_host_pages, 
<token> false); <answer> vm_guest_mode_params[mode].page_shift, 
unsigned <token> vm_calc_num_guest_pages(enum vm_guest_mode mode, size_t size) <answer> int 
<token> int n; <answer> unsigned 
n = DIV_ROUND_UP(size, <token> <answer> vm_guest_mode_params[mode].page_size); 
return <token> n); <answer> vm_adjust_num_guest_pages(mode, 
struct kvm_stats_desc *read_stats_descriptors(int <token> <answer> stats_fd, 
struct kvm_stats_header <token> <answer> *header) 
<token> kvm_stats_desc *stats_desc; <answer> struct 
<token> desc_size, total_size, ret; <answer> ssize_t 
<token> = get_stats_descriptor_size(header); <answer> desc_size 
total_size = header->num_desc <token> desc_size; <answer> * 
<token> = calloc(header->num_desc, desc_size); <answer> stats_desc 
<token> "Allocate memory for stats descriptors"); <answer> TEST_ASSERT(stats_desc, 
ret = pread(stats_fd, stats_desc, total_size, <token> <answer> header->desc_offset); 
TEST_ASSERT(ret <token> total_size, "Read KVM stats descriptors"); <answer> == 
<token> stats_desc; <answer> return 
void read_stat_data(int stats_fd, struct <token> *header, <answer> kvm_stats_header 
struct <token> *desc, uint64_t *data, <answer> kvm_stats_desc 
<token> max_elements) <answer> size_t 
size_t nr_elements = min_t(ssize_t, desc->size, <token> <answer> max_elements); 
size_t size = nr_elements <token> sizeof(*data); <answer> * 
ssize_t <token> <answer> ret; 
TEST_ASSERT(desc->size, "No elements <token> stat '%s'", desc->name); <answer> in 
TEST_ASSERT(max_elements, <token> elements requested for stat '%s'", desc->name); <answer> "Zero 
ret = pread(stats_fd, <token> size, <answer> data, 
header->data_offset + <token> <answer> desc->offset); 
TEST_ASSERT(ret >= 0, "pread() failed <token> stat '%s', errno: %i (%s)", <answer> on 
<token> errno, strerror(errno)); <answer> desc->name, 
<token> == size, <answer> TEST_ASSERT(ret 
"pread() on stat '%s' read %ld <token> wanted %lu bytes", <answer> bytes, 
desc->name, <token> ret); <answer> size, 
void __vm_get_stat(struct <token> *vm, const char *stat_name, uint64_t *data, <answer> kvm_vm 
<token> max_elements) <answer> size_t 
<token> kvm_stats_desc *desc; <answer> struct 
<token> size_desc; <answer> size_t 
<token> i; <answer> int 
if (!vm->stats_fd) <token> <answer> { 
vm->stats_fd = <token> <answer> vm_get_stats_fd(vm); 
read_stats_header(vm->stats_fd, <token> <answer> &vm->stats_header); 
vm->stats_desc = <token> <answer> read_stats_descriptors(vm->stats_fd, 
<token> = get_stats_descriptor_size(&vm->stats_header); <answer> size_desc 
for (i = 0; i < <token> ++i) { <answer> vm->stats_header.num_desc; 
<token> = (void *)vm->stats_desc + (i * size_desc); <answer> desc 
if <token> stat_name)) <answer> (strcmp(desc->name, 
read_stat_data(vm->stats_fd, &vm->stats_header, <token> <answer> desc, 
<token> max_elements); <answer> data, 
__weak void kvm_arch_vm_post_create(struct <token> *vm) <answer> kvm_vm 
__weak <token> kvm_selftest_arch_init(void) <answer> void 
void __attribute((constructor)) <token> <answer> kvm_selftest_init(void) 
#include <token> <answer> <unistd.h> 
<token> <stdio.h> <answer> #include 
<token> <string.h> <answer> #include 
<token> <inttypes.h> <answer> #include 
<token> <linux/string.h> <answer> #include 
<token> "../../arch/x86/include/asm/amd-ibs.h" <answer> #include 
#include <token> <answer> "debug.h" 
#include <token> <answer> "session.h" 
<token> "evlist.h" <answer> #include 
#include <token> <answer> "sample-raw.h" 
<token> "util/sample.h" <answer> #include 
static u32 cpu_family, cpu_model, <token> ibs_op_type; <answer> ibs_fetch_type, 
static <token> zen4_ibs_extensions; <answer> bool 
static void <token> ibs_fetch_ctl reg) <answer> pr_ibs_fetch_ctl(union 
const char * <token> ic_miss_strs[] = { <answer> const 
" <token> 0", <answer> IcMiss 
<token> IcMiss 1", <answer> " 
const char * const <token> = { <answer> l1tlb_pgsz_strs[] 
<token> L1TlbPgSz 4KB", <answer> " 
" <token> 2MB", <answer> L1TlbPgSz 
<token> L1TlbPgSz 1GB", <answer> " 
" <token> RESERVED" <answer> L1TlbPgSz 
const char * const l1tlb_pgsz_strs_erratum1347[] = <token> <answer> { 
" L1TlbPgSz <token> <answer> 4KB", 
" L1TlbPgSz <token> <answer> 16KB", 
<token> L1TlbPgSz 2MB", <answer> " 
" L1TlbPgSz <token> <answer> 1GB" 
const char <token> = NULL; <answer> *ic_miss_str 
const char <token> = NULL; <answer> *l1tlb_pgsz_str 
<token> l3_miss_str[sizeof(" L3MissOnly _ FetchOcMiss _ FetchL3Miss _")] = ""; <answer> char 
if (cpu_family == <token> && cpu_model < 0x10) { <answer> 0x19 
<token> (reg.phy_addr_valid) <answer> if 
l1tlb_pgsz_str = <token> <answer> l1tlb_pgsz_strs_erratum1347[reg.l1tlb_pgsz]; 
} <token> { <answer> else 
if <token> <answer> (reg.phy_addr_valid) 
<token> = l1tlb_pgsz_strs[reg.l1tlb_pgsz]; <answer> l1tlb_pgsz_str 
ic_miss_str = <token> <answer> ic_miss_strs[reg.ic_miss]; 
if (zen4_ibs_extensions) <token> <answer> { 
snprintf(l3_miss_str, <token> <answer> sizeof(l3_miss_str), 
" L3MissOnly %d FetchOcMiss <token> FetchL3Miss %d", <answer> %d 
reg.l3_miss_only, reg.fetch_oc_miss, <token> <answer> reg.fetch_l3_miss); 
printf("ibs_fetch_ctl:\t%016llx MaxCnt %7d Cnt %7d Lat %5d En %d Val %d Comp <token> " <answer> %d%s 
"PhyAddrValid %d%s L1TlbMiss %d L2TlbMiss <token> RandEn %d%s%s\n", <answer> %d 
<token> reg.fetch_maxcnt << 4, reg.fetch_cnt << 4, reg.fetch_lat, <answer> reg.val, 
reg.fetch_en, reg.fetch_val, reg.fetch_comp, ic_miss_str <token> : "", <answer> ? 
reg.phy_addr_valid, <token> ? : "", reg.l1tlb_miss, reg.l2tlb_miss, <answer> l1tlb_pgsz_str 
reg.rand_en, reg.fetch_comp ? (reg.fetch_l2_miss ? " L2Miss 1" : " L2Miss <token> : "", <answer> 0") 
static <token> pr_ic_ibs_extd_ctl(union ic_ibs_extd_ctl reg) <answer> void 
<token> IbsItlbRefillLat %3d\n", reg.val, reg.itlb_refill_lat); <answer> printf("ic_ibs_ext_ctl:\t%016llx 
static void pr_ibs_op_ctl(union ibs_op_ctl <token> <answer> reg) 
char l3_miss_only[sizeof(" <token> _")] = ""; <answer> L3MissOnly 
if <token> <answer> (zen4_ibs_extensions) 
snprintf(l3_miss_only, sizeof(l3_miss_only), " L3MissOnly %d", <token> <answer> reg.l3_miss_only); 
printf("ibs_op_ctl:\t%016llx <token> %9d%s En %d Val %d CntCtl %d=%s CurCnt %9d\n", <answer> MaxCnt 
reg.val, ((reg.opmaxcnt_ext << 16) | reg.opmaxcnt) <token> 4, l3_miss_only, <answer> << 
reg.op_en, reg.op_val, <token> <answer> reg.cnt_ctl, 
reg.cnt_ctl ? "uOps" <token> "cycles", reg.opcurcnt); <answer> : 
static void pr_ibs_op_data(union ibs_op_data <token> <answer> reg) 
printf("ibs_op_data:\t%016llx CompToRetCtr %5d TagToRetCtr <token> BrnRet %d " <answer> %5d%s%s%s 
" RipInvalid %d BrnFuse <token> Microcode %d\n", <answer> %d 
reg.val, <token> reg.tag_to_ret_ctr, <answer> reg.comp_to_ret_ctr, 
reg.op_brn_ret ? (reg.op_return ? " OpReturn 1" : " OpReturn 0") : <token> <answer> "", 
reg.op_brn_ret ? (reg.op_brn_taken ? " OpBrnTaken 1" : <token> OpBrnTaken 0") : "", <answer> " 
<token> ? (reg.op_brn_misp ? " OpBrnMisp 1" : " OpBrnMisp 0") : "", <answer> reg.op_brn_ret 
reg.op_brn_ret, <token> reg.op_brn_fuse, reg.op_microcode); <answer> reg.op_rip_invalid, 
static void pr_ibs_op_data2_extended(union <token> reg) <answer> ibs_op_data2 
static const <token> * const data_src_str[] = { <answer> char 
" DataSrc <token> L3 or other L1/L2 in CCX", <answer> 1=Local 
<token> DataSrc 2=Another CCX cache in the same NUMA node", <answer> " 
" DataSrc <token> <answer> 3=DRAM", 
" DataSrc <token> <answer> 4=(reserved)", 
<token> DataSrc 5=Another CCX cache in a different NUMA node", <answer> " 
<token> DataSrc 6=Long-latency DIMM", <answer> " 
<token> DataSrc 7=MMIO/Config/PCI/APIC", <answer> " 
<token> DataSrc 8=Extension Memory", <answer> " 
" DataSrc <token> <answer> 9=(reserved)", 
<token> DataSrc 10=(reserved)", <answer> " 
" <token> 11=(reserved)", <answer> DataSrc 
" DataSrc 12=Coherent Memory of <token> different processor type", <answer> a 
if (!(cpu_family <token> 0x19 && cpu_model < 0x10 && (reg.dc_miss_no_mab_alloc || reg.sw_pf))) { <answer> == 
snprintf(l2_miss_str, sizeof(l2_miss_str), <token> L2Miss %d", reg.l2_miss); <answer> " 
snprintf(op_dc_miss_open_mem_reqs_str, <token> <answer> sizeof(op_dc_miss_open_mem_reqs_str), 
" <token> %2d", reg.op_dc_miss_open_mem_reqs); <answer> OpDcMissOpenMemReqs 
if <token> <answer> (reg.op_mem_width) 
<token> sizeof(op_mem_width_str), <answer> snprintf(op_mem_width_str, 
" OpMemWidth %2d <token> 1 << (reg.op_mem_width - 1)); <answer> bytes", 
printf("ibs_op_data3:\t%016llx LdOp %d StOp %d DcL1TlbMiss %d <token> %d " <answer> DcL2TlbMiss 
"DcL1TlbHit2M %d DcL1TlbHit1G %d DcL2TlbHit2M %d DcMiss %d DcMisAcc %d <token> <answer> " 
"DcWcMemAcc %d DcUcMemAcc %d DcLockedOp %d DcMissNoMabAlloc %d DcLinAddrValid <token> " <answer> %d 
"DcPhyAddrValid %d <token> %d%s SwPf %d%s%s DcMissLat %5d TlbRefillLat %5d\n", <answer> DcL2TlbHit1G 
reg.val, reg.ld_op, <token> reg.dc_l1tlb_miss, reg.dc_l2tlb_miss, <answer> reg.st_op, 
<token> reg.dc_l1tlb_hit_1g, reg.dc_l2tlb_hit_2m, reg.dc_miss, <answer> reg.dc_l1tlb_hit_2m, 
<token> reg.dc_wc_mem_acc, reg.dc_uc_mem_acc, reg.dc_locked_op, <answer> reg.dc_mis_acc, 
<token> reg.dc_lin_addr_valid, reg.dc_phy_addr_valid, <answer> reg.dc_miss_no_mab_alloc, 
reg.dc_l2_tlb_hit_1g, <token> reg.sw_pf, op_mem_width_str, <answer> l2_miss_str, 
<token> reg.dc_miss_lat, reg.tlb_refill_lat); <answer> op_dc_miss_open_mem_reqs_str, 
static void amd_dump_ibs_op(struct perf_sample <token> <answer> *sample) 
struct perf_ibs_data <token> = sample->raw_data; <answer> *data 
<token> ibs_op_ctl *op_ctl = (union ibs_op_ctl *)data->data; <answer> union 
__u64 <token> = (__u64 *)op_ctl + 1; <answer> *rip 
union ibs_op_data *op_data = (union ibs_op_data <token> + 1); <answer> *)(rip 
union <token> *op_data3 = (union ibs_op_data3 *)(rip + 3); <answer> ibs_op_data3 
<token> (!op_data->op_rip_invalid) <answer> if 
<token> *rip); <answer> printf("IbsOpRip:\t%016llx\n", 
<token> (!(cpu_family == 0x19 && cpu_model < 0x10 && <answer> if 
(op_data3->dc_miss_no_mab_alloc || <token> <answer> op_data3->sw_pf))) 
pr_ibs_op_data2(*(union ibs_op_data2 <token> + 2)); <answer> *)(rip 
<token> (op_data3->dc_lin_addr_valid) <answer> if 
<token> *(rip + 4)); <answer> printf("IbsDCLinAd:\t%016llx\n", 
<token> (op_data3->dc_phy_addr_valid) <answer> if 
printf("IbsDCPhysAd:\t%016llx\n", *(rip + <token> <answer> 5)); 
if <token> && *(rip + 6)) <answer> (op_data->op_brn_ret 
printf("IbsBrTarget:\t%016llx\n", <token> + 6)); <answer> *(rip 
static void amd_dump_ibs_fetch(struct <token> *sample) <answer> perf_sample 
struct perf_ibs_data *data <token> sample->raw_data; <answer> = 
union ibs_fetch_ctl *fetch_ctl = (union <token> *)data->data; <answer> ibs_fetch_ctl 
__u64 <token> = (__u64 *)fetch_ctl + 1; <answer> *addr 
union ic_ibs_extd_ctl *extd_ctl = (union <token> *)addr + 2; <answer> ic_ibs_extd_ctl 
printf("IbsFetchLinAd:\t%016llx\n", <token> <answer> *addr++); 
if <token> <answer> (fetch_ctl->phy_addr_valid) 
printf("IbsFetchPhysAd:\t%016llx\n", <token> <answer> *addr); 
static bool is_valid_ibs_fetch_sample(struct perf_sample <token> <answer> *sample) 
struct <token> *data = sample->raw_data; <answer> perf_ibs_data 
union ibs_fetch_ctl <token> = (union ibs_fetch_ctl *)data->data; <answer> *fetch_ctl 
if (fetch_ctl->fetch_en && <token> <answer> fetch_ctl->fetch_val) 
return <token> <answer> true; 
return <token> <answer> false; 
static bool <token> perf_sample *sample) <answer> is_valid_ibs_op_sample(struct 
struct perf_ibs_data *data = <token> <answer> sample->raw_data; 
union ibs_op_ctl *op_ctl = (union <token> *)data->data; <answer> ibs_op_ctl 
if <token> && op_ctl->op_val) <answer> (op_ctl->op_en 
<token> true; <answer> return 
return <token> <answer> false; 
<token> evlist__amd_sample_raw(struct evlist *evlist, union perf_event *event, <answer> void 
struct perf_sample <token> <answer> *sample) 
struct evsel <token> <answer> *evsel; 
if <token> != PERF_RECORD_SAMPLE || !sample->raw_size) <answer> (event->header.type 
<token> = evlist__event2evsel(evlist, event); <answer> evsel 
if <token> <answer> (!evsel) 
if (evsel->core.attr.type == <token> { <answer> ibs_fetch_type) 
<token> (!is_valid_ibs_fetch_sample(sample)) { <answer> if 
pr_debug("Invalid raw IBS <token> MSR data encountered\n"); <answer> Fetch 
} else <token> (evsel->core.attr.type == ibs_op_type) { <answer> if 
<token> (!is_valid_ibs_op_sample(sample)) { <answer> if 
pr_debug("Invalid raw IBS <token> MSR data encountered\n"); <answer> Op 
static <token> parse_cpuid(struct perf_env *env) <answer> void 
const <token> *cpuid; <answer> char 
<token> ret; <answer> int 
cpuid = <token> <answer> perf_env__cpuid(env); 
ret = sscanf(cpuid, <token> &cpu_family, &cpu_model); <answer> "%*[^,],%u,%u", 
if <token> != 2) <answer> (ret 
pr_debug("problem <token> cpuid\n"); <answer> parsing 
bool <token> evlist *evlist) <answer> evlist__has_amd_ibs(struct 
struct perf_env *env = <token> <answer> evlist->env; 
int ret, nr_pmu_mappings = <token> <answer> perf_env__nr_pmu_mappings(env); 
const char *pmu_mapping <token> perf_env__pmu_mappings(env); <answer> = 
char <token> <answer> name[sizeof("ibs_fetch")]; 
<token> type; <answer> u32 
<token> (nr_pmu_mappings--) { <answer> while 
ret = sscanf(pmu_mapping, "%u:%9s", &type, <token> <answer> name); 
if (ret <token> 2) { <answer> == 
if (strstarts(name, <token> <answer> "ibs_op")) 
ibs_op_type <token> type; <answer> = 
else if (strstarts(name, <token> <answer> "ibs_fetch")) 
<token> = type; <answer> ibs_fetch_type 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/usb.h> 
<token> <linux/usb/audio.h> <answer> #include 
<token> <linux/usb/audio-v2.h> <answer> #include 
#include <token> <answer> <linux/usb/audio-v3.h> 
#include <token> <answer> "usbaudio.h" 
#include <token> <answer> "helper.h" 
<token> "power.h" <answer> #include 
struct <token> * <answer> snd_usb_power_domain 
<token> usb_host_interface *ctrl_iface, <answer> snd_usb_find_power_domain(struct 
unsigned char <token> <answer> id) 
struct <token> *pd; <answer> snd_usb_power_domain 
<token> *p; <answer> void 
pd = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*pd), 
if <token> <answer> (!pd) 
return <token> <answer> NULL; 
p = <token> <answer> NULL; 
while <token> = snd_usb_find_csint_desc(ctrl_iface->extra, <answer> ((p 
p, UAC3_POWER_DOMAIN)) != NULL) <token> <answer> { 
struct uac3_power_domain_descriptor *pd_desc <token> p; <answer> = 
<token> i; <answer> int 
if (!snd_usb_validate_audio_desc(p, <token> <answer> UAC_VERSION_3)) 
for (i = <token> i < pd_desc->bNrEntities; i++) { <answer> 0; 
if (pd_desc->baEntityID[i] <token> id) { <answer> == 
pd->pd_id <token> pd_desc->bPowerDomainID; <answer> = 
<token> = <answer> pd->pd_d1d0_rec 
<token> = <answer> pd->pd_d2d0_rec 
return <token> <answer> pd; 
return <token> <answer> NULL; 
int snd_usb_power_domain_set(struct snd_usb_audio <token> <answer> *chip, 
<token> snd_usb_power_domain *pd, <answer> struct 
<token> char state) <answer> unsigned 
struct usb_device *dev <token> chip->dev; <answer> = 
unsigned <token> current_state; <answer> char 
int <token> idx; <answer> err, 
idx = snd_usb_ctrl_intf(chip) <token> (pd->pd_id << 8); <answer> | 
err = <token> usb_rcvctrlpipe(chip->dev, 0), <answer> snd_usb_ctl_msg(chip->dev, 
<token> | USB_TYPE_CLASS | USB_DIR_IN, <answer> USB_RECIP_INTERFACE 
UAC3_AC_POWER_DOMAIN_CONTROL << 8, <token> <answer> idx, 
&current_state, <token> <answer> sizeof(current_state)); 
if (err < 0) <token> <answer> { 
dev_err(&dev->dev, <token> get UAC3 power state for id %d\n", <answer> "Can't 
return <token> <answer> err; 
if (current_state == <token> { <answer> state) 
dev_dbg(&dev->dev, "UAC3 power domain id %d already <token> state %d\n", <answer> in 
<token> state); <answer> pd->pd_id, 
<token> 0; <answer> return 
err = snd_usb_ctl_msg(chip->dev, usb_sndctrlpipe(chip->dev, <token> UAC2_CS_CUR, <answer> 0), 
USB_RECIP_INTERFACE | USB_TYPE_CLASS <token> USB_DIR_OUT, <answer> | 
<token> << 8, idx, <answer> UAC3_AC_POWER_DOMAIN_CONTROL 
<token> sizeof(state)); <answer> &state, 
<token> (err < 0) { <answer> if 
dev_err(&dev->dev, "Can't set UAC3 <token> state to %d for id %d\n", <answer> power 
state, <token> <answer> pd->pd_id); 
return <token> <answer> err; 
<token> (state == UAC3_PD_STATE_D0) { <answer> if 
switch (current_state) <token> <answer> { 
<token> UAC3_PD_STATE_D2: <answer> case 
<token> * 50); <answer> udelay(pd->pd_d2d0_rec 
<token> UAC3_PD_STATE_D1: <answer> case 
udelay(pd->pd_d1d0_rec * <token> <answer> 50); 
<token> -EINVAL; <answer> return 
dev_dbg(&dev->dev, "UAC3 power domain <token> %d change to state %d\n", <answer> id 
<token> state); <answer> pd->pd_id, 
return <token> <answer> 0; 
#include <token> <answer> <dt-bindings/firmware/imx/rsrc.h> 
<token> <linux/err.h> <answer> #include 
<token> <linux/firmware/imx/sci.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/thermal.h> <answer> #include 
<token> "thermal_hwmon.h" <answer> #include 
#define IMX_SC_MISC_FUNC_GET_TEMP <token> <answer> 13 
static <token> imx_sc_ipc *thermal_ipc_handle; <answer> struct 
struct <token> { <answer> imx_sc_sensor 
struct <token> *tzd; <answer> thermal_zone_device 
u32 <token> <answer> resource_id; 
<token> req_get_temp { <answer> struct 
u16 <token> <answer> resource_id; 
<token> type; <answer> u8 
} __packed <token> <answer> __aligned(4); 
struct <token> { <answer> resp_get_temp 
<token> celsius; <answer> s16 
<token> tenths; <answer> s8 
} <token> __aligned(4); <answer> __packed 
struct <token> { <answer> imx_sc_msg_misc_get_temp 
struct imx_sc_rpc_msg <token> <answer> hdr; 
union <token> <answer> { 
<token> req_get_temp req; <answer> struct 
<token> resp_get_temp resp; <answer> struct 
<token> data; <answer> } 
} __packed <token> <answer> __aligned(4); 
static int <token> thermal_zone_device *tz, int *temp) <answer> imx_sc_thermal_get_temp(struct 
struct imx_sc_msg_misc_get_temp <token> <answer> msg; 
struct imx_sc_rpc_msg <token> = &msg.hdr; <answer> *hdr 
struct <token> *sensor = thermal_zone_device_priv(tz); <answer> imx_sc_sensor 
int <token> <answer> ret; 
<token> = sensor->resource_id; <answer> msg.data.req.resource_id 
msg.data.req.type <token> IMX_SC_C_TEMP; <answer> = 
hdr->ver <token> IMX_SC_RPC_VERSION; <answer> = 
hdr->svc <token> IMX_SC_RPC_SVC_MISC; <answer> = 
hdr->func <token> IMX_SC_MISC_FUNC_GET_TEMP; <answer> = 
hdr->size <token> 2; <answer> = 
ret = <token> &msg, true); <answer> imx_scu_call_rpc(thermal_ipc_handle, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
*temp = msg.data.resp.celsius * <token> + msg.data.resp.tenths * 100; <answer> 1000 
return <token> <answer> 0; 
<token> const struct thermal_zone_device_ops imx_sc_thermal_ops = { <answer> static 
<token> = imx_sc_thermal_get_temp, <answer> .get_temp 
static int imx_sc_thermal_probe(struct <token> *pdev) <answer> platform_device 
struct imx_sc_sensor <token> <answer> *sensor; 
const <token> *resource_id; <answer> int 
<token> i, ret; <answer> int 
<token> = imx_scu_get_handle(&thermal_ipc_handle); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> = of_device_get_match_data(&pdev->dev); <answer> resource_id 
if <token> <answer> (!resource_id) 
return <token> <answer> -EINVAL; 
for <token> = 0; resource_id[i] >= 0; i++) { <answer> (i 
sensor <token> devm_kzalloc(&pdev->dev, sizeof(*sensor), GFP_KERNEL); <answer> = 
if <token> <answer> (!sensor) 
<token> -ENOMEM; <answer> return 
sensor->resource_id <token> resource_id[i]; <answer> = 
<token> = devm_thermal_of_zone_register(&pdev->dev, sensor->resource_id, <answer> sensor->tzd 
<token> &imx_sc_thermal_ops); <answer> sensor, 
if (IS_ERR(sensor->tzd)) <token> <answer> { 
ret <token> PTR_ERR(sensor->tzd); <answer> = 
<token> sensor); <answer> devm_kfree(&pdev->dev, 
if <token> == -ENODEV) <answer> (ret 
dev_err(&pdev->dev, <token> to register thermal zone\n"); <answer> "failed 
return <token> <answer> ret; 
<token> sensor->tzd); <answer> devm_thermal_add_hwmon_sysfs(&pdev->dev, 
<token> 0; <answer> return 
static const int imx_sc_sensors[] <token> { <answer> = 
<token> IMX_SC_R_PMIC_0, <answer> IMX_SC_R_SYSTEM, 
<token> IMX_SC_R_AP_1, <answer> IMX_SC_R_AP_0, 
IMX_SC_R_GPU_0_PID0, <token> <answer> IMX_SC_R_GPU_1_PID0, 
IMX_SC_R_DRC_0, <token> }; <answer> -1 
static <token> struct of_device_id imx_sc_thermal_table[] = { <answer> const 
{ .compatible = <token> .data = imx_sc_sensors }, <answer> "fsl,imx-sc-thermal", 
MODULE_DEVICE_TABLE(of, <token> <answer> imx_sc_thermal_table); 
<token> struct platform_driver imx_sc_thermal_driver = { <answer> static 
<token> = imx_sc_thermal_probe, <answer> .probe 
.driver <token> { <answer> = 
.name <token> "imx-sc-thermal", <answer> = 
<token> = imx_sc_thermal_table, <answer> .of_match_table 
MODULE_AUTHOR("Anson <token> <Anson.Huang@nxp.com>"); <answer> Huang 
MODULE_DESCRIPTION("Thermal driver for NXP i.MX SoCs <token> system controller"); <answer> with 
<token> v2"); <answer> MODULE_LICENSE("GPL 
#include <token> <answer> <linux/clk.h> 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/mfd/syscon.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_graph.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/pinctrl/consumer.h> 
#include <token> <answer> <linux/pm_runtime.h> 
#include <token> <answer> <media/v4l2-fwnode.h> 
<token> <media/v4l2-mc.h> <answer> #include 
#include <token> <answer> "rkisp1-common.h" 
#include <token> <answer> "rkisp1-csi.h" 
struct <token> { <answer> rkisp1_isr_data 
const <token> *name; <answer> char 
irqreturn_t (*isr)(int irq, <token> *ctx); <answer> void 
u32 <token> <answer> line_mask; 
static int <token> v4l2_async_notifier *notifier, <answer> rkisp1_subdev_notifier_bound(struct 
struct v4l2_subdev <token> <answer> *sd, 
<token> v4l2_async_connection *asc) <answer> struct 
struct rkisp1_device <token> = <answer> *rkisp1 
<token> struct rkisp1_device, notifier); <answer> container_of(notifier, 
struct rkisp1_sensor_async <token> = <answer> *s_asd 
container_of(asc, struct <token> asd); <answer> rkisp1_sensor_async, 
<token> source_pad; <answer> int 
<token> ret; <answer> int 
<token> = sd; <answer> s_asd->sd 
<token> = media_entity_get_fwnode_pad(&sd->entity, s_asd->source_ep, <answer> source_pad 
if <token> < 0) { <answer> (source_pad 
dev_err(rkisp1->dev, "failed to find source <token> for %s\n", <answer> pad 
<token> source_pad; <answer> return 
if (s_asd->port <token> 0) <answer> == 
<token> rkisp1_csi_link_sensor(rkisp1, sd, s_asd, source_pad); <answer> return 
<token> = media_create_pad_link(&sd->entity, source_pad, <answer> ret 
<token> ? MEDIA_LNK_FL_ENABLED : 0); <answer> !s_asd->index 
<token> (ret) { <answer> if 
dev_err(rkisp1->dev, "failed to link source pad of <token> <answer> %s\n", 
return <token> <answer> ret; 
<token> 0; <answer> return 
static int rkisp1_subdev_notifier_complete(struct v4l2_async_notifier <token> <answer> *notifier) 
struct rkisp1_device <token> = <answer> *rkisp1 
container_of(notifier, struct <token> notifier); <answer> rkisp1_device, 
<token> v4l2_device_register_subdev_nodes(&rkisp1->v4l2_dev); <answer> return 
static void rkisp1_subdev_notifier_destroy(struct <token> *asc) <answer> v4l2_async_connection 
struct <token> *rk_asd = <answer> rkisp1_sensor_async 
<token> struct rkisp1_sensor_async, asd); <answer> container_of(asc, 
<token> const struct v4l2_async_notifier_operations rkisp1_subdev_notifier_ops = { <answer> static 
.bound = <token> <answer> rkisp1_subdev_notifier_bound, 
.complete <token> rkisp1_subdev_notifier_complete, <answer> = 
<token> = rkisp1_subdev_notifier_destroy, <answer> .destroy 
static int <token> rkisp1_device *rkisp1) <answer> rkisp1_subdev_notifier_register(struct 
struct v4l2_async_notifier *ntf <token> &rkisp1->notifier; <answer> = 
struct fwnode_handle *fwnode = <token> <answer> dev_fwnode(rkisp1->dev); 
struct fwnode_handle <token> <answer> *ep; 
unsigned <token> index = 0; <answer> int 
<token> ret = 0; <answer> int 
v4l2_async_nf_init(ntf, <token> <answer> &rkisp1->v4l2_dev); 
ntf->ops <token> &rkisp1_subdev_notifier_ops; <answer> = 
fwnode_graph_for_each_endpoint(fwnode, <token> { <answer> ep) 
struct fwnode_handle <token> <answer> *port; 
struct v4l2_fwnode_endpoint vep = <token> }; <answer> { 
<token> rkisp1_sensor_async *rk_asd; <answer> struct 
struct fwnode_handle <token> <answer> *source; 
u32 reg = <token> <answer> 0; 
vep.bus_type = <token> <answer> V4L2_MBUS_UNKNOWN; 
static <token> __maybe_unused rkisp1_runtime_suspend(struct device *dev) <answer> int 
struct rkisp1_device *rkisp1 = <token> <answer> dev_get_drvdata(dev); 
rkisp1->irqs_enabled <token> false; <answer> = 
for <token> int il = 0; il < ARRAY_SIZE(rkisp1->irqs); ++il) { <answer> (unsigned 
if (rkisp1->irqs[il] == <token> <answer> -1) 
static <token> rkisp1_create_links(struct rkisp1_device *rkisp1) <answer> int 
unsigned int <token> = rkisp1_path_count(rkisp1); <answer> dev_count 
unsigned <token> i; <answer> int 
int <token> <answer> ret; 
if (rkisp1_has_feature(rkisp1, <token> { <answer> MIPI_CSI2)) 
if (rkisp1_capture_isr(irq, <token> == IRQ_HANDLED) <answer> ctx) 
<token> = IRQ_HANDLED; <answer> ret 
if (rkisp1_isp_isr(irq, ctx) <token> IRQ_HANDLED) <answer> == 
<token> = IRQ_HANDLED; <answer> ret 
<token> (rkisp1_csi_isr(irq, ctx) == IRQ_HANDLED) <answer> if 
ret <token> IRQ_HANDLED; <answer> = 
<token> ret; <answer> return 
static const char * const <token> = { <answer> px30_isp_clks[] 
static const struct <token> px30_isp_isrs[] = { <answer> rkisp1_isr_data 
{ "isp", rkisp1_isp_isr, BIT(RKISP1_IRQ_ISP) <token> <answer> }, 
{ <token> rkisp1_capture_isr, BIT(RKISP1_IRQ_MI) }, <answer> "mi", 
<token> "mipi", rkisp1_csi_isr, BIT(RKISP1_IRQ_MIPI) }, <answer> { 
static const struct rkisp1_info px30_isp_info = <token> <answer> { 
.clks = <token> <answer> px30_isp_clks, 
.clk_size <token> ARRAY_SIZE(px30_isp_clks), <answer> = 
<token> = px30_isp_isrs, <answer> .isrs 
.isr_size = <token> <answer> ARRAY_SIZE(px30_isp_isrs), 
.isp_ver = <token> <answer> RKISP1_V12, 
<token> = RKISP1_FEATURE_MIPI_CSI2 <answer> .features 
| <token> <answer> RKISP1_FEATURE_SELF_PATH 
| <token> <answer> RKISP1_FEATURE_DUAL_CROP, 
static const char * <token> rk3399_isp_clks[] = { <answer> const 
static const <token> rkisp1_isr_data rk3399_isp_isrs[] = { <answer> struct 
{ NULL, rkisp1_isr, BIT(RKISP1_IRQ_ISP) | BIT(RKISP1_IRQ_MI) | <token> }, <answer> BIT(RKISP1_IRQ_MIPI) 
static <token> struct rkisp1_info rk3399_isp_info = { <answer> const 
.clks <token> rk3399_isp_clks, <answer> = 
.clk_size = <token> <answer> ARRAY_SIZE(rk3399_isp_clks), 
<token> = rk3399_isp_isrs, <answer> .isrs 
.isr_size <token> ARRAY_SIZE(rk3399_isp_isrs), <answer> = 
<token> = RKISP1_V10, <answer> .isp_ver 
.features <token> RKISP1_FEATURE_MIPI_CSI2 <answer> = 
<token> RKISP1_FEATURE_SELF_PATH <answer> | 
<token> RKISP1_FEATURE_DUAL_CROP, <answer> | 
static const <token> * const imx8mp_isp_clks[] = { <answer> char 
static const struct <token> imx8mp_isp_isrs[] = { <answer> rkisp1_isr_data 
{ NULL, <token> BIT(RKISP1_IRQ_ISP) | BIT(RKISP1_IRQ_MI) }, <answer> rkisp1_isr, 
static const struct rkisp1_info imx8mp_isp_info <token> { <answer> = 
<token> = imx8mp_isp_clks, <answer> .clks 
.clk_size <token> ARRAY_SIZE(imx8mp_isp_clks), <answer> = 
<token> = imx8mp_isp_isrs, <answer> .isrs 
<token> = ARRAY_SIZE(imx8mp_isp_isrs), <answer> .isr_size 
.isp_ver = <token> <answer> RKISP1_V_IMX8MP, 
.features <token> RKISP1_FEATURE_MAIN_STRIDE <answer> = 
<token> RKISP1_FEATURE_DMA_34BIT, <answer> | 
static const struct of_device_id <token> = { <answer> rkisp1_of_match[] 
<token> = "rockchip,px30-cif-isp", <answer> .compatible 
.data = <token> <answer> &px30_isp_info, 
.compatible <token> "rockchip,rk3399-cif-isp", <answer> = 
<token> = &rk3399_isp_info, <answer> .data 
.compatible <token> "fsl,imx8mp-isp", <answer> = 
.data <token> &imx8mp_isp_info, <answer> = 
<token> rkisp1_of_match); <answer> MODULE_DEVICE_TABLE(of, 
static <token> rkisp1_probe(struct platform_device *pdev) <answer> int 
const <token> rkisp1_info *info; <answer> struct 
struct device *dev = <token> <answer> &pdev->dev; 
struct rkisp1_device <token> <answer> *rkisp1; 
<token> v4l2_device *v4l2_dev; <answer> struct 
unsigned int <token> <answer> i; 
<token> dma_mask; <answer> u64 
int ret, <token> <answer> irq; 
<token> cif_id; <answer> u32 
<token> = devm_kzalloc(dev, sizeof(*rkisp1), GFP_KERNEL); <answer> rkisp1 
if <token> <answer> (!rkisp1) 
return <token> <answer> -ENOMEM; 
info <token> of_device_get_match_data(dev); <answer> = 
<token> = info; <answer> rkisp1->info 
dev_set_drvdata(dev, <token> <answer> rkisp1); 
rkisp1->dev = <token> <answer> dev; 
<token> = rkisp1_has_feature(rkisp1, DMA_34BIT) ? DMA_BIT_MASK(34) : <answer> dma_mask 
ret <token> dma_set_mask_and_coherent(dev, dma_mask); <answer> = 
if <token> <answer> (ret) 
return <token> <answer> ret; 
rkisp1->base_addr = devm_platform_ioremap_resource(pdev, <token> <answer> 0); 
if <token> <answer> (IS_ERR(rkisp1->base_addr)) 
return <token> <answer> PTR_ERR(rkisp1->base_addr); 
<token> (unsigned int il = 0; il < ARRAY_SIZE(rkisp1->irqs); ++il) <answer> for 
rkisp1->irqs[il] <token> -1; <answer> = 
for (i = <token> i < info->isr_size; i++) { <answer> 0; 
irq <token> info->isrs[i].name <answer> = 
? platform_get_irq_byname(pdev, <token> <answer> info->isrs[i].name) 
: platform_get_irq(pdev, <token> <answer> i); 
if <token> < 0) <answer> (irq 
return <token> <answer> irq; 
<token> (unsigned int il = 0; il < ARRAY_SIZE(rkisp1->irqs); ++il) { <answer> for 
if (info->isrs[i].line_mask & <token> <answer> BIT(il)) 
rkisp1->irqs[il] = <token> <answer> irq; 
ret = devm_request_irq(dev, irq, info->isrs[i].isr, <token> <answer> IRQF_SHARED, 
<token> dev); <answer> dev_driver_string(dev), 
if <token> { <answer> (ret) 
dev_err(dev, "request irq <token> %d\n", ret); <answer> failed: 
<token> ret; <answer> return 
<token> (i = 0; i < info->clk_size; i++) <answer> for 
rkisp1->clks[i].id = <token> <answer> info->clks[i]; 
ret = devm_clk_bulk_get(dev, <token> rkisp1->clks); <answer> info->clk_size, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> = info->clk_size; <answer> rkisp1->clk_size 
if (info->isp_ver <token> RKISP1_V_IMX8MP) { <answer> == 
unsigned <token> id; <answer> int 
<token> = syscon_regmap_lookup_by_phandle_args(dev->of_node, <answer> rkisp1->gasket 
<token> &id); <answer> 1, 
if (IS_ERR(rkisp1->gasket)) <token> <answer> { 
ret <token> PTR_ERR(rkisp1->gasket); <answer> = 
dev_err(dev, "failed to get gasket: %d\n", <token> <answer> ret); 
return <token> <answer> ret; 
<token> = id; <answer> rkisp1->gasket_id 
ret <token> pm_runtime_resume_and_get(&pdev->dev); <answer> = 
if <token> <answer> (ret) 
<token> err_pm_runtime_disable; <answer> goto 
cif_id = <token> RKISP1_CIF_VI_ID); <answer> rkisp1_read(rkisp1, 
dev_dbg(rkisp1->dev, <token> 0x%08x\n", cif_id); <answer> "CIF_ID 
rkisp1->media_dev.hw_revision <token> info->isp_ver; <answer> = 
strscpy(rkisp1->media_dev.model, <token> <answer> RKISP1_DRIVER_NAME, 
<token> = &pdev->dev; <answer> rkisp1->media_dev.dev 
strscpy(rkisp1->media_dev.bus_info, <token> <answer> RKISP1_BUS_INFO, 
v4l2_dev <token> &rkisp1->v4l2_dev; <answer> = 
v4l2_dev->mdev = <token> <answer> &rkisp1->media_dev; 
strscpy(v4l2_dev->name, RKISP1_DRIVER_NAME, <token> <answer> sizeof(v4l2_dev->name)); 
<token> = v4l2_device_register(rkisp1->dev, &rkisp1->v4l2_dev); <answer> ret 
<token> (ret) <answer> if 
<token> err_media_dev_cleanup; <answer> goto 
<token> = media_device_register(&rkisp1->media_dev); <answer> ret 
if <token> { <answer> (ret) 
<token> "Failed to register media device: %d\n", ret); <answer> dev_err(dev, 
<token> err_unreg_v4l2_dev; <answer> goto 
<token> (rkisp1->info->features & RKISP1_FEATURE_MIPI_CSI2) { <answer> if 
ret <token> rkisp1_csi_init(rkisp1); <answer> = 
if <token> <answer> (ret) 
goto <token> <answer> err_unreg_media_dev; 
ret <token> rkisp1_entities_register(rkisp1); <answer> = 
<token> (ret) <answer> if 
goto <token> <answer> err_cleanup_csi; 
ret <token> rkisp1_subdev_notifier_register(rkisp1); <answer> = 
if <token> <answer> (ret) 
<token> err_unreg_entities; <answer> goto 
return <token> <answer> 0; 
<token> (rkisp1_has_feature(rkisp1, MIPI_CSI2)) <answer> if 
return <token> <answer> ret; 
<token> void rkisp1_remove(struct platform_device *pdev) <answer> static 
struct rkisp1_device <token> = platform_get_drvdata(pdev); <answer> *rkisp1 
if (rkisp1_has_feature(rkisp1, <token> <answer> MIPI_CSI2)) 
<token> struct platform_driver rkisp1_drv = { <answer> static 
<token> = { <answer> .driver 
.name <token> RKISP1_DRIVER_NAME, <answer> = 
.of_match_table = <token> <answer> of_match_ptr(rkisp1_of_match), 
<token> = &rkisp1_pm_ops, <answer> .pm 
.probe <token> rkisp1_probe, <answer> = 
.remove_new = <token> <answer> rkisp1_remove, 
MODULE_DESCRIPTION("Rockchip ISP1 platform <token> <answer> driver"); 
MODULE_LICENSE("Dual <token> <answer> MIT/GPL"); 
<token> <arpa/inet.h> <answer> #include 
#include <token> <answer> <linux/if_link.h> 
#include <token> <answer> <linux/if_tun.h> 
<token> <linux/limits.h> <answer> #include 
#include <token> <answer> <linux/sysctl.h> 
<token> <linux/time_types.h> <answer> #include 
#include <token> <answer> <linux/net_tstamp.h> 
<token> <net/if.h> <answer> #include 
#include <token> <answer> <stdbool.h> 
<token> <stdio.h> <answer> #include 
<token> <sys/stat.h> <answer> #include 
#include <token> <answer> <unistd.h> 
#include <token> <answer> "test_progs.h" 
#include <token> <answer> "network_helpers.h" 
<token> "test_tunnel_kern.skel.h" <answer> #include 
<token> IP4_ADDR_VETH0 "172.16.1.100" <answer> #define 
<token> IP4_ADDR1_VETH1 "172.16.1.200" <answer> #define 
#define IP4_ADDR2_VETH1 <token> <answer> "172.16.1.20" 
#define <token> "10.1.1.100" <answer> IP4_ADDR_TUNL_DEV0 
#define <token> "10.1.1.200" <answer> IP4_ADDR_TUNL_DEV1 
<token> IP6_ADDR_VETH0 "::11" <answer> #define 
#define IP6_ADDR1_VETH1 <token> <answer> "::22" 
<token> IP6_ADDR2_VETH1 "::bb" <answer> #define 
<token> IP4_ADDR1_HEX_VETH1 0xac1001c8 <answer> #define 
<token> IP4_ADDR2_HEX_VETH1 0xac100114 <answer> #define 
<token> IP6_ADDR1_HEX_VETH1 0x22 <answer> #define 
#define IP6_ADDR2_HEX_VETH1 <token> <answer> 0xbb 
#define <token> "52:54:00:d9:01:00" <answer> MAC_TUNL_DEV0 
#define <token> "52:54:00:d9:02:00" <answer> MAC_TUNL_DEV1 
#define <token> "52:54:00:d9:03:00" <answer> MAC_VETH1 
#define VXLAN_TUNL_DEV0 <token> <answer> "vxlan00" 
<token> VXLAN_TUNL_DEV1 "vxlan11" <answer> #define 
<token> IP6VXLAN_TUNL_DEV0 "ip6vxlan00" <answer> #define 
#define <token> "ip6vxlan11" <answer> IP6VXLAN_TUNL_DEV1 
<token> IPIP_TUNL_DEV0 "ipip00" <answer> #define 
#define IPIP_TUNL_DEV1 <token> <answer> "ipip11" 
#define <token> "0x1111111111111111111111111111111111111111" <answer> XFRM_AUTH 
#define <token> "0x22222222222222222222222222222222" <answer> XFRM_ENC 
<token> XFRM_SPI_IN_TO_OUT 0x1 <answer> #define 
#define XFRM_SPI_OUT_TO_IN <token> <answer> 0x2 
#define PING_ARGS <token> 0.01 -c 3 -w 10 -q" <answer> "-i 
static int <token> <answer> config_device(void) 
SYS(fail, "ip netns <token> at_ns0"); <answer> add 
SYS(fail, "ip link add veth0 address " MAC_VETH1 " type veth peer name <token> <answer> veth1"); 
SYS(fail, "ip link set <token> netns at_ns0"); <answer> veth0 
<token> "ip addr add " IP4_ADDR1_VETH1 "/24 dev veth1"); <answer> SYS(fail, 
SYS(fail, "ip link set dev veth1 up <token> 1500"); <answer> mtu 
SYS(fail, "ip netns <token> at_ns0 ip addr add " IP4_ADDR_VETH0 "/24 dev veth0"); <answer> exec 
<token> "ip netns exec at_ns0 ip link set dev veth0 up mtu 1500"); <answer> SYS(fail, 
<token> 0; <answer> return 
return <token> <answer> -1; 
static void <token> <answer> cleanup(void) 
SYS_NOFAIL("test -f <token> && ip netns delete at_ns0"); <answer> /var/run/netns/at_ns0 
SYS_NOFAIL("ip <token> del veth1"); <answer> link 
SYS_NOFAIL("ip link <token> %s", VXLAN_TUNL_DEV1); <answer> del 
SYS_NOFAIL("ip <token> del %s", IP6VXLAN_TUNL_DEV1); <answer> link 
static int <token> <answer> add_vxlan_tunnel(void) 
"ip netns exec at_ns0 <token> <answer> " 
"ip xfrm state add src %s dst %s <token> esp " <answer> proto 
"spi %d reqid 1 mode <token> replay-window 42 " <answer> tunnel 
<token> 'hmac(sha1)' %s 96 enc 'cbc(aes)' %s", <answer> "auth-trunc 
<token> IP4_ADDR1_VETH1, XFRM_SPI_IN_TO_OUT, XFRM_AUTH, XFRM_ENC); <answer> IP4_ADDR_VETH0, 
<token> netns exec at_ns0 " <answer> "ip 
"ip xfrm policy <token> src %s/32 dst %s/32 dir out " <answer> add 
"tmpl src <token> dst %s proto esp reqid 1 " <answer> %s 
"mode <token> <answer> tunnel", 
IP4_ADDR_TUNL_DEV0, <token> IP4_ADDR_VETH0, IP4_ADDR1_VETH1); <answer> IP4_ADDR_TUNL_DEV1, 
<token> xfrm state add src %s dst %s proto esp " <answer> "ip 
"spi %d reqid 1 mode tunnel replay-window <token> " <answer> 42 
<token> 'hmac(sha1)' %s 96 enc 'cbc(aes)' %s", <answer> "auth-trunc 
IP4_ADDR_VETH0, IP4_ADDR1_VETH1, XFRM_SPI_IN_TO_OUT, XFRM_AUTH, <token> <answer> XFRM_ENC); 
"ip xfrm policy add src <token> dst %s/32 dir in " <answer> %s/32 
"tmpl src %s dst %s proto <token> reqid 1 " <answer> esp 
"mode <token> <answer> tunnel", 
IP4_ADDR_TUNL_DEV0, <token> IP4_ADDR_VETH0, IP4_ADDR1_VETH1); <answer> IP4_ADDR_TUNL_DEV1, 
err = pthread_create(&test_thread, NULL, &test_tunnel_run_tests, <token> <answer> NULL); 
if <token> "pthread_create")) <answer> (ASSERT_OK(err, 
<token> NULL), "pthread_join"); <answer> ASSERT_OK(pthread_join(test_thread, 
cptvf->pfvf_mbox_base = cptvf->reg_base <token> <answer> + 
<token> else { <answer> } 
offset <token> pci_resource_start(pdev, PCI_MBOX_BAR_NUM); <answer> = 
size = <token> PCI_MBOX_BAR_NUM); <answer> pci_resource_len(pdev, 
<token> "cgroup-internal.h" <answer> #include 
<token> <linux/sched/cputime.h> <answer> #include 
#include <token> <answer> <linux/bpf.h> 
<token> <linux/btf.h> <answer> #include 
<token> <linux/btf_ids.h> <answer> #include 
<token> DEFINE_SPINLOCK(cgroup_rstat_lock); <answer> static 
static DEFINE_PER_CPU(raw_spinlock_t, <token> <answer> cgroup_rstat_cpu_lock); 
static void cgroup_base_stat_flush(struct <token> *cgrp, int cpu); <answer> cgroup 
static struct cgroup_rstat_cpu <token> cgroup *cgrp, int cpu) <answer> *cgroup_rstat_cpu(struct 
return per_cpu_ptr(cgrp->rstat_cpu, <token> <answer> cpu); 
__bpf_kfunc void <token> cgroup *cgrp, int cpu) <answer> cgroup_rstat_updated(struct 
raw_spinlock_t <token> = per_cpu_ptr(&cgroup_rstat_cpu_lock, cpu); <answer> *cpu_lock 
unsigned long <token> <answer> flags; 
if (data_race(cgroup_rstat_cpu(cgrp, <token> <answer> cpu)->updated_next)) 
<token> flags); <answer> raw_spin_lock_irqsave(cpu_lock, 
<token> (rstatc->updated_next) <answer> if 
static struct cgroup *cgroup_rstat_push_children(struct <token> *head, <answer> cgroup 
struct <token> *child, int cpu) <answer> cgroup 
static struct cgroup <token> cgroup *root, int cpu) <answer> *cgroup_rstat_updated_list(struct 
raw_spinlock_t *cpu_lock = <token> cpu); <answer> per_cpu_ptr(&cgroup_rstat_cpu_lock, 
<token> cgroup_rstat_cpu *rstatc = cgroup_rstat_cpu(root, cpu); <answer> struct 
struct cgroup *head = <token> *parent, *child; <answer> NULL, 
unsigned <token> flags; <answer> long 
<token> flags); <answer> raw_spin_lock_irqsave(cpu_lock, 
<token> = cgroup_parent(root); <answer> parent 
<token> (parent) { <answer> if 
struct <token> *prstatc; <answer> cgroup_rstat_cpu 
struct cgroup <token> <answer> **nextp; 
prstatc = <token> cpu); <answer> cgroup_rstat_cpu(parent, 
nextp = <token> <answer> &prstatc->updated_children; 
while (*nextp != <token> { <answer> root) 
struct <token> *nrstatc; <answer> cgroup_rstat_cpu 
<token> = cgroup_rstat_cpu(*nextp, cpu); <answer> nrstatc 
<token> == parent); <answer> WARN_ON_ONCE(*nextp 
nextp <token> &nrstatc->updated_next; <answer> = 
*nextp = <token> <answer> rstatc->updated_next; 
<token> = NULL; <answer> rstatc->updated_next 
__weak <token> void bpf_rstat_flush(struct cgroup *cgrp, <answer> noinline 
<token> cgroup *parent, int cpu) <answer> struct 
__bpf_kfunc void <token> cgroup *cgrp) <answer> cgroup_rstat_flush(struct 
void cgroup_rstat_flush_hold(struct <token> *cgrp) <answer> cgroup 
<token> cgroup_rstat_flush_release(void) <answer> void 
int cgroup_rstat_init(struct <token> *cgrp) <answer> cgroup 
int <token> <answer> cpu; 
static void <token> cgroup_base_stat *dst_bstat, <answer> cgroup_base_stat_add(struct 
<token> cgroup_base_stat *src_bstat) <answer> struct 
<token> += src_bstat->cputime.utime; <answer> dst_bstat->cputime.utime 
dst_bstat->cputime.stime <token> src_bstat->cputime.stime; <answer> += 
dst_bstat->cputime.sum_exec_runtime <token> src_bstat->cputime.sum_exec_runtime; <answer> += 
<token> CONFIG_SCHED_CORE <answer> #ifdef 
<token> += src_bstat->forceidle_sum; <answer> dst_bstat->forceidle_sum 
static <token> cgroup_base_stat_sub(struct cgroup_base_stat *dst_bstat, <answer> void 
struct cgroup_base_stat <token> <answer> *src_bstat) 
<token> -= src_bstat->cputime.utime; <answer> dst_bstat->cputime.utime 
dst_bstat->cputime.stime -= <token> <answer> src_bstat->cputime.stime; 
dst_bstat->cputime.sum_exec_runtime -= <token> <answer> src_bstat->cputime.sum_exec_runtime; 
<token> CONFIG_SCHED_CORE <answer> #ifdef 
dst_bstat->forceidle_sum <token> src_bstat->forceidle_sum; <answer> -= 
static void cgroup_base_stat_flush(struct cgroup *cgrp, int <token> <answer> cpu) 
struct cgroup_rstat_cpu <token> = cgroup_rstat_cpu(cgrp, cpu); <answer> *rstatc 
struct <token> *parent = cgroup_parent(cgrp); <answer> cgroup 
struct cgroup_rstat_cpu <token> <answer> *prstatc; 
struct <token> delta; <answer> cgroup_base_stat 
<token> seq; <answer> unsigned 
static void <token> cgroup_base_stat *bstat) <answer> root_cgroup_cputime(struct 
struct <token> *cputime = &bstat->cputime; <answer> task_cputime 
int <token> <answer> i; 
memset(bstat, 0, <token> <answer> sizeof(*bstat)); 
for_each_possible_cpu(i) <token> <answer> { 
struct kernel_cpustat <token> <answer> kcpustat; 
u64 *cpustat = <token> <answer> kcpustat.cpustat; 
<token> user = 0; <answer> u64 
u64 <token> = 0; <answer> sys 
kcpustat_cpu_fetch(&kcpustat, <token> <answer> i); 
<token> += cpustat[CPUTIME_USER]; <answer> user 
user <token> cpustat[CPUTIME_NICE]; <answer> += 
cputime->utime += <token> <answer> user; 
<token> += cpustat[CPUTIME_SYSTEM]; <answer> sys 
<token> += cpustat[CPUTIME_IRQ]; <answer> sys 
sys <token> cpustat[CPUTIME_SOFTIRQ]; <answer> += 
cputime->stime += <token> <answer> sys; 
cputime->sum_exec_runtime += <token> <answer> user; 
<token> += sys; <answer> cputime->sum_exec_runtime 
cputime->sum_exec_runtime <token> cpustat[CPUTIME_STEAL]; <answer> += 
<token> CONFIG_SCHED_CORE <answer> #ifdef 
bstat->forceidle_sum += <token> <answer> cpustat[CPUTIME_FORCEIDLE]; 
void <token> seq_file *seq) <answer> cgroup_base_stat_cputime_show(struct 
struct cgroup *cgrp = <token> <answer> seq_css(seq)->cgroup; 
<token> usage, utime, stime; <answer> u64 
<token> cgroup_base_stat bstat; <answer> struct 
#ifdef <token> <answer> CONFIG_SCHED_CORE 
<token> forceidle_time; <answer> u64 
if (cgroup_parent(cgrp)) <token> <answer> { 
<token> = cgrp->bstat.cputime.sum_exec_runtime; <answer> usage 
cputime_adjust(&cgrp->bstat.cputime, <token> <answer> &cgrp->prev_cputime, 
&utime, <token> <answer> &stime); 
#ifdef <token> <answer> CONFIG_SCHED_CORE 
forceidle_time <token> cgrp->bstat.forceidle_sum; <answer> = 
<token> else { <answer> } 
<token> = bstat.cputime.sum_exec_runtime; <answer> usage 
<token> = bstat.cputime.utime; <answer> utime 
stime = <token> <answer> bstat.cputime.stime; 
<token> CONFIG_SCHED_CORE <answer> #ifdef 
<token> = bstat.forceidle_sum; <answer> forceidle_time 
do_div(usage, <token> <answer> NSEC_PER_USEC); 
<token> NSEC_PER_USEC); <answer> do_div(utime, 
<token> NSEC_PER_USEC); <answer> do_div(stime, 
#ifdef <token> <answer> CONFIG_SCHED_CORE 
<token> NSEC_PER_USEC); <answer> do_div(forceidle_time, 
seq_printf(seq, <token> %llu\n" <answer> "usage_usec 
"user_usec <token> <answer> %llu\n" 
"system_usec <token> <answer> %llu\n", 
usage, utime, <token> <answer> stime); 
<token> CONFIG_SCHED_CORE <answer> #ifdef 
seq_printf(seq, <token> %llu\n", forceidle_time); <answer> "core_sched.force_idle_usec 
<token> <linux/init.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/types.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/mutex.h> 
<token> <linux/gpio/driver.h> <answer> #include 
<token> <linux/gpio/legacy-of-mm-gpiochip.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
<token> <linux/slab.h> <answer> #include 
<token> <lantiq_soc.h> <answer> #include 
static void ltq_mm_apply(struct ltq_mm <token> <answer> *chip) 
<token> long flags; <answer> unsigned 
<token> flags); <answer> spin_lock_irqsave(&ebu_lock, 
ltq_ebu_w32(LTQ_EBU_BUSCON, <token> <answer> LTQ_EBU_BUSCON1); 
<token> chip->mmchip.regs); <answer> __raw_writew(chip->shadow, 
<token> | LTQ_EBU_WP, LTQ_EBU_BUSCON1); <answer> ltq_ebu_w32(LTQ_EBU_BUSCON 
<token> flags); <answer> spin_unlock_irqrestore(&ebu_lock, 
<token> void ltq_mm_set(struct gpio_chip *gc, unsigned offset, int value) <answer> static 
<token> ltq_mm *chip = gpiochip_get_data(gc); <answer> struct 
if <token> <answer> (value) 
chip->shadow |= (1 << <token> <answer> offset); 
chip->shadow &= <token> << offset); <answer> ~(1 
static int ltq_mm_dir_out(struct gpio_chip <token> unsigned offset, int value) <answer> *gc, 
ltq_mm_set(gc, <token> value); <answer> offset, 
return <token> <answer> 0; 
static void <token> of_mm_gpio_chip *mm_gc) <answer> ltq_mm_save_regs(struct 
struct ltq_mm <token> = <answer> *chip 
container_of(mm_gc, struct <token> mmchip); <answer> ltq_mm, 
<token> <linux/err.h> <answer> #include 
<token> <linux/i2c.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/irq.h> <answer> #include 
#include <token> <answer> <linux/regulator/driver.h> 
#include <token> <answer> <linux/regulator/machine.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/regulator/of_regulator.h> 
<token> <linux/regmap.h> <answer> #include 
<token> "da9210-regulator.h" <answer> #include 
struct da9210 <token> <answer> { 
struct <token> *rdev; <answer> regulator_dev 
<token> regmap *regmap; <answer> struct 
static const struct regmap_config <token> = { <answer> da9210_regmap_config 
.reg_bits = <token> <answer> 8, 
<token> = 8, <answer> .val_bits 
static const <token> regulator_ops da9210_buck_ops = { <answer> struct 
<token> = regulator_enable_regmap, <answer> .enable 
<token> = regulator_disable_regmap, <answer> .disable 
.is_enabled <token> regulator_is_enabled_regmap, <answer> = 
<token> = regulator_set_voltage_sel_regmap, <answer> .set_voltage_sel 
.get_voltage_sel <token> regulator_get_voltage_sel_regmap, <answer> = 
.list_voltage <token> regulator_list_voltage_linear, <answer> = 
.set_current_limit <token> regulator_set_current_limit_regmap, <answer> = 
.get_current_limit = <token> <answer> regulator_get_current_limit_regmap, 
static <token> struct of_device_id __maybe_unused da9210_dt_ids[] = { <answer> const 
<token> .compatible = "dlg,da9210", }, <answer> { 
{ <token> <answer> } 
MODULE_DEVICE_TABLE(of, <token> <answer> da9210_dt_ids); 
static int da9210_i2c_probe(struct <token> *i2c) <answer> i2c_client 
struct <token> *chip; <answer> da9210 
struct device *dev = <token> <answer> &i2c->dev; 
<token> da9210_pdata *pdata = dev_get_platdata(dev); <answer> struct 
struct regulator_dev *rdev = <token> <answer> NULL; 
<token> regulator_config config = { }; <answer> struct 
<token> error; <answer> int 
chip = devm_kzalloc(&i2c->dev, sizeof(struct da9210), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!chip) 
<token> -ENOMEM; <answer> return 
chip->regmap <token> devm_regmap_init_i2c(i2c, &da9210_regmap_config); <answer> = 
if (IS_ERR(chip->regmap)) <token> <answer> { 
<token> = PTR_ERR(chip->regmap); <answer> error 
dev_err(&i2c->dev, "Failed <token> allocate register map: %d\n", <answer> to 
<token> error; <answer> return 
<token> = &i2c->dev; <answer> config.dev 
<token> = pdata ? &pdata->da9210_constraints : <answer> config.init_data 
of_get_regulator_init_data(dev, dev->of_node, <token> <answer> &da9210_reg); 
config.driver_data <token> chip; <answer> = 
config.regmap <token> chip->regmap; <answer> = 
<token> = dev->of_node; <answer> config.of_node 
<token> <media/v4l2-ctrls.h> <answer> #include 
<token> <media/v4l2-device.h> <answer> #include 
#include <token> <answer> <media/v4l2-ioctl.h> 
<token> <media/v4l2-mc.h> <answer> #include 
<token> <media/v4l2-subdev.h> <answer> #include 
#include <token> <answer> <media/imx.h> 
<token> "imx-media.h" <answer> #include 
<token> vdic_priv; <answer> struct 
<token> vdic_pipeline_ops { <answer> struct 
int (*setup)(struct <token> *priv); <answer> vdic_priv 
void <token> vdic_priv *priv); <answer> (*start)(struct 
void <token> vdic_priv *priv); <answer> (*stop)(struct 
void <token> vdic_priv *priv); <answer> (*disable)(struct 
#define <token> 32 <answer> MIN_W 
<token> MIN_H 32 <answer> #define 
#define <token> 968 <answer> MAX_W_VDIC 
#define MAX_H_VDIC <token> <answer> 2048 
u32 <token> <answer> fieldtype; 
u32 <token> <answer> in_stride; 
u32 <token> <answer> field_size; 
static <token> __maybe_unused prepare_vdi_in_buffers(struct vdic_priv *priv, <answer> void 
struct imx_media_buffer <token> <answer> *curr) 
dma_addr_t prev_phys, <token> next_phys; <answer> curr_phys, 
struct <token> *prev; <answer> imx_media_buffer 
struct <token> *curr_vb, *prev_vb; <answer> vb2_buffer 
u32 fs = <token> <answer> priv->field_size; 
u32 is = <token> <answer> priv->in_stride; 
<token> 0, prev_phys); <answer> ipu_cpmem_set_buffer(priv->vdi_in_ch_p, 
ipu_cpmem_set_buffer(priv->vdi_in_ch, <token> curr_phys); <answer> 0, 
ipu_cpmem_set_buffer(priv->vdi_in_ch_n, <token> next_phys); <answer> 0, 
<token> 0); <answer> ipu_idmac_select_buffer(priv->vdi_in_ch_p, 
ipu_idmac_select_buffer(priv->vdi_in_ch, <token> <answer> 0); 
<token> 0); <answer> ipu_idmac_select_buffer(priv->vdi_in_ch_n, 
static int setup_vdi_channel(struct vdic_priv <token> <answer> *priv, 
<token> ipuv3_channel *channel, <answer> struct 
<token> phys0, dma_addr_t phys1) <answer> dma_addr_t 
struct imx_media_video_dev *vdev = <token> <answer> priv->vdev; 
<token> int burst_size; <answer> unsigned 
struct ipu_image <token> <answer> image; 
int <token> <answer> ret; 
memset(&image, 0, <token> <answer> sizeof(image)); 
image.pix = <token> <answer> vdev->fmt; 
<token> = vdev->compose; <answer> image.rect 
<token> MEDIA_BUS_FMT_UYVY8_2X8, <answer> ipu_vdi_setup(priv->vdi, 
<token> infmt->height); <answer> infmt->width, 
ipu_vdi_set_field_order(priv->vdi, V4L2_STD_UNKNOWN, <token> <answer> infmt->field); 
ipu_vdi_set_motion(priv->vdi, <token> <answer> priv->motion); 
ret = <token> <answer> priv->ops->setup(priv); 
<token> (ret) <answer> if 
goto <token> <answer> out_put_ipu; 
<token> 0; <answer> return 
return <token> <answer> ret; 
static void vdic_stop(struct vdic_priv <token> <answer> *priv) 
static int vdic_s_ctrl(struct v4l2_ctrl <token> <answer> *ctrl) 
struct vdic_priv <token> = container_of(ctrl->handler, <answer> *priv 
<token> vdic_priv, ctrl_hdlr); <answer> struct 
enum <token> motion; <answer> ipu_motion_sel 
int ret <token> 0; <answer> = 
switch <token> { <answer> (ctrl->id) 
case <token> <answer> V4L2_CID_DEINTERLACING_MODE: 
<token> = ctrl->val; <answer> motion 
if (motion != <token> { <answer> priv->motion) 
if (priv->stream_count != <token> <answer> !enable) 
<token> update_count; <answer> goto 
dev_dbg(priv->ipu_dev, "%s: <token> %s\n", sd->name, <answer> stream 
enable ? "ON" <token> "OFF"); <answer> : 
if <token> <answer> (enable) 
ret = <token> <answer> vdic_start(priv); 
<token> (ret) <answer> if 
goto <token> <answer> out; 
<token> (src_sd) { <answer> if 
if (fi->which != <token> <answer> V4L2_SUBDEV_FORMAT_ACTIVE) 
return <token> <answer> -EINVAL; 
<token> (fi->pad >= VDIC_NUM_PADS) <answer> if 
return <token> <answer> -EINVAL; 
fi->interval = <token> <answer> priv->frame_interval[fi->pad]; 
return <token> <answer> 0; 
<token> int vdic_set_frame_interval(struct v4l2_subdev *sd, <answer> static 
struct v4l2_subdev_state <token> <answer> *sd_state, 
<token> v4l2_subdev_frame_interval *fi) <answer> struct 
struct vdic_priv *priv = <token> <answer> v4l2_get_subdevdata(sd); 
<token> v4l2_fract *input_fi, *output_fi; <answer> struct 
int ret <token> 0; <answer> = 
if (fi->which <token> V4L2_SUBDEV_FORMAT_ACTIVE) <answer> != 
<token> -EINVAL; <answer> return 
input_fi <token> &priv->frame_interval[priv->active_input_pad]; <answer> = 
<token> = &priv->frame_interval[VDIC_SRC_PAD_DIRECT]; <answer> output_fi 
switch <token> { <answer> (fi->pad) 
<token> VDIC_SINK_PAD_DIRECT: <answer> case 
case <token> <answer> VDIC_SINK_PAD_IDMAC: 
fi->interval <token> *input_fi; <answer> = 
if <token> <answer> (priv->csi_direct) 
fi->interval.denominator *= <token> <answer> 2; 
ret = <token> <answer> -EINVAL; 
goto <token> <answer> out; 
priv->frame_interval[fi->pad] <token> fi->interval; <answer> = 
return <token> <answer> ret; 
static <token> vdic_registered(struct v4l2_subdev *sd) <answer> int 
<token> vdic_priv *priv = v4l2_get_subdevdata(sd); <answer> struct 
int i, <token> <answer> ret; 
<token> code; <answer> u32 
for (i = <token> i < VDIC_NUM_PADS; i++) { <answer> 0; 
code <token> 0; <answer> = 
if (i != <token> <answer> VDIC_SINK_PAD_IDMAC) 
<token> 0, PIXFMT_SEL_YUV); <answer> imx_media_enum_ipu_formats(&code, 
mt76_wr(dev, MT_SWDEF_MODE, <token> <answer> MT_SWDEF_NORMAL_MODE); 
ret = <token> <answer> mt792x_mcu_init(dev); 
if <token> <answer> (ret) 
goto <token> <answer> out; 
ret = <token> <answer> mt7921_mcu_set_eeprom(dev); 
<token> (ret) <answer> if 
<token> out; <answer> goto 
ret = <token> <answer> mt7921_mac_init(dev); 
return <token> <answer> ret; 
static int mt7921_init_hardware(struct mt792x_dev <token> <answer> *dev) 
<token> ret, i; <answer> int 
set_bit(MT76_STATE_INITIALIZED, <token> <answer> &dev->mphy.state); 
for <token> = 0; i < MT792x_MCU_INIT_RETRY_COUNT; i++) { <answer> (i 
<token> = __mt7921_init_hardware(dev); <answer> ret 
if <token> <answer> (!ret) 
if <token> == MT792x_MCU_INIT_RETRY_COUNT) { <answer> (i 
<token> "hardware init failed\n"); <answer> dev_err(dev->mt76.dev, 
<token> ret; <answer> return 
<token> 0; <answer> return 
static void mt7921_init_work(struct <token> *work) <answer> work_struct 
struct mt792x_dev *dev <token> container_of(work, struct mt792x_dev, <answer> = 
<token> ret; <answer> int 
ret = <token> <answer> mt7921_init_hardware(dev); 
if <token> <answer> (ret) 
mt76_set_stream_caps(&dev->mphy, <token> <answer> true); 
<token> = mt76_register_device(&dev->mt76, true, mt76_rates, <answer> ret 
if <token> { <answer> (ret) 
<token> "register device failed\n"); <answer> dev_err(dev->mt76.dev, 
ret = <token> <answer> mt7921_init_debugfs(dev); 
if (ret) <token> <answer> { 
<token> "register debugfs failed\n"); <answer> dev_err(dev->mt76.dev, 
<token> = mt7921_thermal_init(&dev->phy); <answer> ret 
if <token> { <answer> (ret) 
dev_err(dev->mt76.dev, "thermal init <token> <answer> failed\n"); 
#include <token> <answer> <linux/dma-mapping.h> 
#include <token> <answer> <linux/font.h> 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <media/media-device.h> 
<token> <media/tpg/v4l2-tpg.h> <answer> #include 
#include <token> <answer> <media/v4l2-device.h> 
#include <token> <answer> "vimc-common.h" 
<token> int vimc_allocator; <answer> unsigned 
module_param_named(allocator, vimc_allocator, uint, <token> <answer> 0444); 
MODULE_PARM_DESC(allocator, " memory allocator selection, <token> is 0.\n" <answer> default 
"\t\t 0 == <token> <answer> vmalloc\n" 
"\t\t 1 == <token> <answer> dma-contig"); 
<token> VIMC_MDEV_MODEL_NAME "VIMC MDEV" <answer> #define 
#define VIMC_DATA_LINK(src, srcpad, sink, <token> link_flags) { \ <answer> sinkpad, 
.src_ent = <token> \ <answer> src, 
.src_pad <token> srcpad, \ <answer> = 
.sink_ent <token> sink, \ <answer> = 
.sink_pad = <token> \ <answer> sinkpad, 
.flags <token> link_flags, \ <answer> = 
<token> VIMC_ANCILLARY_LINK(primary, ancillary) { \ <answer> #define 
.primary_ent = <token> \ <answer> primary, 
<token> = ancillary \ <answer> .ancillary_ent 
static struct vimc_ent_config <token> = { <answer> ent_config[] 
[SENSOR_A] <token> { <answer> = 
<token> = "Sensor A", <answer> .name 
<token> = &vimc_sensor_type <answer> .type 
[SENSOR_B] = <token> <answer> { 
.name = "Sensor <token> <answer> B", 
.type = <token> <answer> &vimc_sensor_type 
[DEBAYER_A] <token> { <answer> = 
.name = <token> A", <answer> "Debayer 
.type = <token> <answer> &vimc_debayer_type 
<token> = { <answer> [DEBAYER_B] 
<token> = "Debayer B", <answer> .name 
.type <token> &vimc_debayer_type <answer> = 
<token> = { <answer> [RAW_CAPTURE_0] 
<token> = "Raw Capture 0", <answer> .name 
<token> = &vimc_capture_type <answer> .type 
[RAW_CAPTURE_1] = <token> <answer> { 
.name = "Raw <token> 1", <answer> Capture 
.type <token> &vimc_capture_type <answer> = 
<token> = { <answer> [RGB_YUV_INPUT] 
vimc->v4l2_dev.release = <token> <answer> vimc_v4l2_dev_release; 
<token> vimc); <answer> platform_set_drvdata(pdev, 
return <token> <answer> 0; 
<token> void vimc_remove(struct platform_device *pdev) <answer> static 
struct vimc_device <token> = platform_get_drvdata(pdev); <answer> *vimc 
dev_dbg(&pdev->dev, <token> <answer> "remove"); 
static void <token> device *dev) <answer> vimc_dev_release(struct 
static struct platform_device vimc_pdev <token> { <answer> = 
.name = <token> <answer> VIMC_PDEV_NAME, 
<token> = vimc_dev_release, <answer> .dev.release 
<token> struct platform_driver vimc_pdrv = { <answer> static 
.probe = <token> <answer> vimc_probe, 
<token> = vimc_remove, <answer> .remove_new 
<token> = { <answer> .driver 
<token> = VIMC_PDEV_NAME, <answer> .name 
<token> int __init vimc_init(void) <answer> static 
int <token> <answer> ret; 
ret = <token> <answer> platform_device_register(&vimc_pdev); 
if <token> { <answer> (ret) 
"platform device registration <token> (err=%d)\n", ret); <answer> failed 
<token> ret; <answer> return 
<token> = platform_driver_register(&vimc_pdrv); <answer> ret 
if <token> { <answer> (ret) 
"platform driver registration failed <token> ret); <answer> (err=%d)\n", 
<token> ret; <answer> return 
<token> 0; <answer> return 
<token> void __exit vimc_exit(void) <answer> static 
<token> Media Controller Driver (VIMC)"); <answer> MODULE_DESCRIPTION("Virtual 
MODULE_AUTHOR("Helen <token> <helen.fornazier@gmail.com>"); <answer> Fornazier 
<token> <linux/clk.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/pm_domain.h> <answer> #include 
<token> <linux/pm_runtime.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
<token> <linux/regulator/consumer.h> <answer> #include 
#include <token> <answer> <linux/reset.h> 
#include <token> <answer> <linux/sizes.h> 
#include <token> <answer> <dt-bindings/power/imx7-power.h> 
<token> <dt-bindings/power/imx8mq-power.h> <answer> #include 
<token> <dt-bindings/power/imx8mm-power.h> <answer> #include 
#include <token> <answer> <dt-bindings/power/imx8mn-power.h> 
<token> <dt-bindings/power/imx8mp-power.h> <answer> #include 
#define <token> 0x000 <answer> GPC_LPCR_A_CORE_BSC 
<token> GPC_PGC_CPU_MAPPING 0x0ec <answer> #define 
<token> IMX8MP_GPC_PGC_CPU_MAPPING 0x1cc <answer> #define 
#define <token> BIT(6) <answer> IMX7_USB_HSIC_PHY_A_CORE_DOMAIN 
<token> IMX7_USB_OTG2_PHY_A_CORE_DOMAIN BIT(5) <answer> #define 
<token> IMX7_USB_OTG1_PHY_A_CORE_DOMAIN BIT(4) <answer> #define 
#define <token> BIT(3) <answer> IMX7_PCIE_PHY_A_CORE_DOMAIN 
<token> IMX7_MIPI_PHY_A_CORE_DOMAIN BIT(2) <answer> #define 
#define IMX8M_PCIE2_A53_DOMAIN <token> <answer> BIT(15) 
#define <token> BIT(14) <answer> IMX8M_MIPI_CSI2_A53_DOMAIN 
#define <token> BIT(13) <answer> IMX8M_MIPI_CSI1_A53_DOMAIN 
#define <token> BIT(12) <answer> IMX8M_DISP_A53_DOMAIN 
#define IMX8M_HDMI_A53_DOMAIN <token> <answer> BIT(11) 
<token> IMX8M_VPU_A53_DOMAIN BIT(10) <answer> #define 
<token> IMX8M_GPU_A53_DOMAIN BIT(9) <answer> #define 
<token> IMX8M_DDR2_A53_DOMAIN BIT(8) <answer> #define 
#define <token> BIT(7) <answer> IMX8M_DDR1_A53_DOMAIN 
#define <token> BIT(5) <answer> IMX8M_OTG2_A53_DOMAIN 
#define IMX8M_OTG1_A53_DOMAIN <token> <answer> BIT(4) 
<token> IMX8M_PCIE1_A53_DOMAIN BIT(3) <answer> #define 
#define IMX8M_MIPI_A53_DOMAIN <token> <answer> BIT(2) 
<token> IMX8MM_VPUH1_A53_DOMAIN BIT(15) <answer> #define 
<token> IMX8MM_VPUG2_A53_DOMAIN BIT(14) <answer> #define 
<token> IMX8MM_VPUG1_A53_DOMAIN BIT(13) <answer> #define 
<token> IMX8MM_DISPMIX_A53_DOMAIN BIT(12) <answer> #define 
#define IMX8MM_VPUMIX_A53_DOMAIN <token> <answer> BIT(10) 
<token> IMX8MM_GPUMIX_A53_DOMAIN BIT(9) <answer> #define 
#define IMX8MM_GPU_A53_DOMAIN <token> | BIT(11)) <answer> (BIT(8) 
#define <token> BIT(7) <answer> IMX8MM_DDR1_A53_DOMAIN 
<token> IMX8MM_OTG2_A53_DOMAIN BIT(5) <answer> #define 
#define IMX8MM_OTG1_A53_DOMAIN <token> <answer> BIT(4) 
<token> IMX8MM_PCIE_A53_DOMAIN BIT(3) <answer> #define 
<token> IMX8MM_MIPI_A53_DOMAIN BIT(2) <answer> #define 
#define <token> BIT(12) <answer> IMX8MN_DISPMIX_A53_DOMAIN 
<token> IMX8MN_GPUMIX_A53_DOMAIN BIT(9) <answer> #define 
<token> IMX8MN_DDR1_A53_DOMAIN BIT(7) <answer> #define 
#define <token> BIT(4) <answer> IMX8MN_OTG1_A53_DOMAIN 
#define IMX8MN_MIPI_A53_DOMAIN <token> <answer> BIT(2) 
<token> IMX8MP_MEDIA_ISPDWP_A53_DOMAIN BIT(20) <answer> #define 
#define <token> BIT(19) <answer> IMX8MP_HSIOMIX_A53_DOMAIN 
<token> IMX8MP_MIPI_PHY2_A53_DOMAIN BIT(18) <answer> #define 
#define IMX8MP_HDMI_PHY_A53_DOMAIN <token> <answer> BIT(17) 
#define IMX8MP_HDMIMIX_A53_DOMAIN <token> <answer> BIT(16) 
#define IMX8MP_VPU_VC8000E_A53_DOMAIN <token> <answer> BIT(15) 
<token> IMX8MP_VPU_G2_A53_DOMAIN BIT(14) <answer> #define 
#define IMX8MP_VPU_G1_A53_DOMAIN <token> <answer> BIT(13) 
#define <token> BIT(12) <answer> IMX8MP_MEDIAMIX_A53_DOMAIN 
<token> IMX8MP_GPU3D_A53_DOMAIN BIT(11) <answer> #define 
#define <token> BIT(10) <answer> IMX8MP_VPUMIX_A53_DOMAIN 
#define <token> BIT(9) <answer> IMX8MP_GPUMIX_A53_DOMAIN 
#define <token> BIT(8) <answer> IMX8MP_GPU2D_A53_DOMAIN 
#define IMX8MP_AUDIOMIX_A53_DOMAIN <token> <answer> BIT(7) 
#define <token> BIT(6) <answer> IMX8MP_MLMIX_A53_DOMAIN 
#define <token> BIT(5) <answer> IMX8MP_USB2_PHY_A53_DOMAIN 
<token> IMX8MP_USB1_PHY_A53_DOMAIN BIT(4) <answer> #define 
#define IMX8MP_PCIE_PHY_A53_DOMAIN <token> <answer> BIT(3) 
#define <token> BIT(2) <answer> IMX8MP_MIPI_PHY1_A53_DOMAIN 
<token> IMX8MP_GPC_PU_PGC_SW_PUP_REQ 0x0d8 <answer> #define 
<token> IMX8MP_GPC_PU_PGC_SW_PDN_REQ 0x0e4 <answer> #define 
#define GPC_PU_PGC_SW_PUP_REQ <token> <answer> 0x0f8 
#define GPC_PU_PGC_SW_PDN_REQ <token> <answer> 0x104 
<token> IMX7_USB_HSIC_PHY_SW_Pxx_REQ BIT(4) <answer> #define 
#define <token> BIT(3) <answer> IMX7_USB_OTG2_PHY_SW_Pxx_REQ 
<token> IMX7_USB_OTG1_PHY_SW_Pxx_REQ BIT(2) <answer> #define 
#define IMX7_PCIE_PHY_SW_Pxx_REQ <token> <answer> BIT(1) 
<token> IMX7_MIPI_PHY_SW_Pxx_REQ BIT(0) <answer> #define 
#define IMX8M_PCIE2_SW_Pxx_REQ <token> <answer> BIT(13) 
<token> IMX8M_MIPI_CSI2_SW_Pxx_REQ BIT(12) <answer> #define 
<token> IMX8M_MIPI_CSI1_SW_Pxx_REQ BIT(11) <answer> #define 
#define IMX8M_DISP_SW_Pxx_REQ <token> <answer> BIT(10) 
#define <token> BIT(9) <answer> IMX8M_HDMI_SW_Pxx_REQ 
#define <token> BIT(8) <answer> IMX8M_VPU_SW_Pxx_REQ 
#define <token> BIT(7) <answer> IMX8M_GPU_SW_Pxx_REQ 
#define <token> BIT(6) <answer> IMX8M_DDR2_SW_Pxx_REQ 
#define IMX8M_DDR1_SW_Pxx_REQ <token> <answer> BIT(5) 
#define IMX8M_OTG2_SW_Pxx_REQ <token> <answer> BIT(3) 
#define <token> BIT(2) <answer> IMX8M_OTG1_SW_Pxx_REQ 
#define <token> BIT(1) <answer> IMX8M_PCIE1_SW_Pxx_REQ 
#define IMX8M_MIPI_SW_Pxx_REQ <token> <answer> BIT(0) 
#define IMX8MM_VPUH1_SW_Pxx_REQ <token> <answer> BIT(13) 
#define <token> BIT(12) <answer> IMX8MM_VPUG2_SW_Pxx_REQ 
#define IMX8MM_VPUG1_SW_Pxx_REQ <token> <answer> BIT(11) 
<token> IMX8MM_DISPMIX_SW_Pxx_REQ BIT(10) <answer> #define 
<token> IMX8MM_VPUMIX_SW_Pxx_REQ BIT(8) <answer> #define 
<token> IMX8MM_GPUMIX_SW_Pxx_REQ BIT(7) <answer> #define 
#define IMX8MM_GPU_SW_Pxx_REQ <token> | BIT(9)) <answer> (BIT(6) 
#define <token> BIT(5) <answer> IMX8MM_DDR1_SW_Pxx_REQ 
#define IMX8MM_OTG2_SW_Pxx_REQ <token> <answer> BIT(3) 
#define IMX8MM_OTG1_SW_Pxx_REQ <token> <answer> BIT(2) 
#define <token> BIT(1) <answer> IMX8MM_PCIE_SW_Pxx_REQ 
#define <token> BIT(0) <answer> IMX8MM_MIPI_SW_Pxx_REQ 
#define <token> BIT(10) <answer> IMX8MN_DISPMIX_SW_Pxx_REQ 
#define <token> BIT(7) <answer> IMX8MN_GPUMIX_SW_Pxx_REQ 
<token> IMX8MN_DDR1_SW_Pxx_REQ BIT(5) <answer> #define 
<token> IMX8MN_OTG1_SW_Pxx_REQ BIT(2) <answer> #define 
#define <token> BIT(0) <answer> IMX8MN_MIPI_SW_Pxx_REQ 
#define IMX8MP_DDRMIX_Pxx_REQ <token> <answer> BIT(19) 
<token> IMX8MP_MEDIA_ISP_DWP_Pxx_REQ BIT(18) <answer> #define 
#define IMX8MP_HSIOMIX_Pxx_REQ <token> <answer> BIT(17) 
#define IMX8MP_MIPI_PHY2_Pxx_REQ <token> <answer> BIT(16) 
#define IMX8MP_HDMI_PHY_Pxx_REQ <token> <answer> BIT(15) 
#define <token> BIT(14) <answer> IMX8MP_HDMIMIX_Pxx_REQ 
<token> IMX8MP_VPU_VC8K_Pxx_REQ BIT(13) <answer> #define 
#define IMX8MP_VPU_G2_Pxx_REQ <token> <answer> BIT(12) 
<token> IMX8MP_VPU_G1_Pxx_REQ BIT(11) <answer> #define 
<token> IMX8MP_MEDIMIX_Pxx_REQ BIT(10) <answer> #define 
#define IMX8MP_GPU_3D_Pxx_REQ <token> <answer> BIT(9) 
#define <token> BIT(8) <answer> IMX8MP_VPU_MIX_SHARE_LOGIC_Pxx_REQ 
#define <token> BIT(7) <answer> IMX8MP_GPU_SHARE_LOGIC_Pxx_REQ 
#define IMX8MP_GPU_2D_Pxx_REQ <token> <answer> BIT(6) 
#define IMX8MP_AUDIOMIX_Pxx_REQ <token> <answer> BIT(5) 
#define <token> BIT(4) <answer> IMX8MP_MLMIX_Pxx_REQ 
#define <token> BIT(3) <answer> IMX8MP_USB2_PHY_Pxx_REQ 
#define <token> BIT(2) <answer> IMX8MP_USB1_PHY_Pxx_REQ 
#define IMX8MP_PCIE_PHY_SW_Pxx_REQ <token> <answer> BIT(1) 
#define IMX8MP_MIPI_PHY1_SW_Pxx_REQ <token> <answer> BIT(0) 
#define GPC_M4_PU_PDN_FLG <token> <answer> 0x1bc 
<token> IMX8MP_GPC_PU_PWRHSK 0x190 <answer> #define 
#define GPC_PU_PWRHSK <token> <answer> 0x1fc 
#define IMX8M_GPU_HSK_PWRDNACKN <token> <answer> BIT(26) 
#define IMX8M_VPU_HSK_PWRDNACKN <token> <answer> BIT(25) 
<token> IMX8M_DISP_HSK_PWRDNACKN BIT(24) <answer> #define 
#define IMX8M_GPU_HSK_PWRDNREQN <token> <answer> BIT(6) 
#define IMX8M_VPU_HSK_PWRDNREQN <token> <answer> BIT(5) 
<token> IMX8M_DISP_HSK_PWRDNREQN BIT(4) <answer> #define 
#define IMX8MM_GPUMIX_HSK_PWRDNACKN <token> <answer> BIT(29) 
#define IMX8MM_GPU_HSK_PWRDNACKN (BIT(27) | <token> <answer> BIT(28)) 
<token> IMX8MM_VPUMIX_HSK_PWRDNACKN BIT(26) <answer> #define 
#define <token> BIT(25) <answer> IMX8MM_DISPMIX_HSK_PWRDNACKN 
#define <token> (BIT(23) | BIT(24)) <answer> IMX8MM_HSIO_HSK_PWRDNACKN 
#define <token> BIT(11) <answer> IMX8MM_GPUMIX_HSK_PWRDNREQN 
<token> IMX8MM_GPU_HSK_PWRDNREQN (BIT(9) | BIT(10)) <answer> #define 
<token> IMX8MM_VPUMIX_HSK_PWRDNREQN BIT(8) <answer> #define 
<token> IMX8MM_DISPMIX_HSK_PWRDNREQN BIT(7) <answer> #define 
<token> IMX8MM_HSIO_HSK_PWRDNREQN (BIT(5) | BIT(6)) <answer> #define 
#define IMX8MN_GPUMIX_HSK_PWRDNACKN (BIT(29) | <token> <answer> BIT(27)) 
#define IMX8MN_DISPMIX_HSK_PWRDNACKN <token> <answer> BIT(25) 
#define IMX8MN_HSIO_HSK_PWRDNACKN <token> <answer> BIT(23) 
#define IMX8MN_GPUMIX_HSK_PWRDNREQN <token> | BIT(9)) <answer> (BIT(11) 
<token> IMX8MN_DISPMIX_HSK_PWRDNREQN BIT(7) <answer> #define 
#define <token> BIT(5) <answer> IMX8MN_HSIO_HSK_PWRDNREQN 
#define <token> BIT(30) <answer> IMX8MP_MEDIAMIX_PWRDNACKN 
#define <token> BIT(29) <answer> IMX8MP_HDMIMIX_PWRDNACKN 
#define IMX8MP_HSIOMIX_PWRDNACKN <token> <answer> BIT(28) 
#define <token> BIT(26) <answer> IMX8MP_VPUMIX_PWRDNACKN 
<token> IMX8MP_GPUMIX_PWRDNACKN BIT(25) <answer> #define 
#define <token> (BIT(23) | BIT(24)) <answer> IMX8MP_MLMIX_PWRDNACKN 
#define IMX8MP_AUDIOMIX_PWRDNACKN (BIT(20) <token> BIT(31)) <answer> | 
#define <token> BIT(14) <answer> IMX8MP_MEDIAMIX_PWRDNREQN 
<token> IMX8MP_HDMIMIX_PWRDNREQN BIT(13) <answer> #define 
#define IMX8MP_HSIOMIX_PWRDNREQN <token> <answer> BIT(12) 
#define IMX8MP_VPUMIX_PWRDNREQN <token> <answer> BIT(10) 
#define IMX8MP_GPUMIX_PWRDNREQN <token> <answer> BIT(9) 
<token> IMX8MP_MLMIX_PWRDNREQN (BIT(7) | BIT(8)) <answer> #define 
#define <token> (BIT(4) | BIT(15)) <answer> IMX8MP_AUDIOMIX_PWRDNREQN 
<token> IMX7_PGC_MIPI 16 <answer> #define 
<token> IMX7_PGC_PCIE 17 <answer> #define 
#define <token> 20 <answer> IMX7_PGC_USB_HSIC 
<token> IMX8M_PGC_MIPI 16 <answer> #define 
<token> IMX8M_PGC_PCIE1 17 <answer> #define 
#define <token> 18 <answer> IMX8M_PGC_OTG1 
#define <token> 19 <answer> IMX8M_PGC_OTG2 
<token> IMX8M_PGC_DDR1 21 <answer> #define 
#define IMX8M_PGC_GPU <token> <answer> 23 
<token> IMX8M_PGC_VPU 24 <answer> #define 
<token> IMX8M_PGC_DISP 26 <answer> #define 
#define <token> 27 <answer> IMX8M_PGC_MIPI_CSI1 
<token> IMX8M_PGC_MIPI_CSI2 28 <answer> #define 
#define IMX8M_PGC_PCIE2 <token> <answer> 29 
#define IMX8MM_PGC_MIPI <token> <answer> 16 
<token> IMX8MM_PGC_PCIE 17 <answer> #define 
#define IMX8MM_PGC_OTG1 <token> <answer> 18 
#define IMX8MM_PGC_OTG2 <token> <answer> 19 
#define <token> 21 <answer> IMX8MM_PGC_DDR1 
#define <token> 22 <answer> IMX8MM_PGC_GPU2D 
<token> IMX8MM_PGC_GPUMIX 23 <answer> #define 
#define <token> 24 <answer> IMX8MM_PGC_VPUMIX 
#define IMX8MM_PGC_GPU3D <token> <answer> 25 
#define IMX8MM_PGC_DISPMIX <token> <answer> 26 
#define IMX8MM_PGC_VPUG1 <token> <answer> 27 
<token> IMX8MM_PGC_VPUG2 28 <answer> #define 
#define IMX8MM_PGC_VPUH1 <token> <answer> 29 
#define IMX8MN_PGC_MIPI <token> <answer> 16 
#define <token> 18 <answer> IMX8MN_PGC_OTG1 
<token> IMX8MN_PGC_DDR1 21 <answer> #define 
<token> IMX8MN_PGC_GPUMIX 23 <answer> #define 
#define <token> 26 <answer> IMX8MN_PGC_DISPMIX 
#define IMX8MP_PGC_NOC <token> <answer> 9 
#define IMX8MP_PGC_MIPI1 <token> <answer> 12 
<token> IMX8MP_PGC_PCIE 13 <answer> #define 
#define IMX8MP_PGC_USB1 <token> <answer> 14 
<token> IMX8MP_PGC_USB2 15 <answer> #define 
<token> IMX8MP_PGC_MLMIX 16 <answer> #define 
<token> IMX8MP_PGC_AUDIOMIX 17 <answer> #define 
<token> IMX8MP_PGC_GPU2D 18 <answer> #define 
<token> IMX8MP_PGC_GPUMIX 19 <answer> #define 
#define <token> 20 <answer> IMX8MP_PGC_VPUMIX 
#define <token> 21 <answer> IMX8MP_PGC_GPU3D 
#define IMX8MP_PGC_MEDIAMIX <token> <answer> 22 
<token> IMX8MP_PGC_VPU_G1 23 <answer> #define 
<token> IMX8MP_PGC_VPU_G2 24 <answer> #define 
<token> IMX8MP_PGC_VPU_VC8000E 25 <answer> #define 
#define IMX8MP_PGC_HDMIMIX <token> <answer> 26 
<token> IMX8MP_PGC_HDMI 27 <answer> #define 
#define <token> 28 <answer> IMX8MP_PGC_MIPI2 
<token> IMX8MP_PGC_HSIOMIX 29 <answer> #define 
#define IMX8MP_PGC_MEDIA_ISP_DWP <token> <answer> 30 
<token> IMX8MP_PGC_DDRMIX 31 <answer> #define 
<token> GPC_PGC_CTRL(n) (0x800 + (n) * 0x40) <answer> #define 
<token> GPC_PGC_SR(n) (GPC_PGC_CTRL(n) + 0xc) <answer> #define 
#define <token> BIT(0) <answer> GPC_PGC_CTRL_PCR 
<token> imx_pgc_regs { <answer> struct 
u16 <token> <answer> map; 
<token> pup; <answer> u16 
<token> pdn; <answer> u16 
u16 <token> <answer> hsk; 
struct <token> { <answer> imx_pgc_domain 
<token> generic_pm_domain genpd; <answer> struct 
<token> regmap *regmap; <answer> struct 
<token> struct imx_pgc_regs *regs; <answer> const 
<token> regulator *regulator; <answer> struct 
<token> reset_control *reset; <answer> struct 
<token> clk_bulk_data *clks; <answer> struct 
int <token> <answer> num_clks; 
unsigned long <token> <answer> pgc; 
const <token> { <answer> struct 
u32 <token> <answer> pxx; 
u32 <token> <answer> map; 
<token> hskreq; <answer> u32 
u32 <token> <answer> hskack; 
} <token> <answer> bits; 
<token> int voltage; <answer> const 
<token> bool keep_clocks; <answer> const 
struct device <token> <answer> *dev; 
unsigned <token> pgc_sw_pup_reg; <answer> int 
unsigned <token> pgc_sw_pdn_reg; <answer> int 
struct <token> { <answer> imx_pgc_domain_data 
const struct <token> *domains; <answer> imx_pgc_domain 
<token> domains_num; <answer> size_t 
<token> struct regmap_access_table *reg_access_table; <answer> const 
const <token> imx_pgc_regs *pgc_regs; <answer> struct 
static inline <token> imx_pgc_domain * <answer> struct 
to_imx_pgc_domain(struct <token> *genpd) <answer> generic_pm_domain 
return <token> struct imx_pgc_domain, genpd); <answer> container_of(genpd, 
<token> int imx_pgc_power_up(struct generic_pm_domain *genpd) <answer> static 
struct imx_pgc_domain *domain = <token> <answer> to_imx_pgc_domain(genpd); 
<token> reg_val, pgc; <answer> u32 
int <token> <answer> ret; 
ret <token> pm_runtime_get_sync(domain->dev); <answer> = 
<token> (ret < 0) { <answer> if 
return <token> <answer> ret; 
if (!IS_ERR(domain->regulator)) <token> <answer> { 
<token> = regulator_enable(domain->regulator); <answer> ret 
if <token> { <answer> (ret) 
"failed to enable regulator: <token> <answer> %pe\n", 
goto <token> <answer> out_put_pm; 
<token> = regmap_read_poll_timeout(domain->regmap, <answer> ret 
domain->regs->pup, <token> <answer> reg_val, 
<token> & domain->bits.pxx), <answer> !(reg_val 
0, <token> <answer> USEC_PER_MSEC); 
<token> (ret) { <answer> if 
dev_err(domain->dev, "failed <token> command PGC\n"); <answer> to 
<token> out_clk_disable; <answer> goto 
ret <token> regmap_read_poll_timeout(domain->regmap, <answer> = 
<token> reg_val, <answer> domain->regs->pdn, 
!(reg_val & <token> <answer> domain->bits.pxx), 
0, <token> <answer> USEC_PER_MSEC); 
if <token> { <answer> (ret) 
dev_err(domain->dev, "failed to command <token> <answer> PGC\n"); 
<token> out_clk_disable; <answer> goto 
<token> = pm_runtime_get_sync(dev); <answer> ret 
if (ret <token> 0) { <answer> < 
return <token> <answer> ret; 
return <token> <answer> 0; 
static int imx_pgc_domain_resume(struct <token> *dev) <answer> device 
<token> pm_runtime_put(dev); <answer> return 
static const struct <token> imx_pgc_domain_pm_ops = { <answer> dev_pm_ops 
SET_SYSTEM_SLEEP_PM_OPS(imx_pgc_domain_suspend, <token> <answer> imx_pgc_domain_resume) 
static const struct platform_device_id imx_pgc_domain_id[] = <token> <answer> { 
{ <token> }, <answer> "imx-pgc-domain", 
<token> }, <answer> { 
<token> struct platform_driver imx_pgc_domain_driver = { <answer> static 
.driver = <token> <answer> { 
<token> = "imx-pgc", <answer> .name 
.pm = <token> <answer> &imx_pgc_domain_pm_ops, 
.probe = <token> <answer> imx_pgc_domain_probe, 
.remove_new = <token> <answer> imx_pgc_domain_remove, 
<token> = imx_pgc_domain_id, <answer> .id_table 
static <token> imx_gpcv2_probe(struct platform_device *pdev) <answer> int 
<token> struct imx_pgc_domain_data *domain_data = <answer> const 
struct regmap_config regmap_config <token> { <answer> = 
<token> = 32, <answer> .reg_bits 
<token> = 32, <answer> .val_bits 
.reg_stride <token> 4, <answer> = 
.rd_table = <token> <answer> domain_data->reg_access_table, 
.wr_table <token> domain_data->reg_access_table, <answer> = 
<token> = SZ_4K, <answer> .max_register 
<token> device *dev = &pdev->dev; <answer> struct 
struct device_node <token> *np; <answer> *pgc_np, 
struct regmap <token> <answer> *regmap; 
void __iomem <token> <answer> *base; 
<token> ret; <answer> int 
pgc_np = of_get_child_by_name(dev->of_node, <token> <answer> "pgc"); 
if (!pgc_np) <token> <answer> { 
dev_err(dev, <token> power domains specified in DT\n"); <answer> "No 
<token> -EINVAL; <answer> return 
base <token> devm_platform_ioremap_resource(pdev, 0); <answer> = 
<token> (IS_ERR(base)) <answer> if 
return <token> <answer> PTR_ERR(base); 
<token> = devm_regmap_init_mmio(dev, base, &regmap_config); <answer> regmap 
if <token> { <answer> (IS_ERR(regmap)) 
ret = <token> <answer> PTR_ERR(regmap); 
dev_err(dev, "failed to init regmap <token> ret); <answer> (%d)\n", 
<token> ret; <answer> return 
for_each_child_of_node(pgc_np, <token> { <answer> np) 
struct <token> *pd_pdev; <answer> platform_device 
<token> imx_pgc_domain *domain; <answer> struct 
<token> domain_index; <answer> u32 
if <token> <answer> (!of_device_is_available(np)) 
ret = of_property_read_u32(np, "reg", <token> <answer> &domain_index); 
if <token> { <answer> (ret) 
dev_err(dev, <token> to read 'reg' property\n"); <answer> "Failed 
return <token> <answer> ret; 
if (domain_index >= <token> { <answer> domain_data->domains_num) 
<token> index %d is out of bounds\n", <answer> "Domain 
pd_pdev <token> platform_device_alloc("imx-pgc-domain", <answer> = 
<token> (!pd_pdev) { <answer> if 
dev_err(dev, "Failed to allocate <token> device\n"); <answer> platform 
<token> -ENOMEM; <answer> return 
<token> = platform_device_add_data(pd_pdev, <answer> ret 
if (ret) <token> <answer> { 
return <token> <answer> ret; 
domain = <token> <answer> pd_pdev->dev.platform_data; 
domain->regmap <token> regmap; <answer> = 
<token> = domain_data->pgc_regs; <answer> domain->regs 
domain->genpd.power_on = <token> <answer> imx_pgc_power_up; 
domain->genpd.power_off = <token> <answer> imx_pgc_power_down; 
<token> = dev; <answer> pd_pdev->dev.parent 
device_set_node(&pd_pdev->dev, <token> <answer> of_fwnode_handle(np)); 
ret = <token> <answer> platform_device_add(pd_pdev); 
if <token> { <answer> (ret) 
<token> ret; <answer> return 
return <token> <answer> 0; 
static const <token> of_device_id imx_gpcv2_dt_ids[] = { <answer> struct 
{ .compatible = "fsl,imx7d-gpc", .data <token> &imx7_pgc_domain_data, }, <answer> = 
{ .compatible = "fsl,imx8mm-gpc", .data <token> &imx8mm_pgc_domain_data, }, <answer> = 
{ .compatible = "fsl,imx8mn-gpc", .data = <token> }, <answer> &imx8mn_pgc_domain_data, 
{ .compatible = "fsl,imx8mp-gpc", .data <token> &imx8mp_pgc_domain_data, }, <answer> = 
{ .compatible = "fsl,imx8mq-gpc", .data = &imx8m_pgc_domain_data, <token> <answer> }, 
{ <token> <answer> } 
static struct <token> imx_gpc_driver = { <answer> platform_driver 
.driver <token> { <answer> = 
<token> = "imx-gpcv2", <answer> .name 
.of_match_table = <token> <answer> imx_gpcv2_dt_ids, 
.probe = <token> <answer> imx_gpcv2_probe, 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/mfd/syscon.h> 
#include <token> <answer> <linux/of.h> 
<token> <linux/phy/phy.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
<token> PHY_OFFSET 0x1000 <answer> #define 
#define MTK_DP_PHY_DIG_PLL_CTL_1 <token> + 0x14) <answer> (PHY_OFFSET 
#define <token> BIT(3) <answer> TPLL_SSC_EN 
#define MTK_DP_PHY_DIG_BIT_RATE (PHY_OFFSET <token> 0x3C) <answer> + 
#define <token> 0 <answer> BIT_RATE_RBR 
<token> BIT_RATE_HBR 1 <answer> #define 
#define BIT_RATE_HBR2 <token> <answer> 2 
#define <token> 3 <answer> BIT_RATE_HBR3 
#define MTK_DP_PHY_DIG_SW_RST <token> + 0x38) <answer> (PHY_OFFSET 
#define DP_GLB_SW_RST_PHYD <token> <answer> BIT(0) 
#define MTK_DP_LANE0_DRIVING_PARAM_3 <token> + 0x138) <answer> (PHY_OFFSET 
#define MTK_DP_LANE1_DRIVING_PARAM_3 (PHY_OFFSET + <token> <answer> 0x238) 
#define MTK_DP_LANE2_DRIVING_PARAM_3 (PHY_OFFSET + <token> <answer> 0x338) 
#define MTK_DP_LANE3_DRIVING_PARAM_3 (PHY_OFFSET + <token> <answer> 0x438) 
#define XTP_LN_TX_LCTXC0_SW0_PRE0_DEFAULT <token> <answer> BIT(4) 
#define XTP_LN_TX_LCTXC0_SW0_PRE1_DEFAULT (BIT(10) <token> BIT(12)) <answer> | 
#define XTP_LN_TX_LCTXC0_SW0_PRE2_DEFAULT GENMASK(20, <token> <answer> 19) 
#define XTP_LN_TX_LCTXC0_SW0_PRE3_DEFAULT <token> 29) <answer> GENMASK(29, 
#define DRIVING_PARAM_3_DEFAULT (XTP_LN_TX_LCTXC0_SW0_PRE0_DEFAULT | <token> <answer> \ 
XTP_LN_TX_LCTXC0_SW0_PRE1_DEFAULT <token> \ <answer> | 
XTP_LN_TX_LCTXC0_SW0_PRE2_DEFAULT | <token> <answer> \ 
#define XTP_LN_TX_LCTXC0_SW1_PRE0_DEFAULT <token> 3) <answer> GENMASK(4, 
#define XTP_LN_TX_LCTXC0_SW1_PRE1_DEFAULT GENMASK(12, <token> <answer> 9) 
#define XTP_LN_TX_LCTXC0_SW1_PRE2_DEFAULT (BIT(18) | <token> <answer> BIT(21)) 
<token> XTP_LN_TX_LCTXC0_SW2_PRE0_DEFAULT GENMASK(29, 29) <answer> #define 
#define DRIVING_PARAM_4_DEFAULT (XTP_LN_TX_LCTXC0_SW1_PRE0_DEFAULT <token> \ <answer> | 
XTP_LN_TX_LCTXC0_SW1_PRE1_DEFAULT <token> \ <answer> | 
<token> | \ <answer> XTP_LN_TX_LCTXC0_SW1_PRE2_DEFAULT 
#define <token> (BIT(3) | BIT(5)) <answer> XTP_LN_TX_LCTXC0_SW2_PRE1_DEFAULT 
<token> XTP_LN_TX_LCTXC0_SW3_PRE0_DEFAULT GENMASK(13, 12) <answer> #define 
#define <token> (XTP_LN_TX_LCTXC0_SW2_PRE1_DEFAULT | \ <answer> DRIVING_PARAM_5_DEFAULT 
<token> XTP_LN_TX_LCTXCP1_SW0_PRE0_DEFAULT 0 <answer> #define 
#define XTP_LN_TX_LCTXCP1_SW0_PRE1_DEFAULT GENMASK(10, <token> <answer> 10) 
#define <token> GENMASK(19, 19) <answer> XTP_LN_TX_LCTXCP1_SW0_PRE2_DEFAULT 
#define XTP_LN_TX_LCTXCP1_SW0_PRE3_DEFAULT <token> 28) <answer> GENMASK(28, 
#define DRIVING_PARAM_6_DEFAULT (XTP_LN_TX_LCTXCP1_SW0_PRE0_DEFAULT | <token> <answer> \ 
XTP_LN_TX_LCTXCP1_SW0_PRE1_DEFAULT <token> \ <answer> | 
XTP_LN_TX_LCTXCP1_SW0_PRE2_DEFAULT <token> \ <answer> | 
#define XTP_LN_TX_LCTXCP1_SW1_PRE0_DEFAULT <token> <answer> 0 
#define XTP_LN_TX_LCTXCP1_SW1_PRE1_DEFAULT GENMASK(10, <token> <answer> 9) 
#define XTP_LN_TX_LCTXCP1_SW1_PRE2_DEFAULT <token> 18) <answer> GENMASK(19, 
<token> XTP_LN_TX_LCTXCP1_SW2_PRE0_DEFAULT 0 <answer> #define 
#define <token> (XTP_LN_TX_LCTXCP1_SW1_PRE0_DEFAULT | \ <answer> DRIVING_PARAM_7_DEFAULT 
XTP_LN_TX_LCTXCP1_SW1_PRE1_DEFAULT | <token> <answer> \ 
<token> | \ <answer> XTP_LN_TX_LCTXCP1_SW1_PRE2_DEFAULT 
#define XTP_LN_TX_LCTXCP1_SW2_PRE1_DEFAULT <token> 3) <answer> GENMASK(3, 
<token> XTP_LN_TX_LCTXCP1_SW3_PRE0_DEFAULT 0 <answer> #define 
<token> DRIVING_PARAM_8_DEFAULT (XTP_LN_TX_LCTXCP1_SW2_PRE1_DEFAULT | \ <answer> #define 
<token> mtk_dp_phy { <answer> struct 
<token> regmap *regs; <answer> struct 
static int mtk_dp_phy_init(struct <token> *phy) <answer> phy 
struct mtk_dp_phy *dp_phy <token> phy_get_drvdata(phy); <answer> = 
static <token> u32 driving_params[] = { <answer> const 
regmap_bulk_write(dp_phy->regs, <token> <answer> MTK_DP_LANE0_DRIVING_PARAM_3, 
<token> ARRAY_SIZE(driving_params)); <answer> driving_params, 
<token> MTK_DP_LANE1_DRIVING_PARAM_3, <answer> regmap_bulk_write(dp_phy->regs, 
<token> ARRAY_SIZE(driving_params)); <answer> driving_params, 
regmap_bulk_write(dp_phy->regs, <token> <answer> MTK_DP_LANE2_DRIVING_PARAM_3, 
driving_params, <token> <answer> ARRAY_SIZE(driving_params)); 
regmap_bulk_write(dp_phy->regs, <token> <answer> MTK_DP_LANE3_DRIVING_PARAM_3, 
driving_params, <token> <answer> ARRAY_SIZE(driving_params)); 
<token> 0; <answer> return 
static int <token> phy *phy, union phy_configure_opts *opts) <answer> mtk_dp_phy_configure(struct 
struct mtk_dp_phy *dp_phy = <token> <answer> phy_get_drvdata(phy); 
<token> val; <answer> u32 
<token> (opts->dp.set_rate) { <answer> if 
<token> (opts->dp.link_rate) { <answer> switch 
"Implementation error, <token> linkrate %x\n", <answer> unknown 
return <token> <answer> -EINVAL; 
<token> 1620: <answer> case 
<token> = BIT_RATE_RBR; <answer> val 
case <token> <answer> 2700: 
val = <token> <answer> BIT_RATE_HBR; 
case <token> <answer> 5400: 
val <token> BIT_RATE_HBR2; <answer> = 
case <token> <answer> 8100: 
val <token> BIT_RATE_HBR3; <answer> = 
regmap_write(dp_phy->regs, <token> val); <answer> MTK_DP_PHY_DIG_BIT_RATE, 
<token> MTK_DP_PHY_DIG_PLL_CTL_1, <answer> regmap_update_bits(dp_phy->regs, 
TPLL_SSC_EN, opts->dp.ssc <token> TPLL_SSC_EN : 0); <answer> ? 
<token> 0; <answer> return 
static int <token> phy *phy) <answer> mtk_dp_phy_reset(struct 
struct <token> *dp_phy = phy_get_drvdata(phy); <answer> mtk_dp_phy 
<token> MTK_DP_PHY_DIG_SW_RST, <answer> regmap_update_bits(dp_phy->regs, 
DP_GLB_SW_RST_PHYD, <token> <answer> 0); 
<token> 200); <answer> usleep_range(50, 
<token> MTK_DP_PHY_DIG_SW_RST, <answer> regmap_update_bits(dp_phy->regs, 
DP_GLB_SW_RST_PHYD, <token> <answer> 1); 
<token> 0; <answer> return 
static const struct phy_ops mtk_dp_phy_dev_ops = <token> <answer> { 
.init = <token> <answer> mtk_dp_phy_init, 
<token> = mtk_dp_phy_configure, <answer> .configure 
.reset = <token> <answer> mtk_dp_phy_reset, 
.owner = <token> <answer> THIS_MODULE, 
static int <token> platform_device *pdev) <answer> mtk_dp_phy_probe(struct 
struct device *dev <token> &pdev->dev; <answer> = 
struct <token> *dp_phy; <answer> mtk_dp_phy 
struct <token> *phy; <answer> phy 
struct <token> *regs; <answer> regmap 
<token> = *(struct regmap **)dev->platform_data; <answer> regs 
<token> (!regs) <answer> if 
<token> dev_err_probe(dev, -EINVAL, <answer> return 
"No data passed, requires struct <token> <answer> regmap**\n"); 
<token> = devm_kzalloc(dev, sizeof(*dp_phy), GFP_KERNEL); <answer> dp_phy 
<token> (!dp_phy) <answer> if 
<token> -ENOMEM; <answer> return 
<token> = regs; <answer> dp_phy->regs 
phy = devm_phy_create(dev, NULL, <token> <answer> &mtk_dp_phy_dev_ops); 
<token> (IS_ERR(phy)) <answer> if 
return dev_err_probe(dev, <token> <answer> PTR_ERR(phy), 
"Failed to create <token> PHY\n"); <answer> DP 
<token> dp_phy); <answer> phy_set_drvdata(phy, 
<token> (!dev->of_node) <answer> if 
<token> "dp", dev_name(dev)); <answer> phy_create_lookup(phy, 
<token> 0; <answer> return 
static struct <token> mtk_dp_phy_driver = { <answer> platform_driver 
.probe <token> mtk_dp_phy_probe, <answer> = 
<token> = { <answer> .driver 
.name <token> "mediatek-dp-phy", <answer> = 
<token> Schneider-Pargmann <msp@baylibre.com>"); <answer> MODULE_AUTHOR("Markus 
<token> DP PHY Driver"); <answer> MODULE_DESCRIPTION("MediaTek 
<token> <linux/delay.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/serial_8250.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
<token> <asm/sni.h> <answer> #include 
<token> <asm/time.h> <answer> #include 
<token> <asm/irq_cpu.h> <answer> #include 
<token> RM200_I8259A_IRQ_BASE 32 <answer> #define 
#define <token> \ <answer> MEMPORT(_base,_irq) 
<token> \ <answer> { 
<token> = _base, \ <answer> .mapbase 
.irq = _irq, <token> <answer> \ 
<token> = 1843200, \ <answer> .uartclk 
.iotype = <token> \ <answer> UPIO_MEM, 
<token> = UPF_BOOT_AUTOCONF|UPF_IOREMAP, \ <answer> .flags 
static struct plat_serial8250_port rm200_data[] = <token> <answer> { 
MEMPORT(0x160003f8, <token> + 4), <answer> RM200_I8259A_IRQ_BASE 
MEMPORT(0x160002f8, RM200_I8259A_IRQ_BASE + <token> <answer> 3), 
<token> }, <answer> { 
static struct platform_device <token> = { <answer> rm200_serial8250_device 
.name <token> "serial8250", <answer> = 
.id = <token> <answer> PLAT8250_DEV_PLATFORM, 
.dev = <token> <answer> { 
.platform_data <token> rm200_data, <answer> = 
static struct resource rm200_ds1216_rsrc[] = <token> <answer> { 
.start <token> 0x1cd41ffc, <answer> = 
<token> = 0x1cd41fff, <answer> .end 
.flags <token> IORESOURCE_MEM <answer> = 
static struct platform_device <token> = { <answer> rm200_ds1216_device 
.name = <token> <answer> "rtc-ds1216", 
.num_resources = <token> <answer> ARRAY_SIZE(rm200_ds1216_rsrc), 
.resource = <token> <answer> rm200_ds1216_rsrc 
<token> struct resource snirm_82596_rm200_rsrc[] = { <answer> static 
<token> = 0x18000000, <answer> .start 
<token> = 0x180fffff, <answer> .end 
<token> = IORESOURCE_MEM <answer> .flags 
.start = <token> <answer> 0x1b000000, 
<token> = 0x1b000004, <answer> .end 
.flags <token> IORESOURCE_MEM <answer> = 
.start = <token> <answer> 0x1ff00000, 
.end = <token> <answer> 0x1ff00020, 
.flags = <token> <answer> IORESOURCE_MEM 
<token> = 27, <answer> .start 
.end = <token> <answer> 27, 
<token> = IORESOURCE_IRQ <answer> .flags 
.flags = <token> <answer> 0x00 
<token> struct platform_device snirm_82596_rm200_pdev = { <answer> static 
<token> = "snirm_82596", <answer> .name 
.num_resources = <token> <answer> ARRAY_SIZE(snirm_82596_rm200_rsrc), 
.resource = <token> <answer> snirm_82596_rm200_rsrc 
<token> struct resource snirm_53c710_rm200_rsrc[] = { <answer> static 
.start = <token> <answer> 0x19000000, 
.end <token> 0x190fffff, <answer> = 
.flags = <token> <answer> IORESOURCE_MEM 
<token> = 26, <answer> .start 
.end <token> 26, <answer> = 
<token> = IORESOURCE_IRQ <answer> .flags 
static <token> platform_device snirm_53c710_rm200_pdev = { <answer> struct 
<token> = "snirm_53c710", <answer> .name 
.num_resources = <token> <answer> ARRAY_SIZE(snirm_53c710_rm200_rsrc), 
<token> = snirm_53c710_rm200_rsrc <answer> .resource 
static int <token> snirm_setup_devinit(void) <answer> __init 
if (sni_brd_type == SNI_BRD_RM200) <token> <answer> { 
<token> 0; <answer> return 
static <token> <answer> DEFINE_RAW_SPINLOCK(sni_rm200_i8259A_lock); 
#define PIC_CMD <token> <answer> 0x00 
#define PIC_IMR <token> <answer> 0x01 
#define PIC_ISR <token> <answer> PIC_CMD 
#define <token> PIC_ISR <answer> PIC_POLL 
#define PIC_OCW3 <token> <answer> PIC_ISR 
<token> unsigned int rm200_cached_irq_mask = 0xffff; <answer> static 
static __iomem <token> *rm200_pic_master; <answer> u8 
static <token> u8 *rm200_pic_slave; <answer> __iomem 
<token> cached_master_mask (rm200_cached_irq_mask) <answer> #define 
#define cached_slave_mask (rm200_cached_irq_mask <token> 8) <answer> >> 
static void sni_rm200_disable_8259A_irq(struct <token> *d) <answer> irq_data 
unsigned int mask, irq = <token> - RM200_I8259A_IRQ_BASE; <answer> d->irq 
<token> long flags; <answer> unsigned 
mask <token> 1 << irq; <answer> = 
<token> flags); <answer> raw_spin_lock_irqsave(&sni_rm200_i8259A_lock, 
rm200_cached_irq_mask |= <token> <answer> mask; 
if (irq & <token> <answer> 8) 
<token> rm200_pic_slave + PIC_IMR); <answer> writeb(cached_slave_mask, 
writeb(cached_master_mask, <token> + PIC_IMR); <answer> rm200_pic_master 
<token> flags); <answer> raw_spin_unlock_irqrestore(&sni_rm200_i8259A_lock, 
static void <token> irq_data *d) <answer> sni_rm200_enable_8259A_irq(struct 
<token> int mask, irq = d->irq - RM200_I8259A_IRQ_BASE; <answer> unsigned 
unsigned <token> flags; <answer> long 
<token> = ~(1 << irq); <answer> mask 
raw_spin_lock_irqsave(&sni_rm200_i8259A_lock, <token> <answer> flags); 
rm200_cached_irq_mask &= <token> <answer> mask; 
<token> (irq & 8) <answer> if 
<token> rm200_pic_slave + PIC_IMR); <answer> writeb(cached_slave_mask, 
writeb(cached_master_mask, <token> + PIC_IMR); <answer> rm200_pic_master 
<token> flags); <answer> raw_spin_unlock_irqrestore(&sni_rm200_i8259A_lock, 
<token> inline int sni_rm200_i8259A_irq_real(unsigned int irq) <answer> static 
<token> value; <answer> int 
<token> irqmask = 1 << irq; <answer> int 
if (irq < 8) <token> <answer> { 
writeb(0x0B, rm200_pic_master + <token> <answer> PIC_CMD); 
<token> = readb(rm200_pic_master + PIC_CMD) & irqmask; <answer> value 
<token> rm200_pic_master + PIC_CMD); <answer> writeb(0x0A, 
<token> value; <answer> return 
<token> sni_rm200_mask_and_ack_8259A(struct irq_data *d) <answer> void 
unsigned int irqmask, irq <token> d->irq - RM200_I8259A_IRQ_BASE; <answer> = 
unsigned long <token> <answer> flags; 
irqmask = 1 <token> irq; <answer> << 
<token> flags); <answer> raw_spin_lock_irqsave(&sni_rm200_i8259A_lock, 
if <token> & irqmask) <answer> (rm200_cached_irq_mask 
<token> spurious_8259A_irq; <answer> goto 
<token> |= irqmask; <answer> rm200_cached_irq_mask 
if (irq <token> 8) { <answer> & 
readb(rm200_pic_slave + <token> <answer> PIC_IMR); 
writeb(cached_slave_mask, rm200_pic_slave <token> PIC_IMR); <answer> + 
writeb(0x60+(irq <token> 7), rm200_pic_slave + PIC_CMD); <answer> & 
writeb(0x60+PIC_CASCADE_IR, <token> + PIC_CMD); <answer> rm200_pic_master 
} <token> { <answer> else 
<token> + PIC_IMR); <answer> readb(rm200_pic_master 
writeb(cached_master_mask, <token> + PIC_IMR); <answer> rm200_pic_master 
writeb(0x60+irq, <token> + PIC_CMD); <answer> rm200_pic_master 
<token> flags); <answer> raw_spin_unlock_irqrestore(&sni_rm200_i8259A_lock, 
if <token> <answer> (sni_rm200_i8259A_irq_real(irq)) 
<token> handle_real_irq; <answer> goto 
static int <token> <answer> spurious_irq_mask; 
if (!(spurious_irq_mask <token> irqmask)) { <answer> & 
"spurious RM200 <token> interrupt: IRQ%d.\n", irq); <answer> 8259A 
spurious_irq_mask <token> irqmask; <answer> |= 
goto <token> <answer> handle_real_irq; 
static struct irq_chip sni_rm200_i8259A_chip = <token> <answer> { 
<token> = "RM200-XT-PIC", <answer> .name 
.irq_mask = <token> <answer> sni_rm200_disable_8259A_irq, 
.irq_unmask <token> sni_rm200_enable_8259A_irq, <answer> = 
.irq_mask_ack <token> sni_rm200_mask_and_ack_8259A, <answer> = 
static inline int <token> <answer> sni_rm200_i8259_irq(void) 
<token> irq; <answer> int 
static struct <token> sni_rm200_pic1_resource = { <answer> resource 
<token> = "onboard ISA pic1", <answer> .name 
<token> = 0x16000020, <answer> .start 
.end <token> 0x16000023, <answer> = 
.flags <token> IORESOURCE_BUSY <answer> = 
static struct resource sni_rm200_pic2_resource <token> { <answer> = 
<token> = "onboard ISA pic2", <answer> .name 
.start = <token> <answer> 0x160000a0, 
.end <token> 0x160000a3, <answer> = 
.flags <token> IORESOURCE_BUSY <answer> = 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/soc/brcmstb/brcmstb.h> 
<token> "phy-brcm-usb-init.h" <answer> #include 
<token> PHY_PORTS 2 <answer> #define 
#define <token> 0 <answer> PHY_PORT_SELECT_0 
<token> PHY_PORT_SELECT_1 0x1000 <answer> #define 
switch (params->selected_family) <token> <answer> { 
case <token> <answer> BRCM_FAMILY_3390A0: 
case <token> <answer> BRCM_FAMILY_4908: 
<token> BRCM_FAMILY_7250B0: <answer> case 
case <token> <answer> BRCM_FAMILY_7366C0: 
case <token> <answer> BRCM_FAMILY_74371A0: 
<token> BRCM_FAMILY_7439B0: <answer> case 
case <token> <answer> BRCM_FAMILY_7445D0: 
case <token> <answer> BRCM_FAMILY_7260A0: 
case <token> <answer> BRCM_FAMILY_7364A0: 
if <token> < 0x20) <answer> (BRCM_REV(params->family_id) 
brcmusb_usb_mdio_write(ctrl_base, 0x1f, 0x9040, <token> <answer> MDIO_USB3); 
<token> = brcmusb_usb_mdio_read(ctrl_base, 0x01, MDIO_USB3) | 0xf; <answer> val 
brcmusb_usb_mdio_write(ctrl_base, <token> val, MDIO_USB3); <answer> 0x01, 
static void brcmusb_usb3_phy_workarounds(struct <token> *params) <answer> brcm_usb_init_params 
void __iomem *ctrl_base = <token> <answer> params->regs[BRCM_REGS_CTRL]; 
<token> void brcmusb_memc_fix(struct brcm_usb_init_params *params) <answer> static 
<token> prid; <answer> u32 
if <token> != BRCM_FAMILY_7445D0) <answer> (params->selected_family 
prid = <token> & 0xfffff000; <answer> params->product_id 
<token> (prid) { <answer> switch 
case <token> <answer> 0x72520000: 
case <token> <answer> 0x74480000: 
case <token> <answer> 0x74490000: 
<token> 0x07252000: <answer> case 
<token> 0x07448000: <answer> case 
<token> 0x07449000: <answer> case 
USB_CTRL_UNSET_FAMILY(params, <token> SCB2_EN); <answer> SETUP, 
<token> void brcmusb_usb3_otp_fix(struct brcm_usb_init_params *params) <answer> static 
void __iomem *xhci_ec_base <token> params->regs[BRCM_REGS_XHCI_EC]; <answer> = 
<token> val; <answer> u32 
if (params->family_id <token> 0x74371000 || !xhci_ec_base) <answer> != 
brcm_usb_writel(0xa20c, USB_XHCI_EC_REG(xhci_ec_base, <token> <answer> IRAADR)); 
val = <token> IRADAT)); <answer> brcm_usb_readl(USB_XHCI_EC_REG(xhci_ec_base, 
<token> enum brcm_family_type get_family_type( <answer> static 
<token> brcm_usb_init_params *params) <answer> struct 
int <token> = -1; <answer> last_type 
u32 last_family <token> 0; <answer> = 
<token> family_no_major; <answer> u32 
<token> int x; <answer> unsigned 
u32 <token> <answer> family; 
family <token> params->family_id & 0xfffffff0; <answer> = 
family_no_major = params->family_id <token> 0xffffff00; <answer> & 
for (x = 0; <token> x++) { <answer> id_to_type_table[x].id; 
<token> (family == id_to_type_table[x].id) <answer> if 
<token> id_to_type_table[x].type; <answer> return 
if (family_no_major <token> (id_to_type_table[x].id & 0xffffff00)) <answer> == 
if (family > id_to_type_table[x].id <token> <answer> && 
last_family <token> id_to_type_table[x].id) { <answer> < 
<token> = id_to_type_table[x].id; <answer> last_family 
last_type <token> id_to_type_table[x].type; <answer> = 
if (USB_CTRL_MASK_FAMILY(params, USB30_CTL1, <token> { <answer> USB3_IOC)) 
<token> (params->ioc) <answer> if 
<token> USB30_CTL1, USB3_IOC); <answer> USB_CTRL_SET_FAMILY(params, 
if <token> == 1) <answer> (params->ipp 
<token> USB30_CTL1, USB3_IPP); <answer> USB_CTRL_SET_FAMILY(params, 
reg <token> brcm_usb_readl(USB_CTRL_REG(ctrl, SETUP)); <answer> = 
orig_reg <token> reg; <answer> = 
if (USB_CTRL_MASK_FAMILY(params, <token> STRAP_CC_DRD_MODE_ENABLE_SEL)) <answer> SETUP, 
if <token> ^ orig_reg) & USB_CTRL_MASK(SETUP, IPP)) <answer> ((reg 
static void usb_wake_enable(struct brcm_usb_init_params <token> <answer> *params, 
bool <token> <answer> enable) 
void __iomem <token> = params->regs[BRCM_REGS_CTRL]; <answer> *ctrl 
<token> (enable) <answer> if 
USB_CTRL_SET(ctrl, <token> RMTWKUP_EN); <answer> USB_PM, 
USB_CTRL_UNSET(ctrl, <token> RMTWKUP_EN); <answer> USB_PM, 
static <token> usb_init_common(struct brcm_usb_init_params *params) <answer> void 
u32 <token> <answer> reg; 
void __iomem <token> = params->regs[BRCM_REGS_CTRL]; <answer> *ctrl 
USB_CTRL_SET_FAMILY(params, SETUP, <token> <answer> SS_EHCI64BIT_EN); 
if <token> SETUP, SCB1_EN)) <answer> (USB_CTRL_MASK_FAMILY(params, 
reg <token> USB_CTRL_MASK_FAMILY(params, SETUP, SCB1_EN); <answer> |= 
if <token> SETUP, SCB2_EN)) <answer> (USB_CTRL_MASK_FAMILY(params, 
reg |= USB_CTRL_MASK_FAMILY(params, SETUP, <token> <answer> SCB2_EN); 
brcm_usb_writel(reg, USB_CTRL_REG(ctrl, <token> <answer> SETUP)); 
USB_CTRL_SET(ctrl, EBRIDGE, <token> <answer> ESTOP_SCB_REQ); 
<token> = brcm_usb_readl(USB_CTRL_REG(ctrl, EBRIDGE)); <answer> reg 
<token> &= ~USB_CTRL_MASK(EBRIDGE, EBR_SCB_SIZE); <answer> reg 
reg |= <token> <answer> 0x800; 
<token> USB_CTRL_REG(ctrl, EBRIDGE)); <answer> brcm_usb_writel(reg, 
static void usb_init_xhci(struct brcm_usb_init_params <token> <answer> *params) 
void __iomem *ctrl = <token> <answer> params->regs[BRCM_REGS_CTRL]; 
USB_CTRL_UNSET(ctrl, <token> PHY3_IDDQ_OVERRIDE); <answer> USB30_PCTL, 
USB_CTRL_SET(ctrl, USB30_PCTL, <token> <answer> PHY3_SOFT_RESETB); 
USB_CTRL_SET(ctrl, USB30_PCTL, <token> <answer> PHY3_SOFT_RESETB_P1); 
USB_CTRL_UNSET(ctrl, <token> PHY3_PLL_SEQ_START); <answer> USB30_CTL1, 
USB_CTRL_SET(ctrl, USB30_CTL1, <token> <answer> PHY3_PLL_SEQ_START); 
<token> 0); <answer> brcmusb_xhci_soft_reset(params, 
static void usb_uninit_common(struct <token> *params) <answer> brcm_usb_init_params 
if (USB_CTRL_MASK_FAMILY(params, USB_PM, <token> <answer> USB_PWRDN)) 
USB_CTRL_SET_FAMILY(params, <token> USB_PWRDN); <answer> USB_PM, 
if (USB_CTRL_MASK_FAMILY(params, <token> PLL_IDDQ_PWRDN)) <answer> PLL_CTL, 
USB_CTRL_SET_FAMILY(params, <token> PLL_IDDQ_PWRDN); <answer> PLL_CTL, 
<token> (params->wake_enabled) <answer> if 
usb_wake_enable(params, <token> <answer> true); 
static void <token> brcm_usb_init_params *params) <answer> usb_uninit_eohci(struct 
static void usb_uninit_xhci(struct <token> *params) <answer> brcm_usb_init_params 
brcmusb_xhci_soft_reset(params, <token> <answer> 1); 
<token> USB30_PCTL, <answer> USB_CTRL_SET(params->regs[BRCM_REGS_CTRL], 
static int <token> brcm_usb_init_params *params) <answer> usb_get_dual_select(struct 
void __iomem *ctrl = <token> <answer> params->regs[BRCM_REGS_CTRL]; 
<token> reg = 0; <answer> u32 
<token> __func__); <answer> pr_debug("%s\n", 
if (USB_CTRL_MASK_FAMILY(params, <token> PORT_MODE)) { <answer> USB_DEVICE_CTL1, 
reg = brcm_usb_readl(USB_CTRL_REG(ctrl, <token> <answer> USB_DEVICE_CTL1)); 
<token> &= USB_CTRL_MASK_FAMILY(params, USB_DEVICE_CTL1, <answer> reg 
return <token> <answer> reg; 
static void usb_set_dual_select(struct brcm_usb_init_params <token> <answer> *params) 
<token> __iomem *ctrl = params->regs[BRCM_REGS_CTRL]; <answer> void 
u32 <token> <answer> reg; 
<token> __func__); <answer> pr_debug("%s\n", 
if <token> USB_DEVICE_CTL1, PORT_MODE)) { <answer> (USB_CTRL_MASK_FAMILY(params, 
<token> = brcm_usb_readl(USB_CTRL_REG(ctrl, USB_DEVICE_CTL1)); <answer> reg 
reg <token> ~USB_CTRL_MASK_FAMILY(params, USB_DEVICE_CTL1, <answer> &= 
reg |= <token> <answer> params->port_mode; 
<token> USB_CTRL_REG(ctrl, USB_DEVICE_CTL1)); <answer> brcm_usb_writel(reg, 
static const <token> brcm_usb_init_ops bcm7445_ops = { <answer> struct 
.init_ipp = <token> <answer> usb_init_ipp, 
.init_common = <token> <answer> usb_init_common, 
<token> = usb_init_eohci, <answer> .init_eohci 
.init_xhci = <token> <answer> usb_init_xhci, 
<token> = usb_uninit_common, <answer> .uninit_common 
.uninit_eohci = <token> <answer> usb_uninit_eohci, 
.uninit_xhci <token> usb_uninit_xhci, <answer> = 
.get_dual_select <token> usb_get_dual_select, <answer> = 
.set_dual_select <token> usb_set_dual_select, <answer> = 
void brcm_usb_dvr_init_4908(struct <token> *params) <answer> brcm_usb_init_params 
<token> fam; <answer> int 
fam <token> BRCM_FAMILY_4908; <answer> = 
params->selected_family <token> fam; <answer> = 
<token> = <answer> params->usb_reg_bits_map 
params->family_name <token> family_names[fam]; <answer> = 
params->ops <token> &bcm7445_ops; <answer> = 
void <token> brcm_usb_init_params *params) <answer> brcm_usb_dvr_init_7445(struct 
<token> fam; <answer> int 
<token> __func__); <answer> pr_debug("%s\n", 
fam = <token> <answer> get_family_type(params); 
<token> = fam; <answer> params->selected_family 
params->usb_reg_bits_map <token> <answer> = 
<token> = family_names[fam]; <answer> params->family_name 
params->ops <token> &bcm7445_ops; <answer> = 
static int write_control_reg(struct echoaudio *chip, <token> value, char force); <answer> u32 
static <token> set_input_clock(struct echoaudio *chip, u16 clock); <answer> int 
static int set_professional_spdif(struct echoaudio *chip, <token> prof); <answer> char 
static int set_digital_mode(struct echoaudio *chip, <token> mode); <answer> u8 
static int load_asic_generic(struct echoaudio *chip, u32 cmd, <token> asic); <answer> short 
static int check_asic_status(struct <token> *chip); <answer> echoaudio 
static int init_hw(struct <token> *chip, u16 device_id, u16 subdevice_id) <answer> echoaudio 
<token> err; <answer> int 
if (snd_BUG_ON((subdevice_id & <token> != GINA24)) <answer> 0xfff0) 
<token> -ENODEV; <answer> return 
err = <token> <answer> init_dsp_comm_page(chip); 
if <token> { <answer> (err) 
"init_hw - <token> not initialize DSP comm page\n"); <answer> could 
<token> err; <answer> return 
chip->device_id = <token> <answer> device_id; 
<token> = subdevice_id; <answer> chip->subdevice_id 
chip->bad_board <token> true; <answer> = 
<token> = <answer> chip->input_clock_types 
<token> | ECHO_CLOCK_BIT_SPDIF | <answer> ECHO_CLOCK_BIT_INTERNAL 
ECHO_CLOCK_BIT_ESYNC | ECHO_CLOCK_BIT_ESYNC96 <token> <answer> | 
clocks_from_dsp = <token> <answer> le32_to_cpu(chip->comm_page->status_clocks); 
clock_bits <token> ECHO_CLOCK_BIT_INTERNAL; <answer> = 
<token> (clocks_from_dsp & GML_CLOCK_DETECT_BIT_SPDIF) <answer> if 
clock_bits |= <token> <answer> ECHO_CLOCK_BIT_SPDIF; 
if (clocks_from_dsp <token> GML_CLOCK_DETECT_BIT_ADAT) <answer> & 
<token> |= ECHO_CLOCK_BIT_ADAT; <answer> clock_bits 
if (clocks_from_dsp & <token> <answer> GML_CLOCK_DETECT_BIT_ESYNC) 
clock_bits |= ECHO_CLOCK_BIT_ESYNC | <token> <answer> ECHO_CLOCK_BIT_ESYNC96; 
return <token> <answer> clock_bits; 
static <token> load_asic(struct echoaudio *chip) <answer> int 
<token> control_reg; <answer> u32 
<token> err; <answer> int 
<token> asic; <answer> short 
<token> (chip->asic_loaded) <answer> if 
<token> 1; <answer> return 
if (!err) <token> <answer> { 
control_reg = GML_CONVERTER_ENABLE <token> GML_48KHZ; <answer> | 
err = write_control_reg(chip, control_reg, <token> <answer> true); 
<token> err; <answer> return 
static int <token> echoaudio *chip, u32 rate) <answer> set_sample_rate(struct 
<token> control_reg, clock; <answer> u32 
if <token> >= 50000 && <answer> (snd_BUG_ON(rate 
<token> == DIGITAL_MODE_ADAT)) <answer> chip->digital_mode 
return <token> <answer> -EINVAL; 
#define pr_fmt(fmt) "[drm-dp] %s: " <token> __func__ <answer> fmt, 
<token> <drm/drm_print.h> <answer> #include 
#include <token> <answer> "dp_reg.h" 
<token> "dp_link.h" <answer> #include 
#include <token> <answer> "dp_panel.h" 
#define <token> 0x7F <answer> DP_TEST_REQUEST_MASK 
<token> audio_sample_rate { <answer> enum 
AUDIO_SAMPLE_RATE_32_KHZ <token> 0x00, <answer> = 
AUDIO_SAMPLE_RATE_44_1_KHZ = <token> <answer> 0x01, 
<token> = 0x02, <answer> AUDIO_SAMPLE_RATE_48_KHZ 
AUDIO_SAMPLE_RATE_88_2_KHZ <token> 0x03, <answer> = 
<token> = 0x04, <answer> AUDIO_SAMPLE_RATE_96_KHZ 
AUDIO_SAMPLE_RATE_176_4_KHZ = <token> <answer> 0x05, 
AUDIO_SAMPLE_RATE_192_KHZ <token> 0x06, <answer> = 
enum audio_pattern_type <token> <answer> { 
AUDIO_TEST_PATTERN_OPERATOR_DEFINED = <token> <answer> 0x00, 
<token> = 0x01, <answer> AUDIO_TEST_PATTERN_SAWTOOTH 
<token> dp_link_request { <answer> struct 
u32 <token> <answer> test_requested; 
u32 <token> <answer> test_link_rate; 
<token> test_lane_count; <answer> u32 
struct <token> { <answer> dp_link_private 
<token> prev_sink_count; <answer> u32 
<token> device *dev; <answer> struct 
struct <token> *drm_dev; <answer> drm_device 
struct drm_dp_aux <token> <answer> *aux; 
<token> dp_link dp_link; <answer> struct 
<token> dp_link_request request; <answer> struct 
struct mutex <token> <answer> psm_mutex; 
u8 <token> <answer> link_status[DP_LINK_STATUS_SIZE]; 
static int dp_aux_link_power_up(struct <token> *aux, <answer> drm_dp_aux 
struct dp_link_info <token> <answer> *link) 
u8 <token> <answer> value; 
<token> len; <answer> ssize_t 
<token> i; <answer> int 
if (link->revision <token> 0x11) <answer> < 
return <token> <answer> 0; 
len = drm_dp_dpcd_readb(aux, DP_SET_POWER, <token> <answer> &value); 
if (len < <token> <answer> 0) 
return <token> <answer> len; 
<token> &= ~DP_SET_POWER_MASK; <answer> value 
value |= <token> <answer> DP_SET_POWER_D0; 
static bool dp_link_is_bit_depth_valid(u32 <token> <answer> tbd) 
static <token> dp_link_parse_video_pattern_params(struct dp_link_private *link) <answer> int 
int <token> = 0; <answer> ret 
<token> rlen; <answer> ssize_t 
u8 <token> <answer> bp; 
<token> = drm_dp_dpcd_readb(link->aux, DP_TEST_PATTERN, &bp); <answer> rlen 
<token> (rlen < 0) { <answer> if 
<token> to read link video pattern. rlen=%zd\n", <answer> DRM_ERROR("failed 
<token> rlen; <answer> return 
<token> (!dp_link_is_video_pattern_valid(bp)) { <answer> if 
DRM_ERROR("invalid link video pattern <token> 0x%x\n", bp); <answer> = 
ret <token> -EINVAL; <answer> = 
<token> ret; <answer> return 
link->dp_link.test_video.test_video_pattern <token> bp; <answer> = 
static <token> dp_link_parse_link_training_params(struct dp_link_private *link) <answer> int 
<token> bp; <answer> u8 
ssize_t <token> <answer> rlen; 
<token> = drm_dp_dpcd_readb(link->aux, DP_TEST_LINK_RATE, &bp); <answer> rlen 
if <token> < 0) { <answer> (rlen 
DRM_ERROR("failed to read link rate. <token> rlen); <answer> rlen=%zd\n", 
return <token> <answer> rlen; 
<token> (!is_link_rate_valid(bp)) { <answer> if 
DRM_ERROR("invalid link rate = <token> bp); <answer> 0x%x\n", 
<token> -EINVAL; <answer> return 
link->request.test_link_rate = <token> <answer> bp; 
drm_dbg_dp(link->drm_dev, "link <token> = 0x%x\n", <answer> rate 
rlen = drm_dp_dpcd_readb(link->aux, DP_TEST_LANE_COUNT, <token> <answer> &bp); 
if (rlen < <token> { <answer> 0) 
DRM_ERROR("failed to <token> lane count. rlen=%zd\n", rlen); <answer> read 
<token> rlen; <answer> return 
bp <token> DP_MAX_LANE_COUNT_MASK; <answer> &= 
<token> (!is_lane_count_valid(bp)) { <answer> if 
DRM_ERROR("invalid <token> count = 0x%x\n", bp); <answer> lane 
return <token> <answer> -EINVAL; 
<token> = bp; <answer> link->request.test_lane_count 
drm_dbg_dp(link->drm_dev, <token> count = 0x%x\n", <answer> "lane 
<token> 0; <answer> return 
static int dp_link_parse_phy_test_params(struct <token> *link) <answer> dp_link_private 
u8 <token> <answer> data; 
<token> rlen; <answer> ssize_t 
rlen <token> drm_dp_dpcd_readb(link->aux, DP_PHY_TEST_PATTERN, <answer> = 
if (rlen < <token> { <answer> 0) 
DRM_ERROR("failed to read phy link pattern. <token> rlen); <answer> rlen=%zd\n", 
<token> rlen; <answer> return 
link->dp_link.phy_params.phy_test_pattern_sel = data <token> 0x07; <answer> & 
drm_dbg_dp(link->drm_dev, "phy_test_pattern_sel = 0x%x\n", <token> <answer> data); 
switch (data) <token> <answer> { 
case <token> <answer> DP_PHY_TEST_PATTERN_SEL_MASK: 
<token> DP_PHY_TEST_PATTERN_NONE: <answer> case 
<token> DP_PHY_TEST_PATTERN_D10_2: <answer> case 
<token> DP_PHY_TEST_PATTERN_ERROR_COUNT: <answer> case 
<token> DP_PHY_TEST_PATTERN_PRBS7: <answer> case 
case <token> <answer> DP_PHY_TEST_PATTERN_80BIT_CUSTOM: 
case <token> <answer> DP_PHY_TEST_PATTERN_CP2520: 
<token> 0; <answer> return 
<token> -EINVAL; <answer> return 
static <token> dp_link_is_video_audio_test_requested(u32 link) <answer> bool 
u8 video_audio_test = (DP_TEST_LINK_VIDEO_PATTERN <token> <answer> | 
DP_TEST_LINK_AUDIO_PATTERN <token> <answer> | 
return ((link & <token> && <answer> video_audio_test) 
!(link <token> ~video_audio_test)); <answer> & 
static int dp_link_parse_request(struct dp_link_private <token> <answer> *link) 
int <token> = 0; <answer> ret 
<token> data; <answer> u8 
<token> rlen; <answer> ssize_t 
<token> = drm_dp_dpcd_readb(link->aux, <answer> rlen 
<token> &data); <answer> DP_DEVICE_SERVICE_IRQ_VECTOR, 
<token> (rlen < 0) { <answer> if 
DRM_ERROR("aux read failed. <token> rlen); <answer> rlen=%zd\n", 
<token> rlen; <answer> return 
<token> "device service irq vector = 0x%x\n", data); <answer> drm_dbg_dp(link->drm_dev, 
if (!(data & DP_AUTOMATED_TEST_REQUEST)) <token> <answer> { 
drm_dbg_dp(link->drm_dev, <token> test requested\n"); <answer> "no 
return <token> <answer> 0; 
rlen = <token> DP_TEST_REQUEST, &data); <answer> drm_dp_dpcd_readb(link->aux, 
if (rlen <token> 0) { <answer> < 
DRM_ERROR("aux read failed. rlen=%zd\n", <token> <answer> rlen); 
return <token> <answer> rlen; 
if (!data || (data <token> DP_TEST_LINK_FAUX_PATTERN)) { <answer> == 
drm_dbg_dp(link->drm_dev, "link 0x%x not supported\n", <token> <answer> data); 
<token> end; <answer> goto 
drm_dbg_dp(link->drm_dev, "Test:(0x%x) <token> data); <answer> requested\n", 
link->request.test_requested <token> data; <answer> = 
if (link->request.test_requested <token> DP_TEST_LINK_PHY_TEST_PATTERN) { <answer> == 
ret <token> dp_link_parse_phy_test_params(link); <answer> = 
<token> (ret) <answer> if 
goto <token> <answer> end; 
<token> = dp_link_parse_link_training_params(link); <answer> ret 
if <token> <answer> (ret) 
<token> end; <answer> goto 
if (link->request.test_requested == <token> { <answer> DP_TEST_LINK_TRAINING) 
ret = <token> <answer> dp_link_parse_link_training_params(link); 
<token> (ret) <answer> if 
<token> end; <answer> goto 
<token> (dp_link_is_video_audio_test_requested( <answer> if 
<token> { <answer> link->request.test_requested)) 
ret <token> dp_link_parse_video_pattern_params(link); <answer> = 
<token> (ret) <answer> if 
goto <token> <answer> end; 
ret = <token> <answer> dp_link_parse_audio_pattern_params(link); 
if <token> { <answer> (ret) 
link->dp_link.test_response = <token> <answer> DP_TEST_NAK; 
} else <token> <answer> { 
if (link->request.test_requested <token> DP_TEST_LINK_EDID_READ) <answer> != 
link->dp_link.test_response = <token> <answer> DP_TEST_ACK; 
link->dp_link.test_response <token> <answer> = 
return <token> <answer> ret; 
static int dp_link_parse_sink_status_field(struct dp_link_private <token> <answer> *link) 
int <token> <answer> len; 
link->prev_sink_count <token> link->dp_link.sink_count; <answer> = 
len <token> drm_dp_read_sink_count(link->aux); <answer> = 
<token> (len < 0) { <answer> if 
DRM_ERROR("DP parse sink <token> failed\n"); <answer> count 
<token> len; <answer> return 
<token> = len; <answer> link->dp_link.sink_count 
len = <token> <answer> drm_dp_dpcd_read_link_status(link->aux, 
if (len < <token> { <answer> DP_LINK_STATUS_SIZE) 
DRM_ERROR("DP <token> status read failed\n"); <answer> link 
<token> len; <answer> return 
return <token> <answer> dp_link_parse_request(link); 
static int dp_link_process_link_training_request(struct dp_link_private <token> <answer> *link) 
if <token> != DP_TEST_LINK_TRAINING) <answer> (link->request.test_requested 
<token> -EINVAL; <answer> return 
"Test:0x%x <token> rate = 0x%x, lane count = 0x%x\n", <answer> link 
link->dp_link.link_params.num_lanes = <token> <answer> link->request.test_lane_count; 
link->dp_link.link_params.rate <token> <answer> = 
return <token> <answer> 0; 
bool dp_link_send_test_response(struct dp_link <token> <answer> *dp_link) 
struct dp_link_private <token> = NULL; <answer> *link 
int ret <token> 0; <answer> = 
<token> (!dp_link) { <answer> if 
DRM_ERROR("invalid <token> <answer> input\n"); 
<token> false; <answer> return 
link <token> container_of(dp_link, struct dp_link_private, dp_link); <answer> = 
ret <token> drm_dp_dpcd_writeb(link->aux, DP_TEST_RESPONSE, <answer> = 
<token> ret == 1; <answer> return 
int <token> dp_link *dp_link, <answer> dp_link_psm_config(struct 
struct <token> *link_info, bool enable) <answer> dp_link_info 
<token> dp_link_private *link = NULL; <answer> struct 
<token> ret = 0; <answer> int 
if (!dp_link) <token> <answer> { 
<token> params\n"); <answer> DRM_ERROR("invalid 
return <token> <answer> -EINVAL; 
link = <token> struct dp_link_private, dp_link); <answer> container_of(dp_link, 
<token> (enable) <answer> if 
ret = <token> link_info); <answer> dp_aux_link_power_down(link->aux, 
ret = dp_aux_link_power_up(link->aux, <token> <answer> link_info); 
<token> (ret) <answer> if 
<token> to %s low power mode\n", enable ? <answer> DRM_ERROR("Failed 
<token> : "exit"); <answer> "enter" 
<token> = enable; <answer> dp_link->psm_enabled 
<token> ret; <answer> return 
bool dp_link_send_edid_checksum(struct <token> *dp_link, u8 checksum) <answer> dp_link 
struct dp_link_private <token> = NULL; <answer> *link 
int ret = <token> <answer> 0; 
<token> (!dp_link) { <answer> if 
<token> input\n"); <answer> DRM_ERROR("invalid 
return <token> <answer> false; 
link = <token> struct dp_link_private, dp_link); <answer> container_of(dp_link, 
ret <token> drm_dp_dpcd_writeb(link->aux, DP_TEST_EDID_CHECKSUM, <answer> = 
return ret == <token> <answer> 1; 
static void dp_link_parse_vx_px(struct <token> *link) <answer> dp_link_private 
drm_dbg_dp(link->drm_dev, <token> 0=%d, 1=%d, 2=%d, 3=%d\n", <answer> "vx: 
drm_dp_get_adjust_request_voltage(link->link_status, <token> <answer> 0), 
<token> 1), <answer> drm_dp_get_adjust_request_voltage(link->link_status, 
drm_dp_get_adjust_request_voltage(link->link_status, <token> <answer> 2), 
drm_dp_get_adjust_request_voltage(link->link_status, <token> <answer> 3)); 
<token> "px: 0=%d, 1=%d, 2=%d, 3=%d\n", <answer> drm_dbg_dp(link->drm_dev, 
drm_dp_get_adjust_request_pre_emphasis(link->link_status, <token> <answer> 0), 
<token> 1), <answer> drm_dp_get_adjust_request_pre_emphasis(link->link_status, 
drm_dp_get_adjust_request_pre_emphasis(link->link_status, <token> <answer> 2), 
drm_dp_get_adjust_request_pre_emphasis(link->link_status, <token> <answer> 3)); 
"Current: <token> = 0x%x, p_level = 0x%x\n", <answer> v_level 
<token> = <answer> link->dp_link.phy_params.v_level 
drm_dp_get_adjust_request_voltage(link->link_status, <token> <answer> 0); 
link->dp_link.phy_params.p_level <token> <answer> = 
<token> 0); <answer> drm_dp_get_adjust_request_pre_emphasis(link->link_status, 
link->dp_link.phy_params.p_level >>= <token> <answer> DP_TRAIN_PRE_EMPHASIS_SHIFT; 
"Requested: v_level = <token> p_level = 0x%x\n", <answer> 0x%x, 
<token> int dp_link_process_phy_test_pattern_request( <answer> static 
<token> dp_link_private *link) <answer> struct 
<token> (!(link->request.test_requested & DP_TEST_LINK_PHY_TEST_PATTERN)) { <answer> if 
<token> "no phy test\n"); <answer> drm_dbg_dp(link->drm_dev, 
<token> -EINVAL; <answer> return 
<token> (!is_link_rate_valid(link->request.test_link_rate) || <answer> if 
!is_lane_count_valid(link->request.test_lane_count)) <token> <answer> { 
DRM_ERROR("Invalid: link rate = 0x%x,lane count <token> 0x%x\n", <answer> = 
<token> -EINVAL; <answer> return 
"Current: rate = 0x%x, lane count = <token> <answer> 0x%x\n", 
"Requested: rate = 0x%x, lane <token> = 0x%x\n", <answer> count 
<token> = link->request.test_lane_count; <answer> link->dp_link.link_params.num_lanes 
<token> = <answer> link->dp_link.link_params.rate 
return <token> <answer> 0; 
<token> bool dp_link_read_psr_error_status(struct dp_link_private *link) <answer> static 
u8 <token> <answer> status; 
drm_dp_dpcd_read(link->aux, <token> &status, 1); <answer> DP_PSR_ERROR_STATUS, 
if (status <token> DP_PSR_LINK_CRC_ERROR) <answer> & 
DRM_ERROR("PSR <token> CRC ERROR\n"); <answer> LINK 
else if (status & <token> <answer> DP_PSR_RFB_STORAGE_ERROR) 
DRM_ERROR("PSR RFB STORAGE <token> <answer> ERROR\n"); 
else if <token> & DP_PSR_VSC_SDP_UNCORRECTABLE_ERROR) <answer> (status 
<token> VSC SDP UNCORRECTABLE ERROR\n"); <answer> DRM_ERROR("PSR 
<token> false; <answer> return 
<token> true; <answer> return 
static bool dp_link_psr_capability_changed(struct dp_link_private <token> <answer> *link) 
<token> status; <answer> u8 
drm_dp_dpcd_read(link->aux, DP_PSR_ESI, <token> 1); <answer> &status, 
if <token> & DP_PSR_CAPS_CHANGE) { <answer> (status 
drm_dbg_dp(link->drm_dev, <token> Capability Change\n"); <answer> "PSR 
return <token> <answer> true; 
return <token> <answer> false; 
<token> u8 get_link_status(const u8 link_status[DP_LINK_STATUS_SIZE], int r) <answer> static 
return <token> - DP_LANE0_1_STATUS]; <answer> link_status[r 
static <token> dp_link_process_link_status_update(struct dp_link_private *link) <answer> int 
bool channel_eq_done <token> drm_dp_channel_eq_ok(link->link_status, <answer> = 
bool clock_recovery_done <token> drm_dp_clock_recovery_ok(link->link_status, <answer> = 
<token> = %d, clock_recovery_done = %d\n", <answer> "channel_eq_done 
<token> clock_recovery_done); <answer> channel_eq_done, 
<token> (channel_eq_done && clock_recovery_done) <answer> if 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
static int dp_link_process_ds_port_status_change(struct <token> *link) <answer> dp_link_private 
<token> (get_link_status(link->link_status, DP_LANE_ALIGN_STATUS_UPDATED) & <answer> if 
goto <token> <answer> reset; 
if (link->prev_sink_count == <token> <answer> link->dp_link.sink_count) 
return <token> <answer> -EINVAL; 
<token> dp_link_process_request(struct dp_link *dp_link) <answer> int 
int <token> = 0; <answer> ret 
struct <token> *link; <answer> dp_link_private 
<token> (!dp_link) { <answer> if 
<token> input\n"); <answer> DRM_ERROR("invalid 
return <token> <answer> -EINVAL; 
link = container_of(dp_link, <token> dp_link_private, dp_link); <answer> struct 
ret = <token> <answer> dp_link_parse_sink_status_field(link); 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if (link->request.test_requested <token> DP_TEST_LINK_EDID_READ) { <answer> == 
dp_link->sink_request |= <token> <answer> DP_TEST_LINK_EDID_READ; 
} <token> if (!dp_link_process_ds_port_status_change(link)) { <answer> else 
dp_link->sink_request <token> DS_PORT_STATUS_CHANGED; <answer> |= 
<token> else if (!dp_link_process_link_training_request(link)) { <answer> } 
<token> |= DP_TEST_LINK_TRAINING; <answer> dp_link->sink_request 
<token> else if (!dp_link_process_phy_test_pattern_request(link)) { <answer> } 
dp_link->sink_request |= <token> <answer> DP_TEST_LINK_PHY_TEST_PATTERN; 
} else <token> (dp_link_read_psr_error_status(link)) { <answer> if 
DRM_ERROR("PSR IRQ_HPD <token> <answer> received\n"); 
} else if (dp_link_psr_capability_changed(link)) <token> <answer> { 
<token> "PSR Capability changed\n"); <answer> drm_dbg_dp(link->drm_dev, 
} <token> { <answer> else 
ret = <token> <answer> dp_link_process_link_status_update(link); 
<token> (!ret) { <answer> if 
<token> |= DP_LINK_STATUS_UPDATED; <answer> dp_link->sink_request 
} <token> { <answer> else 
if <token> { <answer> (dp_link_is_video_pattern_requested(link)) 
<token> = 0; <answer> ret 
dp_link->sink_request <token> DP_TEST_LINK_VIDEO_PATTERN; <answer> |= 
if (dp_link_is_audio_pattern_requested(link)) <token> <answer> { 
<token> |= DP_TEST_LINK_AUDIO_PATTERN; <answer> dp_link->sink_request 
ret <token> -EINVAL; <answer> = 
<token> "sink request=%#x\n", <answer> drm_dbg_dp(link->drm_dev, 
return <token> <answer> ret; 
int dp_link_get_colorimetry_config(struct <token> *dp_link) <answer> dp_link 
<token> cc = DP_MISC0_COLORIMERY_CFG_LEGACY_RGB; <answer> u32 
struct dp_link_private <token> <answer> *link; 
if (!dp_link) <token> <answer> { 
DRM_ERROR("invalid <token> <answer> input\n"); 
return <token> <answer> -EINVAL; 
link = container_of(dp_link, struct dp_link_private, <token> <answer> dp_link); 
<token> (dp_link_is_video_pattern_requested(link)) { <answer> if 
<token> (link->dp_link.test_video.test_dyn_range & <answer> if 
cc <token> DP_MISC0_COLORIMERY_CFG_CEA_RGB; <answer> = 
<token> cc; <answer> return 
int dp_link_adjust_levels(struct <token> *dp_link, u8 *link_status) <answer> dp_link 
int <token> <answer> i; 
int v_max = <token> p_max = 0; <answer> 0, 
<token> dp_link_private *link; <answer> struct 
if (!dp_link) <token> <answer> { 
<token> input\n"); <answer> DRM_ERROR("invalid 
return <token> <answer> -EINVAL; 
link <token> container_of(dp_link, struct dp_link_private, dp_link); <answer> = 
if (dp_link->phy_params.v_level <token> DP_TRAIN_VOLTAGE_SWING_MAX) { <answer> > 
"Requested vSwingLevel=%d, change to <token> <answer> %d\n", 
<token> = DP_TRAIN_VOLTAGE_SWING_MAX; <answer> dp_link->phy_params.v_level 
if <token> > DP_TRAIN_PRE_EMPHASIS_MAX) { <answer> (dp_link->phy_params.p_level 
"Requested preEmphasisLevel=%d, <token> to %d\n", <answer> change 
dp_link->phy_params.p_level <token> DP_TRAIN_PRE_EMPHASIS_MAX; <answer> = 
if ((dp_link->phy_params.p_level <token> DP_TRAIN_PRE_EMPHASIS_LVL_1) <answer> > 
<token> (dp_link->phy_params.v_level == <answer> && 
<token> { <answer> DP_TRAIN_VOLTAGE_SWING_LVL_2)) 
"Requested <token> change to %d\n", <answer> preEmphasisLevel=%d, 
dp_link->phy_params.p_level <token> DP_TRAIN_PRE_EMPHASIS_LVL_1; <answer> = 
drm_dbg_dp(link->drm_dev, "adjusted: v_level=%d, <token> <answer> p_level=%d\n", 
dp_link->phy_params.v_level, <token> <answer> dp_link->phy_params.p_level); 
return <token> <answer> 0; 
void dp_link_reset_phy_params_vx_px(struct dp_link <token> <answer> *dp_link) 
dp_link->phy_params.v_level = <token> <answer> 0; 
dp_link->phy_params.p_level = <token> <answer> 0; 
u32 dp_link_get_test_bits_depth(struct dp_link <token> u32 bpp) <answer> *dp_link, 
<token> tbd; <answer> u32 
struct dp_link_private <token> <answer> *link; 
link = <token> struct dp_link_private, dp_link); <answer> container_of(dp_link, 
switch (bpp) <token> <answer> { 
case <token> <answer> 18: 
tbd = <token> <answer> DP_TEST_BIT_DEPTH_6; 
case <token> <answer> 24: 
tbd <token> DP_TEST_BIT_DEPTH_8; <answer> = 
case <token> <answer> 30: 
tbd <token> DP_TEST_BIT_DEPTH_10; <answer> = 
drm_dbg_dp(link->drm_dev, "bpp=%d not supported, <token> bpc=8\n", <answer> use 
tbd <token> DP_TEST_BIT_DEPTH_8; <answer> = 
<token> = (tbd >> DP_TEST_BIT_DEPTH_SHIFT); <answer> tbd 
return <token> <answer> tbd; 
struct dp_link *dp_link_get(struct device *dev, struct <token> *aux) <answer> drm_dp_aux 
struct <token> *link; <answer> dp_link_private 
<token> dp_link *dp_link; <answer> struct 
if <token> || !aux) { <answer> (!dev 
DRM_ERROR("invalid <token> <answer> input\n"); 
return <token> <answer> ERR_PTR(-EINVAL); 
link = devm_kzalloc(dev, sizeof(*link), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!link) 
<token> ERR_PTR(-ENOMEM); <answer> return 
<token> = dev; <answer> link->dev 
link->aux <token> aux; <answer> = 
dp_link <token> &link->dp_link; <answer> = 
return <token> <answer> dp_link; 
static inline void ixgbe_fcoe_clear_ddp(struct ixgbe_fcoe_ddp <token> <answer> *ddp) 
<token> = 0; <answer> ddp->len 
ddp->err <token> 1; <answer> = 
ddp->udl = <token> <answer> NULL; 
ddp->udp <token> 0UL; <answer> = 
ddp->sgl = <token> <answer> NULL; 
<token> = 0; <answer> ddp->sgc 
<token> ixgbe_fcoe_ddp_put(struct net_device *netdev, u16 xid) <answer> int 
int <token> <answer> len; 
<token> ixgbe_fcoe *fcoe; <answer> struct 
struct <token> *adapter; <answer> ixgbe_adapter 
struct ixgbe_fcoe_ddp <token> <answer> *ddp; 
struct ixgbe_hw <token> <answer> *hw; 
<token> fcbuff; <answer> u32 
if <token> <answer> (!netdev) 
return <token> <answer> 0; 
if (xid <token> netdev->fcoe_ddp_xid) <answer> >= 
<token> 0; <answer> return 
adapter = <token> <answer> netdev_priv(netdev); 
fcoe <token> &adapter->fcoe; <answer> = 
ddp <token> &fcoe->ddp[xid]; <answer> = 
if <token> <answer> (!ddp->udl) 
return <token> <answer> 0; 
<token> = &adapter->hw; <answer> hw 
<token> = ddp->len; <answer> len 
<token> int ixgbe_fcoe_ddp_setup(struct net_device *netdev, u16 xid, <answer> static 
struct scatterlist *sgl, <token> int sgc, <answer> unsigned 
<token> target_mode) <answer> int 
<token> ixgbe_adapter *adapter; <answer> struct 
struct ixgbe_hw <token> <answer> *hw; 
<token> ixgbe_fcoe *fcoe; <answer> struct 
struct <token> *ddp; <answer> ixgbe_fcoe_ddp 
struct ixgbe_fcoe_ddp_pool <token> <answer> *ddp_pool; 
struct <token> *sg; <answer> scatterlist 
<token> int i, j, dmacount; <answer> unsigned 
unsigned <token> len; <answer> int 
static const unsigned int bufflen <token> IXGBE_FCBUFF_MIN; <answer> = 
unsigned int firstoff = <token> <answer> 0; 
unsigned int <token> <answer> lastsize; 
unsigned int <token> = 0; <answer> thisoff 
unsigned int thislen <token> 0; <answer> = 
u32 fcbuff, fcdmarw, <token> fcrxctl; <answer> fcfltrw, 
dma_addr_t addr <token> 0; <answer> = 
if (!netdev || <token> <answer> !sgl) 
<token> 0; <answer> return 
adapter = <token> <answer> netdev_priv(netdev); 
if (xid >= <token> { <answer> netdev->fcoe_ddp_xid) 
<token> "xid=0x%x out-of-range\n", xid); <answer> e_warn(drv, 
<token> 0; <answer> return 
if ((j != 0) && <token> <answer> (thisoff)) 
<token> out_noddp_free; <answer> goto 
if (((i != (dmacount - 1)) <token> (thislen != len)) <answer> || 
&& ((thislen + thisoff) != <token> <answer> bufflen)) 
goto <token> <answer> out_noddp_free; 
ddp->udl[j] = (u64)(addr <token> thisoff); <answer> - 
if <token> == bufflen) { <answer> (lastsize 
if (j >= <token> { <answer> IXGBE_BUFFCNT_MAX) 
goto <token> <answer> out_noddp_free; 
ddp->udl[j] <token> (u64)(fcoe->extra_ddp_buffer_dma); <answer> = 
lastsize = <token> <answer> 1; 
fcbuff = (IXGBE_FCBUFF_4KB << <token> <answer> IXGBE_FCBUFF_BUFFSIZE_SHIFT); 
fcbuff <token> ((j & 0xff) << IXGBE_FCBUFF_BUFFCNT_SHIFT); <answer> |= 
fcbuff <token> (firstoff << IXGBE_FCBUFF_OFFSET_SHIFT); <answer> |= 
if (target_mode && !test_bit(__IXGBE_FCOE_TARGET, <token> { <answer> &fcoe->mode)) 
<token> &fcoe->mode); <answer> set_bit(__IXGBE_FCOE_TARGET, 
fcrxctl = IXGBE_READ_REG(hw, <token> <answer> IXGBE_FCRXCTRL); 
fcrxctl <token> IXGBE_FCRXCTRL_LASTSEQH; <answer> |= 
IXGBE_WRITE_REG(hw, <token> fcrxctl); <answer> IXGBE_FCRXCTRL, 
if <token> == ixgbe_mac_X550) { <answer> (hw->mac.type 
<token> ixgbe_fcoe_ddp_get(struct net_device *netdev, u16 xid, <answer> int 
<token> scatterlist *sgl, unsigned int sgc) <answer> struct 
return ixgbe_fcoe_ddp_setup(netdev, <token> sgl, sgc, 0); <answer> xid, 
int ixgbe_fcoe_ddp_target(struct net_device *netdev, <token> xid, <answer> u16 
<token> scatterlist *sgl, unsigned int sgc) <answer> struct 
return ixgbe_fcoe_ddp_setup(netdev, xid, sgl, <token> 1); <answer> sgc, 
int ixgbe_fcoe_ddp(struct ixgbe_adapter <token> <answer> *adapter, 
union <token> *rx_desc, <answer> ixgbe_adv_rx_desc 
<token> sk_buff *skb) <answer> struct 
int rc = <token> <answer> -EINVAL; 
<token> ixgbe_fcoe *fcoe; <answer> struct 
struct ixgbe_fcoe_ddp <token> <answer> *ddp; 
<token> fc_frame_header *fh; <answer> struct 
<token> fcoe_crc_eof *crc; <answer> struct 
__le32 fcerr = <token> IXGBE_RXDADV_ERR_FCERR); <answer> ixgbe_test_staterr(rx_desc, 
<token> ddp_err; <answer> __le32 
int <token> <answer> ddp_max; 
<token> fctl; <answer> u32 
<token> xid; <answer> u16 
<token> (fcerr == cpu_to_le32(IXGBE_FCERR_BADCRC)) <answer> if 
skb->ip_summed = <token> <answer> CHECKSUM_NONE; 
skb->ip_summed = <token> <answer> CHECKSUM_UNNECESSARY; 
if (eth_hdr(skb)->h_proto == <token> <answer> htons(ETH_P_8021Q)) 
fh = (struct fc_frame_header <token> + <answer> *)(skb->data 
sizeof(struct <token> + sizeof(struct fcoe_hdr)); <answer> vlan_hdr) 
fh <token> (struct fc_frame_header *)(skb->data + <answer> = 
sizeof(struct <token> <answer> fcoe_hdr)); 
fctl = <token> <answer> ntoh24(fh->fh_f_ctl); 
<token> (fctl & FC_FC_EX_CTX) <answer> if 
xid <token> be16_to_cpu(fh->fh_ox_id); <answer> = 
xid <token> be16_to_cpu(fh->fh_rx_id); <answer> = 
ddp_max <token> IXGBE_FCOE_DDP_MAX; <answer> = 
if ((fh->fh_r_ctl == FC_RCTL_DD_SOL_DATA) <token> <answer> && 
(fctl & FC_FC_END_SEQ)) <token> <answer> { 
crc = skb_put(skb, <token> <answer> sizeof(*crc)); 
<token> = FC_EOF_T; <answer> crc->fcoe_eof 
<token> rc; <answer> return 
<token> ixgbe_fso(struct ixgbe_ring *tx_ring, <answer> int 
<token> ixgbe_tx_buffer *first, <answer> struct 
<token> *hdr_len) <answer> u8 
struct <token> *skb = first->skb; <answer> sk_buff 
<token> fc_frame_header *fh; <answer> struct 
<token> vlan_macip_lens; <answer> u32 
<token> fcoe_sof_eof = 0; <answer> u32 
<token> mss_l4len_idx; <answer> u32 
u32 type_tucmd <token> IXGBE_ADVTXT_TUCMD_FCOE; <answer> = 
<token> sof, eof; <answer> u8 
if (skb_is_gso(skb) && <token> != SKB_GSO_FCOE)) { <answer> (skb_shinfo(skb)->gso_type 
dev_err(tx_ring->dev, "Wrong gso type %d:expecting <token> <answer> SKB_GSO_FCOE\n", 
return <token> <answer> -EINVAL; 
void ixgbe_configure_fcoe(struct <token> *adapter) <answer> ixgbe_adapter 
struct <token> *fcoe = &adapter->ring_feature[RING_F_FCOE]; <answer> ixgbe_ring_feature 
struct ixgbe_hw *hw = <token> <answer> &adapter->hw; 
int i, fcoe_q, fcoe_i, fcoe_q_h = <token> <answer> 0; 
int <token> <answer> fcreta_size; 
u32 <token> <answer> etqf; 
void ixgbe_free_fcoe_ddp_resources(struct ixgbe_adapter <token> <answer> *adapter) 
<token> ixgbe_fcoe *fcoe = &adapter->fcoe; <answer> struct 
int <token> i, ddp_max; <answer> cpu, 
<token> ixgbe_setup_fcoe_ddp_resources(struct ixgbe_adapter *adapter) <answer> int 
struct ixgbe_fcoe *fcoe <token> &adapter->fcoe; <answer> = 
struct device *dev <token> &adapter->pdev->dev; <answer> = 
<token> *buffer; <answer> void 
dma_addr_t <token> <answer> dma; 
<token> int cpu; <answer> unsigned 
<token> ixgbe_fcoe_enable(struct net_device *netdev) <answer> int 
struct ixgbe_adapter *adapter <token> netdev_priv(netdev); <answer> = 
struct ixgbe_fcoe <token> = &adapter->fcoe; <answer> *fcoe 
if (!(adapter->flags <token> IXGBE_FLAG_FCOE_CAPABLE)) <answer> & 
<token> -EINVAL; <answer> return 
<token> (adapter->flags & IXGBE_FLAG_FCOE_ENABLED) <answer> if 
<token> -EINVAL; <answer> return 
e_info(drv, "Enabling FCoE offload <token> <answer> features.\n"); 
if <token> & IXGBE_FLAG_SRIOV_ENABLED) <answer> (adapter->flags 
e_warn(probe, "Enabling FCoE on <token> will disable legacy VFs\n"); <answer> PF 
<token> (netif_running(netdev)) <answer> if 
int ixgbe_fcoe_disable(struct <token> *netdev) <answer> net_device 
struct ixgbe_adapter *adapter <token> netdev_priv(netdev); <answer> = 
<token> (!atomic_dec_and_test(&adapter->fcoe.refcnt)) <answer> if 
<token> -EINVAL; <answer> return 
if <token> & IXGBE_FLAG_FCOE_ENABLED)) <answer> (!(adapter->flags 
return <token> <answer> -EINVAL; 
e_info(drv, "Disabling <token> offload features.\n"); <answer> FCoE 
if <token> <answer> (netif_running(netdev)) 
int ixgbe_fcoe_get_wwn(struct net_device *netdev, u64 *wwn, <token> type) <answer> int 
u16 prefix <token> 0xffff; <answer> = 
struct ixgbe_adapter *adapter = <token> <answer> netdev_priv(netdev); 
struct ixgbe_mac_info *mac <token> &adapter->hw.mac; <answer> = 
<token> (type) { <answer> switch 
case <token> <answer> NETDEV_FCOE_WWNN: 
prefix <token> mac->wwnn_prefix; <answer> = 
case <token> <answer> NETDEV_FCOE_WWPN: 
<token> = mac->wwpn_prefix; <answer> prefix 
if ((prefix != <token> && <answer> 0xffff) 
is_valid_ether_addr(mac->san_addr)) <token> <answer> { 
<token> = ((u64) prefix << 48) | <answer> *wwn 
((u64) mac->san_addr[0] << <token> | <answer> 40) 
<token> mac->san_addr[1] << 32) | <answer> ((u64) 
((u64) mac->san_addr[2] << <token> | <answer> 24) 
((u64) <token> << 16) | <answer> mac->san_addr[3] 
((u64) mac->san_addr[4] << <token> | <answer> 8) 
<token> mac->san_addr[5]); <answer> ((u64) 
return <token> <answer> 0; 
return <token> <answer> -EINVAL; 
int ixgbe_fcoe_get_hbainfo(struct net_device <token> <answer> *netdev, 
struct <token> *info) <answer> netdev_fcoe_hbainfo 
struct <token> *adapter = netdev_priv(netdev); <answer> ixgbe_adapter 
struct ixgbe_hw <token> = &adapter->hw; <answer> *hw 
u64 <token> <answer> dsn; 
<token> (!info) <answer> if 
<token> -EINVAL; <answer> return 
u8 ixgbe_fcoe_get_tc(struct ixgbe_adapter <token> <answer> *adapter) 
#ifdef <token> <answer> CONFIG_IXGBE_DCB 
return netdev_get_prio_tc_map(adapter->netdev, <token> <answer> adapter->fcoe.up); 
<token> 0; <answer> return 
<token> <linux/bitops.h> <answer> #include 
#include <token> <answer> <linux/gpio/driver.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/notifier.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
#define SPRD_EIC_MAX_BANK <token> <answer> 3 
#define <token> 8 <answer> SPRD_EIC_PER_BANK_NR 
#define SPRD_EIC_DATA_MASK <token> 0) <answer> GENMASK(7, 
#define SPRD_EIC_BIT(x) <token> & (SPRD_EIC_PER_BANK_NR - 1)) <answer> ((x) 
<token> SPRD_EIC_DBNC_MASK GENMASK(11, 0) <answer> #define 
enum <token> { <answer> sprd_eic_type 
struct sprd_eic <token> <answer> { 
<token> gpio_chip chip; <answer> struct 
<token> notifier_block irq_nb; <answer> struct 
void __iomem <token> <answer> *base[SPRD_EIC_MAX_BANK]; 
enum <token> type; <answer> sprd_eic_type 
<token> lock; <answer> spinlock_t 
<token> irq; <answer> int 
<token> ATOMIC_NOTIFIER_HEAD(sprd_eic_irq_notifier); <answer> static 
static struct sprd_eic <token> notifier_block *nb) <answer> *to_sprd_eic(struct 
return <token> struct sprd_eic, irq_nb); <answer> container_of(nb, 
<token> sprd_eic_variant_data { <answer> struct 
enum sprd_eic_type <token> <answer> type; 
static const char *sprd_eic_label_name[SPRD_EIC_MAX] <token> { <answer> = 
<token> "eic-latch", "eic-async", <answer> "eic-debounce", 
static const struct sprd_eic_variant_data sc9860_eic_dbnc_data <token> { <answer> = 
.type = <token> <answer> SPRD_EIC_DEBOUNCE, 
static const struct sprd_eic_variant_data sc9860_eic_latch_data = <token> <answer> { 
.type = <token> <answer> SPRD_EIC_LATCH, 
static const struct sprd_eic_variant_data <token> = { <answer> sc9860_eic_async_data 
<token> = SPRD_EIC_ASYNC, <answer> .type 
<token> const struct sprd_eic_variant_data sc9860_eic_sync_data = { <answer> static 
<token> = SPRD_EIC_SYNC, <answer> .type 
static inline <token> __iomem *sprd_eic_offset_base(struct sprd_eic *sprd_eic, <answer> void 
<token> int bank) <answer> unsigned 
if (bank <token> SPRD_EIC_MAX_BANK) <answer> >= 
return <token> <answer> NULL; 
return <token> <answer> sprd_eic->base[bank]; 
static void <token> gpio_chip *chip, unsigned int offset, <answer> sprd_eic_update(struct 
<token> reg, unsigned int val) <answer> u16 
struct sprd_eic <token> = gpiochip_get_data(chip); <answer> *sprd_eic 
void __iomem <token> = <answer> *base 
sprd_eic_offset_base(sprd_eic, <token> / SPRD_EIC_PER_BANK_NR); <answer> offset 
unsigned long <token> <answer> flags; 
u32 <token> <answer> tmp; 
<token> flags); <answer> spin_lock_irqsave(&sprd_eic->lock, 
tmp = <token> + reg); <answer> readl_relaxed(base 
<token> (val) <answer> if 
tmp |= <token> <answer> BIT(SPRD_EIC_BIT(offset)); 
<token> &= ~BIT(SPRD_EIC_BIT(offset)); <answer> tmp 
writel_relaxed(tmp, <token> + reg); <answer> base 
<token> flags); <answer> spin_unlock_irqrestore(&sprd_eic->lock, 
static int sprd_eic_read(struct gpio_chip <token> unsigned int offset, u16 reg) <answer> *chip, 
struct sprd_eic *sprd_eic <token> gpiochip_get_data(chip); <answer> = 
void <token> *base = <answer> __iomem 
sprd_eic_offset_base(sprd_eic, offset <token> SPRD_EIC_PER_BANK_NR); <answer> / 
return !!(readl_relaxed(base + <token> & BIT(SPRD_EIC_BIT(offset))); <answer> reg) 
static int sprd_eic_request(struct gpio_chip *chip, unsigned <token> offset) <answer> int 
sprd_eic_update(chip, offset, <token> 1); <answer> SPRD_EIC_DBNC_DMSK, 
<token> 0; <answer> return 
static void sprd_eic_free(struct gpio_chip *chip, unsigned int <token> <answer> offset) 
sprd_eic_update(chip, offset, SPRD_EIC_DBNC_DMSK, <token> <answer> 0); 
static int sprd_eic_get(struct gpio_chip *chip, unsigned <token> offset) <answer> int 
<token> sprd_eic *sprd_eic = gpiochip_get_data(chip); <answer> struct 
<token> (sprd_eic->type) { <answer> switch 
case <token> <answer> SPRD_EIC_DEBOUNCE: 
<token> sprd_eic_read(chip, offset, SPRD_EIC_DBNC_DATA); <answer> return 
case <token> <answer> SPRD_EIC_ASYNC: 
return sprd_eic_read(chip, offset, <token> <answer> SPRD_EIC_ASYNC_DATA); 
case <token> <answer> SPRD_EIC_SYNC: 
return sprd_eic_read(chip, <token> SPRD_EIC_SYNC_DATA); <answer> offset, 
<token> -ENOTSUPP; <answer> return 
static int sprd_eic_direction_input(struct gpio_chip *chip, <token> int offset) <answer> unsigned 
<token> ((sprd_eic->type != SPRD_EIC_DEBOUNCE && <answer> if 
sprd_eic->type != <token> || <answer> SPRD_EIC_LATCH) 
!(trigger <token> IRQ_TYPE_EDGE_BOTH)) <answer> & 
state = sprd_eic_get(chip, <token> <answer> offset); 
switch <token> { <answer> (sprd_eic->type) 
case <token> <answer> SPRD_EIC_DEBOUNCE: 
if <token> <answer> (state) 
sprd_eic_update(chip, offset, <token> 0); <answer> SPRD_EIC_DBNC_IEV, 
<token> offset, SPRD_EIC_DBNC_IEV, 1); <answer> sprd_eic_update(chip, 
<token> SPRD_EIC_LATCH: <answer> case 
if <token> <answer> (state) 
<token> offset, SPRD_EIC_LATCH_INTPOL, 0); <answer> sprd_eic_update(chip, 
sprd_eic_update(chip, offset, <token> 1); <answer> SPRD_EIC_LATCH_INTPOL, 
<token> = sprd_eic_get(chip, offset); <answer> post_state 
<token> (state != post_state) { <answer> if 
dev_warn(chip->parent, "EIC level was <token> <answer> changed.\n"); 
<token> = post_state; <answer> state 
<token> retry; <answer> goto 
static void <token> gpio_chip *chip) <answer> sprd_eic_handle_one_type(struct 
struct sprd_eic <token> = gpiochip_get_data(chip); <answer> *sprd_eic 
<token> bank, n, girq; <answer> u32 
for (bank = 0; bank * SPRD_EIC_PER_BANK_NR < <token> bank++) { <answer> chip->ngpio; 
void __iomem *base <token> sprd_eic_offset_base(sprd_eic, bank); <answer> = 
unsigned long <token> <answer> reg; 
<token> (sprd_eic->type) { <answer> switch 
<token> SPRD_EIC_DEBOUNCE: <answer> case 
reg = readl_relaxed(base + <token> & <answer> SPRD_EIC_DBNC_MIS) 
<token> SPRD_EIC_LATCH: <answer> case 
reg = <token> + SPRD_EIC_LATCH_INTMSK) & <answer> readl_relaxed(base 
<token> SPRD_EIC_ASYNC: <answer> case 
reg = readl_relaxed(base <token> SPRD_EIC_ASYNC_INTMSK) & <answer> + 
case <token> <answer> SPRD_EIC_SYNC: 
<token> = readl_relaxed(base + SPRD_EIC_SYNC_INTMSK) & <answer> reg 
dev_err(chip->parent, "Unsupported EIC <token> <answer> type.\n"); 
for_each_set_bit(n, <token> SPRD_EIC_PER_BANK_NR) { <answer> &reg, 
u32 offset = bank * SPRD_EIC_PER_BANK_NR + <token> <answer> n; 
girq <token> irq_find_mapping(chip->irq.domain, offset); <answer> = 
<token> girq, offset); <answer> sprd_eic_toggle_trigger(chip, 
static void sprd_eic_irq_handler(struct irq_desc <token> <answer> *desc) 
struct irq_chip *ic = <token> <answer> irq_desc_get_chip(desc); 
chained_irq_enter(ic, <token> <answer> desc); 
<token> 0, NULL); <answer> atomic_notifier_call_chain(&sprd_eic_irq_notifier, 
chained_irq_exit(ic, <token> <answer> desc); 
static int <token> notifier_block *nb, unsigned long action, <answer> sprd_eic_irq_notify(struct 
void <token> <answer> *data) 
struct <token> *sprd_eic = to_sprd_eic(nb); <answer> sprd_eic 
return <token> <answer> NOTIFY_OK; 
<token> const struct irq_chip sprd_eic_irq = { <answer> static 
.name <token> "sprd-eic", <answer> = 
.irq_ack <token> sprd_eic_irq_ack, <answer> = 
.irq_mask <token> sprd_eic_irq_mask, <answer> = 
.irq_unmask = <token> <answer> sprd_eic_irq_unmask, 
.irq_set_type <token> sprd_eic_irq_set_type, <answer> = 
.flags <token> IRQCHIP_SKIP_SET_WAKE | IRQCHIP_IMMUTABLE, <answer> = 
static <token> sprd_eic_unregister_notifier(void *data) <answer> void 
struct notifier_block *nb = <token> <answer> data; 
<token> nb); <answer> atomic_notifier_chain_unregister(&sprd_eic_irq_notifier, 
<token> int sprd_eic_probe(struct platform_device *pdev) <answer> static 
const <token> sprd_eic_variant_data *pdata; <answer> struct 
struct device *dev <token> &pdev->dev; <answer> = 
struct gpio_irq_chip <token> <answer> *irq; 
struct <token> *sprd_eic; <answer> sprd_eic 
<token> resource *res; <answer> struct 
<token> num_banks = 0; <answer> u16 
int <token> i; <answer> ret, 
pdata <token> of_device_get_match_data(dev); <answer> = 
if <token> { <answer> (!pdata) 
<token> "No matching driver data found.\n"); <answer> dev_err(dev, 
<token> -EINVAL; <answer> return 
<token> = devm_kzalloc(dev, sizeof(*sprd_eic), GFP_KERNEL); <answer> sprd_eic 
<token> (!sprd_eic) <answer> if 
<token> -ENOMEM; <answer> return 
sprd_eic->type = <token> <answer> pdata->type; 
sprd_eic->irq = <token> 0); <answer> platform_get_irq(pdev, 
<token> (sprd_eic->irq < 0) <answer> if 
<token> sprd_eic->irq; <answer> return 
for (i = 0; i < SPRD_EIC_MAX_BANK; i++) <token> <answer> { 
res = platform_get_resource(pdev, IORESOURCE_MEM, <token> <answer> i); 
if <token> <answer> (!res) 
sprd_eic->base[i] = devm_ioremap_resource(dev, <token> <answer> res); 
if <token> <answer> (IS_ERR(sprd_eic->base[i])) 
return <token> <answer> PTR_ERR(sprd_eic->base[i]); 
sprd_eic->chip.label = <token> <answer> sprd_eic_label_name[sprd_eic->type]; 
sprd_eic->chip.ngpio <token> num_banks * SPRD_EIC_PER_BANK_NR; <answer> = 
sprd_eic->chip.base = <token> <answer> -1; 
sprd_eic->chip.parent <token> dev; <answer> = 
sprd_eic->chip.direction_input <token> sprd_eic_direction_input; <answer> = 
<token> (sprd_eic->type) { <answer> switch 
<token> SPRD_EIC_DEBOUNCE: <answer> case 
<token> = sprd_eic_request; <answer> sprd_eic->chip.request 
sprd_eic->chip.free <token> sprd_eic_free; <answer> = 
sprd_eic->chip.set_config <token> sprd_eic_set_config; <answer> = 
<token> = sprd_eic_set; <answer> sprd_eic->chip.set 
case <token> <answer> SPRD_EIC_ASYNC: 
<token> SPRD_EIC_SYNC: <answer> case 
sprd_eic->chip.get = <token> <answer> sprd_eic_get; 
case <token> <answer> SPRD_EIC_LATCH: 
irq = <token> <answer> &sprd_eic->chip.irq; 
gpio_irq_chip_set_chip(irq, <token> <answer> &sprd_eic_irq); 
irq->handler = <token> <answer> handle_bad_irq; 
irq->default_type = <token> <answer> IRQ_TYPE_NONE; 
irq->parent_handler <token> sprd_eic_irq_handler; <answer> = 
irq->parent_handler_data = <token> <answer> sprd_eic; 
irq->num_parents <token> 1; <answer> = 
irq->parents = <token> <answer> &sprd_eic->irq; 
ret <token> devm_gpiochip_add_data(dev, &sprd_eic->chip, sprd_eic); <answer> = 
if (ret < 0) <token> <answer> { 
<token> "Could not register gpiochip %d.\n", ret); <answer> dev_err(dev, 
<token> ret; <answer> return 
sprd_eic->irq_nb.notifier_call <token> sprd_eic_irq_notify; <answer> = 
<token> = atomic_notifier_chain_register(&sprd_eic_irq_notifier, <answer> ret 
<token> (ret) <answer> if 
return <token> ret, <answer> dev_err_probe(dev, 
"Failed to register <token> the interrupt notifier"); <answer> with 
return <token> sprd_eic_unregister_notifier, <answer> devm_add_action_or_reset(dev, 
static <token> struct of_device_id sprd_eic_of_match[] = { <answer> const 
.compatible = <token> <answer> "sprd,sc9860-eic-debounce", 
<token> = &sc9860_eic_dbnc_data, <answer> .data 
<token> = "sprd,sc9860-eic-latch", <answer> .compatible 
.data = <token> <answer> &sc9860_eic_latch_data, 
.compatible = <token> <answer> "sprd,sc9860-eic-async", 
<token> = &sc9860_eic_async_data, <answer> .data 
.compatible = <token> <answer> "sprd,sc9860-eic-sync", 
.data <token> &sc9860_eic_sync_data, <answer> = 
<token> <asm/unaligned.h> <answer> #include 
#include <token> <answer> <asm/simd.h> 
<token> <asm/switch_to.h> <answer> #include 
<token> <crypto/aes.h> <answer> #include 
<token> <crypto/algapi.h> <answer> #include 
#include <token> <answer> <crypto/b128ops.h> 
#include <token> <answer> <crypto/gf128mul.h> 
#include <token> <answer> <crypto/internal/simd.h> 
#include <token> <answer> <crypto/internal/aead.h> 
#include <token> <answer> <crypto/internal/hash.h> 
<token> <crypto/internal/skcipher.h> <answer> #include 
#include <token> <answer> <crypto/scatterwalk.h> 
<token> <linux/cpufeature.h> <answer> #include 
#include <token> <answer> <linux/crypto.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/types.h> 
#define PPC_ALIGN <token> <answer> 16 
<token> GCM_IV_SIZE 12 <answer> #define 
MODULE_DESCRIPTION("PPC64le AES-GCM <token> Stitched implementation"); <answer> with 
MODULE_AUTHOR("Danny <token> <dtsen@linux.ibm.com"); <answer> Tsen 
<token> v2"); <answer> MODULE_LICENSE("GPL 
asmlinkage <token> aes_p10_set_encrypt_key(const u8 *userKey, const int bits, <answer> int 
<token> *key); <answer> void 
asmlinkage <token> aes_p10_encrypt(const u8 *in, u8 *out, const void *key); <answer> void 
asmlinkage void aes_p10_gcm_encrypt(u8 *in, u8 <token> size_t len, <answer> *out, 
void *rkey, u8 *iv, void <token> <answer> *Xi); 
asmlinkage void aes_p10_gcm_decrypt(u8 *in, u8 *out, <token> len, <answer> size_t 
void *rkey, u8 *iv, void <token> <answer> *Xi); 
asmlinkage void gcm_init_htable(unsigned char htable[], unsigned <token> Xi[]); <answer> char 
asmlinkage void <token> char *Xi, unsigned char *Htable, <answer> gcm_ghash_p10(unsigned 
unsigned <token> *aad, unsigned int alen); <answer> char 
<token> aes_key { <answer> struct 
<token> key[AES_MAX_KEYLENGTH]; <answer> u8 
<token> rounds; <answer> u64 
struct <token> { <answer> gcm_ctx 
u8 <token> <answer> iv[16]; 
u8 <token> <answer> ivtag[16]; 
<token> aad_hash[16]; <answer> u8 
<token> aadLen; <answer> u64 
static void set_aad(struct gcm_ctx *gctx, struct <token> *hash, <answer> Hash_ctx 
<token> char *aad, int alen) <answer> unsigned 
<token> i; <answer> int 
u8 nXi[16] <token> {0, }; <answer> = 
gctx->aadLen <token> alen; <answer> = 
<token> = alen & ~0xf; <answer> i 
<token> (i) { <answer> if 
gcm_ghash_p10(nXi, hash->Htable+32, aad, <token> <answer> i); 
<token> += i; <answer> aad 
alen -= <token> <answer> i; 
if (alen) <token> <answer> { 
for (i = 0; <token> < alen; i++) <answer> i 
<token> ^= aad[i]; <answer> nXi[i] 
<token> 0, 16); <answer> memset(gctx->aad_hash, 
<token> hash->Htable+32, nXi, 16); <answer> gcm_ghash_p10(gctx->aad_hash, 
<token> else { <answer> } 
memcpy(gctx->aad_hash, nXi, <token> <answer> 16); 
memcpy(hash->Htable, gctx->aad_hash, <token> <answer> 16); 
<token> void gcmp10_init(struct gcm_ctx *gctx, u8 *iv, unsigned char *rdkey, <answer> static 
struct Hash_ctx *hash, u8 *assoc, unsigned int <token> <answer> assoclen) 
<token> counter = cpu_to_be32(1); <answer> __be32 
aes_p10_encrypt(hash->H, <token> rdkey); <answer> hash->H, 
gcm_init_htable(hash->Htable+32, <token> <answer> hash->H); 
*((__be32 *)(iv+12)) <token> counter; <answer> = 
gctx->Plen = <token> <answer> 0; 
aes_p10_encrypt(iv, <token> rdkey); <answer> gctx->ivtag, 
counter <token> cpu_to_be32(2); <answer> = 
<token> *)(iv+12)) = counter; <answer> *((__be32 
<token> iv, 16); <answer> memcpy(gctx->iv, 
gctx->aadLen <token> assoclen; <answer> = 
memset(gctx->aad_hash, 0, <token> <answer> 16); 
<token> (assoclen) <answer> if 
set_aad(gctx, <token> assoc, assoclen); <answer> hash, 
static void finish_tag(struct gcm_ctx *gctx, <token> Hash_ctx *hash, int len) <answer> struct 
int <token> <answer> i; 
<token> char len_ac[16 + PPC_ALIGN]; <answer> unsigned 
<token> char *aclen = PTR_ALIGN((void *)len_ac, PPC_ALIGN); <answer> unsigned 
__be64 clen = cpu_to_be64(len <token> 3); <answer> << 
__be64 <token> = cpu_to_be64(gctx->aadLen << 3); <answer> alen 
if (len == 0 && gctx->aadLen == 0) <token> <answer> { 
memcpy(hash->Htable, <token> 16); <answer> gctx->ivtag, 
<token> *)(aclen)) = alen; <answer> *((__be64 
*((__be64 <token> = clen; <answer> *)(aclen+8)) 
gcm_ghash_p10(hash->Htable, <token> aclen, 16); <answer> hash->Htable+32, 
for (i <token> 0; i < 16; i++) <answer> = 
<token> ^= gctx->ivtag[i]; <answer> hash->Htable[i] 
<token> int set_authsize(struct crypto_aead *tfm, unsigned int authsize) <answer> static 
<token> (authsize) { <answer> switch 
<token> 4: <answer> case 
case <token> <answer> 8: 
case <token> <answer> 12: 
<token> 13: <answer> case 
case <token> <answer> 14: 
case <token> <answer> 15: 
case <token> <answer> 16: 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
<token> int p10_aes_gcm_setkey(struct crypto_aead *aead, const u8 *key, <answer> static 
unsigned int <token> <answer> keylen) 
struct crypto_tfm *tfm = <token> <answer> crypto_aead_tfm(aead); 
<token> p10_aes_gcm_ctx *ctx = crypto_tfm_ctx(tfm); <answer> struct 
int <token> <answer> ret; 
ret = aes_p10_set_encrypt_key(key, keylen * 8, <token> <answer> &ctx->enc_key); 
return ret ? -EINVAL : <token> <answer> 0; 
static int p10_aes_gcm_crypt(struct aead_request *req, <token> enc) <answer> int 
<token> crypto_tfm *tfm = req->base.tfm; <answer> struct 
struct p10_aes_gcm_ctx *ctx <token> crypto_tfm_ctx(tfm); <answer> = 
u8 databuf[sizeof(struct <token> + PPC_ALIGN]; <answer> gcm_ctx) 
struct gcm_ctx *gctx = <token> *)databuf, PPC_ALIGN); <answer> PTR_ALIGN((void 
u8 hashbuf[sizeof(struct <token> + PPC_ALIGN]; <answer> Hash_ctx) 
struct Hash_ctx <token> = PTR_ALIGN((void *)hashbuf, PPC_ALIGN); <answer> *hash 
struct <token> assoc_sg_walk; <answer> scatter_walk 
struct <token> walk; <answer> skcipher_walk 
u8 *assocmem <token> NULL; <answer> = 
u8 <token> <answer> *assoc; 
<token> int assoclen = req->assoclen; <answer> unsigned 
unsigned int cryptlen <token> req->cryptlen; <answer> = 
unsigned char <token> <answer> ivbuf[AES_BLOCK_SIZE+PPC_ALIGN]; 
<token> char *iv = PTR_ALIGN((void *)ivbuf, PPC_ALIGN); <answer> unsigned 
int <token> <answer> ret; 
unsigned long auth_tag_len = <token> <answer> crypto_aead_authsize(__crypto_aead_cast(tfm)); 
<token> otag[16]; <answer> u8 
int <token> = 0; <answer> total_processed 
memset(databuf, 0, <token> <answer> sizeof(databuf)); 
<token> 0, sizeof(hashbuf)); <answer> memset(hashbuf, 
memset(ivbuf, <token> sizeof(ivbuf)); <answer> 0, 
memcpy(iv, req->iv, <token> <answer> GCM_IV_SIZE); 
#include <token> <answer> <linux/module.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/gpio/consumer.h> 
<token> <linux/delay.h> <answer> #include 
<token> "fbtft.h" <answer> #include 
#define DRVNAME <token> <answer> "fb_ssd1305" 
#define WIDTH <token> <answer> 128 
#define <token> 64 <answer> HEIGHT 
write_reg(par, 0xA0 | ((par->info->var.rotate == 180) ? <token> : 0x1)); <answer> 0x0 
write_reg(par, ((par->info->var.rotate == <token> ? 0xC8 : 0xC0)); <answer> 180) 
<token> 0xA4); <answer> write_reg(par, 
<token> 0xA6); <answer> write_reg(par, 
static __be16 rtr_type = MPA_V2_RDMA_READ_RTR <token> MPA_V2_RDMA_WRITE_RTR; <answer> | 
static const <token> relaxed_ird_negotiation = true; <answer> bool 
static <token> siw_cm_llp_state_change(struct sock *s); <answer> void 
<token> void siw_cm_llp_data_ready(struct sock *s); <answer> static 
static <token> siw_cm_llp_write_space(struct sock *s); <answer> void 
static void siw_cm_llp_error_report(struct sock <token> <answer> *s); 
static int siw_cm_upcall(struct siw_cep *cep, enum iw_cm_event_type <token> <answer> reason, 
int <token> <answer> status); 
static <token> siw_sk_assign_cm_upcalls(struct sock *sk) <answer> void 
struct siw_cep <token> = sk_to_cep(sk); <answer> *cep 
<token> = sk->sk_state_change; <answer> cep->sk_state_change 
<token> = sk->sk_data_ready; <answer> cep->sk_data_ready 
cep->sk_write_space = <token> <answer> sk->sk_write_space; 
cep->sk_error_report <token> sk->sk_error_report; <answer> = 
sk->sk_state_change = <token> <answer> siw_cm_llp_state_change; 
sk->sk_data_ready = <token> <answer> siw_cm_llp_data_ready; 
<token> = siw_cm_llp_write_space; <answer> sk->sk_write_space 
sk->sk_error_report <token> siw_cm_llp_error_report; <answer> = 
static void siw_sk_restore_upcalls(struct <token> *sk, struct siw_cep *cep) <answer> sock 
sk->sk_state_change <token> cep->sk_state_change; <answer> = 
<token> = cep->sk_data_ready; <answer> sk->sk_data_ready 
sk->sk_write_space = <token> <answer> cep->sk_write_space; 
sk->sk_error_report <token> cep->sk_error_report; <answer> = 
sk->sk_user_data <token> NULL; <answer> = 
static void <token> siw_cep *cep, struct siw_qp *qp) <answer> siw_qp_socket_assoc(struct 
struct <token> *s = cep->sock; <answer> socket 
<token> sock *sk = s->sk; <answer> struct 
qp->attrs.sk <token> s; <answer> = 
sk->sk_data_ready = <token> <answer> siw_qp_llp_data_ready; 
sk->sk_write_space <token> siw_qp_llp_write_space; <answer> = 
static void siw_socket_disassoc(struct <token> *s) <answer> socket 
struct sock *sk = <token> <answer> s->sk; 
<token> siw_cep *cep; <answer> struct 
if <token> { <answer> (sk) 
cep <token> sk_to_cep(sk); <answer> = 
if <token> { <answer> (cep) 
siw_sk_restore_upcalls(sk, <token> <answer> cep); 
<token> else { <answer> } 
pr_warn("siw: <token> restore sk callbacks: no ep\n"); <answer> cannot 
<token> else { <answer> } 
pr_warn("siw: cannot <token> sk callbacks: no sk\n"); <answer> restore 
static <token> siw_rtr_data_ready(struct sock *sk) <answer> void 
struct <token> *cep; <answer> siw_cep 
struct siw_qp *qp = <token> <answer> NULL; 
read_descriptor_t <token> <answer> rd_desc; 
<token> = sk_to_cep(sk); <answer> cep 
if <token> { <answer> (!cep) 
WARN(1, "No connection <token> <answer> endpoint\n"); 
goto <token> <answer> out; 
qp <token> sk_to_qp(sk); <answer> = 
memset(&rd_desc, <token> sizeof(rd_desc)); <answer> 0, 
<token> = qp; <answer> rd_desc.arg.data 
rd_desc.count <token> 1; <answer> = 
<token> &rd_desc, siw_tcp_rx_data); <answer> tcp_read_sock(sk, 
if <token> <answer> (!qp->rx_stream.rx_suspend) 
siw_cm_upcall(cep, <token> 0); <answer> IW_CM_EVENT_ESTABLISHED, 
<token> (qp) <answer> if 
<token> qp); <answer> siw_qp_socket_assoc(cep, 
static void siw_sk_assign_rtr_upcalls(struct siw_cep <token> <answer> *cep) 
<token> sock *sk = cep->sock->sk; <answer> struct 
sk->sk_data_ready = <token> <answer> siw_rtr_data_ready; 
<token> = siw_qp_llp_write_space; <answer> sk->sk_write_space 
static void siw_cep_socket_assoc(struct siw_cep <token> struct socket *s) <answer> *cep, 
<token> = s; <answer> cep->sock 
s->sk->sk_user_data = <token> <answer> cep; 
static struct siw_cep *siw_cep_alloc(struct siw_device <token> <answer> *sdev) 
<token> siw_cep *cep = kzalloc(sizeof(*cep), GFP_KERNEL); <answer> struct 
unsigned <token> flags; <answer> long 
if <token> <answer> (!cep) 
return <token> <answer> NULL; 
cep->state = <token> <answer> SIW_EPSTATE_IDLE; 
cep->sdev <token> sdev; <answer> = 
<token> = false; <answer> cep->enhanced_rdma_conn_est 
<token> flags); <answer> spin_lock_irqsave(&sdev->lock, 
<token> &sdev->cep_list); <answer> list_add_tail(&cep->devq, 
spin_unlock_irqrestore(&sdev->lock, <token> <answer> flags); 
<token> "new endpoint\n"); <answer> siw_dbg_cep(cep, 
return <token> <answer> cep; 
static <token> siw_cm_free_work(struct siw_cep *cep) <answer> void 
<token> list_head *w, *tmp; <answer> struct 
struct <token> *work; <answer> siw_cm_work 
list_for_each_safe(w, <token> &cep->work_freelist) { <answer> tmp, 
work <token> list_entry(w, struct siw_cm_work, list); <answer> = 
static void <token> siw_cep *cep) <answer> siw_cancel_mpatimer(struct 
if <token> { <answer> (cep->mpa_timer) 
<token> (cancel_delayed_work(&cep->mpa_timer->work)) { <answer> if 
<token> int siw_cm_upcall(struct siw_cep *cep, enum iw_cm_event_type reason, <answer> static 
<token> status) <answer> int 
struct iw_cm_event <token> <answer> event; 
struct <token> *id; <answer> iw_cm_id 
memset(&event, <token> sizeof(event)); <answer> 0, 
event.status <token> status; <answer> = 
event.event = <token> <answer> reason; 
if (reason == IW_CM_EVENT_CONNECT_REQUEST) <token> <answer> { 
<token> = cep; <answer> event.provider_data 
id <token> cep->listen_cep->cm_id; <answer> = 
} <token> { <answer> else 
<token> = cep->cm_id; <answer> id 
event.private_data_len = <token> <answer> pd_len; 
event.private_data = <token> <answer> cep->mpa.pdata; 
void siw_qp_cm_drop(struct siw_qp *qp, <token> schedule) <answer> int 
struct <token> *cep = qp->cep; <answer> siw_cep 
<token> = 1; <answer> qp->rx_stream.rx_suspend 
qp->tx_ctx.tx_suspend <token> 1; <answer> = 
<token> (!qp->cep) <answer> if 
if <token> { <answer> (schedule) 
<token> SIW_CM_WORK_CLOSE_LLP); <answer> siw_cm_queue_work(cep, 
} <token> { <answer> else 
<token> (cep->state == SIW_EPSTATE_CLOSED) { <answer> if 
<token> "already closed\n"); <answer> siw_dbg_cep(cep, 
<token> out; <answer> goto 
siw_dbg_cep(cep, "immediate close, state %d\n", <token> <answer> cep->state); 
if <token> { <answer> (cep->cm_id) 
<token> (cep->state) { <answer> switch 
<token> SIW_EPSTATE_AWAIT_MPAREP: <answer> case 
<token> IW_CM_EVENT_CONNECT_REPLY, <answer> siw_cm_upcall(cep, 
<token> SIW_EPSTATE_RDMA_MODE: <answer> case 
<token> IW_CM_EVENT_CLOSE, 0); <answer> siw_cm_upcall(cep, 
<token> SIW_EPSTATE_IDLE: <answer> case 
case <token> <answer> SIW_EPSTATE_LISTENING: 
<token> SIW_EPSTATE_CONNECTING: <answer> case 
<token> SIW_EPSTATE_AWAIT_MPAREQ: <answer> case 
case <token> <answer> SIW_EPSTATE_RECVD_MPAREQ: 
case <token> <answer> SIW_EPSTATE_CLOSED: 
cep->state <token> SIW_EPSTATE_CLOSED; <answer> = 
if <token> { <answer> (cep->qp) 
<token> = NULL; <answer> cep->qp 
<token> siw_cep_put(struct siw_cep *cep) <answer> void 
WARN_ON(kref_read(&cep->ref) < <token> <answer> 1); 
<token> __siw_cep_dealloc); <answer> kref_put(&cep->ref, 
<token> void siw_cep_set_free_and_put(struct siw_cep *cep) <answer> static 
<token> siw_cep_get(struct siw_cep *cep) <answer> void 
static int siw_send_mpareqrep(struct siw_cep *cep, const void <token> u8 pd_len) <answer> *pdata, 
struct socket *s = <token> <answer> cep->sock; 
struct <token> *rr = &cep->mpa.hdr; <answer> mpa_rr 
<token> kvec iov[3]; <answer> struct 
<token> msghdr msg; <answer> struct 
<token> rv; <answer> int 
int iovec_num = <token> <answer> 0; 
<token> mpa_len; <answer> int 
memset(&msg, <token> sizeof(msg)); <answer> 0, 
iov[iovec_num].iov_base <token> rr; <answer> = 
iov[iovec_num].iov_len <token> sizeof(*rr); <answer> = 
mpa_len <token> sizeof(*rr); <answer> = 
if (cep->enhanced_rdma_conn_est) <token> <answer> { 
iov[iovec_num].iov_base = <token> <answer> &cep->mpa.v2_ctrl; 
<token> = sizeof(cep->mpa.v2_ctrl); <answer> iov[iovec_num].iov_len 
mpa_len <token> sizeof(cep->mpa.v2_ctrl); <answer> += 
<token> (pd_len) { <answer> if 
iov[iovec_num].iov_base = (char <token> <answer> *)pdata; 
iov[iovec_num].iov_len = <token> <answer> pd_len; 
mpa_len += <token> <answer> pd_len; 
if <token> <answer> (cep->enhanced_rdma_conn_est) 
pd_len += <token> <answer> sizeof(cep->mpa.v2_ctrl); 
rr->params.pd_len = <token> <answer> cpu_to_be16(pd_len); 
<token> = kernel_sendmsg(s, &msg, iov, iovec_num + 1, mpa_len); <answer> rv 
return rv < 0 <token> rv : 0; <answer> ? 
<token> int siw_recv_mpa_rr(struct siw_cep *cep) <answer> static 
struct mpa_rr *hdr = <token> <answer> &cep->mpa.hdr; 
struct socket <token> = cep->sock; <answer> *s 
<token> pd_len; <answer> u16 
int <token> to_rcv; <answer> rcvd, 
if (cep->mpa.bytes_rcvd <token> sizeof(struct mpa_rr)) { <answer> < 
rcvd = ksock_recv(s, (char <token> + cep->mpa.bytes_rcvd, <answer> *)hdr 
sizeof(struct mpa_rr) <token> cep->mpa.bytes_rcvd, <answer> - 
if <token> <= 0) <answer> (rcvd 
<token> -ECONNABORTED; <answer> return 
<token> += rcvd; <answer> cep->mpa.bytes_rcvd 
if (cep->mpa.bytes_rcvd < sizeof(struct <token> <answer> mpa_rr)) 
return <token> <answer> -EAGAIN; 
if <token> > MPA_MAX_PRIVDATA) <answer> (be16_to_cpu(hdr->params.pd_len) 
<token> -EPROTO; <answer> return 
<token> = be16_to_cpu(hdr->params.pd_len); <answer> pd_len 
to_rcv = pd_len <token> (cep->mpa.bytes_rcvd - sizeof(struct mpa_rr)); <answer> - 
<token> (!to_rcv) { <answer> if 
u32 <token> <answer> word; 
rcvd = ksock_recv(s, (char <token> sizeof(word), MSG_DONTWAIT); <answer> *)&word, 
if (rcvd == <token> <answer> -EAGAIN) 
return <token> <answer> 0; 
<token> (rcvd == 0) { <answer> if 
<token> "peer EOF\n"); <answer> siw_dbg_cep(cep, 
return <token> <answer> -EPIPE; 
if (rcvd < 0) <token> <answer> { 
siw_dbg_cep(cep, <token> %d\n", rcvd); <answer> "error: 
return <token> <answer> rcvd; 
siw_dbg_cep(cep, "peer <token> extra data: %d\n", rcvd); <answer> sent 
<token> -EPROTO; <answer> return 
<token> (!cep->mpa.pdata) { <answer> if 
cep->mpa.pdata = <token> + 4, GFP_KERNEL); <answer> kmalloc(pd_len 
<token> (!cep->mpa.pdata) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = ksock_recv( <answer> rcvd 
s, cep->mpa.pdata + cep->mpa.bytes_rcvd - sizeof(struct <token> <answer> mpa_rr), 
to_rcv <token> 4, MSG_DONTWAIT); <answer> + 
if (rcvd <token> 0) <answer> < 
<token> rcvd; <answer> return 
if <token> > to_rcv) <answer> (rcvd 
<token> -EPROTO; <answer> return 
cep->mpa.bytes_rcvd <token> rcvd; <answer> += 
if (to_rcv == <token> { <answer> rcvd) 
siw_dbg_cep(cep, "%d <token> private data received\n", pd_len); <answer> bytes 
return <token> <answer> 0; 
<token> -EAGAIN; <answer> return 
static int siw_proc_mpareq(struct siw_cep <token> <answer> *cep) 
struct mpa_rr <token> <answer> *req; 
int <token> rv; <answer> version, 
<token> pd_len; <answer> u16 
<token> = siw_recv_mpa_rr(cep); <answer> rv 
<token> (rv) <answer> if 
<token> rv; <answer> return 
req <token> &cep->mpa.hdr; <answer> = 
version = <token> <answer> __mpa_rr_revision(req->params.bits); 
pd_len <token> be16_to_cpu(req->params.pd_len); <answer> = 
<token> (version > MPA_REVISION_2) <answer> if 
if <token> < sizeof(struct mpa_v2_data)) <answer> (pd_len 
<token> reject_conn; <answer> goto 
<token> = true; <answer> cep->enhanced_rdma_conn_est 
if <token> && mpa_crc_strict) <answer> (!mpa_crc_required 
<token> reject_conn; <answer> goto 
cep->ord = <token> & MPA_IRD_ORD_MASK; <answer> ntohs(v2->ird) 
cep->ord = min(cep->ord, <token> <answer> SIW_MAX_ORD_QP); 
cep->ird <token> ntohs(v2->ord) & MPA_IRD_ORD_MASK; <answer> = 
cep->ird = min(cep->ird, <token> <answer> SIW_MAX_IRD_QP); 
<token> (v2->ird & MPA_V2_PEER_TO_PEER) { <answer> if 
cep->mpa.v2_ctrl.ird <token> MPA_V2_PEER_TO_PEER; <answer> |= 
<token> (v2->ord & MPA_V2_RDMA_WRITE_RTR) <answer> if 
cep->mpa.v2_ctrl.ord <token> MPA_V2_RDMA_WRITE_RTR; <answer> |= 
else <token> (v2->ord & MPA_V2_RDMA_READ_RTR) <answer> if 
<token> |= MPA_V2_RDMA_READ_RTR; <answer> cep->mpa.v2_ctrl.ord 
<token> |= MPA_V2_RDMA_WRITE_RTR; <answer> cep->mpa.v2_ctrl.ord 
<token> = SIW_EPSTATE_RECVD_MPAREQ; <answer> cep->state 
siw_dbg_cep(cep, "mpa reply error: <token> %d, enhcd %d\n", <answer> vers 
rep->params.bits & MPA_RR_FLAG_ENHANCED <token> <answer> ? 
<token> : <answer> 1 
siw_cm_upcall(cep, <token> <answer> IW_CM_EVENT_CONNECT_REPLY, 
return <token> <answer> -EINVAL; 
<token> = (struct mpa_v2_data *)cep->mpa.pdata; <answer> v2 
rep_ird = ntohs(v2->ird) & <token> <answer> MPA_IRD_ORD_MASK; 
rep_ord <token> ntohs(v2->ord) & MPA_IRD_ORD_MASK; <answer> = 
if (cep->ird <token> rep_ord && <answer> < 
(relaxed_ird_negotiation <token> false || <answer> == 
rep_ord > <token> { <answer> cep->sdev->attrs.max_ird)) 
<token> "ird %d, rep_ord %d, max_ord %d\n", <answer> siw_dbg_cep(cep, 
<token> rep_ord, <answer> cep->ird, 
ird_insufficient = <token> <answer> true; 
if (cep->ord <token> rep_ird && relaxed_ird_negotiation == false) { <answer> > 
siw_dbg_cep(cep, "ord %d, rep_ird %d\n", <token> <answer> cep->ord, 
ird_insufficient <token> true; <answer> = 
cep->ird <token> rep_ord; <answer> = 
<token> = rep_ird; <answer> cep->ord 
if <token> { <answer> (ird_insufficient) 
<token> TERM_ERROR_LAYER_LLP, <answer> siw_init_terminate(qp, 
<token> 0); <answer> LLP_ECODE_INSUFFICIENT_IRD, 
rv = <token> <answer> -ENOMEM; 
<token> out_err; <answer> goto 
if (cep->mpa.v2_ctrl_req.ird & <token> <answer> MPA_V2_PEER_TO_PEER) 
mpa_p2p_mode <token> <answer> = 
cep->mpa.v2_ctrl_req.ord <token> <answer> & 
(MPA_V2_RDMA_WRITE_RTR <token> MPA_V2_RDMA_READ_RTR); <answer> | 
if (mpa_p2p_mode != <token> { <answer> MPA_V2_RDMA_NO_RTR) 
if ((mpa_p2p_mode <token> v2->ord) == 0) { <answer> & 
"rtr mode: <token> %2x, got %2x\n", <answer> req 
v2->ord & (MPA_V2_RDMA_WRITE_RTR <token> <answer> | 
<token> TERM_ERROR_LAYER_LLP, <answer> siw_init_terminate(qp, 
rv <token> -EPROTO; <answer> = 
<token> out_err; <answer> goto 
mpa_p2p_mode <token> v2->ord & (MPA_V2_RDMA_WRITE_RTR | <answer> = 
memset(&qp_attrs, <token> sizeof(qp_attrs)); <answer> 0, 
if (rep->params.bits <token> MPA_RR_FLAG_CRC) <answer> & 
<token> = SIW_MPA_CRC; <answer> qp_attrs.flags 
<token> = cep->ird; <answer> qp_attrs.irq_size 
qp_attrs.orq_size <token> cep->ord; <answer> = 
qp_attrs.sk <token> cep->sock; <answer> = 
qp_attrs.state = <token> <answer> SIW_QP_STATE_RTS; 
qp_attr_mask <token> SIW_QP_ATTR_STATE | SIW_QP_ATTR_LLP_HANDLE | <answer> = 
SIW_QP_ATTR_ORD | SIW_QP_ATTR_IRD <token> SIW_QP_ATTR_MPA; <answer> | 
<token> void siw_accept_newconn(struct siw_cep *cep) <answer> static 
struct <token> *s = cep->sock; <answer> socket 
struct <token> *new_s = NULL; <answer> socket 
<token> siw_cep *new_cep = NULL; <answer> struct 
if (siw_cm_alloc_work(new_cep, 4) != <token> <answer> 0) 
goto <token> <answer> error; 
new_cep->sk_state_change <token> cep->sk_state_change; <answer> = 
<token> = cep->sk_data_ready; <answer> new_cep->sk_data_ready 
new_cep->sk_write_space <token> cep->sk_write_space; <answer> = 
new_cep->sk_error_report = <token> <answer> cep->sk_error_report; 
<token> = kernel_accept(s, &new_s, O_NONBLOCK); <answer> rv 
if (rv != 0) <token> <answer> { 
<token> "kernel_accept() error: %d\n", rv); <answer> siw_dbg_cep(cep, 
goto <token> <answer> error; 
new_cep->sock = <token> <answer> new_s; 
new_s->sk->sk_user_data <token> new_cep; <answer> = 
if (siw_tcp_nagle == <token> <answer> false) 
new_cep->state = <token> <answer> SIW_EPSTATE_AWAIT_MPAREQ; 
rv = siw_cm_queue_work(new_cep, <token> <answer> SIW_CM_WORK_MPATIMEOUT); 
<token> (rv) <answer> if 
goto <token> <answer> error; 
<token> = cep; <answer> new_cep->listen_cep 
if (atomic_read(&new_s->sk->sk_rmem_alloc)) <token> <answer> { 
siw_dbg_cep(cep, <token> mpa request\n"); <answer> "immediate 
rv = <token> <answer> siw_proc_mpareq(new_cep); 
<token> (rv != -EAGAIN) { <answer> if 
new_cep->listen_cep <token> NULL; <answer> = 
<token> (rv) { <answer> if 
<token> error; <answer> goto 
<token> (new_cep) <answer> if 
if <token> { <answer> (new_s) 
new_cep->sock = <token> <answer> NULL; 
siw_dbg_cep(cep, <token> %d\n", rv); <answer> "error 
static void <token> work_struct *w) <answer> siw_cm_work_handler(struct 
struct <token> *work; <answer> siw_cm_work 
<token> siw_cep *cep; <answer> struct 
int release_cep = <token> rv = 0; <answer> 0, 
<token> = container_of(w, struct siw_cm_work, work.work); <answer> work 
<token> = work->cep; <answer> cep 
siw_dbg_cep(cep, "[QP %u]: work <token> %d, state %d\n", <answer> type: 
cep->qp ? qp_id(cep->qp) : <token> <answer> UINT_MAX, 
<token> cep->state); <answer> work->type, 
switch (work->type) <token> <answer> { 
<token> SIW_CM_WORK_ACCEPT: <answer> case 
<token> SIW_CM_WORK_READ_MPAHDR: <answer> case 
if (cep->state == <token> { <answer> SIW_EPSTATE_AWAIT_MPAREQ) 
if (cep->listen_cep) <token> <answer> { 
<token> (cep->listen_cep->state == <answer> if 
<token> = siw_proc_mpareq(cep); <answer> rv 
<token> = -EFAULT; <answer> rv 
if (rv != <token> { <answer> -EAGAIN) 
cep->listen_cep <token> NULL; <answer> = 
<token> (rv) <answer> if 
<token> else if (cep->state == SIW_EPSTATE_AWAIT_MPAREP) { <answer> } 
rv = <token> <answer> siw_proc_mpareply(cep); 
} else <token> <answer> { 
<token> (cep->state == SIW_EPSTATE_RDMA_MODE) { <answer> if 
siw_dbg_cep(cep, "already in <token> mode"); <answer> RDMA 
} else <token> <answer> { 
<token> "out of state: %d\n", <answer> siw_dbg_cep(cep, 
<token> (rv && rv != -EAGAIN) <answer> if 
release_cep <token> 1; <answer> = 
<token> SIW_CM_WORK_CLOSE_LLP: <answer> case 
if <token> <answer> (cep->qp) 
<token> (cep->cm_id) <answer> if 
siw_cm_upcall(cep, <token> 0); <answer> IW_CM_EVENT_CLOSE, 
<token> = 1; <answer> release_cep 
<token> SIW_CM_WORK_PEER_CLOSE: <answer> case 
<token> (cep->cm_id) { <answer> if 
if (cep->state <token> SIW_EPSTATE_AWAIT_MPAREP) { <answer> == 
siw_cm_upcall(cep, <token> <answer> IW_CM_EVENT_CONNECT_REPLY, 
} else if <token> == SIW_EPSTATE_RDMA_MODE) { <answer> (cep->state 
siw_cm_upcall(cep, <token> 0); <answer> IW_CM_EVENT_DISCONNECT, 
siw_cm_upcall(cep, <token> 0); <answer> IW_CM_EVENT_CLOSE, 
} <token> { <answer> else 
if (cep->state == SIW_EPSTATE_RECVD_MPAREQ) <token> <answer> { 
"mpa req recvd, wait <token> ULP\n"); <answer> for 
} else if (cep->state <token> SIW_EPSTATE_AWAIT_MPAREQ) { <answer> == 
if <token> { <answer> (cep->listen_cep) 
"no mpareq: <token> listener\n"); <answer> drop 
cep->listen_cep <token> NULL; <answer> = 
release_cep <token> 1; <answer> = 
<token> SIW_CM_WORK_MPATIMEOUT: <answer> case 
cep->mpa_timer = <token> <answer> NULL; 
if (cep->state <token> SIW_EPSTATE_AWAIT_MPAREP) { <answer> == 
<token> = 0; <answer> cep->mpa.hdr.params.pd_len 
<token> (cep->cm_id) <answer> if 
<token> IW_CM_EVENT_CONNECT_REPLY, <answer> siw_cm_upcall(cep, 
release_cep = <token> <answer> 1; 
} else if (cep->state <token> SIW_EPSTATE_AWAIT_MPAREQ) { <answer> == 
if (cep->listen_cep) <token> <answer> { 
cep->listen_cep = <token> <answer> NULL; 
release_cep = <token> <answer> 1; 
WARN(1, "Undefined CM <token> type: %d\n", work->type); <answer> work 
if <token> { <answer> (release_cep) 
<token> timer=%s, QP[%u]\n", <answer> "release: 
cep->mpa_timer ? "y" : <token> <answer> "n", 
cep->qp ? qp_id(cep->qp) <token> UINT_MAX); <answer> : 
cep->state <token> SIW_EPSTATE_CLOSED; <answer> = 
if <token> { <answer> (cep->qp) 
struct siw_qp *qp = <token> <answer> cep->qp; 
cep->qp <token> NULL; <answer> = 
<token> (cep->sock) { <answer> if 
cep->sock = <token> <answer> NULL; 
if <token> { <answer> (cep->cm_id) 
static struct <token> *siw_cm_wq; <answer> workqueue_struct 
int siw_cm_queue_work(struct siw_cep *cep, <token> siw_work_type type) <answer> enum 
<token> siw_cm_work *work = siw_get_work(cep); <answer> struct 
unsigned long delay <token> 0; <answer> = 
if <token> { <answer> (!work) 
<token> "failed with no work available\n"); <answer> siw_dbg_cep(cep, 
<token> -ENOMEM; <answer> return 
work->type <token> type; <answer> = 
work->cep <token> cep; <answer> = 
<token> siw_cm_work_handler); <answer> INIT_DELAYED_WORK(&work->work, 
if <token> == SIW_CM_WORK_MPATIMEOUT) { <answer> (type 
<token> = work; <answer> cep->mpa_timer 
if <token> == SIW_EPSTATE_AWAIT_MPAREP) <answer> (cep->state 
<token> = MPAREQ_TIMEOUT; <answer> delay 
delay <token> MPAREP_TIMEOUT; <answer> = 
siw_dbg_cep(cep, "[QP %u]: <token> type: %d, timeout %lu\n", <answer> work 
cep->qp ? qp_id(cep->qp) : -1, <token> delay); <answer> type, 
<token> &work->work, delay); <answer> queue_delayed_work(siw_cm_wq, 
<token> 0; <answer> return 
static void siw_cm_llp_data_ready(struct sock <token> <answer> *sk) 
<token> siw_cep *cep; <answer> struct 
<token> = sk_to_cep(sk); <answer> cep 
if <token> <answer> (!cep) 
<token> out; <answer> goto 
siw_dbg_cep(cep, "cep state: %d, <token> state %d\n", <answer> socket 
<token> sk->sk_state); <answer> cep->state, 
if <token> != TCP_ESTABLISHED) <answer> (sk->sk_state 
<token> out; <answer> goto 
switch <token> { <answer> (cep->state) 
<token> SIW_EPSTATE_RDMA_MODE: <answer> case 
case <token> <answer> SIW_EPSTATE_LISTENING: 
<token> SIW_EPSTATE_AWAIT_MPAREQ: <answer> case 
case <token> <answer> SIW_EPSTATE_AWAIT_MPAREP: 
<token> SIW_CM_WORK_READ_MPAHDR); <answer> siw_cm_queue_work(cep, 
siw_dbg_cep(cep, "unexpected <token> state %d\n", cep->state); <answer> data, 
static void <token> sock *sk) <answer> siw_cm_llp_write_space(struct 
struct siw_cep *cep <token> sk_to_cep(sk); <answer> = 
<token> (cep) <answer> if 
<token> "state: %d\n", cep->state); <answer> siw_dbg_cep(cep, 
<token> void siw_cm_llp_error_report(struct sock *sk) <answer> static 
<token> siw_cep *cep = sk_to_cep(sk); <answer> struct 
if <token> { <answer> (cep) 
siw_dbg_cep(cep, "error %d, socket state: %d, <token> state: %d\n", <answer> cep 
sk->sk_err, <token> cep->state); <answer> sk->sk_state, 
<token> void siw_cm_llp_state_change(struct sock *sk) <answer> static 
<token> siw_cep *cep; <answer> struct 
<token> (*orig_state_change)(struct sock *s); <answer> void 
<token> = sk_to_cep(sk); <answer> cep 
<token> (!cep) { <answer> if 
<token> SIW_CM_WORK_ACCEPT); <answer> siw_cm_queue_work(cep, 
<token> TCP_CLOSE: <answer> case 
case <token> <answer> TCP_CLOSE_WAIT: 
<token> (cep->qp) <answer> if 
cep->qp->tx_ctx.tx_suspend = <token> <answer> 1; 
<token> SIW_CM_WORK_PEER_CLOSE); <answer> siw_cm_queue_work(cep, 
<token> "unexpected socket state %d\n", sk->sk_state); <answer> siw_dbg_cep(cep, 
static int kernel_bindconnect(struct socket *s, struct <token> *laddr, <answer> sockaddr 
struct <token> *raddr, bool afonly) <answer> sockaddr 
<token> rv, flags = 0; <answer> int 
size_t <token> = laddr->sa_family == AF_INET ? <answer> size 
sizeof(struct <token> : sizeof(struct sockaddr_in6); <answer> sockaddr_in) 
if (afonly) <token> <answer> { 
rv <token> ip6_sock_set_v6only(s->sk); <answer> = 
<token> (rv) <answer> if 
return <token> <answer> rv; 
rv = s->ops->bind(s, <token> size); <answer> laddr, 
<token> (rv < 0) <answer> if 
return <token> <answer> rv; 
rv = s->ops->connect(s, <token> size, flags); <answer> raddr, 
<token> rv < 0 ? rv : 0; <answer> return 
int siw_connect(struct iw_cm_id <token> struct iw_cm_conn_param *params) <answer> *id, 
struct siw_device *sdev = <token> <answer> to_siw_dev(id->device); 
struct siw_qp <token> <answer> *qp; 
struct siw_cep *cep <token> NULL; <answer> = 
struct socket <token> = NULL; <answer> *s 
struct sockaddr *laddr <token> (struct sockaddr *)&id->local_addr, <answer> = 
<token> = (struct sockaddr *)&id->remote_addr; <answer> *raddr 
bool p2p_mode = peer_to_peer, <token> = true; <answer> v4 
<token> pd_len = params->private_data_len; <answer> u16 
<token> version = mpa_version, rv; <answer> int 
if <token> > MPA_MAX_PRIVDATA) <answer> (pd_len 
<token> -EINVAL; <answer> return 
if <token> > sdev->attrs.max_ird || <answer> (params->ird 
params->ord <token> sdev->attrs.max_ord) <answer> > 
<token> -ENOMEM; <answer> return 
if <token> == AF_INET6) <answer> (laddr->sa_family 
<token> = false; <answer> v4 
else if <token> != AF_INET) <answer> (laddr->sa_family 
<token> -EAFNOSUPPORT; <answer> return 
if ((v4 <token> to_sockaddr_in(id->remote_addr).sin_port != 0) || <answer> && 
to_sockaddr_in6(id->remote_addr).sin6_port <token> 0) <answer> != 
raddr <token> (struct sockaddr *)&id->m_remote_addr; <answer> = 
qp = <token> params->qpn); <answer> siw_qp_id2obj(sdev, 
if <token> { <answer> (!qp) 
WARN(1, "[QP <token> does not exist\n", params->qpn); <answer> %u] 
<token> = -EINVAL; <answer> rv 
<token> error; <answer> goto 
siw_dbg_qp(qp, "pd_len %d, laddr %pISp, raddr %pISp\n", <token> laddr, <answer> pd_len, 
rv = sock_create(v4 ? AF_INET : AF_INET6, SOCK_STREAM, <token> &s); <answer> IPPROTO_TCP, 
if (rv <token> 0) <answer> < 
<token> error; <answer> goto 
rv = kernel_bindconnect(s, laddr, raddr, <token> <answer> id->afonly); 
<token> (rv != 0) { <answer> if 
siw_dbg_qp(qp, <token> error %d\n", rv); <answer> "kernel_bindconnect: 
<token> error; <answer> goto 
<token> (siw_tcp_nagle == false) <answer> if 
cep <token> siw_cep_alloc(sdev); <answer> = 
if (!cep) <token> <answer> { 
rv = <token> <answer> -ENOMEM; 
<token> error; <answer> goto 
rv = siw_cm_alloc_work(cep, <token> <answer> 4); 
<token> (rv != 0) { <answer> if 
rv = <token> <answer> -ENOMEM; 
<token> error; <answer> goto 
<token> = params->ird; <answer> cep->ird 
<token> = params->ord; <answer> cep->ord 
if (p2p_mode && cep->ord == <token> <answer> 0) 
cep->ord = <token> <answer> 1; 
<token> = SIW_EPSTATE_CONNECTING; <answer> cep->state 
siw_cep_socket_assoc(cep, <token> <answer> s); 
cep->state = <token> <answer> SIW_EPSTATE_AWAIT_MPAREP; 
cep->mpa.hdr.params.bits = <token> <answer> 0; 
if (version > MPA_REVISION_2) <token> <answer> { 
pr_warn("Setting MPA version to %u\n", <token> <answer> MPA_REVISION_2); 
version <token> MPA_REVISION_2; <answer> = 
if <token> == MPA_REVISION_2) { <answer> (version 
<token> = true; <answer> cep->enhanced_rdma_conn_est 
cep->mpa.hdr.params.bits |= <token> <answer> MPA_RR_FLAG_ENHANCED; 
cep->mpa.v2_ctrl.ird <token> htons(cep->ird); <answer> = 
cep->mpa.v2_ctrl.ord <token> htons(cep->ord); <answer> = 
if <token> { <answer> (p2p_mode) 
<token> |= MPA_V2_PEER_TO_PEER; <answer> cep->mpa.v2_ctrl.ird 
cep->mpa.v2_ctrl.ord |= <token> <answer> rtr_type; 
<token> = 0; <answer> cep->mpa.hdr.params.pd_len 
<token> (rv >= 0) { <answer> if 
rv = <token> SIW_CM_WORK_MPATIMEOUT); <answer> siw_cm_queue_work(cep, 
if <token> { <answer> (!rv) 
siw_dbg_cep(cep, "[QP %u]: exit\n", <token> <answer> qp_id(qp)); 
<token> 0; <answer> return 
siw_dbg(id->device, <token> %d\n", rv); <answer> "failed: 
if <token> { <answer> (cep) 
<token> = NULL; <answer> cep->sock 
<token> = NULL; <answer> cep->qp 
<token> = NULL; <answer> cep->cm_id 
qp->cep = <token> <answer> NULL; 
cep->state <token> SIW_EPSTATE_CLOSED; <answer> = 
} else if <token> { <answer> (s) 
<token> (qp) <answer> if 
return <token> <answer> rv; 
int siw_accept(struct iw_cm_id <token> struct iw_cm_conn_param *params) <answer> *id, 
<token> siw_device *sdev = to_siw_dev(id->device); <answer> struct 
<token> siw_cep *cep = (struct siw_cep *)id->provider_data; <answer> struct 
<token> siw_qp *qp; <answer> struct 
struct <token> qp_attrs; <answer> siw_qp_attrs 
int <token> = -EINVAL, max_priv_data = MPA_MAX_PRIVDATA; <answer> rv 
bool wait_for_peer_rts = <token> <answer> false; 
cep->mpa.v2_ctrl.ord <token> <answer> = 
<token> & MPA_IRD_ORD_MASK) | <answer> htons(params->ord 
(cep->mpa.v2_ctrl.ord <token> ~MPA_V2_MASK_IRD_ORD); <answer> & 
cep->mpa.v2_ctrl.ird <token> <answer> = 
htons(params->ird <token> MPA_IRD_ORD_MASK) | <answer> & 
(cep->mpa.v2_ctrl.ird & <token> <answer> ~MPA_V2_MASK_IRD_ORD); 
cep->ird <token> params->ird; <answer> = 
cep->ord = <token> <answer> params->ord; 
cep->cm_id <token> id; <answer> = 
memset(&qp_attrs, <token> sizeof(qp_attrs)); <answer> 0, 
qp_attrs.orq_size = <token> <answer> cep->ord; 
qp_attrs.irq_size <token> cep->ird; <answer> = 
<token> = cep->sock; <answer> qp_attrs.sk 
if <token> & MPA_RR_FLAG_CRC) <answer> (cep->mpa.hdr.params.bits 
<token> = SIW_MPA_CRC; <answer> qp_attrs.flags 
qp_attrs.state <token> SIW_QP_STATE_RTS; <answer> = 
siw_dbg_cep(cep, "[QP%u]: moving to rts\n", <token> <answer> qp_id(qp)); 
int siw_reject(struct iw_cm_id *id, const void *pdata, <token> pd_len) <answer> u8 
<token> siw_cep *cep = (struct siw_cep *)id->provider_data; <answer> struct 
if (cep->state != SIW_EPSTATE_RECVD_MPAREQ) <token> <answer> { 
siw_dbg_cep(cep, "out of <token> <answer> state\n"); 
int siw_create_listen(struct iw_cm_id *id, int <token> <answer> backlog) 
struct <token> *s; <answer> socket 
struct siw_cep <token> = NULL; <answer> *cep 
struct siw_device *sdev = <token> <answer> to_siw_dev(id->device); 
int <token> = id->local_addr.ss_family; <answer> addr_family 
int <token> = 0; <answer> rv 
if (addr_family <token> AF_INET && addr_family != AF_INET6) <answer> != 
return <token> <answer> -EAFNOSUPPORT; 
<token> = sock_create(addr_family, SOCK_STREAM, IPPROTO_TCP, &s); <answer> rv 
if <token> < 0) <answer> (rv 
return <token> <answer> rv; 
if (addr_family == AF_INET) <token> <answer> { 
struct <token> *laddr = &to_sockaddr_in(id->local_addr); <answer> sockaddr_in 
if (!id->provider_data) <token> <answer> { 
id->provider_data <token> <answer> = 
<token> list_head), GFP_KERNEL); <answer> kmalloc(sizeof(struct 
<token> (!id->provider_data) { <answer> if 
rv <token> -ENOMEM; <answer> = 
goto <token> <answer> error; 
<token> list_head *)id->provider_data); <answer> INIT_LIST_HEAD((struct 
list_add_tail(&cep->listenq, (struct list_head <token> <answer> *)id->provider_data); 
<token> = SIW_EPSTATE_LISTENING; <answer> cep->state 
<token> "Listen at laddr %pISp\n", &id->local_addr); <answer> siw_dbg(id->device, 
<token> 0; <answer> return 
<token> "failed: %d\n", rv); <answer> siw_dbg(id->device, 
if <token> { <answer> (cep) 
<token> = NULL; <answer> cep->sock 
cep->state <token> SIW_EPSTATE_CLOSED; <answer> = 
<token> rv; <answer> return 
static void siw_drop_listeners(struct <token> *id) <answer> iw_cm_id 
<token> list_head *p, *tmp; <answer> struct 
list_for_each_safe(p, tmp, (struct <token> *)id->provider_data) { <answer> list_head 
struct siw_cep *cep <token> list_entry(p, struct siw_cep, listenq); <answer> = 
siw_dbg_cep(cep, "drop cep, state <token> cep->state); <answer> %d\n", 
<token> (cep->sock) { <answer> if 
<token> = NULL; <answer> cep->sock 
cep->state <token> SIW_EPSTATE_CLOSED; <answer> = 
int siw_destroy_listen(struct <token> *id) <answer> iw_cm_id 
if (!id->provider_data) <token> <answer> { 
<token> "no cep(s)\n"); <answer> siw_dbg(id->device, 
return <token> <answer> 0; 
id->provider_data = <token> <answer> NULL; 
return <token> <answer> 0; 
int <token> <answer> siw_cm_init(void) 
siw_cm_wq <token> create_singlethread_workqueue("siw_cm_wq"); <answer> = 
<token> (!siw_cm_wq) <answer> if 
return <token> <answer> -ENOMEM; 
return <token> <answer> 0; 
void <token> <answer> siw_cm_exit(void) 
if <token> <answer> (siw_cm_wq) 
<token> <linux/module.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
<token> <linux/gcd.h> <answer> #include 
<token> "rl6231.h" <answer> #include 
<token> rl6231_get_pre_div(struct regmap *map, unsigned int reg, int sft) <answer> int 
<token> pd, val; <answer> int 
regmap_read(map, <token> &val); <answer> reg, 
val = <token> >> sft) & 0x7; <answer> (val 
<token> (val) { <answer> switch 
<token> 0: <answer> case 
case <token> <answer> 1: 
<token> 2: <answer> case 
<token> 3: <answer> case 
pd <token> val + 1; <answer> = 
case <token> <answer> 4: 
pd <token> 6; <answer> = 
case <token> <answer> 5: 
<token> = 8; <answer> pd 
case <token> <answer> 6: 
pd <token> 12; <answer> = 
<token> 7: <answer> case 
pd = <token> <answer> 16; 
pd <token> -EINVAL; <answer> = 
<token> pd; <answer> return 
int <token> rate) <answer> rl6231_calc_dmic_clk(int 
static const int div[] = <token> 3, 4, 6, 8, 12}; <answer> {2, 
<token> i; <answer> int 
<token> (rate < 1000000 * div[0]) { <answer> if 
pr_warn("Base clock rate %d is too <token> rate); <answer> low\n", 
return <token> <answer> -EINVAL; 
for <token> = 0; i < ARRAY_SIZE(div); i++) { <answer> (i 
<token> ((div[i] % 3) == 0) <answer> if 
int <token> unsigned int freq_in, <answer> rl6231_pll_calc(const 
const unsigned int freq_out, <token> rl6231_pll_code *pll_code) <answer> struct 
int max_n = RL6231_PLL_N_MAX, max_m = <token> <answer> RL6231_PLL_M_MAX; 
int i, <token> n_t; <answer> k, 
int k_t, min_k, <token> n = 0, m = 0, m_t = 0; <answer> max_k, 
<token> int red, pll_out, in_t, out_t, div, div_t; <answer> unsigned 
unsigned int <token> = abs(freq_out - freq_in); <answer> red_t 
unsigned int f_in, <token> f_max; <answer> f_out, 
bool m_bypass <token> false, k_bypass = false; <answer> = 
if (RL6231_PLL_INP_MAX < freq_in <token> RL6231_PLL_INP_MIN > freq_in) <answer> || 
<token> -EINVAL; <answer> return 
for (i = <token> i < ARRAY_SIZE(pll_preset_table); i++) { <answer> 0; 
<token> (freq_in == pll_preset_table[i].pll_in && <answer> if 
<token> == pll_preset_table[i].pll_out) { <answer> freq_out 
<token> = pll_preset_table[i].k; <answer> k 
<token> = pll_preset_table[i].m; <answer> m 
<token> = pll_preset_table[i].n; <answer> n 
<token> = pll_preset_table[i].m_bp; <answer> m_bypass 
k_bypass = <token> <answer> pll_preset_table[i].k_bp; 
pr_debug("Use preset PLL <token> table\n"); <answer> parameter 
goto <token> <answer> code_find; 
min_k <token> 80000000 / freq_out - 2; <answer> = 
max_k = <token> / freq_out - 2; <answer> 150000000 
<token> (max_k > RL6231_PLL_K_MAX) <answer> if 
max_k <token> RL6231_PLL_K_MAX; <answer> = 
if (min_k <token> RL6231_PLL_K_MAX) <answer> > 
min_k = <token> = RL6231_PLL_K_MAX; <answer> max_k 
<token> = gcd(freq_in, freq_out); <answer> div_t 
f_max = <token> / RL6231_PLL_N_MAX; <answer> 0xffffffff 
<token> = find_best_div(freq_in, f_max, div_t); <answer> div 
<token> = freq_in / div; <answer> f_in 
f_out <token> freq_out / div; <answer> = 
k = <token> <answer> min_k; 
if <token> < -1) <answer> (min_k 
min_k <token> -1; <answer> = 
for (k_t = min_k; <token> <= max_k; k_t++) { <answer> k_t 
for <token> = 0; n_t <= max_n; n_t++) { <answer> (n_t 
in_t = <token> * (n_t + 2); <answer> f_in 
pll_out = f_out * (k_t + <token> <answer> 2); 
if (in_t <token> pll_out) { <answer> == 
m_bypass <token> true; <answer> = 
n = <token> <answer> n_t; 
<token> = k_t; <answer> k 
<token> code_find; <answer> goto 
out_t = <token> / (k_t + 2); <answer> in_t 
red <token> abs(f_out - out_t); <answer> = 
<token> (red < red_t) { <answer> if 
m_bypass = <token> <answer> true; 
n <token> n_t; <answer> = 
m = <token> <answer> 0; 
k = <token> <answer> k_t; 
<token> (red == 0) <answer> if 
goto <token> <answer> code_find; 
<token> = red; <answer> red_t 
for (m_t = 0; m_t <= <token> m_t++) { <answer> max_m; 
out_t = <token> / ((m_t + 2) * (k_t + 2)); <answer> in_t 
red = abs(f_out <token> out_t); <answer> - 
if <token> < red_t) { <answer> (red 
<token> = false; <answer> m_bypass 
<token> = n_t; <answer> n 
<token> = m_t; <answer> m 
k <token> k_t; <answer> = 
if (red <token> 0) <answer> == 
goto <token> <answer> code_find; 
red_t = <token> <answer> red; 
<token> get approximation about PLL\n"); <answer> pr_debug("Only 
if (k == <token> { <answer> -1) 
k_bypass <token> true; <answer> = 
k <token> 0; <answer> = 
pll_code->m_bp <token> m_bypass; <answer> = 
pll_code->k_bp <token> k_bypass; <answer> = 
pll_code->m_code <token> m; <answer> = 
pll_code->n_code = <token> <answer> n; 
<token> = k; <answer> pll_code->k_code 
<token> 0; <answer> return 
int <token> sclk, int rate) <answer> rl6231_get_clk_info(int 
<token> i; <answer> int 
static const int pd[] = {1, 2, 3, 4, 6, 8, <token> 16}; <answer> 12, 
if (sclk <= 0 <token> rate <= 0) <answer> || 
<token> -EINVAL; <answer> return 
rate = rate <token> 8; <answer> << 
for (i = <token> i < ARRAY_SIZE(pd); i++) <answer> 0; 
if (sclk == <token> * pd[i]) <answer> rate 
return <token> <answer> i; 
return <token> <answer> -EINVAL; 
MODULE_DESCRIPTION("RL6231 class <token> shared support"); <answer> device 
MODULE_AUTHOR("Oder Chiou <token> <answer> <oder_chiou@realtek.com>"); 
MODULE_LICENSE("GPL <token> <answer> v2"); 
<token> <linux/crc32.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> "ubifs.h" <answer> #include 
static <token> is_empty(void *buf, int len) <answer> int 
uint8_t *p = <token> <answer> buf; 
int <token> <answer> i; 
for <token> = 0; i < len; i++) <answer> (i 
<token> (*p++ != 0xff) <answer> if 
return <token> <answer> 0; 
<token> 1; <answer> return 
static int first_non_ff(void *buf, <token> len) <answer> int 
uint8_t *p <token> buf; <answer> = 
int <token> <answer> i; 
for (i = 0; i < <token> i++) <answer> len; 
if <token> != 0xff) <answer> (*p++ 
<token> i; <answer> return 
<token> -1; <answer> return 
static int <token> struct ubifs_info *c, int lnum, void **pbuf, <answer> get_master_node(const 
<token> ubifs_mst_node **mst, void **cor) <answer> struct 
const int sz = <token> <answer> c->mst_node_alsz; 
int <token> offs, len; <answer> err, 
void <token> *buf; <answer> *sbuf, 
sbuf = <token> <answer> vmalloc(c->leb_size); 
<token> (!sbuf) <answer> if 
<token> -ENOMEM; <answer> return 
err = ubifs_leb_read(c, <token> sbuf, 0, c->leb_size, 0); <answer> lnum, 
if <token> && err != -EBADMSG) <answer> (err 
goto <token> <answer> out_free; 
goto <token> <answer> out_err; 
if (ret <token> SCANNED_A_NODE) { <answer> == 
struct ubifs_ch *ch <token> buf; <answer> = 
if (ch->node_type != <token> <answer> UBIFS_MST_NODE) 
goto <token> <answer> out_err; 
dbg_rcvry("found a master node at %d:%d", <token> offs); <answer> lnum, 
*mst <token> buf; <answer> = 
offs <token> sz; <answer> += 
buf <token> sz; <answer> += 
<token> -= sz; <answer> len 
static int write_rcvrd_mst_node(struct <token> *c, <answer> ubifs_info 
struct ubifs_mst_node <token> <answer> *mst) 
<token> err = 0, lnum = UBIFS_MST_LNUM, sz = c->mst_node_alsz; <answer> int 
__le32 <token> <answer> save_flags; 
save_flags = <token> <answer> mst->flags; 
mst->flags <token> cpu_to_le32(UBIFS_MST_RCVRY); <answer> |= 
err <token> ubifs_prepare_node_hmac(c, mst, UBIFS_MST_NODE_SZ, <answer> = 
offsetof(struct ubifs_mst_node, <token> 1); <answer> hmac), 
if <token> <answer> (err) 
goto <token> <answer> out; 
err <token> ubifs_leb_change(c, lnum, mst, sz); <answer> = 
if <token> <answer> (err) 
<token> out; <answer> goto 
err <token> ubifs_leb_change(c, lnum + 1, mst, sz); <answer> = 
if <token> <answer> (err) 
goto <token> <answer> out; 
mst->flags = <token> <answer> save_flags; 
return <token> <answer> err; 
int ubifs_recover_master_node(struct <token> *c) <answer> ubifs_info 
void *buf1 = NULL, *buf2 <token> NULL, *cor1 = NULL, *cor2 = NULL; <answer> = 
struct ubifs_mst_node *mst1 = NULL, *mst2 = <token> *mst; <answer> NULL, 
const <token> sz = c->mst_node_alsz; <answer> int 
int <token> offs1, offs2; <answer> err, 
err <token> get_master_node(c, UBIFS_MST_LNUM, &buf1, &mst1, &cor1); <answer> = 
<token> (err) <answer> if 
goto <token> <answer> out_free; 
err <token> get_master_node(c, UBIFS_MST_LNUM + 1, &buf2, &mst2, &cor2); <answer> = 
if <token> <answer> (err) 
<token> out_free; <answer> goto 
if (mst1) <token> <answer> { 
offs1 = (void *)mst1 - <token> <answer> buf1; 
if ((le32_to_cpu(mst1->flags) & UBIFS_MST_RCVRY) <token> <answer> && 
<token> == 0 && !cor1)) { <answer> (offs1 
dbg_rcvry("recovery <token> <answer> recovery"); 
<token> = mst1; <answer> mst 
<token> else if (mst2) { <answer> } 
offs2 = (void *)mst2 <token> buf2; <answer> - 
if (offs1 <token> offs2) { <answer> == 
if (offs1 != <token> || cor1) <answer> 0 
goto <token> <answer> out_err; 
<token> = mst1; <answer> mst 
} else <token> <answer> { 
if <token> <answer> (!mst2) 
goto <token> <answer> out_err; 
offs2 = (void *)mst2 <token> buf2; <answer> - 
if (offs2 + sz + <token> <= c->leb_size) <answer> sz 
<token> out_err; <answer> goto 
mst <token> mst2; <answer> = 
ubifs_msg(c, "recovered <token> node from LEB %d", <answer> master 
(mst == <token> ? UBIFS_MST_LNUM : UBIFS_MST_LNUM + 1)); <answer> mst1 
<token> mst, UBIFS_MST_NODE_SZ); <answer> memcpy(c->mst_node, 
<token> (c->ro_mount) { <answer> if 
c->mst_node->flags |= <token> <answer> cpu_to_le32(UBIFS_MST_DIRTY); 
} else <token> <answer> { 
<token> ubifs_write_rcvrd_mst_node(struct ubifs_info *c) <answer> int 
int <token> <answer> err; 
if <token> <answer> (!c->rcvrd_mst_node) 
return <token> <answer> 0; 
<token> |= cpu_to_le32(UBIFS_MST_DIRTY); <answer> c->rcvrd_mst_node->flags 
c->mst_node->flags |= <token> <answer> cpu_to_le32(UBIFS_MST_DIRTY); 
err = write_rcvrd_mst_node(c, <token> <answer> c->rcvrd_mst_node); 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> = NULL; <answer> c->rcvrd_mst_node 
return <token> <answer> 0; 
static int is_last_write(const <token> ubifs_info *c, void *buf, int offs) <answer> struct 
int <token> check_len; <answer> empty_offs, 
uint8_t <token> <answer> *p; 
empty_offs <token> ALIGN(offs + 1, c->max_write_size); <answer> = 
check_len = c->leb_size - <token> <answer> empty_offs; 
p = buf <token> empty_offs - offs; <answer> + 
return is_empty(p, <token> <answer> check_len); 
static void clean_buf(const struct ubifs_info <token> void **buf, int lnum, <answer> *c, 
int *offs, int <token> <answer> *len) 
<token> empty_offs, pad_len; <answer> int 
dbg_rcvry("cleaning corruption <token> %d:%d", lnum, *offs); <answer> at 
<token> !(*offs & 7)); <answer> ubifs_assert(c, 
empty_offs = <token> c->min_io_size); <answer> ALIGN(*offs, 
pad_len = <token> - *offs; <answer> empty_offs 
ubifs_pad(c, *buf, <token> <answer> pad_len); 
*offs <token> pad_len; <answer> += 
<token> += pad_len; <answer> *buf 
*len <token> pad_len; <answer> -= 
memset(*buf, 0xff, <token> - empty_offs); <answer> c->leb_size 
static int no_more_nodes(const struct ubifs_info *c, <token> *buf, int len, <answer> void 
int <token> int offs) <answer> lnum, 
struct <token> *ch = buf; <answer> ubifs_ch 
int skip, dlen <token> le32_to_cpu(ch->len); <answer> = 
if (ubifs_check_node(c, <token> len, lnum, offs, 1, 0) != -EUCLEAN) { <answer> buf, 
dbg_rcvry("unexpected bad <token> header at %d:%d", lnum, offs); <answer> common 
<token> 0; <answer> return 
static int fix_unclean_leb(struct ubifs_info <token> struct ubifs_scan_leb *sleb, <answer> *c, 
<token> start) <answer> int 
int lnum <token> sleb->lnum, endpt = start; <answer> = 
static <token> drop_last_group(struct ubifs_scan_leb *sleb, int *offs) <answer> void 
<token> (!list_empty(&sleb->nodes)) { <answer> while 
struct <token> *snod; <answer> ubifs_scan_node 
struct ubifs_ch <token> <answer> *ch; 
snod <token> list_entry(sleb->nodes.prev, struct ubifs_scan_node, <answer> = 
<token> = snod->node; <answer> ch 
if <token> != UBIFS_IN_NODE_GROUP) <answer> (ch->group_type 
<token> grouped node at %d:%d", <answer> dbg_rcvry("dropping 
sleb->lnum, <token> <answer> snod->offs); 
*offs <token> snod->offs; <answer> = 
sleb->nodes_cnt -= <token> <answer> 1; 
static void <token> ubifs_scan_leb *sleb, int *offs) <answer> drop_last_node(struct 
<token> ubifs_scan_node *snod; <answer> struct 
if (!list_empty(&sleb->nodes)) <token> <answer> { 
snod = list_entry(sleb->nodes.prev, struct <token> <answer> ubifs_scan_node, 
dbg_rcvry("dropping last node <token> %d:%d", <answer> at 
sleb->lnum, <token> <answer> snod->offs); 
*offs = <token> <answer> snod->offs; 
<token> -= 1; <answer> sleb->nodes_cnt 
struct ubifs_scan_leb *ubifs_recover_leb(struct ubifs_info *c, <token> lnum, <answer> int 
int offs, <token> *sbuf, int jhead) <answer> void 
int ret = 0, err, len = c->leb_size - offs, <token> = offs, min_io_unit; <answer> start 
int grouped = jhead == -1 <token> 0 : c->jheads[jhead].grouped; <answer> ? 
struct ubifs_scan_leb <token> <answer> *sleb; 
<token> *buf = sbuf + offs; <answer> void 
dbg_rcvry("%d:%d, <token> %d, grouped %d", lnum, offs, jhead, grouped); <answer> jhead 
sleb <token> ubifs_start_scan(c, lnum, offs, sbuf); <answer> = 
if <token> <answer> (IS_ERR(sleb)) 
<token> sleb; <answer> return 
<token> len >= 8); <answer> ubifs_assert(c, 
while (len >= <token> { <answer> 8) 
dbg_scan("look <token> LEB %d:%d (%d bytes left)", <answer> at 
lnum, offs, <token> <answer> len); 
ret = ubifs_scan_a_node(c, buf, len, <token> offs, 1); <answer> lnum, 
<token> (ret == SCANNED_A_NODE) { <answer> if 
ubifs_err(c, "corrupt empty space LEB %d:%d, corruption starts at <token> <answer> %d", 
lnum, <token> corruption); <answer> offs, 
drop_last_group(sleb, <token> <answer> &offs); 
<token> (jhead == GCHD) { <answer> if 
while (offs > <token> <answer> min_io_unit) 
drop_last_node(sleb, <token> <answer> &offs); 
buf <token> sbuf + offs; <answer> = 
len = <token> - offs; <answer> c->leb_size 
clean_buf(c, &buf, lnum, <token> &len); <answer> &offs, 
ubifs_end_scan(c, sleb, <token> offs); <answer> lnum, 
err = fix_unclean_leb(c, <token> start); <answer> sleb, 
if <token> <answer> (err) 
goto <token> <answer> error; 
<token> sleb; <answer> return 
static <token> get_cs_sqnum(struct ubifs_info *c, int lnum, int offs, <answer> int 
unsigned <token> long *cs_sqnum) <answer> long 
<token> ubifs_cs_node *cs_node = NULL; <answer> struct 
int <token> ret; <answer> err, 
<token> %d:%d", lnum, offs); <answer> dbg_rcvry("at 
<token> = kmalloc(UBIFS_CS_NODE_SZ, GFP_KERNEL); <answer> cs_node 
if <token> <answer> (!cs_node) 
<token> -ENOMEM; <answer> return 
if (c->leb_size <token> offs < UBIFS_CS_NODE_SZ) <answer> - 
<token> out_err; <answer> goto 
err = ubifs_leb_read(c, <token> (void *)cs_node, offs, <answer> lnum, 
UBIFS_CS_NODE_SZ, <token> <answer> 0); 
if (err <token> err != -EBADMSG) <answer> && 
goto <token> <answer> out_free; 
ret = ubifs_scan_a_node(c, <token> UBIFS_CS_NODE_SZ, lnum, offs, 0); <answer> cs_node, 
if (ret != <token> { <answer> SCANNED_A_NODE) 
<token> "Not a valid node"); <answer> ubifs_err(c, 
goto <token> <answer> out_err; 
if (cs_node->ch.node_type != <token> { <answer> UBIFS_CS_NODE) 
ubifs_err(c, <token> a CS node, type is %d", cs_node->ch.node_type); <answer> "Not 
<token> out_err; <answer> goto 
if <token> != c->cmt_no) { <answer> (le64_to_cpu(cs_node->cmt_no) 
ubifs_err(c, "CS node <token> %llu != current cmt_no %llu", <answer> cmt_no 
<token> long long)le64_to_cpu(cs_node->cmt_no), <answer> (unsigned 
<token> out_err; <answer> goto 
*cs_sqnum <token> le64_to_cpu(cs_node->ch.sqnum); <answer> = 
dbg_rcvry("commit start sqnum <token> *cs_sqnum); <answer> %llu", 
return <token> <answer> 0; 
<token> = -EINVAL; <answer> err 
ubifs_err(c, "failed <token> get CS sqnum"); <answer> to 
return <token> <answer> err; 
struct ubifs_scan_leb <token> ubifs_info *c, int lnum, <answer> *ubifs_recover_log_leb(struct 
int <token> void *sbuf) <answer> offs, 
struct ubifs_scan_leb <token> <answer> *sleb; 
<token> next_lnum; <answer> int 
<token> %d", lnum); <answer> dbg_rcvry("LEB 
<token> = lnum + 1; <answer> next_lnum 
if (next_lnum <token> UBIFS_LOG_LNUM + c->log_lebs) <answer> >= 
<token> = UBIFS_LOG_LNUM; <answer> next_lnum 
if (next_lnum <token> c->ltail_lnum) { <answer> != 
sleb = <token> next_lnum, 0, sbuf, 0); <answer> ubifs_scan(c, 
<token> (IS_ERR(sleb)) <answer> if 
<token> sleb; <answer> return 
if <token> { <answer> (sleb->nodes_cnt) 
struct <token> *snod; <answer> ubifs_scan_node 
unsigned long long cs_sqnum = <token> <answer> c->cs_sqnum; 
snod = <token> <answer> list_entry(sleb->nodes.next, 
<token> ubifs_scan_node, list); <answer> struct 
<token> (cs_sqnum == 0) { <answer> if 
<token> err; <answer> int 
err = get_cs_sqnum(c, lnum, offs, <token> <answer> &cs_sqnum); 
<token> (err) { <answer> if 
<token> ERR_PTR(err); <answer> return 
if (snod->sqnum > cs_sqnum) <token> <answer> { 
ubifs_err(c, <token> log corruption in LEB %d", <answer> "unrecoverable 
return <token> <answer> ERR_PTR(-EUCLEAN); 
return ubifs_recover_leb(c, lnum, offs, sbuf, <token> <answer> -1); 
static int recover_head(struct ubifs_info *c, int lnum, int offs, void <token> <answer> *sbuf) 
int len = c->max_write_size, <token> <answer> err; 
if (offs + len > <token> <answer> c->leb_size) 
len = c->leb_size - <token> <answer> offs; 
if <token> <answer> (!len) 
return <token> <answer> 0; 
int ubifs_recover_inl_heads(struct ubifs_info <token> void *sbuf) <answer> *c, 
int <token> <answer> err; 
ubifs_assert(c, !c->ro_mount <token> c->remounting_rw); <answer> || 
dbg_rcvry("checking index head at <token> c->ihead_lnum, c->ihead_offs); <answer> %d:%d", 
err = recover_head(c, c->ihead_lnum, <token> sbuf); <answer> c->ihead_offs, 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> LPT head at %d:%d", c->nhead_lnum, c->nhead_offs); <answer> dbg_rcvry("checking 
return recover_head(c, <token> c->nhead_offs, sbuf); <answer> c->nhead_lnum, 
static int <token> ubifs_info *c, <answer> clean_an_unclean_leb(struct 
struct <token> *ucleb, void *sbuf) <answer> ubifs_unclean_leb 
int err, lnum = ucleb->lnum, offs = 0, len = <token> quiet = 1; <answer> ucleb->endpt, 
void *buf <token> sbuf; <answer> = 
<token> %d len %d", lnum, len); <answer> dbg_rcvry("LEB 
<token> (len == 0) { <answer> if 
int <token> ubifs_info *c, void *sbuf) <answer> ubifs_clean_lebs(struct 
while <token> { <answer> (!list_empty(&c->unclean_leb_list)) 
<token> ubifs_unclean_leb *ucleb; <answer> struct 
int <token> <answer> err; 
ucleb = <token> <answer> list_entry(c->unclean_leb_list.next, 
struct ubifs_unclean_leb, <token> <answer> list); 
err = <token> ucleb, sbuf); <answer> clean_an_unclean_leb(c, 
if <token> <answer> (err) 
<token> err; <answer> return 
return <token> <answer> 0; 
static int grab_empty_leb(struct <token> *c) <answer> ubifs_info 
<token> lnum, err; <answer> int 
<token> = ubifs_find_free_leb_for_idx(c); <answer> lnum 
if <token> < 0) { <answer> (lnum 
ubifs_err(c, "could <token> find an empty LEB"); <answer> not 
ubifs_dump_budg(c, <token> <answer> &c->bi); 
return <token> <answer> lnum; 
<token> ubifs_rcvry_gc_commit(struct ubifs_info *c) <answer> int 
struct ubifs_wbuf *wbuf <token> &c->jheads[GCHD].wbuf; <answer> = 
struct ubifs_lprops <token> <answer> lp; 
int <token> <answer> err; 
dbg_rcvry("GC head LEB %d, <token> %d", wbuf->lnum, wbuf->offs); <answer> offs 
<token> = -1; <answer> c->gc_lnum 
if (wbuf->lnum == -1 || wbuf->offs <token> c->leb_size) <answer> == 
return <token> <answer> grab_empty_leb(c); 
err = ubifs_find_dirty_leb(c, <token> wbuf->offs, 2); <answer> &lp, 
if (err) <token> <answer> { 
if (err <token> -ENOSPC) <answer> != 
return <token> <answer> err; 
dbg_rcvry("could not find <token> dirty LEB"); <answer> a 
return <token> <answer> grab_empty_leb(c); 
ubifs_assert(c, !(lp.flags & <token> <answer> LPROPS_INDEX)); 
ubifs_assert(c, lp.free + lp.dirty <token> wbuf->offs); <answer> >= 
err = <token> <answer> ubifs_run_commit(c); 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> LEB %d", lp.lnum); <answer> dbg_rcvry("GC'ing 
mutex_lock_nested(&wbuf->io_mutex, <token> <answer> wbuf->jhead); 
err = ubifs_garbage_collect_leb(c, <token> <answer> &lp); 
if <token> >= 0) { <answer> (err 
int <token> = ubifs_wbuf_sync_nolock(wbuf); <answer> err2 
if <token> <answer> (err2) 
err = <token> <answer> err2; 
if (err < 0) <token> <answer> { 
ubifs_err(c, "GC <token> error %d", err); <answer> failed, 
if (err == <token> <answer> -EAGAIN) 
err = <token> <answer> -EINVAL; 
<token> err; <answer> return 
ubifs_assert(c, <token> == LEB_RETAINED); <answer> err 
if (err <token> LEB_RETAINED) <answer> != 
<token> -EINVAL; <answer> return 
<token> = ubifs_leb_unmap(c, c->gc_lnum); <answer> err 
<token> (err) <answer> if 
return <token> <answer> err; 
dbg_rcvry("allocated <token> %d for GC", lp.lnum); <answer> LEB 
<token> 0; <answer> return 
struct <token> { <answer> size_entry 
<token> rb_node rb; <answer> struct 
<token> inum; <answer> ino_t 
<token> i_size; <answer> loff_t 
loff_t <token> <answer> d_size; 
int <token> <answer> exists; 
struct inode <token> <answer> *inode; 
static int add_ino(struct <token> *c, ino_t inum, loff_t i_size, <answer> ubifs_info 
loff_t d_size, int <token> <answer> exists) 
struct rb_node **p = &c->size_tree.rb_node, *parent = <token> <answer> NULL; 
<token> size_entry *e; <answer> struct 
while (*p) <token> <answer> { 
parent <token> *p; <answer> = 
e <token> rb_entry(parent, struct size_entry, rb); <answer> = 
if (inum <token> e->inum) <answer> < 
<token> = &(*p)->rb_left; <answer> p 
p = <token> <answer> &(*p)->rb_right; 
e <token> kzalloc(sizeof(struct size_entry), GFP_KERNEL); <answer> = 
if <token> <answer> (!e) 
<token> -ENOMEM; <answer> return 
<token> = inum; <answer> e->inum 
e->i_size = <token> <answer> i_size; 
<token> = d_size; <answer> e->d_size 
<token> = exists; <answer> e->exists 
rb_link_node(&e->rb, parent, <token> <answer> p); 
<token> &c->size_tree); <answer> rb_insert_color(&e->rb, 
return <token> <answer> 0; 
static struct size_entry *find_ino(struct <token> *c, ino_t inum) <answer> ubifs_info 
<token> rb_node *p = c->size_tree.rb_node; <answer> struct 
<token> size_entry *e; <answer> struct 
while <token> { <answer> (p) 
e = rb_entry(p, struct size_entry, <token> <answer> rb); 
<token> (inum < e->inum) <answer> if 
p = <token> <answer> p->rb_left; 
<token> if (inum > e->inum) <answer> else 
p = <token> <answer> p->rb_right; 
return <token> <answer> e; 
return <token> <answer> NULL; 
static void remove_ino(struct <token> *c, ino_t inum) <answer> ubifs_info 
struct size_entry *e <token> find_ino(c, inum); <answer> = 
if <token> <answer> (!e) 
rb_erase(&e->rb, <token> <answer> &c->size_tree); 
void <token> ubifs_info *c) <answer> ubifs_destroy_size_tree(struct 
struct size_entry <token> *n; <answer> *e, 
rbtree_postorder_for_each_entry_safe(e, n, &c->size_tree, <token> { <answer> rb) 
c->size_tree <token> RB_ROOT; <answer> = 
int ubifs_recover_size_accum(struct ubifs_info *c, union ubifs_key <token> <answer> *key, 
<token> deletion, loff_t new_size) <answer> int 
ino_t inum = <token> key); <answer> key_inum(c, 
struct size_entry <token> <answer> *e; 
<token> err; <answer> int 
switch (key_type(c, <token> { <answer> key)) 
case <token> <answer> UBIFS_INO_KEY: 
if <token> <answer> (deletion) 
<token> inum); <answer> remove_ino(c, 
else <token> <answer> { 
e = find_ino(c, <token> <answer> inum); 
if <token> { <answer> (e) 
e->i_size <token> new_size; <answer> = 
<token> = 1; <answer> e->exists 
<token> else { <answer> } 
<token> = add_ino(c, inum, new_size, 0, 1); <answer> err 
if <token> <answer> (err) 
<token> err; <answer> return 
case <token> <answer> UBIFS_DATA_KEY: 
e <token> find_ino(c, inum); <answer> = 
if (e) <token> <answer> { 
<token> (new_size > e->d_size) <answer> if 
e->d_size <token> new_size; <answer> = 
} <token> { <answer> else 
err = add_ino(c, inum, <token> new_size, 0); <answer> 0, 
<token> (err) <answer> if 
<token> err; <answer> return 
<token> UBIFS_TRUN_KEY: <answer> case 
e <token> find_ino(c, inum); <answer> = 
<token> (e) <answer> if 
e->d_size = <token> <answer> new_size; 
return <token> <answer> 0; 
static int <token> ubifs_info *c, struct size_entry *e) <answer> fix_size_in_place(struct 
struct ubifs_ino_node <token> = c->sbuf; <answer> *ino 
unsigned <token> *p; <answer> char 
<token> ubifs_key key; <answer> union 
int err, <token> offs, len; <answer> lnum, 
<token> i_size; <answer> loff_t 
<token> crc; <answer> uint32_t 
i_size <token> le64_to_cpu(ino->size); <answer> = 
<token> (i_size >= e->d_size) <answer> if 
<token> 0; <answer> return 
static int inode_fix_size(struct ubifs_info *c, struct <token> *e) <answer> size_entry 
struct inode <token> <answer> *inode; 
struct ubifs_inode <token> <answer> *ui; 
int <token> <answer> err; 
if <token> <answer> (c->ro_mount) 
<token> !e->inode); <answer> ubifs_assert(c, 
if <token> { <answer> (e->inode) 
<token> 0; <answer> return 
dbg_rcvry("ino %lu size <token> -> %lld", <answer> %lld 
(unsigned <token> <answer> long)e->inum, 
inode->i_size, <token> <answer> e->d_size); 
ui <token> ubifs_inode(inode); <answer> = 
inode->i_size = <token> <answer> e->d_size; 
<token> = e->d_size; <answer> ui->ui_size 
ui->synced_i_size = <token> <answer> e->d_size; 
e->inode = <token> <answer> inode; 
if <token> <answer> (c->ro_mount) 
return <token> <answer> 0; 
err = ubifs_jnl_write_inode(c, <token> <answer> inode); 
if <token> <answer> (err) 
<token> err; <answer> return 
<token> &c->size_tree); <answer> rb_erase(&e->rb, 
<token> 0; <answer> return 
<token> ubifs_recover_size(struct ubifs_info *c, bool in_place) <answer> int 
struct rb_node <token> = rb_first(&c->size_tree); <answer> *this 
while (this) <token> <answer> { 
struct <token> *e; <answer> size_entry 
<token> err; <answer> int 
e = rb_entry(this, <token> size_entry, rb); <answer> struct 
<token> = rb_next(this); <answer> this 
if (!e->exists) <token> <answer> { 
union <token> key; <answer> ubifs_key 
ino_key_init(c, &key, <token> <answer> e->inum); 
err = <token> &key, c->sbuf); <answer> ubifs_tnc_lookup(c, 
if (err <token> err != -ENOENT) <answer> && 
<token> err; <answer> return 
if (err == <token> { <answer> -ENOENT) 
<token> (in_place) { <answer> if 
err = <token> e); <answer> fix_size_in_place(c, 
<token> (err) <answer> if 
<token> err; <answer> return 
<token> else { <answer> } 
err <token> inode_fix_size(c, e); <answer> = 
if <token> <answer> (err) 
<token> err; <answer> return 
rb_erase(&e->rb, <token> <answer> &c->size_tree); 
return <token> <answer> 0; 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/syscore_ops.h> 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/serial_core.h> 
<token> <linux/serial_s3c.h> <answer> #include 
<token> <linux/irq.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
<token> <linux/of.h> <answer> #include 
<token> "map.h" <answer> #include 
#include <token> <answer> "regs-gpio.h" 
<token> "cpu.h" <answer> #include 
<token> "pm.h" <answer> #include 
static struct sleep_save irq_save[] <token> { <answer> = 
static struct irq_grp_save <token> <answer> { 
u32 <token> <answer> fltcon; 
<token> con; <answer> u32 
u32 <token> <answer> mask; 
<token> eint_grp_save[5]; <answer> } 
<token> CONFIG_SERIAL_SAMSUNG_UARTS <answer> #ifndef 
#define SERIAL_SAMSUNG_UARTS <token> <answer> 0 
<token> SERIAL_SAMSUNG_UARTS CONFIG_SERIAL_SAMSUNG_UARTS <answer> #define 
static <token> irq_uart_mask[SERIAL_SAMSUNG_UARTS]; <answer> u32 
static int <token> <answer> s3c64xx_irq_pm_suspend(void) 
struct irq_grp_save *grp <token> eint_grp_save; <answer> = 
int <token> <answer> i; 
<token> suspending IRQs\n", __func__); <answer> S3C_PMDBG("%s: 
s3c_pm_do_save(irq_save, <token> <answer> ARRAY_SIZE(irq_save)); 
for <token> = 0; i < SERIAL_SAMSUNG_UARTS; i++) <answer> (i 
<token> = __raw_readl(S3C_VA_UARTx(i) + S3C64XX_UINTM); <answer> irq_uart_mask[i] 
for (i <token> 0; i < ARRAY_SIZE(eint_grp_save); i++, grp++) { <answer> = 
grp->con = __raw_readl(S3C64XX_EINT12CON + <token> * 4)); <answer> (i 
grp->mask = __raw_readl(S3C64XX_EINT12MASK + (i <token> 4)); <answer> * 
grp->fltcon = __raw_readl(S3C64XX_EINT12FLTCON <token> (i * 4)); <answer> + 
return <token> <answer> 0; 
static <token> s3c64xx_irq_pm_resume(void) <answer> void 
struct irq_grp_save *grp = <token> <answer> eint_grp_save; 
int <token> <answer> i; 
S3C_PMDBG("%s: resuming IRQs\n", <token> <answer> __func__); 
s3c_pm_do_restore(irq_save, <token> <answer> ARRAY_SIZE(irq_save)); 
for <token> = 0; i < SERIAL_SAMSUNG_UARTS; i++) <answer> (i 
__raw_writel(irq_uart_mask[i], <token> + S3C64XX_UINTM); <answer> S3C_VA_UARTx(i) 
for (i = 0; i < ARRAY_SIZE(eint_grp_save); i++, <token> { <answer> grp++) 
__raw_writel(grp->con, S3C64XX_EINT12CON + (i * <token> <answer> 4)); 
<token> S3C64XX_EINT12MASK + (i * 4)); <answer> __raw_writel(grp->mask, 
<token> S3C64XX_EINT12FLTCON + (i * 4)); <answer> __raw_writel(grp->fltcon, 
S3C_PMDBG("%s: IRQ <token> restored\n", __func__); <answer> configuration 
static struct syscore_ops s3c64xx_irq_syscore_ops <token> { <answer> = 
.suspend <token> s3c64xx_irq_pm_suspend, <answer> = 
.resume <token> s3c64xx_irq_pm_resume, <answer> = 
<token> __init int s3c64xx_syscore_init(void) <answer> static 
#include <token> <answer> <linux/init.h> 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/leds.h> 
#include <token> <answer> <asm/idle.h> 
<token> <asm/processor.h> <answer> #include 
<token> <cobalt.h> <answer> #include 
#define RESET_PORT <token> __iomem *)CKSEG1ADDR(0x1c000000)) <answer> ((void 
#define RESET <token> <answer> 0x0f 
static int <token> ledtrig_power_off_init(void) <answer> __init 
<token> &power_off_led_trigger); <answer> led_trigger_register_simple("power-off", 
<token> 0; <answer> return 
void <token> <answer> cobalt_machine_halt(void) 
<token> LED_FULL); <answer> led_trigger_event(power_off_led_trigger, 
<token> (1) { <answer> while 
<token> (cpu_wait) <answer> if 
void <token> *command) <answer> cobalt_machine_restart(char 
writeb(RESET, <token> <answer> RESET_PORT); 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/jiffies.h> 
#include <token> <answer> <linux/i2c.h> 
#include <token> <answer> <linux/hwmon-sysfs.h> 
#include <token> <answer> <linux/hwmon.h> 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/mutex.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/sysfs.h> 
#include <token> <answer> <linux/types.h> 
static const unsigned short normal_i2c[] = { 0x18, <token> 0x4e, I2C_CLIENT_END }; <answer> 0x4c, 
#define LM63_REG_CONFIG1 <token> <answer> 0x03 
#define LM63_REG_CONVRATE <token> <answer> 0x04 
#define LM63_REG_CONFIG2 <token> <answer> 0xBF 
#define <token> 0x4A <answer> LM63_REG_CONFIG_FAN 
#define <token> 0x47 <answer> LM63_REG_TACH_COUNT_MSB 
#define <token> 0x46 <answer> LM63_REG_TACH_COUNT_LSB 
<token> LM63_REG_TACH_LIMIT_MSB 0x49 <answer> #define 
<token> LM63_REG_TACH_LIMIT_LSB 0x48 <answer> #define 
<token> LM63_REG_PWM_VALUE 0x4C <answer> #define 
<token> LM63_REG_PWM_FREQ 0x4D <answer> #define 
#define <token> 0x4F <answer> LM63_REG_LUT_TEMP_HYST 
#define LM63_REG_LUT_TEMP(nr) (0x50 + 2 * <token> <answer> (nr)) 
#define LM63_REG_LUT_PWM(nr) <token> + 2 * (nr)) <answer> (0x51 
#define LM63_REG_LOCAL_TEMP <token> <answer> 0x00 
#define <token> 0x05 <answer> LM63_REG_LOCAL_HIGH 
#define <token> 0x01 <answer> LM63_REG_REMOTE_TEMP_MSB 
#define <token> 0x10 <answer> LM63_REG_REMOTE_TEMP_LSB 
#define LM63_REG_REMOTE_OFFSET_MSB <token> <answer> 0x11 
#define <token> 0x12 <answer> LM63_REG_REMOTE_OFFSET_LSB 
#define <token> 0x07 <answer> LM63_REG_REMOTE_HIGH_MSB 
<token> LM63_REG_REMOTE_HIGH_LSB 0x13 <answer> #define 
<token> LM63_REG_REMOTE_LOW_MSB 0x08 <answer> #define 
#define LM63_REG_REMOTE_LOW_LSB <token> <answer> 0x14 
<token> LM63_REG_REMOTE_TCRIT 0x19 <answer> #define 
<token> LM63_REG_REMOTE_TCRIT_HYST 0x21 <answer> #define 
<token> LM63_REG_ALERT_STATUS 0x02 <answer> #define 
#define LM63_REG_ALERT_MASK <token> <answer> 0x16 
<token> LM63_REG_MAN_ID 0xFE <answer> #define 
<token> LM63_REG_CHIP_ID 0xFF <answer> #define 
#define <token> 0x30 <answer> LM96163_REG_TRUTHERM 
<token> LM96163_REG_REMOTE_TEMP_U_MSB 0x31 <answer> #define 
<token> LM96163_REG_REMOTE_TEMP_U_LSB 0x32 <answer> #define 
<token> LM96163_REG_CONFIG_ENHANCED 0x45 <answer> #define 
#define LM63_MAX_CONVRATE <token> <answer> 9 
<token> LM63_MAX_CONVRATE_HZ 32 <answer> #define 
<token> LM96163_MAX_CONVRATE_HZ 26 <answer> #define 
#define FAN_FROM_REG(reg) ((reg) == 0xFFFC || (reg) == 0 ? 0 <token> \ <answer> : 
5400000 <token> (reg)) <answer> / 
#define <token> ((val) <= 82 ? 0xFFFC : \ <answer> FAN_TO_REG(val) 
(5400000 <token> (val)) & 0xFFFC) <answer> / 
<token> TEMP8_FROM_REG(reg) ((reg) * 1000) <answer> #define 
#define TEMP8_TO_REG(val) <token> -128000, \ <answer> DIV_ROUND_CLOSEST(clamp_val((val), 
127000), <token> <answer> 1000) 
#define TEMP8U_TO_REG(val) <token> 0, \ <answer> DIV_ROUND_CLOSEST(clamp_val((val), 
<token> 1000) <answer> 255000), 
#define TEMP11_FROM_REG(reg) ((reg) <token> 32 * 125) <answer> / 
#define TEMP11_TO_REG(val) <token> -128000, \ <answer> (DIV_ROUND_CLOSEST(clamp_val((val), 
127875), <token> * 32) <answer> 125) 
#define TEMP11U_TO_REG(val) (DIV_ROUND_CLOSEST(clamp_val((val), <token> \ <answer> 0, 
<token> 125) * 32) <answer> 255875), 
#define <token> DIV_ROUND_CLOSEST(clamp_val((val), 0, 127000), \ <answer> HYST_TO_REG(val) 
#define <token> rate) \ <answer> UPDATE_INTERVAL(max, 
((1000 << <token> - (rate))) / (max)) <answer> (LM63_MAX_CONVRATE 
enum chips { lm63, <token> lm96163 }; <answer> lm64, 
struct lm63_data <token> <answer> { 
struct i2c_client <token> <answer> *client; 
struct mutex <token> <answer> update_lock; 
const struct attribute_group <token> <answer> *groups[5]; 
<token> pwm1_freq; <answer> u8 
static void lm63_update_lut(struct <token> *data) <answer> lm63_data 
<token> i2c_client *client = data->client; <answer> struct 
int <token> <answer> i; 
if (time_after(jiffies, <token> + 5 * HZ) || <answer> data->lut_last_updated 
<token> { <answer> !data->lut_valid) 
for (i = <token> i < data->lut_size; i++) { <answer> 0; 
data->pwm1[1 + <token> = i2c_smbus_read_byte_data(client, <answer> i] 
data->temp8[3 + i] = <token> <answer> i2c_smbus_read_byte_data(client, 
<token> = i2c_smbus_read_byte_data(client, <answer> data->lut_temp_hyst 
data->lut_last_updated = <token> <answer> jiffies; 
data->lut_valid = <token> <answer> 1; 
static struct lm63_data *lm63_update_device(struct <token> *dev) <answer> device 
struct lm63_data *data = <token> <answer> dev_get_drvdata(dev); 
<token> i2c_client *client = data->client; <answer> struct 
<token> long next_update; <answer> unsigned 
next_update = data->last_updated <token> <answer> + 
<token> (time_after(jiffies, next_update) || !data->valid) { <answer> if 
static int lm63_lut_looks_bad(struct device *dev, <token> lm63_data *data) <answer> struct 
<token> i; <answer> int 
for (i <token> 1; i < data->lut_size; i++) { <answer> = 
if (data->pwm1[1 + i - 1] > data->pwm1[1 + <token> <answer> i] 
|| data->temp8[3 + i - <token> > data->temp8[3 + i]) { <answer> 1] 
"Lookup table doesn't look sane (check entries <token> and %d)\n", <answer> %d 
i, i + <token> <answer> 1); 
return i == <token> ? 0 : 1; <answer> data->lut_size 
static ssize_t show_fan(struct device *dev, struct <token> *devattr, <answer> device_attribute 
<token> *buf) <answer> char 
<token> sensor_device_attribute *attr = to_sensor_dev_attr(devattr); <answer> struct 
struct lm63_data *data = <token> <answer> lm63_update_device(dev); 
return sprintf(buf, "%d\n", <token> <answer> FAN_FROM_REG(data->fan[attr->index])); 
<token> ssize_t set_fan(struct device *dev, struct device_attribute *dummy, <answer> static 
<token> char *buf, size_t count) <answer> const 
struct <token> *data = dev_get_drvdata(dev); <answer> lm63_data 
struct i2c_client <token> = data->client; <answer> *client 
unsigned long <token> <answer> val; 
<token> err; <answer> int 
err = <token> 10, &val); <answer> kstrtoul(buf, 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> = FAN_TO_REG(val); <answer> data->fan[1] 
i2c_smbus_write_byte_data(client, <token> <answer> LM63_REG_TACH_LIMIT_LSB, 
data->fan[1] <token> 0xFF); <answer> & 
<token> LM63_REG_TACH_LIMIT_MSB, <answer> i2c_smbus_write_byte_data(client, 
<token> >> 8); <answer> data->fan[1] 
<token> count; <answer> return 
static ssize_t show_pwm1(struct device *dev, struct <token> *devattr, <answer> device_attribute 
<token> *buf) <answer> char 
struct sensor_device_attribute *attr = <token> <answer> to_sensor_dev_attr(devattr); 
struct lm63_data *data = <token> <answer> lm63_update_device(dev); 
<token> nr = attr->index; <answer> int 
<token> pwm; <answer> int 
<token> (data->pwm_highres) <answer> if 
pwm = <token> <answer> data->pwm1[nr]; 
pwm = <token> >= 2 * data->pwm1_freq ? <answer> data->pwm1[nr] 
255 : (data->pwm1[nr] * <token> + data->pwm1_freq) / <answer> 255 
(2 * <token> <answer> data->pwm1_freq); 
return sprintf(buf, <token> pwm); <answer> "%d\n", 
static <token> set_pwm1(struct device *dev, struct device_attribute *devattr, <answer> ssize_t 
const <token> *buf, size_t count) <answer> char 
struct <token> *attr = to_sensor_dev_attr(devattr); <answer> sensor_device_attribute 
struct lm63_data <token> = dev_get_drvdata(dev); <answer> *data 
struct i2c_client *client <token> data->client; <answer> = 
<token> nr = attr->index; <answer> int 
unsigned <token> val; <answer> long 
<token> err; <answer> int 
<token> reg; <answer> u8 
if (val == <token> && lm63_lut_looks_bad(dev, data)) <answer> 2 
return <token> <answer> -EPERM; 
<token> = i2c_smbus_read_byte_data(client, <answer> data->config_fan 
if (val == <token> <answer> 1) 
data->config_fan |= <token> <answer> 0x20; 
<token> &= ~0x20; <answer> data->config_fan 
i2c_smbus_write_byte_data(client, <token> <answer> LM63_REG_CONFIG_FAN, 
<token> count; <answer> return 
static ssize_t <token> device *dev, <answer> show_local_temp8(struct 
struct device_attribute <token> <answer> *devattr, 
<token> *buf) <answer> char 
<token> sensor_device_attribute *attr = to_sensor_dev_attr(devattr); <answer> struct 
struct lm63_data *data <token> lm63_update_device(dev); <answer> = 
<token> sprintf(buf, "%d\n", TEMP8_FROM_REG(data->temp8[attr->index])); <answer> return 
static ssize_t show_remote_temp8(struct device <token> <answer> *dev, 
struct device_attribute <token> <answer> *devattr, 
char <token> <answer> *buf) 
<token> sensor_device_attribute *attr = to_sensor_dev_attr(devattr); <answer> struct 
struct lm63_data *data <token> lm63_update_device(dev); <answer> = 
return sprintf(buf, "%d\n", temp8_from_reg(data, <token> <answer> attr->index) 
+ <token> <answer> data->temp2_offset); 
<token> ssize_t show_lut_temp(struct device *dev, <answer> static 
struct device_attribute <token> <answer> *devattr, 
char <token> <answer> *buf) 
struct sensor_device_attribute *attr <token> to_sensor_dev_attr(devattr); <answer> = 
struct lm63_data *data <token> lm63_update_device(dev); <answer> = 
return sprintf(buf, "%d\n", <token> attr->index) <answer> lut_temp_from_reg(data, 
<token> data->temp2_offset); <answer> + 
static ssize_t set_temp8(struct device <token> struct device_attribute *devattr, <answer> *dev, 
const char *buf, size_t <token> <answer> count) 
struct sensor_device_attribute <token> = to_sensor_dev_attr(devattr); <answer> *attr 
struct lm63_data *data = <token> <answer> dev_get_drvdata(dev); 
struct i2c_client *client = <token> <answer> data->client; 
int nr = <token> <answer> attr->index; 
long <token> <answer> val; 
int <token> <answer> err; 
<token> temp; <answer> int 
<token> reg; <answer> u8 
<token> = kstrtol(buf, 10, &val); <answer> err 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> (nr) { <answer> switch 
<token> 2: <answer> case 
reg <token> LM63_REG_REMOTE_TCRIT; <answer> = 
<token> (data->remote_unsigned) <answer> if 
temp = TEMP8U_TO_REG(val <token> data->temp2_offset); <answer> - 
temp = TEMP8_TO_REG(val <token> data->temp2_offset); <answer> - 
case <token> <answer> 1: 
<token> = LM63_REG_LOCAL_HIGH; <answer> reg 
temp = <token> <answer> TEMP8_TO_REG(val); 
if <token> <answer> (data->temp11u) 
temp = <token> <answer> TEMP11_FROM_REG(data->temp11u); 
temp <token> TEMP11_FROM_REG(data->temp11[nr]); <answer> = 
} else <token> <answer> { 
if (data->remote_unsigned && nr <token> 2) <answer> == 
temp = <token> <answer> TEMP11_FROM_REG((u16)data->temp11[nr]); 
<token> = TEMP11_FROM_REG(data->temp11[nr]); <answer> temp 
return sprintf(buf, "%d\n", temp <token> data->temp2_offset); <answer> + 
static ssize_t set_temp11(struct device *dev, struct <token> *devattr, <answer> device_attribute 
const char <token> size_t count) <answer> *buf, 
static const u8 reg[6] = <token> <answer> { 
struct <token> *attr = to_sensor_dev_attr(devattr); <answer> sensor_device_attribute 
struct lm63_data *data = <token> <answer> dev_get_drvdata(dev); 
<token> i2c_client *client = data->client; <answer> struct 
<token> val; <answer> long 
<token> err; <answer> int 
int <token> = attr->index; <answer> nr 
err = kstrtol(buf, 10, <token> <answer> &val); 
<token> (err) <answer> if 
return <token> <answer> err; 
if (data->remote_unsigned && nr == <token> <answer> 2) 
data->temp11[nr] = TEMP11U_TO_REG(val - <token> <answer> data->temp2_offset); 
data->temp11[nr] = TEMP11_TO_REG(val - <token> <answer> data->temp2_offset); 
<token> reg[(nr - 1) * 2], <answer> i2c_smbus_write_byte_data(client, 
data->temp11[nr] <token> 8); <answer> >> 
i2c_smbus_write_byte_data(client, reg[(nr - <token> * 2 + 1], <answer> 1) 
data->temp11[nr] & <token> <answer> 0xff); 
<token> count; <answer> return 
static <token> temp2_crit_hyst_show(struct device *dev, <answer> ssize_t 
struct <token> *dummy, char *buf) <answer> device_attribute 
struct <token> *data = lm63_update_device(dev); <answer> lm63_data 
<token> sprintf(buf, "%d\n", temp8_from_reg(data, 2) <answer> return 
<token> data->temp2_offset <answer> + 
- <token> <answer> TEMP8_FROM_REG(data->temp2_crit_hyst)); 
static ssize_t <token> device *dev, <answer> show_lut_temp_hyst(struct 
struct <token> *devattr, char *buf) <answer> device_attribute 
struct <token> *attr = to_sensor_dev_attr(devattr); <answer> sensor_device_attribute 
struct lm63_data *data = <token> <answer> lm63_update_device(dev); 
<token> sprintf(buf, "%d\n", lut_temp_from_reg(data, attr->index) <answer> return 
+ <token> <answer> data->temp2_offset 
- <token> <answer> TEMP8_FROM_REG(data->lut_temp_hyst)); 
static ssize_t temp2_crit_hyst_store(struct device <token> <answer> *dev, 
struct device_attribute <token> <answer> *dummy, 
const <token> *buf, size_t count) <answer> char 
struct lm63_data *data <token> dev_get_drvdata(dev); <answer> = 
struct <token> *client = data->client; <answer> i2c_client 
long <token> <answer> val; 
int <token> <answer> err; 
<token> hyst; <answer> long 
err <token> kstrtol(buf, 10, &val); <answer> = 
<token> (err) <answer> if 
<token> err; <answer> return 
hyst <token> temp8_from_reg(data, 2) + data->temp2_offset - val; <answer> = 
<token> LM63_REG_REMOTE_TCRIT_HYST, <answer> i2c_smbus_write_byte_data(client, 
<token> count; <answer> return 
static void <token> lm63_data *data, unsigned int interval) <answer> lm63_set_convrate(struct 
struct i2c_client *client = <token> <answer> data->client; 
unsigned <token> update_interval; <answer> int 
int <token> <answer> i; 
static umode_t <token> kobject *kobj, <answer> lm63_attribute_mode(struct 
struct attribute *attr, int <token> <answer> index) 
struct device <token> = kobj_to_dev(kobj); <answer> *dev 
struct lm63_data *data = <token> <answer> dev_get_drvdata(dev); 
if <token> == &sensor_dev_attr_temp2_crit.dev_attr.attr <answer> (attr 
&& <token> == lm64 || <answer> (data->kind 
(data->kind <token> lm96163 && (data->config & 0x02)))) <answer> == 
return attr->mode <token> S_IWUSR; <answer> | 
<token> attr->mode; <answer> return 
static const <token> attribute_group lm63_group = { <answer> struct 
.is_visible = <token> <answer> lm63_attribute_mode, 
.attrs = <token> <answer> lm63_attributes, 
static struct attribute *lm63_attributes_fan1[] <token> { <answer> = 
static const <token> attribute_group lm63_group_fan1 = { <answer> struct 
<token> = lm63_attributes_fan1, <answer> .attrs 
<token> void lm63_init_client(struct lm63_data *data) <answer> static 
struct i2c_client *client = <token> <answer> data->client; 
struct device *dev = <token> <answer> &client->dev; 
<token> convrate; <answer> u8 
data->config <token> i2c_smbus_read_byte_data(client, LM63_REG_CONFIG1); <answer> = 
<token> = i2c_smbus_read_byte_data(client, <answer> data->config_fan 
if <token> == lm96163) { <answer> (data->kind 
u8 <token> <answer> config_enhanced 
= <token> <answer> i2c_smbus_read_byte_data(client, 
if (config_enhanced & <token> <answer> 0x20) 
data->lut_temp_highres = <token> <answer> true; 
<token> ((config_enhanced & 0x10) <answer> if 
&& !(data->config_fan <token> 0x08) && data->pwm1_freq == 8) <answer> & 
data->pwm_highres <token> true; <answer> = 
if (config_enhanced & <token> <answer> 0x08) 
data->remote_unsigned <token> true; <answer> = 
static const struct i2c_device_id <token> = { <answer> lm63_id[] 
<token> "lm63", lm63 }, <answer> { 
{ "lm64", <token> }, <answer> lm64 
{ <token> lm96163 }, <answer> "lm96163", 
{ <token> <answer> } 
<token> lm63_id); <answer> MODULE_DEVICE_TABLE(i2c, 
static const struct <token> __maybe_unused lm63_of_match[] = { <answer> of_device_id 
.compatible = <token> <answer> "national,lm63", 
<token> = (void *)lm63 <answer> .data 
<token> = "national,lm64", <answer> .compatible 
.data = <token> *)lm64 <answer> (void 
.compatible = <token> <answer> "national,lm96163", 
<token> = (void *)lm96163 <answer> .data 
<token> }, <answer> { 
MODULE_DEVICE_TABLE(of, <token> <answer> lm63_of_match); 
static <token> i2c_driver lm63_driver = { <answer> struct 
.class <token> I2C_CLASS_HWMON, <answer> = 
<token> = { <answer> .driver 
.name = <token> <answer> "lm63", 
.of_match_table = <token> <answer> of_match_ptr(lm63_of_match), 
.probe <token> lm63_probe, <answer> = 
<token> = lm63_id, <answer> .id_table 
.detect <token> lm63_detect, <answer> = 
.address_list <token> normal_i2c, <answer> = 
MODULE_AUTHOR("Jean <token> <jdelvare@suse.de>"); <answer> Delvare 
<token> driver"); <answer> MODULE_DESCRIPTION("LM63 
<token> <linux/types.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/pci.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/dmi.h> 
<token> <linux/io.h> <answer> #include 
<token> <linux/smp.h> <answer> #include 
#include <token> <answer> <linux/spinlock.h> 
<token> <asm/io_apic.h> <answer> #include 
#include <token> <answer> <linux/irq.h> 
<token> <linux/acpi.h> <answer> #include 
#include <token> <answer> <asm/i8259.h> 
<token> <asm/pc-conf-reg.h> <answer> #include 
#include <token> <answer> <asm/pci_x86.h> 
#define PIRQ_SIGNATURE (('$' << 0) + ('P' << 8) + <token> << 16) + ('R' << 24)) <answer> ('I' 
<token> PIRQ_VERSION 0x0100 <answer> #define 
#define IRT_SIGNATURE (('$' << 0) + ('I' << 8) + <token> << 16) + ('T' << 24)) <answer> ('R' 
<token> int broken_hp_bios_irq9; <answer> static 
<token> int acer_tm360_irqrouting; <answer> static 
static <token> irq_routing_table *pirq_table; <answer> struct 
<token> int pirq_enable_irq(struct pci_dev *dev); <answer> static 
<token> void pirq_disable_irq(struct pci_dev *dev); <answer> static 
unsigned <token> pcibios_irq_mask = 0xfff8; <answer> int 
<token> int pirq_penalty[16] = { <answer> static 
<token> 1000000, 1000000, 1000, 1000, 0, 1000, 1000, <answer> 1000000, 
0, 0, <token> 0, 1000, 100000, 100000, 100000 <answer> 0, 
<token> irq_router { <answer> struct 
char <token> <answer> *name; 
u16 <token> device; <answer> vendor, 
int <token> pci_dev *router, struct pci_dev *dev, int pirq); <answer> (*get)(struct 
int (*set)(struct pci_dev *router, struct pci_dev *dev, <token> pirq, <answer> int 
int <token> <answer> new); 
int (*lvl)(struct pci_dev <token> struct pci_dev *dev, int pirq, <answer> *router, 
<token> irq); <answer> int 
struct <token> { <answer> irq_router_handler 
u16 <token> <answer> vendor; 
int <token> irq_router *r, struct pci_dev *router, u16 device); <answer> (*probe)(struct 
int <token> pci_dev *dev) = pirq_enable_irq; <answer> (*pcibios_enable_irq)(struct 
void (*pcibios_disable_irq)(struct <token> *dev) = pirq_disable_irq; <answer> pci_dev 
static inline struct irq_routing_table *pirq_check_routing_table(u8 <token> <answer> *addr, 
u8 <token> <answer> *limit) 
struct irq_routing_table <token> <answer> *rt; 
<token> i; <answer> int 
u8 <token> <answer> sum; 
rt = (struct <token> *)addr; <answer> irq_routing_table 
if (rt->signature != PIRQ_SIGNATURE <token> <answer> || 
rt->version <token> PIRQ_VERSION || <answer> != 
rt->size % <token> || <answer> 16 
<token> < sizeof(struct irq_routing_table) || <answer> rt->size 
(limit <token> rt->size > limit - addr)) <answer> && 
<token> NULL; <answer> return 
<token> = 0; <answer> sum 
for (i = 0; i <token> rt->size; i++) <answer> < 
<token> += addr[i]; <answer> sum 
if <token> { <answer> (!sum) 
DBG(KERN_DEBUG "PCI: Interrupt <token> Table found at 0x%lx\n", <answer> Routing 
<token> rt; <answer> return 
<token> NULL; <answer> return 
static <token> struct irq_routing_table *pirq_convert_irt_table(u8 *addr, <answer> inline 
<token> *limit) <answer> u8 
<token> irt_routing_table *ir; <answer> struct 
struct <token> *rt; <answer> irq_routing_table 
u16 <token> <answer> size; 
u8 <token> <answer> sum; 
<token> i; <answer> int 
ir = (struct irt_routing_table <token> <answer> *)addr; 
if (ir->signature != IRT_SIGNATURE <token> !ir->used || ir->size < ir->used) <answer> || 
<token> NULL; <answer> return 
size = <token> slots, ir->used); <answer> struct_size(ir, 
if (size > limit - <token> <answer> addr) 
return <token> <answer> NULL; 
DBG(KERN_DEBUG <token> $IRT Interrupt Routing Table found at 0x%lx\n", <answer> "PCI: 
<token> = struct_size(rt, slots, ir->used); <answer> size 
rt <token> kzalloc(size, GFP_KERNEL); <answer> = 
if <token> <answer> (!rt) 
return <token> <answer> NULL; 
rt->signature = <token> <answer> PIRQ_SIGNATURE; 
rt->version = <token> <answer> PIRQ_VERSION; 
rt->size = <token> <answer> size; 
rt->exclusive_irqs = <token> <answer> ir->exclusive_irqs; 
for (i = 0; <token> < ir->used; i++) <answer> i 
<token> = ir->slots[i]; <answer> rt->slots[i] 
addr <token> (u8 *)rt; <answer> = 
sum <token> 0; <answer> = 
for (i <token> 0; i < size; i++) <answer> = 
sum += <token> <answer> addr[i]; 
rt->checksum <token> -sum; <answer> = 
return <token> <answer> rt; 
static struct irq_routing_table * <token> pirq_find_routing_table(void) <answer> __init 
u8 <token> const bios_start = (u8 *)__va(0xf0000); <answer> * 
u8 * const bios_end = <token> *)__va(0x100000); <answer> (u8 
u8 <token> <answer> *addr; 
struct irq_routing_table <token> <answer> *rt; 
<token> (pirq_table_addr) { <answer> if 
rt <token> pirq_check_routing_table((u8 *)__va(pirq_table_addr), <answer> = 
<token> (rt) <answer> if 
return <token> <answer> rt; 
printk(KERN_WARNING <token> PIRQ table NOT found at pirqaddr\n"); <answer> "PCI: 
for <token> = bios_start; <answer> (addr 
addr < bios_end <token> sizeof(struct irq_routing_table); <answer> - 
addr += <token> { <answer> 16) 
rt = pirq_check_routing_table(addr, <token> <answer> bios_end); 
<token> (rt) <answer> if 
return <token> <answer> rt; 
for (addr = <token> <answer> bios_start; 
addr <token> bios_end - sizeof(struct irt_routing_table); <answer> < 
addr++) <token> <answer> { 
rt = pirq_convert_irt_table(addr, <token> <answer> bios_end); 
if <token> <answer> (rt) 
return <token> <answer> rt; 
<token> NULL; <answer> return 
static <token> __init pirq_peer_trick(void) <answer> void 
struct irq_routing_table *rt <token> pirq_table; <answer> = 
u8 <token> <answer> busmap[256]; 
int <token> <answer> i; 
struct irq_info <token> <answer> *e; 
memset(busmap, 0, <token> <answer> sizeof(busmap)); 
for (i <token> 0; i < (rt->size - sizeof(struct irq_routing_table)) / sizeof(struct irq_info); i++) { <answer> = 
e = <token> <answer> &rt->slots[i]; 
<token> DEBUG <answer> #ifdef 
<token> j; <answer> int 
DBG(KERN_DEBUG "%02x:%02x.%x <token> <answer> slot=%02x", 
e->bus, e->devfn / 8, e->devfn <token> 8, e->slot); <answer> % 
for (j <token> 0; j < 4; j++) <answer> = 
DBG(" %d:%02x/%04x", j, <token> e->irq[j].bitmap); <answer> e->irq[j].link, 
busmap[e->bus] = <token> <answer> 1; 
<token> (i = 1; i < 256; i++) { <answer> for 
if (!busmap[i] || <token> i)) <answer> pci_find_bus(0, 
<token> = -1; <answer> pcibios_last_bus 
<token> elcr_set_level_irq(unsigned int irq) <answer> void 
unsigned char mask = 1 <token> (irq & 7); <answer> << 
unsigned int port = PIC_ELCR1 + (irq <token> 3); <answer> >> 
unsigned char <token> <answer> val; 
static u16 <token> <answer> elcr_irq_mask; 
if <token> >= 16 || (1 << irq) & elcr_irq_mask) <answer> (irq 
elcr_irq_mask |= (1 <token> irq); <answer> << 
printk(KERN_DEBUG <token> setting IRQ %u as level-triggered\n", irq); <answer> "PCI: 
val <token> inb(port); <answer> = 
if (!(val & mask)) <token> <answer> { 
<token> " -> edge"); <answer> DBG(KERN_DEBUG 
outb(val <token> mask, port); <answer> | 
<token> PC_CONF_FINALI_LOCK 0x03u <answer> #define 
#define <token> 0x42u <answer> PC_CONF_FINALI_PCI_INTX_RT1 
<token> PC_CONF_FINALI_PCI_INTX_RT2 0x43u <answer> #define 
<token> PC_CONF_FINALI_PCI_INTX_SENS 0x44u <answer> #define 
#define <token> 0xc5u <answer> PC_CONF_FINALI_LOCK_KEY 
static u8 read_pc_conf_nybble(u8 base, <token> index) <answer> u8 
u8 reg = <token> + (index >> 1); <answer> base 
<token> x; <answer> u8 
x = <token> <answer> pc_conf_get(reg); 
return index & 1 ? x >> <token> : x & 0xf; <answer> 4 
<token> void write_pc_conf_nybble(u8 base, u8 index, u8 val) <answer> static 
u8 reg = base <token> (index >> 1); <answer> + 
u8 <token> <answer> x; 
x = <token> <answer> pc_conf_get(reg); 
x = index & 1 ? (x & 0x0f) | <token> << 4) : (x & 0xf0) | val; <answer> (val 
<token> x); <answer> pc_conf_set(reg, 
static int pirq_finali_get(struct pci_dev *router, struct <token> *dev, <answer> pci_dev 
int <token> <answer> pirq) 
static const u8 irqmap[16] = <token> <answer> { 
0, 9, 3, 10, <token> 5, 7, 6, 0, 11, 0, 12, 0, 14, 0, 15 <answer> 4, 
unsigned long <token> <answer> flags; 
<token> index; <answer> u8 
u8 <token> <answer> x; 
index = <token> & 1) << 1 | (pirq & 8) >> 3; <answer> (pirq 
<token> flags); <answer> raw_spin_lock_irqsave(&pc_conf_lock, 
pc_conf_set(PC_CONF_FINALI_LOCK, <token> <answer> PC_CONF_FINALI_LOCK_KEY); 
x = irqmap[read_pc_conf_nybble(PC_CONF_FINALI_PCI_INTX_RT1, <token> <answer> index)]; 
<token> 0); <answer> pc_conf_set(PC_CONF_FINALI_LOCK, 
<token> flags); <answer> raw_spin_unlock_irqrestore(&pc_conf_lock, 
return <token> <answer> x; 
static int <token> pci_dev *router, struct pci_dev *dev, <answer> pirq_finali_set(struct 
<token> pirq, int irq) <answer> int 
<token> const u8 irqmap[16] = { <answer> static 
0, 0, <token> 2, 4, 5, 7, 6, 0, 1, 3, 9, 11, 0, 13, 15 <answer> 0, 
u8 val <token> irqmap[irq]; <answer> = 
<token> long flags; <answer> unsigned 
<token> index; <answer> u8 
if <token> <answer> (!val) 
return <token> <answer> 0; 
index = (pirq & 1) << 1 <token> (pirq & 8) >> 3; <answer> | 
raw_spin_lock_irqsave(&pc_conf_lock, <token> <answer> flags); 
pc_conf_set(PC_CONF_FINALI_LOCK, <token> <answer> PC_CONF_FINALI_LOCK_KEY); 
write_pc_conf_nybble(PC_CONF_FINALI_PCI_INTX_RT1, <token> val); <answer> index, 
<token> 0); <answer> pc_conf_set(PC_CONF_FINALI_LOCK, 
<token> flags); <answer> raw_spin_unlock_irqrestore(&pc_conf_lock, 
return <token> <answer> 1; 
static int pirq_finali_lvl(struct pci_dev *router, struct pci_dev <token> <answer> *dev, 
int <token> int irq) <answer> pirq, 
u8 mask <token> ~((pirq & 0xf0u) >> 4); <answer> = 
<token> long flags; <answer> unsigned 
u8 <token> <answer> trig; 
<token> flags); <answer> raw_spin_lock_irqsave(&pc_conf_lock, 
pc_conf_set(PC_CONF_FINALI_LOCK, <token> <answer> PC_CONF_FINALI_LOCK_KEY); 
<token> = pc_conf_get(PC_CONF_FINALI_PCI_INTX_SENS); <answer> trig 
<token> &= mask; <answer> trig 
pc_conf_set(PC_CONF_FINALI_PCI_INTX_SENS, <token> <answer> trig); 
<token> 0); <answer> pc_conf_set(PC_CONF_FINALI_LOCK, 
raw_spin_unlock_irqrestore(&pc_conf_lock, <token> <answer> flags); 
return <token> <answer> 1; 
static unsigned int read_config_nybble(struct pci_dev *router, unsigned offset, <token> nr) <answer> unsigned 
u8 <token> <answer> x; 
unsigned reg = offset <token> (nr >> 1); <answer> + 
pci_read_config_byte(router, reg, <token> <answer> &x); 
return (nr & 1) ? (x >> <token> : (x & 0xf); <answer> 4) 
static void <token> pci_dev *router, unsigned offset, <answer> write_config_nybble(struct 
unsigned nr, unsigned <token> val) <answer> int 
<token> x; <answer> u8 
unsigned reg <token> offset + (nr >> 1); <answer> = 
pci_read_config_byte(router, reg, <token> <answer> &x); 
x = (nr & 1) ? ((x <token> 0x0f) | (val << 4)) : ((x & 0xf0) | val); <answer> & 
pci_write_config_byte(router, reg, <token> <answer> x); 
static int pirq_ali_get(struct pci_dev *router, struct pci_dev *dev, int <token> <answer> pirq) 
static const unsigned char irqmap[16] = { 0, 9, 3, 10, 4, 5, 7, <token> 1, 11, 0, 12, 0, 14, 0, 15 }; <answer> 6, 
WARN_ON_ONCE(pirq <token> 16); <answer> > 
return irqmap[read_config_nybble(router, 0x48, <token> <answer> pirq-1)]; 
static int pirq_ali_set(struct pci_dev *router, struct pci_dev *dev, int pirq, int <token> <answer> irq) 
static const unsigned char irqmap[16] = { 0, 8, 0, 2, 4, 5, 7, 6, 0, 1, 3, 9, 11, 0, <token> 15 }; <answer> 13, 
<token> int val = irqmap[irq]; <answer> unsigned 
<token> > 16); <answer> WARN_ON_ONCE(pirq 
<token> (val) { <answer> if 
write_config_nybble(router, <token> pirq-1, val); <answer> 0x48, 
return <token> <answer> 1; 
<token> 0; <answer> return 
#define PC_CONF_I82374_ESC_ID <token> <answer> 0x02u 
#define <token> 0x60u <answer> PC_CONF_I82374_PIRQ_ROUTE_CONTROL 
#define PC_CONF_I82374_ESC_ID_KEY <token> <answer> 0x0fu 
static int pirq_esc_get(struct pci_dev *router, struct <token> *dev, int pirq) <answer> pci_dev 
<token> long flags; <answer> unsigned 
int <token> <answer> reg; 
<token> x; <answer> u8 
reg = <token> <answer> pirq; 
if (reg >= 1 && reg <token> 4) <answer> <= 
reg += <token> - 1; <answer> PC_CONF_I82374_PIRQ_ROUTE_CONTROL 
<token> flags); <answer> raw_spin_lock_irqsave(&pc_conf_lock, 
<token> PC_CONF_I82374_ESC_ID_KEY); <answer> pc_conf_set(PC_CONF_I82374_ESC_ID, 
x = <token> <answer> pc_conf_get(reg); 
<token> 0); <answer> pc_conf_set(PC_CONF_I82374_ESC_ID, 
<token> flags); <answer> raw_spin_unlock_irqrestore(&pc_conf_lock, 
<token> (x < 16) ? x : 0; <answer> return 
static int pirq_esc_set(struct <token> *router, struct pci_dev *dev, int pirq, <answer> pci_dev 
int <token> <answer> irq) 
unsigned long <token> <answer> flags; 
<token> reg; <answer> int 
<token> = pirq; <answer> reg 
if (reg >= 1 <token> reg <= 4) <answer> && 
reg <token> PC_CONF_I82374_PIRQ_ROUTE_CONTROL - 1; <answer> += 
raw_spin_lock_irqsave(&pc_conf_lock, <token> <answer> flags); 
pc_conf_set(PC_CONF_I82374_ESC_ID, <token> <answer> PC_CONF_I82374_ESC_ID_KEY); 
pc_conf_set(reg, <token> <answer> irq); 
<token> 0); <answer> pc_conf_set(PC_CONF_I82374_ESC_ID, 
<token> flags); <answer> raw_spin_unlock_irqrestore(&pc_conf_lock, 
<token> 1; <answer> return 
static int pirq_piix_get(struct pci_dev *router, struct <token> *dev, int pirq) <answer> pci_dev 
u8 <token> <answer> x; 
<token> pirq, &x); <answer> pci_read_config_byte(router, 
return (x < 16) ? x <token> 0; <answer> : 
static int pirq_piix_set(struct pci_dev *router, struct pci_dev *dev, <token> pirq, int irq) <answer> int 
pci_write_config_byte(router, <token> irq); <answer> pirq, 
return <token> <answer> 1; 
<token> PCI_I82426EX_PIRQ_ROUTE_CONTROL 0x66u <answer> #define 
static <token> pirq_ib_get(struct pci_dev *router, struct pci_dev *dev, int pirq) <answer> int 
int <token> <answer> reg; 
<token> x; <answer> u8 
reg = <token> <answer> pirq; 
if (reg >= 1 <token> reg <= 2) <answer> && 
reg += <token> - 1; <answer> PCI_I82426EX_PIRQ_ROUTE_CONTROL 
pci_read_config_byte(router, <token> &x); <answer> reg, 
return (x <token> 16) ? x : 0; <answer> < 
static <token> pirq_ib_set(struct pci_dev *router, struct pci_dev *dev, int pirq, <answer> int 
int <token> <answer> irq) 
int <token> <answer> reg; 
<token> = pirq; <answer> reg 
if (reg >= 1 && reg <token> 2) <answer> <= 
<token> += PCI_I82426EX_PIRQ_ROUTE_CONTROL - 1; <answer> reg 
pci_write_config_byte(router, <token> irq); <answer> reg, 
<token> 1; <answer> return 
static int pirq_via_get(struct pci_dev *router, struct pci_dev <token> int pirq) <answer> *dev, 
return read_config_nybble(router, <token> pirq == 4 ? 5 : pirq); <answer> 0x55, 
static int pirq_via_set(struct <token> *router, struct pci_dev *dev, int pirq, int irq) <answer> pci_dev 
write_config_nybble(router, 0x55, pirq == <token> ? 5 : pirq, irq); <answer> 4 
<token> 1; <answer> return 
static int pirq_via586_get(struct pci_dev *router, struct pci_dev *dev, <token> pirq) <answer> int 
static const unsigned <token> pirqmap[5] = { 3, 2, 5, 1, 1 }; <answer> int 
WARN_ON_ONCE(pirq > <token> <answer> 5); 
return read_config_nybble(router, <token> pirqmap[pirq-1]); <answer> 0x55, 
<token> int pirq_via586_set(struct pci_dev *router, struct pci_dev *dev, int pirq, int irq) <answer> static 
static const unsigned int pirqmap[5] = { 3, 2, <token> 1, 1 }; <answer> 5, 
WARN_ON_ONCE(pirq > <token> <answer> 5); 
<token> 0x55, pirqmap[pirq-1], irq); <answer> write_config_nybble(router, 
<token> 1; <answer> return 
static <token> pirq_ite_get(struct pci_dev *router, struct pci_dev *dev, int pirq) <answer> int 
static const unsigned char pirqmap[4] = { 1, <token> 2, 3 }; <answer> 0, 
WARN_ON_ONCE(pirq > <token> <answer> 4); 
return <token> 0x43, pirqmap[pirq-1]); <answer> read_config_nybble(router, 
static int pirq_ite_set(struct pci_dev *router, struct pci_dev *dev, int pirq, int <token> <answer> irq) 
<token> const unsigned char pirqmap[4] = { 1, 0, 2, 3 }; <answer> static 
WARN_ON_ONCE(pirq > <token> <answer> 4); 
write_config_nybble(router, 0x43, pirqmap[pirq-1], <token> <answer> irq); 
<token> 1; <answer> return 
static int <token> pci_dev *router, struct pci_dev *dev, int pirq) <answer> pirq_opti_get(struct 
return read_config_nybble(router, 0xb8, <token> >> 4); <answer> pirq 
static int pirq_opti_set(struct pci_dev *router, struct <token> *dev, int pirq, int irq) <answer> pci_dev 
write_config_nybble(router, 0xb8, pirq >> 4, <token> <answer> irq); 
<token> 1; <answer> return 
static int pirq_cyrix_get(struct pci_dev *router, struct pci_dev *dev, <token> pirq) <answer> int 
return read_config_nybble(router, <token> (pirq-1)^1); <answer> 0x5C, 
static int pirq_cyrix_set(struct pci_dev *router, struct pci_dev *dev, int pirq, int <token> <answer> irq) 
write_config_nybble(router, 0x5C, <token> irq); <answer> (pirq-1)^1, 
<token> 1; <answer> return 
#define <token> 0xc0u <answer> PCI_SIS497_INTA_TO_IRQ_LINK 
#define <token> 0x0fu <answer> PIRQ_SIS497_IRQ_MASK 
#define PIRQ_SIS497_IRQ_ENABLE <token> <answer> 0x80u 
static int pirq_sis497_get(struct pci_dev *router, <token> pci_dev *dev, <answer> struct 
<token> pirq) <answer> int 
int <token> <answer> reg; 
<token> x; <answer> u8 
reg <token> pirq; <answer> = 
if (reg <token> 1 && reg <= 4) <answer> >= 
reg += PCI_SIS497_INTA_TO_IRQ_LINK - <token> <answer> 1; 
<token> reg, &x); <answer> pci_read_config_byte(router, 
return (x & PIRQ_SIS497_IRQ_ENABLE) ? (x <token> PIRQ_SIS497_IRQ_MASK) : 0; <answer> & 
<token> int pirq_sis497_set(struct pci_dev *router, struct pci_dev *dev, <answer> static 
<token> pirq, int irq) <answer> int 
int <token> <answer> reg; 
<token> x; <answer> u8 
reg = <token> <answer> pirq; 
if (reg >= 1 && reg <= <token> <answer> 4) 
<token> += PCI_SIS497_INTA_TO_IRQ_LINK - 1; <answer> reg 
pci_read_config_byte(router, reg, <token> <answer> &x); 
<token> &= ~(PIRQ_SIS497_IRQ_MASK | PIRQ_SIS497_IRQ_ENABLE); <answer> x 
x |= irq ? (PIRQ_SIS497_IRQ_ENABLE <token> irq) : PIRQ_SIS497_IRQ_MASK; <answer> | 
pci_write_config_byte(router, <token> x); <answer> reg, 
return <token> <answer> 1; 
<token> PIRQ_SIS503_IRQ_MASK 0x0f <answer> #define 
#define PIRQ_SIS503_IRQ_DISABLE <token> <answer> 0x80 
<token> PIRQ_SIS503_USB_ENABLE 0x40 <answer> #define 
static int pirq_sis503_get(struct pci_dev *router, <token> pci_dev *dev, <answer> struct 
<token> pirq) <answer> int 
u8 <token> <answer> x; 
<token> reg; <answer> int 
reg <token> pirq; <answer> = 
if (reg >= 0x01 && reg <token> 0x04) <answer> <= 
reg <token> 0x40; <answer> += 
pci_read_config_byte(router, <token> &x); <answer> reg, 
return <token> & PIRQ_SIS503_IRQ_DISABLE) ? 0 : (x & PIRQ_SIS503_IRQ_MASK); <answer> (x 
<token> int pirq_sis503_set(struct pci_dev *router, struct pci_dev *dev, <answer> static 
int pirq, <token> irq) <answer> int 
<token> x; <answer> u8 
<token> reg; <answer> int 
reg = <token> <answer> pirq; 
if (reg <token> 0x01 && reg <= 0x04) <answer> >= 
<token> += 0x40; <answer> reg 
<token> reg, &x); <answer> pci_read_config_byte(router, 
x <token> ~(PIRQ_SIS503_IRQ_MASK | PIRQ_SIS503_IRQ_DISABLE); <answer> &= 
x |= <token> ? irq : PIRQ_SIS503_IRQ_DISABLE; <answer> irq 
pci_write_config_byte(router, reg, <token> <answer> x); 
return <token> <answer> 1; 
static int pirq_vlsi_get(struct pci_dev *router, struct pci_dev *dev, int <token> <answer> pirq) 
WARN_ON_ONCE(pirq <token> 9); <answer> >= 
if <token> > 8) { <answer> (pirq 
dev_info(&dev->dev, "VLSI router PIRQ escape <token> pirq); <answer> (%d)\n", 
return <token> <answer> 0; 
return read_config_nybble(router, <token> pirq-1); <answer> 0x74, 
static int pirq_vlsi_set(struct pci_dev *router, struct pci_dev *dev, <token> pirq, int irq) <answer> int 
<token> >= 9); <answer> WARN_ON_ONCE(pirq 
if <token> > 8) { <answer> (pirq 
dev_info(&dev->dev, "VLSI router PIRQ escape <token> pirq); <answer> (%d)\n", 
return <token> <answer> 0; 
write_config_nybble(router, 0x74, <token> irq); <answer> pirq-1, 
<token> 1; <answer> return 
static int pirq_serverworks_get(struct pci_dev *router, struct pci_dev *dev, int <token> <answer> pirq) 
<token> 0xc00); <answer> outb(pirq, 
return inb(0xc01) <token> 0xf; <answer> & 
static int <token> pci_dev *router, struct pci_dev *dev, <answer> pirq_serverworks_set(struct 
<token> pirq, int irq) <answer> int 
<token> 0xc00); <answer> outb(pirq, 
<token> 0xc01); <answer> outb(irq, 
return <token> <answer> 1; 
static int pirq_amd756_get(struct pci_dev *router, struct pci_dev *dev, int <token> <answer> pirq) 
u8 <token> <answer> irq; 
irq <token> 0; <answer> = 
<token> (pirq <= 4) <answer> if 
irq = read_config_nybble(router, <token> pirq - 1); <answer> 0x56, 
"AMD756: dev [%04x:%04x], <token> PIRQ %d get IRQ %d\n", <answer> router 
dev->vendor, <token> pirq, irq); <answer> dev->device, 
return <token> <answer> irq; 
static int pirq_amd756_set(struct pci_dev *router, struct <token> *dev, int pirq, int irq) <answer> pci_dev 
<token> dev [%04x:%04x], router PIRQ %d set IRQ %d\n", <answer> "AMD756: 
dev->vendor, dev->device, pirq, <token> <answer> irq); 
if (pirq <token> 4) <answer> <= 
write_config_nybble(router, 0x56, pirq - <token> irq); <answer> 1, 
return <token> <answer> 1; 
static int <token> pci_dev *router, struct pci_dev *dev, int pirq) <answer> pirq_pico_get(struct 
outb(0x10 + ((pirq - <token> >> 1), 0x24); <answer> 1) 
return ((pirq <token> 1) & 1) ? (inb(0x26) >> 4) : (inb(0x26) & 0xf); <answer> - 
<token> int pirq_pico_set(struct pci_dev *router, struct pci_dev *dev, int pirq, <answer> static 
<token> irq) <answer> int 
<token> int x; <answer> unsigned 
outb(0x10 + ((pirq <token> 1) >> 1), 0x24); <answer> - 
<token> = inb(0x26); <answer> x 
x = ((pirq - 1) & 1) ? ((x & 0x0f) | (irq <token> 4)) : ((x & 0xf0) | (irq)); <answer> << 
outb(x, <token> <answer> 0x26); 
return <token> <answer> 1; 
<token> CONFIG_PCI_BIOS <answer> #ifdef 
static int pirq_bios_set(struct pci_dev <token> struct pci_dev *dev, int pirq, int irq) <answer> *router, 
struct pci_dev <token> <answer> *bridge; 
int pin <token> pci_get_interrupt_pin(dev, &bridge); <answer> = 
return <token> pin - 1, irq); <answer> pcibios_set_irq_routing(bridge, 
static __init int intel_router_probe(struct irq_router *r, struct pci_dev *router, u16 <token> <answer> device) 
static struct pci_device_id __initdata pirq_440gx[] <token> { <answer> = 
<token> PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_82443GX_0) }, <answer> { 
{ <token> PCI_DEVICE_ID_INTEL_82443GX_2) }, <answer> PCI_DEVICE(PCI_VENDOR_ID_INTEL, 
<token> }, <answer> { 
if (device == PCI_DEVICE_ID_VIA_82C586_0) <token> <answer> { 
switch (router->device) <token> <answer> { 
<token> PCI_DEVICE_ID_VIA_82C686: <answer> case 
device = <token> <answer> PCI_DEVICE_ID_VIA_82C686; 
<token> PCI_DEVICE_ID_VIA_8235: <answer> case 
<token> = PCI_DEVICE_ID_VIA_8235; <answer> device 
case <token> <answer> PCI_DEVICE_ID_VIA_8237: 
device = <token> <answer> PCI_DEVICE_ID_VIA_8237; 
switch <token> { <answer> (device) 
case <token> <answer> PCI_DEVICE_ID_VIA_82C586_0: 
r->name <token> "VIA"; <answer> = 
r->get <token> pirq_via586_get; <answer> = 
r->set <token> pirq_via586_set; <answer> = 
<token> 1; <answer> return 
case <token> <answer> PCI_DEVICE_ID_VIA_82C596: 
case <token> <answer> PCI_DEVICE_ID_VIA_82C686: 
case <token> <answer> PCI_DEVICE_ID_VIA_8231: 
<token> PCI_DEVICE_ID_VIA_8233A: <answer> case 
<token> PCI_DEVICE_ID_VIA_8235: <answer> case 
<token> PCI_DEVICE_ID_VIA_8237: <answer> case 
static bool <token> pirq_try_router(struct irq_router *r, <answer> __init 
struct <token> *rt, <answer> irq_routing_table 
<token> pci_dev *dev) <answer> struct 
struct irq_router_handler <token> <answer> *h; 
DBG(KERN_DEBUG "PCI: Trying IRQ router <token> [%04x:%04x]\n", <answer> for 
<token> dev->device); <answer> dev->vendor, 
for (h = pirq_routers; <token> h++) { <answer> h->vendor; 
static struct irq_info <token> pci_dev *dev) <answer> *pirq_get_dev_info(struct 
<token> irq_routing_table *rt = pirq_table; <answer> struct 
int entries <token> (rt->size - sizeof(struct irq_routing_table)) / <answer> = 
sizeof(struct <token> <answer> irq_info); 
struct <token> *slotinfo = NULL; <answer> irq_info 
struct <token> *info; <answer> irq_info 
for (info <token> rt->slots; entries--; info++) <answer> = 
if <token> == dev->bus->number) { <answer> (info->bus 
<token> (info->devfn == dev->devfn) <answer> if 
return <token> <answer> info; 
if <token> && <answer> (!slotinfo 
PCI_SLOT(info->devfn) <token> PCI_SLOT(dev->devfn)) <answer> == 
slotinfo <token> info; <answer> = 
<token> slotinfo; <answer> return 
<token> struct irq_info *pirq_get_info(struct pci_dev *dev, u8 *pin) <answer> static 
struct <token> *temp_dev = dev; <answer> pci_dev 
struct irq_info <token> <answer> *info; 
u8 temp_pin <token> *pin; <answer> = 
u8 <token> = temp_pin; <answer> dpin 
info = <token> <answer> pirq_get_dev_info(dev); 
while <token> && temp_dev->bus->parent) { <answer> (!info 
struct <token> *bridge = temp_dev->bus->self; <answer> pci_dev 
temp_pin <token> pci_swizzle_interrupt_pin(temp_dev, temp_pin); <answer> = 
info = <token> <answer> pirq_get_dev_info(bridge); 
if <token> <answer> (info) 
"using bridge %s INT %c to get INT <token> <answer> %c\n", 
'A' + temp_pin - 1, 'A' + dpin <token> 1); <answer> - 
<token> = bridge; <answer> temp_dev 
<token> = temp_pin; <answer> *pin 
return <token> <answer> info; 
<token> int pcibios_lookup_irq(struct pci_dev *dev, int assign) <answer> static 
struct irq_info <token> <answer> *info; 
int <token> pirq, newirq; <answer> i, 
u8 <token> pin; <answer> dpin, 
int irq = <token> <answer> 0; 
<token> mask; <answer> u32 
struct <token> *r = &pirq_router; <answer> irq_router 
struct pci_dev <token> = NULL; <answer> *dev2 
char *msg = <token> <answer> NULL; 
if (broken_hp_bios_irq9 && pirq == 0x59 && <token> == 9) { <answer> dev->irq 
dev->irq <token> 11; <answer> = 
pci_write_config_byte(dev, PCI_INTERRUPT_LINE, <token> <answer> 11); 
<token> dev, pirq, 11); <answer> r->set(pirq_router_dev, 
<token> = dev->irq; <answer> newirq 
if (newirq && !((1 << newirq) & <token> { <answer> mask)) 
if (pci_probe <token> PCI_USE_PIRQ_MASK) <answer> & 
newirq = <token> <answer> 0; 
dev_warn(&dev->dev, "IRQ %d <token> match PIRQ mask " <answer> doesn't 
"%#x; try pci=usepirqmask\n", <token> mask); <answer> newirq, 
if (!newirq && assign) <token> <answer> { 
for (i = 0; i < <token> i++) { <answer> 16; 
<token> (!(mask & (1 << i))) <answer> if 
<token> (pirq_penalty[i] < pirq_penalty[newirq] && <answer> if 
<token> IRQF_SHARED)) <answer> can_request_irq(i, 
newirq = <token> <answer> i; 
dev_dbg(&dev->dev, "PCI INT %c -> newirq %d", 'A' + dpin <token> 1, newirq); <answer> - 
<token> (dev2->irq && dev2->irq != irq && \ <answer> if 
(!(pci_probe & PCI_USE_PIRQ_MASK) <token> \ <answer> || 
<token> << dev2->irq) & mask))) { <answer> ((1 
<token> CONFIG_PCI_MSI <answer> #ifndef 
dev_info(&dev2->dev, "IRQ routing <token> " <answer> conflict: 
"have IRQ <token> want IRQ %d\n", <answer> %d, 
<token> irq); <answer> dev2->irq, 
dev2->irq <token> irq; <answer> = 
if <token> != dev2) <answer> (dev 
dev_info(&dev->dev, "sharing IRQ <token> with %s\n", <answer> %d 
irq, <token> <answer> pci_name(dev2)); 
return <token> <answer> 1; 
void __init <token> <answer> pcibios_fixup_irqs(void) 
struct pci_dev *dev <token> NULL; <answer> = 
u8 <token> <answer> pin; 
DBG(KERN_DEBUG <token> IRQ fixup\n"); <answer> "PCI: 
for_each_pci_dev(dev) <token> <answer> { 
if (dev->irq <token> 16) { <answer> >= 
<token> "ignoring bogus IRQ %d\n", dev->irq); <answer> dev_dbg(&dev->dev, 
<token> = 0; <answer> dev->irq 
if <token> >= 100 && <answer> (pirq_penalty[dev->irq] 
pirq_penalty[dev->irq] < <token> <answer> 100000) 
<token> = 0; <answer> pirq_penalty[dev->irq] 
<token> (io_apic_assign_pci_irqs) <answer> if 
<token> = NULL; <answer> dev 
for_each_pci_dev(dev) <token> <answer> { 
pci_read_config_byte(dev, PCI_INTERRUPT_PIN, <token> <answer> &pin); 
if <token> <answer> (!pin) 
if <token> <answer> (!dev->irq) 
<token> 0); <answer> pcibios_lookup_irq(dev, 
static int __init fix_broken_hp_bios_irq9(const <token> dmi_system_id *d) <answer> struct 
if <token> { <answer> (!broken_hp_bios_irq9) 
broken_hp_bios_irq9 = <token> <answer> 1; 
printk(KERN_INFO <token> detected - fixing broken IRQ routing\n", <answer> "%s 
<token> 0; <answer> return 
static int __init fix_acer_tm360_irqrouting(const <token> dmi_system_id *d) <answer> struct 
<token> (!acer_tm360_irqrouting) { <answer> if 
<token> = 1; <answer> acer_tm360_irqrouting 
printk(KERN_INFO "%s detected - fixing broken IRQ <token> <answer> routing\n", 
<token> 0; <answer> return 
static const <token> dmi_system_id pciirq_dmi_table[] __initconst = { <answer> struct 
.callback = <token> <answer> fix_broken_hp_bios_irq9, 
.ident = <token> Pavilion N5400 Series Laptop", <answer> "HP 
.matches <token> { <answer> = 
DMI_MATCH(DMI_SYS_VENDOR, <token> <answer> "Hewlett-Packard"), 
<token> "GE.M1.03"), <answer> DMI_MATCH(DMI_BIOS_VERSION, 
"HP Pavilion Notebook <token> GE"), <answer> Model 
DMI_MATCH(DMI_BOARD_VERSION, <token> N32N-736"), <answer> "OmniBook 
.callback = <token> <answer> fix_acer_tm360_irqrouting, 
.ident = "Acer TravelMate <token> Laptop", <answer> 36x 
.matches = <token> <answer> { 
DMI_MATCH(DMI_SYS_VENDOR, <token> <answer> "Acer"), 
DMI_MATCH(DMI_PRODUCT_NAME, <token> 360"), <answer> "TravelMate 
{ <token> <answer> } 
<token> __init pcibios_irq_init(void) <answer> void 
struct irq_routing_table *rtable <token> NULL; <answer> = 
DBG(KERN_DEBUG "PCI: IRQ <token> <answer> init\n"); 
if <token> == NULL) <answer> (raw_pci_ops 
pirq_table <token> pirq_find_routing_table(); <answer> = 
<token> CONFIG_PCI_BIOS <answer> #ifdef 
if <token> && (pci_probe & PCI_BIOS_IRQ_SCAN)) { <answer> (!pirq_table 
<token> = pcibios_get_irq_routing_table(); <answer> pirq_table 
<token> = pirq_table; <answer> rtable 
<token> (pirq_table) { <answer> if 
if (pirq_table->exclusive_irqs) <token> <answer> { 
int <token> <answer> i; 
for <token> = 0; i < 16; i++) <answer> (i 
if <token> & (1 << i))) <answer> (!(pirq_table->exclusive_irqs 
pirq_penalty[i] += <token> <answer> 100; 
<token> (io_apic_assign_pci_irqs) { <answer> if 
pirq_table = <token> <answer> NULL; 
if (io_apic_assign_pci_irqs <token> pci_routeirq) { <answer> && 
struct pci_dev *dev = <token> <answer> NULL; 
printk(KERN_INFO "PCI: <token> PCI interrupts for all devices because \"pci=routeirq\" specified\n"); <answer> Routing 
static void <token> irq, int active) <answer> pirq_penalize_isa_irq(int 
if (irq < 16) <token> <answer> { 
<token> (active) <answer> if 
pirq_penalty[irq] += <token> <answer> 1000; 
<token> += 100; <answer> pirq_penalty[irq] 
void pcibios_penalize_isa_irq(int irq, int <token> <answer> active) 
#ifdef <token> <answer> CONFIG_ACPI 
if <token> <answer> (!acpi_noirq) 
<token> active); <answer> acpi_penalize_isa_irq(irq, 
pirq_penalize_isa_irq(irq, <token> <answer> active); 
static int pirq_enable_irq(struct pci_dev <token> <answer> *dev) 
<token> pin = 0; <answer> u8 
pci_read_config_byte(dev, <token> &pin); <answer> PCI_INTERRUPT_PIN, 
<token> (pin && !pcibios_lookup_irq(dev, 1)) { <answer> if 
char *msg = <token> <answer> ""; 
if (!io_apic_assign_pci_irqs && <token> <answer> dev->irq) 
<token> 0; <answer> return 
if (io_apic_assign_pci_irqs) <token> <answer> { 
<token> CONFIG_X86_IO_APIC <answer> #ifdef 
<token> pci_dev *temp_dev; <answer> struct 
int <token> <answer> irq; 
<token> (dev->irq_managed && dev->irq > 0) <answer> if 
return <token> <answer> 0; 
<token> = IO_APIC_get_PCI_irq_vector(dev->bus->number, <answer> irq 
PCI_SLOT(dev->devfn), pin - <token> <answer> 1); 
temp_dev = <token> <answer> dev; 
if (dev->class >> 8 == <token> && <answer> PCI_CLASS_STORAGE_IDE 
!(dev->class & <token> <answer> 0x5)) 
return <token> <answer> 0; 
<token> "can't find IRQ for PCI INT %c%s\n", <answer> dev_warn(&dev->dev, 
'A' + pin <token> 1, msg); <answer> - 
return <token> <answer> 0; 
bool mp_should_keep_irq(struct <token> *dev) <answer> device 
<token> (dev->power.is_prepared) <answer> if 
return <token> <answer> true; 
<token> CONFIG_PM <answer> #ifdef 
if (dev->power.runtime_status == <token> <answer> RPM_SUSPENDING) 
<token> true; <answer> return 
<token> false; <answer> return 
static void <token> pci_dev *dev) <answer> pirq_disable_irq(struct 
if (io_apic_assign_pci_irqs && !mp_should_keep_irq(&dev->dev) <token> <answer> && 
dev->irq_managed && dev->irq) <token> <answer> { 
<token> = 0; <answer> dev->irq 
<token> = 0; <answer> dev->irq_managed 
#include <token> <answer> <errno.h> 
#include <token> <answer> <linux/bpf.h> 
<token> <linux/if_ether.h> <answer> #include 
#include <token> <answer> <linux/ip.h> 
#include <token> <answer> <bpf/bpf_helpers.h> 
struct <token> <answer> { 
<token> BPF_MAP_TYPE_ARRAY); <answer> __uint(type, 
<token> 1); <answer> __uint(max_entries, 
__type(key, <token> <answer> __u32); 
<token> __u32); <answer> __type(value, 
} <token> SEC(".maps"); <answer> test_result 
<token> load_bytes_relative(struct __sk_buff *skb) <answer> int 
<token> ethhdr eth; <answer> struct 
struct <token> iph; <answer> iphdr 
__u32 map_key = <token> <answer> 0; 
__u32 test_passed <token> 0; <answer> = 
#include <token> <answer> <linux/clk-provider.h> 
#include <token> <answer> <linux/export.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/string.h> 
#include <token> <answer> "clk.h" 
struct <token> { <answer> clk_gate2 
<token> clk_hw hw; <answer> struct 
<token> __iomem *reg; <answer> void 
u8 <token> <answer> bit_idx; 
<token> cgr_val; <answer> u8 
<token> cgr_mask; <answer> u8 
u8 <token> <answer> flags; 
<token> *lock; <answer> spinlock_t 
unsigned <token> *share_count; <answer> int 
#define to_clk_gate2(_hw) container_of(_hw, <token> clk_gate2, hw) <answer> struct 
static void clk_gate2_do_shared_clks(struct clk_hw *hw, bool <token> <answer> enable) 
struct <token> *gate = to_clk_gate2(hw); <answer> clk_gate2 
<token> reg; <answer> u32 
reg <token> readl(gate->reg); <answer> = 
reg &= ~(gate->cgr_mask << <token> <answer> gate->bit_idx); 
if <token> <answer> (enable) 
reg |= <token> & gate->cgr_mask) << gate->bit_idx; <answer> (gate->cgr_val 
<token> gate->reg); <answer> writel(reg, 
static int clk_gate2_enable(struct clk_hw <token> <answer> *hw) 
<token> clk_gate2 *gate = to_clk_gate2(hw); <answer> struct 
unsigned <token> flags; <answer> long 
<token> flags); <answer> spin_lock_irqsave(gate->lock, 
if (gate->share_count && (*gate->share_count)++ <token> 0) <answer> > 
goto <token> <answer> out; 
clk_gate2_do_shared_clks(hw, <token> <answer> true); 
spin_unlock_irqrestore(gate->lock, <token> <answer> flags); 
return <token> <answer> 0; 
<token> void clk_gate2_disable(struct clk_hw *hw) <answer> static 
struct clk_gate2 <token> = to_clk_gate2(hw); <answer> *gate 
unsigned <token> flags; <answer> long 
spin_lock_irqsave(gate->lock, <token> <answer> flags); 
if (gate->share_count) <token> <answer> { 
if (WARN_ON(*gate->share_count <token> 0)) <answer> == 
goto <token> <answer> out; 
else if <token> > 0) <answer> (--(*gate->share_count) 
<token> out; <answer> goto 
<token> false); <answer> clk_gate2_do_shared_clks(hw, 
spin_unlock_irqrestore(gate->lock, <token> <answer> flags); 
static <token> clk_gate2_reg_is_enabled(void __iomem *reg, u8 bit_idx, <answer> int 
u8 <token> u8 cgr_mask) <answer> cgr_val, 
u32 <token> = readl(reg); <answer> val 
if (((val >> bit_idx) & cgr_mask) == <token> <answer> cgr_val) 
return <token> <answer> 1; 
<token> 0; <answer> return 
static int clk_gate2_is_enabled(struct clk_hw <token> <answer> *hw) 
struct clk_gate2 <token> = to_clk_gate2(hw); <answer> *gate 
unsigned <token> flags; <answer> long 
int ret = <token> <answer> 0; 
spin_lock_irqsave(gate->lock, <token> <answer> flags); 
ret <token> clk_gate2_reg_is_enabled(gate->reg, gate->bit_idx, <answer> = 
<token> gate->cgr_mask); <answer> gate->cgr_val, 
<token> flags); <answer> spin_unlock_irqrestore(gate->lock, 
<token> ret; <answer> return 
static void clk_gate2_disable_unused(struct clk_hw <token> <answer> *hw) 
struct <token> *gate = to_clk_gate2(hw); <answer> clk_gate2 
unsigned long <token> <answer> flags; 
spin_lock_irqsave(gate->lock, <token> <answer> flags); 
if (!gate->share_count || <token> == 0) <answer> *gate->share_count 
clk_gate2_do_shared_clks(hw, <token> <answer> false); 
spin_unlock_irqrestore(gate->lock, <token> <answer> flags); 
<token> const struct clk_ops clk_gate2_ops = { <answer> static 
.enable <token> clk_gate2_enable, <answer> = 
.disable <token> clk_gate2_disable, <answer> = 
<token> = clk_gate2_disable_unused, <answer> .disable_unused 
.is_enabled <token> clk_gate2_is_enabled, <answer> = 
struct <token> *clk_hw_register_gate2(struct device *dev, const char *name, <answer> clk_hw 
const char *parent_name, unsigned long <token> <answer> flags, 
<token> __iomem *reg, u8 bit_idx, u8 cgr_val, u8 cgr_mask, <answer> void 
<token> clk_gate2_flags, spinlock_t *lock, <answer> u8 
unsigned int <token> <answer> *share_count) 
<token> clk_gate2 *gate; <answer> struct 
struct clk_hw <token> <answer> *hw; 
<token> clk_init_data init; <answer> struct 
int <token> <answer> ret; 
<token> = kzalloc(sizeof(struct clk_gate2), GFP_KERNEL); <answer> gate 
if <token> <answer> (!gate) 
return <token> <answer> ERR_PTR(-ENOMEM); 
<token> <linux/device.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
<token> <linux/pinctrl/pinctrl.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> "core.h" <answer> #include 
#include <token> <answer> "devicetree.h" 
struct pinctrl_dt_map <token> <answer> { 
struct list_head <token> <answer> node; 
struct <token> *pctldev; <answer> pinctrl_dev 
struct pinctrl_map <token> <answer> *map; 
unsigned <token> num_maps; <answer> int 
static void dt_free_map(struct <token> *pctldev, <answer> pinctrl_dev 
struct <token> *map, unsigned int num_maps) <answer> pinctrl_map 
<token> i; <answer> int 
for (i = 0; <token> < num_maps; ++i) { <answer> i 
map[i].dev_name = <token> <answer> NULL; 
if <token> { <answer> (pctldev) 
const <token> pinctrl_ops *ops = pctldev->desc->pctlops; <answer> struct 
if <token> <answer> (ops->dt_free_map) 
ops->dt_free_map(pctldev, map, <token> <answer> num_maps); 
<token> else { <answer> } 
ops <token> pctldev->desc->pctlops; <answer> = 
if (!ops->dt_node_to_map) <token> <answer> { 
dev_err(p->dev, "pctldev %s doesn't support <token> <answer> DT\n", 
<token> -ENODEV; <answer> return 
ret = ops->dt_node_to_map(pctldev, np_config, &map, <token> <answer> &num_maps); 
<token> (ret < 0) <answer> if 
return <token> <answer> ret; 
else if <token> == 0) { <answer> (num_maps 
"there is <token> valid maps for state %s\n", statename); <answer> not 
return <token> <answer> 0; 
if (ret < <token> <answer> 0) 
statename <token> prop->name + strlen("pinctrl-"); <answer> = 
<token> int pinctrl_find_cells_size(const struct device_node *np) <answer> static 
const char <token> = "#pinctrl-cells"; <answer> *cells_name 
int <token> error; <answer> cells_size, 
error = <token> cells_name, &cells_size); <answer> of_property_read_u32(np->parent, 
if (error) <token> <answer> { 
error <token> of_property_read_u32(np->parent->parent, <answer> = 
cells_name, <token> <answer> &cells_size); 
if <token> <answer> (error) 
return <token> <answer> -ENOENT; 
return <token> <answer> cells_size; 
static int <token> struct device_node *np, <answer> pinctrl_get_list_and_count(const 
const <token> *list_name, <answer> char 
const <token> **list, <answer> __be32 
<token> *cells_size, <answer> int 
<token> *nr_elements) <answer> int 
int <token> <answer> size; 
<token> = 0; <answer> *cells_size 
<token> = 0; <answer> *nr_elements 
<token> = of_get_property(np, list_name, &size); <answer> *list 
<token> (!*list) <answer> if 
return <token> <answer> -ENOENT; 
*cells_size = <token> <answer> pinctrl_find_cells_size(np); 
if <token> < 0) <answer> (*cells_size 
return <token> <answer> -ENOENT; 
int pinctrl_count_index_with_args(const struct <token> *np, <answer> device_node 
const char <token> <answer> *list_name) 
const __be32 <token> <answer> *list; 
int size, nr_cells, <token> <answer> error; 
error = pinctrl_get_list_and_count(np, list_name, <token> <answer> &list, 
&nr_cells, <token> <answer> &size); 
<token> (error) <answer> if 
<token> error; <answer> return 
return <token> <answer> size; 
static int pinctrl_copy_args(const <token> device_node *np, <answer> struct 
<token> __be32 *list, <answer> const 
int index, int nr_cells, <token> nr_elem, <answer> int 
<token> of_phandle_args *out_args) <answer> struct 
<token> i; <answer> int 
<token> 0, sizeof(*out_args)); <answer> memset(out_args, 
out_args->np = (struct <token> *)np; <answer> device_node 
<token> = nr_cells + 1; <answer> out_args->args_count 
<token> (index >= nr_elem) <answer> if 
<token> -EINVAL; <answer> return 
list += index * <token> + 1); <answer> (nr_cells 
for (i = 0; i < <token> + 1; i++) <answer> nr_cells 
out_args->args[i] <token> be32_to_cpup(list++); <answer> = 
<token> 0; <answer> return 
int pinctrl_parse_index_with_args(const struct <token> *np, <answer> device_node 
<token> char *list_name, int index, <answer> const 
struct <token> *out_args) <answer> of_phandle_args 
const <token> *list; <answer> __be32 
int nr_elem, nr_cells, <token> <answer> error; 
error = <token> list_name, &list, <answer> pinctrl_get_list_and_count(np, 
&nr_cells, <token> <answer> &nr_elem); 
if (error || <token> <answer> !nr_cells) 
return <token> <answer> error; 
error = pinctrl_copy_args(np, list, index, <token> nr_elem, <answer> nr_cells, 
<token> (error) <answer> if 
<token> error; <answer> return 
return <token> <answer> 0; 
#include <token> <answer> <linux/acpi.h> 
#include <token> <answer> <linux/bits.h> 
#include <token> <answer> <linux/freezer.h> 
#include <token> <answer> <linux/i2c.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/kthread.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/types.h> 
#include <token> <answer> <linux/uuid.h> 
#include <token> <answer> <asm/unaligned.h> 
#define <token> (2 * HZ) <answer> SURFACE_3_POLL_INTERVAL 
#define SURFACE_3_STRLEN <token> <answer> 10 
struct <token> { <answer> mshw0011_data 
<token> i2c_client *adp1; <answer> struct 
struct i2c_client <token> <answer> *bat0; 
unsigned <token> notify_mask; <answer> short 
struct task_struct <token> <answer> *poll_task; 
bool <token> <answer> kthread_running; 
bool <token> <answer> charging; 
bool <token> <answer> bat_charging; 
u8 <token> <answer> trip_point; 
<token> full_capacity; <answer> s32 
<token> mshw0011_handler_data { <answer> struct 
struct acpi_connection_info <token> <answer> info; 
<token> i2c_client *client; <answer> struct 
<token> bix { <answer> struct 
u32 <token> <answer> revision; 
u32 <token> <answer> power_unit; 
<token> design_capacity; <answer> u32 
u32 <token> <answer> last_full_charg_capacity; 
<token> battery_technology; <answer> u32 
u32 <token> <answer> design_voltage; 
u32 <token> <answer> design_capacity_of_warning; 
<token> design_capacity_of_low; <answer> u32 
<token> cycle_count; <answer> u32 
u32 <token> <answer> measurement_accuracy; 
<token> max_sampling_time; <answer> u32 
u32 <token> <answer> min_sampling_time; 
<token> max_average_interval; <answer> u32 
u32 <token> <answer> min_average_interval; 
<token> battery_capacity_granularity_1; <answer> u32 
<token> battery_capacity_granularity_2; <answer> u32 
<token> model[SURFACE_3_STRLEN]; <answer> char 
<token> serial[SURFACE_3_STRLEN]; <answer> char 
<token> type[SURFACE_3_STRLEN]; <answer> char 
char <token> <answer> OEM[SURFACE_3_STRLEN]; 
} <token> <answer> __packed; 
struct bst <token> <answer> { 
u32 <token> <answer> battery_state; 
<token> battery_present_rate; <answer> s32 
<token> battery_remaining_capacity; <answer> u32 
u32 <token> <answer> battery_present_voltage; 
} <token> <answer> __packed; 
struct <token> { <answer> gsb_command 
<token> arg0; <answer> u8 
u8 <token> <answer> arg1; 
<token> arg2; <answer> u8 
} <token> <answer> __packed; 
struct <token> { <answer> gsb_buffer 
<token> status; <answer> u8 
<token> len; <answer> u8 
<token> ret; <answer> u8 
union <token> <answer> { 
struct gsb_command <token> <answer> cmd; 
struct <token> bst; <answer> bst 
<token> bix bix; <answer> struct 
<token> __packed; <answer> } 
<token> __packed; <answer> } 
<token> ACPI_BATTERY_STATE_DISCHARGING BIT(0) <answer> #define 
#define <token> BIT(1) <answer> ACPI_BATTERY_STATE_CHARGING 
#define ACPI_BATTERY_STATE_CRITICAL <token> <answer> BIT(2) 
#define <token> 0x01 <answer> MSHW0011_CMD_DEST_BAT0 
#define <token> 0x03 <answer> MSHW0011_CMD_DEST_ADP1 
#define <token> 0x01 <answer> MSHW0011_CMD_BAT0_STA 
<token> MSHW0011_CMD_BAT0_BIX 0x02 <answer> #define 
#define <token> 0x03 <answer> MSHW0011_CMD_BAT0_BCT 
<token> MSHW0011_CMD_BAT0_BTM 0x04 <answer> #define 
#define <token> 0x05 <answer> MSHW0011_CMD_BAT0_BST 
#define <token> 0x06 <answer> MSHW0011_CMD_BAT0_BTP 
<token> MSHW0011_CMD_ADP1_PSR 0x07 <answer> #define 
#define <token> 0x09 <answer> MSHW0011_CMD_BAT0_PSOC 
#define MSHW0011_CMD_BAT0_PMAX <token> <answer> 0x0a 
#define MSHW0011_CMD_BAT0_PSRC <token> <answer> 0x0b 
#define <token> 0x0c <answer> MSHW0011_CMD_BAT0_CHGI 
#define MSHW0011_CMD_BAT0_ARTG <token> <answer> 0x0d 
#define MSHW0011_NOTIFY_GET_VERSION <token> <answer> 0x00 
#define MSHW0011_NOTIFY_ADP1 <token> <answer> 0x01 
#define MSHW0011_NOTIFY_BAT0_BST <token> <answer> 0x02 
#define <token> 0x05 <answer> MSHW0011_NOTIFY_BAT0_BIX 
#define <token> 0x04 <answer> MSHW0011_ADP1_REG_PSR 
#define <token> 0x0c <answer> MSHW0011_BAT0_REG_CAPACITY 
#define <token> 0x0e <answer> MSHW0011_BAT0_REG_FULL_CHG_CAPACITY 
#define MSHW0011_BAT0_REG_DESIGN_CAPACITY <token> <answer> 0x40 
<token> MSHW0011_BAT0_REG_VOLTAGE 0x08 <answer> #define 
#define <token> 0x14 <answer> MSHW0011_BAT0_REG_RATE 
#define <token> 0x45 <answer> MSHW0011_BAT0_REG_OEM 
#define <token> 0x4e <answer> MSHW0011_BAT0_REG_TYPE 
#define <token> 0x56 <answer> MSHW0011_BAT0_REG_SERIAL_NO 
<token> MSHW0011_BAT0_REG_CYCLE_CNT 0x6e <answer> #define 
#define MSHW0011_EV_2_5_MASK GENMASK(8, <token> <answer> 0) 
ret <token> i2c_smbus_read_i2c_block_data(client, MSHW0011_BAT0_REG_SERIAL_NO, <answer> = 
sizeof(buf), <token> <answer> buf); 
if <token> == -EREMOTEIO) { <answer> (ret 
<token> <asm/unaligned.h> <answer> #include 
#include <token> <answer> "carl9170.h" 
#include <token> <answer> "cmd.h" 
<token> carl9170_set_dyn_sifs_ack(struct ar9170 *ar) <answer> int 
<token> val; <answer> u32 
if <token> <answer> (conf_is_ht40(&ar->hw->conf)) 
val <token> 0x010a; <answer> = 
<token> { <answer> else 
<token> (ar->hw->conf.chandef.chan->band == NL80211_BAND_2GHZ) <answer> if 
val = <token> <answer> 0x105; 
<token> = 0x104; <answer> val 
return carl9170_write_reg(ar, AR9170_MAC_REG_DYNAMIC_SIFS_ACK, <token> <answer> val); 
<token> carl9170_set_rts_cts_rate(struct ar9170 *ar) <answer> int 
u32 <token> cts_rate; <answer> rts_rate, 
<token> (conf_is_ht(&ar->hw->conf)) { <answer> if 
cam_mode |= <token> <answer> AR9170_MAC_CAM_STA; 
<token> |= AR9170_MAC_RX_CTRL_PASS_TO_HOST; <answer> rx_ctrl 
mac_addr <token> common->macaddr; <answer> = 
bssid <token> NULL; <answer> = 
if <token> <answer> (err) 
return <token> <answer> err; 
<token> (ar->rx_software_decryption) <answer> if 
enc_mode <token> AR9170_MAC_ENCRYPTION_RX_SOFTWARE; <answer> |= 
if <token> { <answer> (ar->sniffer_enabled) 
enc_mode |= <token> <answer> AR9170_MAC_ENCRYPTION_RX_SOFTWARE; 
err = carl9170_set_mac_reg(ar, AR9170_MAC_REG_MAC_ADDR_L, <token> <answer> mac_addr); 
<token> (err) <answer> if 
<token> err; <answer> return 
err = carl9170_set_mac_reg(ar, AR9170_MAC_REG_BSSID_L, <token> <answer> bssid); 
if <token> <answer> (err) 
return <token> <answer> err; 
carl9170_regwrite(AR9170_MAC_REG_SNIFFER, <token> <answer> sniffer); 
<token> cam_mode); <answer> carl9170_regwrite(AR9170_MAC_REG_CAM_MODE, 
<token> enc_mode); <answer> carl9170_regwrite(AR9170_MAC_REG_ENCRYPTION, 
<token> rx_ctrl); <answer> carl9170_regwrite(AR9170_MAC_REG_RX_CONTROL, 
return <token> <answer> carl9170_regwrite_result(); 
<token> carl9170_set_hwretry_limit(struct ar9170 *ar, const unsigned int max_retry) <answer> int 
u32 tmp <token> min_t(u32, 0x33333, max_retry * 0x11111); <answer> = 
return <token> AR9170_MAC_REG_RETRY_MAX, tmp); <answer> carl9170_write_reg(ar, 
int carl9170_set_beacon_timers(struct <token> *ar) <answer> ar9170 
<token> ieee80211_vif *vif; <answer> struct 
u32 <token> = 0; <answer> v 
<token> pretbtt = 0; <answer> u32 
<token> = carl9170_get_main_vif(ar); <answer> vif 
if (vif) <token> <answer> { 
struct <token> *mvif; <answer> carl9170_vif_info 
mvif <token> (void *) vif->drv_priv; <answer> = 
if (mvif->enable_beacon <token> !WARN_ON(!ar->beacon_enabled)) { <answer> && 
ar->global_beacon_int = vif->bss_conf.beacon_int <token> <answer> / 
SET_VAL(AR9170_MAC_BCN_DTIM, <token> <answer> v, 
switch (vif->type) <token> <answer> { 
<token> NL80211_IFTYPE_MESH_POINT: <answer> case 
<token> NL80211_IFTYPE_ADHOC: <answer> case 
<token> |= AR9170_MAC_BCN_IBSS_MODE; <answer> v 
case <token> <answer> NL80211_IFTYPE_AP: 
v <token> AR9170_MAC_BCN_AP_MODE; <answer> |= 
} else <token> (vif->type == NL80211_IFTYPE_STATION) { <answer> if 
ar->global_beacon_int <token> vif->bss_conf.beacon_int; <answer> = 
<token> v, <answer> SET_VAL(AR9170_MAC_BCN_DTIM, 
<token> |= AR9170_MAC_BCN_STA_PS | <answer> v 
if (ar->global_beacon_int) <token> <answer> { 
if (ar->global_beacon_int < 15) <token> <answer> { 
return <token> <answer> -ERANGE; 
ar->global_pretbtt = ar->global_beacon_int <token> <answer> - 
} <token> { <answer> else 
ar->global_pretbtt = <token> <answer> 0; 
} else <token> <answer> { 
ar->global_beacon_int <token> 0; <answer> = 
<token> = 0; <answer> ar->global_pretbtt 
<token> v, ar->global_beacon_int); <answer> SET_VAL(AR9170_MAC_BCN_PERIOD, 
SET_VAL(AR9170_MAC_PRETBTT, pretbtt, <token> <answer> ar->global_pretbtt); 
SET_VAL(AR9170_MAC_PRETBTT2, <token> ar->global_pretbtt); <answer> pretbtt, 
carl9170_regwrite(AR9170_MAC_REG_PRETBTT, <token> <answer> pretbtt); 
<token> v); <answer> carl9170_regwrite(AR9170_MAC_REG_BCN_PERIOD, 
<token> carl9170_regwrite_result(); <answer> return 
int carl9170_upload_key(struct ar9170 *ar, const <token> id, const u8 *mac, <answer> u8 
const u8 ktype, const u8 keyidx, const u8 <token> <answer> *keydata, 
<token> int keylen) <answer> const 
struct carl9170_set_key_cmd key = { <token> <answer> }; 
static const u8 <token> = { <answer> bcast[ETH_ALEN] 
0xff, <token> 0xff, 0xff, 0xff, 0xff }; <answer> 0xff, 
mac = <token> ? : bcast; <answer> mac 
<token> = cpu_to_le16(id); <answer> key.user 
<token> = cpu_to_le16(keyidx); <answer> key.keyId 
key.type = <token> <answer> cpu_to_le16(ktype); 
<token> mac, ETH_ALEN); <answer> memcpy(&key.macAddr, 
if <token> <answer> (keydata) 
memcpy(&key.key, <token> keylen); <answer> keydata, 
return <token> CARL9170_CMD_EKEY, <answer> carl9170_exec_cmd(ar, 
sizeof(key), (u8 *)&key, <token> NULL); <answer> 0, 
int carl9170_disable_key(struct ar9170 *ar, const u8 <token> <answer> id) 
struct carl9170_disable_key_cmd key = <token> }; <answer> { 
key.user = <token> <answer> cpu_to_le16(id); 
return <token> CARL9170_CMD_DKEY, <answer> carl9170_exec_cmd(ar, 
sizeof(key), <token> *)&key, 0, NULL); <answer> (u8 
int carl9170_set_mac_tpc(struct ar9170 *ar, struct ieee80211_channel <token> <answer> *channel) 
unsigned int <token> chains; <answer> power, 
if (ar->eeprom.tx_mask <token> 1) <answer> != 
<token> = AR9170_TX_PHY_TXCHAIN_2; <answer> chains 
chains = <token> <answer> AR9170_TX_PHY_TXCHAIN_1; 
<token> (channel->band) { <answer> switch 
case <token> <answer> NL80211_BAND_2GHZ: 
<token> = ar->power_2G_ofdm[0] & 0x3f; <answer> power 
<token> NL80211_BAND_5GHZ: <answer> case 
power <token> ar->power_5G_leg[0] & 0x3f; <answer> = 
power = min_t(unsigned <token> power, ar->hw->conf.power_level * 2); <answer> int, 
0x3c1e | power << <token> | chains << 26); <answer> 20 
power << 5 <token> chains << 11 | <answer> | 
power << 21 | chains << <token> <answer> 27); 
<token> << 5 | chains << 11 | <answer> power 
power <token> 21 | chains << 27); <answer> << 
return <token> <answer> carl9170_regwrite_result(); 
spec <token> kvzalloc(sizeof(*spec), GFP_KERNEL); <answer> = 
if <token> <answer> (!spec) 
<token> -ENOMEM; <answer> return 
MLX5_SET(create_flow_group_in, <token> start_flow_index, flow_index); <answer> flow_group_in, 
MLX5_SET(create_flow_group_in, flow_group_in, end_flow_index, <token> <answer> flow_index); 
g = mlx5_create_flow_group(vport->ingress.acl, <token> <answer> flow_group_in); 
if (IS_ERR(g)) <token> <answer> { 
<token> = PTR_ERR(g); <answer> ret 
esw_warn(esw->dev, "vport[%d] ingress create drop flow <token> err(%d)\n", <answer> group, 
<token> ret); <answer> vport->vport, 
goto <token> <answer> drop_err; 
vport->ingress.offloads.drop_grp <token> g; <answer> = 
if <token> vport)) { <answer> (esw_acl_ingress_prio_tag_enabled(esw, 
memset(flow_group_in, 0, <token> <answer> inlen); 
match_criteria = <token> <answer> MLX5_ADDR_OF(create_flow_group_in, 
<token> match_criteria); <answer> flow_group_in, 
<token> flow_group_in, <answer> MLX5_SET(create_flow_group_in, 
<token> MLX5_MATCH_OUTER_HEADERS); <answer> match_criteria_enable, 
<token> match_criteria, outer_headers.cvlan_tag); <answer> MLX5_SET_TO_ONES(fte_match_param, 
MLX5_SET(create_flow_group_in, flow_group_in, start_flow_index, <token> <answer> flow_index); 
MLX5_SET(create_flow_group_in, flow_group_in, end_flow_index, <token> <answer> flow_index); 
g = <token> flow_group_in); <answer> mlx5_create_flow_group(vport->ingress.acl, 
<token> (IS_ERR(g)) { <answer> if 
<token> = PTR_ERR(g); <answer> ret 
esw_warn(esw->dev, "vport[%d] ingress create untagged flow group, <token> <answer> err(%d)\n", 
vport->vport, <token> <answer> ret); 
<token> prio_tag_err; <answer> goto 
<token> = g; <answer> vport->ingress.offloads.metadata_prio_tag_grp 
if (mlx5_eswitch_vport_match_metadata_enabled(esw)) <token> <answer> { 
<token> 0, inlen); <answer> memset(flow_group_in, 
<token> flow_group_in, start_flow_index, flow_index); <answer> MLX5_SET(create_flow_group_in, 
MLX5_SET(create_flow_group_in, flow_group_in, <token> flow_index); <answer> end_flow_index, 
g <token> mlx5_create_flow_group(vport->ingress.acl, flow_group_in); <answer> = 
if <token> { <answer> (IS_ERR(g)) 
<token> = PTR_ERR(g); <answer> ret 
esw_warn(esw->dev, "vport[%d] ingress create drop <token> group, err(%d)\n", <answer> flow 
<token> ret); <answer> vport->vport, 
goto <token> <answer> metadata_err; 
<token> = g; <answer> vport->ingress.offloads.metadata_allmatch_grp 
<token> 0; <answer> return 
if <token> { <answer> (!IS_ERR_OR_NULL(vport->ingress.offloads.metadata_prio_tag_grp)) 
<token> = NULL; <answer> vport->ingress.offloads.metadata_prio_tag_grp 
if (!IS_ERR_OR_NULL(vport->ingress.offloads.drop_grp)) <token> <answer> { 
<token> = NULL; <answer> vport->ingress.offloads.drop_grp 
<token> ret; <answer> return 
static void <token> mlx5_vport *vport) <answer> esw_acl_ingress_ofld_groups_destroy(struct 
<token> (vport->ingress.offloads.metadata_allmatch_grp) { <answer> if 
vport->ingress.offloads.metadata_allmatch_grp = <token> <answer> NULL; 
if (vport->ingress.offloads.metadata_prio_tag_grp) <token> <answer> { 
<token> = NULL; <answer> vport->ingress.offloads.metadata_prio_tag_grp 
if (vport->ingress.offloads.drop_grp) <token> <answer> { 
vport->ingress.offloads.drop_grp = <token> <answer> NULL; 
int esw_acl_ingress_ofld_setup(struct <token> *esw, <answer> mlx5_eswitch 
<token> mlx5_vport *vport) <answer> struct 
int <token> = 0; <answer> num_ftes 
int <token> <answer> err; 
<token> (!mlx5_eswitch_vport_match_metadata_enabled(esw) && <answer> if 
!esw_acl_ingress_prio_tag_enabled(esw, <token> <answer> vport)) 
<token> 0; <answer> return 
if <token> <answer> (mlx5_eswitch_vport_match_metadata_enabled(esw)) 
<token> (vport->vport == MLX5_VPORT_UPLINK) <answer> if 
if (esw_acl_ingress_prio_tag_enabled(esw, <token> <answer> vport)) 
vport->ingress.acl = <token> vport, <answer> esw_acl_table_create(esw, 
if (IS_ERR(vport->ingress.acl)) <token> <answer> { 
err <token> PTR_ERR(vport->ingress.acl); <answer> = 
vport->ingress.acl <token> NULL; <answer> = 
return <token> <answer> err; 
err <token> esw_acl_ingress_ofld_groups_create(esw, vport); <answer> = 
if <token> <answer> (err) 
<token> group_err; <answer> goto 
"vport[%d] configure ingress <token> vport->vport); <answer> rules\n", 
err <token> esw_acl_ingress_ofld_rules_create(esw, vport); <answer> = 
<token> (err) <answer> if 
goto <token> <answer> rules_err; 
return <token> <answer> 0; 
<token> err; <answer> return 
void esw_acl_ingress_ofld_cleanup(struct mlx5_eswitch <token> <answer> *esw, 
struct <token> *vport) <answer> mlx5_vport 
esw_acl_ingress_ofld_rules_destroy(esw, <token> <answer> vport); 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/mfd/core.h> <answer> #include 
#include <token> <answer> <linux/mfd/rsmu.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/of.h> 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/spi/spi.h> <answer> #include 
#include <token> <answer> "rsmu.h" 
<token> RSMU_CM_PAGE_ADDR 0x7C <answer> #define 
<token> RSMU_SABRE_PAGE_ADDR 0x7F <answer> #define 
<token> RSMU_PAGE_MASK 0xFFFFFF80 <answer> #define 
#define RSMU_ADDR_MASK <token> <answer> 0x7F 
static int rsmu_read_device(struct rsmu_ddata *rsmu, u8 reg, u8 <token> u16 bytes) <answer> *buf, 
struct spi_device *client <token> to_spi_device(rsmu->dev); <answer> = 
struct spi_transfer xfer <token> {0}; <answer> = 
<token> spi_message msg; <answer> struct 
<token> cmd[RSMU_MAX_READ_COUNT + 1] = {0}; <answer> u8 
u8 rsp[RSMU_MAX_READ_COUNT <token> 1] = {0}; <answer> + 
<token> ret; <answer> int 
if (bytes > <token> <answer> RSMU_MAX_READ_COUNT) 
<token> -EINVAL; <answer> return 
cmd[0] = <token> | 0x80; <answer> reg 
<token> = rsp; <answer> xfer.rx_buf 
xfer.len = bytes <token> 1; <answer> + 
<token> = cmd; <answer> xfer.tx_buf 
xfer.bits_per_word = <token> <answer> client->bits_per_word; 
xfer.speed_hz <token> client->max_speed_hz; <answer> = 
<token> &msg); <answer> spi_message_add_tail(&xfer, 
ret <token> spi_sync(client, &msg); <answer> = 
<token> (ret >= 0) <answer> if 
<token> &rsp[1], xfer.len-1); <answer> memcpy(buf, 
return <token> <answer> ret; 
static <token> rsmu_write_device(struct rsmu_ddata *rsmu, u8 reg, u8 *buf, u16 bytes) <answer> int 
struct <token> *client = to_spi_device(rsmu->dev); <answer> spi_device 
struct spi_transfer xfer <token> {0}; <answer> = 
<token> spi_message msg; <answer> struct 
u8 cmd[RSMU_MAX_WRITE_COUNT + 1] = <token> <answer> {0}; 
if (bytes > <token> <answer> RSMU_MAX_WRITE_COUNT) 
return <token> <answer> -EINVAL; 
cmd[0] = <token> <answer> reg; 
<token> buf, bytes); <answer> memcpy(&cmd[1], 
<token> = bytes + 1; <answer> xfer.len 
xfer.tx_buf <token> cmd; <answer> = 
xfer.bits_per_word <token> client->bits_per_word; <answer> = 
<token> = client->max_speed_hz; <answer> xfer.speed_hz 
spi_message_add_tail(&xfer, <token> <answer> &msg); 
return spi_sync(client, <token> <answer> &msg); 
static int <token> rsmu_ddata *rsmu, u32 reg) <answer> rsmu_write_page_register(struct 
u8 <token> <answer> page_reg; 
u8 <token> <answer> buf[4]; 
u16 <token> <answer> bytes; 
u32 <token> <answer> page; 
int <token> <answer> err; 
switch <token> { <answer> (rsmu->type) 
case <token> <answer> RSMU_CM: 
#include <token> <answer> <linux/configfs.h> 
#include <token> <answer> <linux/export.h> 
<token> <scsi/iscsi_proto.h> <answer> #include 
<token> <target/target_core_base.h> <answer> #include 
<token> <target/iscsi/iscsi_target_core.h> <answer> #include 
#include <token> <answer> "iscsi_target_parameters.h" 
#include <token> <answer> "iscsi_target_device.h" 
<token> "iscsi_target_tpg.h" <answer> #include 
<token> "iscsi_target_util.h" <answer> #include 
#include <token> <answer> <target/iscsi/iscsi_target_stat.h> 
<token> INITIAL_JIFFIES <answer> #ifndef 
#define <token> ((unsigned long)(unsigned int) (-300*HZ)) <answer> INITIAL_JIFFIES 
static struct <token> *iscsi_instance_tiqn(struct config_item *item) <answer> iscsi_tiqn 
struct iscsi_wwn_stat_grps *igrps <token> container_of(to_config_group(item), <answer> = 
struct <token> iscsi_instance_group); <answer> iscsi_wwn_stat_grps, 
return <token> struct iscsi_tiqn, tiqn_stat_grps); <answer> container_of(igrps, 
static <token> iscsi_stat_instance_inst_show(struct config_item *item, <answer> ssize_t 
char <token> <answer> *page) 
return snprintf(page, PAGE_SIZE, <token> <answer> "%u\n", 
static ssize_t iscsi_stat_instance_min_ver_show(struct config_item <token> <answer> *item, 
char <token> <answer> *page) 
return <token> PAGE_SIZE, "%u\n", ISCSI_DRAFT20_VERSION); <answer> snprintf(page, 
static ssize_t <token> config_item *item, <answer> iscsi_stat_instance_max_ver_show(struct 
char <token> <answer> *page) 
return <token> PAGE_SIZE, "%u\n", ISCSI_DRAFT20_VERSION); <answer> snprintf(page, 
static ssize_t <token> config_item *item, <answer> iscsi_stat_instance_portals_show(struct 
<token> *page) <answer> char 
return <token> PAGE_SIZE, "%u\n", <answer> snprintf(page, 
static <token> iscsi_stat_instance_nodes_show(struct config_item *item, <answer> ssize_t 
<token> *page) <answer> char 
<token> snprintf(page, PAGE_SIZE, "%u\n", ISCSI_INST_NUM_NODES); <answer> return 
static ssize_t iscsi_stat_instance_sessions_show(struct <token> *item, <answer> config_item 
<token> *page) <answer> char 
<token> snprintf(page, PAGE_SIZE, "%u\n", <answer> return 
static <token> iscsi_stat_instance_fail_sess_show(struct config_item *item, <answer> ssize_t 
<token> *page) <answer> char 
<token> iscsi_tiqn *tiqn = iscsi_instance_tiqn(item); <answer> struct 
struct iscsi_sess_err_stats *sess_err = <token> <answer> &tiqn->sess_err_stats; 
u32 <token> <answer> sess_err_count; 
sess_err_count = <token> + <answer> (sess_err->digest_errors 
sess_err->cxn_timeout_errors <token> <answer> + 
<token> snprintf(page, PAGE_SIZE, "%u\n", sess_err_count); <answer> return 
<token> ssize_t iscsi_stat_instance_fail_type_show(struct config_item *item, <answer> static 
<token> *page) <answer> char 
struct iscsi_tiqn *tiqn <token> iscsi_instance_tiqn(item); <answer> = 
struct iscsi_sess_err_stats *sess_err = <token> <answer> &tiqn->sess_err_stats; 
return snprintf(page, <token> "%u\n", <answer> PAGE_SIZE, 
static ssize_t <token> config_item *item, <answer> iscsi_stat_instance_fail_rem_name_show(struct 
char <token> <answer> *page) 
struct iscsi_tiqn *tiqn = <token> <answer> iscsi_instance_tiqn(item); 
<token> iscsi_sess_err_stats *sess_err = &tiqn->sess_err_stats; <answer> struct 
return <token> PAGE_SIZE, "%s\n", <answer> snprintf(page, 
sess_err->last_sess_fail_rem_name[0] <token> <answer> ? 
sess_err->last_sess_fail_rem_name <token> NONE); <answer> : 
static ssize_t iscsi_stat_instance_disc_time_show(struct <token> *item, <answer> config_item 
<token> *page) <answer> char 
return <token> PAGE_SIZE, "%u\n", ISCSI_DISCONTINUITY_TIME); <answer> snprintf(page, 
static <token> iscsi_stat_instance_description_show(struct config_item *item, <answer> ssize_t 
<token> *page) <answer> char 
<token> snprintf(page, PAGE_SIZE, "%s\n", ISCSI_INST_DESCR); <answer> return 
<token> ssize_t iscsi_stat_instance_vendor_show(struct config_item *item, <answer> static 
char <token> <answer> *page) 
<token> snprintf(page, PAGE_SIZE, "Datera, Inc. iSCSI-Target\n"); <answer> return 
static <token> iscsi_stat_instance_version_show(struct config_item *item, <answer> ssize_t 
char <token> <answer> *page) 
return snprintf(page, PAGE_SIZE, "%s\n", <token> <answer> ISCSIT_VERSION); 
CONFIGFS_ATTR_RO(iscsi_stat_instance_, <token> <answer> inst); 
<token> min_ver); <answer> CONFIGFS_ATTR_RO(iscsi_stat_instance_, 
CONFIGFS_ATTR_RO(iscsi_stat_instance_, <token> <answer> max_ver); 
<token> portals); <answer> CONFIGFS_ATTR_RO(iscsi_stat_instance_, 
CONFIGFS_ATTR_RO(iscsi_stat_instance_, <token> <answer> nodes); 
CONFIGFS_ATTR_RO(iscsi_stat_instance_, <token> <answer> sessions); 
CONFIGFS_ATTR_RO(iscsi_stat_instance_, <token> <answer> fail_sess); 
CONFIGFS_ATTR_RO(iscsi_stat_instance_, <token> <answer> fail_type); 
<token> fail_rem_name); <answer> CONFIGFS_ATTR_RO(iscsi_stat_instance_, 
<token> disc_time); <answer> CONFIGFS_ATTR_RO(iscsi_stat_instance_, 
<token> description); <answer> CONFIGFS_ATTR_RO(iscsi_stat_instance_, 
<token> vendor); <answer> CONFIGFS_ATTR_RO(iscsi_stat_instance_, 
CONFIGFS_ATTR_RO(iscsi_stat_instance_, <token> <answer> version); 
<token> struct configfs_attribute *iscsi_stat_instance_attrs[] = { <answer> static 
const struct config_item_type iscsi_stat_instance_cit = <token> <answer> { 
.ct_attrs = <token> <answer> iscsi_stat_instance_attrs, 
<token> = THIS_MODULE, <answer> .ct_owner 
static struct iscsi_tiqn <token> config_item *item) <answer> *iscsi_sess_err_tiqn(struct 
<token> iscsi_wwn_stat_grps *igrps = container_of(to_config_group(item), <answer> struct 
<token> iscsi_wwn_stat_grps, iscsi_sess_err_group); <answer> struct 
return container_of(igrps, struct iscsi_tiqn, <token> <answer> tiqn_stat_grps); 
static ssize_t <token> config_item *item, <answer> iscsi_stat_sess_err_inst_show(struct 
char <token> <answer> *page) 
return snprintf(page, PAGE_SIZE, <token> <answer> "%u\n", 
static <token> iscsi_stat_sess_err_digest_errors_show(struct config_item *item, <answer> ssize_t 
char <token> <answer> *page) 
struct iscsi_tiqn <token> = iscsi_sess_err_tiqn(item); <answer> *tiqn 
<token> iscsi_sess_err_stats *sess_err = &tiqn->sess_err_stats; <answer> struct 
return <token> PAGE_SIZE, "%u\n", sess_err->digest_errors); <answer> snprintf(page, 
<token> ssize_t iscsi_stat_sess_err_cxn_errors_show(struct config_item *item, <answer> static 
char <token> <answer> *page) 
struct iscsi_tiqn *tiqn = <token> <answer> iscsi_sess_err_tiqn(item); 
struct iscsi_sess_err_stats *sess_err = <token> <answer> &tiqn->sess_err_stats; 
return snprintf(page, <token> "%u\n", sess_err->cxn_timeout_errors); <answer> PAGE_SIZE, 
<token> ssize_t iscsi_stat_sess_err_format_errors_show(struct config_item *item, <answer> static 
<token> *page) <answer> char 
struct iscsi_tiqn <token> = iscsi_sess_err_tiqn(item); <answer> *tiqn 
struct iscsi_sess_err_stats *sess_err <token> &tiqn->sess_err_stats; <answer> = 
return snprintf(page, <token> "%u\n", sess_err->pdu_format_errors); <answer> PAGE_SIZE, 
CONFIGFS_ATTR_RO(iscsi_stat_sess_err_, <token> <answer> inst); 
CONFIGFS_ATTR_RO(iscsi_stat_sess_err_, <token> <answer> digest_errors); 
<token> cxn_errors); <answer> CONFIGFS_ATTR_RO(iscsi_stat_sess_err_, 
CONFIGFS_ATTR_RO(iscsi_stat_sess_err_, <token> <answer> format_errors); 
static struct configfs_attribute *iscsi_stat_sess_err_attrs[] = <token> <answer> { 
const struct config_item_type iscsi_stat_sess_err_cit <token> { <answer> = 
<token> = iscsi_stat_sess_err_attrs, <answer> .ct_attrs 
<token> = THIS_MODULE, <answer> .ct_owner 
static struct iscsi_tiqn *iscsi_tgt_attr_tiqn(struct config_item <token> <answer> *item) 
struct iscsi_wwn_stat_grps *igrps <token> container_of(to_config_group(item), <answer> = 
struct iscsi_wwn_stat_grps, <token> <answer> iscsi_tgt_attr_group); 
return container_of(igrps, <token> iscsi_tiqn, tiqn_stat_grps); <answer> struct 
<token> ssize_t iscsi_stat_tgt_attr_inst_show(struct config_item *item, <answer> static 
char <token> <answer> *page) 
return snprintf(page, <token> "%u\n", <answer> PAGE_SIZE, 
<token> ssize_t iscsi_stat_tgt_attr_indx_show(struct config_item *item, <answer> static 
<token> *page) <answer> char 
<token> snprintf(page, PAGE_SIZE, "%u\n", ISCSI_NODE_INDEX); <answer> return 
static <token> iscsi_stat_tgt_attr_login_fails_show(struct config_item *item, <answer> ssize_t 
<token> *page) <answer> char 
struct iscsi_tiqn <token> = iscsi_tgt_attr_tiqn(item); <answer> *tiqn 
struct <token> *lstat = &tiqn->login_stats; <answer> iscsi_login_stats 
u32 <token> <answer> fail_count; 
<token> = (lstat->redirects + lstat->authorize_fails + <answer> fail_count 
<token> + lstat->negotiate_fails + <answer> lstat->authenticate_fails 
return snprintf(page, PAGE_SIZE, "%u\n", <token> <answer> fail_count); 
static ssize_t iscsi_stat_tgt_attr_last_fail_time_show(struct config_item <token> <answer> *item, 
<token> *page) <answer> char 
<token> iscsi_tiqn *tiqn = iscsi_tgt_attr_tiqn(item); <answer> struct 
struct iscsi_login_stats <token> = &tiqn->login_stats; <answer> *lstat 
<token> last_fail_time; <answer> u32 
last_fail_time = <token> ? <answer> lstat->last_fail_time 
<token> - <answer> (u32)(((u32)lstat->last_fail_time 
INITIAL_JIFFIES) * 100 / HZ) <token> 0; <answer> : 
return snprintf(page, PAGE_SIZE, <token> last_fail_time); <answer> "%u\n", 
static ssize_t iscsi_stat_tgt_attr_last_fail_type_show(struct config_item <token> <answer> *item, 
char <token> <answer> *page) 
struct <token> *tiqn = iscsi_tgt_attr_tiqn(item); <answer> iscsi_tiqn 
<token> iscsi_login_stats *lstat = &tiqn->login_stats; <answer> struct 
u32 <token> <answer> last_fail_type; 
<token> = lstat->last_fail_type; <answer> last_fail_type 
<token> snprintf(page, PAGE_SIZE, "%u\n", last_fail_type); <answer> return 
static ssize_t iscsi_stat_tgt_attr_fail_intr_name_show(struct <token> *item, <answer> config_item 
<token> *page) <answer> char 
struct iscsi_tiqn *tiqn <token> iscsi_tgt_attr_tiqn(item); <answer> = 
struct iscsi_login_stats *lstat = <token> <answer> &tiqn->login_stats; 
unsigned <token> buf[ISCSI_IQN_LEN]; <answer> char 
snprintf(buf, ISCSI_IQN_LEN, <token> lstat->last_intr_fail_name[0] ? <answer> "%s", 
<token> : NONE); <answer> lstat->last_intr_fail_name 
<token> snprintf(page, PAGE_SIZE, "%s\n", buf); <answer> return 
static ssize_t iscsi_stat_tgt_attr_fail_intr_addr_type_show(struct <token> *item, <answer> config_item 
char <token> <answer> *page) 
struct iscsi_tiqn *tiqn <token> iscsi_tgt_attr_tiqn(item); <answer> = 
struct iscsi_login_stats *lstat = <token> <answer> &tiqn->login_stats; 
int <token> <answer> ret; 
if (lstat->last_intr_fail_ip_family <token> AF_INET6) <answer> == 
ret = snprintf(page, PAGE_SIZE, <token> <answer> "ipv6\n"); 
ret <token> snprintf(page, PAGE_SIZE, "ipv4\n"); <answer> = 
return <token> <answer> ret; 
static ssize_t iscsi_stat_tgt_attr_fail_intr_addr_show(struct config_item <token> <answer> *item, 
<token> *page) <answer> char 
<token> iscsi_tiqn *tiqn = iscsi_tgt_attr_tiqn(item); <answer> struct 
struct iscsi_login_stats *lstat = <token> <answer> &tiqn->login_stats; 
<token> ret; <answer> int 
ret = snprintf(page, PAGE_SIZE, <token> &lstat->last_intr_fail_sockaddr); <answer> "%pISc\n", 
return <token> <answer> ret; 
<token> inst); <answer> CONFIGFS_ATTR_RO(iscsi_stat_tgt_attr_, 
CONFIGFS_ATTR_RO(iscsi_stat_tgt_attr_, <token> <answer> indx); 
<token> login_fails); <answer> CONFIGFS_ATTR_RO(iscsi_stat_tgt_attr_, 
<token> last_fail_time); <answer> CONFIGFS_ATTR_RO(iscsi_stat_tgt_attr_, 
CONFIGFS_ATTR_RO(iscsi_stat_tgt_attr_, <token> <answer> last_fail_type); 
<token> fail_intr_name); <answer> CONFIGFS_ATTR_RO(iscsi_stat_tgt_attr_, 
CONFIGFS_ATTR_RO(iscsi_stat_tgt_attr_, <token> <answer> fail_intr_addr_type); 
<token> fail_intr_addr); <answer> CONFIGFS_ATTR_RO(iscsi_stat_tgt_attr_, 
static struct configfs_attribute <token> = { <answer> *iscsi_stat_tgt_attr_attrs[] 
const struct <token> iscsi_stat_tgt_attr_cit = { <answer> config_item_type 
<token> = iscsi_stat_tgt_attr_attrs, <answer> .ct_attrs 
.ct_owner <token> THIS_MODULE, <answer> = 
static struct iscsi_tiqn *iscsi_login_stat_tiqn(struct <token> *item) <answer> config_item 
struct iscsi_wwn_stat_grps *igrps <token> container_of(to_config_group(item), <answer> = 
struct iscsi_wwn_stat_grps, <token> <answer> iscsi_login_stats_group); 
return container_of(igrps, <token> iscsi_tiqn, tiqn_stat_grps); <answer> struct 
<token> ssize_t iscsi_stat_login_inst_show(struct config_item *item, char *page) <answer> static 
return snprintf(page, <token> "%u\n", <answer> PAGE_SIZE, 
<token> ssize_t iscsi_stat_login_indx_show(struct config_item *item, <answer> static 
char <token> <answer> *page) 
return snprintf(page, <token> "%u\n", ISCSI_NODE_INDEX); <answer> PAGE_SIZE, 
static ssize_t <token> config_item *item, <answer> iscsi_stat_login_accepts_show(struct 
char <token> <answer> *page) 
<token> iscsi_tiqn *tiqn = iscsi_login_stat_tiqn(item); <answer> struct 
struct <token> *lstat = &tiqn->login_stats; <answer> iscsi_login_stats 
ssize_t <token> <answer> ret; 
ret = snprintf(page, PAGE_SIZE, <token> lstat->accepts); <answer> "%u\n", 
return <token> <answer> ret; 
static ssize_t iscsi_stat_login_other_fails_show(struct config_item <token> <answer> *item, 
char <token> <answer> *page) 
struct <token> *tiqn = iscsi_login_stat_tiqn(item); <answer> iscsi_tiqn 
struct iscsi_login_stats *lstat <token> &tiqn->login_stats; <answer> = 
<token> ret; <answer> ssize_t 
ret = snprintf(page, PAGE_SIZE, <token> lstat->other_fails); <answer> "%u\n", 
<token> ret; <answer> return 
static <token> iscsi_stat_login_redirects_show(struct config_item *item, <answer> ssize_t 
<token> *page) <answer> char 
struct iscsi_tiqn <token> = iscsi_login_stat_tiqn(item); <answer> *tiqn 
struct iscsi_login_stats <token> = &tiqn->login_stats; <answer> *lstat 
<token> ret; <answer> ssize_t 
<token> = snprintf(page, PAGE_SIZE, "%u\n", lstat->redirects); <answer> ret 
return <token> <answer> ret; 
static <token> iscsi_stat_login_authorize_fails_show(struct config_item *item, <answer> ssize_t 
<token> *page) <answer> char 
struct iscsi_tiqn *tiqn <token> iscsi_login_stat_tiqn(item); <answer> = 
<token> iscsi_login_stats *lstat = &tiqn->login_stats; <answer> struct 
ssize_t <token> <answer> ret; 
ret = snprintf(page, PAGE_SIZE, "%u\n", <token> <answer> lstat->authorize_fails); 
<token> ret; <answer> return 
<token> ssize_t iscsi_stat_login_authenticate_fails_show( <answer> static 
struct config_item *item, char <token> <answer> *page) 
struct iscsi_tiqn <token> = iscsi_login_stat_tiqn(item); <answer> *tiqn 
struct <token> *lstat = &tiqn->login_stats; <answer> iscsi_login_stats 
ssize_t <token> <answer> ret; 
ret = snprintf(page, PAGE_SIZE, "%u\n", <token> <answer> lstat->authenticate_fails); 
<token> ret; <answer> return 
static ssize_t iscsi_stat_login_negotiate_fails_show(struct <token> *item, <answer> config_item 
<token> *page) <answer> char 
<token> iscsi_tiqn *tiqn = iscsi_login_stat_tiqn(item); <answer> struct 
struct iscsi_login_stats *lstat <token> &tiqn->login_stats; <answer> = 
<token> ret; <answer> ssize_t 
ret <token> snprintf(page, PAGE_SIZE, "%u\n", lstat->negotiate_fails); <answer> = 
return <token> <answer> ret; 
CONFIGFS_ATTR_RO(iscsi_stat_login_, <token> <answer> inst); 
CONFIGFS_ATTR_RO(iscsi_stat_login_, <token> <answer> indx); 
CONFIGFS_ATTR_RO(iscsi_stat_login_, <token> <answer> accepts); 
<token> other_fails); <answer> CONFIGFS_ATTR_RO(iscsi_stat_login_, 
CONFIGFS_ATTR_RO(iscsi_stat_login_, <token> <answer> redirects); 
<token> authorize_fails); <answer> CONFIGFS_ATTR_RO(iscsi_stat_login_, 
<token> authenticate_fails); <answer> CONFIGFS_ATTR_RO(iscsi_stat_login_, 
CONFIGFS_ATTR_RO(iscsi_stat_login_, <token> <answer> negotiate_fails); 
static struct configfs_attribute *iscsi_stat_login_stats_attrs[] = <token> <answer> { 
const struct config_item_type <token> = { <answer> iscsi_stat_login_cit 
.ct_attrs <token> iscsi_stat_login_stats_attrs, <answer> = 
.ct_owner = <token> <answer> THIS_MODULE, 
static struct iscsi_tiqn *iscsi_logout_stat_tiqn(struct config_item <token> <answer> *item) 
<token> iscsi_wwn_stat_grps *igrps = container_of(to_config_group(item), <answer> struct 
struct iscsi_wwn_stat_grps, <token> <answer> iscsi_logout_stats_group); 
return container_of(igrps, struct iscsi_tiqn, <token> <answer> tiqn_stat_grps); 
static ssize_t <token> config_item *item, char *page) <answer> iscsi_stat_logout_inst_show(struct 
return snprintf(page, PAGE_SIZE, <token> <answer> "%u\n", 
static <token> iscsi_stat_logout_indx_show(struct config_item *item, char *page) <answer> ssize_t 
return snprintf(page, PAGE_SIZE, "%u\n", <token> <answer> ISCSI_NODE_INDEX); 
static <token> iscsi_stat_logout_normal_logouts_show(struct config_item *item, <answer> ssize_t 
<token> *page) <answer> char 
<token> iscsi_tiqn *tiqn = iscsi_logout_stat_tiqn(item); <answer> struct 
struct iscsi_logout_stats *lstats <token> &tiqn->logout_stats; <answer> = 
return <token> PAGE_SIZE, "%u\n", lstats->normal_logouts); <answer> snprintf(page, 
static ssize_t iscsi_stat_logout_abnormal_logouts_show(struct <token> *item, <answer> config_item 
char <token> <answer> *page) 
struct <token> *tiqn = iscsi_logout_stat_tiqn(item); <answer> iscsi_tiqn 
struct iscsi_logout_stats *lstats <token> &tiqn->logout_stats; <answer> = 
<token> snprintf(page, PAGE_SIZE, "%u\n", lstats->abnormal_logouts); <answer> return 
CONFIGFS_ATTR_RO(iscsi_stat_logout_, <token> <answer> inst); 
<token> indx); <answer> CONFIGFS_ATTR_RO(iscsi_stat_logout_, 
CONFIGFS_ATTR_RO(iscsi_stat_logout_, <token> <answer> normal_logouts); 
<token> abnormal_logouts); <answer> CONFIGFS_ATTR_RO(iscsi_stat_logout_, 
static struct configfs_attribute <token> = { <answer> *iscsi_stat_logout_stats_attrs[] 
const <token> config_item_type iscsi_stat_logout_cit = { <answer> struct 
<token> = iscsi_stat_logout_stats_attrs, <answer> .ct_attrs 
.ct_owner <token> THIS_MODULE, <answer> = 
static struct iscsi_node_acl <token> config_item *item) <answer> *iscsi_stat_nacl(struct 
struct <token> *igrps = container_of(to_config_group(item), <answer> iscsi_node_stat_grps 
struct iscsi_node_stat_grps, <token> <answer> iscsi_sess_stats_group); 
<token> container_of(igrps, struct iscsi_node_acl, node_stat_grps); <answer> return 
static ssize_t iscsi_stat_sess_inst_show(struct <token> *item, char *page) <answer> config_item 
struct iscsi_node_acl *acl = <token> <answer> iscsi_stat_nacl(item); 
struct <token> *wwn = acl->se_node_acl.se_tpg->se_tpg_wwn; <answer> se_wwn 
<token> iscsi_tiqn *tiqn = container_of(wwn, <answer> struct 
struct <token> tiqn_wwn); <answer> iscsi_tiqn, 
return snprintf(page, PAGE_SIZE, <token> tiqn->tiqn_index); <answer> "%u\n", 
static ssize_t iscsi_stat_sess_node_show(struct config_item *item, char <token> <answer> *page) 
<token> iscsi_node_acl *acl = iscsi_stat_nacl(item); <answer> struct 
struct se_node_acl *se_nacl <token> &acl->se_node_acl; <answer> = 
struct iscsit_session <token> <answer> *sess; 
struct se_session <token> <answer> *se_sess; 
ssize_t <token> = 0; <answer> ret 
<token> = se_nacl->nacl_sess; <answer> se_sess 
if (se_sess) <token> <answer> { 
sess = <token> <answer> se_sess->fabric_sess_ptr; 
if <token> <answer> (sess) 
ret <token> snprintf(page, PAGE_SIZE, "%u\n", <answer> = 
<token> ? 0 : ISCSI_NODE_INDEX); <answer> sess->sess_ops->SessionType 
<token> ret; <answer> return 
static ssize_t iscsi_stat_sess_indx_show(struct config_item *item, char <token> <answer> *page) 
struct iscsi_node_acl *acl <token> iscsi_stat_nacl(item); <answer> = 
struct se_node_acl <token> = &acl->se_node_acl; <answer> *se_nacl 
<token> iscsit_session *sess; <answer> struct 
struct se_session <token> <answer> *se_sess; 
ssize_t <token> = 0; <answer> ret 
se_sess <token> se_nacl->nacl_sess; <answer> = 
if <token> { <answer> (se_sess) 
sess = <token> <answer> se_sess->fabric_sess_ptr; 
<token> (sess) <answer> if 
ret = <token> PAGE_SIZE, "%u\n", <answer> snprintf(page, 
<token> ret; <answer> return 
static ssize_t iscsi_stat_sess_cmd_pdus_show(struct config_item <token> <answer> *item, 
char <token> <answer> *page) 
struct iscsi_node_acl <token> = iscsi_stat_nacl(item); <answer> *acl 
struct se_node_acl *se_nacl = <token> <answer> &acl->se_node_acl; 
<token> iscsit_session *sess; <answer> struct 
struct <token> *se_sess; <answer> se_session 
ssize_t <token> = 0; <answer> ret 
<token> = se_nacl->nacl_sess; <answer> se_sess 
<token> (se_sess) { <answer> if 
<token> = se_sess->fabric_sess_ptr; <answer> sess 
<token> (sess) <answer> if 
ret <token> snprintf(page, PAGE_SIZE, "%lu\n", <answer> = 
<token> ret; <answer> return 
static ssize_t <token> config_item *item, <answer> iscsi_stat_sess_rsp_pdus_show(struct 
char <token> <answer> *page) 
struct iscsi_node_acl <token> = iscsi_stat_nacl(item); <answer> *acl 
struct <token> *se_nacl = &acl->se_node_acl; <answer> se_node_acl 
<token> iscsit_session *sess; <answer> struct 
struct <token> *se_sess; <answer> se_session 
ssize_t ret <token> 0; <answer> = 
<token> = se_nacl->nacl_sess; <answer> se_sess 
<token> (se_sess) { <answer> if 
sess = <token> <answer> se_sess->fabric_sess_ptr; 
<token> (sess) <answer> if 
<token> = snprintf(page, PAGE_SIZE, "%lu\n", <answer> ret 
return <token> <answer> ret; 
static ssize_t iscsi_stat_sess_txdata_octs_show(struct config_item <token> <answer> *item, 
<token> *page) <answer> char 
struct <token> *acl = iscsi_stat_nacl(item); <answer> iscsi_node_acl 
struct se_node_acl *se_nacl <token> &acl->se_node_acl; <answer> = 
<token> iscsit_session *sess; <answer> struct 
struct <token> *se_sess; <answer> se_session 
ssize_t ret = <token> <answer> 0; 
se_sess <token> se_nacl->nacl_sess; <answer> = 
if (se_sess) <token> <answer> { 
sess <token> se_sess->fabric_sess_ptr; <answer> = 
<token> (sess) <answer> if 
<token> = snprintf(page, PAGE_SIZE, "%lu\n", <answer> ret 
return <token> <answer> ret; 
static ssize_t <token> config_item *item, <answer> iscsi_stat_sess_rxdata_octs_show(struct 
char <token> <answer> *page) 
struct <token> *acl = iscsi_stat_nacl(item); <answer> iscsi_node_acl 
struct <token> *se_nacl = &acl->se_node_acl; <answer> se_node_acl 
struct <token> *sess; <answer> iscsit_session 
struct se_session <token> <answer> *se_sess; 
ssize_t ret = <token> <answer> 0; 
<token> = se_nacl->nacl_sess; <answer> se_sess 
if (se_sess) <token> <answer> { 
<token> = se_sess->fabric_sess_ptr; <answer> sess 
<token> (sess) <answer> if 
ret = snprintf(page, <token> "%lu\n", <answer> PAGE_SIZE, 
return <token> <answer> ret; 
static <token> iscsi_stat_sess_conn_digest_errors_show(struct config_item *item, <answer> ssize_t 
<token> *page) <answer> char 
struct iscsi_node_acl *acl = <token> <answer> iscsi_stat_nacl(item); 
<token> se_node_acl *se_nacl = &acl->se_node_acl; <answer> struct 
struct <token> *sess; <answer> iscsit_session 
struct <token> *se_sess; <answer> se_session 
ssize_t ret = <token> <answer> 0; 
<token> = se_nacl->nacl_sess; <answer> se_sess 
<token> (se_sess) { <answer> if 
sess = <token> <answer> se_sess->fabric_sess_ptr; 
<token> (sess) <answer> if 
ret = snprintf(page, PAGE_SIZE, <token> <answer> "%lu\n", 
return <token> <answer> ret; 
<token> ssize_t iscsi_stat_sess_conn_timeout_errors_show( <answer> static 
struct <token> *item, char *page) <answer> config_item 
<token> iscsi_node_acl *acl = iscsi_stat_nacl(item); <answer> struct 
<token> se_node_acl *se_nacl = &acl->se_node_acl; <answer> struct 
struct iscsit_session <token> <answer> *sess; 
struct <token> *se_sess; <answer> se_session 
ssize_t ret = <token> <answer> 0; 
<token> = se_nacl->nacl_sess; <answer> se_sess 
if <token> { <answer> (se_sess) 
sess <token> se_sess->fabric_sess_ptr; <answer> = 
<token> (sess) <answer> if 
ret = snprintf(page, PAGE_SIZE, <token> <answer> "%lu\n", 
<token> ret; <answer> return 
<token> inst); <answer> CONFIGFS_ATTR_RO(iscsi_stat_sess_, 
CONFIGFS_ATTR_RO(iscsi_stat_sess_, <token> <answer> node); 
CONFIGFS_ATTR_RO(iscsi_stat_sess_, <token> <answer> indx); 
<token> cmd_pdus); <answer> CONFIGFS_ATTR_RO(iscsi_stat_sess_, 
CONFIGFS_ATTR_RO(iscsi_stat_sess_, <token> <answer> rsp_pdus); 
CONFIGFS_ATTR_RO(iscsi_stat_sess_, <token> <answer> txdata_octs); 
<token> rxdata_octs); <answer> CONFIGFS_ATTR_RO(iscsi_stat_sess_, 
CONFIGFS_ATTR_RO(iscsi_stat_sess_, <token> <answer> conn_digest_errors); 
CONFIGFS_ATTR_RO(iscsi_stat_sess_, <token> <answer> conn_timeout_errors); 
static struct configfs_attribute *iscsi_stat_sess_stats_attrs[] <token> { <answer> = 
const struct config_item_type <token> = { <answer> iscsi_stat_sess_cit 
.ct_attrs = <token> <answer> iscsi_stat_sess_stats_attrs, 
.ct_owner <token> THIS_MODULE, <answer> = 
#define <token> KBUILD_MODNAME ": " fmt <answer> pr_fmt(fmt) 
#include <token> <answer> <dt-bindings/clock/fsl,qoriq-clockgen.h> 
<token> <linux/clk.h> <answer> #include 
#include <token> <answer> <linux/clk-provider.h> 
<token> <linux/clkdev.h> <answer> #include 
#include <token> <answer> <linux/fsl/guts.h> 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/of_address.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/slab.h> 
<token> PLL_DIV1 0 <answer> #define 
#define <token> 1 <answer> PLL_DIV2 
#define PLL_DIV3 <token> <answer> 2 
<token> PLL_DIV4 3 <answer> #define 
#define <token> 0 <answer> PLATFORM_PLL 
#define <token> 1 <answer> CGA_PLL1 
#define <token> 2 <answer> CGA_PLL2 
#define CGA_PLL3 <token> <answer> 3 
#define CG_CMUX_GE_PLAT <token> <answer> 1 
static const struct <token> hwaccel_ops = { <answer> clk_ops 
.get_parent <token> mux_get_parent, <answer> = 
static const <token> clockgen_pll_div *get_pll_div(struct clockgen *cg, <answer> struct 
struct mux_hwclock <token> <answer> *hwc, 
int <token> <answer> idx) 
<token> pll, div; <answer> int 
if (!(hwc->info->clksel[idx].flags <token> CLKSEL_VALID)) <answer> & 
<token> NULL; <answer> return 
<token> = hwc->info->clksel[idx].pll; <answer> pll 
<token> = hwc->info->clksel[idx].div; <answer> div 
<token> &cg->pll[pll].div[div]; <answer> return 
static struct clk * __init create_mux_common(struct clockgen <token> <answer> *cg, 
struct mux_hwclock <token> <answer> *hwc, 
const <token> clk_ops *ops, <answer> struct 
unsigned long <token> <answer> min_rate, 
unsigned <token> max_rate, <answer> long 
unsigned <token> pct80_rate, <answer> long 
const char *fmt, int <token> <answer> idx) 
<token> clk_init_data init = {}; <answer> struct 
struct <token> *clk; <answer> clk 
<token> struct clockgen_pll_div *div; <answer> const 
const char <token> <answer> *parent_names[NUM_MUX_PARENTS]; 
<token> name[32]; <answer> char 
int i, <token> <answer> j; 
snprintf(name, sizeof(name), fmt, <token> <answer> idx); 
for (i = 0, j <token> 0; i < NUM_MUX_PARENTS; i++) { <answer> = 
unsigned <token> rate; <answer> long 
hwc->clksel_to_parent[i] <token> -1; <answer> = 
div = get_pll_div(cg, hwc, <token> <answer> i); 
if <token> <answer> (!div) 
<token> = clk_get_rate(div->clk); <answer> rate 
if (hwc->info->clksel[i].flags & CLKSEL_80PCT <token> <answer> && 
rate > <token> <answer> pct80_rate) 
if (rate < <token> <answer> min_rate) 
if (rate <token> max_rate) <answer> > 
<token> = div->name; <answer> parent_names[j] 
hwc->parent_to_clksel[j] = <token> <answer> i; 
<token> = j; <answer> hwc->clksel_to_parent[i] 
init.name <token> name; <answer> = 
<token> = ops; <answer> init.ops 
init.parent_names = <token> <answer> parent_names; 
init.num_parents = <token> = j; <answer> hwc->num_parents 
init.flags = <token> <answer> 0; 
hwc->hw.init = <token> <answer> &init; 
hwc->cg = <token> <answer> cg; 
clk = <token> &hwc->hw); <answer> clk_register(NULL, 
if (IS_ERR(clk)) <token> <answer> { 
pr_err("%s: <token> register %s: %ld\n", __func__, name, <answer> Couldn't 
<token> NULL; <answer> return 
return <token> <answer> clk; 
static struct clk * __init create_one_cmux(struct clockgen *cg, int <token> <answer> idx) 
struct mux_hwclock <token> <answer> *hwc; 
const struct <token> *div; <answer> clockgen_pll_div 
<token> long plat_rate, min_rate; <answer> unsigned 
<token> max_rate, pct80_rate; <answer> u64 
u32 <token> <answer> clksel; 
hwc <token> kzalloc(sizeof(*hwc), GFP_KERNEL); <answer> = 
if <token> <answer> (!hwc) 
<token> NULL; <answer> return 
<token> (cg->info.flags & CG_VER3) <answer> if 
hwc->reg = cg->regs + <token> + 0x20 * idx; <answer> 0x70000 
hwc->reg = cg->regs <token> 0x20 * idx; <answer> + 
<token> = cg->info.cmux_groups[cg->info.cmux_to_group[idx]]; <answer> hwc->info 
clksel <token> (cg_in(cg, hwc->reg) & CLKSEL_MASK) >> CLKSEL_SHIFT; <answer> = 
<token> = get_pll_div(cg, hwc, clksel); <answer> div 
if <token> { <answer> (!div) 
<token> NULL; <answer> return 
<token> = clk_get_rate(div->clk); <answer> max_rate 
pct80_rate = <token> * 8; <answer> max_rate 
do_div(pct80_rate, <token> <answer> 10); 
plat_rate = <token> <answer> clk_get_rate(cg->pll[PLATFORM_PLL].div[PLL_DIV1].clk); 
if (cg->info.flags <token> CG_CMUX_GE_PLAT) <answer> & 
<token> = plat_rate; <answer> min_rate 
min_rate = plat_rate <token> 2; <answer> / 
return create_mux_common(cg, <token> &cmux_ops, min_rate, max_rate, <answer> hwc, 
<token> "cg-cmux%d", idx); <answer> pct80_rate, 
static struct clk * __init create_one_hwaccel(struct <token> *cg, int idx) <answer> clockgen 
<token> mux_hwclock *hwc; <answer> struct 
hwc = kzalloc(sizeof(*hwc), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!hwc) 
return <token> <answer> NULL; 
<token> = cg->regs + 0x20 * idx + 0x10; <answer> hwc->reg 
<token> = cg->info.hwaccel[idx]; <answer> hwc->info 
return create_mux_common(cg, hwc, &hwaccel_ops, 0, <token> 0, <answer> ULONG_MAX, 
<token> idx); <answer> "cg-hwaccel%d", 
static void __init create_muxes(struct clockgen <token> <answer> *cg) 
<token> i; <answer> int 
for (i = 0; i < <token> i++) { <answer> ARRAY_SIZE(cg->cmux); 
<token> (cg->info.cmux_to_group[i] < 0) <answer> if 
if <token> >= <answer> (cg->info.cmux_to_group[i] 
<token> { <answer> ARRAY_SIZE(cg->info.cmux_groups)) 
<token> = create_one_cmux(cg, i); <answer> cg->cmux[i] 
for (i = <token> i < ARRAY_SIZE(cg->hwaccel); i++) { <answer> 0; 
if <token> <answer> (!cg->info.hwaccel[i]) 
cg->hwaccel[i] = create_one_hwaccel(cg, <token> <answer> i); 
static <token> __init _clockgen_init(struct device_node *np, bool legacy); <answer> void 
<token> void __init legacy_init_clockgen(struct device_node *np) <answer> static 
if (!clockgen.node) <token> <answer> { 
<token> device_node *parent_np; <answer> struct 
parent_np <token> of_get_parent(np); <answer> = 
_clockgen_init(parent_np, <token> <answer> true); 
if (WARN_ON(PTR_ERR(clk) <token> -EPROBE_DEFER)) <answer> == 
<token> clk; <answer> return 
return <token> <answer> NULL; 
if (idx != PLATFORM_PLL <token> i >= 4) <answer> && 
<token> sizeof(pll->div[i].name), <answer> snprintf(pll->div[i].name, 
"cg-pll%d-div%d", idx, <token> + 1); <answer> i 
clk = <token> <answer> clk_register_fixed_factor(NULL, 
<token> input, 0, mult, i + 1); <answer> pll->div[i].name, 
if (IS_ERR(clk)) <token> <answer> { 
pr_err("%s: <token> register failed %ld\n", <answer> %s: 
<token> pll->div[i].name, PTR_ERR(clk)); <answer> __func__, 
pll->div[i].clk = <token> <answer> clk; 
ret <token> clk_register_clkdev(clk, pll->div[i].name, NULL); <answer> = 
if (ret != <token> <answer> 0) 
pr_err("%s: %s: register to lookup <token> failed %d\n", <answer> table 
<token> pll->div[i].name, ret); <answer> __func__, 
static void __init create_plls(struct clockgen <token> <answer> *cg) 
<token> i; <answer> int 
for (i = 0; i <token> ARRAY_SIZE(cg->pll); i++) <answer> < 
<token> i); <answer> create_one_pll(cg, 
<token> void __init legacy_pll_init(struct device_node *np, int idx) <answer> static 
<token> clockgen_pll *pll; <answer> struct 
struct clk_onecell_data <token> <answer> *onecell_data; 
struct clk <token> <answer> **subclks; 
int <token> rc; <answer> count, 
pll = <token> <answer> &clockgen.pll[idx]; 
count <token> of_property_count_strings(np, "clock-output-names"); <answer> = 
BUILD_BUG_ON(ARRAY_SIZE(pll->div) < <token> <answer> 4); 
subclks = kcalloc(4, sizeof(struct <token> *), GFP_KERNEL); <answer> clk 
if <token> <answer> (!subclks) 
<token> = kmalloc(sizeof(*onecell_data), GFP_KERNEL); <answer> onecell_data 
if <token> <answer> (!onecell_data) 
goto <token> <answer> err_clks; 
if (count <= <token> { <answer> 3) 
<token> = pll->div[0].clk; <answer> subclks[0] 
subclks[1] <token> pll->div[1].clk; <answer> = 
<token> = pll->div[3].clk; <answer> subclks[2] 
} <token> { <answer> else 
subclks[0] = <token> <answer> pll->div[0].clk; 
<token> = pll->div[1].clk; <answer> subclks[1] 
<token> = pll->div[2].clk; <answer> subclks[2] 
subclks[3] = <token> <answer> pll->div[3].clk; 
onecell_data->clks <token> subclks; <answer> = 
onecell_data->clk_num = <token> <answer> count; 
<token> = of_clk_add_provider(np, of_clk_src_onecell_get, onecell_data); <answer> rc 
if <token> { <answer> (rc) 
pr_err("%s: Couldn't register clk provider for <token> %pOFn: %d\n", <answer> node 
<token> np, rc); <answer> __func__, 
goto <token> <answer> err_cell; 
} else <token> <answer> { 
idx = (res.start & <token> >> 5; <answer> 0xf0) 
legacy_pll_init(np, CGA_PLL1 <token> idx); <answer> + 
static struct clk *clockgen_clk_get(struct <token> *clkspec, void *data) <answer> of_phandle_args 
struct clockgen *cg <token> data; <answer> = 
struct <token> *clk; <answer> clk 
struct <token> *pll; <answer> clockgen_pll 
u32 <token> idx; <answer> type, 
if (clkspec->args_count < 2) <token> <answer> { 
<token> insufficient phandle args\n", __func__); <answer> pr_err("%s: 
<token> ERR_PTR(-EINVAL); <answer> return 
<token> = clkspec->args[0]; <answer> type 
idx = <token> <answer> clkspec->args[1]; 
switch (type) <token> <answer> { 
<token> QORIQ_CLK_SYSCLK: <answer> case 
if (idx <token> 0) <answer> != 
goto <token> <answer> bad_args; 
clk = <token> <answer> cg->sysclk; 
case <token> <answer> QORIQ_CLK_CMUX: 
<token> (idx >= ARRAY_SIZE(cg->cmux)) <answer> if 
<token> bad_args; <answer> goto 
clk = <token> <answer> cg->cmux[idx]; 
<token> QORIQ_CLK_HWACCEL: <answer> case 
if (idx >= <token> <answer> ARRAY_SIZE(cg->hwaccel)) 
goto <token> <answer> bad_args; 
clk <token> cg->hwaccel[idx]; <answer> = 
case <token> <answer> QORIQ_CLK_FMAN: 
if <token> >= ARRAY_SIZE(cg->fman)) <answer> (idx 
<token> bad_args; <answer> goto 
<token> = cg->fman[idx]; <answer> clk 
<token> QORIQ_CLK_PLATFORM_PLL: <answer> case 
<token> = &cg->pll[PLATFORM_PLL]; <answer> pll 
<token> (idx >= ARRAY_SIZE(pll->div)) <answer> if 
goto <token> <answer> bad_args; 
clk <token> pll->div[idx].clk; <answer> = 
case <token> <answer> QORIQ_CLK_CORECLK: 
if <token> != 0) <answer> (idx 
<token> bad_args; <answer> goto 
<token> = cg->coreclk; <answer> clk 
<token> (IS_ERR(clk)) <answer> if 
clk <token> NULL; <answer> = 
<token> bad_args; <answer> goto 
<token> (!clk) <answer> if 
return <token> <answer> ERR_PTR(-ENOENT); 
<token> clk; <answer> return 
<token> Bad phandle args %u %u\n", __func__, type, idx); <answer> pr_err("%s: 
return <token> <answer> ERR_PTR(-EINVAL); 
<token> CONFIG_PPC <answer> #ifdef 
#include <token> <answer> <asm/mpc85xx.h> 
static const u32 a4510_svrs[] __initconst = <token> <answer> { 
#include <token> <answer> <linux/blkdev.h> 
#include <token> <answer> <linux/export.h> 
<token> <linux/pagemap.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/cred.h> 
<token> <linux/mount.h> <answer> #include 
<token> <linux/vfs.h> <answer> #include 
#include <token> <answer> <linux/quotaops.h> 
#include <token> <answer> <linux/mutex.h> 
<token> <linux/namei.h> <answer> #include 
<token> <linux/exportfs.h> <answer> #include 
<token> <linux/iversion.h> <answer> #include 
#include <token> <answer> <linux/writeback.h> 
int always_delete_dentry(const struct <token> *dentry) <answer> dentry 
<token> 1; <answer> return 
const struct <token> simple_dentry_operations = { <answer> dentry_operations 
<token> = always_delete_dentry, <answer> .d_delete 
struct dentry <token> inode *dir, struct dentry *dentry, unsigned int flags) <answer> *simple_lookup(struct 
if (dentry->d_name.len > <token> <answer> NAME_MAX) 
return <token> <answer> ERR_PTR(-ENAMETOOLONG); 
<token> (!dentry->d_sb->s_d_op) <answer> if 
d_set_d_op(dentry, <token> <answer> &simple_dentry_operations); 
<token> NULL); <answer> d_add(dentry, 
<token> NULL; <answer> return 
<token> dcache_dir_open(struct inode *inode, struct file *file) <answer> int 
file->private_data <token> d_alloc_cursor(file->f_path.dentry); <answer> = 
return file->private_data ? <token> : -ENOMEM; <answer> 0 
int dcache_dir_close(struct inode *inode, struct <token> *file) <answer> file 
<token> 0; <answer> return 
<token> struct dentry *scan_positives(struct dentry *cursor, <answer> static 
struct <token> **p, <answer> hlist_node 
loff_t <token> <answer> count, 
<token> dentry *last) <answer> struct 
<token> dentry *dentry = cursor->d_parent, *found = NULL; <answer> struct 
while (*p) <token> <answer> { 
struct dentry *d = hlist_entry(*p, struct <token> d_sib); <answer> dentry, 
<token> = &d->d_sib.next; <answer> p 
<token> (d->d_flags & DCACHE_DENTRY_CURSOR) <answer> if 
if <token> && !--count) { <answer> (simple_positive(d) 
<token> DENTRY_D_LOCK_NESTED); <answer> spin_lock_nested(&d->d_lock, 
<token> (simple_positive(d)) <answer> if 
found = <token> <answer> dget_dlock(d); 
if <token> <answer> (likely(found)) 
count = <token> <answer> 1; 
<token> (need_resched()) { <answer> if 
<token> (!hlist_unhashed(&cursor->d_sib)) <answer> if 
<token> &d->d_sib); <answer> hlist_add_behind(&cursor->d_sib, 
<token> = &cursor->d_sib.next; <answer> p 
return <token> <answer> found; 
loff_t dcache_dir_lseek(struct file *file, loff_t offset, int <token> <answer> whence) 
struct <token> *dentry = file->f_path.dentry; <answer> dentry 
<token> (whence) { <answer> switch 
case <token> <answer> 1: 
offset += <token> <answer> file->f_pos; 
<token> 0: <answer> case 
if <token> >= 0) <answer> (offset 
<token> -EINVAL; <answer> return 
if (offset != file->f_pos) <token> <answer> { 
struct dentry *cursor <token> file->private_data; <answer> = 
<token> dentry *to = NULL; <answer> struct 
if <token> > 2) <answer> (offset 
to = <token> &dentry->d_children.first, <answer> scan_positives(cursor, 
offset - <token> NULL); <answer> 2, 
<token> (to) <answer> if 
hlist_add_behind(&cursor->d_sib, <token> <answer> &to->d_sib); 
file->f_pos = <token> <answer> offset; 
return <token> <answer> offset; 
int dcache_readdir(struct <token> *file, struct dir_context *ctx) <answer> file 
struct dentry <token> = file->f_path.dentry; <answer> *dentry 
struct <token> *cursor = file->private_data; <answer> dentry 
struct <token> *next = NULL; <answer> dentry 
<token> hlist_node **p; <answer> struct 
if <token> ctx)) <answer> (!dir_emit_dots(file, 
<token> 0; <answer> return 
<token> (ctx->pos == 2) <answer> if 
p <token> &dentry->d_children.first; <answer> = 
<token> = &cursor->d_sib.next; <answer> p 
while ((next = scan_positives(cursor, p, 1, next)) <token> NULL) { <answer> != 
if <token> next->d_name.name, next->d_name.len, <answer> (!dir_emit(ctx, 
<token> = &next->d_sib.next; <answer> p 
if <token> <answer> (next) 
<token> &next->d_sib); <answer> hlist_add_before(&cursor->d_sib, 
<token> 0; <answer> return 
ssize_t generic_read_dir(struct file *filp, char __user *buf, size_t <token> loff_t *ppos) <answer> siz, 
return <token> <answer> -EISDIR; 
const struct file_operations simple_dir_operations <token> { <answer> = 
<token> = dcache_dir_open, <answer> .open 
.release <token> dcache_dir_close, <answer> = 
.llseek = <token> <answer> dcache_dir_lseek, 
<token> = generic_read_dir, <answer> .read 
<token> = dcache_readdir, <answer> .iterate_shared 
.fsync <token> noop_fsync, <answer> = 
<token> struct inode_operations simple_dir_inode_operations = { <answer> const 
<token> = simple_lookup, <answer> .lookup 
void <token> offset_ctx *octx) <answer> simple_offset_init(struct 
<token> MT_FLAGS_ALLOC_RANGE); <answer> mt_init_flags(&octx->mt, 
<token> &simple_offset_lock_class); <answer> lockdep_set_class(&octx->mt.ma_lock, 
octx->next_offset = <token> <answer> DIR_OFFSET_MIN; 
int <token> offset_ctx *octx, struct dentry *dentry) <answer> simple_offset_add(struct 
unsigned <token> offset; <answer> long 
<token> ret; <answer> int 
if (dentry2offset(dentry) <token> 0) <answer> != 
return <token> <answer> -EBUSY; 
ret = <token> &offset, dentry, DIR_OFFSET_MIN, <answer> mtree_alloc_cyclic(&octx->mt, 
LONG_MAX, &octx->next_offset, <token> <answer> GFP_KERNEL); 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
offset_set(dentry, <token> <answer> offset); 
<token> 0; <answer> return 
void simple_offset_remove(struct <token> *octx, struct dentry *dentry) <answer> offset_ctx 
<token> offset; <answer> long 
offset <token> dentry2offset(dentry); <answer> = 
<token> (offset == 0) <answer> if 
<token> offset); <answer> mtree_erase(&octx->mt, 
<token> 0); <answer> offset_set(dentry, 
<token> simple_offset_empty(struct dentry *dentry) <answer> int 
struct <token> *inode = d_inode(dentry); <answer> inode 
<token> offset_ctx *octx; <answer> struct 
<token> dentry *child; <answer> struct 
<token> long index; <answer> unsigned 
int <token> = 1; <answer> ret 
if <token> || !S_ISDIR(inode->i_mode)) <answer> (!inode 
return <token> <answer> ret; 
index = <token> <answer> DIR_OFFSET_MIN; 
octx <token> inode->i_op->get_offset_ctx(inode); <answer> = 
mt_for_each(&octx->mt, child, index, <token> { <answer> LONG_MAX) 
if <token> { <answer> (simple_positive(child)) 
ret <token> 0; <answer> = 
<token> ret; <answer> return 
int <token> inode *old_dir, <answer> simple_offset_rename_exchange(struct 
struct <token> *old_dentry, <answer> dentry 
struct inode <token> <answer> *new_dir, 
struct <token> *new_dentry) <answer> dentry 
struct offset_ctx *old_ctx <token> old_dir->i_op->get_offset_ctx(old_dir); <answer> = 
struct offset_ctx *new_ctx <token> new_dir->i_op->get_offset_ctx(new_dir); <answer> = 
long old_index <token> dentry2offset(old_dentry); <answer> = 
<token> new_index = dentry2offset(new_dentry); <answer> long 
int <token> <answer> ret; 
<token> old_dentry); <answer> simple_offset_remove(old_ctx, 
<token> new_dentry); <answer> simple_offset_remove(new_ctx, 
ret <token> simple_offset_add(new_ctx, old_dentry); <answer> = 
if <token> <answer> (ret) 
<token> out_restore; <answer> goto 
ret = simple_offset_add(old_ctx, <token> <answer> new_dentry); 
if <token> { <answer> (ret) 
simple_offset_remove(new_ctx, <token> <answer> old_dentry); 
<token> out_restore; <answer> goto 
ret = simple_rename_exchange(old_dir, <token> new_dir, new_dentry); <answer> old_dentry, 
if (ret) <token> <answer> { 
simple_offset_remove(new_ctx, <token> <answer> old_dentry); 
simple_offset_remove(old_ctx, <token> <answer> new_dentry); 
<token> out_restore; <answer> goto 
return <token> <answer> 0; 
offset_set(old_dentry, <token> <answer> old_index); 
mtree_store(&old_ctx->mt, <token> old_dentry, GFP_KERNEL); <answer> old_index, 
<token> new_index); <answer> offset_set(new_dentry, 
mtree_store(&new_ctx->mt, <token> new_dentry, GFP_KERNEL); <answer> new_index, 
return <token> <answer> ret; 
<token> simple_offset_destroy(struct offset_ctx *octx) <answer> void 
static loff_t offset_dir_llseek(struct <token> *file, loff_t offset, int whence) <answer> file 
switch <token> { <answer> (whence) 
<token> SEEK_CUR: <answer> case 
<token> += file->f_pos; <answer> offset 
case <token> <answer> SEEK_SET: 
<token> (offset >= 0) <answer> if 
return <token> <answer> -EINVAL; 
static int offset_readdir(struct file <token> struct dir_context *ctx) <answer> *file, 
<token> dentry *dir = file->f_path.dentry; <answer> struct 
if (!dir_emit_dots(file, <token> <answer> ctx)) 
<token> 0; <answer> return 
root->i_ino = <token> <answer> 1; 
<token> = S_IFDIR | S_IRUSR | S_IWUSR; <answer> root->i_mode 
s->s_root = <token> <answer> d_make_root(root); 
<token> (!s->s_root) <answer> if 
<token> -ENOMEM; <answer> return 
<token> = ctx->dops; <answer> s->s_d_op 
return <token> <answer> 0; 
<token> int pseudo_fs_get_tree(struct fs_context *fc) <answer> static 
<token> get_tree_nodev(fc, pseudo_fs_fill_super); <answer> return 
static void pseudo_fs_free(struct fs_context <token> <answer> *fc) 
static const <token> fs_context_operations pseudo_fs_context_ops = { <answer> struct 
.free = <token> <answer> pseudo_fs_free, 
.get_tree = <token> <answer> pseudo_fs_get_tree, 
struct pseudo_fs_context *init_pseudo(struct <token> *fc, <answer> fs_context 
<token> long magic) <answer> unsigned 
struct pseudo_fs_context <token> <answer> *ctx; 
ctx = kzalloc(sizeof(struct <token> GFP_KERNEL); <answer> pseudo_fs_context), 
if <token> { <answer> (likely(ctx)) 
<token> = magic; <answer> ctx->magic 
fc->fs_private <token> ctx; <answer> = 
<token> = &pseudo_fs_context_ops; <answer> fc->ops 
fc->sb_flags <token> SB_NOUSER; <answer> |= 
<token> = true; <answer> fc->global 
return <token> <answer> ctx; 
int simple_open(struct inode *inode, struct file <token> <answer> *file) 
if <token> <answer> (inode->i_private) 
<token> = inode->i_private; <answer> file->private_data 
<token> 0; <answer> return 
int simple_link(struct <token> *old_dentry, struct inode *dir, struct dentry *dentry) <answer> dentry 
struct inode *inode <token> d_inode(old_dentry); <answer> = 
inode_set_ctime_to_ts(dir, <token> <answer> inode_set_ctime_current(inode))); 
<token> inode); <answer> d_instantiate(dentry, 
<token> 0; <answer> return 
int simple_empty(struct dentry <token> <answer> *dentry) 
struct <token> *child; <answer> dentry 
int <token> = 0; <answer> ret 
hlist_for_each_entry(child, &dentry->d_children, <token> { <answer> d_sib) 
<token> DENTRY_D_LOCK_NESTED); <answer> spin_lock_nested(&child->d_lock, 
<token> (simple_positive(child)) { <answer> if 
<token> out; <answer> goto 
<token> = 1; <answer> ret 
return <token> <answer> ret; 
int simple_unlink(struct inode *dir, struct dentry <token> <answer> *dentry) 
<token> inode *inode = d_inode(dentry); <answer> struct 
inode_set_ctime_to_ts(dir, <token> <answer> inode_set_ctime_current(inode))); 
return <token> <answer> 0; 
int simple_rmdir(struct inode *dir, struct <token> *dentry) <answer> dentry 
<token> (!simple_empty(dentry)) <answer> if 
<token> -ENOTEMPTY; <answer> return 
<token> dentry); <answer> simple_unlink(dir, 
<token> 0; <answer> return 
void simple_rename_timestamp(struct <token> *old_dir, struct dentry *old_dentry, <answer> inode 
struct inode *new_dir, <token> dentry *new_dentry) <answer> struct 
struct <token> *newino = d_inode(new_dentry); <answer> inode 
<token> inode_set_ctime_current(old_dir)); <answer> inode_set_mtime_to_ts(old_dir, 
if <token> != old_dir) <answer> (new_dir 
if <token> <answer> (newino) 
<token> simple_rename_exchange(struct inode *old_dir, struct dentry *old_dentry, <answer> int 
struct inode *new_dir, struct dentry <token> <answer> *new_dentry) 
bool old_is_dir = <token> <answer> d_is_dir(old_dentry); 
bool new_is_dir <token> d_is_dir(new_dentry); <answer> = 
if (old_dir != <token> && old_is_dir != new_is_dir) { <answer> new_dir 
if <token> { <answer> (old_is_dir) 
} <token> { <answer> else 
<token> old_dentry, new_dir, new_dentry); <answer> simple_rename_timestamp(old_dir, 
return <token> <answer> 0; 
int simple_rename(struct mnt_idmap *idmap, struct <token> *old_dir, <answer> inode 
struct dentry <token> struct inode *new_dir, <answer> *old_dentry, 
struct dentry *new_dentry, unsigned int <token> <answer> flags) 
<token> they_are_dirs = d_is_dir(old_dentry); <answer> int 
if (flags & <token> | RENAME_EXCHANGE)) <answer> ~(RENAME_NOREPLACE 
<token> -EINVAL; <answer> return 
if (flags <token> RENAME_EXCHANGE) <answer> & 
return simple_rename_exchange(old_dir, old_dentry, <token> new_dentry); <answer> new_dir, 
<token> (!simple_empty(new_dentry)) <answer> if 
return <token> <answer> -ENOTEMPTY; 
<token> (d_really_is_positive(new_dentry)) { <answer> if 
<token> new_dentry); <answer> simple_unlink(new_dir, 
if <token> { <answer> (they_are_dirs) 
} else if <token> { <answer> (they_are_dirs) 
simple_rename_timestamp(old_dir, old_dentry, new_dir, <token> <answer> new_dentry); 
<token> 0; <answer> return 
int <token> mnt_idmap *idmap, struct dentry *dentry, <answer> simple_setattr(struct 
<token> iattr *iattr) <answer> struct 
struct inode *inode = <token> <answer> d_inode(dentry); 
int <token> <answer> error; 
error = setattr_prepare(idmap, dentry, <token> <answer> iattr); 
<token> (error) <answer> if 
<token> error; <answer> return 
if (iattr->ia_valid <token> ATTR_SIZE) <answer> & 
<token> iattr->ia_size); <answer> truncate_setsize(inode, 
<token> inode, iattr); <answer> setattr_copy(idmap, 
return <token> <answer> 0; 
static int simple_read_folio(struct file *file, <token> folio *folio) <answer> struct 
<token> 0, folio_size(folio)); <answer> folio_zero_range(folio, 
return <token> <answer> 0; 
int simple_write_begin(struct file *file, <token> address_space *mapping, <answer> struct 
loff_t <token> unsigned len, <answer> pos, 
struct page **pagep, void <token> <answer> **fsdata) 
struct folio <token> <answer> *folio; 
folio = __filemap_get_folio(mapping, pos <token> PAGE_SIZE, FGP_WRITEBEGIN, <answer> / 
<token> (IS_ERR(folio)) <answer> if 
return <token> <answer> PTR_ERR(folio); 
*pagep = <token> <answer> &folio->page; 
if <token> && (len != folio_size(folio))) { <answer> (!folio_test_uptodate(folio) 
size_t from = <token> pos); <answer> offset_in_folio(folio, 
folio_zero_segments(folio, <token> from, <answer> 0, 
<token> + len, folio_size(folio)); <answer> from 
<token> 0; <answer> return 
static int simple_write_end(struct <token> *file, struct address_space *mapping, <answer> file 
loff_t <token> unsigned len, unsigned copied, <answer> pos, 
struct <token> *page, void *fsdata) <answer> page 
struct folio *folio <token> page_folio(page); <answer> = 
struct inode *inode = <token> <answer> folio->mapping->host; 
loff_t last_pos = <token> + copied; <answer> pos 
<token> (last_pos > inode->i_size) <answer> if 
i_size_write(inode, <token> <answer> last_pos); 
<token> copied; <answer> return 
const struct address_space_operations ram_aops <token> { <answer> = 
<token> = simple_read_folio, <answer> .read_folio 
.write_begin <token> simple_write_begin, <answer> = 
<token> = simple_write_end, <answer> .write_end 
<token> = noop_dirty_folio, <answer> .dirty_folio 
<token> simple_fill_super(struct super_block *s, unsigned long magic, <answer> int 
<token> struct tree_descr *files) <answer> const 
struct inode <token> <answer> *inode; 
struct dentry <token> <answer> *dentry; 
int <token> <answer> i; 
s->s_blocksize <token> PAGE_SIZE; <answer> = 
s->s_blocksize_bits <token> PAGE_SHIFT; <answer> = 
s->s_magic = <token> <answer> magic; 
s->s_op <token> &simple_super_operations; <answer> = 
<token> = 1; <answer> s->s_time_gran 
inode = <token> <answer> new_inode(s); 
<token> (!inode) <answer> if 
<token> -ENOMEM; <answer> return 
<token> = 1; <answer> inode->i_ino 
inode->i_mode = S_IFDIR | <token> <answer> 0755; 
inode->i_op = <token> <answer> &simple_dir_inode_operations; 
inode->i_fop = <token> <answer> &simple_dir_operations; 
<token> 2); <answer> set_nlink(inode, 
s->s_root = <token> <answer> d_make_root(inode); 
<token> (!s->s_root) <answer> if 
<token> -ENOMEM; <answer> return 
for (i = 0; !files->name <token> files->name[0]; i++, files++) { <answer> || 
<token> (!files->name) <answer> if 
ssize_t simple_read_from_buffer(void __user *to, size_t count, loff_t <token> <answer> *ppos, 
const void <token> size_t available) <answer> *from, 
<token> pos = *ppos; <answer> loff_t 
size_t <token> <answer> ret; 
if (pos < <token> <answer> 0) 
return <token> <answer> -EINVAL; 
if (pos >= available <token> !count) <answer> || 
<token> 0; <answer> return 
if (count > <token> - pos) <answer> available 
count = available - <token> <answer> pos; 
<token> = copy_to_user(to, from + pos, count); <answer> ret 
<token> (ret == count) <answer> if 
return <token> <answer> -EFAULT; 
count <token> ret; <answer> -= 
*ppos = <token> + count; <answer> pos 
return <token> <answer> count; 
ssize_t <token> *to, size_t available, loff_t *ppos, <answer> simple_write_to_buffer(void 
const <token> __user *from, size_t count) <answer> void 
loff_t pos = <token> <answer> *ppos; 
size_t <token> <answer> res; 
<token> (pos < 0) <answer> if 
return <token> <answer> -EINVAL; 
if (pos >= available || <token> <answer> !count) 
<token> 0; <answer> return 
if (count <token> available - pos) <answer> > 
<token> = available - pos; <answer> count 
res = copy_from_user(to <token> pos, from, count); <answer> + 
if (res == <token> <answer> count) 
<token> -EFAULT; <answer> return 
<token> -= res; <answer> count 
*ppos = <token> + count; <answer> pos 
return <token> <answer> count; 
ssize_t memory_read_from_buffer(void *to, size_t <token> loff_t *ppos, <answer> count, 
const void <token> size_t available) <answer> *from, 
loff_t <token> = *ppos; <answer> pos 
if (pos <token> 0) <answer> < 
<token> -EINVAL; <answer> return 
<token> (pos >= available) <answer> if 
<token> 0; <answer> return 
if (count > <token> - pos) <answer> available 
count <token> available - pos; <answer> = 
memcpy(to, <token> + pos, count); <answer> from 
<token> = pos + count; <answer> *ppos 
<token> count; <answer> return 
void <token> file *file, size_t n) <answer> simple_transaction_set(struct 
<token> simple_transaction_argresp *ar = file->private_data; <answer> struct 
BUG_ON(n > <token> <answer> SIMPLE_TRANSACTION_LIMIT); 
<token> = n; <answer> ar->size 
char *simple_transaction_get(struct file <token> const char __user *buf, size_t size) <answer> *file, 
struct simple_transaction_argresp <token> <answer> *ar; 
<token> DEFINE_SPINLOCK(simple_transaction_lock); <answer> static 
<token> (size > SIMPLE_TRANSACTION_LIMIT - 1) <answer> if 
return <token> <answer> ERR_PTR(-EFBIG); 
ar = (struct <token> *)get_zeroed_page(GFP_KERNEL); <answer> simple_transaction_argresp 
if <token> <answer> (!ar) 
return <token> <answer> ERR_PTR(-ENOMEM); 
<token> simple_attr_open(struct inode *inode, struct file *file, <answer> int 
int (*get)(void *, u64 *), <token> (*set)(void *, u64), <answer> int 
<token> char *fmt) <answer> const 
struct simple_attr <token> <answer> *attr; 
attr <token> kzalloc(sizeof(*attr), GFP_KERNEL); <answer> = 
<token> (!attr) <answer> if 
return <token> <answer> -ENOMEM; 
attr->get <token> get; <answer> = 
attr->set = <token> <answer> set; 
<token> = inode->i_private; <answer> attr->data 
<token> = fmt; <answer> attr->fmt 
file->private_data <token> attr; <answer> = 
return <token> file); <answer> nonseekable_open(inode, 
int simple_attr_release(struct inode <token> struct file *file) <answer> *inode, 
return <token> <answer> 0; 
int generic_encode_ino32_fh(struct inode *inode, __u32 *fh, <token> *max_len, <answer> int 
struct inode <token> <answer> *parent) 
struct fid *fid <token> (void *)fh; <answer> = 
int len <token> *max_len; <answer> = 
<token> type = FILEID_INO32_GEN; <answer> int 
if (parent <token> (len < 4)) { <answer> && 
<token> = 4; <answer> *max_len 
<token> FILEID_INVALID; <answer> return 
} else if (len <token> 2) { <answer> < 
*max_len <token> 2; <answer> = 
<token> FILEID_INVALID; <answer> return 
len = <token> <answer> 2; 
fid->i32.ino = <token> <answer> inode->i_ino; 
fid->i32.gen = <token> <answer> inode->i_generation; 
<token> (parent) { <answer> if 
fid->i32.parent_ino <token> parent->i_ino; <answer> = 
fid->i32.parent_gen <token> parent->i_generation; <answer> = 
<token> = 4; <answer> len 
type = <token> <answer> FILEID_INO32_GEN_PARENT; 
*max_len = <token> <answer> len; 
<token> type; <answer> return 
struct dentry *generic_fh_to_dentry(struct <token> *sb, struct fid *fid, <answer> super_block 
int fh_len, <token> fh_type, struct inode *(*get_inode) <answer> int 
(struct super_block *sb, u64 <token> u32 gen)) <answer> ino, 
struct <token> *inode = NULL; <answer> inode 
if (fh_len < <token> <answer> 2) 
return <token> <answer> NULL; 
<token> (fh_type) { <answer> switch 
<token> FILEID_INO32_GEN: <answer> case 
<token> FILEID_INO32_GEN_PARENT: <answer> case 
inode = get_inode(sb, <token> fid->i32.gen); <answer> fid->i32.ino, 
<token> d_obtain_alias(inode); <answer> return 
struct dentry *generic_fh_to_parent(struct super_block *sb, struct fid <token> <answer> *fid, 
int <token> int fh_type, struct inode *(*get_inode) <answer> fh_len, 
(struct <token> *sb, u64 ino, u32 gen)) <answer> super_block 
struct inode *inode = <token> <answer> NULL; 
if (fh_len <= <token> <answer> 2) 
<token> NULL; <answer> return 
<token> (fh_type) { <answer> switch 
<token> FILEID_INO32_GEN_PARENT: <answer> case 
<token> = get_inode(sb, fid->i32.parent_ino, <answer> inode 
<token> > 3 ? fid->i32.parent_gen : 0)); <answer> (fh_len 
return <token> <answer> d_obtain_alias(inode); 
int __generic_file_fsync(struct file *file, loff_t start, <token> end, <answer> loff_t 
int <token> <answer> datasync) 
struct inode *inode <token> file->f_mapping->host; <answer> = 
<token> err; <answer> int 
int <token> <answer> ret; 
err = file_write_and_wait_range(file, <token> end); <answer> start, 
<token> (err) <answer> if 
<token> err; <answer> return 
<token> = sync_mapping_buffers(inode->i_mapping); <answer> ret 
<token> (!(inode->i_state & I_DIRTY_ALL)) <answer> if 
<token> out; <answer> goto 
if (datasync <token> !(inode->i_state & I_DIRTY_DATASYNC)) <answer> && 
goto <token> <answer> out; 
<token> = sync_inode_metadata(inode, 1); <answer> err 
if <token> == 0) <answer> (ret 
ret <token> err; <answer> = 
int generic_file_fsync(struct file *file, loff_t start, loff_t <token> <answer> end, 
<token> datasync) <answer> int 
<token> inode *inode = file->f_mapping->host; <answer> struct 
int <token> <answer> err; 
err <token> __generic_file_fsync(file, start, end, datasync); <answer> = 
if <token> <answer> (err) 
<token> err; <answer> return 
<token> blkdev_issue_flush(inode->i_sb->s_bdev); <answer> return 
<token> generic_check_addressable(unsigned blocksize_bits, u64 num_blocks) <answer> int 
u64 <token> = num_blocks - 1; <answer> last_fs_block 
u64 last_fs_page <token> <answer> = 
last_fs_block <token> (PAGE_SHIFT - blocksize_bits); <answer> >> 
<token> (unlikely(num_blocks == 0)) <answer> if 
return <token> <answer> 0; 
if ((blocksize_bits < 9) || (blocksize_bits <token> PAGE_SHIFT)) <answer> > 
return <token> <answer> -EINVAL; 
if ((last_fs_block > (sector_t)(~0ULL) >> <token> - 9)) || <answer> (blocksize_bits 
(last_fs_page <token> (pgoff_t)(~0ULL))) { <answer> > 
<token> -EFBIG; <answer> return 
<token> 0; <answer> return 
int noop_fsync(struct file *file, loff_t start, loff_t end, int <token> <answer> datasync) 
<token> 0; <answer> return 
ssize_t <token> kiocb *iocb, struct iov_iter *iter) <answer> noop_direct_IO(struct 
<token> -EINVAL; <answer> return 
<token> = I_DIRTY; <answer> inode->i_state 
<token> = S_IRUSR | S_IWUSR; <answer> inode->i_mode 
inode->i_uid = <token> <answer> current_fsuid(); 
inode->i_gid = <token> <answer> current_fsgid(); 
inode->i_flags |= <token> <answer> S_PRIVATE; 
return <token> <answer> inode; 
simple_nosetlease(struct file *filp, int arg, struct file_lease <token> <answer> **flp, 
void <token> <answer> **priv) 
return <token> <answer> -EINVAL; 
const char *simple_get_link(struct dentry <token> struct inode *inode, <answer> *dentry, 
struct delayed_call <token> <answer> *done) 
<token> inode->i_link; <answer> return 
<token> struct inode_operations simple_symlink_inode_operations = { <answer> const 
.get_link = <token> <answer> simple_get_link, 
static struct dentry *empty_dir_lookup(struct inode *dir, struct dentry *dentry, <token> int flags) <answer> unsigned 
<token> ERR_PTR(-ENOENT); <answer> return 
static <token> empty_dir_getattr(struct mnt_idmap *idmap, <answer> int 
const struct path <token> struct kstat *stat, <answer> *path, 
u32 <token> unsigned int query_flags) <answer> request_mask, 
<token> inode *inode = d_inode(path->dentry); <answer> struct 
<token> request_mask, inode, stat); <answer> generic_fillattr(&nop_mnt_idmap, 
<token> 0; <answer> return 
static int empty_dir_setattr(struct mnt_idmap <token> <answer> *idmap, 
struct dentry *dentry, <token> iattr *attr) <answer> struct 
return <token> <answer> -EPERM; 
static ssize_t empty_dir_listxattr(struct dentry *dentry, char *list, <token> size) <answer> size_t 
return <token> <answer> -EOPNOTSUPP; 
static <token> struct inode_operations empty_dir_inode_operations = { <answer> const 
<token> = empty_dir_lookup, <answer> .lookup 
.permission = <token> <answer> generic_permission, 
.setattr <token> empty_dir_setattr, <answer> = 
.getattr = <token> <answer> empty_dir_getattr, 
.listxattr <token> empty_dir_listxattr, <answer> = 
static loff_t empty_dir_llseek(struct <token> *file, loff_t offset, int whence) <answer> file 
<token> int generic_ci_d_compare(const struct dentry *dentry, unsigned int len, <answer> static 
const char *str, const struct qstr <token> <answer> *name) 
const <token> dentry *parent; <answer> struct 
<token> struct inode *dir; <answer> const 
char <token> <answer> strbuf[DNAME_INLINE_LEN]; 
struct qstr <token> <answer> qstr; 
if (len == name->len && <token> name->name, len)) <answer> !memcmp(str, 
<token> 0; <answer> return 
<token> = READ_ONCE(dentry->d_parent); <answer> parent 
<token> = READ_ONCE(parent->d_inode); <answer> dir 
if (!dir <token> !IS_CASEFOLDED(dir)) <answer> || 
return <token> <answer> 1; 
<token> (len <= DNAME_INLINE_LEN - 1) { <answer> if 
memcpy(strbuf, str, <token> <answer> len); 
strbuf[len] <token> 0; <answer> = 
str <token> strbuf; <answer> = 
static int generic_ci_d_hash(const struct dentry *dentry, <token> qstr *str) <answer> struct 
const struct <token> *dir = READ_ONCE(dentry->d_inode); <answer> inode 
struct super_block <token> = dentry->d_sb; <answer> *sb 
const struct <token> *um = sb->s_encoding; <answer> unicode_map 
<token> ret; <answer> int 
<token> (!dir || !IS_CASEFOLDED(dir)) <answer> if 
return <token> <answer> 0; 
ret <token> utf8_casefold_hash(um, dentry, str); <answer> = 
if (ret < 0 <token> sb_has_strict_encoding(sb)) <answer> && 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
<token> const struct dentry_operations generic_ci_dentry_ops = { <answer> static 
<token> = generic_ci_d_hash, <answer> .d_hash 
.d_compare <token> generic_ci_d_compare, <answer> = 
<token> CONFIG_FS_ENCRYPTION <answer> #ifdef 
.d_revalidate = <token> <answer> fscrypt_d_revalidate, 
#ifdef <token> <answer> CONFIG_FS_ENCRYPTION 
static const <token> dentry_operations generic_encrypted_dentry_ops = { <answer> struct 
.d_revalidate <token> fscrypt_d_revalidate, <answer> = 
void generic_set_sb_d_ops(struct <token> *sb) <answer> super_block 
<token> IS_ENABLED(CONFIG_UNICODE) <answer> #if 
if (sb->s_encoding) <token> <answer> { 
<token> = &generic_ci_dentry_ops; <answer> sb->s_d_op 
#ifdef <token> <answer> CONFIG_FS_ENCRYPTION 
<token> (sb->s_cop) { <answer> if 
sb->s_d_op = <token> <answer> &generic_encrypted_dentry_ops; 
bool inode_maybe_inc_iversion(struct inode <token> bool force) <answer> *inode, 
u64 <token> new; <answer> cur, 
cur = <token> <answer> inode_peek_iversion_raw(inode); 
do <token> <answer> { 
<token> inode_query_iversion(struct inode *inode) <answer> u64 
<token> cur, new; <answer> u64 
cur <token> inode_peek_iversion_raw(inode); <answer> = 
do <token> <answer> { 
new = cur <token> I_VERSION_QUERIED; <answer> | 
} while (!atomic64_try_cmpxchg(&inode->i_version, &cur, <token> <answer> new)); 
return cur >> <token> <answer> I_VERSION_QUERIED_SHIFT; 
<token> direct_write_fallback(struct kiocb *iocb, struct iov_iter *iter, <answer> ssize_t 
ssize_t direct_written, <token> buffered_written) <answer> ssize_t 
struct address_space *mapping <token> iocb->ki_filp->f_mapping; <answer> = 
loff_t pos = iocb->ki_pos <token> buffered_written; <answer> - 
loff_t <token> = iocb->ki_pos - 1; <answer> end 
<token> err; <answer> int 
if (unlikely(buffered_written <token> 0)) { <answer> < 
if <token> <answer> (direct_written) 
return <token> <answer> direct_written; 
<token> buffered_written; <answer> return 
err <token> filemap_write_and_wait_range(mapping, pos, end); <answer> = 
<token> (err < 0) { <answer> if 
iocb->ki_pos -= <token> <answer> buffered_written; 
<token> (direct_written) <answer> if 
return <token> <answer> direct_written; 
<token> err; <answer> return 
invalidate_mapping_pages(mapping, pos >> PAGE_SHIFT, end <token> PAGE_SHIFT); <answer> >> 
return <token> + buffered_written; <answer> direct_written 
struct timespec64 simple_inode_init_ts(struct <token> *inode) <answer> inode 
struct timespec64 ts <token> inode_set_ctime_current(inode); <answer> = 
inode_set_atime_to_ts(inode, <token> <answer> ts); 
inode_set_mtime_to_ts(inode, <token> <answer> ts); 
<token> ts; <answer> return 
static inline struct <token> *get_stashed_dentry(struct dentry *stashed) <answer> dentry 
struct <token> *dentry; <answer> dentry 
dentry = <token> <answer> READ_ONCE(stashed); 
if <token> <answer> (!dentry) 
return <token> <answer> NULL; 
if <token> <answer> (!lockref_get_not_dead(&dentry->d_lockref)) 
<token> NULL; <answer> return 
<token> dentry; <answer> return 
static struct dentry *prepare_anon_dentry(struct dentry <token> <answer> **stashed, 
struct super_block <token> <answer> *sb, 
void <token> <answer> *data) 
struct <token> *dentry; <answer> dentry 
<token> inode *inode; <answer> struct 
<token> struct stashed_operations *sops = sb->s_fs_info; <answer> const 
int <token> <answer> ret; 
<token> = new_inode_pseudo(sb); <answer> inode 
if <token> { <answer> (!inode) 
<token> ERR_PTR(-ENOMEM); <answer> return 
inode->i_flags <token> S_IMMUTABLE; <answer> |= 
<token> = S_IFREG; <answer> inode->i_mode 
<token> = sops->init_inode(inode, data); <answer> ret 
if (ret < <token> { <answer> 0) 
<token> ERR_PTR(ret); <answer> return 
int path_from_stashed(struct dentry **stashed, struct vfsmount *mnt, void <token> <answer> *data, 
struct <token> *path) <answer> path 
struct dentry <token> <answer> *dentry; 
const struct stashed_operations <token> = mnt->mnt_sb->s_fs_info; <answer> *sops 
<token> dentry, NULL); <answer> cmpxchg(stashed, 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/fs.h> 
#include <token> <answer> <linux/string.h> 
<token> <linux/slab.h> <answer> #include 
<token> <linux/pm.h> <answer> #include 
#include <token> <answer> <linux/timer.h> 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/input.h> 
#include <token> <answer> <linux/mfd/ezx-pcap.h> 
struct <token> { <answer> pcap_ts 
struct pcap_chip <token> <answer> *pcap; 
<token> input_dev *input; <answer> struct 
struct delayed_work <token> <answer> work; 
u16 x, <token> <answer> y; 
u16 <token> <answer> pressure; 
u8 <token> <answer> read_state; 
<token> COMPILE_OFFSETS <answer> #define 
#include <token> <answer> <linux/crypto.h> 
#include <token> <answer> <crypto/aria.h> 
<token> <linux/sched.h> <answer> #include 
#include <token> <answer> <linux/stddef.h> 
<token> <linux/hardirq.h> <answer> #include 
<token> <linux/suspend.h> <answer> #include 
#include <token> <answer> <linux/kbuild.h> 
<token> <asm/processor.h> <answer> #include 
<token> <asm/thread_info.h> <answer> #include 
<token> <asm/sigframe.h> <answer> #include 
#include <token> <answer> <asm/bootparam.h> 
#include <token> <answer> <asm/suspend.h> 
#include <token> <answer> <asm/tlbflush.h> 
#include <token> <answer> <asm/tdx.h> 
#ifdef <token> <answer> CONFIG_XEN 
<token> <xen/interface/xen.h> <answer> #include 
<token> CONFIG_X86_32 <answer> #ifdef 
<token> include "asm-offsets_32.c" <answer> # 
<token> include "asm-offsets_64.c" <answer> # 
static <token> __used common(void) <answer> void 
<token> task_struct, thread.sp); <answer> OFFSET(TASK_threadsp, 
<token> CONFIG_STACKPROTECTOR <answer> #ifdef 
OFFSET(TASK_stack_canary, task_struct, <token> <answer> stack_canary); 
<token> pbe, address); <answer> OFFSET(pbe_address, 
<token> pbe, orig_address); <answer> OFFSET(pbe_orig_address, 
OFFSET(pbe_next, <token> next); <answer> pbe, 
#if <token> || defined(CONFIG_IA32_EMULATION) <answer> defined(CONFIG_X86_32) 
OFFSET(IA32_SIGCONTEXT_ax, sigcontext_32, <token> <answer> ax); 
OFFSET(IA32_SIGCONTEXT_bx, <token> bx); <answer> sigcontext_32, 
OFFSET(IA32_SIGCONTEXT_cx, <token> cx); <answer> sigcontext_32, 
OFFSET(IA32_SIGCONTEXT_dx, sigcontext_32, <token> <answer> dx); 
<token> sigcontext_32, si); <answer> OFFSET(IA32_SIGCONTEXT_si, 
OFFSET(IA32_SIGCONTEXT_di, <token> di); <answer> sigcontext_32, 
OFFSET(IA32_SIGCONTEXT_bp, <token> bp); <answer> sigcontext_32, 
OFFSET(IA32_SIGCONTEXT_sp, <token> sp); <answer> sigcontext_32, 
OFFSET(IA32_SIGCONTEXT_ip, <token> ip); <answer> sigcontext_32, 
OFFSET(IA32_RT_SIGFRAME_sigcontext, <token> uc.uc_mcontext); <answer> rt_sigframe_ia32, 
#ifdef <token> <answer> CONFIG_XEN 
<token> vcpu_info, evtchn_upcall_mask); <answer> OFFSET(XEN_vcpu_info_mask, 
OFFSET(XEN_vcpu_info_pending, <token> evtchn_upcall_pending); <answer> vcpu_info, 
OFFSET(XEN_vcpu_info_arch_cr2, <token> arch.cr2); <answer> vcpu_info, 
OFFSET(TDX_MODULE_rcx, tdx_module_args, <token> <answer> rcx); 
OFFSET(TDX_MODULE_rdx, <token> rdx); <answer> tdx_module_args, 
OFFSET(TDX_MODULE_r8, tdx_module_args, <token> <answer> r8); 
OFFSET(TDX_MODULE_r9, <token> r9); <answer> tdx_module_args, 
OFFSET(TDX_MODULE_r10, <token> r10); <answer> tdx_module_args, 
OFFSET(TDX_MODULE_r11, <token> r11); <answer> tdx_module_args, 
OFFSET(TDX_MODULE_r12, tdx_module_args, <token> <answer> r12); 
<token> tdx_module_args, r13); <answer> OFFSET(TDX_MODULE_r13, 
<token> tdx_module_args, r14); <answer> OFFSET(TDX_MODULE_r14, 
OFFSET(TDX_MODULE_r15, <token> r15); <answer> tdx_module_args, 
OFFSET(TDX_MODULE_rbx, tdx_module_args, <token> <answer> rbx); 
OFFSET(TDX_MODULE_rdi, tdx_module_args, <token> <answer> rdi); 
OFFSET(TDX_MODULE_rsi, <token> rsi); <answer> tdx_module_args, 
OFFSET(BP_scratch, <token> scratch); <answer> boot_params, 
OFFSET(BP_secure_boot, boot_params, <token> <answer> secure_boot); 
<token> boot_params, hdr.loadflags); <answer> OFFSET(BP_loadflags, 
OFFSET(BP_hardware_subarch, boot_params, <token> <answer> hdr.hardware_subarch); 
OFFSET(BP_version, <token> hdr.version); <answer> boot_params, 
<token> boot_params, hdr.kernel_alignment); <answer> OFFSET(BP_kernel_alignment, 
OFFSET(BP_init_size, <token> hdr.init_size); <answer> boot_params, 
OFFSET(BP_pref_address, boot_params, <token> <answer> hdr.pref_address); 
<token> sizeof(struct pt_regs)); <answer> DEFINE(PTREGS_SIZE, 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/reboot.h> <answer> #include 
#include <token> <answer> "iomap.h" 
#include <token> <answer> "common.h" 
#include <token> <answer> "control.h" 
<token> "prm3xxx.h" <answer> #include 
#define TI81XX_PRM_DEVICE_RSTCTRL <token> <answer> 0x00a0 
#define <token> BIT(1) <answer> TI81XX_GLOBAL_RST_COLD 
void ti81xx_restart(enum <token> mode, const char *cmd) <answer> reboot_mode 
<token> 0, <answer> omap2_prm_set_mod_reg_bits(TI81XX_GLOBAL_RST_COLD, 
<token> (1) <answer> while 
#include <token> <answer> <linux/delay.h> 
<token> <linux/pci.h> <answer> #include 
<token> <linux/vmalloc.h> <answer> #include 
#include <token> <answer> "qib.h" 
#include <token> <answer> "qib_qsfp.h" 
<token> QSFP_MAX_RETRY 4 <answer> #define 
<token> int qsfp_read(struct qib_pportdata *ppd, int addr, void *bp, int len) <answer> static 
struct qib_devdata *dd = <token> <answer> ppd->dd; 
u32 <token> mask; <answer> out, 
int ret, cnt, pass <token> 0; <answer> = 
int stuck = <token> <answer> 0; 
u8 <token> = bp; <answer> *buff 
ret = <token> <answer> mutex_lock_interruptible(&dd->eep_lock); 
if <token> <answer> (ret) 
goto <token> <answer> no_unlock; 
<token> (dd->twsi_eeprom_dev == QIB_TWSI_NO_DEV) { <answer> if 
ret <token> -ENXIO; <answer> = 
<token> bail; <answer> goto 
mask = QSFP_GPIO_MOD_SEL_N <token> QSFP_GPIO_MOD_RST_N | QSFP_GPIO_LP_MODE; <answer> | 
<token> = QSFP_GPIO_MOD_RST_N | QSFP_GPIO_LP_MODE; <answer> out 
<token> (ppd->hw_pidx) { <answer> if 
mask <<= <token> <answer> QSFP_GPIO_PORT2_SHIFT; 
<token> <<= QSFP_GPIO_PORT2_SHIFT; <answer> out 
dd->f_gpio_mod(dd, out, mask, <token> <answer> mask); 
if <token> <answer> (stuck) 
qib_dev_err(dd, "QSFP interface bus stuck <token> <answer> non-idle\n"); 
if <token> >= QSFP_MAX_RETRY && ret) <answer> (pass 
qib_dev_porterr(dd, ppd->port, "QSFP failed <token> retrying\n"); <answer> even 
<token> if (pass) <answer> else 
qib_dev_porterr(dd, ppd->port, "QSFP retries: %d\n", <token> <answer> pass); 
return <token> <answer> ret; 
static int qib_qsfp_write(struct qib_pportdata *ppd, <token> addr, void *bp, <answer> int 
<token> len) <answer> int 
struct qib_devdata *dd <token> ppd->dd; <answer> = 
u32 out, <token> <answer> mask; 
<token> ret, cnt; <answer> int 
<token> *buff = bp; <answer> u8 
<token> = mutex_lock_interruptible(&dd->eep_lock); <answer> ret 
if <token> <answer> (ret) 
<token> no_unlock; <answer> goto 
if (dd->twsi_eeprom_dev == <token> { <answer> QIB_TWSI_NO_DEV) 
<token> = -ENXIO; <answer> ret 
<token> bail; <answer> goto 
mask = QSFP_GPIO_MOD_SEL_N | QSFP_GPIO_MOD_RST_N <token> QSFP_GPIO_LP_MODE; <answer> | 
out <token> QSFP_GPIO_MOD_RST_N | QSFP_GPIO_LP_MODE; <answer> = 
<token> (ppd->hw_pidx) { <answer> if 
mask <token> QSFP_GPIO_PORT2_SHIFT; <answer> <<= 
<token> <<= QSFP_GPIO_PORT2_SHIFT; <answer> out 
<token> out, mask, mask); <answer> dd->f_gpio_mod(dd, 
return <token> <answer> ret; 
static int qsfp_cks(struct qib_pportdata *ppd, int <token> int next) <answer> first, 
int <token> <answer> ret; 
u16 <token> <answer> cks; 
u8 <token> <answer> bval; 
<token> = 0; <answer> cks 
<token> (first < next) { <answer> while 
ret <token> qsfp_read(ppd, first, &bval, 1); <answer> = 
if (ret <token> 0) <answer> < 
goto <token> <answer> bail; 
<token> += bval; <answer> cks 
<token> = cks & 0xFF; <answer> ret 
return <token> <answer> ret; 
int qib_refresh_qsfp_cache(struct qib_pportdata *ppd, struct <token> *cp) <answer> qib_qsfp_cache 
<token> ret; <answer> int 
int <token> <answer> idx; 
u16 <token> <answer> cks; 
<token> peek[4]; <answer> u8 
u8 poke <token> 0; <answer> = 
ret <token> qib_qsfp_write(ppd, 127, &poke, 1); <answer> = 
if (ret != <token> { <answer> 1) 
qib_dev_porterr(ppd->dd, <token> <answer> ppd->port, 
"Failed QSFP Page <token> <answer> set\n"); 
goto <token> <answer> bail; 
ret = qsfp_read(ppd, <token> &cp->id, 1); <answer> QSFP_MOD_ID_OFFS, 
if (ret <token> 0) <answer> < 
goto <token> <answer> bail; 
if ((cp->id & <token> != 0x0C) <answer> 0xFE) 
qib_dev_porterr(ppd->dd, <token> <answer> ppd->port, 
"QSFP ID byte <token> 0x%02X, S/B 0x0C/D\n", cp->id); <answer> is 
cks = <token> <answer> cp->id; 
ret <token> qsfp_read(ppd, QSFP_MOD_PWR_OFFS, &cp->pwr, 1); <answer> = 
if <token> < 0) <answer> (ret 
<token> bail; <answer> goto 
cks <token> cp->pwr; <answer> += 
ret = <token> QSFP_MOD_PWR_OFFS + 1, QSFP_MOD_LEN_OFFS); <answer> qsfp_cks(ppd, 
<token> (ret < 0) <answer> if 
goto <token> <answer> bail; 
cks += <token> <answer> ret; 
ret = qsfp_read(ppd, QSFP_MOD_LEN_OFFS, &cp->len, <token> <answer> 1); 
if (ret < <token> <answer> 0) 
<token> bail; <answer> goto 
cks += <token> <answer> cp->len; 
ret = qsfp_read(ppd, QSFP_MOD_TECH_OFFS, <token> 1); <answer> &cp->tech, 
if (ret <token> 0) <answer> < 
goto <token> <answer> bail; 
cks <token> cp->tech; <answer> += 
ret = qsfp_read(ppd, <token> &cp->vendor, QSFP_VEND_LEN); <answer> QSFP_VEND_OFFS, 
if <token> < 0) <answer> (ret 
<token> bail; <answer> goto 
<token> (idx = 0; idx < QSFP_VEND_LEN; ++idx) <answer> for 
cks <token> cp->vendor[idx]; <answer> += 
ret <token> qsfp_read(ppd, QSFP_IBXCV_OFFS, &cp->xt_xcv, 1); <answer> = 
if (ret <token> 0) <answer> < 
goto <token> <answer> bail; 
cks += <token> <answer> cp->xt_xcv; 
ret = qsfp_read(ppd, QSFP_VOUI_OFFS, &cp->oui, <token> <answer> QSFP_VOUI_LEN); 
if (ret <token> 0) <answer> < 
goto <token> <answer> bail; 
for (idx = 0; <token> < QSFP_VOUI_LEN; ++idx) <answer> idx 
cks <token> cp->oui[idx]; <answer> += 
ret = qsfp_read(ppd, QSFP_PN_OFFS, <token> QSFP_PN_LEN); <answer> &cp->partnum, 
if <token> < 0) <answer> (ret 
goto <token> <answer> bail; 
for (idx = 0; idx < QSFP_PN_LEN; <token> <answer> ++idx) 
<token> += cp->partnum[idx]; <answer> cks 
ret = qsfp_read(ppd, QSFP_REV_OFFS, &cp->rev, <token> <answer> QSFP_REV_LEN); 
if <token> < 0) <answer> (ret 
<token> bail; <answer> goto 
for (idx = 0; <token> < QSFP_REV_LEN; ++idx) <answer> idx 
cks <token> cp->rev[idx]; <answer> += 
ret <token> qsfp_read(ppd, QSFP_ATTEN_OFFS, &cp->atten, QSFP_ATTEN_LEN); <answer> = 
if <token> < 0) <answer> (ret 
goto <token> <answer> bail; 
for (idx = 0; idx < <token> ++idx) <answer> QSFP_ATTEN_LEN; 
cks += <token> <answer> cp->atten[idx]; 
<token> = qsfp_cks(ppd, QSFP_ATTEN_OFFS + QSFP_ATTEN_LEN, QSFP_CC_OFFS); <answer> ret 
if (ret <token> 0) <answer> < 
goto <token> <answer> bail; 
<token> += ret; <answer> cks 
<token> &= 0xFF; <answer> cks 
ret = qsfp_read(ppd, <token> &cp->cks1, 1); <answer> QSFP_CC_OFFS, 
if <token> < 0) <answer> (ret 
goto <token> <answer> bail; 
if <token> != cp->cks1) <answer> (cks 
qib_dev_porterr(ppd->dd, <token> <answer> ppd->port, 
<token> cks1 is %02X, computed %02X\n", cp->cks1, <answer> "QSFP 
<token> qib_qsfp_init(struct qib_qsfp_data *qd, <answer> void 
void <token> work_struct *)) <answer> (*fevent)(struct 
u32 mask, <token> <answer> highs; 
struct qib_devdata *dd <token> qd->ppd->dd; <answer> = 
mask = QSFP_GPIO_MOD_SEL_N | QSFP_GPIO_MOD_RST_N <token> QSFP_GPIO_LP_MODE; <answer> | 
<token> = mask - QSFP_GPIO_MOD_RST_N; <answer> highs 
if <token> { <answer> (qd->ppd->hw_pidx) 
mask <token> QSFP_GPIO_PORT2_SHIFT; <answer> <<= 
highs <token> QSFP_GPIO_PORT2_SHIFT; <answer> <<= 
dd->f_gpio_mod(dd, <token> mask, mask); <answer> highs, 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/string.h> <answer> #include 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <net/netlabel.h> 
#include <token> <answer> "sidtab.h" 
<token> "mls.h" <answer> #include 
<token> "policydb.h" <answer> #include 
#include <token> <answer> "services.h" 
int <token> policydb *p, struct context *context) <answer> mls_compute_context_len(struct 
int i, l, len, head, <token> <answer> prev; 
char <token> <answer> *nm; 
struct ebitmap <token> <answer> *e; 
struct ebitmap_node <token> <answer> *node; 
<token> (!p->mls_enabled) <answer> if 
return <token> <answer> 0; 
void mls_sid_to_context(struct <token> *p, struct context *context, <answer> policydb 
char <token> <answer> **scontext) 
char *scontextp, <token> <answer> *nm; 
int i, l, <token> prev; <answer> head, 
<token> ebitmap *e; <answer> struct 
<token> ebitmap_node *node; <answer> struct 
<token> (!p->mls_enabled) <answer> if 
<token> = *scontext; <answer> scontextp 
<token> = ':'; <answer> *scontextp 
for <token> = 0; l < 2; l++) { <answer> (l 
strcpy(scontextp, sym_name(p, <token> <answer> SYM_LEVELS, 
context->range.level[l].sens <token> 1)); <answer> - 
<token> += strlen(scontextp); <answer> scontextp 
return ebitmap_contains(&levdatum->level->cat, <token> <answer> &l->cat, 
int mls_range_isvalid(struct policydb <token> struct mls_range *r) <answer> *p, 
<token> (mls_level_isvalid(p, &r->level[0]) && <answer> return 
<token> &r->level[1]) && <answer> mls_level_isvalid(p, 
<token> &r->level[0])); <answer> mls_level_dom(&r->level[1], 
int mls_context_isvalid(struct <token> *p, struct context *c) <answer> policydb 
struct user_datum <token> <answer> *usrdatum; 
if <token> <answer> (!p->mls_enabled) 
return <token> <answer> 1; 
<token> (!mls_range_isvalid(p, &c->range)) <answer> if 
return <token> <answer> 0; 
<token> (c->role == OBJECT_R_VAL) <answer> if 
return <token> <answer> 1; 
if (!c->user || c->user > <token> <answer> p->p_users.nprim) 
<token> 0; <answer> return 
usrdatum <token> p->user_val_to_struct[c->user - 1]; <answer> = 
if <token> c->range)) <answer> (!mls_range_contains(usrdatum->range, 
<token> mls_context_to_sid(struct policydb *pol, char oldc, char *scontext, <answer> int 
<token> context *context, struct sidtab *s, u32 def_sid) <answer> struct 
char *sensitivity, *cur_cat, *next_cat, <token> <answer> *rngptr; 
<token> level_datum *levdatum; <answer> struct 
struct cat_datum <token> *rngdatum; <answer> *catdatum, 
u32 <token> <answer> i; 
int <token> rc; <answer> l, 
char <token> <answer> *rangep[2]; 
<token> (!pol->mls_enabled) { <answer> if 
if (oldc <token> def_sid == SECSID_NULL) <answer> && 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
if (!oldc) <token> <answer> { 
struct context <token> <answer> *defcon; 
<token> (def_sid == SECSID_NULL) <answer> if 
return <token> <answer> -EINVAL; 
defcon = sidtab_search(s, <token> <answer> def_sid); 
<token> (!defcon) <answer> if 
<token> -EINVAL; <answer> return 
return mls_context_cpy(context, <token> <answer> defcon); 
rangep[0] = <token> <answer> scontext; 
rangep[1] = strchr(scontext, <token> <answer> '-'); 
if <token> { <answer> (rangep[1]) 
<token> = '\0'; <answer> rangep[1][0] 
int mls_from_string(struct <token> *p, char *str, struct context *context, <answer> policydb 
gfp_t <token> <answer> gfp_mask) 
<token> *tmpstr; <answer> char 
<token> rc; <answer> int 
<token> (!p->mls_enabled) <answer> if 
return <token> <answer> -EINVAL; 
tmpstr <token> kstrdup(str, gfp_mask); <answer> = 
if <token> { <answer> (!tmpstr) 
<token> = -ENOMEM; <answer> rc 
} <token> { <answer> else 
rc <token> mls_context_to_sid(p, ':', tmpstr, context, NULL, <answer> = 
return <token> <answer> rc; 
<token> mls_range_set(struct context *context, struct mls_range *range) <answer> int 
int <token> rc = 0; <answer> l, 
<token> (mls_level_dom(user_clr, fromcon_clr)) <answer> if 
*usercon_clr = <token> <answer> *fromcon_clr; 
else <token> (mls_level_dom(fromcon_clr, user_clr)) <answer> if 
<token> = *user_clr; <answer> *usercon_clr 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
int <token> policydb *oldp, struct policydb *newp, <answer> mls_convert_context(struct 
struct context <token> struct context *newc) <answer> *oldc, 
<token> level_datum *levdatum; <answer> struct 
struct cat_datum <token> <answer> *catdatum; 
struct <token> *node; <answer> ebitmap_node 
u32 <token> <answer> i; 
<token> l; <answer> int 
if <token> || !newp->mls_enabled) <answer> (!oldp->mls_enabled 
<token> 0; <answer> return 
for (l = 0; l < 2; <token> { <answer> l++) 
char *name <token> sym_name(oldp, SYM_LEVELS, <answer> = 
oldc->range.level[l].sens - <token> <answer> 1); 
levdatum <token> symtab_search(&newp->p_levels, name); <answer> = 
<token> (!levdatum) <answer> if 
return <token> <answer> -EINVAL; 
newc->range.level[l].sens = <token> <answer> levdatum->level->sens; 
ebitmap_for_each_positive_bit(&oldc->range.level[l].cat, <token> <answer> node, 
int <token> <answer> rc; 
catdatum <token> symtab_search(&newp->p_cats, <answer> = 
sym_name(oldp, <token> i)); <answer> SYM_CATS, 
<token> (!catdatum) <answer> if 
<token> -EINVAL; <answer> return 
rc <token> ebitmap_set_bit(&newc->range.level[l].cat, <answer> = 
<token> - 1, 1); <answer> catdatum->value 
<token> (rc) <answer> if 
<token> rc; <answer> return 
<token> 0; <answer> return 
<token> mls_compute_sid(struct policydb *p, struct context *scontext, <answer> int 
struct context <token> u16 tclass, u32 specified, <answer> *tcontext, 
struct context <token> bool sock) <answer> *newcontext, 
struct <token> rtr; <answer> range_trans 
struct <token> *r; <answer> mls_range 
struct <token> *cladatum; <answer> class_datum 
char <token> = 0; <answer> default_range 
if <token> <answer> (!p->mls_enabled) 
<token> 0; <answer> return 
switch <token> { <answer> (specified) 
case <token> <answer> AVTAB_TRANSITION: 
void mls_export_netlbl_lvl(struct policydb *p, struct context <token> <answer> *context, 
struct netlbl_lsm_secattr <token> <answer> *secattr) 
<token> (!p->mls_enabled) <answer> if 
secattr->attr.mls.lvl = context->range.level[0].sens - <token> <answer> 1; 
secattr->flags <token> NETLBL_SECATTR_MLS_LVL; <answer> |= 
void mls_import_netlbl_lvl(struct policydb *p, struct context <token> <answer> *context, 
struct <token> *secattr) <answer> netlbl_lsm_secattr 
if <token> <answer> (!p->mls_enabled) 
context->range.level[0].sens = <token> + 1; <answer> secattr->attr.mls.lvl 
context->range.level[1].sens <token> context->range.level[0].sens; <answer> = 
int mls_export_netlbl_cat(struct policydb *p, <token> context *context, <answer> struct 
struct <token> *secattr) <answer> netlbl_lsm_secattr 
<token> rc; <answer> int 
if <token> <answer> (!p->mls_enabled) 
return <token> <answer> 0; 
rc <token> ebitmap_netlbl_export(&context->range.level[0].cat, <answer> = 
if <token> == 0 && secattr->attr.mls.cat != NULL) <answer> (rc 
secattr->flags <token> NETLBL_SECATTR_MLS_CAT; <answer> |= 
return <token> <answer> rc; 
int <token> policydb *p, struct context *context, <answer> mls_import_netlbl_cat(struct 
struct <token> *secattr) <answer> netlbl_lsm_secattr 
<token> rc; <answer> int 
<token> (!p->mls_enabled) <answer> if 
return <token> <answer> 0; 
rc = <token> <answer> ebitmap_netlbl_import(&context->range.level[0].cat, 
if <token> <answer> (rc) 
<token> import_netlbl_cat_failure; <answer> goto 
memcpy(&context->range.level[1].cat, <token> <answer> &context->range.level[0].cat, 
return <token> <answer> 0; 
return <token> <answer> rc; 
<token> NDEBUG <answer> #undef 
#include <token> <answer> <assert.h> 
<token> <errno.h> <answer> #include 
<token> <sched.h> <answer> #include 
<token> <signal.h> <answer> #include 
<token> <stdbool.h> <answer> #include 
<token> <stdint.h> <answer> #include 
<token> <stdio.h> <answer> #include 
#include <token> <answer> <string.h> 
#include <token> <answer> <stdlib.h> 
#include <token> <answer> <sys/mount.h> 
#include <token> <answer> <sys/types.h> 
<token> <sys/stat.h> <answer> #include 
<token> <sys/wait.h> <answer> #include 
<token> <fcntl.h> <answer> #include 
<token> <unistd.h> <answer> #include 
<token> <sys/syscall.h> <answer> #include 
<token> <sys/uio.h> <answer> #include 
#include <token> <answer> <linux/kdev_t.h> 
<token> <sys/time.h> <answer> #include 
#include <token> <answer> <sys/resource.h> 
<token> "../kselftest.h" <answer> #include 
<token> inline long sys_execveat(int dirfd, const char *pathname, char **argv, char **envp, int flags) <answer> static 
return syscall(SYS_execveat, dirfd, pathname, argv, <token> flags); <answer> envp, 
static void <token> <answer> make_private_tmp(void) 
if (unshare(CLONE_NEWNS) == -1) <token> <answer> { 
if (errno == ENOSYS || <token> == EPERM) { <answer> errno 
if (mount(NULL, "/", <token> MS_PRIVATE|MS_REC, NULL) == -1) { <answer> NULL, 
if (mount(NULL, "/tmp", "tmpfs", 0, NULL) <token> -1) { <answer> == 
static pid_t pid = <token> <answer> -1; 
static <token> ate(void) <answer> void 
if <token> > 0) { <answer> (pid 
<token> SIGTERM); <answer> kill(pid, 
struct <token> { <answer> elf64_hdr 
uint8_t <token> <answer> e_ident[16]; 
uint16_t <token> <answer> e_type; 
uint16_t <token> <answer> e_machine; 
uint32_t <token> <answer> e_version; 
<token> e_entry; <answer> uint64_t 
<token> e_phoff; <answer> uint64_t 
<token> e_shoff; <answer> uint64_t 
uint32_t <token> <answer> e_flags; 
<token> e_ehsize; <answer> uint16_t 
uint16_t <token> <answer> e_phentsize; 
uint16_t <token> <answer> e_phnum; 
<token> e_shentsize; <answer> uint16_t 
uint16_t <token> <answer> e_shnum; 
<token> e_shstrndx; <answer> uint16_t 
struct <token> { <answer> elf64_phdr 
<token> p_type; <answer> uint32_t 
uint32_t <token> <answer> p_flags; 
uint64_t <token> <answer> p_offset; 
uint64_t <token> <answer> p_vaddr; 
<token> p_paddr; <answer> uint64_t 
<token> p_filesz; <answer> uint64_t 
<token> p_memsz; <answer> uint64_t 
uint64_t <token> <answer> p_align; 
#ifdef <token> <answer> __x86_64__ 
<token> PAGE_SIZE 4096 <answer> #define 
#define VADDR (1UL << <token> <answer> 32) 
#define MAPS_OFFSET <token> <answer> 73 
#define syscall <token> 0x05 <answer> 0x0f, 
<token> mov_rdi(x) \ <answer> #define 
<token> 0xbf, \ <answer> 0x48, 
(x)&0xff, <token> ((x)>>16)&0xff, ((x)>>24)&0xff, \ <answer> ((x)>>8)&0xff, 
((x)>>32)&0xff, ((x)>>40)&0xff, ((x)>>48)&0xff, <token> <answer> ((x)>>56)&0xff 
<token> mov_rsi(x) \ <answer> #define 
0x48, 0xbe, <token> <answer> \ 
(x)&0xff, ((x)>>8)&0xff, ((x)>>16)&0xff, <token> \ <answer> ((x)>>24)&0xff, 
((x)>>32)&0xff, ((x)>>40)&0xff, <token> ((x)>>56)&0xff <answer> ((x)>>48)&0xff, 
<token> mov_eax(x) \ <answer> #define 
0xb8, (x)&0xff, <token> ((x)>>16)&0xff, ((x)>>24)&0xff <answer> ((x)>>8)&0xff, 
static <token> uint8_t payload[] = { <answer> const 
static <token> int g_vsyscall; <answer> volatile 
static const char <token> <answer> *str_vsyscall; 
static const char <token> = ""; <answer> str_vsyscall_0[] 
static const char <token> = <answer> str_vsyscall_1[] 
"ffffffffff600000-ffffffffff601000 --xp 00000000 00:00 <token> [vsyscall]\n"; <answer> 0 
static <token> char str_vsyscall_2[] = <answer> const 
"ffffffffff600000-ffffffffff601000 <token> 00000000 00:00 0 [vsyscall]\n"; <answer> r-xp 
<token> __x86_64__ <answer> #ifdef 
static void sigaction_SIGSEGV(int _, siginfo_t *__, <token> *___) <answer> void 
<token> void vsyscall(void) <answer> static 
<token> pid; <answer> pid_t 
<token> wstatus; <answer> int 
<token> = fork(); <answer> pid 
if (pid < <token> { <answer> 0) 
<token> "fork, errno %d\n", errno); <answer> fprintf(stderr, 
if (pid == 0) <token> <answer> { 
struct rlimit rlim = <token> 0}; <answer> {0, 
<token> &rlim); <answer> (void)setrlimit(RLIMIT_CORE, 
<token> <linux/err.h> <answer> #include 
<token> <linux/export.h> <answer> #include 
<token> <linux/if_ether.h> <answer> #include 
#include <token> <answer> <linux/igmp.h> 
<token> <linux/in.h> <answer> #include 
#include <token> <answer> <linux/jhash.h> 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/log2.h> 
#include <token> <answer> <linux/netdevice.h> 
#include <token> <answer> <linux/netfilter_bridge.h> 
<token> <linux/random.h> <answer> #include 
#include <token> <answer> <linux/rculist.h> 
#include <token> <answer> <linux/skbuff.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/timer.h> 
<token> <linux/inetdevice.h> <answer> #include 
#include <token> <answer> <linux/mroute.h> 
<token> <net/ip.h> <answer> #include 
#include <token> <answer> <net/switchdev.h> 
<token> IS_ENABLED(CONFIG_IPV6) <answer> #if 
<token> <linux/icmpv6.h> <answer> #include 
<token> <net/ipv6.h> <answer> #include 
<token> <net/mld.h> <answer> #include 
<token> <net/ip6_checksum.h> <answer> #include 
#include <token> <answer> <net/addrconf.h> 
<token> "br_private.h" <answer> #include 
#include <token> <answer> "br_private_mcast_eht.h" 
static bool <token> net_bridge_port_group *pg, <answer> br_multicast_del_eht_set_entry(struct 
union net_bridge_eht_addr <token> <answer> *src_addr, 
union <token> *h_addr); <answer> net_bridge_eht_addr 
static <token> br_multicast_create_eht_set_entry(const struct net_bridge_mcast *brmctx, <answer> void 
struct net_bridge_port_group <token> <answer> *pg, 
union net_bridge_eht_addr <token> <answer> *src_addr, 
<token> net_bridge_eht_addr *h_addr, <answer> union 
<token> filter_mode, <answer> int 
<token> allow_zero_src); <answer> bool 
<token> struct net_bridge_group_eht_host * <answer> static 
br_multicast_eht_host_lookup(struct <token> *pg, <answer> net_bridge_port_group 
<token> net_bridge_eht_addr *h_addr) <answer> union 
struct rb_node *node <token> pg->eht_host_tree.rb_node; <answer> = 
while (node) <token> <answer> { 
struct <token> *this; <answer> net_bridge_group_eht_host 
int <token> <answer> result; 
this <token> rb_entry(node, struct net_bridge_group_eht_host, <answer> = 
result = memcmp(h_addr, <token> sizeof(*h_addr)); <answer> &this->h_addr, 
if (result <token> 0) <answer> < 
node <token> node->rb_left; <answer> = 
else if (result > <token> <answer> 0) 
<token> = node->rb_right; <answer> node 
<token> this; <answer> return 
return <token> <answer> NULL; 
static int br_multicast_eht_host_filter_mode(struct <token> *pg, <answer> net_bridge_port_group 
union net_bridge_eht_addr <token> <answer> *h_addr) 
struct <token> *eht_host; <answer> net_bridge_group_eht_host 
eht_host <token> br_multicast_eht_host_lookup(pg, h_addr); <answer> = 
<token> (!eht_host) <answer> if 
<token> MCAST_INCLUDE; <answer> return 
return <token> <answer> eht_host->filter_mode; 
static struct net_bridge_group_eht_set_entry <token> <answer> * 
br_multicast_eht_set_entry_lookup(struct net_bridge_group_eht_set <token> <answer> *eht_set, 
union net_bridge_eht_addr <token> <answer> *h_addr) 
struct rb_node *node = <token> <answer> eht_set->entry_tree.rb_node; 
while (node) <token> <answer> { 
struct net_bridge_group_eht_set_entry <token> <answer> *this; 
<token> result; <answer> int 
this = rb_entry(node, struct <token> <answer> net_bridge_group_eht_set_entry, 
result <token> memcmp(h_addr, &this->h_addr, sizeof(*h_addr)); <answer> = 
if (result < <token> <answer> 0) 
node <token> node->rb_left; <answer> = 
else if <token> > 0) <answer> (result 
node = <token> <answer> node->rb_right; 
return <token> <answer> this; 
return <token> <answer> NULL; 
static <token> net_bridge_group_eht_set * <answer> struct 
<token> net_bridge_port_group *pg, <answer> br_multicast_eht_set_lookup(struct 
union net_bridge_eht_addr <token> <answer> *src_addr) 
struct rb_node *node <token> pg->eht_set_tree.rb_node; <answer> = 
while (node) <token> <answer> { 
struct <token> *this; <answer> net_bridge_group_eht_set 
<token> result; <answer> int 
this = rb_entry(node, <token> net_bridge_group_eht_set, <answer> struct 
result <token> memcmp(src_addr, &this->src_addr, sizeof(*src_addr)); <answer> = 
<token> (result < 0) <answer> if 
<token> = node->rb_left; <answer> node 
else if (result > <token> <answer> 0) 
node = <token> <answer> node->rb_right; 
return <token> <answer> this; 
<token> NULL; <answer> return 
static <token> __eht_destroy_host(struct net_bridge_group_eht_host *eht_host) <answer> void 
rb_erase(&eht_host->rb_node, <token> <answer> &eht_host->pg->eht_host_tree); 
static <token> br_multicast_destroy_eht_set_entry(struct net_bridge_mcast_gc *gc) <answer> void 
struct <token> *set_h; <answer> net_bridge_group_eht_set_entry 
<token> = container_of(gc, struct net_bridge_group_eht_set_entry, mcast_gc); <answer> set_h 
<token> void br_multicast_destroy_eht_set(struct net_bridge_mcast_gc *gc) <answer> static 
struct <token> *eht_set; <answer> net_bridge_group_eht_set 
eht_set = container_of(gc, struct <token> mcast_gc); <answer> net_bridge_group_eht_set, 
<token> void __eht_del_set_entry(struct net_bridge_group_eht_set_entry *set_h) <answer> static 
<token> net_bridge_group_eht_host *eht_host = set_h->h_parent; <answer> struct 
union net_bridge_eht_addr <token> <answer> zero_addr; 
<token> &set_h->eht_set->entry_tree); <answer> rb_erase(&set_h->rb_node, 
memset(&zero_addr, 0, <token> <answer> sizeof(zero_addr)); 
if <token> &zero_addr, sizeof(zero_addr))) <answer> (memcmp(&set_h->h_addr, 
hlist_add_head(&set_h->mcast_gc.gc_node, <token> <answer> &set_h->br->mcast_gc_list); 
<token> &set_h->br->mcast_gc_work); <answer> queue_work(system_long_wq, 
if <token> <answer> (hlist_empty(&eht_host->set_entries)) 
static <token> br_multicast_del_eht_set(struct net_bridge_group_eht_set *eht_set) <answer> void 
struct <token> *set_h; <answer> net_bridge_group_eht_set_entry 
struct <token> *node; <answer> rb_node 
while <token> = rb_first(&eht_set->entry_tree))) { <answer> ((node 
set_h = rb_entry(node, struct <token> <answer> net_bridge_group_eht_set_entry, 
<token> &eht_set->pg->eht_set_tree); <answer> rb_erase(&eht_set->rb_node, 
hlist_add_head(&eht_set->mcast_gc.gc_node, <token> <answer> &eht_set->br->mcast_gc_list); 
<token> &eht_set->br->mcast_gc_work); <answer> queue_work(system_long_wq, 
void br_multicast_eht_clean_sets(struct <token> *pg) <answer> net_bridge_port_group 
struct <token> *eht_set; <answer> net_bridge_group_eht_set 
<token> rb_node *node; <answer> struct 
while ((node <token> rb_first(&pg->eht_set_tree))) { <answer> = 
eht_set = <token> struct net_bridge_group_eht_set, <answer> rb_entry(node, 
static void <token> timer_list *t) <answer> br_multicast_eht_set_entry_expired(struct 
struct net_bridge_group_eht_set_entry *set_h = from_timer(set_h, t, <token> <answer> timer); 
struct net_bridge <token> = set_h->br; <answer> *br 
if (RB_EMPTY_NODE(&set_h->rb_node) || <token> <answer> timer_pending(&set_h->timer)) 
goto <token> <answer> out; 
static void br_multicast_eht_set_expired(struct <token> *t) <answer> timer_list 
struct net_bridge_group_eht_set *eht_set = from_timer(eht_set, <token> <answer> t, 
struct net_bridge *br <token> eht_set->br; <answer> = 
if (RB_EMPTY_NODE(&eht_set->rb_node) <token> timer_pending(&eht_set->timer)) <answer> || 
goto <token> <answer> out; 
static <token> net_bridge_group_eht_host * <answer> struct 
__eht_lookup_create_host(struct <token> *pg, <answer> net_bridge_port_group 
union net_bridge_eht_addr <token> <answer> *h_addr, 
unsigned char <token> <answer> filter_mode) 
struct rb_node <token> = &pg->eht_host_tree.rb_node, *parent = NULL; <answer> **link 
<token> net_bridge_group_eht_host *eht_host; <answer> struct 
while (*link) <token> <answer> { 
struct <token> *this; <answer> net_bridge_group_eht_host 
<token> result; <answer> int 
this <token> rb_entry(*link, struct net_bridge_group_eht_host, <answer> = 
result = <token> &this->h_addr, sizeof(*h_addr)); <answer> memcmp(h_addr, 
parent <token> *link; <answer> = 
if (result <token> 0) <answer> < 
link = <token> <answer> &((*link)->rb_left); 
else if <token> > 0) <answer> (result 
link = <token> <answer> &((*link)->rb_right); 
return <token> <answer> this; 
<token> (br_multicast_eht_hosts_over_limit(pg)) <answer> if 
<token> NULL; <answer> return 
eht_host = <token> GFP_ATOMIC); <answer> kzalloc(sizeof(*eht_host), 
<token> (!eht_host) <answer> if 
<token> NULL; <answer> return 
<token> h_addr, sizeof(*h_addr)); <answer> memcpy(&eht_host->h_addr, 
<token> = pg; <answer> eht_host->pg 
eht_host->filter_mode = <token> <answer> filter_mode; 
<token> parent, link); <answer> rb_link_node(&eht_host->rb_node, 
rb_insert_color(&eht_host->rb_node, <token> <answer> &pg->eht_host_tree); 
<token> eht_host; <answer> return 
static <token> net_bridge_group_eht_set_entry * <answer> struct 
<token> net_bridge *br, <answer> __eht_lookup_create_set_entry(struct 
struct <token> *eht_set, <answer> net_bridge_group_eht_set 
<token> net_bridge_group_eht_host *eht_host, <answer> struct 
<token> allow_zero_src) <answer> bool 
struct rb_node **link = &eht_set->entry_tree.rb_node, *parent <token> NULL; <answer> = 
struct net_bridge_group_eht_set_entry <token> <answer> *set_h; 
while <token> { <answer> (*link) 
struct <token> *this; <answer> net_bridge_group_eht_set_entry 
int <token> <answer> result; 
this <token> rb_entry(*link, struct net_bridge_group_eht_set_entry, <answer> = 
result = <token> &this->h_addr, <answer> memcmp(&eht_host->h_addr, 
sizeof(union <token> <answer> net_bridge_eht_addr)); 
parent = <token> <answer> *link; 
if (result <token> 0) <answer> < 
<token> = &((*link)->rb_left); <answer> link 
else <token> (result > 0) <answer> if 
link = <token> <answer> &((*link)->rb_right); 
return <token> <answer> this; 
<token> (!allow_zero_src) <answer> if 
return <token> <answer> set_h; 
static struct <token> * <answer> net_bridge_group_eht_set 
__eht_lookup_create_set(struct <token> *pg, <answer> net_bridge_port_group 
union net_bridge_eht_addr <token> <answer> *src_addr) 
struct rb_node **link = &pg->eht_set_tree.rb_node, *parent <token> NULL; <answer> = 
struct <token> *eht_set; <answer> net_bridge_group_eht_set 
while <token> { <answer> (*link) 
struct <token> *this; <answer> net_bridge_group_eht_set 
int <token> <answer> result; 
this = <token> struct net_bridge_group_eht_set, <answer> rb_entry(*link, 
result = memcmp(src_addr, &this->src_addr, <token> <answer> sizeof(*src_addr)); 
parent = <token> <answer> *link; 
if (result <token> 0) <answer> < 
link <token> &((*link)->rb_left); <answer> = 
<token> if (result > 0) <answer> else 
<token> = &((*link)->rb_right); <answer> link 
return <token> <answer> this; 
eht_set <token> kzalloc(sizeof(*eht_set), GFP_ATOMIC); <answer> = 
if <token> <answer> (!eht_set) 
<token> NULL; <answer> return 
<token> src_addr, sizeof(*src_addr)); <answer> memcpy(&eht_set->src_addr, 
<token> = br_multicast_destroy_eht_set; <answer> eht_set->mcast_gc.destroy 
eht_set->pg = <token> <answer> pg; 
<token> = pg->key.port->br; <answer> eht_set->br 
<token> = RB_ROOT; <answer> eht_set->entry_tree 
<token> br_multicast_eht_set_expired, 0); <answer> timer_setup(&eht_set->timer, 
rb_link_node(&eht_set->rb_node, parent, <token> <answer> link); 
rb_insert_color(&eht_set->rb_node, <token> <answer> &pg->eht_set_tree); 
<token> eht_set; <answer> return 
static <token> br_multicast_ip_src_to_eht_addr(const struct br_ip *src, <answer> void 
union <token> *dest) <answer> net_bridge_eht_addr 
<token> (src->proto) { <answer> switch 
<token> htons(ETH_P_IP): <answer> case 
dest->ip4 = <token> <answer> src->src.ip4; 
#if <token> <answer> IS_ENABLED(CONFIG_IPV6) 
case <token> <answer> htons(ETH_P_IPV6): 
memcpy(&dest->ip6, &src->src.ip6, sizeof(struct <token> <answer> in6_addr)); 
static <token> br_eht_convert_host_filter_mode(const struct net_bridge_mcast *brmctx, <answer> void 
struct <token> *pg, <answer> net_bridge_port_group 
union net_bridge_eht_addr <token> <answer> *h_addr, 
<token> filter_mode) <answer> int 
struct net_bridge_group_eht_host <token> <answer> *eht_host; 
union <token> zero_addr; <answer> net_bridge_eht_addr 
eht_host = br_multicast_eht_host_lookup(pg, <token> <answer> h_addr); 
<token> (eht_host) <answer> if 
eht_host->filter_mode <token> filter_mode; <answer> = 
memset(&zero_addr, 0, <token> <answer> sizeof(zero_addr)); 
switch (filter_mode) <token> <answer> { 
<token> MCAST_INCLUDE: <answer> case 
<token> &zero_addr, h_addr); <answer> br_multicast_del_eht_set_entry(pg, 
case <token> <answer> MCAST_EXCLUDE: 
br_multicast_create_eht_set_entry(brmctx, <token> &zero_addr, <answer> pg, 
<token> MCAST_EXCLUDE, <answer> h_addr, 
<token> void br_multicast_create_eht_set_entry(const struct net_bridge_mcast *brmctx, <answer> static 
struct net_bridge_port_group <token> <answer> *pg, 
<token> net_bridge_eht_addr *src_addr, <answer> union 
union net_bridge_eht_addr <token> <answer> *h_addr, 
int <token> <answer> filter_mode, 
bool <token> <answer> allow_zero_src) 
struct net_bridge_group_eht_set_entry <token> <answer> *set_h; 
struct <token> *eht_host; <answer> net_bridge_group_eht_host 
struct net_bridge <token> = pg->key.port->br; <answer> *br 
<token> net_bridge_group_eht_set *eht_set; <answer> struct 
union net_bridge_eht_addr <token> <answer> zero_addr; 
memset(&zero_addr, 0, <token> <answer> sizeof(zero_addr)); 
if (!allow_zero_src && !memcmp(src_addr, &zero_addr, <token> <answer> sizeof(zero_addr))) 
<token> = __eht_lookup_create_set(pg, src_addr); <answer> eht_set 
if <token> <answer> (!eht_set) 
eht_host = __eht_lookup_create_host(pg, h_addr, <token> <answer> filter_mode); 
<token> (!eht_host) <answer> if 
<token> fail_host; <answer> goto 
set_h = __eht_lookup_create_set_entry(br, eht_set, <token> <answer> eht_host, 
if <token> <answer> (!set_h) 
<token> fail_set_entry; <answer> goto 
<token> jiffies + br_multicast_gmi(brmctx)); <answer> mod_timer(&set_h->timer, 
mod_timer(&eht_set->timer, jiffies + <token> <answer> br_multicast_gmi(brmctx)); 
if <token> <answer> (hlist_empty(&eht_host->set_entries)) 
if <token> <answer> (RB_EMPTY_ROOT(&eht_set->entry_tree)) 
static bool br_multicast_del_eht_set_entry(struct <token> *pg, <answer> net_bridge_port_group 
union <token> *src_addr, <answer> net_bridge_eht_addr 
union <token> *h_addr) <answer> net_bridge_eht_addr 
struct <token> *set_h; <answer> net_bridge_group_eht_set_entry 
<token> net_bridge_group_eht_set *eht_set; <answer> struct 
<token> set_deleted = false; <answer> bool 
eht_set <token> br_multicast_eht_set_lookup(pg, src_addr); <answer> = 
if <token> <answer> (!eht_set) 
goto <token> <answer> out; 
set_h <token> br_multicast_eht_set_entry_lookup(eht_set, h_addr); <answer> = 
if <token> <answer> (!set_h) 
goto <token> <answer> out; 
if (RB_EMPTY_ROOT(&eht_set->entry_tree)) <token> <answer> { 
<token> = true; <answer> set_deleted 
return <token> <answer> set_deleted; 
static <token> br_multicast_del_eht_host(struct net_bridge_port_group *pg, <answer> void 
union <token> *h_addr) <answer> net_bridge_eht_addr 
struct net_bridge_group_eht_set_entry <token> <answer> *set_h; 
struct net_bridge_group_eht_host <token> <answer> *eht_host; 
struct <token> *tmp; <answer> hlist_node 
eht_host <token> br_multicast_eht_host_lookup(pg, h_addr); <answer> = 
<token> (!eht_host) <answer> if 
hlist_for_each_entry_safe(set_h, <token> &eht_host->set_entries, host_list) <answer> tmp, 
if <token> & BR_SGRP_F_SEND) || <answer> (!(src_ent->flags 
filter_mode != MCAST_INCLUDE <token> <answer> || 
eht_set = <token> <answer> br_multicast_eht_set_lookup(pg, 
if <token> <answer> (!eht_set) 
mod_timer(&eht_set->timer, jiffies <token> br_multicast_lmqt(brmctx)); <answer> + 
<token> changed; <answer> return 
<token> bool br_multicast_eht_inc(const struct net_bridge_mcast *brmctx, <answer> static 
struct <token> *pg, <answer> net_bridge_port_group 
union net_bridge_eht_addr <token> <answer> *h_addr, 
<token> *srcs, <answer> void 
<token> nsrcs, <answer> u32 
size_t <token> <answer> addr_size, 
bool <token> <answer> to_report) 
<token> changed; <answer> bool 
<token> = __eht_inc_exc(brmctx, pg, h_addr, srcs, nsrcs, addr_size, <answer> changed 
<token> to_report); <answer> MCAST_INCLUDE, 
br_eht_convert_host_filter_mode(brmctx, pg, <token> MCAST_INCLUDE); <answer> h_addr, 
return <token> <answer> changed; 
<token> bool br_multicast_eht_exc(const struct net_bridge_mcast *brmctx, <answer> static 
<token> net_bridge_port_group *pg, <answer> struct 
union net_bridge_eht_addr <token> <answer> *h_addr, 
<token> *srcs, <answer> void 
<token> nsrcs, <answer> u32 
size_t <token> <answer> addr_size, 
bool <token> <answer> to_report) 
bool <token> <answer> changed; 
changed = __eht_inc_exc(brmctx, pg, h_addr, srcs, <token> addr_size, <answer> nsrcs, 
MCAST_EXCLUDE, <token> <answer> to_report); 
br_eht_convert_host_filter_mode(brmctx, pg, <token> MCAST_EXCLUDE); <answer> h_addr, 
<token> changed; <answer> return 
static <token> __eht_ip4_handle(const struct net_bridge_mcast *brmctx, <answer> bool 
struct <token> *pg, <answer> net_bridge_port_group 
union net_bridge_eht_addr <token> <answer> *h_addr, 
void <token> <answer> *srcs, 
u32 <token> <answer> nsrcs, 
int <token> <answer> grec_type) 
bool <token> = false, to_report = false; <answer> changed 
switch <token> { <answer> (grec_type) 
<token> IGMPV3_ALLOW_NEW_SOURCES: <answer> case 
br_multicast_eht_allow(brmctx, pg, <token> srcs, nsrcs, <answer> h_addr, 
<token> IGMPV3_BLOCK_OLD_SOURCES: <answer> case 
changed = <token> pg, h_addr, srcs, nsrcs, <answer> br_multicast_eht_block(brmctx, 
<token> IGMPV3_CHANGE_TO_INCLUDE: <answer> case 
<token> = true; <answer> to_report 
case <token> <answer> IGMPV3_MODE_IS_INCLUDE: 
<token> = br_multicast_eht_inc(brmctx, pg, h_addr, srcs, nsrcs, <answer> changed 
<token> to_report); <answer> sizeof(__be32), 
<token> IGMPV3_CHANGE_TO_EXCLUDE: <answer> case 
to_report = <token> <answer> true; 
<token> IGMPV3_MODE_IS_EXCLUDE: <answer> case 
changed = br_multicast_eht_exc(brmctx, <token> h_addr, srcs, nsrcs, <answer> pg, 
sizeof(__be32), <token> <answer> to_report); 
return <token> <answer> changed; 
<token> IS_ENABLED(CONFIG_IPV6) <answer> #if 
static bool __eht_ip6_handle(const struct net_bridge_mcast <token> <answer> *brmctx, 
<token> net_bridge_port_group *pg, <answer> struct 
union net_bridge_eht_addr <token> <answer> *h_addr, 
void <token> <answer> *srcs, 
<token> nsrcs, <answer> u32 
<token> grec_type) <answer> int 
bool changed = false, to_report = <token> <answer> false; 
<token> (grec_type) { <answer> switch 
<token> MLD2_ALLOW_NEW_SOURCES: <answer> case 
br_multicast_eht_allow(brmctx, pg, h_addr, <token> nsrcs, <answer> srcs, 
<token> in6_addr)); <answer> sizeof(struct 
<token> MLD2_BLOCK_OLD_SOURCES: <answer> case 
changed = br_multicast_eht_block(brmctx, pg, h_addr, srcs, <token> <answer> nsrcs, 
<token> in6_addr)); <answer> sizeof(struct 
case <token> <answer> MLD2_CHANGE_TO_INCLUDE: 
to_report <token> true; <answer> = 
<token> MLD2_MODE_IS_INCLUDE: <answer> case 
changed <token> br_multicast_eht_inc(brmctx, pg, h_addr, srcs, nsrcs, <answer> = 
<token> in6_addr), <answer> sizeof(struct 
<token> MLD2_CHANGE_TO_EXCLUDE: <answer> case 
to_report = <token> <answer> true; 
<token> MLD2_MODE_IS_EXCLUDE: <answer> case 
<token> = br_multicast_eht_exc(brmctx, pg, h_addr, srcs, nsrcs, <answer> changed 
sizeof(struct <token> <answer> in6_addr), 
<token> changed; <answer> return 
#include <token> <answer> <linux/i2c.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/types.h> <answer> #include 
<token> "cs42l42.h" <answer> #include 
static const struct <token> cs42l83_reg_defaults[] = { <answer> reg_default 
{ CS42L42_FRZ_CTL, 0x00 <token> <answer> }, 
{ <token> 0x10 }, <answer> CS42L42_SRC_CTL, 
static const struct regmap_config cs42l83_regmap <token> { <answer> = 
.reg_bits = <token> <answer> 8, 
.val_bits = <token> <answer> 8, 
.readable_reg <token> cs42l42_readable_register, <answer> = 
.volatile_reg <token> cs42l42_volatile_register, <answer> = 
<token> = &cs42l42_page_range, <answer> .ranges 
.num_ranges <token> 1, <answer> = 
<token> = CS42L42_MAX_REGISTER, <answer> .max_register 
.reg_defaults = <token> <answer> cs42l83_reg_defaults, 
.num_reg_defaults = <token> <answer> ARRAY_SIZE(cs42l83_reg_defaults), 
<token> = REGCACHE_MAPLE, <answer> .cache_type 
.use_single_read <token> true, <answer> = 
<token> = true, <answer> .use_single_write 
static int <token> i2c_client *i2c_client) <answer> cs42l83_i2c_probe(struct 
<token> device *dev = &i2c_client->dev; <answer> struct 
struct cs42l42_private <token> <answer> *cs42l83; 
<token> regmap *regmap; <answer> struct 
int <token> <answer> ret; 
cs42l83 = devm_kzalloc(dev, sizeof(*cs42l83), <token> <answer> GFP_KERNEL); 
<token> (!cs42l83) <answer> if 
<token> -ENOMEM; <answer> return 
regmap = <token> &cs42l83_regmap); <answer> devm_regmap_init_i2c(i2c_client, 
<token> (IS_ERR(regmap)) <answer> if 
return <token> PTR_ERR(regmap), <answer> dev_err_probe(&i2c_client->dev, 
"regmap_init() <token> <answer> failed\n"); 
cs42l83->devid <token> CS42L83_CHIP_ID; <answer> = 
cs42l83->dev <token> dev; <answer> = 
<token> = regmap; <answer> cs42l83->regmap 
<token> = i2c_client->irq; <answer> cs42l83->irq 
<token> = cs42l42_common_probe(cs42l83, &cs42l42_soc_component, &cs42l42_dai); <answer> ret 
if <token> <answer> (ret) 
<token> ret; <answer> return 
return <token> <answer> cs42l42_init(cs42l83); 
static void <token> i2c_client *i2c_client) <answer> cs42l83_i2c_remove(struct 
struct cs42l42_private *cs42l83 <token> dev_get_drvdata(&i2c_client->dev); <answer> = 
static int __maybe_unused <token> device *dev) <answer> cs42l83_i2c_resume(struct 
<token> ret; <answer> int 
ret <token> cs42l42_resume(dev); <answer> = 
if <token> <answer> (ret) 
return <token> <answer> ret; 
return <token> <answer> 0; 
static <token> struct dev_pm_ops cs42l83_i2c_pm_ops = { <answer> const 
SET_SYSTEM_SLEEP_PM_OPS(cs42l42_suspend, <token> <answer> cs42l83_i2c_resume) 
static const struct <token> __maybe_unused cs42l83_of_match[] = { <answer> of_device_id 
{ .compatible = "cirrus,cs42l83", <token> <answer> }, 
<token> cs42l83_of_match); <answer> MODULE_DEVICE_TABLE(of, 
<token> struct i2c_driver cs42l83_i2c_driver = { <answer> static 
.driver <token> { <answer> = 
.name <token> "cs42l83", <answer> = 
<token> = &cs42l83_i2c_pm_ops, <answer> .pm 
.of_match_table = <token> <answer> of_match_ptr(cs42l83_of_match), 
.probe <token> cs42l83_i2c_probe, <answer> = 
<token> = cs42l83_i2c_remove, <answer> .remove 
<token> CS42L83 I2C driver"); <answer> MODULE_DESCRIPTION("ASoC 
MODULE_AUTHOR("Martin Povišer <token> <answer> <povik+lin@cutebit.org>"); 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/gpio.h> 
#include <token> <answer> <linux/i2c.h> 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/mfd/core.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/irqdomain.h> 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/mfd/wm8994/core.h> 
#include <token> <answer> <linux/mfd/wm8994/pdata.h> 
#include <token> <answer> <linux/mfd/wm8994/registers.h> 
#include <token> <answer> <linux/delay.h> 
static <token> struct regmap_irq wm8994_irqs[] = { <answer> const 
[WM8994_IRQ_TEMP_SHUT] = <token> <answer> { 
<token> = 1, <answer> .reg_offset 
<token> = WM8994_TEMP_SHUT_EINT, <answer> .mask 
<token> = { <answer> [WM8994_IRQ_MIC1_DET] 
<token> = 1, <answer> .reg_offset 
.mask <token> WM8994_MIC1_DET_EINT, <answer> = 
[WM8994_IRQ_MIC1_SHRT] <token> { <answer> = 
.reg_offset <token> 1, <answer> = 
.mask <token> WM8994_MIC1_SHRT_EINT, <answer> = 
[WM8994_IRQ_MIC2_DET] = <token> <answer> { 
.reg_offset <token> 1, <answer> = 
.mask = <token> <answer> WM8994_MIC2_DET_EINT, 
[WM8994_IRQ_MIC2_SHRT] <token> { <answer> = 
.reg_offset <token> 1, <answer> = 
.mask = <token> <answer> WM8994_MIC2_SHRT_EINT, 
[WM8994_IRQ_FLL1_LOCK] = <token> <answer> { 
.reg_offset <token> 1, <answer> = 
.mask <token> WM8994_FLL1_LOCK_EINT, <answer> = 
<token> = { <answer> [WM8994_IRQ_FLL2_LOCK] 
.reg_offset <token> 1, <answer> = 
<token> = WM8994_FLL2_LOCK_EINT, <answer> .mask 
<token> = { <answer> [WM8994_IRQ_SRC1_LOCK] 
.reg_offset = <token> <answer> 1, 
.mask = <token> <answer> WM8994_SRC1_LOCK_EINT, 
[WM8994_IRQ_SRC2_LOCK] <token> { <answer> = 
.reg_offset <token> 1, <answer> = 
.mask = <token> <answer> WM8994_SRC2_LOCK_EINT, 
[WM8994_IRQ_AIF1DRC1_SIG_DET] = <token> <answer> { 
.reg_offset = <token> <answer> 1, 
<token> = WM8994_AIF1DRC1_SIG_DET, <answer> .mask 
<token> = { <answer> [WM8994_IRQ_AIF1DRC2_SIG_DET] 
.reg_offset <token> 1, <answer> = 
.mask = <token> <answer> WM8994_AIF1DRC2_SIG_DET_EINT, 
[WM8994_IRQ_AIF2DRC_SIG_DET] <token> { <answer> = 
.reg_offset <token> 1, <answer> = 
.mask <token> WM8994_AIF2DRC_SIG_DET_EINT, <answer> = 
<token> = { <answer> [WM8994_IRQ_FIFOS_ERR] 
<token> = 1, <answer> .reg_offset 
.mask <token> WM8994_FIFOS_ERR_EINT, <answer> = 
[WM8994_IRQ_WSEQ_DONE] <token> { <answer> = 
.reg_offset <token> 1, <answer> = 
<token> = WM8994_WSEQ_DONE_EINT, <answer> .mask 
[WM8994_IRQ_DCS_DONE] = <token> <answer> { 
.reg_offset = <token> <answer> 1, 
.mask <token> WM8994_DCS_DONE_EINT, <answer> = 
[WM8994_IRQ_TEMP_WARN] = <token> <answer> { 
.reg_offset = <token> <answer> 1, 
.mask = <token> <answer> WM8994_TEMP_WARN_EINT, 
[WM8994_IRQ_GPIO(1)] <token> { <answer> = 
.mask <token> WM8994_GP1_EINT, <answer> = 
[WM8994_IRQ_GPIO(2)] <token> { <answer> = 
.mask <token> WM8994_GP2_EINT, <answer> = 
<token> = { <answer> [WM8994_IRQ_GPIO(3)] 
.mask = <token> <answer> WM8994_GP3_EINT, 
[WM8994_IRQ_GPIO(4)] = <token> <answer> { 
<token> = WM8994_GP4_EINT, <answer> .mask 
<token> = { <answer> [WM8994_IRQ_GPIO(5)] 
.mask <token> WM8994_GP5_EINT, <answer> = 
<token> = { <answer> [WM8994_IRQ_GPIO(6)] 
.mask = <token> <answer> WM8994_GP6_EINT, 
<token> = { <answer> [WM8994_IRQ_GPIO(7)] 
.mask = <token> <answer> WM8994_GP7_EINT, 
[WM8994_IRQ_GPIO(8)] <token> { <answer> = 
.mask <token> WM8994_GP8_EINT, <answer> = 
<token> = { <answer> [WM8994_IRQ_GPIO(9)] 
.mask <token> WM8994_GP8_EINT, <answer> = 
<token> = { <answer> [WM8994_IRQ_GPIO(10)] 
<token> = WM8994_GP10_EINT, <answer> .mask 
[WM8994_IRQ_GPIO(11)] = <token> <answer> { 
.mask <token> WM8994_GP11_EINT, <answer> = 
<token> const struct regmap_irq_chip wm8994_irq_chip = { <answer> static 
.name = <token> <answer> "wm8994", 
<token> = wm8994_irqs, <answer> .irqs 
.num_irqs = <token> <answer> ARRAY_SIZE(wm8994_irqs), 
<token> = 2, <answer> .num_regs 
.status_base <token> WM8994_INTERRUPT_STATUS_1, <answer> = 
.mask_base <token> WM8994_INTERRUPT_STATUS_1_MASK, <answer> = 
.ack_base = <token> <answer> WM8994_INTERRUPT_STATUS_1, 
.runtime_pm = <token> <answer> true, 
static void <token> irq_data *data) <answer> wm8994_edge_irq_enable(struct 
<token> void wm8994_edge_irq_disable(struct irq_data *data) <answer> static 
static struct <token> wm8994_edge_irq_chip = { <answer> irq_chip 
.name = <token> <answer> "wm8994_edge", 
<token> = wm8994_edge_irq_disable, <answer> .irq_disable 
.irq_enable = <token> <answer> wm8994_edge_irq_enable, 
static irqreturn_t <token> irq, void *data) <answer> wm8994_edge_irq(int 
struct wm8994 *wm8994 <token> data; <answer> = 
while <token> <answer> (gpio_get_value_cansleep(wm8994->pdata.irq_gpio)) 
<token> 0)); <answer> handle_nested_irq(irq_find_mapping(wm8994->edge_irq, 
<token> IRQ_HANDLED; <answer> return 
static <token> wm8994_edge_irq_map(struct irq_domain *h, unsigned int virq, <answer> int 
irq_hw_number_t <token> <answer> hw) 
<token> wm8994 *wm8994 = h->host_data; <answer> struct 
irq_set_chip_data(virq, <token> <answer> wm8994); 
<token> &wm8994_edge_irq_chip, handle_edge_irq); <answer> irq_set_chip_and_handler(virq, 
irq_set_nested_thread(virq, <token> <answer> 1); 
return <token> <answer> 0; 
<token> const struct irq_domain_ops wm8994_edge_irq_ops = { <answer> static 
<token> = wm8994_edge_irq_map, <answer> .map 
<token> = irq_domain_xlate_twocell, <answer> .xlate 
int wm8994_irq_init(struct <token> *wm8994) <answer> wm8994 
int <token> <answer> ret; 
unsigned <token> irqflags; <answer> long 
struct wm8994_pdata <token> = &wm8994->pdata; <answer> *pdata 
<token> (!wm8994->irq) { <answer> if 
"No interrupt specified, <token> interrupts\n"); <answer> no 
<token> = 0; <answer> wm8994->irq_base 
return <token> <answer> 0; 
for (n = 0; n < <token> n++) { <answer> adapter->num_tx_queues; 
<token> = adapter->tx_ring[n]; <answer> tx_ring 
pr_info("TX QUEUE INDEX <token> %d\n", tx_ring->queue_index); <answer> = 
pr_info("T [desc] [address <token> ] [PlPOCIStDDM Ln] [bi->dma ] leng ntw timestamp bi->skb\n"); <answer> 63:0 
for (i = 0; tx_ring->desc <token> (i < tx_ring->count); i++) { <answer> && 
const char <token> <answer> *next_desc; 
struct <token> *buffer_info; <answer> igb_tx_buffer 
tx_desc = IGB_TX_DESC(tx_ring, <token> <answer> i); 
buffer_info <token> &tx_ring->tx_buffer_info[i]; <answer> = 
u0 = (struct <token> *)tx_desc; <answer> my_u0 
if (i <token> tx_ring->next_to_use && <answer> == 
i == <token> <answer> tx_ring->next_to_clean) 
next_desc <token> " NTC/U"; <answer> = 
else if (i == <token> <answer> tx_ring->next_to_use) 
next_desc = <token> NTU"; <answer> " 
<token> if (i == tx_ring->next_to_clean) <answer> else 
next_desc = <token> NTC"; <answer> " 
next_desc <token> ""; <answer> = 
pr_info("T [0x%03X] %016llX %016llX <token> %04X %p %016llX %p%s\n", <answer> %016llX 
i, <token> <answer> le64_to_cpu(u0->a), 
<token> dma), <answer> (u64)dma_unmap_addr(buffer_info, 
<token> len), <answer> dma_unmap_len(buffer_info, 
<token> next_desc); <answer> buffer_info->skb, 
if <token> && buffer_info->skb) <answer> (netif_msg_pktdata(adapter) 
<token> "", <answer> print_hex_dump(KERN_INFO, 
16, 1, <token> <answer> buffer_info->skb->data, 
<token> len), <answer> dma_unmap_len(buffer_info, 
for <token> = 0; n < adapter->num_rx_queues; n++) { <answer> (n 
rx_ring <token> adapter->rx_ring[n]; <answer> = 
pr_info("RX <token> INDEX = %d\n", rx_ring->queue_index); <answer> QUEUE 
pr_info("R [desc] [ PktBuf <token> [ HeadBuf DD] [bi->dma ] [bi->skb] <-- Adv Rx Read format\n"); <answer> A0] 
pr_info("RWB[desc] [PcsmIpSHl PtRs] [vl er S cks ln] ---------------- [bi->skb] <-- Adv <token> Write-Back format\n"); <answer> Rx 
for <token> = 0; i < rx_ring->count; i++) { <answer> (i 
const char <token> <answer> *next_desc; 
<token> igb_rx_buffer *buffer_info; <answer> struct 
<token> = &rx_ring->rx_buffer_info[i]; <answer> buffer_info 
rx_desc = IGB_RX_DESC(rx_ring, <token> <answer> i); 
u0 <token> (struct my_u0 *)rx_desc; <answer> = 
staterr = <token> <answer> le32_to_cpu(rx_desc->wb.upper.status_error); 
if (i <token> rx_ring->next_to_use) <answer> == 
next_desc = <token> NTU"; <answer> " 
else if (i == <token> <answer> rx_ring->next_to_clean) 
next_desc = <token> NTC"; <answer> " 
next_desc <token> ""; <answer> = 
if (staterr & E1000_RXD_STAT_DD) <token> <answer> { 
static <token> igb_get_i2c_data(void *data) <answer> int 
<token> igb_adapter *adapter = (struct igb_adapter *)data; <answer> struct 
struct <token> *hw = &adapter->hw; <answer> e1000_hw 
s32 i2cctl = <token> <answer> rd32(E1000_I2CPARAMS); 
return !!(i2cctl <token> E1000_I2C_DATA_IN); <answer> & 
static void igb_set_i2c_data(void *data, int <token> <answer> state) 
struct igb_adapter *adapter = (struct igb_adapter <token> <answer> *)data; 
struct e1000_hw *hw = <token> <answer> &adapter->hw; 
<token> i2cctl = rd32(E1000_I2CPARAMS); <answer> s32 
if (state) <token> <answer> { 
i2cctl |= <token> | E1000_I2C_DATA_OE_N; <answer> E1000_I2C_DATA_OUT 
<token> else { <answer> } 
i2cctl &= <token> <answer> ~E1000_I2C_DATA_OE_N; 
i2cctl <token> ~E1000_I2C_DATA_OUT; <answer> &= 
wr32(E1000_I2CPARAMS, <token> <answer> i2cctl); 
static void igb_set_i2c_clk(void <token> int state) <answer> *data, 
struct igb_adapter <token> = (struct igb_adapter *)data; <answer> *adapter 
<token> e1000_hw *hw = &adapter->hw; <answer> struct 
s32 <token> = rd32(E1000_I2CPARAMS); <answer> i2cctl 
if (state) <token> <answer> { 
<token> |= E1000_I2C_CLK_OUT | E1000_I2C_CLK_OE_N; <answer> i2cctl 
<token> else { <answer> } 
i2cctl <token> ~E1000_I2C_CLK_OUT; <answer> &= 
<token> &= ~E1000_I2C_CLK_OE_N; <answer> i2cctl 
<token> i2cctl); <answer> wr32(E1000_I2CPARAMS, 
static <token> igb_get_i2c_clk(void *data) <answer> int 
struct igb_adapter *adapter = <token> igb_adapter *)data; <answer> (struct 
struct <token> *hw = &adapter->hw; <answer> e1000_hw 
s32 i2cctl <token> rd32(E1000_I2CPARAMS); <answer> = 
return <token> & E1000_I2C_CLK_IN); <answer> !!(i2cctl 
static const struct i2c_algo_bit_data igb_i2c_algo <token> { <answer> = 
<token> = igb_set_i2c_data, <answer> .setsda 
<token> = igb_set_i2c_clk, <answer> .setscl 
.getsda <token> igb_get_i2c_data, <answer> = 
.getscl = <token> <answer> igb_get_i2c_clk, 
<token> = 5, <answer> .udelay 
.timeout = <token> <answer> 20, 
struct <token> *igb_get_hw_dev(struct e1000_hw *hw) <answer> net_device 
struct <token> *adapter = hw->back; <answer> igb_adapter 
return <token> <answer> adapter->netdev; 
<token> int __init igb_init_module(void) <answer> static 
int <token> <answer> ret; 
<token> igb_driver_string); <answer> pr_info("%s\n", 
pr_info("%s\n", <token> <answer> igb_copyright); 
#ifdef <token> <answer> CONFIG_IGB_DCA 
<token> = pci_register_driver(&igb_driver); <answer> ret 
<token> ret; <answer> return 
static <token> __exit igb_exit_module(void) <answer> void 
#ifdef <token> <answer> CONFIG_IGB_DCA 
<token> Q_IDX_82576(i) (((i & 0x1) << 3) + (i >> 1)) <answer> #define 
static <token> igb_cache_ring_register(struct igb_adapter *adapter) <answer> void 
<token> i = 0, j = 0; <answer> int 
u32 rbase_offset <token> adapter->vfs_allocated_count; <answer> = 
switch (adapter->hw.mac.type) <token> <answer> { 
<token> e1000_82576: <answer> case 
if <token> { <answer> (adapter->vfs_allocated_count) 
for (; <token> < adapter->rss_queues; i++) <answer> i 
adapter->rx_ring[i]->reg_idx <token> rbase_offset + <answer> = 
<token> e1000_82575: <answer> case 
case <token> <answer> e1000_82580: 
case <token> <answer> e1000_i350: 
<token> e1000_i354: <answer> case 
case <token> <answer> e1000_i210: 
<token> e1000_i211: <answer> case 
for (; i < <token> i++) <answer> adapter->num_rx_queues; 
adapter->rx_ring[i]->reg_idx <token> rbase_offset + i; <answer> = 
for <token> j < adapter->num_tx_queues; j++) <answer> (; 
<token> = rbase_offset + j; <answer> adapter->tx_ring[j]->reg_idx 
u32 igb_rd32(struct e1000_hw *hw, u32 <token> <answer> reg) 
struct <token> *igb = container_of(hw, struct igb_adapter, hw); <answer> igb_adapter 
<token> __iomem *hw_addr = READ_ONCE(hw->hw_addr); <answer> u8 
u32 value <token> 0; <answer> = 
if <token> <answer> (E1000_REMOVED(hw_addr)) 
return <token> <answer> ~value; 
<token> = readl(&hw_addr[reg]); <answer> value 
static void igb_write_ivar(struct <token> *hw, int msix_vector, <answer> e1000_hw 
int <token> int offset) <answer> index, 
u32 <token> = array_rd32(E1000_IVAR0, index); <answer> ivar 
if (rx_queue > <token> <answer> IGB_N0_QUEUE) 
msixbm = <token> << rx_queue; <answer> E1000_EICR_RX_QUEUE0 
if (tx_queue > <token> <answer> IGB_N0_QUEUE) 
<token> |= E1000_EICR_TX_QUEUE0 << tx_queue; <answer> msixbm 
<token> (!(adapter->flags & IGB_FLAG_HAS_MSIX) && msix_vector == 0) <answer> if 
msixbm <token> E1000_EIMS_OTHER; <answer> |= 
array_wr32(E1000_MSIXBM(0), msix_vector, <token> <answer> msixbm); 
q_vector->eims_value = <token> <answer> msixbm; 
case <token> <answer> e1000_82576: 
if <token> > IGB_N0_QUEUE) <answer> (rx_queue 
<token> msix_vector, <answer> igb_write_ivar(hw, 
rx_queue <token> 0x7, <answer> & 
(rx_queue & 0x8) <token> 1); <answer> << 
<token> (tx_queue > IGB_N0_QUEUE) <answer> if 
igb_write_ivar(hw, <token> <answer> msix_vector, 
<token> & 0x7, <answer> tx_queue 
((tx_queue & <token> << 1) + 8); <answer> 0x8) 
q_vector->eims_value <token> BIT(msix_vector); <answer> = 
case <token> <answer> e1000_82580: 
case <token> <answer> e1000_i350: 
<token> e1000_i354: <answer> case 
case <token> <answer> e1000_i210: 
<token> e1000_i211: <answer> case 
<token> (rx_queue > IGB_N0_QUEUE) <answer> if 
<token> msix_vector, <answer> igb_write_ivar(hw, 
<token> >> 1, <answer> rx_queue 
(rx_queue & 0x1) << <token> <answer> 4); 
if <token> > IGB_N0_QUEUE) <answer> (tx_queue 
igb_write_ivar(hw, <token> <answer> msix_vector, 
tx_queue >> <token> <answer> 1, 
((tx_queue <token> 0x1) << 4) + 8); <answer> & 
<token> = BIT(msix_vector); <answer> q_vector->eims_value 
static void <token> igb_adapter *adapter) <answer> igb_configure_msix(struct 
u32 <token> <answer> tmp; 
int <token> vector = 0; <answer> i, 
struct e1000_hw <token> = &adapter->hw; <answer> *hw 
adapter->eims_enable_mask = <token> <answer> 0; 
wr32(E1000_GPIE, E1000_GPIE_MSIX_MODE <token> <answer> | 
E1000_GPIE_PBA <token> E1000_GPIE_EIAME | <answer> | 
static int <token> igb_adapter *adapter) <answer> igb_request_msix(struct 
unsigned int <token> = adapter->num_q_vectors; <answer> num_q_vectors 
struct net_device *netdev <token> adapter->netdev; <answer> = 
int i, err = 0, vector = 0, <token> = 0; <answer> free_vector 
err = <token> <answer> request_irq(adapter->msix_entries[vector].vector, 
<token> 0, netdev->name, adapter); <answer> igb_msix_other, 
<token> (err) <answer> if 
<token> err_out; <answer> goto 
if (num_q_vectors > MAX_Q_VECTORS) <token> <answer> { 
num_q_vectors <token> MAX_Q_VECTORS; <answer> = 
"The number of queue <token> (%d) is higher than max allowed (%d)\n", <answer> vectors 
<token> MAX_Q_VECTORS); <answer> adapter->num_q_vectors, 
for <token> = 0; i < num_q_vectors; i++) { <answer> (i 
struct igb_q_vector *q_vector <token> adapter->q_vector[i]; <answer> = 
q_vector->itr_register = <token> + E1000_EITR(vector); <answer> adapter->io_addr 
<token> (q_vector->rx.ring && q_vector->tx.ring) <answer> if 
<token> "%s-TxRx-%u", netdev->name, <answer> sprintf(q_vector->name, 
else if <token> <answer> (q_vector->tx.ring) 
<token> "%s-tx-%u", netdev->name, <answer> sprintf(q_vector->name, 
else if <token> <answer> (q_vector->rx.ring) 
sprintf(q_vector->name, "%s-rx-%u", <token> <answer> netdev->name, 
sprintf(q_vector->name, <token> netdev->name); <answer> "%s-unused", 
err <token> request_irq(adapter->msix_entries[vector].vector, <answer> = 
<token> 0, q_vector->name, <answer> igb_msix_ring, 
<token> (err) <answer> if 
<token> err_free; <answer> goto 
<token> 0; <answer> return 
static <token> igb_free_q_vector(struct igb_adapter *adapter, int v_idx) <answer> void 
<token> igb_q_vector *q_vector = adapter->q_vector[v_idx]; <answer> struct 
<token> = NULL; <answer> adapter->q_vector[v_idx] 
<token> (q_vector) <answer> if 
kfree_rcu(q_vector, <token> <answer> rcu); 
static void igb_reset_q_vector(struct igb_adapter *adapter, <token> v_idx) <answer> int 
<token> igb_q_vector *q_vector = adapter->q_vector[v_idx]; <answer> struct 
<token> (!q_vector) <answer> if 
<token> (q_vector->tx.ring) <answer> if 
<token> = NULL; <answer> adapter->tx_ring[q_vector->tx.ring->queue_index] 
if <token> <answer> (q_vector->rx.ring) 
<token> = NULL; <answer> adapter->rx_ring[q_vector->rx.ring->queue_index] 
static void igb_reset_interrupt_capability(struct igb_adapter <token> <answer> *adapter) 
<token> v_idx = adapter->num_q_vectors; <answer> int 
if (adapter->flags & <token> <answer> IGB_FLAG_HAS_MSIX) 
else <token> (adapter->flags & IGB_FLAG_HAS_MSI) <answer> if 
while <token> <answer> (v_idx--) 
igb_reset_q_vector(adapter, <token> <answer> v_idx); 
<token> void igb_free_q_vectors(struct igb_adapter *adapter) <answer> static 
<token> v_idx = adapter->num_q_vectors; <answer> int 
adapter->num_tx_queues = <token> <answer> 0; 
adapter->num_rx_queues = <token> <answer> 0; 
<token> = 0; <answer> adapter->num_q_vectors 
while (v_idx--) <token> <answer> { 
igb_reset_q_vector(adapter, <token> <answer> v_idx); 
<token> v_idx); <answer> igb_free_q_vector(adapter, 
<token> void igb_clear_interrupt_scheme(struct igb_adapter *adapter) <answer> static 
static <token> igb_set_interrupt_capability(struct igb_adapter *adapter, bool msix) <answer> void 
int <token> <answer> err; 
int numvecs, <token> <answer> i; 
if <token> <answer> (!msix) 
goto <token> <answer> msi_only; 
adapter->flags |= <token> <answer> IGB_FLAG_HAS_MSIX; 
<token> int igb_alloc_q_vector(struct igb_adapter *adapter, <answer> static 
int <token> int v_idx, <answer> v_count, 
<token> txr_count, int txr_idx, <answer> int 
int <token> int rxr_idx) <answer> rxr_count, 
struct igb_q_vector <token> <answer> *q_vector; 
struct <token> *ring; <answer> igb_ring 
<token> ring_count; <answer> int 
size_t <token> <answer> size; 
if (adapter->hw.mac.type <token> e1000_i350) <answer> >= 
set_bit(IGB_RING_FLAG_RX_LB_VLAN_BSWAP, <token> <answer> &ring->flags); 
<token> int igb_alloc_q_vectors(struct igb_adapter *adapter) <answer> static 
int q_vectors = <token> <answer> adapter->num_q_vectors; 
int rxr_remaining = <token> <answer> adapter->num_rx_queues; 
int <token> = adapter->num_tx_queues; <answer> txr_remaining 
int rxr_idx = 0, txr_idx = 0, <token> = 0; <answer> v_idx 
<token> err; <answer> int 
if <token> >= (rxr_remaining + txr_remaining)) { <answer> (q_vectors 
<token> (; rxr_remaining; v_idx++) { <answer> for 
err = igb_alloc_q_vector(adapter, <token> v_idx, <answer> q_vectors, 
0, 0, <token> rxr_idx); <answer> 1, 
if <token> <answer> (err) 
goto <token> <answer> err_out; 
static int igb_init_interrupt_scheme(struct <token> *adapter, bool msix) <answer> igb_adapter 
struct pci_dev <token> = adapter->pdev; <answer> *pdev 
int <token> <answer> err; 
<token> msix); <answer> igb_set_interrupt_capability(adapter, 
<token> = igb_alloc_q_vectors(adapter); <answer> err 
if <token> { <answer> (err) 
<token> "Unable to allocate memory for vectors\n"); <answer> dev_err(&pdev->dev, 
<token> err_alloc_q_vectors; <answer> goto 
return <token> <answer> 0; 
<token> err; <answer> return 
static <token> igb_request_irq(struct igb_adapter *adapter) <answer> int 
struct <token> *netdev = adapter->netdev; <answer> net_device 
struct pci_dev <token> = adapter->pdev; <answer> *pdev 
int err = <token> <answer> 0; 
if (adapter->flags & IGB_FLAG_HAS_MSIX) <token> <answer> { 
err = <token> <answer> igb_request_msix(adapter); 
if <token> <answer> (!err) 
<token> request_done; <answer> goto 
static void <token> igb_adapter *adapter) <answer> igb_irq_disable(struct 
struct e1000_hw *hw = <token> <answer> &adapter->hw; 
if (adapter->flags & <token> { <answer> IGB_FLAG_HAS_MSIX) 
u32 <token> = rd32(E1000_EIAM); <answer> regval 
wr32(E1000_EIAM, regval <token> ~adapter->eims_enable_mask); <answer> & 
wr32(E1000_EIMC, <token> <answer> adapter->eims_enable_mask); 
regval <token> rd32(E1000_EIAC); <answer> = 
wr32(E1000_EIAC, <token> & ~adapter->eims_enable_mask); <answer> regval 
<token> 0); <answer> wr32(E1000_IAM, 
<token> ~0); <answer> wr32(E1000_IMC, 
<token> (adapter->flags & IGB_FLAG_HAS_MSIX) { <answer> if 
<token> i; <answer> int 
for (i = 0; i < <token> i++) <answer> adapter->num_q_vectors; 
} else <token> <answer> { 
<token> void igb_irq_enable(struct igb_adapter *adapter) <answer> static 
struct e1000_hw *hw = <token> <answer> &adapter->hw; 
if (adapter->flags & <token> { <answer> IGB_FLAG_HAS_MSIX) 
u32 ims = E1000_IMS_LSC | <token> | E1000_IMS_DRSTA; <answer> E1000_IMS_DOUTSYNC 
u32 regval <token> rd32(E1000_EIAC); <answer> = 
wr32(E1000_EIAC, regval <token> adapter->eims_enable_mask); <answer> | 
<token> = rd32(E1000_EIAM); <answer> regval 
wr32(E1000_EIAM, <token> | adapter->eims_enable_mask); <answer> regval 
<token> adapter->eims_enable_mask); <answer> wr32(E1000_EIMS, 
if <token> { <answer> (adapter->vfs_allocated_count) 
<token> 0xFF); <answer> wr32(E1000_MBVFIMR, 
ims <token> E1000_IMS_VMMB; <answer> |= 
wr32(E1000_IMS, <token> <answer> ims); 
} else <token> <answer> { 
wr32(E1000_IMS, <token> | <answer> IMS_ENABLE_MASK 
wr32(E1000_IAM, IMS_ENABLE_MASK <token> <answer> | 
<token> void igb_update_mng_vlan(struct igb_adapter *adapter) <answer> static 
struct e1000_hw *hw = <token> <answer> &adapter->hw; 
u16 pf_id <token> adapter->vfs_allocated_count; <answer> = 
u16 <token> = adapter->hw.mng_cookie.vlan_id; <answer> vid 
<token> old_vid = adapter->mng_vlan_id; <answer> u16 
if (hw->mng_cookie.status & E1000_MNG_DHCP_COOKIE_STATUS_VLAN) <token> <answer> { 
static void <token> igb_adapter *adapter) <answer> igb_release_hw_control(struct 
struct e1000_hw *hw <token> &adapter->hw; <answer> = 
<token> ctrl_ext; <answer> u32 
static void igb_get_hw_control(struct igb_adapter <token> <answer> *adapter) 
struct <token> *hw = &adapter->hw; <answer> e1000_hw 
u32 <token> <answer> ctrl_ext; 
static void <token> igb_adapter *adapter, int queue) <answer> igb_config_tx_modes(struct 
struct net_device <token> = adapter->netdev; <answer> *netdev 
struct e1000_hw *hw = <token> <answer> &adapter->hw; 
struct <token> *ring; <answer> igb_ring 
u32 <token> tqavctrl; <answer> tqavcc, 
u16 <token> <answer> value; 
WARN_ON(hw->mac.type != <token> <answer> e1000_i210); 
WARN_ON(queue < 0 || queue > <token> <answer> 1); 
ring <token> adapter->tx_ring[queue]; <answer> = 
if (ring->cbs_enable || <token> { <answer> ring->launchtime_enable) 
set_tx_desc_fetch_prio(hw, <token> TX_QUEUE_PRIO_HIGH); <answer> queue, 
set_queue_mode(hw, queue, <token> <answer> QUEUE_MODE_STREAM_RESERVATION); 
} else <token> <answer> { 
set_tx_desc_fetch_prio(hw, <token> TX_QUEUE_PRIO_LOW); <answer> queue, 
<token> queue, QUEUE_MODE_STRICT_PRIORITY); <answer> set_queue_mode(hw, 
<token> (queue == 0 && !ring->cbs_enable) { <answer> if 
tqavctrl = <token> <answer> rd32(E1000_I210_TQAVCTRL); 
<token> |= E1000_TQAVCTRL_DATATRANARB; <answer> tqavctrl 
<token> tqavctrl); <answer> wr32(E1000_I210_TQAVCTRL, 
value = DIV_ROUND_UP_ULL(ring->idleslope * 61034ULL, <token> <answer> 1000000); 
tqavcc <token> rd32(E1000_I210_TQAVCC(queue)); <answer> = 
tqavcc <token> ~E1000_TQAVCC_IDLESLOPE_MASK; <answer> &= 
tqavcc |= <token> <answer> value; 
wr32(E1000_I210_TQAVCC(queue), <token> <answer> tqavcc); 
0x80000000 + <token> * 0x7735); <answer> ring->hicredit 
<token> else { <answer> } 
if (!is_any_cbs_enabled(adapter)) <token> <answer> { 
tqavctrl = <token> <answer> rd32(E1000_I210_TQAVCTRL); 
tqavctrl &= <token> <answer> ~E1000_TQAVCTRL_DATATRANARB; 
<token> tqavctrl); <answer> wr32(E1000_I210_TQAVCTRL, 
tqavctrl <token> rd32(E1000_I210_TQAVCTRL); <answer> = 
<token> |= E1000_TQAVCTRL_DATATRANTIM | <answer> tqavctrl 
<token> tqavctrl); <answer> wr32(E1000_I210_TQAVCTRL, 
} <token> { <answer> else 
if <token> { <answer> (!is_any_txtime_enabled(adapter)) 
<token> = rd32(E1000_I210_TQAVCTRL); <answer> tqavctrl 
tqavctrl <token> ~E1000_TQAVCTRL_DATATRANTIM; <answer> &= 
tqavctrl <token> ~E1000_TQAVCTRL_FETCHTIME_DELTA; <answer> &= 
wr32(E1000_I210_TQAVCTRL, <token> <answer> tqavctrl); 
netdev_dbg(netdev, "Qav Tx mode: cbs %s, launchtime %s, <token> %d idleslope %d sendslope %d hiCredit %d locredit %d\n", <answer> queue 
ring->cbs_enable ? "enabled" <token> "disabled", <answer> : 
ring->launchtime_enable ? "enabled" <token> "disabled", <answer> : 
ring->idleslope, <token> <answer> ring->sendslope, 
ring->hicredit, <token> <answer> ring->locredit); 
<token> int igb_save_txtime_params(struct igb_adapter *adapter, int queue, <answer> static 
bool <token> <answer> enable) 
struct <token> *ring; <answer> igb_ring 
<token> (queue < 0 || queue > adapter->num_tx_queues) <answer> if 
return <token> <answer> -EINVAL; 
ring = <token> <answer> adapter->tx_ring[queue]; 
ring->launchtime_enable = <token> <answer> enable; 
<token> 0; <answer> return 
static int igb_save_cbs_params(struct igb_adapter *adapter, <token> queue, <answer> int 
bool <token> int idleslope, int sendslope, <answer> enable, 
int <token> int locredit) <answer> hicredit, 
<token> igb_ring *ring; <answer> struct 
if (queue < 0 || queue <token> adapter->num_tx_queues) <answer> > 
<token> -EINVAL; <answer> return 
<token> = adapter->tx_ring[queue]; <answer> ring 
ring->cbs_enable <token> enable; <answer> = 
ring->idleslope = <token> <answer> idleslope; 
ring->sendslope = <token> <answer> sendslope; 
ring->hicredit <token> hicredit; <answer> = 
ring->locredit = <token> <answer> locredit; 
<token> 0; <answer> return 
static void <token> igb_adapter *adapter) <answer> igb_setup_tx_mode(struct 
struct net_device *netdev <token> adapter->netdev; <answer> = 
struct <token> *hw = &adapter->hw; <answer> e1000_hw 
u32 <token> <answer> val; 
val <token> rd32(E1000_I210_TQAVCTRL); <answer> = 
val |= E1000_TQAVCTRL_XMIT_MODE | <token> <answer> E1000_TQAVCTRL_SP_WAIT_SR; 
<token> &= ~E1000_TQAVCTRL_DATAFETCHARB; <answer> val 
<token> val); <answer> wr32(E1000_I210_TQAVCTRL, 
<token> = rd32(E1000_TXPBS); <answer> val 
val <token> ~I210_TXPBSIZE_MASK; <answer> &= 
<token> |= I210_TXPBSIZE_PB0_6KB | I210_TXPBSIZE_PB1_6KB | <answer> val 
<token> | I210_TXPBSIZE_PB3_6KB; <answer> I210_TXPBSIZE_PB2_6KB 
<token> val); <answer> wr32(E1000_TXPBS, 
val <token> rd32(E1000_RXPBS); <answer> = 
val <token> ~I210_RXPBSIZE_MASK; <answer> &= 
val |= <token> <answer> I210_RXPBSIZE_PB_30KB; 
wr32(E1000_RXPBS, <token> <answer> val); 
val = (4096 <token> 1) / 64; <answer> - 
<token> val); <answer> wr32(E1000_I210_DTXMXPKTSZ, 
max_queue = (adapter->num_tx_queues < <token> ? <answer> I210_SR_QUEUES_NUM) 
<token> : I210_SR_QUEUES_NUM; <answer> adapter->num_tx_queues 
for (i = 0; i < max_queue; <token> { <answer> i++) 
<token> i); <answer> igb_config_tx_modes(adapter, 
} <token> { <answer> else 
wr32(E1000_RXPBS, <token> <answer> I210_RXPBSIZE_DEFAULT); 
wr32(E1000_TXPBS, <token> <answer> I210_TXPBSIZE_DEFAULT); 
wr32(E1000_I210_DTXMXPKTSZ, <token> <answer> I210_DTXMXPKTSZ_DEFAULT); 
val = <token> <answer> rd32(E1000_I210_TQAVCTRL); 
val <token> ~E1000_TQAVCTRL_XMIT_MODE; <answer> &= 
<token> val); <answer> wr32(E1000_I210_TQAVCTRL, 
netdev_dbg(netdev, "FQTSS %s\n", (is_fqtss_enabled(adapter)) <token> <answer> ? 
"enabled" : <token> <answer> "disabled"); 
static void igb_configure(struct <token> *adapter) <answer> igb_adapter 
struct net_device <token> = adapter->netdev; <answer> *netdev 
int <token> <answer> i; 
<token> (i = 0; i < adapter->num_rx_queues; i++) { <answer> for 
struct igb_ring *ring <token> adapter->rx_ring[i]; <answer> = 
igb_alloc_rx_buffers(ring, <token> <answer> igb_desc_unused(ring)); 
void <token> igb_adapter *adapter) <answer> igb_power_up_link(struct 
if (adapter->hw.phy.media_type == <token> <answer> e1000_media_type_copper) 
<token> void igb_power_down_link(struct igb_adapter *adapter) <answer> static 
if <token> == e1000_media_type_copper) <answer> (adapter->hw.phy.media_type 
static <token> igb_check_swap_media(struct igb_adapter *adapter) <answer> void 
struct e1000_hw <token> = &adapter->hw; <answer> *hw 
<token> ctrl_ext, connsw; <answer> u32 
bool <token> = false; <answer> swap_now 
ctrl_ext <token> rd32(E1000_CTRL_EXT); <answer> = 
<token> = rd32(E1000_CONNSW); <answer> connsw 
if ((hw->phy.media_type <token> e1000_media_type_copper) && <answer> == 
<token> & E1000_CONNSW_AUTOSENSE_EN))) { <answer> (!(connsw 
<token> = true; <answer> swap_now 
} else <token> ((hw->phy.media_type != e1000_media_type_copper) && <answer> if 
!(connsw & <token> { <answer> E1000_CONNSW_SERDESD)) 
int igb_up(struct <token> *adapter) <answer> igb_adapter 
<token> e1000_hw *hw = &adapter->hw; <answer> struct 
int <token> <answer> i; 
<token> &adapter->state); <answer> set_bit(__IGB_DOWN, 
static void igb_enable_mas(struct igb_adapter <token> <answer> *adapter) 
struct <token> *hw = &adapter->hw; <answer> e1000_hw 
<token> connsw = rd32(E1000_CONNSW); <answer> u32 
static <token> igb_set_i2c_bb(struct e1000_hw *hw) <answer> void 
u32 <token> <answer> ctrl_ext; 
s32 <token> <answer> i2cctl; 
ctrl_ext = <token> <answer> rd32(E1000_CTRL_EXT); 
<token> |= E1000_CTRL_I2C_ENA; <answer> ctrl_ext 
wr32(E1000_CTRL_EXT, <token> <answer> ctrl_ext); 
i2cctl <token> rd32(E1000_I2CPARAMS); <answer> = 
<token> |= E1000_I2CBB_EN <answer> i2cctl 
<token> E1000_I2C_CLK_OE_N <answer> | 
<token> E1000_I2C_DATA_OE_N; <answer> | 
<token> i2cctl); <answer> wr32(E1000_I2CPARAMS, 
<token> igb_reset(struct igb_adapter *adapter) <answer> void 
struct pci_dev *pdev = <token> <answer> adapter->pdev; 
struct e1000_hw *hw = <token> <answer> &adapter->hw; 
<token> e1000_mac_info *mac = &hw->mac; <answer> struct 
struct e1000_fc_info <token> = &hw->fc; <answer> *fc 
u32 <token> hwm; <answer> pba, 
switch (mac->type) <token> <answer> { 
<token> e1000_i350: <answer> case 
case <token> <answer> e1000_i354: 
case <token> <answer> e1000_82580: 
pba <token> rd32(E1000_RXPBS); <answer> = 
pba = <token> <answer> igb_rxpbs_adjust_82580(pba); 
case <token> <answer> e1000_82576: 
pba <token> rd32(E1000_RXPBS); <answer> = 
pba &= <token> <answer> E1000_RXPBS_SIZE_MASK_82576; 
case <token> <answer> e1000_82575: 
<token> e1000_i210: <answer> case 
case <token> <answer> e1000_i211: 
pba = <token> <answer> E1000_PBA_34K; 
if <token> == e1000_82575) { <answer> (mac->type 
u32 <token> min_tx_space, needed_tx_space; <answer> min_rx_space, 
min_rx_space <token> DIV_ROUND_UP(MAX_JUMBO_FRAME_SIZE, 1024); <answer> = 
<token> = adapter->max_frame_size; <answer> min_tx_space 
min_tx_space += <token> e1000_adv_tx_desc) - ETH_FCS_LEN; <answer> sizeof(union 
<token> = DIV_ROUND_UP(min_tx_space, 512); <answer> min_tx_space 
if (needed_tx_space < pba) <token> <answer> { 
pba <token> needed_tx_space; <answer> -= 
<token> (pba < min_rx_space) <answer> if 
pba <token> min_rx_space; <answer> = 
hwm = (pba <token> 10) - (adapter->max_frame_size + MAX_JUMBO_FRAME_SIZE); <answer> << 
if <token> <answer> (!hw->mac.autoneg) 
igb_init_dmac(adapter, <token> <answer> pba); 
<token> CONFIG_IGB_HWMON <answer> #ifdef 
if <token> <answer> (adapter->ets) 
if (features <token> NETIF_F_HW_VLAN_CTAG_RX) <answer> & 
features |= <token> <answer> NETIF_F_HW_VLAN_CTAG_TX; 
<token> &= ~NETIF_F_HW_VLAN_CTAG_TX; <answer> features 
<token> features; <answer> return 
static int igb_set_features(struct <token> *netdev, <answer> net_device 
<token> features) <answer> netdev_features_t 
<token> changed = netdev->features ^ features; <answer> netdev_features_t 
struct igb_adapter <token> = netdev_priv(netdev); <answer> *adapter 
if (changed <token> NETIF_F_HW_VLAN_CTAG_RX) <answer> & 
<token> features); <answer> igb_vlan_mode(netdev, 
<token> (!(changed & (NETIF_F_RXALL | NETIF_F_NTUPLE))) <answer> if 
<token> 0; <answer> return 
if (!(features <token> NETIF_F_NTUPLE)) { <answer> & 
<token> hlist_node *node2; <answer> struct 
struct <token> *rule; <answer> igb_nfc_filter 
hlist_for_each_entry_safe(rule, <token> <answer> node2, 
&adapter->nfc_filter_list, nfc_node) <token> <answer> { 
igb_erase_filter(adapter, <token> <answer> rule); 
adapter->nfc_filter_count = <token> <answer> 0; 
<token> = features; <answer> netdev->features 
if <token> <answer> (netif_running(netdev)) 
return <token> <answer> 1; 
static int igb_ndo_fdb_add(struct ndmsg *ndm, <token> nlattr *tb[], <answer> struct 
struct <token> *dev, <answer> net_device 
const unsigned char *addr, u16 <token> <answer> vid, 
<token> flags, <answer> u16 
struct netlink_ext_ack <token> <answer> *extack) 
if (skb->encapsulation && !(features & <token> <answer> NETIF_F_TSO_MANGLEID)) 
features &= <token> <answer> ~NETIF_F_TSO; 
return <token> <answer> features; 
static <token> igb_offload_apply(struct igb_adapter *adapter, s32 queue) <answer> void 
<token> (!is_fqtss_enabled(adapter)) { <answer> if 
<token> true); <answer> enable_fqtss(adapter, 
igb_config_tx_modes(adapter, <token> <answer> queue); 
if <token> && !is_any_txtime_enabled(adapter)) <answer> (!is_any_cbs_enabled(adapter) 
<token> false); <answer> enable_fqtss(adapter, 
static int igb_offload_cbs(struct <token> *adapter, <answer> igb_adapter 
struct tc_cbs_qopt_offload <token> <answer> *qopt) 
<token> e1000_hw *hw = &adapter->hw; <answer> struct 
<token> err; <answer> int 
<token> ring->tail); <answer> writel(ring->next_to_use, 
static struct igb_ring *igb_xdp_tx_queue_mapping(struct <token> *adapter) <answer> igb_adapter 
<token> int r_idx = smp_processor_id(); <answer> unsigned 
if (r_idx >= <token> <answer> adapter->num_tx_queues) 
r_idx = <token> % adapter->num_tx_queues; <answer> r_idx 
<token> adapter->tx_ring[r_idx]; <answer> return 
static int igb_xdp_xmit_back(struct igb_adapter *adapter, struct <token> *xdp) <answer> xdp_buff 
<token> xdp_frame *xdpf = xdp_convert_buff_to_frame(xdp); <answer> struct 
<token> cpu = smp_processor_id(); <answer> int 
struct igb_ring <token> <answer> *tx_ring; 
struct <token> *nq; <answer> netdev_queue 
u32 <token> <answer> ret; 
<token> (unlikely(!xdpf)) <answer> if 
<token> IGB_XDP_CONSUMED; <answer> return 
tx_ring <token> adapter->xdp_prog ? igb_xdp_tx_queue_mapping(adapter) : NULL; <answer> = 
if <token> <answer> (unlikely(!tx_ring)) 
<token> IGB_XDP_CONSUMED; <answer> return 
<token> = txring_txq(tx_ring); <answer> nq 
__netif_tx_lock(nq, <token> <answer> cpu); 
tx_ring = adapter->xdp_prog ? igb_xdp_tx_queue_mapping(adapter) <token> NULL; <answer> : 
if <token> <answer> (unlikely(!tx_ring)) 
return <token> <answer> -ENXIO; 
nq = <token> <answer> txring_txq(tx_ring); 
__netif_tx_lock(nq, <token> <answer> cpu); 
<token> igb_set_fw_version(struct igb_adapter *adapter) <answer> void 
struct <token> *hw = &adapter->hw; <answer> e1000_hw 
struct <token> fw; <answer> e1000_fw_version 
<token> &fw); <answer> igb_get_fw_version(hw, 
switch <token> { <answer> (hw->mac.type) 
case <token> <answer> e1000_i210: 
case <token> <answer> e1000_i211: 
if (!(igb_get_flash_presence_i210(hw))) <token> <answer> { 
fw.invm_major, <token> <answer> fw.invm_minor, 
static void <token> igb_adapter *adapter) <answer> igb_init_mas(struct 
struct e1000_hw <token> = &adapter->hw; <answer> *hw 
<token> eeprom_data; <answer> u16 
hw->nvm.ops.read(hw, NVM_COMPAT, <token> &eeprom_data); <answer> 1, 
<token> (hw->bus.func) { <answer> switch 
<token> E1000_FUNC_0: <answer> case 
if (eeprom_data & IGB_MAS_ENABLE_0) <token> <answer> { 
adapter->flags |= <token> <answer> IGB_FLAG_MAS_ENABLE; 
"MAS: Enabling Media Autosense for port <token> <answer> %d\n", 
case <token> <answer> E1000_FUNC_1: 
if (eeprom_data <token> IGB_MAS_ENABLE_1) { <answer> & 
<token> |= IGB_FLAG_MAS_ENABLE; <answer> adapter->flags 
"MAS: Enabling Media Autosense for <token> %d\n", <answer> port 
case <token> <answer> E1000_FUNC_2: 
if <token> & IGB_MAS_ENABLE_2) { <answer> (eeprom_data 
<token> |= IGB_FLAG_MAS_ENABLE; <answer> adapter->flags 
"MAS: Enabling Media <token> for port %d\n", <answer> Autosense 
case <token> <answer> E1000_FUNC_3: 
if (eeprom_data & IGB_MAS_ENABLE_3) <token> <answer> { 
<token> |= IGB_FLAG_MAS_ENABLE; <answer> adapter->flags 
"MAS: Enabling Media Autosense for port <token> <answer> %d\n", 
static s32 igb_init_i2c(struct <token> *adapter) <answer> igb_adapter 
<token> status = 0; <answer> s32 
adapter->i2c_adap.owner = <token> <answer> THIS_MODULE; 
<token> = igb_i2c_algo; <answer> adapter->i2c_algo 
adapter->i2c_algo.data = <token> <answer> adapter; 
adapter->i2c_adap.algo_data = <token> <answer> &adapter->i2c_algo; 
adapter->i2c_adap.dev.parent <token> &adapter->pdev->dev; <answer> = 
strscpy(adapter->i2c_adap.name, <token> BB", <answer> "igb 
status = <token> <answer> i2c_bit_add_bus(&adapter->i2c_adap); 
<token> status; <answer> return 
<token> int igb_probe(struct pci_dev *pdev, const struct pci_device_id *ent) <answer> static 
struct <token> *netdev; <answer> net_device 
struct igb_adapter <token> <answer> *adapter; 
<token> e1000_hw *hw; <answer> struct 
<token> eeprom_data = 0; <answer> u16 
s32 <token> <answer> ret_val; 
<token> (pdev->is_virtfn) { <answer> if 
WARN(1, KERN_ERR "%s (%x:%x) should not <token> a VF!\n", <answer> be 
pci_name(pdev), <token> pdev->device); <answer> pdev->vendor, 
return <token> <answer> -EINVAL; 
err = <token> <answer> pci_enable_device_mem(pdev); 
if <token> <answer> (err) 
return <token> <answer> err; 
err <token> dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64)); <answer> = 
<token> (err) { <answer> if 
"No <token> DMA configuration, aborting\n"); <answer> usable 
goto <token> <answer> err_dma; 
err <token> pci_request_mem_regions(pdev, igb_driver_name); <answer> = 
<token> (err) <answer> if 
<token> err_pci_reg; <answer> goto 
err = <token> <answer> -ENOMEM; 
netdev = alloc_etherdev_mq(sizeof(struct <token> <answer> igb_adapter), 
<token> (!netdev) <answer> if 
<token> err_alloc_etherdev; <answer> goto 
<token> &pdev->dev); <answer> SET_NETDEV_DEV(netdev, 
<token> netdev); <answer> pci_set_drvdata(pdev, 
adapter <token> netdev_priv(netdev); <answer> = 
adapter->netdev <token> netdev; <answer> = 
adapter->pdev = <token> <answer> pdev; 
<token> = &adapter->hw; <answer> hw 
hw->back <token> adapter; <answer> = 
adapter->msg_enable = netif_msg_init(debug, <token> <answer> DEFAULT_MSG_ENABLE); 
<token> = -EIO; <answer> err 
adapter->io_addr = <token> 0, 0); <answer> pci_iomap(pdev, 
<token> (!adapter->io_addr) <answer> if 
goto <token> <answer> err_ioremap; 
netdev->features |= NETIF_F_SG <token> <answer> | 
<token> | <answer> NETIF_F_TSO 
NETIF_F_TSO6 <token> <answer> | 
NETIF_F_RXHASH <token> <answer> | 
NETIF_F_RXCSUM <token> <answer> | 
if (hw->mac.type <token> e1000_82576) <answer> >= 
netdev->features |= NETIF_F_SCTP_CRC | <token> <answer> NETIF_F_GSO_UDP_L4; 
if <token> >= e1000_i350) <answer> (hw->mac.type 
<token> |= NETIF_F_HW_TC; <answer> netdev->features 
#define IGB_GSO_PARTIAL_FEATURES (NETIF_F_GSO_GRE | <token> <answer> \ 
NETIF_F_GSO_GRE_CSUM | <token> <answer> \ 
<token> | \ <answer> NETIF_F_GSO_IPXIP4 
<token> | \ <answer> NETIF_F_GSO_IPXIP6 
NETIF_F_GSO_UDP_TUNNEL <token> \ <answer> | 
netdev->gso_partial_features = <token> <answer> IGB_GSO_PARTIAL_FEATURES; 
netdev->features |= NETIF_F_GSO_PARTIAL <token> IGB_GSO_PARTIAL_FEATURES; <answer> | 
switch (hw->mac.type) <token> <answer> { 
<token> e1000_i210: <answer> case 
<token> e1000_i211: <answer> case 
if (igb_get_flash_presence_i210(hw)) <token> <answer> { 
if (hw->nvm.ops.validate(hw) < <token> { <answer> 0) 
"The NVM <token> Is Not Valid\n"); <answer> Checksum 
<token> = -EIO; <answer> err 
<token> err_eeprom; <answer> goto 
if (hw->nvm.ops.validate(hw) <token> 0) { <answer> < 
<token> "The NVM Checksum Is Not Valid\n"); <answer> dev_err(&pdev->dev, 
err = <token> <answer> -EIO; 
<token> err_eeprom; <answer> goto 
if (eth_platform_get_mac_address(&pdev->dev, <token> { <answer> hw->mac.addr)) 
switch (pdev->device) <token> <answer> { 
<token> E1000_DEV_ID_82575GB_QUAD_COPPER: <answer> case 
<token> &= ~IGB_FLAG_WOL_SUPPORTED; <answer> adapter->flags 
case <token> <answer> E1000_DEV_ID_82575EB_FIBER_SERDES: 
<token> E1000_DEV_ID_82576_FIBER: <answer> case 
<token> E1000_DEV_ID_82576_SERDES: <answer> case 
<token> (rd32(E1000_STATUS) & E1000_STATUS_FUNC_1) <answer> if 
adapter->flags <token> ~IGB_FLAG_WOL_SUPPORTED; <answer> &= 
<token> E1000_DEV_ID_82576_QUAD_COPPER: <answer> case 
<token> E1000_DEV_ID_82576_QUAD_COPPER_ET2: <answer> case 
if (((hw->mac.type == e1000_i350) <token> <answer> || 
(hw->mac.type <token> e1000_i354)) && <answer> == 
(pdev->subsystem_vendor == <token> { <answer> PCI_VENDOR_ID_DELL)) 
adapter->flags <token> IGB_FLAG_WOL_SUPPORTED; <answer> |= 
adapter->wol = <token> <answer> 0; 
if (hw->mac.type == e1000_i350) <token> <answer> { 
if (((pdev->subsystem_device == 0x5001) <token> <answer> || 
(pdev->subsystem_device == 0x5002)) <token> <answer> && 
(hw->bus.func == <token> { <answer> 0)) 
<token> |= IGB_FLAG_WOL_SUPPORTED; <answer> adapter->flags 
adapter->wol <token> 0; <answer> = 
if (pdev->subsystem_device <token> 0x1F52) <answer> == 
adapter->flags <token> IGB_FLAG_WOL_SUPPORTED; <answer> |= 
adapter->flags <token> IGB_FLAG_WOL_SUPPORTED); <answer> & 
strcpy(netdev->name, <token> <answer> "eth%d"); 
err = <token> <answer> register_netdev(netdev); 
<token> (err) <answer> if 
<token> err_register; <answer> goto 
hw->nvm.ops.read(hw, <token> 1, &ets_word); <answer> NVM_ETS_CFG, 
if <token> != 0x0000 && ets_word != 0xFFFF) <answer> (ets_word 
adapter->ets <token> true; <answer> = 
<token> = false; <answer> adapter->ets 
<token> (adapter->ets) <answer> if 
if <token> <answer> (igb_sysfs_init(adapter)) 
"failed <token> allocate sysfs resources\n"); <answer> to 
} <token> { <answer> else 
adapter->ets <token> false; <answer> = 
num_vf_mac_filters <token> adapter->hw.mac.rar_entry_count - <answer> = 
(1 + <token> + <answer> IGB_PF_MAC_FILTERS_RESERVED 
adapter->vf_mac_list = <token> <answer> kcalloc(num_vf_mac_filters, 
<token> vf_mac_filter), <answer> sizeof(struct 
mac_list = <token> <answer> adapter->vf_mac_list; 
if <token> { <answer> (adapter->vf_mac_list) 
"Unable to <token> memory for VF MAC filter list\n"); <answer> allocate 
dev_info(&pdev->dev, "%d <token> allocated\n", <answer> VFs 
for <token> = 0; i < adapter->vfs_allocated_count; i++) <answer> (i 
<token> i); <answer> igb_vf_configure(adapter, 
static void igb_remove_i2c(struct igb_adapter <token> <answer> *adapter) 
static void igb_remove(struct pci_dev <token> <answer> *pdev) 
<token> net_device *netdev = pci_get_drvdata(pdev); <answer> struct 
struct igb_adapter *adapter <token> netdev_priv(netdev); <answer> = 
<token> e1000_hw *hw = &adapter->hw; <answer> struct 
<token> CONFIG_IGB_HWMON <answer> #ifdef 
set_bit(__IGB_DOWN, <token> <answer> &adapter->state); 
<token> CONFIG_IGB_DCA <answer> #ifdef 
if (adapter->flags <token> IGB_FLAG_DCA_ENABLED) { <answer> & 
dev_info(&pdev->dev, "DCA <token> <answer> disabled\n"); 
adapter->flags &= <token> <answer> ~IGB_FLAG_DCA_ENABLED; 
<token> E1000_DCA_CTRL_DCA_MODE_DISABLE); <answer> wr32(E1000_DCA_CTRL, 
#ifdef <token> <answer> CONFIG_PCI_IOV 
<token> false); <answer> igb_disable_sriov(pdev, 
pci_iounmap(pdev, <token> <answer> adapter->io_addr); 
if <token> <answer> (hw->flash_address) 
static <token> igb_probe_vfs(struct igb_adapter *adapter) <answer> void 
#ifdef <token> <answer> CONFIG_PCI_IOV 
struct <token> *pdev = adapter->pdev; <answer> pci_dev 
struct <token> *hw = &adapter->hw; <answer> e1000_hw 
<token> true); <answer> igb_set_interrupt_capability(adapter, 
pci_sriov_set_totalvfs(pdev, <token> <answer> 7); 
igb_enable_sriov(pdev, <token> false); <answer> max_vfs, 
if (adapter->rss_queues <token> (max_rss_queues / 2)) <answer> > 
<token> |= IGB_FLAG_QUEUE_PAIRS; <answer> adapter->flags 
adapter->flags <token> ~IGB_FLAG_QUEUE_PAIRS; <answer> &= 
<token> int igb_sw_init(struct igb_adapter *adapter) <answer> static 
<token> e1000_hw *hw = &adapter->hw; <answer> struct 
struct net_device *netdev = <token> <answer> adapter->netdev; 
struct pci_dev *pdev = <token> <answer> adapter->pdev; 
pci_read_config_word(pdev, PCI_COMMAND, <token> <answer> &hw->bus.pci_cmd_word); 
<token> int __igb_open(struct net_device *netdev, bool resuming) <answer> static 
struct <token> *adapter = netdev_priv(netdev); <answer> igb_adapter 
struct e1000_hw *hw = <token> <answer> &adapter->hw; 
struct pci_dev *pdev <token> adapter->pdev; <answer> = 
<token> err; <answer> int 
int <token> <answer> i; 
err <token> igb_request_irq(adapter); <answer> = 
if <token> <answer> (err) 
<token> err_req_irq; <answer> goto 
static int __igb_close(struct net_device <token> bool suspending) <answer> *netdev, 
struct igb_adapter *adapter = <token> <answer> netdev_priv(netdev); 
struct pci_dev *pdev <token> adapter->pdev; <answer> = 
<token> &adapter->state)); <answer> WARN_ON(test_bit(__IGB_RESETTING, 
if <token> <answer> (!suspending) 
<token> (!suspending) <answer> if 
<token> 0; <answer> return 
int igb_close(struct <token> *netdev) <answer> net_device 
if (netif_device_present(netdev) <token> netdev->dismantle) <answer> || 
return __igb_close(netdev, <token> <answer> false); 
return <token> <answer> 0; 
<token> igb_setup_tx_resources(struct igb_ring *tx_ring) <answer> int 
struct device *dev <token> tx_ring->dev; <answer> = 
int <token> <answer> size; 
size = <token> igb_tx_buffer) * tx_ring->count; <answer> sizeof(struct 
tx_ring->tx_buffer_info = <token> <answer> vmalloc(size); 
<token> (!tx_ring->tx_buffer_info) <answer> if 
<token> err; <answer> goto 
static int igb_setup_all_tx_resources(struct igb_adapter <token> <answer> *adapter) 
<token> pci_dev *pdev = adapter->pdev; <answer> struct 
int i, err = <token> <answer> 0; 
for (i = 0; <token> < adapter->num_tx_queues; i++) { <answer> i 
err = <token> <answer> igb_setup_tx_resources(adapter->tx_ring[i]); 
if <token> { <answer> (err) 
"Allocation for Tx Queue <token> failed\n", i); <answer> %u 
<token> (i--; i >= 0; i--) <answer> for 
return <token> <answer> err; 
void igb_setup_tctl(struct <token> *adapter) <answer> igb_adapter 
struct e1000_hw *hw = <token> <answer> &adapter->hw; 
<token> tctl; <answer> u32 
void igb_configure_tx_ring(struct igb_adapter <token> <answer> *adapter, 
<token> igb_ring *ring) <answer> struct 
struct e1000_hw *hw <token> &adapter->hw; <answer> = 
u32 <token> = 0; <answer> txdctl 
<token> tdba = ring->dma; <answer> u64 
int <token> = ring->reg_idx; <answer> reg_idx 
ring->count * sizeof(union <token> <answer> e1000_adv_tx_desc)); 
<token> & 0x00000000ffffffffULL); <answer> tdba 
<token> tdba >> 32); <answer> wr32(E1000_TDBAH(reg_idx), 
ring->tail = <token> + E1000_TDT(reg_idx); <answer> adapter->io_addr 
<token> 0); <answer> wr32(E1000_TDH(reg_idx), 
<token> ring->tail); <answer> writel(0, 
txdctl |= <token> <answer> IGB_TX_PTHRESH; 
txdctl |= <token> << 8; <answer> IGB_TX_HTHRESH 
<token> |= IGB_TX_WTHRESH << 16; <answer> txdctl 
static <token> igb_configure_tx(struct igb_adapter *adapter) <answer> void 
struct e1000_hw <token> = &adapter->hw; <answer> *hw 
<token> i; <answer> int 
int igb_setup_rx_resources(struct igb_ring <token> <answer> *rx_ring) 
<token> igb_adapter *adapter = netdev_priv(rx_ring->netdev); <answer> struct 
struct device *dev <token> rx_ring->dev; <answer> = 
int size, <token> <answer> res; 
static int igb_setup_all_rx_resources(struct <token> *adapter) <answer> igb_adapter 
struct pci_dev *pdev <token> adapter->pdev; <answer> = 
int <token> err = 0; <answer> i, 
<token> (i = 0; i < adapter->num_rx_queues; i++) { <answer> for 
err = <token> <answer> igb_setup_rx_resources(adapter->rx_ring[i]); 
<token> (err) { <answer> if 
"Allocation for Rx Queue %u failed\n", <token> <answer> i); 
for (i--; i >= 0; <token> <answer> i--) 
return <token> <answer> err; 
<token> void igb_setup_mrqc(struct igb_adapter *adapter) <answer> static 
<token> e1000_hw *hw = &adapter->hw; <answer> struct 
u32 mrqc, <token> <answer> rxcsum; 
u32 j, <token> <answer> num_rx_queues; 
u32 <token> <answer> rss_key[10]; 
netdev_rss_key_fill(rss_key, <token> <answer> sizeof(rss_key)); 
for (j <token> 0; j < 10; j++) <answer> = 
wr32(E1000_RSSRK(j), <token> <answer> rss_key[j]); 
num_rx_queues = <token> <answer> adapter->rss_queues; 
switch (hw->mac.type) <token> <answer> { 
<token> e1000_82576: <answer> case 
rxcsum = <token> <answer> rd32(E1000_RXCSUM); 
rxcsum |= <token> <answer> E1000_RXCSUM_PCSD; 
if <token> >= e1000_82576) <answer> (adapter->hw.mac.type 
mrqc = E1000_MRQC_RSS_FIELD_IPV4 <token> <answer> | 
E1000_MRQC_RSS_FIELD_IPV4_TCP <token> <answer> | 
<token> | <answer> E1000_MRQC_RSS_FIELD_IPV6 
<token> | <answer> E1000_MRQC_RSS_FIELD_IPV6_TCP 
if (adapter->flags & <token> <answer> IGB_FLAG_RSS_FIELD_IPV4_UDP) 
<token> |= E1000_MRQC_RSS_FIELD_IPV4_UDP; <answer> mrqc 
if <token> & IGB_FLAG_RSS_FIELD_IPV6_UDP) <answer> (adapter->flags 
<token> |= E1000_MRQC_RSS_FIELD_IPV6_UDP; <answer> mrqc 
if (adapter->vfs_allocated_count) <token> <answer> { 
if (hw->mac.type > e1000_82575) <token> <answer> { 
void igb_setup_rctl(struct <token> *adapter) <answer> igb_adapter 
struct e1000_hw *hw = <token> <answer> &adapter->hw; 
u32 <token> <answer> rctl; 
<token> = rd32(E1000_RCTL); <answer> rctl 
rctl <token> ~(3 << E1000_RCTL_MO_SHIFT); <answer> &= 
rctl &= ~(E1000_RCTL_LBM_TCVR <token> E1000_RCTL_LBM_MAC); <answer> | 
rctl <token> E1000_RCTL_EN | E1000_RCTL_BAM | E1000_RCTL_RDMTS_HALF | <answer> |= 
(hw->mac.mc_filter_type <token> E1000_RCTL_MO_SHIFT); <answer> << 
<token> |= E1000_RCTL_SECRC; <answer> rctl 
if <token> { <answer> (adapter->vfs_allocated_count) 
<token> rctl); <answer> wr32(E1000_RCTL, 
static inline int igb_set_vf_rlpml(struct igb_adapter *adapter, int <token> <answer> size, 
<token> vfn) <answer> int 
struct e1000_hw *hw <token> &adapter->hw; <answer> = 
u32 <token> <answer> vmolr; 
<token> (size > MAX_JUMBO_FRAME_SIZE) <answer> if 
size = <token> <answer> MAX_JUMBO_FRAME_SIZE; 
vmolr = <token> <answer> rd32(E1000_VMOLR(vfn)); 
vmolr &= <token> <answer> ~E1000_VMOLR_RLPML_MASK; 
vmolr |= <token> | E1000_VMOLR_LPE; <answer> size 
<token> vmolr); <answer> wr32(E1000_VMOLR(vfn), 
return <token> <answer> 0; 
static inline <token> igb_set_vf_vlan_strip(struct igb_adapter *adapter, <answer> void 
int vfn, <token> enable) <answer> bool 
struct e1000_hw <token> = &adapter->hw; <answer> *hw 
u32 val, <token> <answer> reg; 
if (hw->mac.type < <token> <answer> e1000_82576) 
if (hw->mac.type <token> e1000_i350) <answer> == 
reg = <token> <answer> E1000_DVMOLR(vfn); 
reg = <token> <answer> E1000_VMOLR(vfn); 
val = <token> <answer> rd32(reg); 
if <token> <answer> (enable) 
val |= <token> <answer> E1000_VMOLR_STRVLAN; 
val &= <token> <answer> ~(E1000_VMOLR_STRVLAN); 
wr32(reg, <token> <answer> val); 
static inline void igb_set_vmolr(struct <token> *adapter, <answer> igb_adapter 
int vfn, bool <token> <answer> aupe) 
struct e1000_hw *hw <token> &adapter->hw; <answer> = 
<token> vmolr; <answer> u32 
if (hw->mac.type < <token> <answer> e1000_82576) 
vmolr <token> rd32(E1000_VMOLR(vfn)); <answer> = 
<token> (aupe) <answer> if 
<token> (vfn <= adapter->vfs_allocated_count) <answer> if 
void <token> igb_adapter *adapter, struct igb_ring *ring) <answer> igb_setup_srrctl(struct 
struct e1000_hw <token> = &adapter->hw; <answer> *hw 
int <token> = ring->reg_idx; <answer> reg_idx 
u32 srrctl = <token> <answer> 0; 
srrctl <token> IGB_RX_HDR_LEN << E1000_SRRCTL_BSIZEHDRSIZE_SHIFT; <answer> = 
<token> (ring_uses_large_buffer(ring)) <answer> if 
srrctl |= IGB_RXBUFFER_3072 >> <token> <answer> E1000_SRRCTL_BSIZEPKT_SHIFT; 
srrctl |= IGB_RXBUFFER_2048 >> <token> <answer> E1000_SRRCTL_BSIZEPKT_SHIFT; 
srrctl <token> E1000_SRRCTL_DESCTYPE_ADV_ONEBUF; <answer> |= 
<token> (hw->mac.type >= e1000_82580) <answer> if 
srrctl |= <token> <answer> E1000_SRRCTL_TIMESTAMP; 
<token> (adapter->vfs_allocated_count || <answer> if 
<token> & e1000_fc_rx_pause) && <answer> (!(hw->fc.current_mode 
adapter->num_rx_queues <token> 1)) <answer> > 
srrctl |= <token> <answer> E1000_SRRCTL_DROP_EN; 
<token> srrctl); <answer> wr32(E1000_SRRCTL(reg_idx), 
void <token> igb_adapter *adapter, <answer> igb_configure_rx_ring(struct 
<token> igb_ring *ring) <answer> struct 
<token> e1000_hw *hw = &adapter->hw; <answer> struct 
<token> e1000_adv_rx_desc *rx_desc; <answer> union 
u64 rdba <token> ring->dma; <answer> = 
<token> reg_idx = ring->reg_idx; <answer> int 
<token> rxdctl = 0; <answer> u32 
<token> NULL)); <answer> MEM_TYPE_PAGE_SHARED, 
static void igb_configure_rx(struct <token> *adapter) <answer> igb_adapter 
<token> i; <answer> int 
for (i = 0; i < <token> i++) { <answer> adapter->num_rx_queues; 
struct igb_ring *rx_ring <token> adapter->rx_ring[i]; <answer> = 
<token> rx_ring); <answer> igb_set_rx_buffer_len(adapter, 
<token> rx_ring); <answer> igb_configure_rx_ring(adapter, 
void <token> igb_ring *tx_ring) <answer> igb_free_tx_resources(struct 
tx_ring->tx_buffer_info <token> NULL; <answer> = 
static <token> igb_free_all_tx_resources(struct igb_adapter *adapter) <answer> void 
<token> i; <answer> int 
for (i = 0; i < <token> i++) <answer> adapter->num_tx_queues; 
if <token> <answer> (adapter->tx_ring[i]) 
static <token> igb_clean_tx_ring(struct igb_ring *tx_ring) <answer> void 
u16 i = <token> <answer> tx_ring->next_to_clean; 
struct igb_tx_buffer *tx_buffer = <token> <answer> &tx_ring->tx_buffer_info[i]; 
<token> (i != tx_ring->next_to_use) { <answer> while 
union e1000_adv_tx_desc <token> *tx_desc; <answer> *eop_desc, 
static void igb_clean_all_tx_rings(struct igb_adapter <token> <answer> *adapter) 
int <token> <answer> i; 
for (i = 0; i < adapter->num_tx_queues; <token> <answer> i++) 
<token> (adapter->tx_ring[i]) <answer> if 
void igb_free_rx_resources(struct <token> *rx_ring) <answer> igb_ring 
<token> = NULL; <answer> rx_ring->xdp_prog 
rx_ring->rx_buffer_info <token> NULL; <answer> = 
static void igb_free_all_rx_resources(struct igb_adapter <token> <answer> *adapter) 
<token> i; <answer> int 
for (i = 0; i < <token> i++) <answer> adapter->num_rx_queues; 
<token> (adapter->rx_ring[i]) <answer> if 
static void igb_clean_rx_ring(struct igb_ring <token> <answer> *rx_ring) 
u16 i <token> rx_ring->next_to_clean; <answer> = 
<token> = NULL; <answer> rx_ring->skb 
static void igb_clean_all_rx_rings(struct <token> *adapter) <answer> igb_adapter 
<token> i; <answer> int 
for <token> = 0; i < adapter->num_rx_queues; i++) <answer> (i 
if <token> <answer> (adapter->rx_ring[i]) 
static int igb_set_mac(struct net_device *netdev, void <token> <answer> *p) 
<token> igb_adapter *adapter = netdev_priv(netdev); <answer> struct 
struct e1000_hw <token> = &adapter->hw; <answer> *hw 
struct sockaddr *addr <token> p; <answer> = 
if <token> <answer> (!is_valid_ether_addr(addr->sa_data)) 
<token> -EADDRNOTAVAIL; <answer> return 
eth_hw_addr_set(netdev, <token> <answer> addr->sa_data); 
memcpy(hw->mac.addr, addr->sa_data, <token> <answer> netdev->addr_len); 
static <token> igb_write_mc_addr_list(struct net_device *netdev) <answer> int 
<token> igb_adapter *adapter = netdev_priv(netdev); <answer> struct 
struct e1000_hw <token> = &adapter->hw; <answer> *hw 
<token> netdev_hw_addr *ha; <answer> struct 
u8 <token> <answer> *mta_list; 
int <token> <answer> i; 
if <token> { <answer> (netdev_mc_empty(netdev)) 
static void <token> net_device *netdev) <answer> igb_set_rx_mode(struct 
struct <token> *adapter = netdev_priv(netdev); <answer> igb_adapter 
<token> e1000_hw *hw = &adapter->hw; <answer> struct 
unsigned int vfn <token> adapter->vfs_allocated_count; <answer> = 
u32 rctl = 0, vmolr = 0, rlpml = <token> <answer> MAX_JUMBO_FRAME_SIZE; 
<token> count; <answer> int 
count = <token> <answer> igb_write_mc_addr_list(netdev); 
<token> (count < 0) { <answer> if 
rctl |= <token> <answer> E1000_RCTL_MPE; 
vmolr |= <token> <answer> E1000_VMOLR_MPME; 
} else if <token> { <answer> (count) 
<token> |= E1000_VMOLR_ROMPE; <answer> vmolr 
if (__dev_uc_sync(netdev, <token> igb_uc_unsync)) { <answer> igb_uc_sync, 
rctl |= <token> <answer> E1000_RCTL_UPE; 
vmolr |= <token> <answer> E1000_VMOLR_ROPE; 
if ((hw->mac.type < <token> || (hw->mac.type > e1000_i350)) <answer> e1000_82576) 
static void igb_update_phy_info(struct <token> *t) <answer> timer_list 
struct igb_adapter *adapter = <token> t, phy_info_timer); <answer> from_timer(adapter, 
<token> igb_has_link(struct igb_adapter *adapter) <answer> bool 
