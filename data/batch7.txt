#include <token> <answer> <linux/clk-provider.h> 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_address.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/spinlock.h> 
<token> SUN4I_A10_PLL3_GATE_BIT 31 <answer> #define 
<token> SUN4I_A10_PLL3_DIV_WIDTH 7 <answer> #define 
<token> SUN4I_A10_PLL3_DIV_SHIFT 0 <answer> #define 
<token> DEFINE_SPINLOCK(sun4i_a10_pll3_lock); <answer> static 
static void <token> sun4i_a10_pll3_setup(struct device_node *node) <answer> __init 
const char *clk_name = <token> *parent; <answer> node->name, 
struct clk_multiplier <token> <answer> *mult; 
struct <token> *gate; <answer> clk_gate 
<token> resource res; <answer> struct 
void <token> *reg; <answer> __iomem 
struct clk <token> <answer> *clk; 
int <token> <answer> ret; 
of_property_read_string(node, <token> &clk_name); <answer> "clock-output-names", 
parent <token> of_clk_get_parent_name(node, 0); <answer> = 
reg <token> of_io_request_and_map(node, 0, of_node_full_name(node)); <answer> = 
if <token> { <answer> (IS_ERR(reg)) 
pr_err("%s: <token> not map the clock registers\n", clk_name); <answer> Could 
<token> = kzalloc(sizeof(*gate), GFP_KERNEL); <answer> gate 
<token> (!gate) <answer> if 
goto <token> <answer> err_unmap; 
<token> = reg; <answer> gate->reg 
<token> = SUN4I_A10_PLL3_GATE_BIT; <answer> gate->bit_idx 
gate->lock = <token> <answer> &sun4i_a10_pll3_lock; 
mult = kzalloc(sizeof(*mult), <token> <answer> GFP_KERNEL); 
<token> (!mult) <answer> if 
goto <token> <answer> err_free_gate; 
mult->reg = <token> <answer> reg; 
mult->shift = <token> <answer> SUN4I_A10_PLL3_DIV_SHIFT; 
<token> = SUN4I_A10_PLL3_DIV_WIDTH; <answer> mult->width 
mult->lock = <token> <answer> &sun4i_a10_pll3_lock; 
clk = <token> clk_name, <answer> clk_register_composite(NULL, 
&parent, <token> <answer> 1, 
<token> NULL, <answer> NULL, 
&mult->hw, <token> <answer> &clk_multiplier_ops, 
<token> &clk_gate_ops, <answer> &gate->hw, 
if (IS_ERR(clk)) <token> <answer> { 
<token> Couldn't register the clock\n", clk_name); <answer> pr_err("%s: 
goto <token> <answer> err_free_mult; 
ret = <token> of_clk_src_simple_get, clk); <answer> of_clk_add_provider(node, 
if (ret) <token> <answer> { 
pr_err("%s: Couldn't <token> DT provider\n", <answer> register 
<token> err_clk_unregister; <answer> goto 
of_address_to_resource(node, <token> &res); <answer> 0, 
release_mem_region(res.start, <token> <answer> resource_size(&res)); 
CLK_OF_DECLARE(sun4i_a10_pll3, <token> <answer> "allwinner,sun4i-a10-pll3-clk", 
<token> "priv.h" <answer> #include 
#include <token> <answer> "regs.h" 
#include <token> <answer> <core/client.h> 
<token> <core/gpuobj.h> <answer> #include 
#include <token> <answer> <engine/fifo.h> 
#include <token> <answer> <engine/fifo/chan.h> 
<token> <subdev/instmem.h> <answer> #include 
<token> <subdev/timer.h> <answer> #include 
static <token> <answer> u32 
<token> = { <answer> nv04_gr_ctx_regs[] 
#define nv04_gr(p) container_of((p), struct <token> base) <answer> nv04_gr, 
struct nv04_gr <token> <answer> { 
struct nvkm_gr <token> <answer> base; 
<token> nv04_gr_chan *chan[16]; <answer> struct 
<token> lock; <answer> spinlock_t 
<token> nv04_gr_chan(p) container_of((p), struct nv04_gr_chan, object) <answer> #define 
struct <token> { <answer> nv04_gr_chan 
struct nvkm_object <token> <answer> object; 
<token> nv04_gr *gr; <answer> struct 
<token> chid; <answer> int 
u32 <token> <answer> nv04[ARRAY_SIZE(nv04_gr_ctx_regs)]; 
<token> void <answer> static 
nv04_gr_set_ctx1(struct nvkm_device *device, u32 <token> u32 mask, u32 value) <answer> inst, 
int <token> = (nvkm_rd32(device, NV04_PGRAPH_TRAPPED_ADDR) >> 13) & 0x7; <answer> subc 
u32 <token> <answer> tmp; 
<token> = nvkm_rd32(device, 0x700000 + inst); <answer> tmp 
tmp &= <token> <answer> ~mask; 
tmp |= <token> <answer> value; 
nvkm_wr32(device, 0x700000 + inst, <token> <answer> tmp); 
nvkm_wr32(device, NV04_PGRAPH_CTX_SWITCH1, <token> <answer> tmp); 
nvkm_wr32(device, NV04_PGRAPH_CTX_CACHE1 + (subc << <token> tmp); <answer> 2), 
static <token> <answer> void 
nv04_gr_set_ctx_val(struct nvkm_device *device, u32 inst, u32 <token> u32 value) <answer> mask, 
int class, op, <token> = 1; <answer> valid 
u32 <token> ctx1; <answer> tmp, 
ctx1 = nvkm_rd32(device, <token> + inst); <answer> 0x700000 
class = <token> & 0xff; <answer> ctx1 
op = <token> >> 15) & 7; <answer> (ctx1 
tmp = <token> 0x70000c + inst); <answer> nvkm_rd32(device, 
tmp &= <token> <answer> ~mask; 
<token> |= value; <answer> tmp 
nvkm_wr32(device, 0x70000c + <token> tmp); <answer> inst, 
case <token> <answer> 0x57: 
nv04_gr_set_ctx1(device, inst, 0x1000, <token> <answer> 0x1000); 
<token> true; <answer> return 
return <token> <answer> false; 
static <token> <answer> bool 
nv03_gr_mthd_gdi(struct nvkm_device *device, u32 <token> u32 mthd, u32 data) <answer> inst, 
<token> (*func)(struct nvkm_device *, u32, u32); <answer> bool 
<token> (mthd) { <answer> switch 
case 0x0184: func = <token> break; <answer> nv01_gr_mthd_bind_patt; 
case 0x0188: func <token> nv04_gr_mthd_bind_rop; break; <answer> = 
case 0x018c: func <token> nv04_gr_mthd_bind_beta1; break; <answer> = 
case 0x0190: func = <token> break; <answer> nv04_gr_mthd_bind_surf_dst; 
case 0x02fc: func = nv04_gr_mthd_set_operation; <token> <answer> break; 
return <token> <answer> false; 
return func(device, <token> data); <answer> inst, 
static <token> <answer> bool 
nv04_gr_mthd_gdi(struct nvkm_device *device, <token> inst, u32 mthd, u32 data) <answer> u32 
bool (*func)(struct nvkm_device <token> u32, u32); <answer> *, 
switch <token> { <answer> (mthd) 
case 0x0188: <token> = nv04_gr_mthd_bind_patt; break; <answer> func 
case <token> func = nv04_gr_mthd_bind_rop; break; <answer> 0x018c: 
case 0x0190: func <token> nv04_gr_mthd_bind_beta1; break; <answer> = 
case 0x0194: func = nv04_gr_mthd_bind_beta4; <token> <answer> break; 
case 0x0198: <token> = nv04_gr_mthd_bind_surf2d; break; <answer> func 
case 0x02fc: <token> = nv04_gr_mthd_set_operation; break; <answer> func 
return <token> <answer> false; 
return <token> inst, data); <answer> func(device, 
static <token> <answer> bool 
nv01_gr_mthd_blit(struct nvkm_device *device, u32 inst, u32 <token> u32 data) <answer> mthd, 
bool (*func)(struct nvkm_device <token> u32, u32); <answer> *, 
switch <token> { <answer> (mthd) 
case 0x0184: func <token> nv01_gr_mthd_bind_chroma; break; <answer> = 
<token> 0x0188: func = nv01_gr_mthd_bind_clip; break; <answer> case 
case 0x018c: func = nv01_gr_mthd_bind_patt; <token> <answer> break; 
case <token> func = nv04_gr_mthd_bind_rop; break; <answer> 0x0190: 
case 0x0194: func = nv04_gr_mthd_bind_beta1; <token> <answer> break; 
case 0x0198: func <token> nv04_gr_mthd_bind_surf_dst; break; <answer> = 
case 0x019c: func = nv04_gr_mthd_bind_surf_src; <token> <answer> break; 
case <token> func = nv04_gr_mthd_set_operation; break; <answer> 0x02fc: 
<token> false; <answer> return 
<token> func(device, inst, data); <answer> return 
static <token> <answer> bool 
nv04_gr_mthd_blit(struct nvkm_device <token> u32 inst, u32 mthd, u32 data) <answer> *device, 
<token> (*func)(struct nvkm_device *, u32, u32); <answer> bool 
switch <token> { <answer> (mthd) 
case 0x0184: func = <token> break; <answer> nv01_gr_mthd_bind_chroma; 
case 0x0188: func = nv01_gr_mthd_bind_clip; <token> <answer> break; 
case 0x018c: func = nv04_gr_mthd_bind_patt; <token> <answer> break; 
<token> 0x0190: func = nv04_gr_mthd_bind_rop; break; <answer> case 
case 0x0194: func = <token> break; <answer> nv04_gr_mthd_bind_beta1; 
case 0x0198: func = nv04_gr_mthd_bind_beta4; <token> <answer> break; 
case 0x019c: <token> = nv04_gr_mthd_bind_surf2d; break; <answer> func 
case <token> func = nv04_gr_mthd_set_operation; break; <answer> 0x02fc: 
return <token> <answer> false; 
return <token> inst, data); <answer> func(device, 
<token> bool <answer> static 
nv04_gr_mthd_iifc(struct nvkm_device *device, <token> inst, u32 mthd, u32 data) <answer> u32 
bool (*func)(struct <token> *, u32, u32); <answer> nvkm_device 
<token> (mthd) { <answer> switch 
case 0x0188: <token> = nv01_gr_mthd_bind_chroma; break; <answer> func 
case 0x018c: func <token> nv01_gr_mthd_bind_clip; break; <answer> = 
case 0x0190: func = nv04_gr_mthd_bind_patt; <token> <answer> break; 
case <token> func = nv04_gr_mthd_bind_rop; break; <answer> 0x0194: 
case 0x0198: <token> = nv04_gr_mthd_bind_beta1; break; <answer> func 
<token> 0x019c: func = nv04_gr_mthd_bind_beta4; break; <answer> case 
case 0x01a0: func = <token> break; <answer> nv04_gr_mthd_bind_surf2d_swzsurf; 
<token> 0x03e4: func = nv04_gr_mthd_set_operation; break; <answer> case 
return <token> <answer> false; 
return <token> inst, data); <answer> func(device, 
static <token> <answer> bool 
nv01_gr_mthd_ifc(struct nvkm_device <token> u32 inst, u32 mthd, u32 data) <answer> *device, 
bool (*func)(struct nvkm_device *, u32, <token> <answer> u32); 
switch (mthd) <token> <answer> { 
<token> 0x0184: func = nv01_gr_mthd_bind_chroma; break; <answer> case 
case 0x0188: <token> = nv01_gr_mthd_bind_clip; break; <answer> func 
case 0x018c: func <token> nv01_gr_mthd_bind_patt; break; <answer> = 
<token> 0x0190: func = nv04_gr_mthd_bind_rop; break; <answer> case 
case <token> func = nv04_gr_mthd_bind_beta1; break; <answer> 0x0194: 
case 0x0198: func = <token> break; <answer> nv04_gr_mthd_bind_surf_dst; 
case 0x02fc: func = nv04_gr_mthd_set_operation; <token> <answer> break; 
return <token> <answer> false; 
return func(device, <token> data); <answer> inst, 
<token> bool <answer> static 
nv04_gr_mthd_ifc(struct nvkm_device *device, u32 inst, u32 mthd, <token> data) <answer> u32 
bool (*func)(struct <token> *, u32, u32); <answer> nvkm_device 
switch (mthd) <token> <answer> { 
case <token> func = nv01_gr_mthd_bind_chroma; break; <answer> 0x0184: 
case 0x0188: func <token> nv01_gr_mthd_bind_clip; break; <answer> = 
case 0x018c: func <token> nv04_gr_mthd_bind_patt; break; <answer> = 
case <token> func = nv04_gr_mthd_bind_rop; break; <answer> 0x0190: 
case <token> func = nv04_gr_mthd_bind_beta1; break; <answer> 0x0194: 
case 0x0198: func <token> nv04_gr_mthd_bind_beta4; break; <answer> = 
case 0x019c: <token> = nv04_gr_mthd_bind_surf2d; break; <answer> func 
case 0x02fc: func <token> nv04_gr_mthd_set_operation; break; <answer> = 
<token> false; <answer> return 
<token> func(device, inst, data); <answer> return 
<token> bool <answer> static 
nv03_gr_mthd_sifc(struct nvkm_device *device, u32 inst, u32 mthd, u32 <token> <answer> data) 
bool (*func)(struct <token> *, u32, u32); <answer> nvkm_device 
<token> (mthd) { <answer> switch 
case 0x0184: func <token> nv01_gr_mthd_bind_chroma; break; <answer> = 
case <token> func = nv01_gr_mthd_bind_patt; break; <answer> 0x0188: 
case 0x018c: func = <token> break; <answer> nv04_gr_mthd_bind_rop; 
case 0x0190: func = <token> break; <answer> nv04_gr_mthd_bind_beta1; 
case 0x0194: <token> = nv04_gr_mthd_bind_surf_dst; break; <answer> func 
case 0x02fc: func = nv04_gr_mthd_set_operation; <token> <answer> break; 
<token> false; <answer> return 
<token> func(device, inst, data); <answer> return 
static <token> <answer> bool 
nv04_gr_mthd_sifc(struct nvkm_device *device, u32 <token> u32 mthd, u32 data) <answer> inst, 
bool (*func)(struct nvkm_device *, <token> u32); <answer> u32, 
<token> (mthd) { <answer> switch 
case <token> func = nv01_gr_mthd_bind_chroma; break; <answer> 0x0184: 
case 0x0188: func = nv04_gr_mthd_bind_patt; <token> <answer> break; 
case 0x018c: <token> = nv04_gr_mthd_bind_rop; break; <answer> func 
case 0x0190: func = <token> break; <answer> nv04_gr_mthd_bind_beta1; 
case 0x0194: func <token> nv04_gr_mthd_bind_beta4; break; <answer> = 
case <token> func = nv04_gr_mthd_bind_surf2d; break; <answer> 0x0198: 
<token> 0x02fc: func = nv04_gr_mthd_set_operation; break; <answer> case 
<token> false; <answer> return 
return <token> inst, data); <answer> func(device, 
static <token> <answer> bool 
<token> nvkm_device *device, u32 inst, u32 mthd, u32 data) <answer> nv03_gr_mthd_sifm(struct 
bool <token> nvkm_device *, u32, u32); <answer> (*func)(struct 
switch (mthd) <token> <answer> { 
case 0x0188: func <token> nv01_gr_mthd_bind_patt; break; <answer> = 
case 0x018c: func = <token> break; <answer> nv04_gr_mthd_bind_rop; 
case 0x0190: <token> = nv04_gr_mthd_bind_beta1; break; <answer> func 
case 0x0194: func = nv04_gr_mthd_bind_surf_dst; <token> <answer> break; 
case 0x0304: func <token> nv04_gr_mthd_set_operation; break; <answer> = 
return <token> <answer> false; 
return func(device, <token> data); <answer> inst, 
<token> bool <answer> static 
nv04_gr_mthd_sifm(struct nvkm_device *device, u32 <token> u32 mthd, u32 data) <answer> inst, 
bool (*func)(struct nvkm_device *, <token> u32); <answer> u32, 
switch (mthd) <token> <answer> { 
case 0x0188: <token> = nv04_gr_mthd_bind_patt; break; <answer> func 
case 0x018c: func <token> nv04_gr_mthd_bind_rop; break; <answer> = 
case <token> func = nv04_gr_mthd_bind_beta1; break; <answer> 0x0190: 
case <token> func = nv04_gr_mthd_bind_beta4; break; <answer> 0x0194: 
case 0x0198: func <token> nv04_gr_mthd_bind_surf2d; break; <answer> = 
case 0x0304: <token> = nv04_gr_mthd_set_operation; break; <answer> func 
<token> false; <answer> return 
<token> func(device, inst, data); <answer> return 
<token> bool <answer> static 
nv04_gr_mthd_surf3d(struct nvkm_device *device, u32 inst, u32 mthd, <token> data) <answer> u32 
bool (*func)(struct nvkm_device *, u32, <token> <answer> u32); 
switch (mthd) <token> <answer> { 
case 0x02f8: func <token> nv04_gr_mthd_surf3d_clip_h; break; <answer> = 
case 0x02fc: func = <token> break; <answer> nv04_gr_mthd_surf3d_clip_v; 
<token> false; <answer> return 
return func(device, <token> data); <answer> inst, 
<token> bool <answer> static 
nv03_gr_mthd_ttri(struct <token> *device, u32 inst, u32 mthd, u32 data) <answer> nvkm_device 
<token> (*func)(struct nvkm_device *, u32, u32); <answer> bool 
switch (mthd) <token> <answer> { 
case 0x0188: <token> = nv01_gr_mthd_bind_clip; break; <answer> func 
case 0x018c: func = nv04_gr_mthd_bind_surf_color; <token> <answer> break; 
case 0x0190: func = <token> break; <answer> nv04_gr_mthd_bind_surf_zeta; 
return <token> <answer> false; 
return <token> inst, data); <answer> func(device, 
static <token> <answer> bool 
nv01_gr_mthd_prim(struct nvkm_device *device, u32 inst, u32 mthd, u32 <token> <answer> data) 
bool <token> nvkm_device *, u32, u32); <answer> (*func)(struct 
<token> (mthd) { <answer> switch 
case 0x0184: func = nv01_gr_mthd_bind_clip; <token> <answer> break; 
case 0x0188: func <token> nv01_gr_mthd_bind_patt; break; <answer> = 
<token> 0x018c: func = nv04_gr_mthd_bind_rop; break; <answer> case 
<token> 0x0190: func = nv04_gr_mthd_bind_beta1; break; <answer> case 
case <token> func = nv04_gr_mthd_bind_surf_dst; break; <answer> 0x0194: 
case 0x02fc: func = nv04_gr_mthd_set_operation; <token> <answer> break; 
<token> false; <answer> return 
<token> func(device, inst, data); <answer> return 
static <token> <answer> bool 
nv04_gr_mthd_prim(struct nvkm_device *device, u32 inst, u32 <token> u32 data) <answer> mthd, 
<token> (*func)(struct nvkm_device *, u32, u32); <answer> bool 
switch <token> { <answer> (mthd) 
case 0x0184: func <token> nv01_gr_mthd_bind_clip; break; <answer> = 
case 0x0188: <token> = nv04_gr_mthd_bind_patt; break; <answer> func 
<token> 0x018c: func = nv04_gr_mthd_bind_rop; break; <answer> case 
case 0x0190: func = nv04_gr_mthd_bind_beta1; <token> <answer> break; 
<token> 0x0194: func = nv04_gr_mthd_bind_beta4; break; <answer> case 
case 0x0198: <token> = nv04_gr_mthd_bind_surf2d; break; <answer> func 
case <token> func = nv04_gr_mthd_set_operation; break; <answer> 0x02fc: 
return <token> <answer> false; 
return func(device, inst, <token> <answer> data); 
<token> bool <answer> static 
nv04_gr_mthd(struct nvkm_device *device, u32 inst, u32 <token> u32 data) <answer> mthd, 
bool (*func)(struct nvkm_device *, u32, <token> u32); <answer> u32, 
switch (nvkm_rd32(device, 0x700000 + <token> & 0x000000ff) { <answer> inst) 
case <token> ... 0x1e: <answer> 0x1c 
func = nv01_gr_mthd_prim; <token> <answer> break; 
case 0x1f: func = nv01_gr_mthd_blit; <token> <answer> break; 
case 0x21: func = <token> break; <answer> nv01_gr_mthd_ifc; 
case <token> func = nv03_gr_mthd_sifc; break; <answer> 0x36: 
case 0x37: func = nv03_gr_mthd_sifm; <token> <answer> break; 
case 0x48: func = nv03_gr_mthd_ttri; <token> <answer> break; 
case <token> func = nv04_gr_mthd_gdi; break; <answer> 0x4a: 
case 0x4b: func = <token> break; <answer> nv03_gr_mthd_gdi; 
case 0x53: func = nv04_gr_mthd_surf3d; <token> <answer> break; 
<token> 0x5c ... 0x5e: <answer> case 
func <token> nv04_gr_mthd_prim; break; <answer> = 
case 0x5f: func = nv04_gr_mthd_blit; <token> <answer> break; 
case <token> func = nv04_gr_mthd_iifc; break; <answer> 0x60: 
case 0x61: func <token> nv04_gr_mthd_ifc; break; <answer> = 
case 0x76: func <token> nv04_gr_mthd_sifc; break; <answer> = 
case <token> func = nv04_gr_mthd_sifm; break; <answer> 0x77: 
return <token> <answer> false; 
return func(device, inst, mthd, <token> <answer> data); 
<token> int <answer> static 
nv04_gr_object_bind(struct nvkm_object *object, <token> nvkm_gpuobj *parent, <answer> struct 
int align, <token> nvkm_gpuobj **pgpuobj) <answer> struct 
int ret = <token> 16, align, <answer> nvkm_gpuobj_new(object->engine->subdev.device, 
false, parent, <token> <answer> pgpuobj); 
if (ret == <token> { <answer> 0) 
<token> 0x00, object->oclass); <answer> nvkm_wo32(*pgpuobj, 
<token> __BIG_ENDIAN <answer> #ifdef 
nvkm_mo32(*pgpuobj, <token> 0x00080000, 0x00080000); <answer> 0x00, 
nvkm_wo32(*pgpuobj, 0x04, <token> <answer> 0x00000000); 
nvkm_wo32(*pgpuobj, <token> 0x00000000); <answer> 0x08, 
<token> 0x0c, 0x00000000); <answer> nvkm_wo32(*pgpuobj, 
<token> ret; <answer> return 
const struct <token> <answer> nvkm_object_func 
<token> = { <answer> nv04_gr_object 
.bind = <token> <answer> nv04_gr_object_bind, 
static struct nv04_gr_chan <token> <answer> * 
nv04_gr_channel(struct <token> *gr) <answer> nv04_gr 
struct nvkm_device *device = <token> <answer> gr->base.engine.subdev.device; 
struct nv04_gr_chan *chan <token> NULL; <answer> = 
if (nvkm_rd32(device, <token> & 0x00010000) { <answer> NV04_PGRAPH_CTX_CONTROL) 
<token> chid = nvkm_rd32(device, NV04_PGRAPH_CTX_USER) >> 24; <answer> int 
<token> (chid < ARRAY_SIZE(gr->chan)) <answer> if 
chan <token> gr->chan[chid]; <answer> = 
return <token> <answer> chan; 
<token> int <answer> static 
nv04_gr_load_context(struct nv04_gr_chan *chan, int <token> <answer> chid) 
struct nvkm_device *device <token> chan->gr->base.engine.subdev.device; <answer> = 
int <token> <answer> i; 
for (i = 0; i < <token> i++) <answer> ARRAY_SIZE(nv04_gr_ctx_regs); 
<token> nv04_gr_ctx_regs[i], chan->nv04[i]); <answer> nvkm_wr32(device, 
nvkm_wr32(device, <token> 0x10010100); <answer> NV04_PGRAPH_CTX_CONTROL, 
nvkm_mask(device, NV04_PGRAPH_CTX_USER, <token> chid << 24); <answer> 0xff000000, 
nvkm_mask(device, NV04_PGRAPH_FFINTFC_ST2, 0xfff00000, <token> <answer> 0x00000000); 
<token> 0; <answer> return 
<token> int <answer> static 
nv04_gr_unload_context(struct nv04_gr_chan <token> <answer> *chan) 
struct nvkm_device <token> = chan->gr->base.engine.subdev.device; <answer> *device 
<token> i; <answer> int 
<token> (i = 0; i < ARRAY_SIZE(nv04_gr_ctx_regs); i++) <answer> for 
<token> = nvkm_rd32(device, nv04_gr_ctx_regs[i]); <answer> chan->nv04[i] 
<token> NV04_PGRAPH_CTX_CONTROL, 0x10000000); <answer> nvkm_wr32(device, 
nvkm_mask(device, NV04_PGRAPH_CTX_USER, <token> 0x0f000000); <answer> 0xff000000, 
<token> 0; <answer> return 
static <token> <answer> void 
nv04_gr_context_switch(struct nv04_gr <token> <answer> *gr) 
struct nvkm_device <token> = gr->base.engine.subdev.device; <answer> *device 
struct nv04_gr_chan *prev = <token> <answer> NULL; 
<token> nv04_gr_chan *next = NULL; <answer> struct 
<token> chid; <answer> int 
<token> nvkm_gr *gr) <answer> nv04_gr_idle(struct 
struct <token> *subdev = &gr->engine.subdev; <answer> nvkm_subdev 
<token> nvkm_device *device = subdev->device; <answer> struct 
u32 mask = <token> <answer> 0xffffffff; 
<token> (device->card_type == NV_40) <answer> if 
mask &= <token> <answer> ~NV40_PGRAPH_STATUS_SYNC_STALL; 
if (nvkm_msec(device, <token> <answer> 2000, 
if <token> NV04_PGRAPH_STATUS) & mask)) <answer> (!(nvkm_rd32(device, 
) < 0) <token> <answer> { 
nvkm_error(subdev, <token> timed out with status %08x\n", <answer> "idle 
nvkm_rd32(device, <token> <answer> NV04_PGRAPH_STATUS)); 
<token> false; <answer> return 
<token> true; <answer> return 
<token> const struct nvkm_bitfield <answer> static 
<token> = { <answer> nv04_gr_intr_name[] 
{ NV_PGRAPH_INTR_NOTIFY, <token> }, <answer> "NOTIFY" 
static const <token> nvkm_bitfield <answer> struct 
nv04_gr_nstatus[] = <token> <answer> { 
<token> NV04_PGRAPH_NSTATUS_STATE_IN_USE, "STATE_IN_USE" }, <answer> { 
<token> NV04_PGRAPH_NSTATUS_INVALID_STATE, "INVALID_STATE" }, <answer> { 
<token> NV04_PGRAPH_NSTATUS_BAD_ARGUMENT, "BAD_ARGUMENT" }, <answer> { 
{ NV04_PGRAPH_NSTATUS_PROTECTION_FAULT, "PROTECTION_FAULT" <token> <answer> }, 
<token> struct nvkm_bitfield <answer> const 
<token> = { <answer> nv04_gr_nsource[] 
{ NV03_PGRAPH_NSOURCE_NOTIFICATION, <token> }, <answer> "NOTIFICATION" 
{ <token> "DATA_ERROR" }, <answer> NV03_PGRAPH_NSOURCE_DATA_ERROR, 
{ <token> "PROTECTION_ERROR" }, <answer> NV03_PGRAPH_NSOURCE_PROTECTION_ERROR, 
{ <token> "RANGE_EXCEPTION" }, <answer> NV03_PGRAPH_NSOURCE_RANGE_EXCEPTION, 
{ NV03_PGRAPH_NSOURCE_LIMIT_COLOR, <token> }, <answer> "LIMIT_COLOR" 
{ NV03_PGRAPH_NSOURCE_LIMIT_ZETA, <token> }, <answer> "LIMIT_ZETA" 
{ NV03_PGRAPH_NSOURCE_ILLEGAL_MTHD, "ILLEGAL_MTHD" <token> <answer> }, 
{ NV03_PGRAPH_NSOURCE_DMA_R_PROTECTION, "DMA_R_PROTECTION" <token> <answer> }, 
{ NV03_PGRAPH_NSOURCE_DMA_W_PROTECTION, <token> }, <answer> "DMA_W_PROTECTION" 
<token> NV03_PGRAPH_NSOURCE_FORMAT_EXCEPTION, "FORMAT_EXCEPTION" }, <answer> { 
<token> NV03_PGRAPH_NSOURCE_PATCH_EXCEPTION, "PATCH_EXCEPTION" }, <answer> { 
<token> NV03_PGRAPH_NSOURCE_STATE_INVALID, "STATE_INVALID" }, <answer> { 
{ NV03_PGRAPH_NSOURCE_DOUBLE_NOTIFY, <token> }, <answer> "DOUBLE_NOTIFY" 
{ NV03_PGRAPH_NSOURCE_NOTIFY_IN_USE, <token> }, <answer> "NOTIFY_IN_USE" 
<token> NV03_PGRAPH_NSOURCE_METHOD_CNT, "METHOD_CNT" }, <answer> { 
{ NV03_PGRAPH_NSOURCE_BFR_NOTIFICATION, "BFR_NOTIFICATION" <token> <answer> }, 
{ NV03_PGRAPH_NSOURCE_DMA_VTX_PROTECTION, "DMA_VTX_PROTECTION" <token> <answer> }, 
<token> NV03_PGRAPH_NSOURCE_DMA_WIDTH_A, "DMA_WIDTH_A" }, <answer> { 
{ <token> "DMA_WIDTH_B" }, <answer> NV03_PGRAPH_NSOURCE_DMA_WIDTH_B, 
static <token> <answer> void 
<token> nvkm_gr *base) <answer> nv04_gr_intr(struct 
struct nv04_gr <token> = nv04_gr(base); <answer> *gr 
<token> nvkm_subdev *subdev = &gr->base.engine.subdev; <answer> struct 
<token> nvkm_device *device = subdev->device; <answer> struct 
u32 stat = nvkm_rd32(device, <token> <answer> NV03_PGRAPH_INTR); 
u32 nsource <token> nvkm_rd32(device, NV03_PGRAPH_NSOURCE); <answer> = 
u32 nstatus <token> nvkm_rd32(device, NV03_PGRAPH_NSTATUS); <answer> = 
u32 addr = nvkm_rd32(device, <token> <answer> NV04_PGRAPH_TRAPPED_ADDR); 
u32 chid = (addr & 0x0f000000) <token> 24; <answer> >> 
u32 subc = <token> & 0x0000e000) >> 13; <answer> (addr 
u32 <token> = (addr & 0x00001ffc); <answer> mthd 
u32 data = <token> NV04_PGRAPH_TRAPPED_DATA); <answer> nvkm_rd32(device, 
<token> class = nvkm_rd32(device, 0x400180 + subc * 4) & 0xff; <answer> u32 
u32 inst = <token> 0x40016c) & 0xffff) << 4; <answer> (nvkm_rd32(device, 
u32 show <token> stat; <answer> = 
char <token> src[128], sta[128]; <answer> msg[128], 
struct <token> *chan; <answer> nv04_gr_chan 
<token> long flags; <answer> unsigned 
<token> flags); <answer> spin_lock_irqsave(&gr->lock, 
chan <token> gr->chan[chid]; <answer> = 
if (stat <token> NV_PGRAPH_INTR_NOTIFY) { <answer> & 
if <token> && (nsource & NV03_PGRAPH_NSOURCE_ILLEGAL_MTHD)) { <answer> (chan 
if <token> inst, mthd, data)) <answer> (!nv04_gr_mthd(device, 
<token> &= ~NV_PGRAPH_INTR_NOTIFY; <answer> show 
if (stat & <token> { <answer> NV_PGRAPH_INTR_CONTEXT_SWITCH) 
<token> NV03_PGRAPH_INTR, NV_PGRAPH_INTR_CONTEXT_SWITCH); <answer> nvkm_wr32(device, 
<token> &= ~NV_PGRAPH_INTR_CONTEXT_SWITCH; <answer> stat 
show <token> ~NV_PGRAPH_INTR_CONTEXT_SWITCH; <answer> &= 
nvkm_wr32(device, <token> stat); <answer> NV03_PGRAPH_INTR, 
<token> NV04_PGRAPH_FIFO, 0x00000001); <answer> nvkm_wr32(device, 
if (show) <token> <answer> { 
nvkm_snprintbf(msg, <token> nv04_gr_intr_name, show); <answer> sizeof(msg), 
nvkm_snprintbf(src, sizeof(src), <token> nsource); <answer> nv04_gr_nsource, 
<token> sizeof(sta), nv04_gr_nstatus, nstatus); <answer> nvkm_snprintbf(sta, 
<token> "intr %08x [%s] nsource %08x [%s] " <answer> nvkm_error(subdev, 
"nstatus %08x [%s] ch %d [%s] <token> %d " <answer> subc 
<token> %04x mthd %04x data %08x\n", <answer> "class 
show, msg, nsource, src, nstatus, sta, <token> <answer> chid, 
chan ? chan->object.client->name <token> "unknown", <answer> : 
subc, class, <token> data); <answer> mthd, 
<token> flags); <answer> spin_unlock_irqrestore(&gr->lock, 
static <token> <answer> int 
nv04_gr_init(struct <token> *base) <answer> nvkm_gr 
<token> nv04_gr *gr = nv04_gr(base); <answer> struct 
struct nvkm_device *device <token> gr->base.engine.subdev.device; <answer> = 
<token> NV04_PGRAPH_DEBUG_0, 0x1231c000); <answer> nvkm_wr32(device, 
#define pr_fmt(fmt) <token> " fmt, __func__ <answer> "%s: 
#include <token> <answer> <linux/cdev.h> 
<token> <linux/cred.h> <answer> #include 
#include <token> <answer> <linux/fs.h> 
#include <token> <answer> <linux/idr.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/tee_drv.h> 
#include <token> <answer> <linux/uaccess.h> 
#include <token> <answer> <crypto/hash.h> 
<token> <crypto/sha1.h> <answer> #include 
<token> "tee_private.h" <answer> #include 
<token> TEE_NUM_DEVICES 32 <answer> #define 
#define TEE_IOCTL_PARAM_SIZE(x) (sizeof(struct tee_param) <token> (x)) <answer> * 
<token> TEE_UUID_NS_NAME_SIZE 128 <answer> #define 
static const uuid_t tee_client_uuid_ns = UUID_INIT(0x58ac9ca0, <token> 0x4683, <answer> 0x2086, 
0xa1, 0xb8, <token> 0x4b, <answer> 0xec, 
0xc0, 0x8e, 0x01, <token> <answer> 0xb6); 
<token> DECLARE_BITMAP(dev_mask, TEE_NUM_DEVICES); <answer> static 
<token> DEFINE_SPINLOCK(driver_lock); <answer> static 
static const struct class tee_class = <token> <answer> { 
.name = <token> <answer> "tee", 
static <token> tee_devt; <answer> dev_t 
struct <token> *teedev_open(struct tee_device *teedev) <answer> tee_context 
int <token> <answer> rc; 
struct <token> *ctx; <answer> tee_context 
<token> (!tee_device_get(teedev)) <answer> if 
return <token> <answer> ERR_PTR(-EINVAL); 
ctx = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*ctx), 
if (!ctx) <token> <answer> { 
rc <token> -ENOMEM; <answer> = 
goto <token> <answer> err; 
<token> = teedev; <answer> ctx->teedev 
rc = <token> <answer> teedev->desc->ops->open(ctx); 
<token> (rc) <answer> if 
<token> err; <answer> goto 
<token> ctx; <answer> return 
return <token> <answer> ERR_PTR(rc); 
void <token> tee_context *ctx) <answer> teedev_ctx_get(struct 
if <token> <answer> (ctx->releasing) 
static void teedev_ctx_release(struct kref <token> <answer> *ref) 
struct tee_context *ctx <token> container_of(ref, struct tee_context, <answer> = 
<token> = true; <answer> ctx->releasing 
<token> teedev_ctx_put(struct tee_context *ctx) <answer> void 
if <token> <answer> (ctx->releasing) 
<token> teedev_ctx_release); <answer> kref_put(&ctx->refcount, 
void teedev_close_context(struct tee_context <token> <answer> *ctx) 
struct <token> *teedev = ctx->teedev; <answer> tee_device 
static int tee_open(struct <token> *inode, struct file *filp) <answer> inode 
<token> tee_context *ctx; <answer> struct 
ctx <token> teedev_open(container_of(inode->i_cdev, struct tee_device, cdev)); <answer> = 
<token> (IS_ERR(ctx)) <answer> if 
<token> PTR_ERR(ctx); <answer> return 
<token> = false; <answer> ctx->supp_nowait 
filp->private_data = <token> <answer> ctx; 
<token> 0; <answer> return 
static int tee_release(struct inode <token> struct file *filp) <answer> *inode, 
<token> 0; <answer> return 
static int uuid_v5(uuid_t *uuid, <token> uuid_t *ns, const void *name, <answer> const 
size_t <token> <answer> size) 
unsigned char <token> <answer> hash[SHA1_DIGEST_SIZE]; 
struct crypto_shash *shash <token> NULL; <answer> = 
struct shash_desc *desc <token> NULL; <answer> = 
int <token> <answer> rc; 
shash <token> crypto_alloc_shash("sha1", 0, 0); <answer> = 
if (IS_ERR(shash)) <token> <answer> { 
rc <token> PTR_ERR(shash); <answer> = 
pr_err("shash(sha1) <token> failed\n"); <answer> allocation 
<token> rc; <answer> return 
desc <token> kzalloc(sizeof(*desc) + crypto_shash_descsize(shash), <answer> = 
if <token> { <answer> (!desc) 
rc <token> -ENOMEM; <answer> = 
<token> out_free_shash; <answer> goto 
<token> = shash; <answer> desc->tfm 
rc <token> crypto_shash_init(desc); <answer> = 
if (rc < <token> <answer> 0) 
goto <token> <answer> out_free_desc; 
<token> = crypto_shash_update(desc, (const u8 *)ns, sizeof(*ns)); <answer> rc 
if <token> < 0) <answer> (rc 
<token> out_free_desc; <answer> goto 
rc = crypto_shash_update(desc, (const u8 *)name, <token> <answer> size); 
if (rc <token> 0) <answer> < 
goto <token> <answer> out_free_desc; 
rc = <token> hash); <answer> crypto_shash_final(desc, 
if <token> < 0) <answer> (rc 
goto <token> <answer> out_free_desc; 
memcpy(uuid->b, hash, <token> <answer> UUID_SIZE); 
name = <token> GFP_KERNEL); <answer> kzalloc(TEE_UUID_NS_NAME_SIZE, 
if <token> <answer> (!name) 
return <token> <answer> -ENOMEM; 
switch (connection_method) <token> <answer> { 
<token> TEE_IOCTL_LOGIN_USER: <answer> case 
name_len = snprintf(name, TEE_UUID_NS_NAME_SIZE, <token> <answer> "uid=%x", 
if (name_len >= <token> { <answer> TEE_UUID_NS_NAME_SIZE) 
rc <token> -E2BIG; <answer> = 
<token> out_free_name; <answer> goto 
case <token> <answer> TEE_IOCTL_LOGIN_GROUP: 
<token> connection_data, sizeof(gid_t)); <answer> memcpy(&ns_grp, 
grp = make_kgid(current_user_ns(), <token> <answer> ns_grp); 
if <token> || !in_egroup_p(grp)) { <answer> (!gid_valid(grp) 
rc = <token> <answer> -EPERM; 
<token> out_free_name; <answer> goto 
name_len = snprintf(name, <token> "gid=%x", <answer> TEE_UUID_NS_NAME_SIZE, 
if (name_len <token> TEE_UUID_NS_NAME_SIZE) { <answer> >= 
rc <token> -E2BIG; <answer> = 
goto <token> <answer> out_free_name; 
rc = <token> <answer> -EINVAL; 
<token> out_free_name; <answer> goto 
rc <token> uuid_v5(uuid, &tee_client_uuid_ns, name, name_len); <answer> = 
<token> rc; <answer> return 
static int tee_ioctl_version(struct tee_context <token> <answer> *ctx, 
struct tee_ioctl_version_data __user <token> <answer> *uvers) 
<token> tee_ioctl_version_data vers; <answer> struct 
<token> &vers); <answer> ctx->teedev->desc->ops->get_version(ctx->teedev, 
if <token> & TEE_DESC_PRIVILEGED) <answer> (ctx->teedev->desc->flags 
vers.gen_caps |= <token> <answer> TEE_GEN_CAP_PRIVILEGED; 
<token> (copy_to_user(uvers, &vers, sizeof(vers))) <answer> if 
return <token> <answer> -EFAULT; 
return <token> <answer> 0; 
static <token> tee_ioctl_shm_alloc(struct tee_context *ctx, <answer> int 
struct tee_ioctl_shm_alloc_data <token> *udata) <answer> __user 
long <token> <answer> ret; 
<token> tee_ioctl_shm_alloc_data data; <answer> struct 
struct tee_shm <token> <answer> *shm; 
if <token> udata, sizeof(data))) <answer> (copy_from_user(&data, 
<token> -EFAULT; <answer> return 
<token> ret; <answer> return 
<token> int <answer> static 
<token> tee_context *ctx, <answer> tee_ioctl_shm_register(struct 
struct <token> __user *udata) <answer> tee_ioctl_shm_register_data 
<token> ret; <answer> long 
struct tee_ioctl_shm_register_data <token> <answer> data; 
<token> tee_shm *shm; <answer> struct 
if (copy_from_user(&data, udata, <token> <answer> sizeof(data))) 
return <token> <answer> -EFAULT; 
return <token> <answer> ret; 
static int params_from_user(struct tee_context *ctx, struct tee_param <token> <answer> *params, 
<token> num_params, <answer> size_t 
<token> tee_ioctl_param __user *uparams) <answer> struct 
<token> n; <answer> size_t 
for (n <token> 0; n < num_params; n++) { <answer> = 
struct <token> *shm; <answer> tee_shm 
struct tee_ioctl_param <token> <answer> ip; 
if (copy_from_user(&ip, <token> + n, sizeof(ip))) <answer> uparams 
<token> -EFAULT; <answer> return 
if (ip.c <token> TEE_MEMREF_NULL) { <answer> != 
shm = <token> ip.c); <answer> tee_shm_get_from_id(ctx, 
if <token> <answer> (IS_ERR(shm)) 
return <token> <answer> PTR_ERR(shm); 
if ((ip.a + ip.b) <token> ip.a || <answer> < 
(ip.a + ip.b) > <token> { <answer> shm->size) 
return <token> <answer> -EINVAL; 
} else if (ctx->cap_memref_null) <token> <answer> { 
if (rc && have_session <token> ctx->teedev->desc->ops->close_session) <answer> && 
ctx->teedev->desc->ops->close_session(ctx, <token> <answer> arg.session); 
<token> (params) { <answer> if 
p->u.memref.shm <token> NULL; <answer> = 
p->u.memref.shm_offs = <token> <answer> 0; 
p->u.memref.size = <token> <answer> ip.b; 
memset(&p->u, 0, <token> <answer> sizeof(p->u)); 
<token> 0; <answer> return 
static <token> tee_ioctl_supp_send(struct tee_context *ctx, <answer> int 
struct tee_ioctl_buf_data <token> *ubuf) <answer> __user 
long <token> <answer> rc; 
struct <token> buf; <answer> tee_ioctl_buf_data 
<token> tee_iocl_supp_send_arg __user *uarg; <answer> struct 
struct <token> *params; <answer> tee_param 
u32 <token> <answer> num_params; 
<token> ret; <answer> u32 
struct <token> *tee_device_alloc(const struct tee_desc *teedesc, <answer> tee_device 
struct device <token> <answer> *dev, 
struct tee_shm_pool <token> <answer> *pool, 
<token> *driver_data) <answer> void 
struct tee_device <token> <answer> *teedev; 
void <token> <answer> *ret; 
int <token> max_id; <answer> rc, 
int offs = <token> <answer> 0; 
<token> (!teedesc || !teedesc->name || !teedesc->ops || <answer> if 
<token> || !teedesc->ops->open || <answer> !teedesc->ops->get_version 
!teedesc->ops->release || <token> <answer> !pool) 
return <token> <answer> ERR_PTR(-EINVAL); 
<token> = kzalloc(sizeof(*teedev), GFP_KERNEL); <answer> teedev 
if <token> { <answer> (!teedev) 
ret = <token> <answer> ERR_PTR(-ENOMEM); 
goto <token> <answer> err; 
max_id <token> TEE_NUM_DEVICES / 2; <answer> = 
if (teedesc->flags & TEE_DESC_PRIVILEGED) <token> <answer> { 
offs = TEE_NUM_DEVICES <token> 2; <answer> / 
max_id = <token> <answer> TEE_NUM_DEVICES; 
teedev->id = find_next_zero_bit(dev_mask, <token> offs); <answer> max_id, 
if (teedev->id < <token> <answer> max_id) 
set_bit(teedev->id, <token> <answer> dev_mask); 
if (teedev->id >= <token> { <answer> max_id) 
ret <token> ERR_PTR(-ENOMEM); <answer> = 
<token> err; <answer> goto 
snprintf(teedev->name, sizeof(teedev->name), <token> <answer> "tee%s%d", 
<token> & TEE_DESC_PRIVILEGED ? "priv" : "", <answer> teedesc->flags 
<token> - offs); <answer> teedev->id 
<token> = &tee_class; <answer> teedev->dev.class 
teedev->dev.release = <token> <answer> tee_release_device; 
teedev->dev.parent <token> dev; <answer> = 
teedev->dev.devt = MKDEV(MAJOR(tee_devt), <token> <answer> teedev->id); 
rc = dev_set_name(&teedev->dev, "%s", <token> <answer> teedev->name); 
if <token> { <answer> (rc) 
ret = <token> <answer> ERR_PTR(rc); 
goto <token> <answer> err_devt; 
cdev_init(&teedev->cdev, <token> <answer> &tee_fops); 
<token> = teedesc->owner; <answer> teedev->cdev.owner 
<token> driver_data); <answer> dev_set_drvdata(&teedev->dev, 
<token> tee_device_register(struct tee_device *teedev) <answer> int 
<token> rc; <answer> int 
<token> (teedev->flags & TEE_DEVICE_FLAG_REGISTERED) { <answer> if 
<token> "attempt to register twice\n"); <answer> dev_err(&teedev->dev, 
<token> -EINVAL; <answer> return 
teedev->dev.groups <token> tee_dev_groups; <answer> = 
rc = cdev_device_add(&teedev->cdev, <token> <answer> &teedev->dev); 
if (rc) <token> <answer> { 
"unable to cdev_device_add() <token> major %d, minor %d, err=%d\n", <answer> %s, 
teedev->name, <token> <answer> MAJOR(teedev->dev.devt), 
MINOR(teedev->dev.devt), <token> <answer> rc); 
return <token> <answer> rc; 
<token> |= TEE_DEVICE_FLAG_REGISTERED; <answer> teedev->flags 
<token> 0; <answer> return 
void tee_device_put(struct <token> *teedev) <answer> tee_device 
void tee_device_unregister(struct <token> *teedev) <answer> tee_device 
<token> (!teedev) <answer> if 
if <token> & TEE_DEVICE_FLAG_REGISTERED) <answer> (teedev->flags 
<token> &teedev->dev); <answer> cdev_device_del(&teedev->cdev, 
<token> = NULL; <answer> teedev->pool 
void *tee_get_drvdata(struct <token> *teedev) <answer> tee_device 
<token> dev_get_drvdata(&teedev->dev); <answer> return 
<token> match_dev_data { <answer> struct 
struct tee_ioctl_version_data <token> <answer> *vers; 
const void <token> <answer> *data; 
<token> (*match)(struct tee_ioctl_version_data *, const void *); <answer> int 
static int match_dev(struct device *dev, <token> void *data) <answer> const 
<token> struct match_dev_data *match_data = data; <answer> const 
struct tee_device *teedev = <token> struct tee_device, dev); <answer> container_of(dev, 
<token> match_data->vers); <answer> teedev->desc->ops->get_version(teedev, 
return match_data->match(match_data->vers, <token> <answer> match_data->data); 
struct <token> * <answer> tee_context 
<token> tee_context *start, <answer> tee_client_open_context(struct 
<token> (*match)(struct tee_ioctl_version_data *, <answer> int 
<token> void *), <answer> const 
const void <token> struct tee_ioctl_version_data *vers) <answer> *data, 
struct <token> *dev = NULL; <answer> device 
struct <token> *put_dev = NULL; <answer> device 
struct tee_context *ctx <token> NULL; <answer> = 
struct tee_ioctl_version_data <token> <answer> v; 
struct <token> match_data = { vers ? vers : &v, data, match }; <answer> match_dev_data 
<token> (start) <answer> if 
<token> = &start->teedev->dev; <answer> dev 
do <token> <answer> { 
dev = class_find_device(&tee_class, dev, &match_data, <token> <answer> match_dev); 
if <token> { <answer> (!dev) 
ctx = <token> <answer> ERR_PTR(-ENOENT); 
put_dev = <token> <answer> dev; 
ctx = teedev_open(container_of(dev, struct <token> dev)); <answer> tee_device, 
<token> while (IS_ERR(ctx) && PTR_ERR(ctx) != -ENOMEM); <answer> } 
<token> (!IS_ERR(ctx)) <answer> if 
ctx->supp_nowait <token> true; <answer> = 
<token> ctx; <answer> return 
void <token> tee_context *ctx) <answer> tee_client_close_context(struct 
void tee_client_get_version(struct <token> *ctx, <answer> tee_context 
<token> tee_ioctl_version_data *vers) <answer> struct 
<token> vers); <answer> ctx->teedev->desc->ops->get_version(ctx->teedev, 
<token> tee_client_open_session(struct tee_context *ctx, <answer> int 
<token> tee_ioctl_open_session_arg *arg, <answer> struct 
struct <token> *param) <answer> tee_param 
if <token> <answer> (!ctx->teedev->desc->ops->open_session) 
<token> -EINVAL; <answer> return 
<token> ctx->teedev->desc->ops->open_session(ctx, arg, param); <answer> return 
int tee_client_close_session(struct <token> *ctx, u32 session) <answer> tee_context 
<token> (!ctx->teedev->desc->ops->close_session) <answer> if 
return <token> <answer> -EINVAL; 
return <token> session); <answer> ctx->teedev->desc->ops->close_session(ctx, 
int <token> tee_context *ctx, u32 session) <answer> tee_client_system_session(struct 
if <token> <answer> (!ctx->teedev->desc->ops->system_session) 
return <token> <answer> -EINVAL; 
return <token> session); <answer> ctx->teedev->desc->ops->system_session(ctx, 
int <token> tee_context *ctx, <answer> tee_client_invoke_func(struct 
struct <token> *arg, <answer> tee_ioctl_invoke_arg 
<token> tee_param *param) <answer> struct 
if <token> <answer> (!ctx->teedev->desc->ops->invoke_func) 
<token> -EINVAL; <answer> return 
<token> ctx->teedev->desc->ops->invoke_func(ctx, arg, param); <answer> return 
<token> tee_client_cancel_req(struct tee_context *ctx, <answer> int 
<token> tee_ioctl_cancel_arg *arg) <answer> struct 
<token> (!ctx->teedev->desc->ops->cancel_req) <answer> if 
<token> -EINVAL; <answer> return 
<token> ctx->teedev->desc->ops->cancel_req(ctx, arg->cancel_id, <answer> return 
static int tee_client_device_match(struct device <token> <answer> *dev, 
struct device_driver <token> <answer> *drv) 
const <token> tee_client_device_id *id_table; <answer> struct 
struct <token> *tee_device; <answer> tee_client_device 
id_table = <token> <answer> to_tee_client_driver(drv)->id_table; 
tee_device = <token> <answer> to_tee_client_device(dev); 
<token> (!uuid_is_null(&id_table->uuid)) { <answer> while 
<token> (uuid_equal(&tee_device->id.uuid, &id_table->uuid)) <answer> if 
return <token> <answer> 1; 
return <token> <answer> 0; 
static int tee_client_device_uevent(const struct device <token> <answer> *dev, 
struct <token> *env) <answer> kobj_uevent_env 
<token> *dev_id = &to_tee_client_device(dev)->id.uuid; <answer> uuid_t 
<token> add_uevent_var(env, "MODALIAS=tee:%pUb", dev_id); <answer> return 
const struct bus_type tee_bus_type = <token> <answer> { 
<token> = "tee", <answer> .name 
.match = <token> <answer> tee_client_device_match, 
<token> = tee_client_device_uevent, <answer> .uevent 
static int __init <token> <answer> tee_init(void) 
<token> rc; <answer> int 
rc <token> class_register(&tee_class); <answer> = 
<token> (rc) { <answer> if 
pr_err("couldn't create <token> <answer> class\n"); 
return <token> <answer> rc; 
rc = alloc_chrdev_region(&tee_devt, <token> TEE_NUM_DEVICES, "tee"); <answer> 0, 
if (rc) <token> <answer> { 
pr_err("failed to allocate <token> dev region\n"); <answer> char 
<token> out_unreg_class; <answer> goto 
rc = <token> <answer> bus_register(&tee_bus_type); 
<token> (rc) { <answer> if 
pr_err("failed to <token> tee bus\n"); <answer> register 
<token> out_unreg_chrdev; <answer> goto 
<token> 0; <answer> return 
unregister_chrdev_region(tee_devt, <token> <answer> TEE_NUM_DEVICES); 
<token> rc; <answer> return 
static void <token> tee_exit(void) <answer> __exit 
unregister_chrdev_region(tee_devt, <token> <answer> TEE_NUM_DEVICES); 
<token> Driver"); <answer> MODULE_DESCRIPTION("TEE 
MODULE_LICENSE("GPL <token> <answer> v2"); 
<token> <linux/clk.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/dmaengine.h> 
<token> <linux/dma-mapping.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/of.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/pinctrl/consumer.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
<token> <linux/spi/spi.h> <answer> #include 
#include <token> <answer> <linux/spi/spi-fsl-dspi.h> 
#define DRIVER_NAME <token> <answer> "fsl-dspi" 
#define <token> 0x00 <answer> SPI_MCR 
<token> SPI_MCR_HOST BIT(31) <answer> #define 
#define SPI_MCR_PCSIS(x) ((x) << <token> <answer> 16) 
<token> SPI_MCR_CLR_TXF BIT(11) <answer> #define 
#define <token> BIT(10) <answer> SPI_MCR_CLR_RXF 
<token> SPI_MCR_XSPI BIT(3) <answer> #define 
<token> SPI_MCR_DIS_TXF BIT(13) <answer> #define 
#define SPI_MCR_DIS_RXF <token> <answer> BIT(12) 
#define SPI_MCR_HALT <token> <answer> BIT(0) 
#define <token> 0x08 <answer> SPI_TCR 
#define SPI_TCR_GET_TCNT(x) <token> & GENMASK(31, 16)) >> 16) <answer> (((x) 
#define SPI_CTAR(x) (0x0c + (((x) & GENMASK(1, <token> * 4)) <answer> 0)) 
#define <token> (((x) << 27) & GENMASK(30, 27)) <answer> SPI_CTAR_FMSZ(x) 
#define <token> BIT(26) <answer> SPI_CTAR_CPOL 
#define <token> BIT(25) <answer> SPI_CTAR_CPHA 
#define SPI_CTAR_LSBFE <token> <answer> BIT(24) 
#define <token> (((x) << 22) & GENMASK(23, 22)) <answer> SPI_CTAR_PCSSCK(x) 
#define SPI_CTAR_PASC(x) (((x) <token> 20) & GENMASK(21, 20)) <answer> << 
#define SPI_CTAR_PDT(x) (((x) << 18) & <token> 18)) <answer> GENMASK(19, 
#define SPI_CTAR_PBR(x) (((x) << 16) <token> GENMASK(17, 16)) <answer> & 
#define <token> (((x) << 12) & GENMASK(15, 12)) <answer> SPI_CTAR_CSSCK(x) 
#define SPI_CTAR_ASC(x) (((x) << 8) & <token> 8)) <answer> GENMASK(11, 
#define SPI_CTAR_DT(x) (((x) << 4) & <token> 4)) <answer> GENMASK(7, 
#define SPI_CTAR_BR(x) ((x) <token> GENMASK(3, 0)) <answer> & 
#define <token> 0xf <answer> SPI_CTAR_SCALE_BITS 
#define <token> 0x0c <answer> SPI_CTAR0_SLAVE 
#define <token> 0x2c <answer> SPI_SR 
#define SPI_SR_TCFQF <token> <answer> BIT(31) 
<token> SPI_SR_TFUF BIT(27) <answer> #define 
#define SPI_SR_TFFF <token> <answer> BIT(25) 
#define SPI_SR_CMDTCF <token> <answer> BIT(23) 
#define SPI_SR_SPEF <token> <answer> BIT(21) 
<token> SPI_SR_RFOF BIT(19) <answer> #define 
#define SPI_SR_TFIWF <token> <answer> BIT(18) 
<token> SPI_SR_RFDF BIT(17) <answer> #define 
#define <token> BIT(16) <answer> SPI_SR_CMDFFF 
#define SPI_SR_CLEAR (SPI_SR_TCFQF <token> \ <answer> | 
SPI_SR_TFUF <token> SPI_SR_TFFF | \ <answer> | 
SPI_SR_CMDTCF | SPI_SR_SPEF <token> \ <answer> | 
SPI_SR_RFOF | SPI_SR_TFIWF | <token> <answer> \ 
SPI_SR_RFDF <token> SPI_SR_CMDFFF) <answer> | 
<token> SPI_RSER_TFFFE BIT(25) <answer> #define 
#define <token> BIT(24) <answer> SPI_RSER_TFFFD 
#define SPI_RSER_RFDFE <token> <answer> BIT(17) 
<token> SPI_RSER_RFDFD BIT(16) <answer> #define 
<token> SPI_RSER 0x30 <answer> #define 
<token> SPI_RSER_TCFQE BIT(31) <answer> #define 
<token> SPI_RSER_CMDTCFE BIT(23) <answer> #define 
<token> SPI_PUSHR 0x34 <answer> #define 
#define <token> BIT(15) <answer> SPI_PUSHR_CMD_CONT 
#define SPI_PUSHR_CMD_CTAS(x) (((x) << 12 & <token> 12))) <answer> GENMASK(14, 
#define <token> BIT(11) <answer> SPI_PUSHR_CMD_EOQ 
#define <token> BIT(10) <answer> SPI_PUSHR_CMD_CTCNT 
#define SPI_PUSHR_CMD_PCS(x) <token> & GENMASK(5, 0)) <answer> (BIT(x) 
#define <token> 0x34 <answer> SPI_PUSHR_SLAVE 
#define SPI_POPR <token> <answer> 0x38 
#define SPI_TXFR0 <token> <answer> 0x3c 
#define <token> 0x40 <answer> SPI_TXFR1 
<token> SPI_TXFR2 0x44 <answer> #define 
#define <token> 0x48 <answer> SPI_TXFR3 
#define SPI_RXFR0 <token> <answer> 0x7c 
<token> SPI_RXFR1 0x80 <answer> #define 
#define SPI_RXFR2 <token> <answer> 0x84 
<token> SPI_RXFR3 0x88 <answer> #define 
<token> SPI_CTARE(x) (0x11c + (((x) & GENMASK(1, 0)) * 4)) <answer> #define 
<token> SPI_CTARE_FMSZE(x) (((x) & 0x1) << 16) <answer> #define 
#define SPI_CTARE_DTCP(x) <token> & 0x7ff) <answer> ((x) 
#define SPI_SREX <token> <answer> 0x13c 
#define SPI_FRAME_BITS(bits) SPI_CTAR_FMSZ((bits) <token> 1) <answer> - 
#define SPI_FRAME_EBITS(bits) <token> - 1) >> 4) <answer> SPI_CTARE_FMSZE(((bits) 
#define DMA_COMPLETION_TIMEOUT <token> <answer> msecs_to_jiffies(3000) 
struct <token> { <answer> chip_data 
u32 <token> <answer> ctar_val; 
<token> dspi_trans_mode { <answer> enum 
struct <token> { <answer> fsl_dspi_devtype_data 
<token> dspi_trans_mode trans_mode; <answer> enum 
<token> max_clock_factor; <answer> u8 
<token> fifo_size; <answer> int 
enum <token> <answer> { 
static const struct <token> devtype_data[] = { <answer> fsl_dspi_devtype_data 
[VF610] = <token> <answer> { 
.trans_mode = <token> <answer> DSPI_DMA_MODE, 
.max_clock_factor <token> 2, <answer> = 
.fifo_size <token> 4, <answer> = 
<token> = { <answer> [LS1021A] 
<token> pushr_cmd; <answer> int 
<token> pushr_tx; <answer> int 
void (*host_to_dev)(struct fsl_dspi *dspi, u32 <token> <answer> *txdata); 
void (*dev_to_host)(struct <token> *dspi, u32 rxdata); <answer> fsl_dspi 
static <token> dspi_native_host_to_dev(struct fsl_dspi *dspi, u32 *txdata) <answer> void 
switch <token> { <answer> (dspi->oper_word_size) 
<token> 1: <answer> case 
*txdata = *(u8 <token> <answer> *)dspi->tx; 
case <token> <answer> 2: 
*txdata = *(u16 <token> <answer> *)dspi->tx; 
<token> 4: <answer> case 
*txdata = *(u32 <token> <answer> *)dspi->tx; 
dspi->tx += <token> <answer> dspi->oper_word_size; 
static void dspi_native_dev_to_host(struct fsl_dspi *dspi, u32 <token> <answer> rxdata) 
switch <token> { <answer> (dspi->oper_word_size) 
<token> 1: <answer> case 
*(u8 *)dspi->rx = <token> <answer> rxdata; 
<token> 2: <answer> case 
*(u16 *)dspi->rx <token> rxdata; <answer> = 
case <token> <answer> 4: 
<token> *)dspi->rx = rxdata; <answer> *(u32 
dspi->rx += <token> <answer> dspi->oper_word_size; 
static void dspi_8on32_host_to_dev(struct fsl_dspi *dspi, u32 <token> <answer> *txdata) 
*txdata <token> cpu_to_be32(*(u32 *)dspi->tx); <answer> = 
dspi->tx <token> sizeof(u32); <answer> += 
static void dspi_8on32_dev_to_host(struct <token> *dspi, u32 rxdata) <answer> fsl_dspi 
<token> *)dspi->rx = be32_to_cpu(rxdata); <answer> *(u32 
dspi->rx <token> sizeof(u32); <answer> += 
static <token> dspi_8on16_host_to_dev(struct fsl_dspi *dspi, u32 *txdata) <answer> void 
*txdata = <token> *)dspi->tx); <answer> cpu_to_be16(*(u16 
dspi->tx += <token> <answer> sizeof(u16); 
static void dspi_8on16_dev_to_host(struct <token> *dspi, u32 rxdata) <answer> fsl_dspi 
*(u16 <token> = be16_to_cpu(rxdata); <answer> *)dspi->rx 
dspi->rx += <token> <answer> sizeof(u16); 
static void dspi_16on32_host_to_dev(struct fsl_dspi *dspi, <token> *txdata) <answer> u32 
u16 hi = *(u16 <token> <answer> *)dspi->tx; 
u16 lo = <token> *)(dspi->tx + 2); <answer> *(u16 
*txdata = (u32)hi <token> 16 | lo; <answer> << 
dspi->tx += <token> <answer> sizeof(u32); 
static void dspi_16on32_dev_to_host(struct fsl_dspi <token> u32 rxdata) <answer> *dspi, 
u16 hi <token> rxdata & 0xffff; <answer> = 
u16 <token> = rxdata >> 16; <answer> lo 
*(u16 *)dspi->rx = <token> <answer> lo; 
*(u16 *)(dspi->rx + <token> = hi; <answer> 2) 
<token> += sizeof(u32); <answer> dspi->rx 
static u32 dspi_pop_tx(struct fsl_dspi <token> <answer> *dspi) 
u32 <token> = 0; <answer> txdata 
if <token> <answer> (dspi->tx) 
dspi->host_to_dev(dspi, <token> <answer> &txdata); 
dspi->len <token> dspi->oper_word_size; <answer> -= 
<token> txdata; <answer> return 
while <token> { <answer> (dspi->len) 
if <token> > dspi->oper_word_size) <answer> (dspi->len 
cmd |= <token> <answer> SPI_PUSHR_CMD_CONT; 
regmap_write(dspi->regmap_pushr, dspi->pushr_cmd, <token> <answer> cmd); 
static void dspi_pushr_txdata_write(struct fsl_dspi *dspi, u16 <token> <answer> txdata) 
<token> dspi->pushr_tx, txdata); <answer> regmap_write(dspi->regmap_pushr, 
<token> void dspi_xspi_fifo_write(struct fsl_dspi *dspi, int num_words) <answer> static 
int num_bytes = num_words * <token> <answer> dspi->oper_word_size; 
u16 tx_cmd = <token> <answer> dspi->tx_cmd; 
if (!(dspi->tx_cmd & SPI_PUSHR_CMD_CONT) && num_bytes == <token> <answer> dspi->len) 
<token> |= SPI_PUSHR_CMD_EOQ; <answer> tx_cmd 
<token> tx_cmd); <answer> dspi_pushr_cmd_write(dspi, 
do <token> <answer> { 
if (dspi->len >= <token> 8)) <answer> DIV_ROUND_UP(dspi->oper_bits_per_word, 
dspi->oper_bits_per_word <token> 2; <answer> /= 
} <token> (dspi->oper_bits_per_word > 8); <answer> while 
if (xfer->bits_per_word == 8 <token> dspi->oper_bits_per_word == 32) { <answer> && 
dspi->dev_to_host <token> dspi_8on32_dev_to_host; <answer> = 
dspi->host_to_dev <token> dspi_8on32_host_to_dev; <answer> = 
} else if <token> == 8 && dspi->oper_bits_per_word == 16) { <answer> (xfer->bits_per_word 
dspi->dev_to_host = <token> <answer> dspi_8on16_dev_to_host; 
dspi->host_to_dev = <token> <answer> dspi_8on16_host_to_dev; 
} else if (xfer->bits_per_word == 16 && dspi->oper_bits_per_word == 32) <token> <answer> { 
dspi->dev_to_host <token> dspi_16on32_dev_to_host; <answer> = 
dspi->host_to_dev <token> dspi_16on32_host_to_dev; <answer> = 
<token> else { <answer> } 
<token> = dspi_native_dev_to_host; <answer> dspi->dev_to_host 
dspi->host_to_dev = <token> <answer> dspi_native_host_to_dev; 
dspi->oper_bits_per_word <token> xfer->bits_per_word; <answer> = 
dspi->oper_word_size = DIV_ROUND_UP(dspi->oper_bits_per_word, <token> <answer> 8); 
<token> SPI_CTAR(0), <answer> regmap_write(dspi->regmap, 
<token> | <answer> dspi->cur_chip->ctar_val 
static void <token> fsl_dspi *dspi) <answer> dspi_fifo_write(struct 
<token> num_fifo_entries = dspi->devtype_data->fifo_size; <answer> int 
struct spi_transfer *xfer = <token> <answer> dspi->cur_transfer; 
<token> spi_message *msg = dspi->cur_msg; <answer> struct 
<token> num_words, num_bytes; <answer> int 
num_words = <token> / dspi->oper_word_size; <answer> dspi->len 
<token> (num_words > num_fifo_entries) <answer> if 
<token> = num_fifo_entries; <answer> num_words 
dspi->words_in_flight = <token> <answer> num_words; 
spi_take_timestamp_pre(dspi->ctlr, <token> dspi->progress, !dspi->irq); <answer> xfer, 
<token> num_words); <answer> dspi_xspi_fifo_write(dspi, 
<token> dspi->cur_transfer, <answer> spi_take_timestamp_post(dspi->ctlr, 
dspi->progress, <token> <answer> !dspi->irq); 
static int dspi_rxtx(struct fsl_dspi <token> <answer> *dspi) 
if <token> <answer> (!dspi->len) 
<token> (transfer->cs_change) <answer> if 
<token> |= SPI_PUSHR_CMD_CONT; <answer> dspi->tx_cmd 
<token> else { <answer> } 
<token> (!transfer->cs_change) <answer> if 
<token> |= SPI_PUSHR_CMD_CONT; <answer> dspi->tx_cmd 
dspi->tx = <token> <answer> transfer->tx_buf; 
dspi->rx <token> transfer->rx_buf; <answer> = 
<token> = transfer->len; <answer> dspi->len 
<token> = 0; <answer> dspi->progress 
regmap_update_bits(dspi->regmap, <token> <answer> SPI_MCR, 
<token> | SPI_MCR_CLR_RXF, <answer> SPI_MCR_CLR_TXF 
SPI_MCR_CLR_TXF | <token> <answer> SPI_MCR_CLR_RXF); 
spi_take_timestamp_pre(dspi->ctlr, <token> <answer> dspi->cur_transfer, 
<token> !dspi->irq); <answer> dspi->progress, 
if (dspi->devtype_data->trans_mode == DSPI_DMA_MODE) <token> <answer> { 
status = <token> <answer> dspi_dma_xfer(dspi); 
} <token> { <answer> else 
<token> (dspi->irq) { <answer> if 
} <token> { <answer> else 
do <token> <answer> { 
status = <token> <answer> dspi_poll(dspi); 
} <token> (status == -EINPROGRESS); <answer> while 
if <token> <answer> (status) 
if (!(dspi->tx_cmd & <token> <answer> SPI_PUSHR_CMD_CONT)) 
<token> &cs); <answer> dspi_deassert_cs(spi, 
message->status = <token> <answer> status; 
return <token> <answer> status; 
static int <token> spi_device *spi) <answer> dspi_setup(struct 
<token> fsl_dspi *dspi = spi_controller_get_devdata(spi->controller); <answer> struct 
u32 period_ns = DIV_ROUND_UP(NSEC_PER_SEC, <token> <answer> spi->max_speed_hz); 
unsigned char br = 0, pbr = 0, pcssck = <token> cssck = 0; <answer> 0, 
u32 quarter_period_ns <token> DIV_ROUND_UP(period_ns, 4); <answer> = 
<token> cs_sck_delay = 0, sck_cs_delay = 0; <answer> u32 
<token> fsl_dspi_platform_data *pdata; <answer> struct 
unsigned <token> pasc = 0, asc = 0; <answer> char 
struct <token> *chip; <answer> chip_data 
unsigned long <token> <answer> clkrate; 
bool <token> = true; <answer> cs 
<token> (cs_sck_delay < quarter_period_ns) <answer> if 
cs_sck_delay <token> quarter_period_ns; <answer> = 
if <token> < quarter_period_ns) <answer> (sck_cs_delay 
sck_cs_delay = <token> <answer> quarter_period_ns; 
"DSPI controller timing params: CS-to-SCK delay <token> ns, SCK-to-CS delay %u ns\n", <answer> %u 
cs_sck_delay, <token> <answer> sck_cs_delay); 
<token> = clk_get_rate(dspi->clk); <answer> clkrate 
hz_to_spi_baud(&pbr, &br, <token> clkrate); <answer> spi->max_speed_hz, 
if (dspi->devtype_data->trans_mode == DSPI_DMA_MODE) <token> <answer> { 
<token> <linux/device.h> <answer> #include 
<token> <linux/dma-mapping.h> <answer> #include 
#include <token> <answer> <kunit/test.h> 
<token> <kunit/device.h> <answer> #include 
#include <token> <answer> <kunit/resource.h> 
#include <token> <answer> "device-impl.h" 
struct device_driver *kunit_driver_create(struct kunit *test, const <token> *name) <answer> char 
struct <token> *driver; <answer> device_driver 
int <token> = -ENOMEM; <answer> err 
driver = <token> sizeof(*driver), GFP_KERNEL); <answer> kunit_kzalloc(test, 
<token> (!driver) <answer> if 
<token> ERR_PTR(err); <answer> return 
<token> = name; <answer> driver->name 
driver->bus <token> &kunit_bus_type; <answer> = 
<token> = THIS_MODULE; <answer> driver->owner 
<token> = driver_register(driver); <answer> err 
if (err) <token> <answer> { 
kunit_kfree(test, <token> <answer> driver); 
return <token> <answer> ERR_PTR(err); 
<token> driver_unregister_wrapper, driver); <answer> kunit_add_action(test, 
return <token> <answer> driver; 
struct <token> *kunit_device_register_with_driver(struct kunit *test, <answer> device 
const <token> *name, <answer> char 
const <token> device_driver *drv) <answer> struct 
struct kunit_device *kunit_dev <token> kunit_device_register_internal(test, name, drv); <answer> = 
if <token> <answer> (IS_ERR_OR_NULL(kunit_dev)) 
return <token> <answer> ERR_CAST(kunit_dev); 
return <token> <answer> &kunit_dev->dev; 
struct device *kunit_device_register(struct kunit <token> const char *name) <answer> *test, 
struct <token> *drv; <answer> device_driver 
struct <token> *dev; <answer> kunit_device 
drv = kunit_driver_create(test, <token> <answer> name); 
if <token> <answer> (IS_ERR(drv)) 
return <token> <answer> ERR_CAST(drv); 
dev = kunit_device_register_internal(test, <token> drv); <answer> name, 
if (IS_ERR(dev)) <token> <answer> { 
kunit_release_action(test, driver_unregister_wrapper, <token> *)drv); <answer> (void 
return <token> <answer> ERR_CAST(dev); 
#include <token> <answer> <linux/dma-buf.h> 
#include <token> <answer> <drm/drm.h> 
<token> <drm/drm_device.h> <answer> #include 
#include <token> <answer> <drm/drm_gem.h> 
<token> <drm/drm_gem_dma_helper.h> <answer> #include 
#include <token> <answer> <drm/drm_prime.h> 
#include <token> <answer> "mtk_drm_drv.h" 
<token> "mtk_drm_gem.h" <answer> #include 
static int <token> drm_gem_object *obj, struct vm_area_struct *vma); <answer> mtk_drm_gem_object_mmap(struct 
static const <token> vm_operations_struct vm_ops = { <answer> struct 
.open = <token> <answer> drm_gem_vm_open, 
<token> = drm_gem_vm_close, <answer> .close 
<token> const struct drm_gem_object_funcs mtk_drm_gem_object_funcs = { <answer> static 
<token> = mtk_drm_gem_free_object, <answer> .free 
<token> = mtk_gem_prime_get_sg_table, <answer> .get_sg_table 
.vmap <token> mtk_drm_gem_prime_vmap, <answer> = 
<token> = mtk_drm_gem_prime_vunmap, <answer> .vunmap 
.mmap = <token> <answer> mtk_drm_gem_object_mmap, 
<token> = &vm_ops, <answer> .vm_ops 
static struct mtk_drm_gem_obj *mtk_drm_gem_init(struct drm_device <token> <answer> *dev, 
unsigned <token> size) <answer> long 
struct <token> *mtk_gem_obj; <answer> mtk_drm_gem_obj 
<token> ret; <answer> int 
size <token> round_up(size, PAGE_SIZE); <answer> = 
mtk_gem_obj = kzalloc(sizeof(*mtk_gem_obj), <token> <answer> GFP_KERNEL); 
<token> (!mtk_gem_obj) <answer> if 
<token> ERR_PTR(-ENOMEM); <answer> return 
<token> = &mtk_drm_gem_object_funcs; <answer> mtk_gem_obj->base.funcs 
ret <token> drm_gem_object_init(dev, &mtk_gem_obj->base, size); <answer> = 
if (ret <token> 0) { <answer> < 
DRM_ERROR("failed to <token> gem object\n"); <answer> initialize 
<token> ERR_PTR(ret); <answer> return 
return <token> <answer> mtk_gem_obj; 
<token> mtk_drm_gem_obj *mtk_drm_gem_create(struct drm_device *dev, <answer> struct 
size_t size, bool <token> <answer> alloc_kmap) 
<token> mtk_drm_private *priv = dev->dev_private; <answer> struct 
struct <token> *mtk_gem; <answer> mtk_drm_gem_obj 
struct <token> *obj; <answer> drm_gem_object 
int <token> <answer> ret; 
mtk_gem = <token> size); <answer> mtk_drm_gem_init(dev, 
<token> (IS_ERR(mtk_gem)) <answer> if 
<token> ERR_CAST(mtk_gem); <answer> return 
<token> = &mtk_gem->base; <answer> obj 
mtk_gem->dma_attrs = <token> <answer> DMA_ATTR_WRITE_COMBINE; 
if <token> <answer> (!alloc_kmap) 
mtk_gem->dma_attrs |= <token> <answer> DMA_ATTR_NO_KERNEL_MAPPING; 
mtk_gem->cookie <token> dma_alloc_attrs(priv->dma_dev, obj->size, <answer> = 
<token> GFP_KERNEL, <answer> &mtk_gem->dma_addr, 
<token> (!mtk_gem->cookie) { <answer> if 
DRM_ERROR("failed to allocate <token> byte dma buffer", obj->size); <answer> %zx 
ret = <token> <answer> -ENOMEM; 
<token> err_gem_free; <answer> goto 
if <token> <answer> (alloc_kmap) 
mtk_gem->kvaddr = <token> <answer> mtk_gem->cookie; 
DRM_DEBUG_DRIVER("cookie = <token> dma_addr = %pad size = %zu\n", <answer> %p 
mtk_gem->cookie, <token> <answer> &mtk_gem->dma_addr, 
return <token> <answer> mtk_gem; 
<token> ERR_PTR(ret); <answer> return 
void mtk_drm_gem_free_object(struct drm_gem_object <token> <answer> *obj) 
<token> mtk_drm_gem_obj *mtk_gem = to_mtk_gem_obj(obj); <answer> struct 
<token> mtk_drm_private *priv = obj->dev->dev_private; <answer> struct 
<token> (mtk_gem->sg) <answer> if 
<token> mtk_gem->sg); <answer> drm_prime_gem_destroy(obj, 
dma_free_attrs(priv->dma_dev, obj->size, <token> <answer> mtk_gem->cookie, 
<token> mtk_gem->dma_attrs); <answer> mtk_gem->dma_addr, 
args->size <token> args->pitch; <answer> = 
args->size *= <token> <answer> args->height; 
mtk_gem = <token> args->size, false); <answer> mtk_drm_gem_create(dev, 
if <token> <answer> (IS_ERR(mtk_gem)) 
return <token> <answer> PTR_ERR(mtk_gem); 
ret = <token> &mtk_gem->base, &args->handle); <answer> drm_gem_handle_create(file_priv, 
<token> (ret) <answer> if 
goto <token> <answer> err_handle_create; 
<token> = 0; <answer> vma->vm_pgoff 
vm_flags_set(vma, VM_IO <token> VM_DONTEXPAND | VM_DONTDUMP); <answer> | 
vma->vm_page_prot = <token> <answer> pgprot_writecombine(vm_get_page_prot(vma->vm_flags)); 
<token> = pgprot_decrypted(vma->vm_page_prot); <answer> vma->vm_page_prot 
ret = dma_mmap_attrs(priv->dma_dev, vma, <token> <answer> mtk_gem->cookie, 
<token> obj->size, mtk_gem->dma_attrs); <answer> mtk_gem->dma_addr, 
<token> ret; <answer> return 
struct <token> *mtk_gem_prime_get_sg_table(struct drm_gem_object *obj) <answer> sg_table 
struct mtk_drm_gem_obj <token> = to_mtk_gem_obj(obj); <answer> *mtk_gem 
struct mtk_drm_private <token> = obj->dev->dev_private; <answer> *priv 
struct sg_table <token> <answer> *sgt; 
int <token> <answer> ret; 
sgt = kzalloc(sizeof(*sgt), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!sgt) 
<token> ERR_PTR(-ENOMEM); <answer> return 
ret = dma_get_sgtable_attrs(priv->dma_dev, <token> mtk_gem->cookie, <answer> sgt, 
<token> obj->size, <answer> mtk_gem->dma_addr, 
<token> (ret) { <answer> if 
DRM_ERROR("failed to <token> sgt, %d\n", ret); <answer> allocate 
<token> ERR_PTR(ret); <answer> return 
<token> sgt; <answer> return 
struct drm_gem_object *mtk_gem_prime_import_sg_table(struct drm_device <token> <answer> *dev, 
<token> dma_buf_attachment *attach, struct sg_table *sg) <answer> struct 
struct mtk_drm_gem_obj <token> <answer> *mtk_gem; 
#define pr_fmt(fmt) KBUILD_MODNAME ": " <token> <answer> fmt 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/sched.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/fs.h> <answer> #include 
<token> <linux/crc32.h> <answer> #include 
#include <token> <answer> <linux/pagemap.h> 
<token> <linux/mtd/mtd.h> <answer> #include 
<token> <linux/compiler.h> <answer> #include 
<token> "nodelist.h" <answer> #include 
static int check_node_data(struct jffs2_sb_info *c, struct <token> *tn) <answer> jffs2_tmp_dnode_info 
struct <token> *ref = tn->fn->raw; <answer> jffs2_raw_node_ref 
int err = 0, <token> = 0; <answer> pointed 
struct jffs2_eraseblock <token> <answer> *jeb; 
<token> char *buffer; <answer> unsigned 
<token> crc, ofs, len; <answer> uint32_t 
size_t <token> <answer> retlen; 
<token> == 0); <answer> BUG_ON(tn->csize 
err = mtd_point(c->mtd, <token> len, &retlen, (void **)&buffer, NULL); <answer> ofs, 
if (!err <token> retlen < len) { <answer> && 
JFFS2_WARNING("MTD point returned len too <token> %zu instead of %u.\n", retlen, tn->csize); <answer> short: 
<token> ofs, retlen); <answer> mtd_unpoint(c->mtd, 
} <token> if (err) { <answer> else 
if (err <token> -EOPNOTSUPP) <answer> != 
JFFS2_WARNING("MTD <token> failed: error code %d.\n", err); <answer> point 
<token> else <answer> } 
err = jffs2_flash_read(c, <token> len, &retlen, buffer); <answer> ofs, 
if <token> { <answer> (err) 
JFFS2_ERROR("can not read <token> bytes from 0x%08x, error code: %d.\n", len, ofs, err); <answer> %d 
<token> free_out; <answer> goto 
if (retlen != len) <token> <answer> { 
JFFS2_ERROR("short read at %#08x: %zd instead of %d.\n", <token> retlen, len); <answer> ofs, 
err = <token> <answer> -EIO; 
<token> free_out; <answer> goto 
ref->flash_offset |= <token> <answer> REF_PRISTINE; 
<token> += len; <answer> jeb->used_size 
<token> -= len; <answer> jeb->unchecked_size 
<token> += len; <answer> c->used_size 
<token> -= len; <answer> c->unchecked_size 
<token> jeb); <answer> jffs2_dbg_acct_paranoia_check_nolock(c, 
<token> 0; <answer> return 
<token> __ECOS <answer> #ifndef 
mtd_unpoint(c->mtd, ofs, <token> <answer> len); 
<token> err; <answer> return 
static int check_tn_node(struct jffs2_sb_info *c, struct <token> *tn) <answer> jffs2_tmp_dnode_info 
<token> ret; <answer> int 
<token> int jffs2_add_tn_to_tree(struct jffs2_sb_info *c, <answer> static 
struct <token> *rii, <answer> jffs2_readinode_info 
struct jffs2_tmp_dnode_info <token> <answer> *tn) 
<token> fn_end = tn->fn->ofs + tn->fn->size; <answer> uint32_t 
struct jffs2_tmp_dnode_info *this, <token> <answer> *ptn; 
dbg_readinode("insert fragment %#04x-%#04x, <token> %u at %08x\n", tn->fn->ofs, fn_end, tn->version, ref_offset(tn->fn->raw)); <answer> ver 
if <token> { <answer> (!tn->fn->size) 
if (rii->mdata_tn) <token> <answer> { 
if <token> < tn->version) { <answer> (rii->mdata_tn->version 
<token> (this->overlapped) { <answer> while 
ptn = <token> <answer> tn_prev(this); 
if <token> { <answer> (!ptn) 
this->overlapped = <token> <answer> 0; 
this <token> ptn; <answer> = 
dbg_readinode("'this' found %#04x-%#04x <token> this->fn->ofs, this->fn->ofs + this->fn->size, this->fn ? "data" : "hole"); <answer> (%s)\n", 
<token> (this) { <answer> while 
<token> (this->fn->ofs > fn_end) <answer> if 
<token> this ver %d, 0x%x-0x%x\n", <answer> dbg_readinode("Ponder 
this->version, this->fn->ofs, <token> <answer> this->fn->size); 
if (this->version == <token> { <answer> tn->version) 
<token> (!check_tn_node(c, this)) { <answer> if 
struct <token> *parent; <answer> rb_node 
struct rb_node <token> = &rii->tn_root.rb_node; <answer> **link 
struct jffs2_tmp_dnode_info <token> = NULL; <answer> *insert_point 
while (*link) <token> <answer> { 
parent = <token> <answer> *link; 
insert_point = rb_entry(parent, struct jffs2_tmp_dnode_info, <token> <answer> rb); 
<token> (tn->fn->ofs > insert_point->fn->ofs) <answer> if 
<token> = &insert_point->rb.rb_right; <answer> link 
<token> if (tn->fn->ofs < insert_point->fn->ofs || <answer> else 
tn->fn->size <token> insert_point->fn->size) <answer> < 
<token> = &insert_point->rb.rb_left; <answer> link 
link <token> &insert_point->rb.rb_right; <answer> = 
<token> &insert_point->rb, link); <answer> rb_link_node(&tn->rb, 
<token> &rii->tn_root); <answer> rb_insert_color(&tn->rb, 
this->overlapped <token> 0; <answer> = 
this = <token> <answer> ptn; 
static void <token> rb_root *root, struct rb_node *node) <answer> eat_last(struct 
<token> rb_node *parent = rb_parent(node); <answer> struct 
struct <token> **link; <answer> rb_node 
static void ver_insert(struct <token> *ver_root, struct jffs2_tmp_dnode_info *tn) <answer> rb_root 
struct rb_node **link = <token> <answer> &ver_root->rb_node; 
struct rb_node *parent = <token> <answer> NULL; 
struct jffs2_tmp_dnode_info <token> <answer> *this_tn; 
while (*link) <token> <answer> { 
parent = <token> <answer> *link; 
this_tn = rb_entry(parent, struct <token> rb); <answer> jffs2_tmp_dnode_info, 
if <token> > this_tn->version) <answer> (tn->version 
link = <token> <answer> &parent->rb_left; 
<token> = &parent->rb_right; <answer> link 
<token> new node at %p (root is %p)\n", link, ver_root); <answer> dbg_readinode("Link 
<token> parent, link); <answer> rb_link_node(&tn->rb, 
<token> ver_root); <answer> rb_insert_color(&tn->rb, 
static int jffs2_build_inode_fragtree(struct jffs2_sb_info <token> <answer> *c, 
struct <token> *f, <answer> jffs2_inode_info 
<token> jffs2_readinode_info *rii) <answer> struct 
struct jffs2_tmp_dnode_info *pen, <token> *this; <answer> *last, 
struct rb_root ver_root = <token> <answer> RB_ROOT; 
uint32_t high_ver <token> 0; <answer> = 
<token> (rii->mdata_tn) { <answer> if 
dbg_readinode("potential mdata is ver %d at %p\n", rii->mdata_tn->version, <token> <answer> rii->mdata_tn); 
high_ver <token> rii->mdata_tn->version; <answer> = 
rii->latest_ref <token> rii->mdata_tn->fn->raw; <answer> = 
#ifdef <token> <answer> JFFS2_DBG_READINODE_MESSAGES 
this <token> tn_last(&rii->tn_root); <answer> = 
while <token> { <answer> (this) 
dbg_readinode("tn %p ver %d range 0x%x-0x%x ov <token> this, this->version, this->fn->ofs, <answer> %d\n", 
this->fn->ofs+this->fn->size, <token> <answer> this->overlapped); 
<token> = tn_prev(this); <answer> this 
pen <token> tn_last(&rii->tn_root); <answer> = 
while ((last = <token> { <answer> pen)) 
pen = <token> <answer> tn_prev(last); 
<token> &last->rb); <answer> eat_last(&rii->tn_root, 
ver_insert(&ver_root, <token> <answer> last); 
if (unlikely(last->overlapped)) <token> <answer> { 
<token> (pen) <answer> if 
last->overlapped <token> 0; <answer> = 
this <token> tn_last(&ver_root); <answer> = 
<token> (this) { <answer> while 
<token> jffs2_tmp_dnode_info *vers_next; <answer> struct 
<token> ret; <answer> int 
<token> = tn_prev(this); <answer> vers_next 
<token> &this->rb); <answer> eat_last(&ver_root, 
if (check_tn_node(c, <token> { <answer> this)) 
dbg_readinode("node ver <token> 0x%x-0x%x failed CRC\n", <answer> %d, 
this->version, <token> <answer> this->fn->ofs, 
<token> this); <answer> jffs2_kill_tn(c, 
} else <token> <answer> { 
<token> (this->version > high_ver) { <answer> if 
high_ver = <token> <answer> this->version; 
rii->latest_ref = <token> <answer> this->fn->raw; 
dbg_readinode("Add %p (v <token> 0x%x-0x%x, ov %d) to fragtree\n", <answer> %d, 
this, <token> this->fn->ofs, <answer> this->version, 
<token> this->overlapped); <answer> this->fn->ofs+this->fn->size, 
ret <token> jffs2_add_full_dnode_to_inode(c, f, this->fn); <answer> = 
if (ret) <token> <answer> { 
JFFS2_ERROR("Add node <token> tree failed %d\n", ret); <answer> to 
<token> (1) { <answer> while 
vers_next <token> tn_prev(this); <answer> = 
<token> (check_tn_node(c, this)) <answer> if 
<token> this->fn->raw); <answer> jffs2_mark_node_obsolete(c, 
this = <token> <answer> vers_next; 
if <token> <answer> (!this) 
<token> &vers_next->rb); <answer> eat_last(&ver_root, 
return <token> <answer> ret; 
<token> = vers_next; <answer> this 
<token> 0; <answer> return 
static void jffs2_free_tmp_dnode_info_list(struct rb_root <token> <answer> *list) 
<token> jffs2_tmp_dnode_info *tn, *next; <answer> struct 
rbtree_postorder_for_each_entry_safe(tn, <token> list, rb) { <answer> next, 
*list = <token> <answer> RB_ROOT; 
static void jffs2_free_full_dirent_list(struct <token> *fd) <answer> jffs2_full_dirent 
struct jffs2_full_dirent <token> <answer> *next; 
while (fd) <token> <answer> { 
next <token> fd->next; <answer> = 
<token> = next; <answer> fd 
static inline <token> read_direntry(struct jffs2_sb_info *c, struct jffs2_raw_node_ref *ref, <answer> int 
struct jffs2_raw_dirent *rd, <token> read, <answer> size_t 
struct <token> *rii) <answer> jffs2_readinode_info 
struct jffs2_full_dirent <token> <answer> *fd; 
<token> crc; <answer> uint32_t 
if <token> > sizeof(*rd)) <answer> (read 
<token> &rd->name[0], <answer> memcpy(&fd->name[0], 
<token> rd->nsize, (read - sizeof(*rd)) )); <answer> min_t(uint32_t, 
crc = crc32(0, <token> rd->nsize); <answer> fd->name, 
if (unlikely(crc <token> je32_to_cpu(rd->name_crc))) { <answer> != 
JFFS2_NOTICE("name CRC failed on <token> node at" <answer> dirent 
"%#08x: <token> %#08x,calculated %#08x\n", <answer> read 
ref_offset(ref), je32_to_cpu(rd->node_crc), <token> <answer> crc); 
<token> ref); <answer> jffs2_mark_node_obsolete(c, 
return <token> <answer> 0; 
fd->nhash = full_name_hash(NULL, <token> rd->nsize); <answer> fd->name, 
fd->next = <token> <answer> NULL; 
<token> = '\0'; <answer> fd->name[rd->nsize] 
jffs2_add_fd_to_list(c, fd, <token> <answer> &rii->fds); 
<token> 0; <answer> return 
static inline int read_dnode(struct jffs2_sb_info *c, struct jffs2_raw_node_ref <token> <answer> *ref, 
struct <token> *rd, int rdlen, <answer> jffs2_raw_inode 
<token> jffs2_readinode_info *rii) <answer> struct 
struct jffs2_tmp_dnode_info <token> <answer> *tn; 
uint32_t <token> csize; <answer> len, 
int <token> = 0; <answer> ret 
uint32_t <token> <answer> crc; 
unsigned char <token> <answer> *buf; 
if (len >= csize && <token> != je32_to_cpu(rd->data_crc))) { <answer> unlikely(tn->partial_crc 
JFFS2_NOTICE("wrong data <token> in data node at 0x%08x: read %#08x, calculated %#08x.\n", <answer> CRC 
ref_offset(ref), <token> je32_to_cpu(rd->data_crc)); <answer> tn->partial_crc, 
<token> ref); <answer> jffs2_mark_node_obsolete(c, 
<token> free_out; <answer> goto 
} <token> if (csize == 0) { <answer> else 
<token> jffs2_eraseblock *jeb; <answer> struct 
dbg_readinode("the node <token> no data.\n"); <answer> has 
jeb = <token> / c->sector_size]; <answer> &c->blocks[ref->flash_offset 
<token> = ref_totlen(c, jeb, ref); <answer> len 
jeb->used_size += <token> <answer> len; 
jeb->unchecked_size <token> len; <answer> -= 
c->used_size <token> len; <answer> += 
<token> -= len; <answer> c->unchecked_size 
ref->flash_offset = ref_offset(ref) <token> REF_NORMAL; <answer> | 
<token> = jffs2_alloc_full_dnode(); <answer> tn->fn 
if <token> { <answer> (!tn->fn) 
<token> fn failed\n"); <answer> JFFS2_ERROR("alloc 
ret = <token> <answer> -ENOMEM; 
<token> free_out; <answer> goto 
tn->version = <token> <answer> je32_to_cpu(rd->version); 
<token> = je32_to_cpu(rd->offset); <answer> tn->fn->ofs 
<token> = je32_to_cpu(rd->data_crc); <answer> tn->data_crc 
tn->csize <token> csize; <answer> = 
tn->fn->raw <token> ref; <answer> = 
tn->overlapped = <token> <answer> 0; 
if (tn->version <token> rii->highest_version) <answer> > 
rii->highest_version = <token> <answer> tn->version; 
if (rd->compr == JFFS2_COMPR_ZERO && <token> && csize) <answer> !je32_to_cpu(rd->dsize) 
tn->fn->size = <token> <answer> csize; 
tn->fn->size = <token> <answer> je32_to_cpu(rd->dsize); 
dbg_readinode2("dnode @%08x: ver %u, offset %#04x, dsize <token> csize %#04x\n", <answer> %#04x, 
<token> je32_to_cpu(rd->version), <answer> ref_offset(ref), 
je32_to_cpu(rd->offset), je32_to_cpu(rd->dsize), <token> <answer> csize); 
<token> = jffs2_add_tn_to_tree(c, rii, tn); <answer> ret 
if <token> { <answer> (ret) 
return <token> <answer> ret; 
<token> JFFS2_DBG_READINODE2_MESSAGES <answer> #ifdef 
dbg_readinode2("After adding <token> %d:\n", je32_to_cpu(rd->version)); <answer> ver 
<token> = tn_first(&rii->tn_root); <answer> tn 
while (tn) <token> <answer> { 
<token> v %d r 0x%x-0x%x ov %d\n", <answer> dbg_readinode2("%p: 
tn, tn->version, <token> <answer> tn->fn->ofs, 
tn->fn->ofs+tn->fn->size, <token> <answer> tn->overlapped); 
tn = <token> <answer> tn_next(tn); 
<token> 0; <answer> return 
<token> inline int read_unknown(struct jffs2_sb_info *c, struct jffs2_raw_node_ref *ref, struct jffs2_unknown_node *un) <answer> static 
static int read_more(struct jffs2_sb_info *c, struct <token> *ref, <answer> jffs2_raw_node_ref 
int needed_len, <token> *rdlen, unsigned char *buf) <answer> int 
int err, <token> = needed_len - *rdlen; <answer> to_read 
<token> retlen; <answer> size_t 
uint32_t <token> <answer> offs; 
<token> (jffs2_is_writebuffered(c)) { <answer> if 
int rem = <token> % c->wbuf_pagesize; <answer> to_read 
if <token> <answer> (rem) 
to_read += <token> - rem; <answer> c->wbuf_pagesize 
static <token> jffs2_get_inode_nodes(struct jffs2_sb_info *c, struct jffs2_inode_info *f, <answer> int 
struct <token> *rii) <answer> jffs2_readinode_info 
struct jffs2_raw_node_ref <token> *valid_ref; <answer> *ref, 
unsigned char *buf <token> NULL; <answer> = 
<token> jffs2_node_union *node; <answer> union 
size_t <token> <answer> retlen; 
int <token> err; <answer> len, 
rii->mctime_ver = <token> <answer> 0; 
<token> #%u\n", f->inocache->ino); <answer> dbg_readinode("ino 
len <token> sizeof(union jffs2_node_union) + c->wbuf_pagesize; <answer> = 
buf = kmalloc(len, <token> <answer> GFP_KERNEL); 
<token> (!buf) <answer> if 
<token> -ENOMEM; <answer> return 
valid_ref <token> jffs2_first_valid_node(f->inocache->nodes); <answer> = 
if (!valid_ref && <token> != 1) <answer> f->inocache->ino 
JFFS2_WARNING("Eep. No valid nodes for ino #%u.\n", <token> <answer> f->inocache->ino); 
while <token> { <answer> (valid_ref) 
ref = <token> <answer> valid_ref; 
valid_ref <token> jffs2_first_valid_node(ref->next_in_ino); <answer> = 
len <token> JFFS2_MIN_NODE_HEADER; <answer> = 
<token> (jffs2_is_writebuffered(c)) { <answer> if 
int <token> rem; <answer> end, 
end = ref_offset(ref) + <token> <answer> len; 
rem <token> end % c->wbuf_pagesize; <answer> = 
if <token> <answer> (rem) 
end += c->wbuf_pagesize <token> rem; <answer> - 
len = end <token> ref_offset(ref); <answer> - 
dbg_readinode("read %d bytes at %#08x(%d).\n", len, ref_offset(ref), <token> <answer> ref_flags(ref)); 
latest_node->ctime = <token> = cpu_to_je32(rii.latest_mctime); <answer> latest_node->mtime 
case <token> <answer> S_IFREG: 
if <token> <answer> (!je32_to_cpu(latest_node->isize)) 
<token> = latest_node->dsize; <answer> latest_node->isize 
if (f->inocache->state != <token> { <answer> INO_STATE_CHECKING) 
<token> csize = je32_to_cpu(latest_node->csize); <answer> uint32_t 
if (csize <token> JFFS2_MAX_NAME_LEN) <answer> > 
return <token> <answer> -ENAMETOOLONG; 
f->target = kmalloc(csize + 1, <token> <answer> GFP_KERNEL); 
if (!f->target) <token> <answer> { 
JFFS2_ERROR("can't allocate %u <token> of memory for the symlink target path cache\n", csize); <answer> bytes 
<token> -ENOMEM; <answer> return 
ret = <token> ref_offset(rii.latest_ref) + sizeof(*latest_node), <answer> jffs2_flash_read(c, 
csize, &retlen, <token> *)f->target); <answer> (char 
if (ret || retlen != <token> { <answer> csize) 
<token> (retlen != csize) <answer> if 
<token> = -EIO; <answer> ret 
<token> = NULL; <answer> f->target 
<token> ret; <answer> return 
<token> = '\0'; <answer> f->target[csize] 
dbg_readinode("symlink's target <token> cached\n", f->target); <answer> '%s' 
<token> S_IFBLK: <answer> case 
case <token> <answer> S_IFCHR: 
if (f->metadata) <token> <answer> { 
JFFS2_ERROR("Argh. Special inode #%u with mode 0%o had metadata <token> <answer> node\n", 
f->inocache->ino, <token> <answer> jemode_to_cpu(latest_node->mode)); 
<token> -EIO; <answer> return 
if (!frag_first(&f->fragtree)) <token> <answer> { 
JFFS2_ERROR("Argh. Special inode #%u with mode <token> has no fragments\n", <answer> 0%o 
<token> jemode_to_cpu(latest_node->mode)); <answer> f->inocache->ino, 
<token> -EIO; <answer> return 
dbg_readinode("waiting for ino #%u <token> state %d\n", ino, f->inocache->state); <answer> in 
sleep_on_spinunlock(&c->inocache_wq, <token> <answer> &c->inocache_lock); 
goto <token> <answer> retry_inocache; 
<token> INO_STATE_READING: <answer> case 
<token> INO_STATE_PRESENT: <answer> case 
<token> Trying to read_inode #%u when it's already in state %d!\n", ino, f->inocache->state); <answer> JFFS2_ERROR("Eep. 
#define <token> <answer> _RTL871X_IOCTL_SET_C_ 
#include <token> <answer> "osdep_service.h" 
<token> "drv_types.h" <answer> #include 
<token> "rtl871x_ioctl_set.h" <answer> #include 
<token> "usb_osintf.h" <answer> #include 
#include <token> <answer> "usb_ops.h" 
static u8 validate_ssid(struct ndis_802_11_ssid <token> <answer> *ssid) 
<token> i; <answer> u8 
if (ssid->SsidLength > <token> <answer> 32) 
return <token> <answer> false; 
for (i = <token> i < ssid->SsidLength; i++) { <answer> 0; 
<token> (!pmlmepriv->sitesurveyctrl.traffic_busy) <answer> if 
r8712_sitesurvey_cmd(padapter, <token> <answer> &pmlmepriv->assoc_ssid); 
<token> true; <answer> return 
<token> = r8712_select_and_join_from_scan(pmlmepriv); <answer> ret 
if (!ret) <token> <answer> { 
jiffies + <token> <answer> msecs_to_jiffies(MAX_JOIN_TIMEOUT)); 
} <token> { <answer> else 
if (check_fwstate(pmlmepriv, WIFI_ADHOC_STATE)) <token> <answer> { 
struct wlan_bssid_ex <token> = <answer> *pdev_network 
pmlmepriv->fw_state = <token> <answer> WIFI_ADHOC_MASTER_STATE; 
pibss = <token> <answer> padapter->registrypriv.dev_network.MacAddress; 
sizeof(struct <token> <answer> ndis_802_11_ssid)); 
if <token> <answer> (r8712_createbss_cmd(padapter)) 
return <token> <answer> false; 
pmlmepriv->to_join <token> false; <answer> = 
<token> else { <answer> } 
if <token> <answer> (!pmlmepriv->sitesurveyctrl.traffic_busy) 
return <token> <answer> true; 
u8 r8712_set_802_11_bssid(struct _adapter *padapter, u8 <token> <answer> *bssid) 
<token> long irqL; <answer> unsigned 
<token> status = true; <answer> u8 
<token> mlme_priv *pmlmepriv = &padapter->mlmepriv; <answer> struct 
if (is_zero_ether_addr(bssid) || <token> { <answer> is_broadcast_ether_addr(bssid)) 
status = <token> <answer> false; 
<token> status; <answer> return 
spin_lock_irqsave(&pmlmepriv->lock, <token> <answer> irqL); 
if (check_fwstate(pmlmepriv, _FW_UNDER_SURVEY <token> <answer> | 
_FW_UNDER_LINKING)) <token> <answer> { 
status = <token> _FW_UNDER_LINKING); <answer> check_fwstate(pmlmepriv, 
<token> _Abort_Set_BSSID; <answer> goto 
if <token> <answer> (check_fwstate(pmlmepriv, 
<token> | WIFI_ADHOC_MASTER_STATE)) { <answer> _FW_LINKED 
if (!memcmp(&pmlmepriv->cur_network.network.MacAddress, <token> <answer> bssid, 
ETH_ALEN)) <token> <answer> { 
if (!check_fwstate(pmlmepriv, <token> <answer> WIFI_STATION_STATE)) 
goto <token> <answer> _Abort_Set_BSSID; 
} else <token> <answer> { 
if <token> _FW_LINKED)) <answer> (check_fwstate(pmlmepriv, 
<token> ((check_fwstate(pmlmepriv, <answer> if 
<token> { <answer> WIFI_ADHOC_MASTER_STATE))) 
set_fwstate(pmlmepriv, <token> <answer> WIFI_ADHOC_STATE); 
memcpy(&pmlmepriv->assoc_bssid, <token> ETH_ALEN); <answer> bssid, 
pmlmepriv->assoc_by_bssid = <token> <answer> true; 
status <token> do_join(padapter); <answer> = 
goto <token> <answer> done; 
<token> irqL); <answer> spin_unlock_irqrestore(&pmlmepriv->lock, 
<token> status; <answer> return 
void r8712_set_802_11_ssid(struct <token> *padapter, <answer> _adapter 
struct ndis_802_11_ssid <token> <answer> *ssid) 
unsigned <token> irqL; <answer> long 
<token> mlme_priv *pmlmepriv = &padapter->mlmepriv; <answer> struct 
struct wlan_network <token> = &pmlmepriv->cur_network; <answer> *pnetwork 
<token> (!padapter->hw_init_completed) <answer> if 
spin_lock_irqsave(&pmlmepriv->lock, <token> <answer> irqL); 
if (check_fwstate(pmlmepriv, <token> | _FW_UNDER_LINKING)) { <answer> _FW_UNDER_SURVEY 
check_fwstate(pmlmepriv, <token> <answer> _FW_UNDER_LINKING); 
goto <token> <answer> _Abort_Set_SSID; 
if (check_fwstate(pmlmepriv, <token> | WIFI_ADHOC_MASTER_STATE)) { <answer> _FW_LINKED 
if ((pmlmepriv->assoc_ssid.SsidLength <token> ssid->SsidLength) && <answer> == 
(!memcmp(&pmlmepriv->assoc_ssid.Ssid, <token> <answer> ssid->Ssid, 
ssid->SsidLength))) <token> <answer> { 
if <token> WIFI_STATION_STATE)) { <answer> (!check_fwstate(pmlmepriv, 
<token> (!r8712_is_same_ibss(padapter, <answer> if 
pnetwork)) <token> <answer> { 
if <token> <answer> (check_fwstate(pmlmepriv, 
if <token> <answer> (check_fwstate(pmlmepriv, 
WIFI_ADHOC_MASTER_STATE)) <token> <answer> { 
} else <token> <answer> { 
goto <token> <answer> _Abort_Set_SSID; 
} else <token> <answer> { 
if <token> _FW_LINKED)) <answer> (check_fwstate(pmlmepriv, 
if <token> <answer> (check_fwstate(pmlmepriv, 
WIFI_ADHOC_MASTER_STATE)) <token> <answer> { 
<token> WIFI_ADHOC_STATE); <answer> set_fwstate(pmlmepriv, 
<token> (padapter->securitypriv.btkip_countermeasure) <answer> if 
goto <token> <answer> _Abort_Set_SSID; 
<token> (!validate_ssid(ssid)) <answer> if 
<token> _Abort_Set_SSID; <answer> goto 
<token> ssid, sizeof(struct ndis_802_11_ssid)); <answer> memcpy(&pmlmepriv->assoc_ssid, 
pmlmepriv->assoc_by_bssid <token> false; <answer> = 
goto <token> <answer> done; 
spin_unlock_irqrestore(&pmlmepriv->lock, <token> <answer> irqL); 
<token> r8712_set_802_11_infrastructure_mode(struct _adapter *padapter, <answer> void 
enum <token> networktype) <answer> NDIS_802_11_NETWORK_INFRASTRUCTURE 
<token> long irqL; <answer> unsigned 
struct <token> *pmlmepriv = &padapter->mlmepriv; <answer> mlme_priv 
struct <token> *cur_network = &pmlmepriv->cur_network; <answer> wlan_network 
<token> NDIS_802_11_NETWORK_INFRASTRUCTURE *pold_state = <answer> enum 
if <token> != networktype) { <answer> (*pold_state 
<token> irqL); <answer> spin_lock_irqsave(&pmlmepriv->lock, 
if (check_fwstate(pmlmepriv, _FW_LINKED) <token> <answer> || 
<token> == Ndis802_11IBSS)) <answer> (*pold_state 
if <token> <answer> (check_fwstate(pmlmepriv, 
_FW_LINKED <token> WIFI_ADHOC_MASTER_STATE)) <answer> | 
if (check_fwstate(pmlmepriv, <token> || <answer> _FW_LINKED) 
(*pold_state <token> Ndis802_11Infrastructure) || <answer> == 
<token> == Ndis802_11IBSS)) { <answer> (*pold_state 
<token> = networktype; <answer> *pold_state 
_clr_fwstate_(pmlmepriv, WIFI_STATION_STATE | <token> | <answer> WIFI_AP_STATE 
<token> | WIFI_ADHOC_MASTER_STATE); <answer> WIFI_ADHOC_STATE 
switch (networktype) <token> <answer> { 
case <token> <answer> Ndis802_11IBSS: 
<token> WIFI_ADHOC_STATE); <answer> set_fwstate(pmlmepriv, 
case <token> <answer> Ndis802_11Infrastructure: 
<token> WIFI_STATION_STATE); <answer> set_fwstate(pmlmepriv, 
case <token> <answer> Ndis802_11APMode: 
<token> WIFI_AP_STATE); <answer> set_fwstate(pmlmepriv, 
<token> Ndis802_11AutoUnknown: <answer> case 
<token> Ndis802_11InfrastructureMax: <answer> case 
<token> irqL); <answer> spin_unlock_irqrestore(&pmlmepriv->lock, 
u8 r8712_set_802_11_disassociate(struct <token> *padapter) <answer> _adapter 
unsigned long <token> <answer> irqL; 
struct mlme_priv *pmlmepriv = <token> <answer> &padapter->mlmepriv; 
<token> irqL); <answer> spin_lock_irqsave(&pmlmepriv->lock, 
if (check_fwstate(pmlmepriv, <token> { <answer> _FW_LINKED)) 
spin_unlock_irqrestore(&pmlmepriv->lock, <token> <answer> irqL); 
return <token> <answer> true; 
u8 r8712_set_802_11_bssid_list_scan(struct _adapter <token> <answer> *padapter) 
struct mlme_priv *pmlmepriv <token> NULL; <answer> = 
<token> long irqL; <answer> unsigned 
u8 <token> = true; <answer> ret 
<token> (!padapter) <answer> if 
<token> false; <answer> return 
<token> = &padapter->mlmepriv; <answer> pmlmepriv 
<token> (!padapter->hw_init_completed) <answer> if 
<token> false; <answer> return 
<token> irqL); <answer> spin_lock_irqsave(&pmlmepriv->lock, 
if <token> _FW_UNDER_SURVEY | _FW_UNDER_LINKING) || <answer> (check_fwstate(pmlmepriv, 
pmlmepriv->sitesurveyctrl.traffic_busy) <token> <answer> { 
void vchiq_add_connected_callback(struct vchiq_device <token> void (*callback)(void)) <answer> *device, 
<token> (mutex_lock_killable(&g_connected_mutex)) <answer> if 
if <token> { <answer> (g_connected) 
void <token> <answer> vchiq_call_connected_callbacks(void) 
int <token> <answer> i; 
if <token> <answer> (mutex_lock_killable(&g_connected_mutex)) 
for (i = 0; i < <token> i++) <answer> g_num_deferred_callbacks; 
<token> = 0; <answer> g_num_deferred_callbacks 
g_connected <token> 1; <answer> = 
#include <token> <answer> <linux/module.h> 
<token> <linux/slab.h> <answer> #include 
<token> <linux/vmalloc.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
<token> <linux/string.h> <answer> #include 
#include <token> <answer> <linux/ppp_defs.h> 
<token> <linux/ppp-comp.h> <answer> #include 
<token> <linux/zlib.h> <answer> #include 
<token> <asm/unaligned.h> <answer> #include 
struct ppp_deflate_state <token> <answer> { 
<token> seqno; <answer> int 
int <token> <answer> w_size; 
int <token> <answer> unit; 
int <token> <answer> mru; 
int <token> <answer> debug; 
z_stream <token> <answer> strm; 
<token> compstat stats; <answer> struct 
static <token> z_comp_free(void *arg) <answer> void 
<token> ppp_deflate_state *state = (struct ppp_deflate_state *) arg; <answer> struct 
if (state) <token> <answer> { 
static void *z_comp_alloc(unsigned <token> *options, int opt_len) <answer> char 
struct <token> *state; <answer> ppp_deflate_state 
<token> w_size; <answer> int 
if <token> != CILEN_DEFLATE || <answer> (opt_len 
(options[0] <token> CI_DEFLATE && options[0] != CI_DEFLATE_DRAFT) || <answer> != 
<token> != CILEN_DEFLATE || <answer> options[1] 
DEFLATE_METHOD(options[2]) != DEFLATE_METHOD_VAL <token> <answer> || 
options[3] != <token> <answer> DEFLATE_CHK_SEQUENCE) 
<token> NULL; <answer> return 
w_size = <token> <answer> DEFLATE_SIZE(options[2]); 
<token> (w_size < DEFLATE_MIN_SIZE || w_size > DEFLATE_MAX_SIZE) <answer> if 
<token> NULL; <answer> return 
state = <token> <answer> kzalloc(sizeof(*state), 
<token> (state == NULL) <answer> if 
return <token> <answer> NULL; 
<token> = NULL; <answer> state->strm.next_in 
<token> = w_size; <answer> state->w_size 
state->strm.workspace = <token> 8)); <answer> vmalloc(zlib_deflate_workspacesize(-w_size, 
<token> (state->strm.workspace == NULL) <answer> if 
<token> out_free; <answer> goto 
if (zlib_deflateInit2(&state->strm, <token> <answer> Z_DEFAULT_COMPRESSION, 
DEFLATE_METHOD_VAL, <token> 8, Z_DEFAULT_STRATEGY) <answer> -w_size, 
!= <token> <answer> Z_OK) 
goto <token> <answer> out_free; 
<token> (void *) state; <answer> return 
<token> NULL; <answer> return 
static int z_comp_init(void *arg, unsigned char *options, <token> opt_len, <answer> int 
int unit, <token> hdrlen, int debug) <answer> int 
struct ppp_deflate_state *state <token> (struct ppp_deflate_state *) arg; <answer> = 
if (opt_len < CILEN_DEFLATE <token> <answer> || 
(options[0] != <token> && options[0] != CI_DEFLATE_DRAFT) || <answer> CI_DEFLATE 
options[1] != CILEN_DEFLATE <token> <answer> || 
<token> != DEFLATE_METHOD_VAL || <answer> DEFLATE_METHOD(options[2]) 
DEFLATE_SIZE(options[2]) != <token> || <answer> state->w_size 
<token> != DEFLATE_CHK_SEQUENCE) <answer> options[3] 
<token> 0; <answer> return 
state->seqno <token> 0; <answer> = 
state->unit <token> unit; <answer> = 
state->debug <token> debug; <answer> = 
return <token> <answer> 1; 
<token> void z_comp_reset(void *arg) <answer> static 
<token> ppp_deflate_state *state = (struct ppp_deflate_state *) arg; <answer> struct 
<token> = 0; <answer> state->seqno 
static int z_compress(void *arg, unsigned char *rptr, <token> char *obuf, <answer> unsigned 
int <token> int osize) <answer> isize, 
struct <token> *state = (struct ppp_deflate_state *) arg; <answer> ppp_deflate_state 
int <token> proto, off, olen, oavail; <answer> r, 
unsigned char <token> <answer> *wptr; 
proto <token> PPP_PROTOCOL(rptr); <answer> = 
if <token> > 0x3fff || proto == 0xfd || proto == 0xfb) <answer> (proto 
return <token> <answer> 0; 
if (osize > <token> <answer> isize) 
osize <token> isize; <answer> = 
wptr = <token> <answer> obuf; 
wptr[0] = <token> <answer> PPP_ADDRESS(rptr); 
wptr[1] = <token> <answer> PPP_CONTROL(rptr); 
<token> wptr + 2); <answer> put_unaligned_be16(PPP_COMP, 
wptr <token> PPP_HDRLEN; <answer> += 
put_unaligned_be16(state->seqno, <token> <answer> wptr); 
wptr <token> DEFLATE_OVHD; <answer> += 
olen = PPP_HDRLEN <token> DEFLATE_OVHD; <answer> + 
state->strm.next_out = <token> <answer> wptr; 
state->strm.avail_out = oavail <token> osize - olen; <answer> = 
if (olen < <token> && olen <= osize) { <answer> isize 
state->stats.comp_bytes += <token> <answer> olen; 
} <token> { <answer> else 
state->stats.inc_bytes <token> isize; <answer> += 
olen <token> 0; <answer> = 
<token> += isize; <answer> state->stats.unc_bytes 
<token> olen; <answer> return 
static <token> z_comp_stats(void *arg, struct compstat *stats) <answer> void 
struct ppp_deflate_state *state = (struct <token> *) arg; <answer> ppp_deflate_state 
*stats <token> state->stats; <answer> = 
static void <token> *arg) <answer> z_decomp_free(void 
struct ppp_deflate_state *state = (struct ppp_deflate_state <token> arg; <answer> *) 
if <token> { <answer> (state) 
static void *z_decomp_alloc(unsigned char *options, int <token> <answer> opt_len) 
struct ppp_deflate_state <token> <answer> *state; 
int <token> <answer> w_size; 
if <token> != CILEN_DEFLATE || <answer> (opt_len 
(options[0] != CI_DEFLATE <token> options[0] != CI_DEFLATE_DRAFT) || <answer> && 
options[1] != <token> || <answer> CILEN_DEFLATE 
DEFLATE_METHOD(options[2]) != DEFLATE_METHOD_VAL <token> <answer> || 
options[3] <token> DEFLATE_CHK_SEQUENCE) <answer> != 
<token> NULL; <answer> return 
w_size = <token> <answer> DEFLATE_SIZE(options[2]); 
if (w_size < DEFLATE_MIN_SIZE || w_size <token> DEFLATE_MAX_SIZE) <answer> > 
<token> NULL; <answer> return 
state = kzalloc(sizeof(*state), <token> <answer> GFP_KERNEL); 
if (state == <token> <answer> NULL) 
<token> NULL; <answer> return 
state->w_size <token> w_size; <answer> = 
state->strm.next_out <token> NULL; <answer> = 
state->strm.workspace = <token> <answer> vmalloc(zlib_inflate_workspacesize()); 
if (state->strm.workspace <token> NULL) <answer> == 
<token> out_free; <answer> goto 
if (zlib_inflateInit2(&state->strm, -w_size) <token> Z_OK) <answer> != 
goto <token> <answer> out_free; 
<token> (void *) state; <answer> return 
<token> NULL; <answer> return 
<token> int z_decomp_init(void *arg, unsigned char *options, int opt_len, <answer> static 
int unit, int hdrlen, <token> mru, int debug) <answer> int 
struct ppp_deflate_state *state = (struct ppp_deflate_state <token> arg; <answer> *) 
if (opt_len < CILEN_DEFLATE <token> <answer> || 
(options[0] != CI_DEFLATE && <token> != CI_DEFLATE_DRAFT) || <answer> options[0] 
options[1] != <token> || <answer> CILEN_DEFLATE 
<token> != DEFLATE_METHOD_VAL || <answer> DEFLATE_METHOD(options[2]) 
DEFLATE_SIZE(options[2]) <token> state->w_size || <answer> != 
options[3] <token> DEFLATE_CHK_SEQUENCE) <answer> != 
return <token> <answer> 0; 
<token> = 0; <answer> state->seqno 
<token> = unit; <answer> state->unit 
<token> = debug; <answer> state->debug 
state->mru <token> mru; <answer> = 
return <token> <answer> 1; 
<token> void z_decomp_reset(void *arg) <answer> static 
struct ppp_deflate_state *state <token> (struct ppp_deflate_state *) arg; <answer> = 
<token> = 0; <answer> state->seqno 
static int z_decompress(void *arg, unsigned char *ibuf, int <token> <answer> isize, 
unsigned char *obuf, <token> osize) <answer> int 
struct ppp_deflate_state *state = (struct <token> *) arg; <answer> ppp_deflate_state 
<token> olen, seq, r; <answer> int 
int <token> overflow; <answer> decode_proto, 
<token> char overflow_buf[1]; <answer> unsigned 
if (isize <= PPP_HDRLEN <token> DEFLATE_OVHD) { <answer> + 
<token> (state->debug) <answer> if 
printk(KERN_DEBUG "z_decompress%d: <token> pkt (%d)\n", <answer> short 
state->unit, <token> <answer> isize); 
return <token> <answer> DECOMP_ERROR; 
<token> = PPP_ADDRESS(ibuf); <answer> obuf[0] 
<token> = PPP_CONTROL(ibuf); <answer> obuf[1] 
obuf[2] <token> 0; <answer> = 
state->strm.next_in = ibuf + PPP_HDRLEN + <token> <answer> DEFLATE_OVHD; 
state->strm.avail_in = <token> - (PPP_HDRLEN + DEFLATE_OVHD); <answer> isize 
state->strm.next_out <token> obuf + 3; <answer> = 
<token> = 1; <answer> state->strm.avail_out 
decode_proto <token> 1; <answer> = 
overflow <token> 0; <answer> = 
for (;;) <token> <answer> { 
r = zlib_inflate(&state->strm, <token> <answer> Z_PACKET_FLUSH); 
if (r != Z_OK) <token> <answer> { 
<token> (state->debug) <answer> if 
printk(KERN_DEBUG <token> inflate returned %d (%s)\n", <answer> "z_decompress%d: 
<token> r, (state->strm.msg? state->strm.msg: "")); <answer> state->unit, 
<token> DECOMP_FATALERROR; <answer> return 
if (state->strm.avail_out <token> 0) <answer> != 
<token> = overflow_buf; <answer> state->strm.next_out 
<token> = 1; <answer> state->strm.avail_out 
overflow <token> 1; <answer> = 
} else <token> <answer> { 
<token> (state->debug) <answer> if 
printk(KERN_DEBUG <token> ran out of mru\n", <answer> "z_decompress%d: 
return <token> <answer> DECOMP_FATALERROR; 
<token> (decode_proto) { <answer> if 
<token> (state->debug) <answer> if 
printk(KERN_DEBUG <token> didn't get proto\n", <answer> "z_decompress%d: 
return <token> <answer> DECOMP_ERROR; 
olen = osize <token> overflow - state->strm.avail_out; <answer> + 
<token> += olen; <answer> state->stats.unc_bytes 
<token> += isize; <answer> state->stats.comp_bytes 
<token> olen; <answer> return 
<token> void z_incomp(void *arg, unsigned char *ibuf, int icnt) <answer> static 
<token> ppp_deflate_state *state = (struct ppp_deflate_state *) arg; <answer> struct 
int proto, <token> <answer> r; 
proto <token> PPP_PROTOCOL(ibuf); <answer> = 
if (proto > 0x3fff || proto == 0xfd || proto <token> 0xfb) <answer> == 
state->strm.next_in = ibuf + <token> <answer> 3; 
state->strm.avail_in <token> icnt - 3; <answer> = 
if <token> > 0xff) { <answer> (proto 
<token> = zlib_inflateIncomp(&state->strm); <answer> r 
if <token> != Z_OK) { <answer> (r 
state->stats.inc_bytes <token> icnt; <answer> += 
<token> += icnt; <answer> state->stats.unc_bytes 
<token> struct compressor ppp_deflate = { <answer> static 
.compress_proto <token> CI_DEFLATE, <answer> = 
.comp_alloc = <token> <answer> z_comp_alloc, 
<token> = z_comp_free, <answer> .comp_free 
.comp_init <token> z_comp_init, <answer> = 
<token> = z_comp_reset, <answer> .comp_reset 
.compress = <token> <answer> z_compress, 
<token> = z_comp_stats, <answer> .comp_stat 
.decomp_alloc <token> z_decomp_alloc, <answer> = 
.decomp_free = <token> <answer> z_decomp_free, 
<token> = z_decomp_init, <answer> .decomp_init 
.decomp_reset <token> z_decomp_reset, <answer> = 
.decompress = <token> <answer> z_decompress, 
<token> = z_incomp, <answer> .incomp 
.decomp_stat = <token> <answer> z_comp_stats, 
.owner = <token> <answer> THIS_MODULE 
static struct compressor <token> = { <answer> ppp_deflate_draft 
.compress_proto = <token> <answer> CI_DEFLATE_DRAFT, 
<token> = z_comp_alloc, <answer> .comp_alloc 
<token> = z_comp_free, <answer> .comp_free 
<token> = z_comp_init, <answer> .comp_init 
<token> = z_comp_reset, <answer> .comp_reset 
<token> = z_compress, <answer> .compress 
.comp_stat <token> z_comp_stats, <answer> = 
<token> = z_decomp_alloc, <answer> .decomp_alloc 
.decomp_free = <token> <answer> z_decomp_free, 
.decomp_init <token> z_decomp_init, <answer> = 
.decomp_reset = <token> <answer> z_decomp_reset, 
<token> = z_decompress, <answer> .decompress 
.incomp <token> z_incomp, <answer> = 
<token> = z_comp_stats, <answer> .decomp_stat 
<token> = THIS_MODULE <answer> .owner 
<token> int __init deflate_init(void) <answer> static 
<token> rc; <answer> int 
<token> = ppp_register_compressor(&ppp_deflate); <answer> rc 
if <token> <answer> (rc) 
<token> rc; <answer> return 
rc <token> ppp_register_compressor(&ppp_deflate_draft); <answer> = 
if <token> { <answer> (rc) 
<token> rc; <answer> return 
pr_info("PPP <token> Compression module registered\n"); <answer> Deflate 
return <token> <answer> 0; 
<token> void __exit deflate_cleanup(void) <answer> static 
MODULE_DESCRIPTION("PPP Deflate compression <token> <answer> module"); 
MODULE_LICENSE("Dual <token> <answer> BSD/GPL"); 
<token> __stringify(CI_DEFLATE)); <answer> MODULE_ALIAS("ppp-compress-" 
MODULE_ALIAS("ppp-compress-" <token> <answer> __stringify(CI_DEFLATE_DRAFT)); 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/parport.h> <answer> #include 
<token> <linux/input.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/mutex.h> 
<token> <linux/slab.h> <answer> #include 
<token> Pavlik <vojtech@ucw.cz>"); <answer> MODULE_AUTHOR("Vojtech 
MODULE_DESCRIPTION("TurboGraFX <token> port interface driver"); <answer> parallel 
<token> TGFX_MAX_PORTS 3 <answer> #define 
#define TGFX_MAX_DEVICES <token> <answer> 7 
struct <token> { <answer> tgfx_config 
<token> args[TGFX_MAX_DEVICES + 1]; <answer> int 
<token> int nargs; <answer> unsigned 
<token> struct tgfx_config tgfx_cfg[TGFX_MAX_PORTS]; <answer> static 
module_param_array_named(map, tgfx_cfg[0].args, <token> &tgfx_cfg[0].nargs, 0); <answer> int, 
MODULE_PARM_DESC(map, "Describes first set of <token> (<parport#>,<js1>,<js2>,..<js7>"); <answer> devices 
<token> tgfx_cfg[1].args, int, &tgfx_cfg[1].nargs, 0); <answer> module_param_array_named(map2, 
MODULE_PARM_DESC(map2, "Describes second set of <token> <answer> devices"); 
module_param_array_named(map3, tgfx_cfg[2].args, int, <token> 0); <answer> &tgfx_cfg[2].nargs, 
MODULE_PARM_DESC(map3, "Describes third <token> of devices"); <answer> set 
static void <token> timer_list *t) <answer> tgfx_timer(struct 
struct tgfx <token> = from_timer(tgfx, t, timer); <answer> *tgfx 
struct input_dev <token> <answer> *dev; 
int <token> data2, i; <answer> data1, 
for (i = 0; i < 7; <token> <answer> i++) 
if (tgfx->sticks & (1 <token> i)) { <answer> << 
dev <token> tgfx->dev[i]; <answer> = 
<token> ~(1 << i)); <answer> parport_write_data(tgfx->pd->port, 
data1 = parport_read_status(tgfx->pd->port) <token> 0x7f; <answer> ^ 
static void <token> parport *pp) <answer> tgfx_attach(struct 
struct tgfx <token> <answer> *tgfx; 
<token> input_dev *input_dev; <answer> struct 
struct <token> *pd; <answer> pardevice 
int i, <token> port_idx; <answer> j, 
int <token> n_devs; <answer> *n_buttons, 
<token> pardev_cb tgfx_parport_cb; <answer> struct 
for (port_idx = 0; port_idx < TGFX_MAX_PORTS; <token> { <answer> port_idx++) 
<token> (tgfx_cfg[port_idx].nargs == 0 || <answer> if 
tgfx_cfg[port_idx].args[0] < <token> <answer> 0) 
<token> (tgfx_cfg[port_idx].args[0] == pp->number) <answer> if 
if (port_idx <token> TGFX_MAX_PORTS) { <answer> == 
pr_debug("Not <token> parport%d.\n", pp->number); <answer> using 
n_buttons = <token> + 1; <answer> tgfx_cfg[port_idx].args 
n_devs = tgfx_cfg[port_idx].nargs <token> 1; <answer> - 
memset(&tgfx_parport_cb, <token> sizeof(tgfx_parport_cb)); <answer> 0, 
tgfx_parport_cb.flags <token> PARPORT_FLAG_EXCL; <answer> = 
pd <token> parport_register_dev_model(pp, "turbografx", &tgfx_parport_cb, <answer> = 
if <token> { <answer> (!pd) 
pr_err("parport busy already <token> lp.o loaded?\n"); <answer> - 
tgfx = <token> tgfx), GFP_KERNEL); <answer> kzalloc(sizeof(struct 
if <token> { <answer> (!tgfx) 
printk(KERN_ERR "turbografx.c: Not enough <token> <answer> memory\n"); 
<token> err_unreg_pardev; <answer> goto 
<token> = pd; <answer> tgfx->pd 
tgfx->parportno <token> pp->number; <answer> = 
timer_setup(&tgfx->timer, tgfx_timer, <token> <answer> 0); 
for (i = 0; i < <token> i++) { <answer> n_devs; 
if <token> < 1) <answer> (n_buttons[i] 
if <token> > ARRAY_SIZE(tgfx_buttons)) { <answer> (n_buttons[i] 
printk(KERN_ERR "turbografx.c: Invalid number of buttons %d\n", <token> <answer> n_buttons[i]); 
<token> err_unreg_devs; <answer> goto 
tgfx->dev[i] = <token> = input_allocate_device(); <answer> input_dev 
if (!input_dev) <token> <answer> { 
<token> "turbografx.c: Not enough memory for input device\n"); <answer> printk(KERN_ERR 
goto <token> <answer> err_unreg_devs; 
<token> |= (1 << i); <answer> tgfx->sticks 
snprintf(tgfx->name[i], <token> <answer> sizeof(tgfx->name[i]), 
"TurboGraFX %d-button Multisystem <token> n_buttons[i]); <answer> joystick", 
snprintf(tgfx->phys[i], <token> <answer> sizeof(tgfx->phys[i]), 
"%s/input%d", <token> i); <answer> tgfx->pd->port->name, 
<token> = tgfx->name[i]; <answer> input_dev->name 
<token> = tgfx->phys[i]; <answer> input_dev->phys 
<token> = BUS_PARPORT; <answer> input_dev->id.bustype 
input_dev->id.vendor <token> 0x0003; <answer> = 
input_dev->id.product = <token> <answer> n_buttons[i]; 
input_dev->id.version = <token> <answer> 0x0100; 
input_set_drvdata(input_dev, <token> <answer> tgfx); 
input_dev->open = <token> <answer> tgfx_open; 
input_dev->close = <token> <answer> tgfx_close; 
input_dev->evbit[0] = BIT_MASK(EV_KEY) <token> BIT_MASK(EV_ABS); <answer> | 
input_set_abs_params(input_dev, ABS_X, -1, <token> 0, 0); <answer> 1, 
input_set_abs_params(input_dev, ABS_Y, -1, <token> 0, 0); <answer> 1, 
for (j = 0; j < n_buttons[i]; <token> <answer> j++) 
<token> input_dev->keybit); <answer> set_bit(tgfx_buttons[j], 
<token> (input_register_device(tgfx->dev[i])) <answer> if 
goto <token> <answer> err_free_dev; 
if <token> { <answer> (!tgfx->sticks) 
printk(KERN_ERR "turbografx.c: No valid <token> specified\n"); <answer> devices 
goto <token> <answer> err_free_tgfx; 
tgfx_base[port_idx] = <token> <answer> tgfx; 
while (--i <token> 0) <answer> >= 
if <token> <answer> (tgfx->dev[i]) 
static void tgfx_detach(struct <token> *port) <answer> parport 
int <token> <answer> i; 
struct <token> *tgfx; <answer> tgfx 
for (i <token> 0; i < TGFX_MAX_PORTS; i++) { <answer> = 
<token> (tgfx_base[i] && tgfx_base[i]->parportno == port->number) <answer> if 
if (i == <token> <answer> TGFX_MAX_PORTS) 
tgfx <token> tgfx_base[i]; <answer> = 
<token> = NULL; <answer> tgfx_base[i] 
<token> (i = 0; i < TGFX_MAX_DEVICES; i++) <answer> for 
<token> (tgfx->dev[i]) <answer> if 
static struct parport_driver tgfx_parport_driver = <token> <answer> { 
<token> = "turbografx", <answer> .name 
.match_port <token> tgfx_attach, <answer> = 
.detach <token> tgfx_detach, <answer> = 
.devmodel = <token> <answer> true, 
static int <token> tgfx_init(void) <answer> __init 
int <token> <answer> i; 
int have_dev <token> 0; <answer> = 
for (i = 0; <token> < TGFX_MAX_PORTS; i++) { <answer> i 
if <token> == 0 || tgfx_cfg[i].args[0] < 0) <answer> (tgfx_cfg[i].nargs 
if (tgfx_cfg[i].nargs <token> 2) { <answer> < 
printk(KERN_ERR <token> at least one joystick must be specified\n"); <answer> "turbografx.c: 
return <token> <answer> -EINVAL; 
<token> = 1; <answer> have_dev 
<token> (!have_dev) <answer> if 
return <token> <answer> -ENODEV; 
<token> parport_register_driver(&tgfx_parport_driver); <answer> return 
static void <token> tgfx_exit(void) <answer> __exit 
<token> <linux/bitfield.h> <answer> #include 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <sound/pcm_params.h> 
<token> <sound/pcm_iec958.h> <answer> #include 
<token> <sound/soc.h> <answer> #include 
<token> <sound/soc-dai.h> <answer> #include 
<token> "aiu.h" <answer> #include 
#define <token> BIT(0) <answer> AIU_958_MISC_NON_PCM 
#define AIU_958_MISC_MODE_16BITS <token> <answer> BIT(1) 
#define AIU_958_MISC_16BITS_ALIGN <token> 5) <answer> GENMASK(6, 
<token> AIU_958_MISC_MODE_32BITS BIT(7) <answer> #define 
#define AIU_958_MISC_U_FROM_STREAM <token> <answer> BIT(12) 
#define AIU_958_MISC_FORCE_LR <token> <answer> BIT(13) 
<token> AIU_958_CTRL_HOLD_EN BIT(0) <answer> #define 
#define <token> BIT(1) <answer> AIU_CLK_CTRL_958_DIV_EN 
#define AIU_CLK_CTRL_958_DIV <token> 4) <answer> GENMASK(5, 
#define AIU_CLK_CTRL_958_DIV_MORE <token> <answer> BIT(12) 
#define AIU_CS_WORD_LEN <token> <answer> 4 
<token> AIU_958_INTERNAL_DIV 2 <answer> #define 
<token> void <answer> static 
aiu_encoder_spdif_divider_enable(struct <token> *component, <answer> snd_soc_component 
<token> enable) <answer> bool 
snd_soc_component_update_bits(component, <token> <answer> AIU_CLK_CTRL, 
<token> ? AIU_CLK_CTRL_958_DIV_EN : 0); <answer> enable 
static void aiu_encoder_spdif_hold(struct snd_soc_component <token> <answer> *component, 
bool <token> <answer> enable) 
snd_soc_component_update_bits(component, <token> <answer> AIU_958_CTRL, 
enable <token> AIU_958_CTRL_HOLD_EN : 0); <answer> ? 
<token> int <answer> static 
aiu_encoder_spdif_trigger(struct <token> *substream, int cmd, <answer> snd_pcm_substream 
<token> snd_soc_dai *dai) <answer> struct 
struct snd_soc_component *component = <token> <answer> dai->component; 
switch <token> { <answer> (cmd) 
<token> SNDRV_PCM_TRIGGER_START: <answer> case 
<token> SNDRV_PCM_TRIGGER_RESUME: <answer> case 
case <token> <answer> SNDRV_PCM_TRIGGER_PAUSE_RELEASE: 
<token> false); <answer> aiu_encoder_spdif_hold(component, 
return <token> <answer> 0; 
<token> SNDRV_PCM_TRIGGER_STOP: <answer> case 
case <token> <answer> SNDRV_PCM_TRIGGER_SUSPEND: 
case <token> <answer> SNDRV_PCM_TRIGGER_PAUSE_PUSH: 
<token> true); <answer> aiu_encoder_spdif_hold(component, 
return <token> <answer> 0; 
<token> -EINVAL; <answer> return 
static <token> aiu_encoder_spdif_setup_cs_word(struct snd_soc_component *component, <answer> int 
<token> snd_pcm_hw_params *params) <answer> struct 
u8 <token> <answer> cs[AIU_CS_WORD_LEN]; 
unsigned int <token> <answer> val; 
<token> ret; <answer> int 
<token> = snd_pcm_create_iec958_consumer_hw_params(params, cs, <answer> ret 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
ret = <token> <answer> clk_set_parent(aiu->spdif.clks[MCLK].clk, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> = clk_bulk_prepare_enable(aiu->spdif.clk_num, aiu->spdif.clks); <answer> ret 
if <token> <answer> (ret) 
dev_err(dai->dev, <token> to enable spdif clocks\n"); <answer> "failed 
<token> ret; <answer> return 
static <token> aiu_encoder_spdif_shutdown(struct snd_pcm_substream *substream, <answer> void 
struct snd_soc_dai <token> <answer> *dai) 
struct <token> *aiu = snd_soc_component_get_drvdata(dai->component); <answer> aiu 
<token> aiu->spdif.clks); <answer> clk_bulk_disable_unprepare(aiu->spdif.clk_num, 
<token> struct snd_soc_dai_ops aiu_encoder_spdif_dai_ops = { <answer> const 
.trigger <token> aiu_encoder_spdif_trigger, <answer> = 
.hw_params = <token> <answer> aiu_encoder_spdif_hw_params, 
.hw_free = <token> <answer> aiu_encoder_spdif_hw_free, 
.startup <token> aiu_encoder_spdif_startup, <answer> = 
.shutdown <token> aiu_encoder_spdif_shutdown, <answer> = 
#include <token> <answer> <linux/atomic.h> 
<token> <linux/percpu.h> <answer> #include 
<token> <linux/wait.h> <answer> #include 
<token> <linux/lockdep.h> <answer> #include 
<token> <linux/percpu-rwsem.h> <answer> #include 
#include <token> <answer> <linux/rcupdate.h> 
#include <token> <answer> <linux/sched.h> 
#include <token> <answer> <linux/sched/task.h> 
<token> <linux/sched/debug.h> <answer> #include 
#include <token> <answer> <linux/errno.h> 
<token> <trace/events/lock.h> <answer> #include 
<token> __percpu_init_rwsem(struct percpu_rw_semaphore *sem, <answer> int 
<token> char *name, struct lock_class_key *key) <answer> const 
sem->read_count = <token> <answer> alloc_percpu(int); 
if <token> <answer> (unlikely(!sem->read_count)) 
<token> -ENOMEM; <answer> return 
<token> 0); <answer> atomic_set(&sem->block, 
<token> CONFIG_DEBUG_LOCK_ALLOC <answer> #ifdef 
debug_check_no_locks_freed((void *)sem, <token> <answer> sizeof(*sem)); 
lockdep_init_map(&sem->dep_map, <token> key, 0); <answer> name, 
<token> 0; <answer> return 
void <token> percpu_rw_semaphore *sem) <answer> percpu_free_rwsem(struct 
if <token> <answer> (!sem->read_count) 
<token> (likely(!atomic_read_acquire(&sem->block))) <answer> if 
return <token> <answer> true; 
static int <token> wait_queue_entry *wq_entry, <answer> percpu_rwsem_wake_function(struct 
unsigned int mode, <token> wake_flags, <answer> int 
<token> *key) <answer> void 
bool reader = <token> & WQ_FLAG_CUSTOM; <answer> wq_entry->flags 
struct percpu_rw_semaphore <token> = key; <answer> *sem 
<token> task_struct *p; <answer> struct 
<token> = !__percpu_rwsem_trylock(sem, reader); <answer> wait 
<token> (wait) { <answer> if 
wq_entry.flags |= WQ_FLAG_EXCLUSIVE | <token> * WQ_FLAG_CUSTOM; <answer> reader 
__add_wait_queue_entry_tail(&sem->waiters, <token> <answer> &wq_entry); 
while <token> { <answer> (wait) 
<token> (!smp_load_acquire(&wq_entry.private)) <answer> if 
bool __sched __percpu_down_read(struct percpu_rw_semaphore *sem, bool <token> <answer> try) 
if <token> <answer> (__percpu_down_read_trylock(sem)) 
return <token> <answer> true; 
if <token> <answer> (try) 
return <token> <answer> false; 
trace_contention_begin(sem, LCB_F_PERCPU <token> LCB_F_READ); <answer> | 
static bool <token> percpu_rw_semaphore *sem) <answer> readers_active_check(struct 
if <token> != 0) <answer> (per_cpu_sum(*sem->read_count) 
return <token> <answer> false; 
if (!__percpu_down_write_trylock(sem)) <token> <answer> { 
trace_contention_begin(sem, <token> | LCB_F_WRITE); <answer> LCB_F_PERCPU 
<token> 0); <answer> atomic_set_release(&sem->block, 
__wake_up(&sem->waiters, TASK_NORMAL, 1, <token> <answer> sem); 
#define <token> <answer> _GNU_SOURCE 
#include <token> <answer> <asm/unistd.h> 
#include <token> <answer> <linux/time_types.h> 
#include <token> <answer> <poll.h> 
<token> <unistd.h> <answer> #include 
#include <token> <answer> <assert.h> 
<token> <signal.h> <answer> #include 
<token> <pthread.h> <answer> #include 
#include <token> <answer> <sys/epoll.h> 
#include <token> <answer> <sys/socket.h> 
#include <token> <answer> <sys/eventfd.h> 
#include <token> <answer> "../../kselftest_harness.h" 
struct <token> <answer> epoll_mtcontext 
int <token> <answer> efd[3]; 
<token> sfd[4]; <answer> int 
volatile <token> count; <answer> int 
<token> main; <answer> pthread_t 
<token> waiter; <answer> pthread_t 
<token> __NR_epoll_pwait2 <answer> #ifndef 
#define __NR_epoll_pwait2 <token> <answer> -1 
static <token> int sys_epoll_pwait2(int fd, struct epoll_event *events, <answer> inline 
int <token> <answer> maxevents, 
const <token> __kernel_timespec *timeout, <answer> struct 
<token> sigset_t *sigset, size_t sigsetsize) <answer> const 
return syscall(__NR_epoll_pwait2, fd, <token> maxevents, timeout, <answer> events, 
sigset, <token> <answer> sigsetsize); 
static void signal_handler(int <token> <answer> signum) 
static <token> kill_timeout(struct epoll_mtcontext *ctx) <answer> void 
pthread_kill(ctx->main, <token> <answer> SIGUSR1); 
pthread_kill(ctx->waiter, <token> <answer> SIGUSR1); 
static void *waiter_entry1a(void <token> <answer> *data) 
struct <token> e; <answer> epoll_event 
struct epoll_mtcontext *ctx <token> data; <answer> = 
if (epoll_wait(ctx->efd[0], &e, 1, <token> > 0) <answer> -1) 
__sync_fetch_and_add(&ctx->count, <token> <answer> 1); 
return <token> <answer> NULL; 
static void <token> *data) <answer> *waiter_entry1ap(void 
struct <token> pfd; <answer> pollfd 
<token> epoll_event e; <answer> struct 
struct epoll_mtcontext *ctx = <token> <answer> data; 
pfd.fd = <token> <answer> ctx->efd[0]; 
<token> = POLLIN; <answer> pfd.events 
if (poll(&pfd, 1, -1) <token> 0) { <answer> > 
if (epoll_wait(ctx->efd[0], &e, 1, <token> > 0) <answer> 0) 
__sync_fetch_and_add(&ctx->count, <token> <answer> 1); 
return <token> <answer> NULL; 
<token> void *waiter_entry1o(void *data) <answer> static 
struct epoll_event <token> <answer> e; 
struct epoll_mtcontext <token> = data; <answer> *ctx 
if (epoll_wait(ctx->efd[0], &e, 1, -1) > <token> <answer> 0) 
<token> 1); <answer> __sync_fetch_and_or(&ctx->count, 
return <token> <answer> NULL; 
static <token> *waiter_entry1op(void *data) <answer> void 
struct <token> pfd; <answer> pollfd 
struct epoll_event <token> <answer> e; 
struct epoll_mtcontext *ctx = <token> <answer> data; 
pfd.fd <token> ctx->efd[0]; <answer> = 
pfd.events = <token> <answer> POLLIN; 
if (poll(&pfd, 1, -1) > 0) <token> <answer> { 
if (epoll_wait(ctx->efd[0], &e, 1, <token> > 0) <answer> 0) 
__sync_fetch_and_or(&ctx->count, <token> <answer> 1); 
<token> NULL; <answer> return 
static void *waiter_entry2a(void <token> <answer> *data) 
<token> epoll_event events[2]; <answer> struct 
struct <token> *ctx = data; <answer> epoll_mtcontext 
if <token> events, 2, -1) > 0) <answer> (epoll_wait(ctx->efd[0], 
<token> 1); <answer> __sync_fetch_and_add(&ctx->count, 
return <token> <answer> NULL; 
static void *waiter_entry2ap(void <token> <answer> *data) 
struct <token> pfd; <answer> pollfd 
struct epoll_event <token> <answer> events[2]; 
<token> epoll_mtcontext *ctx = data; <answer> struct 
pfd.fd <token> ctx->efd[0]; <answer> = 
<token> = POLLIN; <answer> pfd.events 
if <token> 1, -1) > 0) { <answer> (poll(&pfd, 
if (epoll_wait(ctx->efd[0], events, 2, <token> > 0) <answer> 0) 
<token> 1); <answer> __sync_fetch_and_add(&ctx->count, 
<token> NULL; <answer> return 
static void *emitter_entry1(void <token> <answer> *data) 
struct <token> *ctx = data; <answer> epoll_mtcontext 
<token> "w", 1); <answer> write(ctx->sfd[1], 
<token> NULL; <answer> return 
<token> void *emitter_entry2(void *data) <answer> static 
<token> epoll_mtcontext *ctx = data; <answer> struct 
write(ctx->sfd[1], <token> 1); <answer> "w", 
<token> "w", 1); <answer> write(ctx->sfd[3], 
return <token> <answer> NULL; 
<token> efd; <answer> int 
int <token> <answer> sfd[2]; 
struct epoll_event <token> <answer> e; 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, <token> 0); <answer> sfd), 
efd <token> epoll_create(1); <answer> = 
ASSERT_GE(efd, <token> <answer> 0); 
<token> = EPOLLIN; <answer> e.events 
ASSERT_EQ(epoll_ctl(efd, EPOLL_CTL_ADD, sfd[0], <token> 0); <answer> &e), 
ASSERT_EQ(write(sfd[1], "w", 1), <token> <answer> 1); 
EXPECT_EQ(epoll_wait(efd, &e, 1, 0), <token> <answer> 1); 
EXPECT_EQ(epoll_wait(efd, &e, <token> 0), 1); <answer> 1, 
int <token> <answer> efd; 
<token> sfd[2]; <answer> int 
struct <token> e; <answer> epoll_event 
<token> SOCK_STREAM, 0, sfd), 0); <answer> ASSERT_EQ(socketpair(AF_UNIX, 
efd <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(efd, 
e.events <token> EPOLLIN | EPOLLET; <answer> = 
ASSERT_EQ(epoll_ctl(efd, EPOLL_CTL_ADD, sfd[0], <token> 0); <answer> &e), 
ASSERT_EQ(write(sfd[1], "w", <token> 1); <answer> 1), 
EXPECT_EQ(epoll_wait(efd, &e, 1, 0), <token> <answer> 1); 
EXPECT_EQ(epoll_wait(efd, &e, 1, 0), <token> <answer> 0); 
int <token> <answer> efd; 
<token> sfd[4]; <answer> int 
struct <token> events[2]; <answer> epoll_event 
<token> SOCK_STREAM, 0, &sfd[0]), 0); <answer> ASSERT_EQ(socketpair(AF_UNIX, 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, <token> &sfd[2]), 0); <answer> 0, 
efd <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(efd, 
events[0].events <token> EPOLLIN; <answer> = 
ASSERT_EQ(epoll_ctl(efd, <token> sfd[0], events), 0); <answer> EPOLL_CTL_ADD, 
events[0].events <token> EPOLLIN; <answer> = 
<token> EPOLL_CTL_ADD, sfd[2], events), 0); <answer> ASSERT_EQ(epoll_ctl(efd, 
ASSERT_EQ(write(sfd[1], <token> 1), 1); <answer> "w", 
ASSERT_EQ(write(sfd[3], <token> 1), 1); <answer> "w", 
EXPECT_EQ(epoll_wait(efd, <token> 2, 0), 2); <answer> events, 
EXPECT_EQ(epoll_wait(efd, events, <token> 0), 2); <answer> 2, 
<token> efd; <answer> int 
<token> sfd[4]; <answer> int 
struct <token> events[2]; <answer> epoll_event 
<token> SOCK_STREAM, 0, &sfd[0]), 0); <answer> ASSERT_EQ(socketpair(AF_UNIX, 
<token> SOCK_STREAM, 0, &sfd[2]), 0); <answer> ASSERT_EQ(socketpair(AF_UNIX, 
<token> = epoll_create(1); <answer> efd 
ASSERT_GE(efd, <token> <answer> 0); 
events[0].events = <token> | EPOLLET; <answer> EPOLLIN 
ASSERT_EQ(epoll_ctl(efd, EPOLL_CTL_ADD, sfd[0], events), <token> <answer> 0); 
<token> = EPOLLIN | EPOLLET; <answer> events[0].events 
ASSERT_EQ(epoll_ctl(efd, <token> sfd[2], events), 0); <answer> EPOLL_CTL_ADD, 
ASSERT_EQ(write(sfd[1], "w", 1), <token> <answer> 1); 
ASSERT_EQ(write(sfd[3], <token> 1), 1); <answer> "w", 
<token> events, 2, 0), 2); <answer> EXPECT_EQ(epoll_wait(efd, 
EXPECT_EQ(epoll_wait(efd, events, 2, <token> 0); <answer> 0), 
int <token> <answer> efd; 
int <token> <answer> sfd[2]; 
struct <token> pfd; <answer> pollfd 
struct epoll_event <token> <answer> e; 
ASSERT_EQ(socketpair(AF_UNIX, <token> 0, &sfd[0]), 0); <answer> SOCK_STREAM, 
<token> = epoll_create(1); <answer> efd 
<token> 0); <answer> ASSERT_GE(efd, 
e.events <token> EPOLLIN; <answer> = 
ASSERT_EQ(epoll_ctl(efd, EPOLL_CTL_ADD, sfd[0], &e), <token> <answer> 0); 
ASSERT_EQ(write(sfd[1], "w", 1), <token> <answer> 1); 
pfd.fd = <token> <answer> efd; 
pfd.events <token> POLLIN; <answer> = 
ASSERT_EQ(poll(&pfd, 1, <token> 1); <answer> 0), 
ASSERT_EQ(epoll_wait(efd, <token> 1, 0), 1); <answer> &e, 
<token> = efd; <answer> pfd.fd 
pfd.events <token> POLLIN; <answer> = 
ASSERT_EQ(poll(&pfd, <token> 0), 1); <answer> 1, 
ASSERT_EQ(epoll_wait(efd, &e, 1, 0), <token> <answer> 1); 
int <token> <answer> efd; 
int <token> <answer> sfd[2]; 
struct <token> pfd; <answer> pollfd 
<token> epoll_event e; <answer> struct 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, &sfd[0]), <token> <answer> 0); 
efd <token> epoll_create(1); <answer> = 
ASSERT_GE(efd, <token> <answer> 0); 
e.events = EPOLLIN | <token> <answer> EPOLLET; 
ASSERT_EQ(epoll_ctl(efd, EPOLL_CTL_ADD, <token> &e), 0); <answer> sfd[0], 
ASSERT_EQ(write(sfd[1], "w", 1), <token> <answer> 1); 
<token> = efd; <answer> pfd.fd 
pfd.events = <token> <answer> POLLIN; 
ASSERT_EQ(poll(&pfd, 1, 0), <token> <answer> 1); 
<token> &e, 1, 0), 1); <answer> ASSERT_EQ(epoll_wait(efd, 
pfd.fd = <token> <answer> efd; 
<token> = POLLIN; <answer> pfd.events 
ASSERT_EQ(poll(&pfd, <token> 0), 0); <answer> 1, 
ASSERT_EQ(epoll_wait(efd, &e, 1, <token> 0); <answer> 0), 
int <token> <answer> efd; 
int <token> <answer> sfd[4]; 
struct <token> pfd; <answer> pollfd 
struct epoll_event <token> <answer> events[2]; 
<token> SOCK_STREAM, 0, &sfd[0]), 0); <answer> ASSERT_EQ(socketpair(AF_UNIX, 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, <token> 0); <answer> &sfd[2]), 
efd <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(efd, 
events[0].events <token> EPOLLIN; <answer> = 
ASSERT_EQ(epoll_ctl(efd, EPOLL_CTL_ADD, <token> events), 0); <answer> sfd[0], 
events[0].events <token> EPOLLIN; <answer> = 
<token> EPOLL_CTL_ADD, sfd[2], events), 0); <answer> ASSERT_EQ(epoll_ctl(efd, 
ASSERT_EQ(write(sfd[1], <token> 1), 1); <answer> "w", 
<token> "w", 1), 1); <answer> ASSERT_EQ(write(sfd[3], 
<token> = efd; <answer> pfd.fd 
pfd.events = <token> <answer> POLLIN; 
<token> 1, 0), 1); <answer> EXPECT_EQ(poll(&pfd, 
EXPECT_EQ(epoll_wait(efd, <token> 2, 0), 2); <answer> events, 
pfd.fd = <token> <answer> efd; 
pfd.events <token> POLLIN; <answer> = 
EXPECT_EQ(poll(&pfd, 1, 0), <token> <answer> 1); 
EXPECT_EQ(epoll_wait(efd, <token> 2, 0), 2); <answer> events, 
<token> efd; <answer> int 
int <token> <answer> sfd[4]; 
struct pollfd <token> <answer> pfd; 
struct epoll_event <token> <answer> events[2]; 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, <token> &sfd[0]), 0); <answer> 0, 
ASSERT_EQ(socketpair(AF_UNIX, <token> 0, &sfd[2]), 0); <answer> SOCK_STREAM, 
efd <token> epoll_create(1); <answer> = 
ASSERT_GE(efd, <token> <answer> 0); 
events[0].events = EPOLLIN | <token> <answer> EPOLLET; 
ASSERT_EQ(epoll_ctl(efd, EPOLL_CTL_ADD, sfd[0], <token> 0); <answer> events), 
events[0].events = <token> | EPOLLET; <answer> EPOLLIN 
ASSERT_EQ(epoll_ctl(efd, <token> sfd[2], events), 0); <answer> EPOLL_CTL_ADD, 
ASSERT_EQ(write(sfd[1], "w", 1), <token> <answer> 1); 
ASSERT_EQ(write(sfd[3], "w", 1), <token> <answer> 1); 
pfd.fd <token> efd; <answer> = 
<token> = POLLIN; <answer> pfd.events 
EXPECT_EQ(poll(&pfd, 1, 0), <token> <answer> 1); 
EXPECT_EQ(epoll_wait(efd, events, 2, 0), <token> <answer> 2); 
<token> = efd; <answer> pfd.fd 
pfd.events = <token> <answer> POLLIN; 
EXPECT_EQ(poll(&pfd, <token> 0), 0); <answer> 1, 
EXPECT_EQ(epoll_wait(efd, events, 2, 0), <token> <answer> 0); 
<token> emitter; <answer> pthread_t 
struct epoll_event <token> <answer> e; 
struct epoll_mtcontext ctx = { <token> }; <answer> 0 
<token> signal_handler); <answer> signal(SIGUSR1, 
<token> SOCK_STREAM, 0, ctx.sfd), 0); <answer> ASSERT_EQ(socketpair(AF_UNIX, 
ctx.efd[0] = <token> <answer> epoll_create(1); 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
e.events = <token> <answer> EPOLLIN; 
<token> EPOLL_CTL_ADD, ctx.sfd[0], &e), 0); <answer> ASSERT_EQ(epoll_ctl(ctx.efd[0], 
<token> = pthread_self(); <answer> ctx.main 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1a, &ctx), <token> <answer> 0); 
<token> NULL, emitter_entry1, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&emitter, 
if <token> &e, 1, -1) > 0) <answer> (epoll_wait(ctx.efd[0], 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
<token> 2); <answer> EXPECT_EQ(ctx.count, 
<token> (pthread_tryjoin_np(emitter, NULL) < 0) { <answer> if 
<token> SIGUSR1); <answer> pthread_kill(emitter, 
<token> NULL); <answer> pthread_join(emitter, 
pthread_t <token> <answer> emitter; 
struct <token> e; <answer> epoll_event 
<token> epoll_mtcontext ctx = { 0 }; <answer> struct 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, ctx.sfd), <token> <answer> 0); 
ctx.efd[0] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
e.events = EPOLLIN <token> EPOLLET; <answer> | 
<token> EPOLL_CTL_ADD, ctx.sfd[0], &e), 0); <answer> ASSERT_EQ(epoll_ctl(ctx.efd[0], 
ctx.main = <token> <answer> pthread_self(); 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, <token> &ctx), 0); <answer> waiter_entry1a, 
ASSERT_EQ(pthread_create(&emitter, NULL, emitter_entry1, <token> 0); <answer> &ctx), 
if <token> &e, 1, -1) > 0) <answer> (epoll_wait(ctx.efd[0], 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
<token> NULL), 0); <answer> ASSERT_EQ(pthread_join(ctx.waiter, 
<token> 1); <answer> EXPECT_EQ(ctx.count, 
<token> (pthread_tryjoin_np(emitter, NULL) < 0) { <answer> if 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
pthread_join(emitter, <token> <answer> NULL); 
<token> emitter; <answer> pthread_t 
struct <token> events[2]; <answer> epoll_event 
struct epoll_mtcontext <token> = { 0 }; <answer> ctx 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, <token> 0); <answer> &ctx.sfd[0]), 
ASSERT_EQ(socketpair(AF_UNIX, <token> 0, &ctx.sfd[2]), 0); <answer> SOCK_STREAM, 
ctx.efd[0] = <token> <answer> epoll_create(1); 
ASSERT_GE(ctx.efd[0], <token> <answer> 0); 
<token> = EPOLLIN; <answer> events[0].events 
ASSERT_EQ(epoll_ctl(ctx.efd[0], <token> ctx.sfd[0], events), 0); <answer> EPOLL_CTL_ADD, 
events[0].events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.sfd[2], events), <token> <answer> 0); 
ctx.main <token> pthread_self(); <answer> = 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry2a, <token> 0); <answer> &ctx), 
ASSERT_EQ(pthread_create(&emitter, NULL, emitter_entry2, &ctx), <token> <answer> 0); 
if <token> events, 2, -1) > 0) <answer> (epoll_wait(ctx.efd[0], 
<token> 1); <answer> __sync_fetch_and_add(&ctx.count, 
ASSERT_EQ(pthread_join(ctx.waiter, NULL), <token> <answer> 0); 
EXPECT_EQ(ctx.count, <token> <answer> 2); 
if (pthread_tryjoin_np(emitter, NULL) < <token> { <answer> 0) 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
pthread_join(emitter, <token> <answer> NULL); 
pthread_t <token> <answer> emitter; 
struct <token> events[2]; <answer> epoll_event 
struct <token> ctx = { 0 }; <answer> epoll_mtcontext 
<token> signal_handler); <answer> signal(SIGUSR1, 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, &ctx.sfd[0]), <token> <answer> 0); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, <token> 0); <answer> &ctx.sfd[2]), 
<token> = epoll_create(1); <answer> ctx.efd[0] 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
events[0].events = EPOLLIN <token> EPOLLET; <answer> | 
ASSERT_EQ(epoll_ctl(ctx.efd[0], <token> ctx.sfd[0], events), 0); <answer> EPOLL_CTL_ADD, 
events[0].events = <token> | EPOLLET; <answer> EPOLLIN 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.sfd[2], events), <token> <answer> 0); 
<token> = pthread_self(); <answer> ctx.main 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1a, &ctx), <token> <answer> 0); 
ASSERT_EQ(pthread_create(&emitter, <token> emitter_entry2, &ctx), 0); <answer> NULL, 
if <token> events, 1, -1) > 0) <answer> (epoll_wait(ctx.efd[0], 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
EXPECT_EQ(ctx.count, <token> <answer> 2); 
if (pthread_tryjoin_np(emitter, <token> < 0) { <answer> NULL) 
<token> SIGUSR1); <answer> pthread_kill(emitter, 
<token> NULL); <answer> pthread_join(emitter, 
<token> emitter; <answer> pthread_t 
struct epoll_event <token> <answer> e; 
<token> epoll_mtcontext ctx = { 0 }; <answer> struct 
<token> signal_handler); <answer> signal(SIGUSR1, 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, ctx.sfd), <token> <answer> 0); 
ctx.efd[0] = <token> <answer> epoll_create(1); 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
e.events <token> EPOLLIN; <answer> = 
<token> EPOLL_CTL_ADD, ctx.sfd[0], &e), 0); <answer> ASSERT_EQ(epoll_ctl(ctx.efd[0], 
<token> = pthread_self(); <answer> ctx.main 
ASSERT_EQ(pthread_create(&ctx.waiter, <token> waiter_entry1ap, &ctx), 0); <answer> NULL, 
ASSERT_EQ(pthread_create(&emitter, <token> emitter_entry1, &ctx), 0); <answer> NULL, 
if (epoll_wait(ctx.efd[0], &e, <token> -1) > 0) <answer> 1, 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
<token> NULL), 0); <answer> ASSERT_EQ(pthread_join(ctx.waiter, 
EXPECT_EQ(ctx.count, <token> <answer> 2); 
<token> (pthread_tryjoin_np(emitter, NULL) < 0) { <answer> if 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
<token> NULL); <answer> pthread_join(emitter, 
<token> emitter; <answer> pthread_t 
struct <token> e; <answer> epoll_event 
struct <token> ctx = { 0 }; <answer> epoll_mtcontext 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, <token> 0, ctx.sfd), 0); <answer> SOCK_STREAM, 
<token> = epoll_create(1); <answer> ctx.efd[0] 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
e.events = EPOLLIN <token> EPOLLET; <answer> | 
ASSERT_EQ(epoll_ctl(ctx.efd[0], <token> ctx.sfd[0], &e), 0); <answer> EPOLL_CTL_ADD, 
ctx.main <token> pthread_self(); <answer> = 
<token> NULL, waiter_entry1ap, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&ctx.waiter, 
<token> NULL, emitter_entry1, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&emitter, 
if (epoll_wait(ctx.efd[0], &e, 1, -1) > <token> <answer> 0) 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
ASSERT_EQ(pthread_join(ctx.waiter, NULL), <token> <answer> 0); 
EXPECT_EQ(ctx.count, <token> <answer> 1); 
if (pthread_tryjoin_np(emitter, NULL) < <token> { <answer> 0) 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
pthread_join(emitter, <token> <answer> NULL); 
<token> emitter; <answer> pthread_t 
struct epoll_event <token> <answer> events[2]; 
struct <token> ctx = { 0 }; <answer> epoll_mtcontext 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, &ctx.sfd[0]), <token> <answer> 0); 
<token> SOCK_STREAM, 0, &ctx.sfd[2]), 0); <answer> ASSERT_EQ(socketpair(AF_UNIX, 
<token> = epoll_create(1); <answer> ctx.efd[0] 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
events[0].events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(ctx.efd[0], <token> ctx.sfd[0], events), 0); <answer> EPOLL_CTL_ADD, 
<token> = EPOLLIN; <answer> events[0].events 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, <token> events), 0); <answer> ctx.sfd[2], 
ctx.main <token> pthread_self(); <answer> = 
ASSERT_EQ(pthread_create(&ctx.waiter, <token> waiter_entry2ap, &ctx), 0); <answer> NULL, 
ASSERT_EQ(pthread_create(&emitter, NULL, emitter_entry2, &ctx), <token> <answer> 0); 
if (epoll_wait(ctx.efd[0], <token> 2, -1) > 0) <answer> events, 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
<token> 2); <answer> EXPECT_EQ(ctx.count, 
if (pthread_tryjoin_np(emitter, <token> < 0) { <answer> NULL) 
<token> SIGUSR1); <answer> pthread_kill(emitter, 
<token> NULL); <answer> pthread_join(emitter, 
<token> emitter; <answer> pthread_t 
<token> epoll_event events[2]; <answer> struct 
struct epoll_mtcontext <token> = { 0 }; <answer> ctx 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, &ctx.sfd[0]), <token> <answer> 0); 
<token> SOCK_STREAM, 0, &ctx.sfd[2]), 0); <answer> ASSERT_EQ(socketpair(AF_UNIX, 
<token> = epoll_create(1); <answer> ctx.efd[0] 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
<token> = EPOLLIN | EPOLLET; <answer> events[0].events 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.sfd[0], events), <token> <answer> 0); 
events[0].events = <token> | EPOLLET; <answer> EPOLLIN 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.sfd[2], <token> 0); <answer> events), 
ctx.main <token> pthread_self(); <answer> = 
ASSERT_EQ(pthread_create(&ctx.waiter, <token> waiter_entry1ap, &ctx), 0); <answer> NULL, 
ASSERT_EQ(pthread_create(&emitter, NULL, emitter_entry2, <token> 0); <answer> &ctx), 
if (epoll_wait(ctx.efd[0], events, 1, <token> > 0) <answer> -1) 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
ASSERT_EQ(pthread_join(ctx.waiter, NULL), <token> <answer> 0); 
<token> 2); <answer> EXPECT_EQ(ctx.count, 
<token> (pthread_tryjoin_np(emitter, NULL) < 0) { <answer> if 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
<token> NULL); <answer> pthread_join(emitter, 
int <token> <answer> efd[2]; 
<token> sfd[2]; <answer> int 
struct <token> e; <answer> epoll_event 
<token> SOCK_STREAM, 0, sfd), 0); <answer> ASSERT_EQ(socketpair(AF_UNIX, 
efd[0] <token> epoll_create(1); <answer> = 
ASSERT_GE(efd[0], <token> <answer> 0); 
efd[1] <token> epoll_create(1); <answer> = 
ASSERT_GE(efd[1], <token> <answer> 0); 
e.events <token> EPOLLIN; <answer> = 
ASSERT_EQ(epoll_ctl(efd[1], EPOLL_CTL_ADD, sfd[0], &e), <token> <answer> 0); 
e.events <token> EPOLLIN; <answer> = 
<token> EPOLL_CTL_ADD, efd[1], &e), 0); <answer> ASSERT_EQ(epoll_ctl(efd[0], 
<token> "w", 1), 1); <answer> ASSERT_EQ(write(sfd[1], 
EXPECT_EQ(epoll_wait(efd[0], &e, <token> 0), 1); <answer> 1, 
EXPECT_EQ(epoll_wait(efd[0], &e, 1, 0), <token> <answer> 1); 
int <token> <answer> efd[2]; 
<token> sfd[2]; <answer> int 
struct <token> e; <answer> epoll_event 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, sfd), <token> <answer> 0); 
<token> = epoll_create(1); <answer> efd[0] 
<token> 0); <answer> ASSERT_GE(efd[0], 
efd[1] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(efd[1], 
e.events = EPOLLIN <token> EPOLLET; <answer> | 
ASSERT_EQ(epoll_ctl(efd[1], EPOLL_CTL_ADD, <token> &e), 0); <answer> sfd[0], 
<token> = EPOLLIN; <answer> e.events 
ASSERT_EQ(epoll_ctl(efd[0], EPOLL_CTL_ADD, <token> &e), 0); <answer> efd[1], 
ASSERT_EQ(write(sfd[1], "w", <token> 1); <answer> 1), 
<token> &e, 1, 0), 1); <answer> EXPECT_EQ(epoll_wait(efd[0], 
EXPECT_EQ(epoll_wait(efd[0], <token> 1, 0), 1); <answer> &e, 
int <token> <answer> efd[2]; 
int <token> <answer> sfd[2]; 
struct epoll_event <token> <answer> e; 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, <token> sfd), 0); <answer> 0, 
efd[0] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(efd[0], 
efd[1] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(efd[1], 
e.events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(efd[1], EPOLL_CTL_ADD, sfd[0], <token> 0); <answer> &e), 
e.events = EPOLLIN <token> EPOLLET; <answer> | 
ASSERT_EQ(epoll_ctl(efd[0], EPOLL_CTL_ADD, efd[1], <token> 0); <answer> &e), 
<token> "w", 1), 1); <answer> ASSERT_EQ(write(sfd[1], 
EXPECT_EQ(epoll_wait(efd[0], <token> 1, 0), 1); <answer> &e, 
EXPECT_EQ(epoll_wait(efd[0], &e, <token> 0), 0); <answer> 1, 
<token> efd[2]; <answer> int 
<token> sfd[2]; <answer> int 
struct <token> e; <answer> epoll_event 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, <token> sfd), 0); <answer> 0, 
efd[0] = <token> <answer> epoll_create(1); 
ASSERT_GE(efd[0], <token> <answer> 0); 
efd[1] = <token> <answer> epoll_create(1); 
ASSERT_GE(efd[1], <token> <answer> 0); 
e.events = EPOLLIN | <token> <answer> EPOLLET; 
ASSERT_EQ(epoll_ctl(efd[1], <token> sfd[0], &e), 0); <answer> EPOLL_CTL_ADD, 
e.events = <token> | EPOLLET; <answer> EPOLLIN 
<token> EPOLL_CTL_ADD, efd[1], &e), 0); <answer> ASSERT_EQ(epoll_ctl(efd[0], 
ASSERT_EQ(write(sfd[1], <token> 1), 1); <answer> "w", 
EXPECT_EQ(epoll_wait(efd[0], &e, 1, <token> 1); <answer> 0), 
EXPECT_EQ(epoll_wait(efd[0], <token> 1, 0), 0); <answer> &e, 
<token> efd[2]; <answer> int 
int <token> <answer> sfd[2]; 
<token> pollfd pfd; <answer> struct 
<token> epoll_event e; <answer> struct 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, <token> sfd), 0); <answer> 0, 
<token> = epoll_create(1); <answer> efd[0] 
<token> 0); <answer> ASSERT_GE(efd[0], 
<token> = epoll_create(1); <answer> efd[1] 
ASSERT_GE(efd[1], <token> <answer> 0); 
<token> = EPOLLIN; <answer> e.events 
ASSERT_EQ(epoll_ctl(efd[1], EPOLL_CTL_ADD, sfd[0], <token> 0); <answer> &e), 
e.events = <token> <answer> EPOLLIN; 
<token> EPOLL_CTL_ADD, efd[1], &e), 0); <answer> ASSERT_EQ(epoll_ctl(efd[0], 
ASSERT_EQ(write(sfd[1], "w", <token> 1); <answer> 1), 
pfd.fd = <token> <answer> efd[0]; 
<token> = POLLIN; <answer> pfd.events 
EXPECT_EQ(poll(&pfd, <token> 0), 1); <answer> 1, 
EXPECT_EQ(epoll_wait(efd[0], &e, 1, 0), <token> <answer> 1); 
<token> = efd[0]; <answer> pfd.fd 
pfd.events = <token> <answer> POLLIN; 
<token> 1, 0), 1); <answer> EXPECT_EQ(poll(&pfd, 
<token> &e, 1, 0), 1); <answer> EXPECT_EQ(epoll_wait(efd[0], 
int <token> <answer> efd[2]; 
<token> sfd[2]; <answer> int 
<token> pollfd pfd; <answer> struct 
<token> epoll_event e; <answer> struct 
<token> SOCK_STREAM, 0, sfd), 0); <answer> ASSERT_EQ(socketpair(AF_UNIX, 
efd[0] = <token> <answer> epoll_create(1); 
<token> 0); <answer> ASSERT_GE(efd[0], 
efd[1] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(efd[1], 
e.events = EPOLLIN <token> EPOLLET; <answer> | 
ASSERT_EQ(epoll_ctl(efd[1], EPOLL_CTL_ADD, sfd[0], &e), <token> <answer> 0); 
e.events <token> EPOLLIN; <answer> = 
ASSERT_EQ(epoll_ctl(efd[0], EPOLL_CTL_ADD, <token> &e), 0); <answer> efd[1], 
ASSERT_EQ(write(sfd[1], <token> 1), 1); <answer> "w", 
pfd.fd = <token> <answer> efd[0]; 
pfd.events = <token> <answer> POLLIN; 
<token> 1, 0), 1); <answer> EXPECT_EQ(poll(&pfd, 
<token> &e, 1, 0), 1); <answer> EXPECT_EQ(epoll_wait(efd[0], 
pfd.fd = <token> <answer> efd[0]; 
<token> = POLLIN; <answer> pfd.events 
EXPECT_EQ(poll(&pfd, <token> 0), 1); <answer> 1, 
EXPECT_EQ(epoll_wait(efd[0], &e, 1, <token> 1); <answer> 0), 
int <token> <answer> efd[2]; 
<token> sfd[2]; <answer> int 
struct pollfd <token> <answer> pfd; 
struct epoll_event <token> <answer> e; 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, <token> 0); <answer> sfd), 
efd[0] = <token> <answer> epoll_create(1); 
ASSERT_GE(efd[0], <token> <answer> 0); 
efd[1] = <token> <answer> epoll_create(1); 
<token> 0); <answer> ASSERT_GE(efd[1], 
<token> = EPOLLIN; <answer> e.events 
ASSERT_EQ(epoll_ctl(efd[1], EPOLL_CTL_ADD, <token> &e), 0); <answer> sfd[0], 
e.events = EPOLLIN | <token> <answer> EPOLLET; 
ASSERT_EQ(epoll_ctl(efd[0], <token> efd[1], &e), 0); <answer> EPOLL_CTL_ADD, 
<token> "w", 1), 1); <answer> ASSERT_EQ(write(sfd[1], 
pfd.fd = <token> <answer> efd[0]; 
pfd.events = <token> <answer> POLLIN; 
EXPECT_EQ(poll(&pfd, 1, <token> 1); <answer> 0), 
EXPECT_EQ(epoll_wait(efd[0], &e, <token> 0), 1); <answer> 1, 
<token> = efd[0]; <answer> pfd.fd 
pfd.events <token> POLLIN; <answer> = 
EXPECT_EQ(poll(&pfd, <token> 0), 0); <answer> 1, 
EXPECT_EQ(epoll_wait(efd[0], &e, <token> 0), 0); <answer> 1, 
int <token> <answer> efd[2]; 
<token> sfd[2]; <answer> int 
<token> pollfd pfd; <answer> struct 
struct epoll_event <token> <answer> e; 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, sfd), <token> <answer> 0); 
efd[0] <token> epoll_create(1); <answer> = 
ASSERT_GE(efd[0], <token> <answer> 0); 
efd[1] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(efd[1], 
<token> = EPOLLIN | EPOLLET; <answer> e.events 
ASSERT_EQ(epoll_ctl(efd[1], EPOLL_CTL_ADD, sfd[0], &e), <token> <answer> 0); 
e.events = <token> | EPOLLET; <answer> EPOLLIN 
<token> EPOLL_CTL_ADD, efd[1], &e), 0); <answer> ASSERT_EQ(epoll_ctl(efd[0], 
<token> "w", 1), 1); <answer> ASSERT_EQ(write(sfd[1], 
pfd.fd = <token> <answer> efd[0]; 
pfd.events <token> POLLIN; <answer> = 
EXPECT_EQ(poll(&pfd, <token> 0), 1); <answer> 1, 
EXPECT_EQ(epoll_wait(efd[0], &e, <token> 0), 1); <answer> 1, 
pfd.fd = <token> <answer> efd[0]; 
pfd.events <token> POLLIN; <answer> = 
EXPECT_EQ(poll(&pfd, 1, 0), <token> <answer> 0); 
EXPECT_EQ(epoll_wait(efd[0], &e, 1, <token> 0); <answer> 0), 
pthread_t <token> <answer> emitter; 
struct epoll_event <token> <answer> e; 
struct epoll_mtcontext ctx = <token> 0 }; <answer> { 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, ctx.sfd), <token> <answer> 0); 
ctx.efd[0] <token> epoll_create(1); <answer> = 
ASSERT_GE(ctx.efd[0], <token> <answer> 0); 
ctx.efd[1] = <token> <answer> epoll_create(1); 
ASSERT_GE(ctx.efd[1], <token> <answer> 0); 
e.events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, ctx.sfd[0], <token> 0); <answer> &e), 
e.events <token> EPOLLIN; <answer> = 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.efd[1], <token> 0); <answer> &e), 
ctx.main <token> pthread_self(); <answer> = 
<token> NULL, waiter_entry1a, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&ctx.waiter, 
<token> NULL, emitter_entry1, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&emitter, 
if (epoll_wait(ctx.efd[0], &e, 1, <token> > 0) <answer> -1) 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
ASSERT_EQ(pthread_join(ctx.waiter, NULL), <token> <answer> 0); 
<token> 2); <answer> EXPECT_EQ(ctx.count, 
if <token> NULL) < 0) { <answer> (pthread_tryjoin_np(emitter, 
<token> SIGUSR1); <answer> pthread_kill(emitter, 
pthread_join(emitter, <token> <answer> NULL); 
<token> emitter; <answer> pthread_t 
struct <token> e; <answer> epoll_event 
<token> epoll_mtcontext ctx = { 0 }; <answer> struct 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, <token> ctx.sfd), 0); <answer> 0, 
ctx.efd[0] = <token> <answer> epoll_create(1); 
ASSERT_GE(ctx.efd[0], <token> <answer> 0); 
ctx.efd[1] = <token> <answer> epoll_create(1); 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
<token> = EPOLLIN | EPOLLET; <answer> e.events 
<token> EPOLL_CTL_ADD, ctx.sfd[0], &e), 0); <answer> ASSERT_EQ(epoll_ctl(ctx.efd[1], 
e.events <token> EPOLLIN; <answer> = 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, <token> &e), 0); <answer> ctx.efd[1], 
ctx.main <token> pthread_self(); <answer> = 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1a, &ctx), <token> <answer> 0); 
ASSERT_EQ(pthread_create(&emitter, <token> emitter_entry1, &ctx), 0); <answer> NULL, 
if (epoll_wait(ctx.efd[0], <token> 1, -1) > 0) <answer> &e, 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
<token> NULL), 0); <answer> ASSERT_EQ(pthread_join(ctx.waiter, 
<token> 2); <answer> EXPECT_EQ(ctx.count, 
if (pthread_tryjoin_np(emitter, NULL) < <token> { <answer> 0) 
<token> SIGUSR1); <answer> pthread_kill(emitter, 
<token> NULL); <answer> pthread_join(emitter, 
pthread_t <token> <answer> emitter; 
<token> epoll_event e; <answer> struct 
<token> epoll_mtcontext ctx = { 0 }; <answer> struct 
<token> signal_handler); <answer> signal(SIGUSR1, 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, <token> 0); <answer> ctx.sfd), 
ctx.efd[0] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
<token> = epoll_create(1); <answer> ctx.efd[1] 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
e.events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, <token> &e), 0); <answer> ctx.sfd[0], 
<token> = EPOLLIN | EPOLLET; <answer> e.events 
<token> EPOLL_CTL_ADD, ctx.efd[1], &e), 0); <answer> ASSERT_EQ(epoll_ctl(ctx.efd[0], 
ctx.main = <token> <answer> pthread_self(); 
ASSERT_EQ(pthread_create(&ctx.waiter, <token> waiter_entry1a, &ctx), 0); <answer> NULL, 
<token> NULL, emitter_entry1, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&emitter, 
if (epoll_wait(ctx.efd[0], &e, 1, -1) > <token> <answer> 0) 
<token> 1); <answer> __sync_fetch_and_add(&ctx.count, 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
EXPECT_EQ(ctx.count, <token> <answer> 1); 
if <token> NULL) < 0) { <answer> (pthread_tryjoin_np(emitter, 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
pthread_join(emitter, <token> <answer> NULL); 
pthread_t <token> <answer> emitter; 
struct <token> e; <answer> epoll_event 
struct epoll_mtcontext <token> = { 0 }; <answer> ctx 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, <token> 0); <answer> ctx.sfd), 
<token> = epoll_create(1); <answer> ctx.efd[0] 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
ctx.efd[1] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
e.events = <token> | EPOLLET; <answer> EPOLLIN 
ASSERT_EQ(epoll_ctl(ctx.efd[1], <token> ctx.sfd[0], &e), 0); <answer> EPOLL_CTL_ADD, 
e.events <token> EPOLLIN | EPOLLET; <answer> = 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, <token> &e), 0); <answer> ctx.efd[1], 
<token> = pthread_self(); <answer> ctx.main 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1a, <token> 0); <answer> &ctx), 
ASSERT_EQ(pthread_create(&emitter, <token> emitter_entry1, &ctx), 0); <answer> NULL, 
if <token> &e, 1, -1) > 0) <answer> (epoll_wait(ctx.efd[0], 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
ASSERT_EQ(pthread_join(ctx.waiter, NULL), <token> <answer> 0); 
<token> 1); <answer> EXPECT_EQ(ctx.count, 
if (pthread_tryjoin_np(emitter, NULL) < <token> { <answer> 0) 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
pthread_join(emitter, <token> <answer> NULL); 
pthread_t <token> <answer> emitter; 
struct <token> e; <answer> epoll_event 
struct epoll_mtcontext ctx <token> { 0 }; <answer> = 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, <token> ctx.sfd), 0); <answer> 0, 
ctx.efd[0] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
ctx.efd[1] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
e.events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, ctx.sfd[0], &e), <token> <answer> 0); 
e.events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, <token> &e), 0); <answer> ctx.efd[1], 
<token> = pthread_self(); <answer> ctx.main 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1ap, <token> 0); <answer> &ctx), 
ASSERT_EQ(pthread_create(&emitter, <token> emitter_entry1, &ctx), 0); <answer> NULL, 
if (epoll_wait(ctx.efd[0], &e, 1, -1) <token> 0) <answer> > 
<token> 1); <answer> __sync_fetch_and_add(&ctx.count, 
<token> NULL), 0); <answer> ASSERT_EQ(pthread_join(ctx.waiter, 
EXPECT_EQ(ctx.count, <token> <answer> 2); 
if <token> NULL) < 0) { <answer> (pthread_tryjoin_np(emitter, 
<token> SIGUSR1); <answer> pthread_kill(emitter, 
pthread_join(emitter, <token> <answer> NULL); 
<token> emitter; <answer> pthread_t 
struct <token> e; <answer> epoll_event 
struct epoll_mtcontext <token> = { 0 }; <answer> ctx 
<token> signal_handler); <answer> signal(SIGUSR1, 
ASSERT_EQ(socketpair(AF_UNIX, <token> 0, ctx.sfd), 0); <answer> SOCK_STREAM, 
ctx.efd[0] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
<token> = epoll_create(1); <answer> ctx.efd[1] 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
e.events = EPOLLIN <token> EPOLLET; <answer> | 
<token> EPOLL_CTL_ADD, ctx.sfd[0], &e), 0); <answer> ASSERT_EQ(epoll_ctl(ctx.efd[1], 
e.events <token> EPOLLIN; <answer> = 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.efd[1], &e), <token> <answer> 0); 
ctx.main = <token> <answer> pthread_self(); 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1ap, &ctx), <token> <answer> 0); 
ASSERT_EQ(pthread_create(&emitter, NULL, emitter_entry1, &ctx), <token> <answer> 0); 
if <token> &e, 1, -1) > 0) <answer> (epoll_wait(ctx.efd[0], 
<token> 1); <answer> __sync_fetch_and_add(&ctx.count, 
<token> NULL), 0); <answer> ASSERT_EQ(pthread_join(ctx.waiter, 
EXPECT_EQ(ctx.count, <token> <answer> 2); 
if <token> NULL) < 0) { <answer> (pthread_tryjoin_np(emitter, 
<token> SIGUSR1); <answer> pthread_kill(emitter, 
<token> NULL); <answer> pthread_join(emitter, 
pthread_t <token> <answer> emitter; 
struct epoll_event <token> <answer> e; 
struct epoll_mtcontext ctx = { 0 <token> <answer> }; 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, <token> 0, ctx.sfd), 0); <answer> SOCK_STREAM, 
ctx.efd[0] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
ctx.efd[1] <token> epoll_create(1); <answer> = 
ASSERT_GE(ctx.efd[1], <token> <answer> 0); 
e.events <token> EPOLLIN; <answer> = 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, ctx.sfd[0], &e), <token> <answer> 0); 
e.events = EPOLLIN | <token> <answer> EPOLLET; 
ASSERT_EQ(epoll_ctl(ctx.efd[0], <token> ctx.efd[1], &e), 0); <answer> EPOLL_CTL_ADD, 
<token> = pthread_self(); <answer> ctx.main 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, <token> &ctx), 0); <answer> waiter_entry1ap, 
<token> NULL, emitter_entry1, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&emitter, 
if (epoll_wait(ctx.efd[0], &e, <token> -1) > 0) <answer> 1, 
<token> 1); <answer> __sync_fetch_and_add(&ctx.count, 
ASSERT_EQ(pthread_join(ctx.waiter, NULL), <token> <answer> 0); 
<token> 1); <answer> EXPECT_EQ(ctx.count, 
if (pthread_tryjoin_np(emitter, NULL) < 0) <token> <answer> { 
<token> SIGUSR1); <answer> pthread_kill(emitter, 
pthread_join(emitter, <token> <answer> NULL); 
pthread_t <token> <answer> emitter; 
struct <token> e; <answer> epoll_event 
struct epoll_mtcontext <token> = { 0 }; <answer> ctx 
<token> signal_handler); <answer> signal(SIGUSR1, 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, ctx.sfd), <token> <answer> 0); 
ctx.efd[0] = <token> <answer> epoll_create(1); 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
ctx.efd[1] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
e.events = EPOLLIN <token> EPOLLET; <answer> | 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, <token> &e), 0); <answer> ctx.sfd[0], 
e.events <token> EPOLLIN | EPOLLET; <answer> = 
<token> EPOLL_CTL_ADD, ctx.efd[1], &e), 0); <answer> ASSERT_EQ(epoll_ctl(ctx.efd[0], 
<token> = pthread_self(); <answer> ctx.main 
<token> NULL, waiter_entry1ap, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&ctx.waiter, 
ASSERT_EQ(pthread_create(&emitter, NULL, emitter_entry1, <token> 0); <answer> &ctx), 
<token> (epoll_wait(ctx.efd[0], &e, 1, -1) > 0) <answer> if 
<token> 1); <answer> __sync_fetch_and_add(&ctx.count, 
ASSERT_EQ(pthread_join(ctx.waiter, NULL), <token> <answer> 0); 
<token> 1); <answer> EXPECT_EQ(ctx.count, 
if (pthread_tryjoin_np(emitter, NULL) < <token> { <answer> 0) 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
pthread_join(emitter, <token> <answer> NULL); 
pthread_t <token> <answer> emitter; 
<token> epoll_event e; <answer> struct 
struct epoll_mtcontext ctx = <token> 0 }; <answer> { 
<token> signal_handler); <answer> signal(SIGUSR1, 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, ctx.sfd), <token> <answer> 0); 
<token> = epoll_create(1); <answer> ctx.efd[0] 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
ctx.efd[1] = <token> <answer> epoll_create(1); 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
e.events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, <token> &e), 0); <answer> ctx.sfd[0], 
<token> = EPOLLIN; <answer> e.events 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, <token> &e), 0); <answer> ctx.efd[1], 
ctx.main <token> pthread_self(); <answer> = 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, <token> &ctx), 0); <answer> waiter_entry1a, 
ASSERT_EQ(pthread_create(&emitter, <token> emitter_entry1, &ctx), 0); <answer> NULL, 
<token> (epoll_wait(ctx.efd[1], &e, 1, -1) > 0) <answer> if 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
<token> NULL), 0); <answer> ASSERT_EQ(pthread_join(ctx.waiter, 
EXPECT_EQ(ctx.count, <token> <answer> 2); 
if (pthread_tryjoin_np(emitter, NULL) < 0) <token> <answer> { 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
pthread_join(emitter, <token> <answer> NULL); 
<token> emitter; <answer> pthread_t 
struct <token> e; <answer> epoll_event 
struct epoll_mtcontext <token> = { 0 }; <answer> ctx 
<token> signal_handler); <answer> signal(SIGUSR1, 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, <token> ctx.sfd), 0); <answer> 0, 
ctx.efd[0] <token> epoll_create(1); <answer> = 
ASSERT_GE(ctx.efd[0], <token> <answer> 0); 
ctx.efd[1] <token> epoll_create(1); <answer> = 
ASSERT_GE(ctx.efd[1], <token> <answer> 0); 
e.events = <token> | EPOLLET; <answer> EPOLLIN 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, ctx.sfd[0], &e), <token> <answer> 0); 
e.events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.efd[1], <token> 0); <answer> &e), 
ctx.main = <token> <answer> pthread_self(); 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1o, <token> 0); <answer> &ctx), 
ASSERT_EQ(pthread_create(&emitter, NULL, <token> &ctx), 0); <answer> emitter_entry1, 
if (epoll_wait(ctx.efd[1], <token> 1, -1) > 0) <answer> &e, 
<token> 2); <answer> __sync_fetch_and_or(&ctx.count, 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
EXPECT_TRUE((ctx.count == <token> || (ctx.count == 3)); <answer> 2) 
if <token> NULL) < 0) { <answer> (pthread_tryjoin_np(emitter, 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
<token> NULL); <answer> pthread_join(emitter, 
<token> emitter; <answer> pthread_t 
<token> epoll_event e; <answer> struct 
struct epoll_mtcontext ctx = { 0 <token> <answer> }; 
<token> signal_handler); <answer> signal(SIGUSR1, 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, ctx.sfd), <token> <answer> 0); 
<token> = epoll_create(1); <answer> ctx.efd[0] 
ASSERT_GE(ctx.efd[0], <token> <answer> 0); 
<token> = epoll_create(1); <answer> ctx.efd[1] 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
e.events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(ctx.efd[1], <token> ctx.sfd[0], &e), 0); <answer> EPOLL_CTL_ADD, 
e.events = EPOLLIN <token> EPOLLET; <answer> | 
ASSERT_EQ(epoll_ctl(ctx.efd[0], <token> ctx.efd[1], &e), 0); <answer> EPOLL_CTL_ADD, 
ctx.main = <token> <answer> pthread_self(); 
ASSERT_EQ(pthread_create(&ctx.waiter, <token> waiter_entry1a, &ctx), 0); <answer> NULL, 
ASSERT_EQ(pthread_create(&emitter, NULL, <token> &ctx), 0); <answer> emitter_entry1, 
if (epoll_wait(ctx.efd[1], &e, <token> -1) > 0) <answer> 1, 
<token> 1); <answer> __sync_fetch_and_add(&ctx.count, 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
<token> 2); <answer> EXPECT_EQ(ctx.count, 
if (pthread_tryjoin_np(emitter, NULL) < 0) <token> <answer> { 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
pthread_join(emitter, <token> <answer> NULL); 
pthread_t <token> <answer> emitter; 
<token> epoll_event e; <answer> struct 
<token> epoll_mtcontext ctx = { 0 }; <answer> struct 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, <token> 0, ctx.sfd), 0); <answer> SOCK_STREAM, 
ctx.efd[0] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
ctx.efd[1] <token> epoll_create(1); <answer> = 
ASSERT_GE(ctx.efd[1], <token> <answer> 0); 
<token> = EPOLLIN | EPOLLET; <answer> e.events 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, ctx.sfd[0], &e), <token> <answer> 0); 
e.events = EPOLLIN <token> EPOLLET; <answer> | 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.efd[1], <token> 0); <answer> &e), 
<token> = pthread_self(); <answer> ctx.main 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1o, &ctx), <token> <answer> 0); 
ASSERT_EQ(pthread_create(&emitter, <token> emitter_entry1, &ctx), 0); <answer> NULL, 
<token> (epoll_wait(ctx.efd[1], &e, 1, -1) > 0) <answer> if 
<token> 2); <answer> __sync_fetch_and_or(&ctx.count, 
ASSERT_EQ(pthread_join(ctx.waiter, NULL), <token> <answer> 0); 
EXPECT_TRUE((ctx.count <token> 2) || (ctx.count == 3)); <answer> == 
if (pthread_tryjoin_np(emitter, NULL) < <token> { <answer> 0) 
<token> SIGUSR1); <answer> pthread_kill(emitter, 
<token> NULL); <answer> pthread_join(emitter, 
<token> emitter; <answer> pthread_t 
<token> pollfd pfd; <answer> struct 
struct <token> e; <answer> epoll_event 
struct epoll_mtcontext ctx = { 0 <token> <answer> }; 
<token> signal_handler); <answer> signal(SIGUSR1, 
ASSERT_EQ(socketpair(AF_UNIX, <token> 0, ctx.sfd), 0); <answer> SOCK_STREAM, 
<token> = epoll_create(1); <answer> ctx.efd[0] 
ASSERT_GE(ctx.efd[0], <token> <answer> 0); 
ctx.efd[1] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
<token> = EPOLLIN; <answer> e.events 
<token> EPOLL_CTL_ADD, ctx.sfd[0], &e), 0); <answer> ASSERT_EQ(epoll_ctl(ctx.efd[1], 
e.events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(ctx.efd[0], <token> ctx.efd[1], &e), 0); <answer> EPOLL_CTL_ADD, 
ctx.main = <token> <answer> pthread_self(); 
<token> NULL, waiter_entry1a, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&ctx.waiter, 
ASSERT_EQ(pthread_create(&emitter, NULL, emitter_entry1, &ctx), <token> <answer> 0); 
pfd.fd = <token> <answer> ctx.efd[1]; 
pfd.events <token> POLLIN; <answer> = 
<token> (poll(&pfd, 1, -1) > 0) { <answer> if 
if (epoll_wait(ctx.efd[1], &e, 1, <token> > 0) <answer> 0) 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
<token> 2); <answer> EXPECT_EQ(ctx.count, 
if <token> NULL) < 0) { <answer> (pthread_tryjoin_np(emitter, 
<token> SIGUSR1); <answer> pthread_kill(emitter, 
<token> NULL); <answer> pthread_join(emitter, 
<token> emitter; <answer> pthread_t 
<token> pollfd pfd; <answer> struct 
<token> epoll_event e; <answer> struct 
struct epoll_mtcontext <token> = { 0 }; <answer> ctx 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, <token> ctx.sfd), 0); <answer> 0, 
ctx.efd[0] = <token> <answer> epoll_create(1); 
ASSERT_GE(ctx.efd[0], <token> <answer> 0); 
ctx.efd[1] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
e.events = EPOLLIN <token> EPOLLET; <answer> | 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, ctx.sfd[0], <token> 0); <answer> &e), 
<token> = EPOLLIN; <answer> e.events 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.efd[1], <token> 0); <answer> &e), 
ctx.main = <token> <answer> pthread_self(); 
<token> NULL, waiter_entry1o, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&ctx.waiter, 
ASSERT_EQ(pthread_create(&emitter, <token> emitter_entry1, &ctx), 0); <answer> NULL, 
pfd.fd = <token> <answer> ctx.efd[1]; 
pfd.events = <token> <answer> POLLIN; 
if <token> 1, -1) > 0) { <answer> (poll(&pfd, 
if (epoll_wait(ctx.efd[1], &e, <token> 0) > 0) <answer> 1, 
<token> 2); <answer> __sync_fetch_and_or(&ctx.count, 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
EXPECT_TRUE((ctx.count == 2) <token> (ctx.count == 3)); <answer> || 
if (pthread_tryjoin_np(emitter, NULL) < 0) <token> <answer> { 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
<token> NULL); <answer> pthread_join(emitter, 
<token> emitter; <answer> pthread_t 
struct <token> pfd; <answer> pollfd 
struct <token> e; <answer> epoll_event 
struct epoll_mtcontext ctx = { <token> }; <answer> 0 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, ctx.sfd), <token> <answer> 0); 
ctx.efd[0] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
<token> = epoll_create(1); <answer> ctx.efd[1] 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
e.events <token> EPOLLIN; <answer> = 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, ctx.sfd[0], &e), <token> <answer> 0); 
e.events = EPOLLIN | <token> <answer> EPOLLET; 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.efd[1], &e), <token> <answer> 0); 
<token> = pthread_self(); <answer> ctx.main 
ASSERT_EQ(pthread_create(&ctx.waiter, <token> waiter_entry1a, &ctx), 0); <answer> NULL, 
ASSERT_EQ(pthread_create(&emitter, NULL, <token> &ctx), 0); <answer> emitter_entry1, 
pfd.fd <token> ctx.efd[1]; <answer> = 
pfd.events <token> POLLIN; <answer> = 
<token> (poll(&pfd, 1, -1) > 0) { <answer> if 
if (epoll_wait(ctx.efd[1], <token> 1, 0) > 0) <answer> &e, 
<token> 1); <answer> __sync_fetch_and_add(&ctx.count, 
<token> NULL), 0); <answer> ASSERT_EQ(pthread_join(ctx.waiter, 
EXPECT_EQ(ctx.count, <token> <answer> 2); 
if (pthread_tryjoin_np(emitter, <token> < 0) { <answer> NULL) 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
pthread_join(emitter, <token> <answer> NULL); 
pthread_t <token> <answer> emitter; 
struct <token> pfd; <answer> pollfd 
<token> epoll_event e; <answer> struct 
struct epoll_mtcontext ctx = { 0 <token> <answer> }; 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, <token> 0); <answer> ctx.sfd), 
<token> = epoll_create(1); <answer> ctx.efd[0] 
ASSERT_GE(ctx.efd[0], <token> <answer> 0); 
ctx.efd[1] = <token> <answer> epoll_create(1); 
ASSERT_GE(ctx.efd[1], <token> <answer> 0); 
e.events <token> EPOLLIN | EPOLLET; <answer> = 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, ctx.sfd[0], &e), <token> <answer> 0); 
e.events = <token> | EPOLLET; <answer> EPOLLIN 
<token> EPOLL_CTL_ADD, ctx.efd[1], &e), 0); <answer> ASSERT_EQ(epoll_ctl(ctx.efd[0], 
ctx.main = <token> <answer> pthread_self(); 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1o, &ctx), <token> <answer> 0); 
ASSERT_EQ(pthread_create(&emitter, <token> emitter_entry1, &ctx), 0); <answer> NULL, 
<token> = ctx.efd[1]; <answer> pfd.fd 
<token> = POLLIN; <answer> pfd.events 
if (poll(&pfd, 1, -1) > 0) <token> <answer> { 
if <token> &e, 1, 0) > 0) <answer> (epoll_wait(ctx.efd[1], 
<token> 2); <answer> __sync_fetch_and_or(&ctx.count, 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
EXPECT_TRUE((ctx.count <token> 2) || (ctx.count == 3)); <answer> == 
if (pthread_tryjoin_np(emitter, NULL) < 0) <token> <answer> { 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
pthread_join(emitter, <token> <answer> NULL); 
pthread_t <token> <answer> emitter; 
struct epoll_event <token> <answer> e; 
struct epoll_mtcontext ctx = { 0 <token> <answer> }; 
signal(SIGUSR1, <token> <answer> signal_handler); 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, <token> 0); <answer> ctx.sfd), 
ctx.efd[0] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
ctx.efd[1] = <token> <answer> epoll_create(1); 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
<token> = EPOLLIN; <answer> e.events 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, ctx.sfd[0], <token> 0); <answer> &e), 
<token> = EPOLLIN; <answer> e.events 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, <token> &e), 0); <answer> ctx.efd[1], 
ctx.main <token> pthread_self(); <answer> = 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1ap, <token> 0); <answer> &ctx), 
<token> NULL, emitter_entry1, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&emitter, 
if <token> &e, 1, -1) > 0) <answer> (epoll_wait(ctx.efd[1], 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
EXPECT_EQ(ctx.count, <token> <answer> 2); 
if (pthread_tryjoin_np(emitter, <token> < 0) { <answer> NULL) 
<token> SIGUSR1); <answer> pthread_kill(emitter, 
pthread_join(emitter, <token> <answer> NULL); 
pthread_t <token> <answer> emitter; 
<token> epoll_event e; <answer> struct 
struct epoll_mtcontext <token> = { 0 }; <answer> ctx 
<token> signal_handler); <answer> signal(SIGUSR1, 
<token> SOCK_STREAM, 0, ctx.sfd), 0); <answer> ASSERT_EQ(socketpair(AF_UNIX, 
<token> = epoll_create(1); <answer> ctx.efd[0] 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
<token> = epoll_create(1); <answer> ctx.efd[1] 
ASSERT_GE(ctx.efd[1], <token> <answer> 0); 
e.events = EPOLLIN <token> EPOLLET; <answer> | 
ASSERT_EQ(epoll_ctl(ctx.efd[1], <token> ctx.sfd[0], &e), 0); <answer> EPOLL_CTL_ADD, 
e.events = <token> <answer> EPOLLIN; 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, <token> &e), 0); <answer> ctx.efd[1], 
ctx.main <token> pthread_self(); <answer> = 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1op, <token> 0); <answer> &ctx), 
ASSERT_EQ(pthread_create(&emitter, <token> emitter_entry1, &ctx), 0); <answer> NULL, 
if (epoll_wait(ctx.efd[1], &e, <token> -1) > 0) <answer> 1, 
__sync_fetch_and_or(&ctx.count, <token> <answer> 2); 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
EXPECT_TRUE((ctx.count <token> 2) || (ctx.count == 3)); <answer> == 
if (pthread_tryjoin_np(emitter, NULL) < 0) <token> <answer> { 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
<token> NULL); <answer> pthread_join(emitter, 
<token> emitter; <answer> pthread_t 
struct epoll_event <token> <answer> e; 
struct epoll_mtcontext ctx = { <token> }; <answer> 0 
<token> signal_handler); <answer> signal(SIGUSR1, 
ASSERT_EQ(socketpair(AF_UNIX, SOCK_STREAM, 0, <token> 0); <answer> ctx.sfd), 
ctx.efd[0] <token> epoll_create(1); <answer> = 
ASSERT_GE(ctx.efd[0], <token> <answer> 0); 
<token> = epoll_create(1); <answer> ctx.efd[1] 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
e.events <token> EPOLLIN; <answer> = 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, ctx.sfd[0], &e), <token> <answer> 0); 
e.events <token> EPOLLIN | EPOLLET; <answer> = 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.efd[1], &e), <token> <answer> 0); 
ctx.main = <token> <answer> pthread_self(); 
<token> NULL, waiter_entry1ap, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&ctx.waiter, 
<token> NULL, emitter_entry1, &ctx), 0); <answer> ASSERT_EQ(pthread_create(&emitter, 
if (epoll_wait(ctx.efd[1], &e, 1, -1) <token> 0) <answer> > 
__sync_fetch_and_add(&ctx.count, <token> <answer> 1); 
ASSERT_EQ(pthread_join(ctx.waiter, <token> 0); <answer> NULL), 
<token> 2); <answer> EXPECT_EQ(ctx.count, 
if (pthread_tryjoin_np(emitter, <token> < 0) { <answer> NULL) 
pthread_kill(emitter, <token> <answer> SIGUSR1); 
<token> NULL); <answer> pthread_join(emitter, 
pthread_t <token> <answer> emitter; 
<token> epoll_event e; <answer> struct 
struct epoll_mtcontext ctx = { <token> }; <answer> 0 
<token> signal_handler); <answer> signal(SIGUSR1, 
ASSERT_EQ(socketpair(AF_UNIX, <token> 0, ctx.sfd), 0); <answer> SOCK_STREAM, 
<token> = epoll_create(1); <answer> ctx.efd[0] 
<token> 0); <answer> ASSERT_GE(ctx.efd[0], 
ctx.efd[1] <token> epoll_create(1); <answer> = 
<token> 0); <answer> ASSERT_GE(ctx.efd[1], 
e.events = EPOLLIN | <token> <answer> EPOLLET; 
ASSERT_EQ(epoll_ctl(ctx.efd[1], EPOLL_CTL_ADD, <token> &e), 0); <answer> ctx.sfd[0], 
<token> = EPOLLIN | EPOLLET; <answer> e.events 
ASSERT_EQ(epoll_ctl(ctx.efd[0], EPOLL_CTL_ADD, ctx.efd[1], <token> 0); <answer> &e), 
ctx.main <token> pthread_self(); <answer> = 
ASSERT_EQ(pthread_create(&ctx.waiter, NULL, waiter_entry1op, &ctx), <token> <answer> 0); 
ASSERT_EQ(pthread_create(&emitter, NULL, emitter_entry1, <token> 0); <answer> &ctx), 
<token> <linux/clk-provider.h> <answer> #include 
#include <token> <answer> <linux/err.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/of_address.h> 
#include <token> <answer> "icst.h" 
<token> "clk-icst.h" <answer> #include 
<token> INTEGRATOR_HDR_LOCK_OFFSET 0x14 <answer> #define 
#define <token> 0x1c <answer> VERSATILE_SYS_OSCCLCD_OFFSET 
#define <token> 0x20 <answer> VERSATILE_SYS_LOCK_OFFSET 
#include <token> <answer> <linux/sort.h> 
<token> "intel_engine_regs.h" <answer> #include 
#include <token> <answer> "intel_gt_clock_utils.h" 
<token> "selftest_llc.h" <answer> #include 
<token> "selftest_rc6.h" <answer> #include 
#include <token> <answer> "selftest_rps.h" 
static int <token> void *A, const void *B) <answer> cmp_u64(const 
const u64 *a = A, *b <token> B; <answer> = 
if (a < <token> <answer> b) 
return <token> <answer> -1; 
else <token> (a > b) <answer> if 
return <token> <answer> 1; 
<token> 0; <answer> return 
static int cmp_u32(const void *A, const void <token> <answer> *B) 
<token> u32 *a = A, *b = B; <answer> const 
<token> (a < b) <answer> if 
<token> -1; <answer> return 
else if (a <token> b) <answer> > 
<token> 1; <answer> return 
return <token> <answer> 0; 
static u32 read_timestamp(struct intel_engine_cs <token> <answer> *engine) 
<token> drm_i915_private *i915 = engine->i915; <answer> struct 
<token> (intel_gt_is_wedged(to_gt(i915))) <answer> if 
return <token> <answer> 0; 
<token> intel_gt_live_subtests(tests, to_gt(i915)); <answer> return 
<token> <linux/mm.h> <answer> #include 
#include <token> <answer> <linux/mmzone.h> 
<token> <linux/page_reporting.h> <answer> #include 
<token> <linux/gfp.h> <answer> #include 
#include <token> <answer> <linux/export.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/scatterlist.h> <answer> #include 
<token> "page_reporting.h" <answer> #include 
<token> "internal.h" <answer> #include 
return <token> kp, 0, MAX_PAGE_ORDER); <answer> param_set_uint_minmax(val, 
static <token> struct kernel_param_ops page_reporting_param_ops = { <answer> const 
<token> = &page_order_update_notify, <answer> .set 
<token> = &param_get_int, <answer> .get 
<token> &page_reporting_param_ops, <answer> module_param_cb(page_reporting_order, 
&page_reporting_order, <token> <answer> 0644); 
MODULE_PARM_DESC(page_reporting_order, "Set page reporting <token> <answer> order"); 
#define PAGE_REPORTING_DELAY (2 * <token> <answer> HZ) 
static struct page_reporting_dev_info <token> *pr_dev_info __read_mostly; <answer> __rcu 
<token> { <answer> enum 
PAGE_REPORTING_IDLE = <token> <answer> 0, 
state = atomic_xchg(&prdev->state, <token> <answer> PAGE_REPORTING_REQUESTED); 
if (state <token> PAGE_REPORTING_IDLE) <answer> != 
<token> PAGE_REPORTING_DELAY); <answer> schedule_delayed_work(&prdev->work, 
prdev = <token> <answer> rcu_dereference(pr_dev_info); 
<token> (likely(prdev)) <answer> if 
<token> void <answer> static 
page_reporting_drain(struct <token> *prdev, <answer> page_reporting_dev_info 
struct scatterlist *sgl, unsigned int nents, <token> reported) <answer> bool 
struct scatterlist <token> = sgl; <answer> *sg 
<token> { <answer> do 
struct page <token> = sg_page(sg); <answer> *page 
int mt <token> get_pageblock_migratetype(page); <answer> = 
unsigned <token> order = get_order(sg->length); <answer> int 
__putback_isolated_page(page, order, <token> <answer> mt); 
if (PageBuddy(page) && buddy_order(page) == <token> <answer> order) 
} while <token> = sg_next(sg))); <answer> ((sg 
static <token> <answer> int 
page_reporting_cycle(struct page_reporting_dev_info *prdev, struct zone <token> <answer> *zone, 
<token> int order, unsigned int mt, <answer> unsigned 
struct scatterlist *sgl, <token> int *offset) <answer> unsigned 
struct free_area *area = <token> <answer> &zone->free_area[order]; 
struct list_head *list <token> &area->free_list[mt]; <answer> = 
unsigned <token> page_len = PAGE_SIZE << order; <answer> int 
struct page *page, <token> <answer> *next; 
long <token> <answer> budget; 
int <token> = 0; <answer> err 
<token> (list_empty(list)) <answer> if 
<token> err; <answer> return 
budget = <token> PAGE_REPORTING_CAPACITY * 16); <answer> DIV_ROUND_UP(area->nr_free, 
<token> (budget < 0) { <answer> if 
atomic_set(&prdev->state, <token> <answer> PAGE_REPORTING_REQUESTED); 
<token> = page; <answer> next 
<token> (!list_is_first(&page->lru, list)) <answer> if 
list_rotate_to_front(&page->lru, <token> <answer> list); 
next = <token> struct page, lru); <answer> list_first_entry(list, 
<token> (!zone_watermark_ok(zone, 0, watermark, 0, ALLOC_CMA)) <answer> if 
return <token> <answer> err; 
<token> state); <answer> atomic_set(&prdev->state, 
state = <token> state, PAGE_REPORTING_IDLE); <answer> atomic_cmpxchg(&prdev->state, 
if <token> == PAGE_REPORTING_REQUESTED) <answer> (state 
schedule_delayed_work(&prdev->work, <token> <answer> PAGE_REPORTING_DELAY); 
static <token> <answer> DEFINE_MUTEX(page_reporting_mutex); 
int <token> page_reporting_dev_info *prdev) <answer> page_reporting_register(struct 
int err = <token> <answer> 0; 
if (page_reporting_order == -1) <token> <answer> { 
if (prdev->order > 0 && <token> <= MAX_PAGE_ORDER) <answer> prdev->order 
page_reporting_order = <token> <answer> prdev->order; 
page_reporting_order <token> pageblock_order; <answer> = 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/usb.h> 
<token> "main.h" <answer> #include 
<token> "rtw8821c.h" <answer> #include 
<token> "usb.h" <answer> #include 
static const <token> usb_device_id rtw_8821cu_id_table[] = { <answer> struct 
{ USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, 0x2006, 0xff, 0xff, <token> <answer> 0xff), 
.driver_info <token> (kernel_ulong_t)&(rtw8821c_hw_spec) }, <answer> = 
{ USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, 0x8731, 0xff, 0xff, <token> <answer> 0xff), 
.driver_info = <token> }, <answer> (kernel_ulong_t)&(rtw8821c_hw_spec) 
{ USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, 0x8811, <token> 0xff, 0xff), <answer> 0xff, 
.driver_info = (kernel_ulong_t)&(rtw8821c_hw_spec) <token> <answer> }, 
{ USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, <token> 0xff, 0xff, 0xff), <answer> 0xb820, 
.driver_info <token> (kernel_ulong_t)&(rtw8821c_hw_spec) }, <answer> = 
{ USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, 0xb82b, 0xff, 0xff, <token> <answer> 0xff), 
.driver_info = (kernel_ulong_t)&(rtw8821c_hw_spec) <token> <answer> }, 
{ USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, 0xc80c, 0xff, 0xff, <token> <answer> 0xff), 
.driver_info = <token> }, <answer> (kernel_ulong_t)&(rtw8821c_hw_spec) 
{ USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, <token> 0xff, 0xff, 0xff), <answer> 0xc811, 
.driver_info = <token> }, <answer> (kernel_ulong_t)&(rtw8821c_hw_spec) 
<token> USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, 0xc820, 0xff, 0xff, 0xff), <answer> { 
<token> = (kernel_ulong_t)&(rtw8821c_hw_spec) }, <answer> .driver_info 
<token> USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, 0xc821, 0xff, 0xff, 0xff), <answer> { 
<token> = (kernel_ulong_t)&(rtw8821c_hw_spec) }, <answer> .driver_info 
{ USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, 0xc82a, 0xff, 0xff, <token> <answer> 0xff), 
.driver_info = <token> }, <answer> (kernel_ulong_t)&(rtw8821c_hw_spec) 
{ USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, 0xc82b, <token> 0xff, 0xff), <answer> 0xff, 
.driver_info = (kernel_ulong_t)&(rtw8821c_hw_spec) <token> <answer> }, 
{ <token> 0xc82c, 0xff, 0xff, 0xff), <answer> USB_DEVICE_AND_INTERFACE_INFO(RTW_USB_VENDOR_ID_REALTEK, 
.driver_info = <token> }, <answer> (kernel_ulong_t)&(rtw8821c_hw_spec) 
{ USB_DEVICE_AND_INTERFACE_INFO(0x2001, 0x331d, <token> 0xff, 0xff), <answer> 0xff, 
<token> <linux/gfp.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/irq.h> <answer> #include 
#include <token> <answer> <linux/gpio/consumer.h> 
#include <token> <answer> <linux/libata.h> 
#include <token> <answer> <scsi/scsi_host.h> 
<token> <asm/mach-rc32434/rb.h> <answer> #include 
<token> DRV_NAME "pata-rb532-cf" <answer> #define 
#define <token> "0.1.0" <answer> DRV_VERSION 
#define <token> "PATA driver for RouterBOARD 532 Compact Flash" <answer> DRV_DESC 
<token> RB500_CF_MAXPORTS 1 <answer> #define 
<token> RB500_CF_IO_DELAY 400 <answer> #define 
#define RB500_CF_REG_BASE <token> <answer> 0x0800 
<token> RB500_CF_REG_ERR 0x080D <answer> #define 
#define RB500_CF_REG_CTRL <token> <answer> 0x080E 
#include <token> <answer> <media/rc-map.h> 
<token> <linux/module.h> <answer> #include 
static <token> rc_map_table rc5_hauppauge_new[] = { <answer> struct 
{ 0x1d00, <token> }, <answer> KEY_NUMERIC_0 
{ <token> KEY_NUMERIC_1 }, <answer> 0x1d01, 
<token> 0x1d02, KEY_NUMERIC_2 }, <answer> { 
<token> 0x1d03, KEY_NUMERIC_3 }, <answer> { 
<token> 0x1d04, KEY_NUMERIC_4 }, <answer> { 
{ <token> KEY_NUMERIC_5 }, <answer> 0x1d05, 
{ 0x1d06, <token> }, <answer> KEY_NUMERIC_6 
{ <token> KEY_NUMERIC_7 }, <answer> 0x1d07, 
<token> 0x1d08, KEY_NUMERIC_8 }, <answer> { 
{ 0x1d09, KEY_NUMERIC_9 <token> <answer> }, 
{ <token> KEY_TEXT }, <answer> 0x1d0a, 
{ 0x1d0d, KEY_MENU <token> <answer> }, 
{ 0x1d0f, <token> }, <answer> KEY_MUTE 
{ 0x1d10, KEY_VOLUMEUP <token> <answer> }, 
{ <token> KEY_VOLUMEDOWN }, <answer> 0x1d11, 
{ 0x1c3b, KEY_GOTO <token> <answer> }, 
<token> 0x1c3d, KEY_POWER }, <answer> { 
{ 0x1c14, <token> }, <answer> KEY_UP 
{ 0x1c15, KEY_DOWN <token> <answer> }, 
{ 0x1c16, KEY_LEFT <token> <answer> }, 
{ 0x1c17, KEY_RIGHT <token> <answer> }, 
{ 0x1c25, KEY_OK <token> <answer> }, 
{ 0x1c00, <token> }, <answer> KEY_NUMERIC_0 
{ 0x1c01, KEY_NUMERIC_1 <token> <answer> }, 
<token> 0x1c02, KEY_NUMERIC_2 }, <answer> { 
{ <token> KEY_NUMERIC_3 }, <answer> 0x1c03, 
{ 0x1c04, <token> }, <answer> KEY_NUMERIC_4 
{ 0x1c05, <token> }, <answer> KEY_NUMERIC_5 
<token> 0x1c06, KEY_NUMERIC_6 }, <answer> { 
<token> 0x1c07, KEY_NUMERIC_7 }, <answer> { 
{ 0x1c08, KEY_NUMERIC_8 <token> <answer> }, 
{ <token> KEY_NUMERIC_9 }, <answer> 0x1c09, 
<token> 0x000f, KEY_TV }, <answer> { 
<token> 0x001f, KEY_TV }, <answer> { 
{ 0x0020, KEY_CHANNELUP <token> <answer> }, 
{ 0x000c, KEY_RADIO <token> <answer> }, 
<token> 0x0011, KEY_VOLUMEDOWN }, <answer> { 
#include <token> <answer> <stdio.h> 
#include <token> <answer> <unistd.h> 
<token> <sys/syscall.h> <answer> #include 
#include <token> <answer> <sys/time.h> 
#include <token> <answer> <sys/types.h> 
<token> <sys/wait.h> <answer> #include 
#include <token> <answer> <stdlib.h> 
<token> <pthread.h> <answer> #include 
#include <token> <answer> "utils.h" 
<token> "fpu.h" <answer> #include 
<token> THREAD_FACTOR 8 <answer> #define 
<token> double darray[32]; <answer> __thread 
int <token> <answer> threads_starting; 
<token> running; <answer> int 
extern int preempt_fpu(double <token> int *threads_starting, int *running); <answer> *darray, 
void <token> *p) <answer> *preempt_fpu_c(void 
long <token> <answer> rc; 
<token> ARRAY_SIZE(darray)); <answer> randomise_darray(darray, 
rc <token> preempt_fpu(darray, &threads_starting, &running); <answer> = 
return <token> *)rc; <answer> (void 
int <token> <answer> test_preempt_fpu(void) 
int i, rc, <token> <answer> threads; 
pthread_t <token> <answer> *tids; 
threads <token> sysconf(_SC_NPROCESSORS_ONLN) * THREAD_FACTOR; <answer> = 
tids = malloc((threads) * <token> <answer> sizeof(pthread_t)); 
running <token> true; <answer> = 
threads_starting = <token> <answer> threads; 
<token> (i = 0; i < threads; i++) { <answer> for 
rc = <token> NULL, preempt_fpu_c, NULL); <answer> pthread_create(&tids[i], 
<token> NULL); <answer> setbuf(stdout, 
running <token> 0; <answer> = 
for (i <token> 0; i < threads; i++) { <answer> = 
void <token> <answer> *rc_p; 
<token> &rc_p); <answer> pthread_join(tids[i], 
<token> ((long) rc_p) <answer> if 
<token> rc_p); <answer> FAIL_IF((long) 
<token> 0; <answer> return 
<token> main(int argc, char *argv[]) <answer> int 
<token> test_harness(test_preempt_fpu, "fpu_preempt"); <answer> return 
<token> <stdio.h> <answer> #include 
#include <token> <answer> <stdbool.h> 
#include <token> <answer> <stdarg.h> 
#include <token> <answer> <assert.h> 
<token> <malloc.h> <answer> #include 
<token> <inttypes.h> <answer> #include 
#include <token> <answer> <stdint.h> 
<token> "json_writer.h" <answer> #include 
<token> json_writer { <answer> struct 
#include <token> <answer> <linux/types.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/delay.h> <answer> #include 
<token> <linux/sched.h> <answer> #include 
#include <token> <answer> <linux/i2c.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/spinlock.h> <answer> #include 
#include <token> <answer> <linux/wait.h> 
#include <token> <answer> <linux/suspend.h> 
#include <token> <answer> <linux/kthread.h> 
#include <token> <answer> <linux/moduleparam.h> 
#include <token> <answer> <linux/freezer.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_platform.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <asm/machdep.h> <answer> #include 
#include <token> <answer> <asm/io.h> 
#include <token> <answer> <asm/sections.h> 
#undef <token> <answer> DEBUG 
<token> CONFIG_REG 0x40 <answer> #define 
<token> MANUAL_MASK 0xe0 <answer> #define 
#define <token> 0x20 <answer> AUTO_MASK 
<token> INVERT_MASK 0x10 <answer> #define 
if (abs(var - th->last_var[fan_number]) <token> 2) <answer> < 
started = <token> <answer> true; 
new_speed = fan_speed <token> ((var-1)*step); <answer> + 
if <token> < fan_speed) <answer> (new_speed 
new_speed = <token> <answer> fan_speed; 
<token> (new_speed > 255) <answer> if 
new_speed <token> 255; <answer> = 
if <token> <answer> (verbose) 
<token> "adt746x: Setting fans speed to %d " <answer> printk(KERN_DEBUG 
"(limit exceeded by %d on <token> <answer> %s)\n", 
<token> var, <answer> new_speed, 
write_both_fan_speed(th, <token> <answer> new_speed); 
th->last_var[fan_number] <token> var; <answer> = 
} else if (var <token> -2) { <answer> < 
<token> (i == 2 && lastvar < -1) { <answer> if 
if (th->last_speed[fan_number] != <token> <answer> 0) 
if <token> <answer> (verbose) 
printk(KERN_DEBUG "adt746x: <token> " <answer> Stopping 
<token> 0); <answer> write_both_fan_speed(th, 
lastvar <token> var; <answer> = 
if <token> <answer> (started) 
static int monitor_task(void <token> <answer> *arg) 
struct thermostat* th <token> arg; <answer> = 
while(!kthread_should_stop()) <token> <answer> { 
<token> DEBUG <answer> #ifndef 
<token> (fan_speed != -1) <answer> if 
if (fan_speed != <token> <answer> -1) 
#ifdef <token> <answer> DEBUG 
return <token> <answer> 0; 
static void set_limit(struct thermostat *th, int <token> <answer> i) 
<token> = of_platform_device_create(np, "temperatures", NULL); <answer> th->pdev 
if <token> <answer> (!th->pdev) 
dev = <token> <answer> &th->pdev->dev; 
dev_set_drvdata(dev, <token> <answer> th); 
err = device_create_file(dev, <token> <answer> &dev_attr_sensor1_temperature); 
err |= device_create_file(dev, <token> <answer> &dev_attr_sensor2_temperature); 
err |= <token> &dev_attr_sensor1_limit); <answer> device_create_file(dev, 
err |= device_create_file(dev, <token> <answer> &dev_attr_sensor2_limit); 
<token> |= device_create_file(dev, &dev_attr_sensor1_location); <answer> err 
err <token> device_create_file(dev, &dev_attr_sensor2_location); <answer> |= 
err <token> device_create_file(dev, &dev_attr_limit_adjust); <answer> |= 
err |= <token> &dev_attr_specified_fan_speed); <answer> device_create_file(dev, 
err |= <token> &dev_attr_sensor1_fan_speed); <answer> device_create_file(dev, 
if(th->type <token> ADT7460) <answer> == 
err |= <token> &dev_attr_sensor2_fan_speed); <answer> device_create_file(dev, 
if <token> <answer> (err) 
"Failed <token> create temperature attribute file(s).\n"); <answer> to 
<token> void thermostat_remove_files(struct thermostat *th) <answer> static 
<token> device *dev; <answer> struct 
if <token> <answer> (!th->pdev) 
dev <token> &th->pdev->dev; <answer> = 
device_remove_file(dev, <token> <answer> &dev_attr_sensor1_temperature); 
<token> &dev_attr_sensor2_temperature); <answer> device_remove_file(dev, 
<token> &dev_attr_sensor1_limit); <answer> device_remove_file(dev, 
<token> &dev_attr_sensor2_limit); <answer> device_remove_file(dev, 
device_remove_file(dev, <token> <answer> &dev_attr_sensor1_location); 
device_remove_file(dev, <token> <answer> &dev_attr_sensor2_location); 
<token> &dev_attr_limit_adjust); <answer> device_remove_file(dev, 
device_remove_file(dev, <token> <answer> &dev_attr_specified_fan_speed); 
device_remove_file(dev, <token> <answer> &dev_attr_sensor1_fan_speed); 
<token> (th->type == ADT7460) <answer> if 
device_remove_file(dev, <token> <answer> &dev_attr_sensor2_fan_speed); 
static int probe_thermostat(struct <token> *client) <answer> i2c_client 
<token> struct i2c_device_id *id = i2c_client_get_device_id(client); <answer> const 
struct device_node *np = <token> <answer> client->dev.of_node; 
struct <token> th; <answer> thermostat* 
<token> __be32 *prop; <answer> const 
<token> i, rc, vers, offset = 0; <answer> int 
if <token> <answer> (!np) 
return <token> <answer> -ENXIO; 
prop = <token> "hwsensor-params-version", NULL); <answer> of_get_property(np, 
if <token> <answer> (!prop) 
<token> -ENXIO; <answer> return 
vers <token> be32_to_cpup(prop); <answer> = 
printk(KERN_INFO <token> version %d (%ssupported)\n", <answer> "adt746x: 
vers, vers == 1 <token> "" : "un"); <answer> ? 
if <token> != 1) <answer> (vers 
<token> -ENXIO; <answer> return 
if (of_property_present(np, <token> { <answer> "hwsensor-location")) 
for (i <token> 0; i < 3; i++) { <answer> = 
sensor_location[i] = <token> <answer> of_get_property(np, 
<token> NULL) + offset; <answer> "hwsensor-location", 
<token> (sensor_location[i] == NULL) <answer> if 
<token> = ""; <answer> sensor_location[i] 
printk(KERN_INFO <token> %d: %s\n", i, sensor_location[i]); <answer> "sensor 
offset <token> strlen(sensor_location[i]) + 1; <answer> += 
th <token> kzalloc(sizeof(struct thermostat), GFP_KERNEL); <answer> = 
<token> (!th) <answer> if 
return <token> <answer> -ENOMEM; 
<token> th); <answer> i2c_set_clientdata(client, 
<token> = client; <answer> th->clt 
th->type <token> id->driver_data; <answer> = 
rc = <token> CONFIG_REG); <answer> read_reg(th, 
if (rc < <token> { <answer> 0) 
dev_err(&client->dev, "Thermostat <token> to read config!\n"); <answer> failed 
<token> -ENODEV; <answer> return 
#include <token> <answer> <linux/module.h> 
<token> <linux/trace_events.h> <answer> #include 
static struct trace_event_file <token> <answer> *create_synth_test; 
<token> struct trace_event_file *empty_synth_test; <answer> static 
static <token> trace_event_file *gen_synth_test; <answer> struct 
static int <token> test_gen_synth_cmd(void) <answer> __init 
<token> dynevent_cmd cmd; <answer> struct 
u64 <token> <answer> vals[7]; 
<token> *buf; <answer> char 
int <token> <answer> ret; 
ret <token> synth_event_gen_cmd_start(&cmd, "gen_synth_test", THIS_MODULE, <answer> = 
"pid_t", <token> <answer> "next_pid_field", 
<token> "next_comm_field", <answer> "char[16]", 
<token> "ts_ns", <answer> "u64", 
<token> "ts_ms"); <answer> "u64", 
if <token> <answer> (ret) 
goto <token> <answer> free; 
gen_synth_test <token> trace_get_event_file(NULL, "synthetic", <answer> = 
<token> (IS_ERR(gen_synth_test)) { <answer> if 
<token> = PTR_ERR(gen_synth_test); <answer> ret 
goto <token> <answer> delete; 
<token> int __init test_empty_synth_event(void) <answer> static 
<token> dynevent_cmd cmd; <answer> struct 
u64 <token> <answer> vals[7]; 
<token> *buf; <answer> char 
<token> ret; <answer> int 
ret = synth_event_gen_cmd_start(&cmd, <token> THIS_MODULE); <answer> "empty_synth_test", 
if <token> <answer> (ret) 
<token> free; <answer> goto 
empty_synth_test <token> trace_get_event_file(NULL, "synthetic", <answer> = 
<token> (IS_ERR(empty_synth_test)) { <answer> if 
<token> = PTR_ERR(empty_synth_test); <answer> ret 
<token> delete; <answer> goto 
static int <token> test_create_synth_event(void) <answer> __init 
u64 <token> <answer> vals[9]; 
<token> ret; <answer> int 
create_synth_test = trace_get_event_file(NULL, <token> <answer> "synthetic", 
<token> (IS_ERR(create_synth_test)) { <answer> if 
ret <token> PTR_ERR(create_synth_test); <answer> = 
<token> delete; <answer> goto 
<token> int __init test_add_next_synth_val(void) <answer> static 
<token> synth_event_trace_state trace_state; <answer> struct 
<token> ret; <answer> int 
static int __init <token> <answer> test_add_synth_val(void) 
<token> synth_event_trace_state trace_state; <answer> struct 
int <token> <answer> ret; 
static int <token> test_trace_synth_event(void) <answer> __init 
<token> ret; <answer> int 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/pci.h> 
<token> <linux/pci_ids.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <sound/pcm.h> <answer> #include 
#include <token> <answer> <sound/hda_register.h> 
#include <token> <answer> <sound/hdaudio_ext.h> 
<token> <sound/compress_driver.h> <answer> #include 
int snd_hdac_ext_host_stream_setup(struct hdac_ext_stream <token> bool code_loading) <answer> *hext_stream, 
<token> hext_stream->host_setup(hdac_stream(hext_stream), code_loading); <answer> return 
<token> int snd_hdac_apl_host_stream_setup(struct hdac_stream *hstream, bool code_loading) <answer> static 
struct hdac_ext_stream *hext_stream = <token> <answer> stream_to_hdac_ext_stream(hstream); 
<token> ret; <answer> int 
snd_hdac_ext_stream_decouple(hstream->bus, hext_stream, <token> <answer> false); 
<token> = snd_hdac_stream_setup(hstream, code_loading); <answer> ret 
<token> hext_stream, true); <answer> snd_hdac_ext_stream_decouple(hstream->bus, 
<token> ret; <answer> return 
static <token> snd_hdac_ext_stream_init(struct hdac_bus *bus, <answer> void 
<token> hdac_ext_stream *hext_stream, <answer> struct 
int idx, int <token> int tag) <answer> direction, 
<token> (bus->ppcap) { <answer> if 
hext_stream->pphc_addr = bus->ppcap <token> AZX_PPHC_BASE + <answer> + 
<token> * idx; <answer> AZX_PPHC_INTERVAL 
hext_stream->pplc_addr = bus->ppcap + AZX_PPLC_BASE <token> <answer> + 
AZX_PPLC_MULTI * <token> + <answer> bus->num_streams 
AZX_PPLC_INTERVAL * <token> <answer> idx; 
<token> = false; <answer> hext_stream->decoupled 
<token> &hext_stream->hstream, idx, direction, tag); <answer> snd_hdac_stream_init(bus, 
int snd_hdac_ext_stream_init_all(struct hdac_bus *bus, <token> start_idx, <answer> int 
int <token> int dir) <answer> num_stream, 
struct pci_dev *pci <token> to_pci_dev(bus->dev); <answer> = 
int <token> hdac_stream *, bool); <answer> (*setup_op)(struct 
int <token> = 0; <answer> stream_tag 
<token> i, tag, idx = start_idx; <answer> int 
if (pci->device <token> PCI_DEVICE_ID_INTEL_HDA_APL) <answer> == 
setup_op = <token> <answer> snd_hdac_apl_host_stream_setup; 
<token> = snd_hdac_stream_setup; <answer> setup_op 
for (i <token> 0; i < num_stream; i++) { <answer> = 
<token> hdac_ext_stream *hext_stream = <answer> struct 
<token> GFP_KERNEL); <answer> kzalloc(sizeof(*hext_stream), 
<token> (!hext_stream) <answer> if 
<token> -ENOMEM; <answer> return 
tag = <token> <answer> ++stream_tag; 
snd_hdac_ext_stream_init(bus, <token> idx, dir, tag); <answer> hext_stream, 
<token> = setup_op; <answer> hext_stream->host_setup 
return <token> <answer> 0; 
void snd_hdac_ext_stream_free_all(struct hdac_bus <token> <answer> *bus) 
<token> hdac_stream *s, *_s; <answer> struct 
<token> hdac_ext_stream *hext_stream; <answer> struct 
list_for_each_entry_safe(s, <token> &bus->stream_list, list) { <answer> _s, 
hext_stream = <token> <answer> stream_to_hdac_ext_stream(s); 
snd_hdac_ext_stream_decouple(bus, <token> false); <answer> hext_stream, 
void snd_hdac_ext_stream_decouple_locked(struct hdac_bus <token> <answer> *bus, 
<token> hdac_ext_stream *hext_stream, <answer> struct 
bool <token> <answer> decouple) 
struct hdac_stream *hstream <token> &hext_stream->hstream; <answer> = 
u32 <token> <answer> val; 
int <token> = AZX_PPCTL_PROCEN(hstream->index); <answer> mask 
val = readw(bus->ppcap + AZX_REG_PP_PPCTL) & <token> <answer> mask; 
<token> (decouple && !val) <answer> if 
snd_hdac_updatel(bus->ppcap, AZX_REG_PP_PPCTL, mask, <token> <answer> mask); 
else if (!decouple && <token> <answer> val) 
snd_hdac_updatel(bus->ppcap, AZX_REG_PP_PPCTL, <token> 0); <answer> mask, 
hext_stream->decoupled = <token> <answer> decouple; 
void snd_hdac_ext_stream_decouple(struct <token> *bus, <answer> hdac_bus 
struct hdac_ext_stream *hext_stream, bool <token> <answer> decouple) 
snd_hdac_ext_stream_decouple_locked(bus, <token> decouple); <answer> hext_stream, 
void <token> hdac_ext_stream *hext_stream) <answer> snd_hdac_ext_stream_start(struct 
snd_hdac_updatel(hext_stream->pplc_addr, <token> <answer> AZX_REG_PPLCCTL, 
AZX_PPLCCTL_RUN, <token> <answer> AZX_PPLCCTL_RUN); 
void <token> hdac_ext_stream *hext_stream) <answer> snd_hdac_ext_stream_clear(struct 
<token> AZX_REG_PPLCCTL, AZX_PPLCCTL_RUN, 0); <answer> snd_hdac_updatel(hext_stream->pplc_addr, 
void <token> hdac_ext_stream *hext_stream) <answer> snd_hdac_ext_stream_reset(struct 
unsigned <token> val; <answer> char 
int <token> <answer> timeout; 
snd_hdac_updatel(hext_stream->pplc_addr, <token> <answer> AZX_REG_PPLCCTL, 
AZX_PPLCCTL_STRST, <token> <answer> AZX_PPLCCTL_STRST); 
timeout = <token> <answer> 50; 
do <token> <answer> { 
val = readl(hext_stream->pplc_addr + AZX_REG_PPLCCTL) <token> <answer> & 
<token> (val) <answer> if 
<token> while (--timeout); <answer> } 
val &= <token> <answer> ~AZX_PPLCCTL_STRST; 
writel(val, hext_stream->pplc_addr <token> AZX_REG_PPLCCTL); <answer> + 
timeout <token> 50; <answer> = 
int <token> hdac_ext_stream *hext_stream, int fmt) <answer> snd_hdac_ext_stream_setup(struct 
<token> hdac_stream *hstream = &hext_stream->hstream; <answer> struct 
unsigned int <token> <answer> val; 
struct hdac_ext_stream <token> hdac_bus *bus, <answer> *snd_hdac_ext_stream_assign(struct 
struct snd_pcm_substream <token> <answer> *substream, 
<token> type) <answer> int 
<token> hdac_ext_stream *hext_stream = NULL; <answer> struct 
struct hdac_stream *hstream <token> NULL; <answer> = 
switch (type) <token> <answer> { 
case <token> <answer> HDAC_EXT_STREAM_TYPE_COUPLED: 
hstream <token> snd_hdac_stream_assign(bus, substream); <answer> = 
<token> (hstream) <answer> if 
hext_stream = <token> <answer> container_of(hstream, 
<token> hdac_ext_stream, <answer> struct 
return <token> <answer> hext_stream; 
case <token> <answer> HDAC_EXT_STREAM_TYPE_HOST: 
return hdac_ext_host_dma_stream_assign(bus, <token> <answer> substream); 
<token> HDAC_EXT_STREAM_TYPE_LINK: <answer> case 
<token> hdac_ext_link_dma_stream_assign(bus, substream); <answer> return 
<token> NULL; <answer> return 
void snd_hdac_ext_stream_release(struct hdac_ext_stream *hext_stream, int <token> <answer> type) 
<token> hdac_bus *bus = hext_stream->hstream.bus; <answer> struct 
switch (type) <token> <answer> { 
<token> HDAC_EXT_STREAM_TYPE_COUPLED: <answer> case 
case <token> <answer> HDAC_EXT_STREAM_TYPE_HOST: 
struct <token> *snd_hdac_ext_cstream_assign(struct hdac_bus *bus, <answer> hdac_ext_stream 
struct <token> *cstream) <answer> snd_compr_stream 
struct hdac_ext_stream <token> = NULL; <answer> *res 
<token> hdac_stream *hstream; <answer> struct 
list_for_each_entry(hstream, &bus->stream_list, list) <token> <answer> { 
<token> hdac_ext_stream *hext_stream = stream_to_hdac_ext_stream(hstream); <answer> struct 
if (hstream->direction <token> cstream->direction) <answer> != 
if (!hstream->opened) <token> <answer> { 
res = <token> <answer> hext_stream; 
if (res) <token> <answer> { 
snd_hdac_ext_stream_decouple_locked(bus, res, <token> <answer> true); 
res->hstream.opened <token> 1; <answer> = 
res->hstream.running = <token> <answer> 0; 
res->hstream.cstream <token> cstream; <answer> = 
<token> res; <answer> return 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> "echo.h" 
#define <token> 64 <answer> MIN_TX_POWER_FOR_ADAPTION 
#define <token> 64 <answer> MIN_RX_POWER_FOR_ADAPTION 
<token> = tx; <answer> ec->tx 
ec->rx <token> rx; <answer> = 
tx >>= <token> <answer> 1; 
rx >>= <token> <answer> 1; 
<token> (ec->adaption_mode & ECHO_CAN_USE_RX_HPF) { <answer> if 
tmp = rx <token> 15; <answer> << 
tmp -= (tmp <token> 4); <answer> >> 
ec->rx_1 += -(ec->rx_1 >> DC_LOG2BETA) + <token> - ec->rx_2; <answer> tmp 
tmp1 = ec->rx_1 >> <token> <answer> 15; 
<token> (tmp1 > 16383) <answer> if 
tmp1 <token> 16383; <answer> = 
if (tmp1 <token> -16383) <answer> < 
tmp1 <token> -16383; <answer> = 
rx <token> tmp1; <answer> = 
ec->rx_2 <token> tmp; <answer> = 
int new, <token> <answer> old; 
new <token> (int)tx * (int)tx; <answer> = 
old <token> (int)ec->fir_state.history[ec->fir_state.curr_pos] * <answer> = 
<token> += <answer> ec->pstates 
((new <token> old) + (1 << (ec->log2taps - 1))) >> ec->log2taps; <answer> - 
if <token> < 0) <answer> (ec->pstates 
ec->pstates <token> 0; <answer> = 
ec->factor <token> 0; <answer> = 
ec->shift <token> 0; <answer> = 
<token> (!ec->nonupdate_dwell) { <answer> if 
int <token> logp, shift; <answer> p, 
<token> = MIN_TX_POWER_FOR_ADAPTION + ec->pstates; <answer> p 
logp = top_bit(p) + <token> <answer> ec->log2taps; 
shift = 30 - 2 - <token> <answer> logp; 
<token> = shift; <answer> ec->shift 
lms_adapt_bg(ec, clean_bg, <token> <answer> shift); 
<token> = 0; <answer> ec->adapt 
if ((ec->lrx > MIN_RX_POWER_FOR_ADAPTION) && (ec->lrx <token> ec->ltx)) <answer> > 
ec->nonupdate_dwell <token> DTD_HANGOVER; <answer> = 
<token> (ec->nonupdate_dwell) <answer> if 
if ((ec->adaption_mode <token> ECHO_CAN_USE_ADAPTION) && <answer> & 
<token> == 0) && <answer> (ec->nonupdate_dwell 
ec->adapt <token> 1; <answer> = 
<token> ec->fir_taps16[1], <answer> memcpy(ec->fir_taps16[0], 
ec->taps * <token> <answer> sizeof(int16_t)); 
} <token> <answer> else 
<token> else <answer> } 
<token> = 0; <answer> ec->cond_met 
if ((16 * <token> < ec->ltx)) { <answer> ec->lclean 
if (ec->adaption_mode & ECHO_CAN_USE_CNG) <token> <answer> { 
<token> = ec->lbgn; <answer> ec->cng_level 
ec->cng_rndnum <token> <answer> = 
1664525U * ec->cng_rndnum <token> 1013904223U; <answer> + 
ec->cng_filter <token> <answer> = 
((ec->cng_rndnum & 0xFFFF) - 32768 <token> <answer> + 
5 * ec->cng_filter) >> <token> <answer> 3; 
<token> = <answer> ec->clean_nlp 
(ec->cng_filter * ec->cng_level * <token> >> 14; <answer> 8) 
<token> else if (ec->adaption_mode & ECHO_CAN_USE_CLIP) { <answer> } 
ec->clean_nlp <token> 0; <answer> = 
} else <token> <answer> { 
if (ec->lclean < 40) <token> <answer> { 
ec->lbgn_acc += abs(ec->clean) - <token> <answer> ec->lbgn; 
ec->lbgn = (ec->lbgn_acc + (1 << <token> >> 12; <answer> 11)) 
int16_t oslec_hpf_tx(struct <token> *ec, int16_t tx) <answer> oslec_state 
<token> tmp; <answer> int 
<token> tmp1; <answer> int 
if (ec->adaption_mode & <token> { <answer> ECHO_CAN_USE_TX_HPF) 
tmp = tx <token> 15; <answer> << 
tmp -= (tmp >> <token> <answer> 4); 
ec->tx_1 += -(ec->tx_1 <token> DC_LOG2BETA) + tmp - ec->tx_2; <answer> >> 
tmp1 = ec->tx_1 >> <token> <answer> 15; 
if (tmp1 <token> 32767) <answer> > 
tmp1 <token> 32767; <answer> = 
<token> (tmp1 < -32767) <answer> if 
tmp1 <token> -32767; <answer> = 
tx <token> tmp1; <answer> = 
ec->tx_2 = <token> <answer> tmp; 
return <token> <answer> tx; 
MODULE_AUTHOR("David <token> <answer> Rowe"); 
<token> Source Line Echo Canceller"); <answer> MODULE_DESCRIPTION("Open 
#include <token> <answer> "core.h" 
#include <token> <answer> "debug.h" 
static int <token> ath12k *ar, <answer> ath12k_dbring_bufs_replenish(struct 
struct ath12k_dbring <token> <answer> *ring, 
struct <token> *buff, <answer> ath12k_dbring_element 
<token> gfp) <answer> gfp_t 
struct ath12k_base *ab = <token> <answer> ar->ab; 
struct <token> *srng; <answer> hal_srng 
dma_addr_t <token> <answer> paddr; 
void *ptr_aligned, *ptr_unaligned, <token> <answer> *desc; 
int <token> <answer> ret; 
int <token> <answer> buf_id; 
u32 <token> <answer> cookie; 
<token> = &ab->hal.srng_list[ring->refill_srng.ring_id]; <answer> srng 
ath12k_hal_srng_access_begin(ab, <token> <answer> srng); 
ptr_unaligned = <token> <answer> buff->payload; 
<token> = PTR_ALIGN(ptr_unaligned, ring->buf_align); <answer> ptr_aligned 
paddr <token> dma_map_single(ab->dev, ptr_aligned, ring->buf_sz, <answer> = 
ret = <token> paddr); <answer> dma_mapping_error(ab->dev, 
if <token> <answer> (ret) 
<token> err; <answer> goto 
buf_id = idr_alloc(&ring->bufs_idr, <token> 0, ring->bufs_max, gfp); <answer> buff, 
if (buf_id < 0) <token> <answer> { 
<token> = -ENOBUFS; <answer> ret 
goto <token> <answer> err_dma_unmap; 
<token> = ath12k_hal_srng_src_get_next_entry(ab, srng); <answer> desc 
if <token> { <answer> (!desc) 
ret <token> -ENOENT; <answer> = 
<token> err_idr_remove; <answer> goto 
<token> = paddr; <answer> buff->paddr 
cookie = u32_encode_bits(ar->pdev_idx, DP_RXDMA_BUF_COOKIE_PDEV_ID) <token> <answer> | 
u32_encode_bits(buf_id, <token> <answer> DP_RXDMA_BUF_COOKIE_BUF_ID); 
ath12k_hal_rx_buf_addr_info_set(desc, paddr, cookie, <token> <answer> 0); 
ath12k_hal_srng_access_end(ab, <token> <answer> srng); 
return <token> <answer> 0; 
idr_remove(&ring->bufs_idr, <token> <answer> buf_id); 
<token> paddr, ring->buf_sz, <answer> dma_unmap_single(ab->dev, 
<token> srng); <answer> ath12k_hal_srng_access_end(ab, 
return <token> <answer> ret; 
static int <token> ath12k *ar, <answer> ath12k_dbring_fill_bufs(struct 
struct ath12k_dbring <token> <answer> *ring, 
gfp_t <token> <answer> gfp) 
struct ath12k_dbring_element <token> <answer> *buff; 
struct hal_srng <token> <answer> *srng; 
struct ath12k_base <token> = ar->ab; <answer> *ab 
int <token> req_entries, num_free; <answer> num_remain, 
u32 <token> <answer> align; 
<token> size, ret; <answer> int 
srng = <token> <answer> &ab->hal.srng_list[ring->refill_srng.ring_id]; 
num_free = ath12k_hal_srng_src_num_free(ab, srng, <token> <answer> true); 
req_entries = <token> ring->bufs_max); <answer> min(num_free, 
<token> = req_entries; <answer> num_remain 
align = <token> <answer> ring->buf_align; 
size = sizeof(*buff) + ring->buf_sz + align - <token> <answer> 1; 
while (num_remain > <token> { <answer> 0) 
buff <token> kzalloc(size, gfp); <answer> = 
<token> (!buff) <answer> if 
ret = ath12k_dbring_bufs_replenish(ar, ring, <token> gfp); <answer> buff, 
if <token> { <answer> (ret) 
ath12k_warn(ab, "failed to replenish db ring <token> %d req_ent %d\n", <answer> num_remain 
num_remain, <token> <answer> req_entries); 
return <token> <answer> num_remain; 
int ath12k_dbring_wmi_cfg_setup(struct ath12k <token> <answer> *ar, 
struct ath12k_dbring <token> <answer> *ring, 
enum wmi_direct_buffer_module <token> <answer> id) 
struct ath12k_wmi_pdev_dma_ring_cfg_arg <token> = {0}; <answer> arg 
int <token> <answer> ret; 
if (id >= <token> <answer> WMI_DIRECT_BUF_MAX) 
<token> -EINVAL; <answer> return 
arg.pdev_id = <token> <answer> DP_SW2HW_MACID(ring->pdev_id); 
arg.module_id <token> id; <answer> = 
<token> = lower_32_bits(ring->refill_srng.paddr); <answer> arg.base_paddr_lo 
arg.base_paddr_hi = <token> <answer> upper_32_bits(ring->refill_srng.paddr); 
arg.head_idx_paddr_lo = <token> <answer> lower_32_bits(ring->hp_addr); 
arg.head_idx_paddr_hi = <token> <answer> upper_32_bits(ring->hp_addr); 
<token> = lower_32_bits(ring->tp_addr); <answer> arg.tail_idx_paddr_lo 
arg.tail_idx_paddr_hi <token> upper_32_bits(ring->tp_addr); <answer> = 
<token> = ring->bufs_max; <answer> arg.num_elems 
arg.buf_size <token> ring->buf_sz; <answer> = 
<token> = ring->num_resp_per_event; <answer> arg.num_resp_per_event 
arg.event_timeout_ms <token> ring->event_timeout_ms; <answer> = 
ret = ath12k_wmi_pdev_dma_ring_cfg(ar, <token> <answer> &arg); 
<token> (ret) { <answer> if 
ath12k_warn(ar->ab, <token> to setup db ring cfg\n"); <answer> "failed 
<token> ret; <answer> return 
return <token> <answer> 0; 
int ath12k_dbring_set_cfg(struct <token> *ar, struct ath12k_dbring *ring, <answer> ath12k 
u32 num_resp_per_event, <token> event_timeout_ms, <answer> u32 
<token> (*handler)(struct ath12k *, <answer> int 
struct ath12k_dbring_data <token> <answer> *)) 
if <token> <answer> (WARN_ON(!ring)) 
return <token> <answer> -EINVAL; 
<token> = num_resp_per_event; <answer> ring->num_resp_per_event 
ring->event_timeout_ms <token> event_timeout_ms; <answer> = 
ring->handler <token> handler; <answer> = 
return <token> <answer> 0; 
<token> ath12k_dbring_buf_setup(struct ath12k *ar, <answer> int 
struct <token> *ring, <answer> ath12k_dbring 
struct ath12k_dbring_cap <token> <answer> *db_cap) 
<token> ath12k_base *ab = ar->ab; <answer> struct 
struct <token> *srng; <answer> hal_srng 
<token> ret; <answer> int 
srng <token> &ab->hal.srng_list[ring->refill_srng.ring_id]; <answer> = 
<token> = ring->refill_srng.size / <answer> ring->bufs_max 
<token> HAL_RXDMA_DIR_BUF); <answer> ath12k_hal_srng_get_entrysize(ab, 
<token> = db_cap->min_buf_sz; <answer> ring->buf_sz 
<token> = db_cap->min_buf_align; <answer> ring->buf_align 
ring->pdev_id <token> db_cap->pdev_id; <answer> = 
ring->hp_addr <token> ath12k_hal_srng_get_hp_addr(ab, srng); <answer> = 
ring->tp_addr = <token> srng); <answer> ath12k_hal_srng_get_tp_addr(ab, 
<token> = ath12k_dbring_fill_bufs(ar, ring, GFP_KERNEL); <answer> ret 
return <token> <answer> ret; 
int ath12k_dbring_srng_setup(struct ath12k *ar, struct <token> *ring, <answer> ath12k_dbring 
int ring_num, <token> num_entries) <answer> int 
int <token> <answer> ret; 
<token> = ath12k_dp_srng_setup(ar->ab, &ring->refill_srng, HAL_RXDMA_DIR_BUF, <answer> ret 
ring_num, <token> num_entries); <answer> ar->pdev_idx, 
if (ret < <token> { <answer> 0) 
ath12k_warn(ar->ab, <token> to setup srng: %d ring_id %d\n", <answer> "failed 
ret, <token> <answer> ring_num); 
goto <token> <answer> err; 
return <token> <answer> 0; 
<token> &ring->refill_srng); <answer> ath12k_dp_srng_cleanup(ar->ab, 
<token> ret; <answer> return 
<token> ath12k_dbring_get_cap(struct ath12k_base *ab, <answer> int 
u8 <token> <answer> pdev_idx, 
<token> wmi_direct_buffer_module id, <answer> enum 
<token> ath12k_dbring_cap *db_cap) <answer> struct 
int <token> <answer> i; 
if <token> || !ab->db_caps) <answer> (!ab->num_db_cap 
return <token> <answer> -ENOENT; 
if (id <token> WMI_DIRECT_BUF_MAX) <answer> >= 
<token> -EINVAL; <answer> return 
for (i = 0; i < ab->num_db_cap; <token> { <answer> i++) 
if (pdev_idx == ab->db_caps[i].pdev_id <token> <answer> && 
id <token> ab->db_caps[i].id) { <answer> == 
*db_cap <token> ab->db_caps[i]; <answer> = 
return <token> <answer> 0; 
return <token> <answer> -ENOENT; 
int ath12k_dbring_buffer_release_event(struct <token> *ab, <answer> ath12k_base 
struct ath12k_dbring_buf_release_event <token> <answer> *ev) 
struct ath12k_dbring <token> = NULL; <answer> *ring 
<token> hal_srng *srng; <answer> struct 
<token> ath12k *ar; <answer> struct 
<token> ath12k_dbring_element *buff; <answer> struct 
struct ath12k_dbring_data <token> <answer> handler_data; 
struct ath12k_buffer_addr <token> <answer> desc; 
<token> *vaddr_unalign; <answer> u8 
<token> num_entry, num_buff_reaped; <answer> u32 
<token> pdev_idx, rbm; <answer> u8 
<token> cookie; <answer> u32 
int <token> <answer> buf_id; 
int <token> <answer> size; 
dma_addr_t <token> <answer> paddr; 
int ret = <token> <answer> 0; 
<token> = le32_to_cpu(ev->fixed.pdev_id); <answer> pdev_idx 
if (pdev_idx >= ab->num_radios) <token> <answer> { 
ath12k_warn(ab, "Invalid pdev id <token> pdev_idx); <answer> %d\n", 
return <token> <answer> -EINVAL; 
<token> (ev->fixed.num_buf_release_entry != <answer> if 
<token> { <answer> ev->fixed.num_meta_data_entry) 
ath12k_warn(ab, "Buffer entry %d mismatch meta entry <token> <answer> %d\n", 
<token> -EINVAL; <answer> return 
<token> = ab->pdevs[pdev_idx].ar; <answer> ar 
<token> (!rcu_dereference(ab->pdevs_active[pdev_idx])) { <answer> if 
ret <token> -EINVAL; <answer> = 
goto <token> <answer> rcu_unlock; 
switch (ev->fixed.module_id) <token> <answer> { 
<token> WMI_DIRECT_BUF_SPECTRAL: <answer> case 
ring <token> NULL; <answer> = 
ath12k_warn(ab, "Recv dma buffer release ev on unsupp <token> %d\n", <answer> module 
<token> (!ring) { <answer> if 
<token> = -EINVAL; <answer> ret 
goto <token> <answer> rcu_unlock; 
srng <token> &ab->hal.srng_list[ring->refill_srng.ring_id]; <answer> = 
num_entry = <token> <answer> le32_to_cpu(ev->fixed.num_buf_release_entry); 
size = sizeof(*buff) <token> ring->buf_sz + ring->buf_align - 1; <answer> + 
num_buff_reaped <token> 0; <answer> = 
while (num_buff_reaped < <token> { <answer> num_entry) 
desc.info0 <token> ev->buf_entry[num_buff_reaped].paddr_lo; <answer> = 
desc.info1 = <token> <answer> ev->buf_entry[num_buff_reaped].paddr_hi; 
handler_data.meta = <token> <answer> ev->meta_data[num_buff_reaped]; 
ath12k_hal_rx_buf_addr_info_get(&desc, &paddr, <token> &rbm); <answer> &cookie, 
buf_id <token> u32_get_bits(cookie, DP_RXDMA_BUF_COOKIE_BUF_ID); <answer> = 
<token> = idr_find(&ring->bufs_idr, buf_id); <answer> buff 
if (!buff) <token> <answer> { 
<token> buf_id); <answer> idr_remove(&ring->bufs_idr, 
dma_unmap_single(ab->dev, buff->paddr, <token> <answer> ring->buf_sz, 
if (ring->handler) <token> <answer> { 
<token> = buff->payload; <answer> vaddr_unalign 
handler_data.data = <token> <answer> PTR_ALIGN(vaddr_unalign, 
handler_data.data_sz <token> ring->buf_sz; <answer> = 
ring->handler(ar, <token> <answer> &handler_data); 
memset(buff, 0, <token> <answer> size); 
ath12k_dbring_bufs_replenish(ar, ring, <token> GFP_ATOMIC); <answer> buff, 
<token> ret; <answer> return 
void ath12k_dbring_srng_cleanup(struct ath12k *ar, struct ath12k_dbring <token> <answer> *ring) 
<token> &ring->refill_srng); <answer> ath12k_dp_srng_cleanup(ar->ab, 
void ath12k_dbring_buf_cleanup(struct ath12k <token> struct ath12k_dbring *ring) <answer> *ar, 
struct ath12k_dbring_element <token> <answer> *buff; 
int <token> <answer> buf_id; 
<token> buff, buf_id) { <answer> idr_for_each_entry(&ring->bufs_idr, 
<token> buf_id); <answer> idr_remove(&ring->bufs_idr, 
dma_unmap_single(ar->ab->dev, <token> <answer> buff->paddr, 
<token> DMA_FROM_DEVICE); <answer> ring->buf_sz, 
<token> "dr_types.h" <answer> #include 
<token> "mlx5_ifc_dr_ste_v1.h" <answer> #include 
enum dr_ptrn_modify_hdr_action_id <token> <answer> { 
<token> = 0x00, <answer> DR_PTRN_MODIFY_HDR_ACTION_ID_NOP 
<token> = 0x05, <answer> DR_PTRN_MODIFY_HDR_ACTION_ID_COPY 
<token> = 0x06, <answer> DR_PTRN_MODIFY_HDR_ACTION_ID_SET 
DR_PTRN_MODIFY_HDR_ACTION_ID_ADD = <token> <answer> 0x07, 
DR_PTRN_MODIFY_HDR_ACTION_ID_INSERT_INLINE = <token> <answer> 0x0a, 
struct mlx5dr_ptrn_mgr <token> <answer> { 
<token> mlx5dr_domain *dmn; <answer> struct 
struct mlx5dr_icm_pool <token> <answer> *ptrn_icm_pool; 
list_add(&cached_pattern->list, <token> <answer> &mgr->ptrn_list); 
<token> cached_pattern; <answer> return 
return <token> <answer> NULL; 
<token> struct mlx5dr_ptrn_obj * <answer> static 
<token> mlx5dr_ptrn_mgr *mgr, <answer> dr_ptrn_alloc_pattern(struct 
u16 num_of_actions, u8 <token> <answer> *data) 
struct mlx5dr_ptrn_obj <token> <answer> *pattern; 
struct <token> *chunk; <answer> mlx5dr_icm_chunk 
<token> chunk_size; <answer> u32 
u32 <token> <answer> index; 
chunk_size = <token> <answer> ilog2(roundup_pow_of_two(num_of_actions)); 
for (i = 0; i < num_of_actions; i++) <token> <answer> { 
action_id = MLX5_GET(ste_double_action_set_v1, &hw_actions[i], <token> <answer> action_id); 
if <token> == DR_PTRN_MODIFY_HDR_ACTION_ID_SET || <answer> (action_id 
<token> == DR_PTRN_MODIFY_HDR_ACTION_ID_ADD || <answer> action_id 
<token> == DR_PTRN_MODIFY_HDR_ACTION_ID_INSERT_INLINE) <answer> action_id 
MLX5_SET(ste_double_action_set_v1, &hw_actions[i], <token> 0); <answer> inline_data, 
if <token> pattern->chunk, <answer> (mlx5dr_send_postsend_pattern(mgr->dmn, 
<token> pattern->data)) { <answer> num_of_actions, 
<token> free_pattern; <answer> goto 
} else <token> <answer> { 
<token> pattern; <answer> return 
return <token> <answer> NULL; 
mlx5dr_ptrn_cache_put_pattern(struct mlx5dr_ptrn_mgr <token> <answer> *mgr, 
struct mlx5dr_ptrn_obj <token> <answer> *pattern) 
if <token> <answer> (refcount_dec_and_test(&pattern->refcount)) 
struct mlx5dr_ptrn_mgr *mlx5dr_ptrn_mgr_create(struct <token> *dmn) <answer> mlx5dr_domain 
struct mlx5dr_ptrn_mgr <token> <answer> *mgr; 
<token> (!mlx5dr_domain_is_support_ptrn_arg(dmn)) <answer> if 
return <token> <answer> NULL; 
mgr = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*mgr), 
<token> (!mgr) <answer> if 
<token> NULL; <answer> return 
mgr->dmn <token> dmn; <answer> = 
mgr->ptrn_icm_pool = mlx5dr_icm_pool_create(dmn, <token> <answer> DR_ICM_TYPE_MODIFY_HDR_PTRN); 
if (!mgr->ptrn_icm_pool) <token> <answer> { 
mlx5dr_err(dmn, "Couldn't get modify-header-pattern <token> <answer> memory\n"); 
goto <token> <answer> free_mgr; 
return <token> <answer> mgr; 
return <token> <answer> NULL; 
void mlx5dr_ptrn_mgr_destroy(struct mlx5dr_ptrn_mgr <token> <answer> *mgr) 
struct <token> *pattern; <answer> mlx5dr_ptrn_obj 
struct <token> *tmp; <answer> mlx5dr_ptrn_obj 
<token> (!mgr) <answer> if 
list_for_each_entry_safe(pattern, tmp, &mgr->ptrn_list, list) <token> <answer> { 
#include <token> <answer> <linux/iosys-map.h> 
#include <token> <answer> <drm/drm_atomic.h> 
<token> <drm/drm_atomic_helper.h> <answer> #include 
#include <token> <answer> <drm/drm_blend.h> 
<token> <drm/drm_fourcc.h> <answer> #include 
<token> <drm/drm_gem_atomic_helper.h> <answer> #include 
#include <token> <answer> <drm/drm_gem_framebuffer_helper.h> 
<token> "vkms_drv.h" <answer> #include 
<token> "vkms_formats.h" <answer> #include 
static const u32 vkms_formats[] <token> { <answer> = 
static <token> drm_plane_state * <answer> struct 
vkms_plane_duplicate_state(struct <token> *plane) <answer> drm_plane 
struct vkms_plane_state <token> <answer> *vkms_state; 
struct vkms_frame_info <token> <answer> *frame_info; 
<token> = kzalloc(sizeof(*vkms_state), GFP_KERNEL); <answer> vkms_state 
<token> (!vkms_state) <answer> if 
return <token> <answer> NULL; 
frame_info = kzalloc(sizeof(*frame_info), <token> <answer> GFP_KERNEL); 
<token> (!frame_info) { <answer> if 
DRM_DEBUG_KMS("Couldn't <token> frame_info\n"); <answer> allocate 
return <token> <answer> NULL; 
<token> = frame_info; <answer> vkms_state->frame_info 
<token> &vkms_state->base); <answer> __drm_gem_duplicate_shadow_plane_state(plane, 
return <token> <answer> &vkms_state->base.base; 
static void vkms_plane_destroy_state(struct drm_plane <token> <answer> *plane, 
struct drm_plane_state <token> <answer> *old_state) 
<token> vkms_plane_state *vkms_state = to_vkms_plane_state(old_state); <answer> struct 
struct <token> *crtc = vkms_state->base.base.crtc; <answer> drm_crtc 
if (crtc <token> vkms_state->frame_info->fb) { <answer> && 
if <token> <answer> (drm_framebuffer_read_refcount(vkms_state->frame_info->fb)) 
vkms_state->frame_info = <token> <answer> NULL; 
static void vkms_plane_reset(struct drm_plane <token> <answer> *plane) 
struct vkms_plane_state <token> <answer> *vkms_state; 
if <token> { <answer> (plane->state) 
<token> plane->state); <answer> vkms_plane_destroy_state(plane, 
<token> _GNU_SOURCE <answer> #define 
<token> <sched.h> <answer> #include 
#include <token> <answer> <sys/timerfd.h> 
#include <token> <answer> <sys/syscall.h> 
<token> <time.h> <answer> #include 
#include <token> <answer> <unistd.h> 
#include <token> <answer> <stdlib.h> 
#include <token> <answer> <stdio.h> 
<token> <stdint.h> <answer> #include 
<token> <pthread.h> <answer> #include 
#include <token> <answer> <signal.h> 
#include <token> <answer> <string.h> 
<token> "log.h" <answer> #include 
#include <token> <answer> "timens.h" 
void <token> sig) <answer> test_sig(int 
if (sig <token> SIGUSR2) <answer> == 
<token> thread_args { <answer> struct 
struct timespec *now, <token> <answer> *rem; 
<token> *lock; <answer> pthread_mutex_t 
<token> clockid; <answer> int 
int <token> <answer> abs; 
void *call_nanosleep(void <token> <answer> *_args) 
<token> thread_args *args = _args; <answer> struct 
clock_nanosleep(args->clockid, args->abs ? TIMER_ABSTIME : <token> args->now, args->rem); <answer> 0, 
<token> NULL; <answer> return 
int run_test(int clockid, <token> abs) <answer> int 
struct timespec <token> = {}, rem; <answer> now 
struct thread_args args = { .now = <token> .rem = &rem, .clockid = clockid}; <answer> &now, 
<token> timespec start; <answer> struct 
pthread_mutex_t <token> <answer> lock; 
pthread_t <token> <answer> thread; 
int <token> ok, ret; <answer> j, 
signal(SIGUSR1, <token> <answer> test_sig); 
signal(SIGUSR2, <token> <answer> test_sig); 
<token> NULL); <answer> pthread_mutex_init(&lock, 
if (clock_gettime(clockid, &start) == -1) <token> <answer> { 
if (errno <token> EINVAL && check_skip(clockid)) <answer> == 
<token> 0; <answer> return 
<token> pr_perror("clock_gettime"); <answer> return 
if <token> { <answer> (abs) 
now.tv_sec = <token> <answer> start.tv_sec; 
<token> = start.tv_nsec; <answer> now.tv_nsec 
now.tv_sec += <token> <answer> 3600; 
<token> = abs; <answer> args.abs 
<token> = &lock; <answer> args.lock 
ret <token> pthread_create(&thread, NULL, call_nanosleep, &args); <answer> = 
if (ret <token> 0) { <answer> != 
pr_err("Unable <token> create a thread: %s", strerror(ret)); <answer> to 
return <token> <answer> 1; 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/sched.h> <answer> #include 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <linux/clocksource.h> 
<token> <linux/clockchips.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_address.h> <answer> #include 
#include <token> <answer> <linux/of_irq.h> 
<token> <linux/bitops.h> <answer> #include 
<token> DRIVER_NAME "asm9260-timer" <answer> #define 
#define <token> 4 <answer> SET_REG 
<token> CLR_REG 8 <answer> #define 
#define <token> BIT(7) <answer> BM_C3_RST 
#define BM_C2_RST <token> <answer> BIT(6) 
#define <token> BIT(5) <answer> BM_C1_RST 
#define <token> BIT(4) <answer> BM_C0_RST 
<token> BM_C3_EN BIT(3) <answer> #define 
#define <token> BIT(2) <answer> BM_C2_EN 
#define <token> BIT(1) <answer> BM_C1_EN 
<token> BM_C0_EN BIT(0) <answer> #define 
#define <token> 0 <answer> BM_DIR_COUNT_UP 
#define <token> 1 <answer> BM_DIR_COUNT_DOWN 
#define <token> 0 <answer> BM_DIR0_SHIFT 
<token> BM_DIR1_SHIFT 4 <answer> #define 
#define <token> 8 <answer> BM_DIR2_SHIFT 
#define <token> 12 <answer> BM_DIR3_SHIFT 
#define BM_DIR_DEFAULT (BM_DIR_COUNT_UP << <token> | \ <answer> BM_DIR0_SHIFT 
<token> << BM_DIR1_SHIFT | \ <answer> BM_DIR_COUNT_UP 
BM_DIR_COUNT_UP << BM_DIR2_SHIFT <token> \ <answer> | 
BM_DIR_COUNT_UP <token> BM_DIR3_SHIFT) <answer> << 
#define <token> 0x0040 <answer> HW_TC1 
#define <token> 0x0050 <answer> HW_TC2 
#define HW_TC3 <token> <answer> 0x0060 
static int __init asm9260_timer_init(struct <token> *np) <answer> device_node 
<token> irq; <answer> int 
<token> clk *clk; <answer> struct 
<token> ret; <answer> int 
<token> long rate; <answer> unsigned 
priv.base <token> of_io_request_and_map(np, 0, np->name); <answer> = 
if <token> { <answer> (IS_ERR(priv.base)) 
pr_err("%pOFn: unable to map <token> np); <answer> resource\n", 
<token> PTR_ERR(priv.base); <answer> return 
clk = <token> 0); <answer> of_clk_get(np, 
if (IS_ERR(clk)) <token> <answer> { 
pr_err("Failed to <token> clk!\n"); <answer> get 
<token> PTR_ERR(clk); <answer> return 
ret <token> clk_prepare_enable(clk); <answer> = 
if (ret) <token> <answer> { 
pr_err("Failed to <token> clk!\n"); <answer> enable 
<token> ret; <answer> return 
irq = <token> 0); <answer> irq_of_parse_and_map(np, 
ret = request_irq(irq, <token> IRQF_TIMER, <answer> asm9260_timer_interrupt, 
<token> &event_dev); <answer> DRIVER_NAME, 
if (ret) <token> <answer> { 
pr_err("Failed to <token> irq!\n"); <answer> setup 
<token> ret; <answer> return 
writel_relaxed(0xffffffff, priv.base <token> HW_MR1); <answer> + 
<token> <linux/slab.h> <answer> #include 
<token> <linux/clkdev.h> <answer> #include 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <linux/clk-provider.h> 
#include <token> <answer> <linux/io.h> 
<token> <linux/of_address.h> <answer> #include 
<token> <linux/syscore_ops.h> <answer> #include 
<token> "clk.h" <answer> #include 
<token> LIST_HEAD(clock_reg_cache_list); <answer> static 
void <token> __iomem *base, <answer> samsung_clk_save(void 
<token> samsung_clk_reg_dump *rd, <answer> struct 
<token> int num_regs) <answer> unsigned 
<token> (; num_regs > 0; --num_regs, ++rd) <answer> for 
rd->value = readl(base <token> rd->offset); <answer> + 
void samsung_clk_restore(void __iomem <token> <answer> *base, 
const struct samsung_clk_reg_dump <token> <answer> *rd, 
unsigned <token> num_regs) <answer> int 
for (; num_regs > 0; --num_regs, <token> <answer> ++rd) 
<token> base + rd->offset); <answer> writel(rd->value, 
<token> samsung_clk_reg_dump *samsung_clk_alloc_reg_dump( <answer> struct 
const unsigned <token> *rdump, <answer> long 
unsigned long <token> <answer> nr_rdump) 
struct <token> *rd; <answer> samsung_clk_reg_dump 
<token> int i; <answer> unsigned 
rd = kcalloc(nr_rdump, <token> GFP_KERNEL); <answer> sizeof(*rd), 
<token> (!rd) <answer> if 
return <token> <answer> NULL; 
for (i = 0; <token> < nr_rdump; ++i) <answer> i 
rd[i].offset = <token> <answer> rdump[i]; 
return <token> <answer> rd; 
struct samsung_clk_provider <token> __init samsung_clk_init(struct device *dev, <answer> * 
void __iomem *base, unsigned long <token> <answer> nr_clks) 
<token> samsung_clk_provider *ctx; <answer> struct 
<token> i; <answer> int 
<token> = kzalloc(struct_size(ctx, clk_data.hws, nr_clks), GFP_KERNEL); <answer> ctx 
if <token> <answer> (!ctx) 
panic("could <token> allocate clock provider context.\n"); <answer> not 
for <token> = 0; i < nr_clks; ++i) <answer> (i 
ctx->clk_data.hws[i] <token> ERR_PTR(-ENOENT); <answer> = 
ctx->dev <token> dev; <answer> = 
ctx->reg_base = <token> <answer> base; 
ctx->clk_data.num = <token> <answer> nr_clks; 
<token> ctx; <answer> return 
void <token> samsung_clk_of_add_provider(struct device_node *np, <answer> __init 
<token> samsung_clk_provider *ctx) <answer> struct 
if <token> { <answer> (np) 
<token> (of_clk_add_hw_provider(np, of_clk_hw_onecell_get, <answer> if 
panic("could not register clk <token> <answer> provider\n"); 
ret = clk_hw_register_clkdev(clk_hw, list->name, <token> <answer> NULL); 
if <token> <answer> (ret) 
<token> failed to register clock lookup for %s", <answer> pr_err("%s: 
<token> list->name); <answer> __func__, 
void __init <token> samsung_clk_provider *ctx, <answer> samsung_clk_of_register_fixed_ext(struct 
<token> samsung_fixed_rate_clock *fixed_rate_clk, <answer> struct 
<token> int nr_fixed_rate_clk, <answer> unsigned 
<token> struct of_device_id *clk_matches) <answer> const 
const struct <token> *match; <answer> of_device_id 
<token> device_node *clk_np; <answer> struct 
u32 <token> <answer> freq; 
for_each_matching_node_and_match(clk_np, <token> &match) { <answer> clk_matches, 
if <token> "clock-frequency", &freq)) <answer> (of_property_read_u32(clk_np, 
fixed_rate_clk[(unsigned long)match->data].fixed_rate = <token> <answer> freq; 
<token> fixed_rate_clk, nr_fixed_rate_clk); <answer> samsung_clk_register_fixed_rate(ctx, 
#ifdef <token> <answer> CONFIG_PM_SLEEP 
<token> int samsung_clk_suspend(void) <answer> static 
<token> samsung_clock_reg_cache *reg_cache; <answer> struct 
list_for_each_entry(reg_cache, &clock_reg_cache_list, node) <token> <answer> { 
<token> reg_cache->rdump, <answer> samsung_clk_save(reg_cache->reg_base, 
<token> reg_cache->rsuspend, <answer> samsung_clk_restore(reg_cache->reg_base, 
return <token> <answer> 0; 
<token> void samsung_clk_resume(void) <answer> static 
<token> samsung_clock_reg_cache *reg_cache; <answer> struct 
list_for_each_entry(reg_cache, &clock_reg_cache_list, <token> <answer> node) 
<token> reg_cache->rdump, <answer> samsung_clk_restore(reg_cache->reg_base, 
<token> struct syscore_ops samsung_clk_syscore_ops = { <answer> static 
.suspend <token> samsung_clk_suspend, <answer> = 
<token> = samsung_clk_resume, <answer> .resume 
void samsung_clk_extended_sleep_init(void <token> *reg_base, <answer> __iomem 
const unsigned <token> *rdump, <answer> long 
<token> long nr_rdump, <answer> unsigned 
<token> struct samsung_clk_reg_dump *rsuspend, <answer> const 
<token> long nr_rsuspend) <answer> unsigned 
struct samsung_clock_reg_cache <token> <answer> *reg_cache; 
reg_cache = kzalloc(sizeof(struct <token> <answer> samsung_clock_reg_cache), 
if <token> <answer> (!reg_cache) 
panic("could <token> allocate register reg_cache.\n"); <answer> not 
<token> = samsung_clk_alloc_reg_dump(rdump, nr_rdump); <answer> reg_cache->rdump 
<token> (!reg_cache->rdump) <answer> if 
panic("could not allocate register <token> storage.\n"); <answer> dump 
<token> (list_empty(&clock_reg_cache_list)) <answer> if 
reg_cache->reg_base <token> reg_base; <answer> = 
<token> = nr_rdump; <answer> reg_cache->rd_num 
reg_cache->rsuspend <token> rsuspend; <answer> = 
reg_cache->rsuspend_num = <token> <answer> nr_rsuspend; 
<token> &clock_reg_cache_list); <answer> list_add_tail(&reg_cache->node, 
void <token> samsung_cmu_register_clocks(struct samsung_clk_provider *ctx, <answer> __init 
const <token> samsung_cmu_info *cmu) <answer> struct 
if <token> <answer> (cmu->pll_clks) 
<token> cmu->pll_clks, cmu->nr_pll_clks); <answer> samsung_clk_register_pll(ctx, 
if <token> <answer> (cmu->mux_clks) 
samsung_clk_register_mux(ctx, <token> cmu->nr_mux_clks); <answer> cmu->mux_clks, 
if <token> <answer> (cmu->div_clks) 
<token> cmu->div_clks, cmu->nr_div_clks); <answer> samsung_clk_register_div(ctx, 
<token> (cmu->gate_clks) <answer> if 
<token> cmu->gate_clks, <answer> samsung_clk_register_gate(ctx, 
<token> (cmu->fixed_clks) <answer> if 
samsung_clk_register_fixed_rate(ctx, <token> <answer> cmu->fixed_clks, 
if <token> <answer> (cmu->fixed_factor_clks) 
<token> cmu->fixed_factor_clks, <answer> samsung_clk_register_fixed_factor(ctx, 
<token> (cmu->cpu_clks) <answer> if 
samsung_clk_register_cpu(ctx, <token> cmu->nr_cpu_clks); <answer> cmu->cpu_clks, 
struct samsung_clk_provider * __init <token> <answer> samsung_cmu_register_one( 
struct device_node <token> <answer> *np, 
const struct samsung_cmu_info <token> <answer> *cmu) 
<token> __iomem *reg_base; <answer> void 
struct <token> *ctx; <answer> samsung_clk_provider 
reg_base = <token> 0); <answer> of_iomap(np, 
<token> (!reg_base) { <answer> if 
panic("%s: failed to <token> registers\n", __func__); <answer> map 
return <token> <answer> NULL; 
ctx = samsung_clk_init(NULL, reg_base, <token> <answer> cmu->nr_clk_ids); 
<token> cmu); <answer> samsung_cmu_register_clocks(ctx, 
<token> (cmu->clk_regs) <answer> if 
cmu->clk_regs, <token> <answer> cmu->nr_clk_regs, 
<token> cmu->nr_suspend_regs); <answer> cmu->suspend_regs, 
samsung_clk_of_add_provider(np, <token> <answer> ctx); 
<token> ctx; <answer> return 
<token> "umc_v8_7.h" <answer> #include 
<token> "amdgpu_ras.h" <answer> #include 
<token> "amdgpu_umc.h" <answer> #include 
<token> "amdgpu.h" <answer> #include 
#include <token> <answer> "rsmu/rsmu_0_0_2_offset.h" 
#include <token> <answer> "rsmu/rsmu_0_0_2_sh_mask.h" 
<token> "umc/umc_8_7_0_offset.h" <answer> #include 
<token> "umc/umc_8_7_0_sh_mask.h" <answer> #include 
#define UMC_8_INST_DIST <token> <answer> 0x40000 
const <token> <answer> uint32_t 
<token> = { <answer> umc_v8_7_channel_idx_tbl[UMC_V8_7_UMC_INSTANCE_NUM][UMC_V8_7_CHANNEL_INSTANCE_NUM] 
<token> 11}, {4, 13}, <answer> {2, 
{1, <token> {7, 14}, <answer> 8}, 
<token> 3}, {12, 5}, <answer> {10, 
{9, 0}, <token> 6} <answer> {15, 
static inline <token> get_umc_v8_7_reg_offset(struct amdgpu_device *adev, <answer> uint32_t 
<token> umc_inst, <answer> uint32_t 
<token> ch_inst) <answer> uint32_t 
return adev->umc.channel_offs*ch_inst + <token> <answer> UMC_8_INST_DIST*umc_inst; 
static void <token> amdgpu_device *adev, <answer> umc_v8_7_ecc_info_query_correctable_error_count(struct 
uint32_t <token> uint32_t ch_inst, <answer> umc_inst, 
unsigned <token> *error_count) <answer> long 
<token> mc_umc_status; <answer> uint64_t 
<token> eccinfo_table_idx; <answer> uint32_t 
<token> amdgpu_ras *ras = amdgpu_ras_get_context(adev); <answer> struct 
eccinfo_table_idx = umc_inst * adev->umc.channel_inst_num <token> ch_inst; <answer> + 
mc_umc_status <token> ras->umc_ecc.ecc[eccinfo_table_idx].mca_umc_status; <answer> = 
if (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) <token> 1 && <answer> == 
<token> MCA_UMC_UMC0_MCUMC_STATUST0, CECC) == 1) <answer> REG_GET_FIELD(mc_umc_status, 
<token> += 1; <answer> *error_count 
static void umc_v8_7_ecc_info_querry_uncorrectable_error_count(struct <token> *adev, <answer> amdgpu_device 
uint32_t <token> uint32_t ch_inst, <answer> umc_inst, 
<token> long *error_count) <answer> unsigned 
uint64_t <token> <answer> mc_umc_status; 
uint32_t <token> <answer> eccinfo_table_idx; 
<token> amdgpu_ras *ras = amdgpu_ras_get_context(adev); <answer> struct 
eccinfo_table_idx = umc_inst <token> adev->umc.channel_inst_num + ch_inst; <answer> * 
<token> ch_inst) { <answer> LOOP_UMC_INST_AND_CH(umc_inst, 
<token> ch_inst, <answer> umc_inst, 
<token> ch_inst, <answer> umc_inst, 
static void umc_v8_7_convert_error_address(struct amdgpu_device <token> <answer> *adev, 
struct ras_err_data <token> uint64_t err_addr, <answer> *err_data, 
uint32_t <token> uint32_t umc_inst) <answer> ch_inst, 
<token> retired_page; <answer> uint64_t 
<token> channel_index; <answer> uint32_t 
<token> = <answer> channel_index 
adev->umc.channel_idx_tbl[umc_inst <token> adev->umc.channel_inst_num + ch_inst]; <answer> * 
LOOP_UMC_INST_AND_CH(umc_inst, ch_inst) <token> <answer> { 
static void umc_v8_7_clear_error_count_per_channel(struct amdgpu_device <token> <answer> *adev, 
uint32_t <token> <answer> umc_reg_offset) 
<token> ecc_err_cnt_addr; <answer> uint32_t 
uint32_t ecc_err_cnt_sel, <token> <answer> ecc_err_cnt_sel_addr; 
<token> = <answer> ecc_err_cnt_sel_addr 
<token> 0, mmUMCCH0_0_GeccErrCntSel); <answer> SOC15_REG_OFFSET(UMC, 
<token> = <answer> ecc_err_cnt_addr 
SOC15_REG_OFFSET(UMC, 0, <token> <answer> mmUMCCH0_0_GeccErrCnt); 
mc_umc_status = RREG64_PCIE((mc_umc_status_addr + umc_reg_offset) <token> 4); <answer> * 
if <token> MCA_UMC_UMC0_MCUMC_STATUST0, ErrorCodeExt) == 6 && <answer> (REG_GET_FIELD(mc_umc_status, 
REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1 <token> <answer> && 
REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, CECC) <token> 1) <answer> == 
*error_count <token> 1; <answer> += 
<token> void umc_v8_7_querry_uncorrectable_error_count(struct amdgpu_device *adev, <answer> static 
<token> umc_reg_offset, <answer> uint32_t 
<token> long *error_count) <answer> unsigned 
<token> mc_umc_status; <answer> uint64_t 
<token> mc_umc_status_addr; <answer> uint32_t 
<token> = SOC15_REG_OFFSET(UMC, 0, mmMCA_UMC_UMC0_MCUMC_STATUST0); <answer> mc_umc_status_addr 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/kref.h> 
<token> <linux/uaccess.h> <answer> #include 
#include <token> <answer> <linux/usb.h> 
<token> <linux/mutex.h> <answer> #include 
#include <token> <answer> <linux/mmc/host.h> 
#include <token> <answer> <linux/mmc/card.h> 
<token> <linux/mmc/sdio_func.h> <answer> #include 
<token> <linux/mmc/sdio_ids.h> <answer> #include 
#include <token> <answer> <linux/workqueue.h> 
#include <token> <answer> <linux/ctype.h> 
#include <token> <answer> <linux/firmware.h> 
#include <token> <answer> <linux/scatterlist.h> 
struct <token> { <answer> host_controller_info 
<token> info_size; <answer> u8 
<token> firmware_version; <answer> u16 
<token> number_of_ports; <answer> u8 
} <token> <answer> __packed; 
#define <token> 1024 <answer> FIRMWARE_BLOCK_BOUNDARY 
struct sd_command_header <token> <answer> { 
u8 <token> <answer> header_size; 
u8 <token> <answer> header_type; 
<token> port_number; <answer> u8 
static void <token> vub300_mmc_host *vub300) <answer> vub300_queue_cmnd_work(struct 
if (queue_work(cmndworkqueue, &vub300->cmndwork)) <token> <answer> { 
} else <token> <answer> { 
<token> vub300_delete); <answer> kref_put(&vub300->kref, 
static void vub300_queue_poll_work(struct vub300_mmc_host *vub300, int <token> <answer> delay) 
if (queue_delayed_work(pollworkqueue, <token> delay)) { <answer> &vub300->pollwork, 
<token> else { <answer> } 
<token> vub300_delete); <answer> kref_put(&vub300->kref, 
static void vub300_queue_dead_work(struct vub300_mmc_host <token> <answer> *vub300) 
<token> (queue_work(deadworkqueue, &vub300->deadwork)) { <answer> if 
} else <token> <answer> { 
<token> vub300_delete); <answer> kref_put(&vub300->kref, 
static void <token> urb *urb) <answer> irqpoll_res_completed(struct 
<token> retval; <answer> int 
retval <token> <answer> = 
usb_control_msg(vub300->udev, usb_rcvctrlpipe(vub300->udev, <token> <answer> 0), 
USB_DIR_IN | USB_TYPE_VENDOR | <token> <answer> USB_RECIP_DEVICE, 
<token> 0x0000, &vub300->system_port_status, <answer> 0x0000, 
<token> 1000); <answer> sizeof(vub300->system_port_status), 
if (sizeof(vub300->system_port_status) == <token> <answer> retval) 
static <token> __vub300_irqpoll_response(struct vub300_mmc_host *vub300) <answer> void 
static <token> vub300_pollwork_thread(struct work_struct *work) <answer> void 
} else if <token> { <answer> (vub300->card_present) 
} else if (vub300->mmc && <token> { <answer> vub300->mmc->card) 
} else <token> <answer> { 
mod_timer(&vub300->inactivity_timer, jiffies <token> HZ); <answer> + 
kref_put(&vub300->kref, <token> <answer> vub300_delete); 
static void <token> timer_list *t) <answer> vub300_inactivity_timer_expired(struct 
<token> else if (!vub300->data) { <answer> } 
} <token> if (vub300->urb) { <answer> else 
vub300->cmd->error <token> <answer> = 
} else <token> <answer> { 
<token> = <answer> vub300->cmd->error 
} else <token> <answer> { 
static void snoop_block_size_and_bus_width(struct vub300_mmc_host <token> <answer> *vub300, 
u32 <token> <answer> cmd_arg) 
if <token> & cmd_arg) == 0x80022200) <answer> ((0xFBFFFE00 
vub300->fbs[1] = (cmd_arg << 8) | (0x00FF & <token> <answer> vub300->fbs[1]); 
else if ((0xFBFFFE00 & cmd_arg) == <token> <answer> 0x80022000) 
vub300->fbs[1] = (0xFF & cmd_arg) | (0xFF00 <token> vub300->fbs[1]); <answer> & 
else <token> ((0xFBFFFE00 & cmd_arg) == 0x80042200) <answer> if 
<token> = (cmd_arg << 8) | (0x00FF & vub300->fbs[2]); <answer> vub300->fbs[2] 
else if ((0xFBFFFE00 & <token> == 0x80042000) <answer> cmd_arg) 
vub300->fbs[2] = (0xFF & <token> | (0xFF00 & vub300->fbs[2]); <answer> cmd_arg) 
else if <token> & cmd_arg) == 0x80062200) <answer> ((0xFBFFFE00 
vub300->fbs[3] = (cmd_arg << 8) | <token> & vub300->fbs[3]); <answer> (0x00FF 
else if ((0xFBFFFE00 <token> cmd_arg) == 0x80062000) <answer> & 
vub300->fbs[3] = (0xFF <token> cmd_arg) | (0xFF00 & vub300->fbs[3]); <answer> & 
else if <token> & cmd_arg) == 0x80082200) <answer> ((0xFBFFFE00 
vub300->fbs[4] = (cmd_arg << 8) <token> (0x00FF & vub300->fbs[4]); <answer> | 
else if ((0xFBFFFE00 & cmd_arg) == <token> <answer> 0x80082000) 
vub300->fbs[4] <token> (0xFF & cmd_arg) | (0xFF00 & vub300->fbs[4]); <answer> = 
else if ((0xFBFFFE00 <token> cmd_arg) == 0x800A2200) <answer> & 
vub300->fbs[5] <token> (cmd_arg << 8) | (0x00FF & vub300->fbs[5]); <answer> = 
else if ((0xFBFFFE00 & cmd_arg) <token> 0x800A2000) <answer> == 
vub300->fbs[5] = (0xFF & cmd_arg) | (0xFF00 & <token> <answer> vub300->fbs[5]); 
else if ((0xFBFFFE00 & cmd_arg) <token> 0x800C2200) <answer> == 
vub300->fbs[6] = (cmd_arg << 8) <token> (0x00FF & vub300->fbs[6]); <answer> | 
else if ((0xFBFFFE00 & cmd_arg) == <token> <answer> 0x800C2000) 
<token> = (0xFF & cmd_arg) | (0xFF00 & vub300->fbs[6]); <answer> vub300->fbs[6] 
else if ((0xFBFFFE00 & cmd_arg) <token> 0x800E2200) <answer> == 
vub300->fbs[7] = (cmd_arg << 8) | (0x00FF <token> vub300->fbs[7]); <answer> & 
else if ((0xFBFFFE00 & <token> == 0x800E2000) <answer> cmd_arg) 
vub300->fbs[7] = (0xFF & cmd_arg) | (0xFF00 & <token> <answer> vub300->fbs[7]); 
else if ((0xFBFFFE03 & <token> == 0x80000E00) <answer> cmd_arg) 
<token> = 1; <answer> vub300->bus_width 
else if <token> & cmd_arg) == 0x80000E02) <answer> ((0xFBFFFE03 
vub300->bus_width = <token> <answer> 4; 
static <token> send_command(struct vub300_mmc_host *vub300) <answer> void 
<token> = 20; <answer> vub300->cmnd.head.header_size 
<token> = 0x00; <answer> vub300->cmnd.head.header_type 
static void vub300_sg_timed_out(struct <token> *t) <answer> timer_list 
<token> vub300_mmc_host *vub300 = from_timer(vub300, t, <answer> struct 
vub300->usb_timed_out <token> 1; <answer> = 
static <token> roundup_to_multiple_of_64(u16 number) <answer> u16 
return 0xFFC0 & <token> + number); <answer> (0x3F 
static void __download_offload_pseudocode(struct vub300_mmc_host <token> <answer> *vub300, 
const <token> firmware *fw) <answer> struct 
<token> register_count = 0; <answer> u8 
u16 ts <token> 0; <answer> = 
<token> interrupt_size = 0; <answer> u16 
const u8 <token> = fw->data; <answer> *data 
int <token> = fw->size; <answer> size 
u8 <token> <answer> c; 
dev_info(&vub300->udev->dev, "using %s for SDIO <token> processing\n", <answer> offload 
do <token> <answer> { 
<token> = *data++; <answer> c 
static void download_offload_pseudocode(struct vub300_mmc_host <token> <answer> *vub300) 
struct <token> *card = vub300->mmc->card; <answer> mmc_card 
int sdio_funcs <token> card->sdio_funcs; <answer> = 
const struct firmware *fw <token> NULL; <answer> = 
<token> l = snprintf(vub300->vub_name, sizeof(vub300->vub_name), <answer> int 
"vub_%04X%04X", <token> card->cis.device); <answer> card->cis.vendor, 
int n <token> 0; <answer> = 
int <token> <answer> retval; 
for (n = 0; n < sdio_funcs; n++) <token> <answer> { 
struct sdio_func *sf <token> card->sdio_func[n]; <answer> = 
l += scnprintf(vub300->vub_name + <token> <answer> l, 
sizeof(vub300->vub_name) - l, <token> <answer> "_%04X%04X", 
sf->vendor, <token> <answer> sf->device); 
snprintf(vub300->vub_name + l, <token> - l, ".bin"); <answer> sizeof(vub300->vub_name) 
dev_info(&vub300->udev->dev, "requesting <token> firmware %s\n", <answer> offload 
retval = request_firmware(&fw, vub300->vub_name, <token> <answer> &card->dev); 
<token> (retval < 0) { <answer> if 
strscpy(vub300->vub_name, <token> <answer> "vub_default.bin", 
retval = <token> vub300->vub_name, &card->dev); <answer> request_firmware(&fw, 
if (retval < <token> { <answer> 0) 
<token> SDIO offload firmware found", <answer> "no 
<token> else { <answer> } 
<token> fw); <answer> __download_offload_pseudocode(vub300, 
<token> else { <answer> } 
__download_offload_pseudocode(vub300, <token> <answer> fw); 
static <token> vub300_usb_bulk_msg_completion(struct urb *urb) <answer> void 
<token> else if (vub300->command_out_urb->status) { <answer> } 
vub300->usb_transport_fail <token> vub300->command_out_urb->status; <answer> = 
cmd->error <token> -EPROTO == vub300->command_out_urb->status ? <answer> = 
-ESHUTDOWN : <token> <answer> vub300->command_out_urb->status; 
} else if (vub300->command_res_urb->status) <token> <answer> { 
<token> = vub300->command_res_urb->status; <answer> vub300->usb_transport_fail 
cmd->error = -EPROTO <token> vub300->command_res_urb->status ? <answer> == 
<token> : vub300->command_res_urb->status; <answer> -ESHUTDOWN 
} else if (vub300->resp.common.header_type <token> 0x00) { <answer> == 
} <token> if (vub300->resp.common.header_type == RESPONSE_ERROR) { <answer> else 
cmd->error <token> <answer> = 
<token> (vub300->data) <answer> if 
<token> else if (vub300->resp.common.header_type == RESPONSE_PIGGYBACKED) { <answer> } 
int offloaded_data_length <token> <answer> = 
<token> - <answer> vub300->resp.common.header_size 
<token> sd_register_header); <answer> sizeof(struct 
int register_count <token> offloaded_data_length >> 3; <answer> = 
int ri <token> 0; <answer> = 
while <token> { <answer> (register_count--) 
add_offloaded_reg(vub300, <token> <answer> &vub300->resp.pig.reg[ri]); 
<token> += 1; <answer> ri 
vub300->resp.common.header_size <token> <answer> = 
<token> sd_register_header); <answer> sizeof(struct 
<token> = 0x00; <answer> vub300->resp.common.header_type 
<token> = 0; <answer> cmd->error 
} else if <token> == RESPONSE_PIG_DISABLED) { <answer> (vub300->resp.common.header_type 
int <token> = <answer> offloaded_data_length 
<token> - <answer> vub300->resp.common.header_size 
sizeof(struct <token> <answer> sd_register_header); 
int register_count = offloaded_data_length >> <token> <answer> 3; 
int ri <token> 0; <answer> = 
while (register_count--) <token> <answer> { 
<token> &vub300->resp.pig.reg[ri]); <answer> add_offloaded_reg(vub300, 
ri <token> 1; <answer> += 
<token> (vub300->irqs_queued) { <answer> if 
vub300->irqs_queued <token> 1; <answer> += 
} else <token> (vub300->irq_enabled) { <answer> if 
vub300->irqs_queued <token> 1; <answer> += 
<token> 0); <answer> vub300_queue_poll_work(vub300, 
} <token> { <answer> else 
vub300->irqs_queued <token> 1; <answer> += 
<token> = 1; <answer> vub300->irq_disabled 
<token> = <answer> vub300->resp.common.header_size 
<token> sd_register_header); <answer> sizeof(struct 
<token> = 0x00; <answer> vub300->resp.common.header_type 
cmd->error <token> 0; <answer> = 
<token> else if (vub300->resp.common.header_type == RESPONSE_PIG_ENABLED) { <answer> } 
int <token> = <answer> offloaded_data_length 
<token> - <answer> vub300->resp.common.header_size 
<token> sd_register_header); <answer> sizeof(struct 
int register_count = offloaded_data_length >> <token> <answer> 3; 
int ri = <token> <answer> 0; 
while <token> { <answer> (register_count--) 
add_offloaded_reg(vub300, <token> <answer> &vub300->resp.pig.reg[ri]); 
ri += <token> <answer> 1; 
if (vub300->irqs_queued) <token> <answer> { 
vub300->irqs_queued <token> 1; <answer> += 
} else if (vub300->irq_enabled) <token> <answer> { 
vub300->irqs_queued <token> 1; <answer> += 
vub300_queue_poll_work(vub300, <token> <answer> 0); 
} else <token> <answer> { 
vub300->irqs_queued += <token> <answer> 1; 
vub300->irq_disabled = <token> <answer> 0; 
<token> = <answer> vub300->resp.common.header_size 
<token> sd_register_header); <answer> sizeof(struct 
vub300->resp.common.header_type = <token> <answer> 0x00; 
cmd->error <token> 0; <answer> = 
} <token> { <answer> else 
cmd->error <token> -EINVAL; <answer> = 
static <token> construct_request_response(struct vub300_mmc_host *vub300, <answer> void 
struct mmc_command <token> <answer> *cmd) 
int resp_len = <token> <answer> vub300->resp_len; 
int <token> = (17 == resp_len) ? resp_len : resp_len - 1; <answer> less_cmd 
int bytes = 3 <token> less_cmd; <answer> & 
int words <token> less_cmd >> 2; <answer> = 
u8 *r = <token> <answer> vub300->resp.response.command_response; 
if <token> <answer> (!resp_len) 
if (bytes == 3) <token> <answer> { 
cmd->resp[words] = (r[1 <token> (words << 2)] << 24) <answer> + 
<token> (r[2 + (words << 2)] << 16) <answer> | 
| (r[3 + (words <token> 2)] << 8); <answer> << 
} else if (bytes == <token> { <answer> 2) 
cmd->resp[words] = (r[1 + (words << <token> << 24) <answer> 2)] 
| (r[2 + (words << <token> << 16); <answer> 2)] 
} else if (bytes <token> 1) { <answer> == 
cmd->resp[words] = (r[1 + <token> << 2)] << 24); <answer> (words 
while (words-- <token> 0) { <answer> > 
cmd->resp[words] = (r[1 + (words << 2)] <token> 24) <answer> << 
| (r[2 + (words << 2)] <token> 16) <answer> << 
| (r[3 + (words << 2)] << <token> <answer> 8) 
| (r[4 + (words << 2)] <token> 0); <answer> << 
if ((cmd->opcode == 53) && <token> & cmd->resp[0])) <answer> (0x000000FF 
cmd->resp[0] <token> 0xFFFFFF00; <answer> &= 
} <token> if (0 == vub300->mmc->card->sdio_funcs) { <answer> else 
<token> "SD memory device", <answer> strscpy(vub300->vub_name, 
<token> else { <answer> } 
if <token> <answer> (!data) 
<token> = 0; <answer> data_length 
else if <token> & data->flags) <answer> (MMC_DATA_READ 
data_length = __command_read_data(vub300, <token> data); <answer> cmd, 
data_length = __command_write_data(vub300, <token> data); <answer> cmd, 
__vub300_command_response(vub300, cmd, data, <token> <answer> data_length); 
vub300->req <token> NULL; <answer> = 
vub300->cmd <token> NULL; <answer> = 
<token> = NULL; <answer> vub300->data 
<token> (cmd->error) { <answer> if 
<token> (cmd->error == -ENOMEDIUM) <answer> if 
<token> req); <answer> mmc_request_done(vub300->mmc, 
kref_put(&vub300->kref, <token> <answer> vub300_delete); 
} <token> { <answer> else 
construct_request_response(vub300, <token> <answer> cmd); 
vub300->resp_len <token> 0; <answer> = 
kref_put(&vub300->kref, <token> <answer> vub300_delete); 
mmc_request_done(vub300->mmc, <token> <answer> req); 
static int <token> vub300_mmc_host *vub300, <answer> examine_cyclic_buffer(struct 
struct mmc_command *cmd, u8 <token> <answer> Function) 
<token> = 0; <answer> vub300->sdio_register[i].prepared 
<token> 0; <answer> return 
} <token> { <answer> else 
<token> checksum = 0x00; <answer> u8 
u8 rsp0 <token> 0x00; <answer> = 
u8 rsp1 <token> 0x00; <answer> = 
u8 rsp2 = <token> <answer> vub300->sdio_register[i].response; 
u8 rsp3 <token> vub300->sdio_register[i].regvalue; <answer> = 
vub300->sdio_register[i].prepared = <token> <answer> 0; 
<token> = checksum << 24; <answer> cmd->resp[1] 
cmd->resp[0] = (rsp0 << <token> <answer> 24) 
| (rsp1 << <token> <answer> 16) 
<token> (rsp2 << 8) <answer> | 
| (rsp3 << <token> <answer> 0); 
return <token> <answer> 1; 
} else <token> <answer> { 
<token> += 1; <answer> i 
if <token> == 0) <answer> (vub300->total_offload_count 
<token> 0; <answer> return 
<token> if (vub300->fn[func].offload_count == 0) <answer> else 
<token> 0; <answer> return 
return <token> cmd, func); <answer> examine_cyclic_buffer(vub300, 
static void vub300_mmc_request(struct mmc_host <token> struct mmc_request *req) <answer> *mmc, 
<token> (cmd->opcode == 52 && <answer> if 
satisfy_request_from_offloaded_data(vub300, cmd)) <token> <answer> { 
cmd->error <token> 0; <answer> = 
<token> vub300_delete); <answer> kref_put(&vub300->kref, 
<token> req); <answer> mmc_request_done(mmc, 
} else <token> <answer> { 
<token> = cmd; <answer> vub300->cmd 
<token> = req; <answer> vub300->req 
vub300->data = <token> <answer> data; 
if <token> <answer> (data) 
vub300->datasize <token> data->blksz * data->blocks; <answer> = 
<token> = 0; <answer> vub300->datasize 
kref_put(&vub300->kref, <token> <answer> vub300_delete); 
static void <token> vub300_mmc_host *vub300, u8 buf[8], <answer> __set_clock_speed(struct 
<token> mmc_ios *ios) <answer> struct 
if <token> { <answer> (limit_speed_to_24_MHz) 
mmc->caps <token> MMC_CAP_MMC_HIGHSPEED; <answer> |= 
<token> |= MMC_CAP_SD_HIGHSPEED; <answer> mmc->caps 
mmc->f_max <token> 24000000; <answer> = 
dev_info(&udev->dev, "limiting SDIO <token> to 24_MHz\n"); <answer> speed 
} <token> { <answer> else 
<token> |= MMC_CAP_MMC_HIGHSPEED; <answer> mmc->caps 
mmc->caps <token> MMC_CAP_SD_HIGHSPEED; <answer> |= 
mmc->f_max = <token> <answer> 48000000; 
mmc->f_min = <token> <answer> 200000; 
mmc->max_blk_count = <token> <answer> 511; 
mmc->max_blk_size = <token> <answer> 512; 
mmc->max_segs = <token> <answer> 128; 
if <token> <answer> (force_max_req_size) 
mmc->max_req_size = force_max_req_size <token> 1024; <answer> * 
mmc->max_req_size <token> 64 * 1024; <answer> = 
<token> = mmc->max_req_size; <answer> mmc->max_seg_size 
mmc->ocr_avail <token> 0; <answer> = 
mmc->ocr_avail |= <token> <answer> MMC_VDD_165_195; 
mmc->ocr_avail |= <token> <answer> MMC_VDD_20_21; 
mmc->ocr_avail |= <token> <answer> MMC_VDD_21_22; 
<token> |= MMC_VDD_22_23; <answer> mmc->ocr_avail 
<token> |= MMC_VDD_23_24; <answer> mmc->ocr_avail 
mmc->ocr_avail |= <token> <answer> MMC_VDD_24_25; 
mmc->ocr_avail <token> MMC_VDD_25_26; <answer> |= 
<token> |= MMC_VDD_26_27; <answer> mmc->ocr_avail 
mmc->ocr_avail <token> MMC_VDD_27_28; <answer> |= 
mmc->ocr_avail |= <token> <answer> MMC_VDD_28_29; 
<token> |= MMC_VDD_29_30; <answer> mmc->ocr_avail 
mmc->ocr_avail <token> MMC_VDD_30_31; <answer> |= 
<token> |= MMC_VDD_31_32; <answer> mmc->ocr_avail 
mmc->ocr_avail |= <token> <answer> MMC_VDD_32_33; 
mmc->ocr_avail <token> MMC_VDD_33_34; <answer> |= 
mmc->ocr_avail |= <token> <answer> MMC_VDD_34_35; 
mmc->ocr_avail <token> MMC_VDD_35_36; <answer> |= 
<token> = &vub300_mmc_ops; <answer> mmc->ops 
vub300 = <token> <answer> mmc_priv(mmc); 
<token> = mmc; <answer> vub300->mmc 
vub300->card_powered <token> 0; <answer> = 
vub300->bus_width = <token> <answer> 0; 
<token> = 0x00; <answer> vub300->cmnd.head.block_size[0] 
vub300->cmnd.head.block_size[1] = <token> <answer> 0x00; 
vub300->app_spec <token> 0; <answer> = 
<token> = command_out_urb; <answer> vub300->command_out_urb 
vub300->command_res_urb = <token> <answer> command_res_urb; 
vub300->usb_timed_out <token> 0; <answer> = 
vub300->dynamic_register_count = <token> <answer> 0; 
for <token> = 0; i < ARRAY_SIZE(vub300->fn); i++) { <answer> (i 
<token> = 0; <answer> vub300->fn[i].offload_point 
vub300->fn[i].offload_count = <token> <answer> 0; 
vub300->total_offload_count <token> 0; <answer> = 
<token> = 0; <answer> vub300->irq_enabled 
vub300->irq_disabled = <token> <answer> 0; 
vub300->irqs_queued <token> 0; <answer> = 
for (i = 0; i < ARRAY_SIZE(vub300->sdio_register); <token> <answer> i++) 
<token> = 0; <answer> vub300->sdio_register[i++].activate 
vub300->udev = <token> <answer> udev; 
vub300->interface <token> interface; <answer> = 
vub300->cmnd_res_ep = <token> <answer> 0; 
<token> = 0; <answer> vub300->cmnd_out_ep 
<token> = 0; <answer> vub300->data_inp_ep 
<token> = 0; <answer> vub300->data_out_ep 
for <token> = 0; i < ARRAY_SIZE(vub300->fbs); i++) <answer> (i 
vub300->fbs[i] <token> 512; <answer> = 
vub300->large_usb_packets <token> 0; <answer> = 
iface_desc = <token> <answer> interface->cur_altsetting; 
for (i = 0; i <token> iface_desc->desc.bNumEndpoints; ++i) { <answer> < 
struct usb_endpoint_descriptor *endpoint <token> <answer> = 
"vub300 <token> %s EndPoint(%d) %02X\n", <answer> testing 
usb_endpoint_is_bulk_in(endpoint) ? "BULK <token> : <answer> IN" 
<token> ? "BULK OUT" : <answer> usb_endpoint_is_bulk_out(endpoint) 
<token> i, endpoint->bEndpointAddress); <answer> "UNKNOWN", 
if <token> > 64) <answer> (endpoint->wMaxPacketSize 
<token> = 1; <answer> vub300->large_usb_packets 
<token> (usb_endpoint_is_bulk_in(endpoint)) { <answer> if 
if <token> { <answer> (!vub300->cmnd_res_ep) 
<token> = <answer> vub300->cmnd_res_ep 
} else <token> (!vub300->data_inp_ep) { <answer> if 
vub300->data_inp_ep <token> <answer> = 
<token> else { <answer> } 
" unexpected bulk_in <token> <answer> endpoint"); 
<token> else if (usb_endpoint_is_bulk_out(endpoint)) { <answer> } 
<token> (!vub300->cmnd_out_ep) { <answer> if 
<token> = <answer> vub300->cmnd_out_ep 
} else if (!vub300->data_out_ep) <token> <answer> { 
vub300->data_out_ep <token> <answer> = 
} <token> { <answer> else 
" unexpected <token> endpoint"); <answer> bulk_out 
} else <token> <answer> { 
"vub300 ignoring EndPoint(%d) %02X", <token> <answer> i, 
if (vub300->cmnd_res_ep && vub300->cmnd_out_ep <token> <answer> && 
vub300->data_inp_ep && <token> { <answer> vub300->data_out_ep) 
<token> %s packets" <answer> "vub300 
" using EndPoints %02X %02X %02X <token> <answer> %02X\n", 
vub300->large_usb_packets ? "LARGE" : <token> <answer> "SMALL", 
<token> vub300->cmnd_res_ep, <answer> vub300->cmnd_out_ep, 
<token> vub300->data_inp_ep); <answer> vub300->data_out_ep, 
return <token> <answer> retval; 
static <token> vub300_disconnect(struct usb_interface *interface) <answer> void 
#include <token> <answer> <linux/bitops.h> 
#include <token> <answer> <linux/i2c.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/mod_devicetable.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/mutex.h> <answer> #include 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> <linux/time64.h> 
<token> <linux/iio/iio.h> <answer> #include 
#define DRIVER_NAME <token> <answer> "sunrise_co2" 
#define SUNRISE_ERROR_STATUS_REG <token> <answer> 0x00 
#define <token> 0x06 <answer> SUNRISE_CO2_FILTERED_COMP_REG 
<token> SUNRISE_CHIP_TEMPERATURE_REG 0x08 <answer> #define 
#define <token> 0x81 <answer> SUNRISE_CALIBRATION_STATUS_REG 
<token> SUNRISE_CALIBRATION_COMMAND_REG 0x82 <answer> #define 
#define <token> 0x7c02 <answer> SUNRISE_CALIBRATION_FACTORY_CMD 
#define SUNRISE_CALIBRATION_BACKGROUND_CMD <token> <answer> 0x7c06 
#define SUNRISE_CALIBRATION_TIMEOUT_US <token> * USEC_PER_SEC) <answer> (30 
<token> sunrise_dev { <answer> struct 
struct i2c_client <token> <answer> *client; 
<token> regmap *regmap; <answer> struct 
<token> client->addr, <answer> __i2c_smbus_xfer(client->adapter, 
sunrise->ignore_nak ? I2C_M_IGNORE_NAK <token> 0, <answer> : 
I2C_SMBUS_WRITE, 0, I2C_SMBUS_BYTE_DATA, <token> <answer> &data); 
usleep_range(500, <token> <answer> 1500); 
ret = __i2c_smbus_xfer(client->adapter, <token> client->flags, <answer> client->addr, 
<token> ((u8 *)reg_buf)[0], <answer> I2C_SMBUS_READ, 
I2C_SMBUS_I2C_BLOCK_DATA, <token> <answer> &data); 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
memcpy(val_buf, &data.block[1], <token> <answer> data.block[0]); 
return <token> <answer> 0; 
static int sunrise_regmap_write(void *context, const void *val_buf, size_t <token> <answer> count) 
struct i2c_client *client = <token> <answer> context; 
struct sunrise_dev *sunrise = <token> <answer> i2c_get_clientdata(client); 
union <token> data; <answer> i2c_smbus_data 
static int sunrise_read_byte(struct sunrise_dev <token> u8 reg) <answer> *sunrise, 
const struct i2c_client *client = <token> <answer> sunrise->client; 
const struct device *dev = <token> <answer> &client->dev; 
unsigned <token> val; <answer> int 
<token> ret; <answer> int 
i2c_lock_bus(client->adapter, <token> <answer> I2C_LOCK_SEGMENT); 
<token> = regmap_read(sunrise->regmap, reg, &val); <answer> ret 
<token> I2C_LOCK_SEGMENT); <answer> i2c_unlock_bus(client->adapter, 
if <token> { <answer> (ret) 
dev_err(dev, "Read byte <token> reg 0x%02x (%d)\n", reg, ret); <answer> failed: 
<token> ret; <answer> return 
return <token> <answer> val; 
static int <token> sunrise_dev *sunrise, u8 reg, u16 *val) <answer> sunrise_read_word(struct 
const struct <token> *client = sunrise->client; <answer> i2c_client 
const struct device *dev = <token> <answer> &client->dev; 
__be16 <token> <answer> be_val; 
int <token> <answer> ret; 
<token> I2C_LOCK_SEGMENT); <answer> i2c_lock_bus(client->adapter, 
ret = regmap_bulk_read(sunrise->regmap, reg, <token> sizeof(be_val)); <answer> &be_val, 
i2c_unlock_bus(client->adapter, <token> <answer> I2C_LOCK_SEGMENT); 
<token> (ret) { <answer> if 
dev_err(dev, "Read word failed: reg <token> (%d)\n", reg, ret); <answer> 0x%02x 
<token> ret; <answer> return 
*val <token> be16_to_cpu(be_val); <answer> = 
<token> 0; <answer> return 
static int sunrise_write_byte(struct sunrise_dev *sunrise, u8 <token> u8 val) <answer> reg, 
const struct i2c_client *client <token> sunrise->client; <answer> = 
<token> struct device *dev = &client->dev; <answer> const 
<token> ret; <answer> int 
i2c_lock_bus(client->adapter, <token> <answer> I2C_LOCK_SEGMENT); 
<token> = regmap_write(sunrise->regmap, reg, val); <answer> ret 
i2c_unlock_bus(client->adapter, <token> <answer> I2C_LOCK_SEGMENT); 
if <token> <answer> (ret) 
dev_err(dev, "Write byte failed: reg <token> (%d)\n", reg, ret); <answer> 0x%02x 
<token> ret; <answer> return 
static int sunrise_write_word(struct <token> *sunrise, u8 reg, u16 data) <answer> sunrise_dev 
const struct i2c_client <token> = sunrise->client; <answer> *client 
<token> struct device *dev = &client->dev; <answer> const 
__be16 be_data = <token> <answer> cpu_to_be16(data); 
<token> ret; <answer> int 
<token> I2C_LOCK_SEGMENT); <answer> i2c_lock_bus(client->adapter, 
ret <token> regmap_bulk_write(sunrise->regmap, reg, &be_data, sizeof(be_data)); <answer> = 
i2c_unlock_bus(client->adapter, <token> <answer> I2C_LOCK_SEGMENT); 
if <token> <answer> (ret) 
dev_err(dev, <token> word failed: reg 0x%02x (%d)\n", reg, ret); <answer> "Write 
<token> ret; <answer> return 
return read_poll_timeout(sunrise_read_byte, status, status & <token> <answer> data->bit, 
200000, SUNRISE_CALIBRATION_TIMEOUT_US, <token> <answer> false, 
<token> SUNRISE_CALIBRATION_STATUS_REG); <answer> sunrise, 
static ssize_t <token> iio_dev *iiodev, <answer> sunrise_cal_factory_write(struct 
uintptr_t <token> <answer> private, 
<token> struct iio_chan_spec *chan, <answer> const 
<token> char *buf, size_t len) <answer> const 
struct <token> *sunrise = iio_priv(iiodev); <answer> sunrise_dev 
bool <token> <answer> enable; 
<token> ret; <answer> int 
<token> = kstrtobool(buf, &enable); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> (!enable) <answer> if 
return <token> <answer> len; 
ret = <token> &calib_data[SUNRISE_CALIBRATION_FACTORY]); <answer> sunrise_calibrate(sunrise, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
return <token> <answer> len; 
static ssize_t sunrise_cal_background_write(struct iio_dev <token> <answer> *iiodev, 
<token> private, <answer> uintptr_t 
const <token> iio_chan_spec *chan, <answer> struct 
const char *buf, <token> len) <answer> size_t 
struct sunrise_dev *sunrise <token> iio_priv(iiodev); <answer> = 
bool <token> <answer> enable; 
int <token> <answer> ret; 
ret = <token> &enable); <answer> kstrtobool(buf, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> (!enable) <answer> if 
return <token> <answer> len; 
<token> = sunrise_calibrate(sunrise, &calib_data[SUNRISE_CALIBRATION_BACKGROUND]); <answer> ret 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> len; <answer> return 
<token> = 1; <answer> *val 
*val2 <token> 10000; <answer> = 
<token> IIO_VAL_FRACTIONAL; <answer> return 
case <token> <answer> IIO_TEMP: 
if (i2c_check_functionality(client->adapter, <token> <answer> I2C_FUNC_PROTOCOL_MANGLING)) 
<token> = true; <answer> sunrise->ignore_nak 
iio_dev->info = <token> <answer> &sunrise_info; 
iio_dev->name = <token> <answer> DRIVER_NAME; 
iio_dev->channels <token> sunrise_channels; <answer> = 
<token> = ARRAY_SIZE(sunrise_channels); <answer> iio_dev->num_channels 
iio_dev->modes = <token> <answer> INDIO_DIRECT_MODE; 
return <token> iio_dev); <answer> devm_iio_device_register(&client->dev, 
static const <token> of_device_id sunrise_of_match[] = { <answer> struct 
{ .compatible <token> "senseair,sunrise-006-0-0007" }, <answer> = 
<token> sunrise_of_match); <answer> MODULE_DEVICE_TABLE(of, 
static struct i2c_driver <token> = { <answer> sunrise_driver 
<token> = { <answer> .driver 
.name <token> DRIVER_NAME, <answer> = 
.of_match_table <token> sunrise_of_match, <answer> = 
.probe = <token> <answer> sunrise_probe, 
MODULE_AUTHOR("Jacopo Mondi <token> <answer> <jacopo@jmondi.org>"); 
MODULE_DESCRIPTION("Senseair Sunrise 006-0-0007 CO2 <token> IIO driver"); <answer> sensor 
MODULE_LICENSE("GPL <token> <answer> v2"); 
#include <token> <answer> <linux/bpf.h> 
<token> <bpf/bpf_helpers.h> <answer> #include 
#include <token> <answer> <bpf/bpf_endian.h> 
int bpf_prog1(struct sk_msg_md <token> <answer> *msg) 
<token> SK_PASS; <answer> return 
<token> _license[] SEC("license") = "GPL"; <answer> char 
#define pr_fmt(fmt) <token> ": " fmt <answer> KBUILD_MODNAME 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/spinlock.h> 
#include <token> <answer> <linux/completion.h> 
<token> <linux/buffer_head.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/gfs2_ondisk.h> 
#include <token> <answer> <linux/rcupdate.h> 
<token> <linux/rculist_bl.h> <answer> #include 
#include <token> <answer> <linux/atomic.h> 
<token> <linux/mempool.h> <answer> #include 
<token> "gfs2.h" <answer> #include 
<token> "incore.h" <answer> #include 
#include <token> <answer> "super.h" 
<token> "sys.h" <answer> #include 
#include <token> <answer> "util.h" 
<token> "glock.h" <answer> #include 
<token> "quota.h" <answer> #include 
<token> "recovery.h" <answer> #include 
#include <token> <answer> "dir.h" 
<token> "glops.h" <answer> #include 
<token> workqueue_struct *gfs2_control_wq; <answer> struct 
static void <token> *foo) <answer> gfs2_init_inode_once(void 
<token> gfs2_inode *ip = foo; <answer> struct 
<token> 0); <answer> atomic_set(&ip->i_sizehint, 
ip->i_qadata <token> NULL; <answer> = 
memset(&ip->i_res, 0, <token> <answer> sizeof(ip->i_res)); 
ip->i_hash_cache <token> NULL; <answer> = 
static void <token> *foo) <answer> gfs2_init_glock_once(void 
struct <token> *gl = foo; <answer> gfs2_glock 
atomic_set(&gl->gl_ail_count, <token> <answer> 0); 
atomic_set(&gl->gl_revokes, <token> <answer> 0); 
static <token> gfs2_init_gl_aspace_once(void *foo) <answer> void 
struct <token> *gla = foo; <answer> gfs2_glock_aspace 
static <token> __init init_gfs2_fs(void) <answer> int 
<token> error; <answer> int 
<token> "."); <answer> gfs2_str2qstr(&gfs2_qdot, 
<token> ".."); <answer> gfs2_str2qstr(&gfs2_qdotdot, 
error = <token> <answer> gfs2_sys_init(); 
if <token> <answer> (error) 
<token> error; <answer> return 
error = <token> <answer> list_lru_init(&gfs2_qd_lru); 
if <token> <answer> (error) 
goto <token> <answer> fail_lru; 
error <token> gfs2_glock_init(); <answer> = 
<token> (error) <answer> if 
goto <token> <answer> fail_glock; 
error = <token> <answer> -ENOMEM; 
<token> = kmem_cache_create("gfs2_glock", <answer> gfs2_glock_cachep 
sizeof(struct <token> <answer> gfs2_glock), 
0, <token> <answer> SLAB_RECLAIM_ACCOUNT, 
if <token> <answer> (!gfs2_glock_cachep) 
goto <token> <answer> fail_cachep1; 
gfs2_glock_aspace_cachep = <token> <answer> kmem_cache_create("gfs2_glock(aspace)", 
sizeof(struct <token> <answer> gfs2_glock_aspace), 
<token> 0, gfs2_init_gl_aspace_once); <answer> 0, 
if <token> <answer> (!gfs2_glock_aspace_cachep) 
<token> fail_cachep2; <answer> goto 
gfs2_inode_cachep <token> kmem_cache_create("gfs2_inode", <answer> = 
sizeof(struct <token> <answer> gfs2_inode), 
<token> SLAB_RECLAIM_ACCOUNT| <answer> 0, 
if <token> <answer> (!gfs2_inode_cachep) 
<token> fail_cachep3; <answer> goto 
gfs2_bufdata_cachep <token> kmem_cache_create("gfs2_bufdata", <answer> = 
<token> gfs2_bufdata), <answer> sizeof(struct 
0, 0, <token> <answer> NULL); 
<token> (!gfs2_bufdata_cachep) <answer> if 
goto <token> <answer> fail_cachep4; 
<token> = kmem_cache_create("gfs2_rgrpd", <answer> gfs2_rgrpd_cachep 
<token> gfs2_rgrpd), <answer> sizeof(struct 
0, 0, <token> <answer> NULL); 
if <token> <answer> (!gfs2_rgrpd_cachep) 
<token> fail_cachep5; <answer> goto 
gfs2_quotad_cachep = <token> <answer> kmem_cache_create("gfs2_quotad", 
sizeof(struct <token> <answer> gfs2_quota_data), 
0, SLAB_RECLAIM_ACCOUNT, <token> <answer> NULL); 
if <token> <answer> (!gfs2_quotad_cachep) 
goto <token> <answer> fail_cachep6; 
gfs2_qadata_cachep <token> kmem_cache_create("gfs2_qadata", <answer> = 
<token> gfs2_qadata), <answer> sizeof(struct 
<token> 0, NULL); <answer> 0, 
if <token> <answer> (!gfs2_qadata_cachep) 
goto <token> <answer> fail_cachep7; 
gfs2_trans_cachep = <token> <answer> kmem_cache_create("gfs2_trans", 
<token> gfs2_trans), <answer> sizeof(struct 
0, <token> NULL); <answer> 0, 
if <token> <answer> (!gfs2_trans_cachep) 
goto <token> <answer> fail_cachep8; 
error <token> gfs2_qd_shrinker_init(); <answer> = 
if <token> <answer> (error) 
<token> fail_shrinker; <answer> goto 
error = <token> <answer> -ENOMEM; 
gfs2_recovery_wq = <token> <answer> alloc_workqueue("gfs2_recovery", 
WQ_MEM_RECLAIM | <token> 0); <answer> WQ_FREEZABLE, 
<token> (!gfs2_recovery_wq) <answer> if 
goto <token> <answer> fail_wq1; 
<token> = alloc_workqueue("gfs2_control", <answer> gfs2_control_wq 
WQ_UNBOUND | WQ_FREEZABLE, <token> <answer> 0); 
if <token> <answer> (!gfs2_control_wq) 
<token> fail_wq2; <answer> goto 
gfs2_freeze_wq = alloc_workqueue("gfs2_freeze", <token> 0); <answer> 0, 
<token> (!gfs2_freeze_wq) <answer> if 
goto <token> <answer> fail_wq3; 
<token> = mempool_create_page_pool(64, 0); <answer> gfs2_page_pool 
<token> (!gfs2_page_pool) <answer> if 
goto <token> <answer> fail_mempool; 
error <token> register_filesystem(&gfs2_fs_type); <answer> = 
if <token> <answer> (error) 
goto <token> <answer> fail_fs1; 
error <token> register_filesystem(&gfs2meta_fs_type); <answer> = 
if <token> <answer> (error) 
<token> fail_fs2; <answer> goto 
<token> installed\n"); <answer> pr_info("GFS2 
<token> 0; <answer> return 
return <token> <answer> error; 
<token> void __exit exit_gfs2_fs(void) <answer> static 
MODULE_DESCRIPTION("Global File <token> <answer> System"); 
MODULE_AUTHOR("Red <token> Inc."); <answer> Hat, 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/ioport.h> 
<token> <linux/isa.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/netdevice.h> <answer> #include 
<token> "sja1000.h" <answer> #include 
MODULE_DESCRIPTION("Driver for Technologic Systems TS-CAN1 <token> boards"); <answer> PC104 
MODULE_AUTHOR("Andre B. <token> <anbadeol@gmail.com>"); <answer> Oliveira 
#include <token> <answer> <linux/dmi.h> 
#include <token> <answer> <linux/hid.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/platform_data/x86/asus-wmi.h> <answer> #include 
#include <token> <answer> <linux/input/mt.h> 
if (report->id <token> FEATURE_KBD_LED_REPORT_ID1 || <answer> == 
report->id <token> FEATURE_KBD_LED_REPORT_ID2) { <answer> == 
<token> -1; <answer> return 
if (data[1] == 0xea || <token> == 0xec || data[1] == 0x02 || <answer> data[1] 
data[1] == 0x8a || data[1] == 0x9e) <token> <answer> { 
<token> -1; <answer> return 
<token> (drvdata->quirks & QUIRK_ROG_NKEY_KEYBOARD) { <answer> if 
if(data[0] == <token> && data[1] == 0x30) { <answer> 0x02 
return <token> <answer> -1; 
if (drvdata->quirks & QUIRK_ROG_CLAYMORE_II_KEYBOARD) <token> <answer> { 
if(size <token> 2 && data[0] == 0x02 && data[1] == 0x00) { <answer> == 
<token> -1; <answer> return 
return <token> <answer> 0; 
static int asus_kbd_set_report(struct hid_device *hdev, const <token> *buf, size_t buf_size) <answer> u8 
unsigned <token> *dmabuf; <answer> char 
<token> ret; <answer> int 
<token> = kmemdup(buf, buf_size, GFP_KERNEL); <answer> dmabuf 
<token> (!dmabuf) <answer> if 
return <token> <answer> -ENOMEM; 
ret = <token> buf[0], dmabuf, <answer> hid_hw_raw_request(hdev, 
<token> HID_FEATURE_REPORT, <answer> buf_size, 
return <token> <answer> ret; 
static int <token> hid_device *hdev) <answer> asus_kbd_init(struct 
const u8 buf[] = { FEATURE_KBD_REPORT_ID, 0x41, 0x53, 0x55, 0x53, <token> 0x54, <answer> 0x20, 
<token> 0x63, 0x68, 0x2e, 0x49, 0x6e, 0x63, 0x2e, 0x00 }; <answer> 0x65, 
int <token> <answer> ret; 
ret = asus_kbd_set_report(hdev, buf, <token> <answer> sizeof(buf)); 
if (ret <token> 0) <answer> < 
hid_err(hdev, "Asus failed to send init command: %d\n", <token> <answer> ret); 
<token> ret; <answer> return 
<token> int asus_kbd_get_functions(struct hid_device *hdev, <answer> static 
unsigned char <token> <answer> *kbd_func) 
const u8 buf[] = { FEATURE_KBD_REPORT_ID, 0x05, 0x20, 0x31, 0x00, <token> }; <answer> 0x08 
u8 <token> <answer> *readbuf; 
<token> ret; <answer> int 
<token> = asus_kbd_set_report(hdev, buf, sizeof(buf)); <answer> ret 
if (ret < 0) <token> <answer> { 
hid_err(hdev, "Asus failed <token> send configuration command: %d\n", ret); <answer> to 
return <token> <answer> ret; 
<token> = kzalloc(FEATURE_KBD_REPORT_SIZE, GFP_KERNEL); <answer> readbuf 
<token> (!readbuf) <answer> if 
<token> -ENOMEM; <answer> return 
ret = <token> FEATURE_KBD_REPORT_ID, readbuf, <answer> hid_hw_raw_request(hdev, 
FEATURE_KBD_REPORT_SIZE, <token> <answer> HID_FEATURE_REPORT, 
if (ret <token> 0) { <answer> < 
hid_err(hdev, "Asus failed to request functions: <token> ret); <answer> %d\n", 
<token> ret; <answer> return 
*kbd_func = <token> <answer> readbuf[6]; 
<token> ret; <answer> return 
<token> int rog_nkey_led_init(struct hid_device *hdev) <answer> static 
const u8 buf_init_start[] = <token> FEATURE_KBD_LED_REPORT_ID1, 0xB9 }; <answer> { 
u8 buf_init2[] = { FEATURE_KBD_LED_REPORT_ID1, 0x41, 0x53, 0x55, 0x53, <token> <answer> 0x20, 
0x54, 0x65, 0x63, 0x68, 0x2e, 0x49, 0x6e, 0x63, 0x2e, <token> }; <answer> 0x00 
u8 buf_init3[] <token> { FEATURE_KBD_LED_REPORT_ID1, <answer> = 
0x05, 0x20, 0x31, 0x00, <token> }; <answer> 0x08 
int <token> <answer> ret; 
hid_info(hdev, "Asus initialise <token> Device"); <answer> N-KEY 
static bool asus_kbd_wmi_led_control_present(struct <token> *hdev) <answer> hid_device 
<token> value; <answer> u32 
int <token> <answer> ret; 
if <token> <answer> (!IS_ENABLED(CONFIG_ASUS_WMI)) 
<token> false; <answer> return 
ret <token> asus_wmi_evaluate_method(ASUS_WMI_METHODID_DSTS, <answer> = 
ASUS_WMI_DEVID_KBD_BACKLIGHT, <token> &value); <answer> 0, 
<token> "WMI backlight check: rc %d value %x", ret, value); <answer> hid_dbg(hdev, 
if <token> <answer> (ret) 
return <token> <answer> false; 
return !!(value <token> ASUS_WMI_DSTS_PRESENCE_BIT); <answer> & 
static int <token> hid_device *hdev) <answer> asus_kbd_register_leds(struct 
<token> asus_drvdata *drvdata = hid_get_drvdata(hdev); <answer> struct 
unsigned <token> kbd_func; <answer> char 
int <token> <answer> ret; 
if (drvdata->quirks <token> QUIRK_ROG_NKEY_KEYBOARD) { <answer> & 
ret <token> rog_nkey_led_init(hdev); <answer> = 
<token> (ret < 0) <answer> if 
<token> ret; <answer> return 
<token> else { <answer> } 
static int asus_parse_battery(struct asus_drvdata *drvdata, <token> *data, int size) <answer> u8 
<token> sts; <answer> u8 
u8 <token> <answer> lvl; 
int <token> <answer> val; 
lvl <token> data[1]; <answer> = 
sts = <token> <answer> data[8]; 
<token> = ((int)lvl * 100) / (int)BATTERY_LEVEL_MAX; <answer> drvdata->battery_capacity 
switch <token> { <answer> (sts) 
<token> BATTERY_STAT_CHARGING: <answer> case 
val <token> POWER_SUPPLY_STATUS_CHARGING; <answer> = 
case <token> <answer> BATTERY_STAT_FULL: 
val <token> POWER_SUPPLY_STATUS_FULL; <answer> = 
case <token> <answer> BATTERY_STAT_DISCONNECT: 
val <token> POWER_SUPPLY_STATUS_DISCHARGING; <answer> = 
drvdata->battery_stat = <token> <answer> val; 
<token> 0; <answer> return 
static <token> asus_report_battery(struct asus_drvdata *drvdata, u8 *data, int size) <answer> int 
<token> -1; <answer> return 
if <token> & (QUIRK_T100CHI | QUIRK_T90CHI)) && <answer> ((drvdata->quirks 
(field->application == (HID_UP_GENDESK | <token> || <answer> 0x0080) 
<token> == HID_GD_MOUSE || <answer> field->application 
usage->hid == (HID_UP_GENDEVCTRLS | 0x0024) <token> <answer> || 
usage->hid <token> (HID_UP_GENDEVCTRLS | 0x0025) || <answer> == 
<token> == (HID_UP_GENDEVCTRLS | 0x0026))) <answer> usage->hid 
<token> -1; <answer> return 
return <token> <answer> -1; 
if <token> & QUIRK_USE_KBD_BACKLIGHT) <answer> (drvdata->quirks 
drvdata->enable_backlight = <token> <answer> true; 
<token> hi->input->evbit); <answer> set_bit(EV_REP, 
return <token> <answer> 1; 
if ((usage->hid & <token> == HID_UP_MSVENDOR) { <answer> HID_USAGE_PAGE) 
switch (usage->hid & <token> { <answer> HID_USAGE) 
case 0xff01: asus_map_key_clear(BTN_1); <token> <answer> break; 
case 0xff02: asus_map_key_clear(BTN_2); <token> <answer> break; 
<token> 0xff03: asus_map_key_clear(BTN_3); break; <answer> case 
case 0xff04: <token> break; <answer> asus_map_key_clear(BTN_4); 
case 0xff05: <token> break; <answer> asus_map_key_clear(BTN_5); 
case 0xff06: asus_map_key_clear(BTN_6); <token> <answer> break; 
case 0xff07: asus_map_key_clear(BTN_7); <token> <answer> break; 
case <token> asus_map_key_clear(BTN_8); break; <answer> 0xff08: 
case <token> asus_map_key_clear(BTN_9); break; <answer> 0xff09: 
<token> 0xff0a: asus_map_key_clear(BTN_A); break; <answer> case 
<token> 0xff0b: asus_map_key_clear(BTN_B); break; <answer> case 
case 0x00f1: <token> break; <answer> asus_map_key_clear(KEY_WLAN); 
case 0x00f2: asus_map_key_clear(KEY_BRIGHTNESSDOWN); <token> <answer> break; 
case <token> asus_map_key_clear(KEY_BRIGHTNESSUP); break; <answer> 0x00f3: 
case <token> asus_map_key_clear(KEY_DISPLAY_OFF); break; <answer> 0x00f4: 
case 0x00f7: <token> break; <answer> asus_map_key_clear(KEY_CAMERA); 
case <token> asus_map_key_clear(KEY_PROG1); break; <answer> 0x00f8: 
<token> 0; <answer> return 
set_bit(EV_REP, <token> <answer> hi->input->evbit); 
<token> 1; <answer> return 
if (drvdata->quirks <token> QUIRK_NO_CONSUMER_USAGES && <answer> & 
(usage->hid <token> HID_USAGE_PAGE) == HID_UP_CONSUMER) { <answer> & 
switch (usage->hid & HID_USAGE) <token> <answer> { 
<token> -1; <answer> return 
if ((drvdata->quirks <token> QUIRK_MEDION_E1239T) && <answer> & 
usage->hid <token> (HID_UP_CONSUMER | 0xe2)) { <answer> == 
input_set_capability(hi->input, <token> KEY_MUTE); <answer> EV_KEY, 
<token> -1; <answer> return 
return <token> <answer> 0; 
static int asus_start_multitouch(struct hid_device <token> <answer> *hdev) 
int <token> <answer> ret; 
static <token> unsigned char buf[] = { <answer> const 
<token> 0x00, 0x03, 0x01, 0x00 <answer> FEATURE_REPORT_ID, 
unsigned char *dmabuf = kmemdup(buf, sizeof(buf), <token> <answer> GFP_KERNEL); 
if <token> { <answer> (!dmabuf) 
ret <token> -ENOMEM; <answer> = 
hid_err(hdev, <token> failed to alloc dma buf: %d\n", ret); <answer> "Asus 
return <token> <answer> ret; 
ret = hid_hw_raw_request(hdev, <token> dmabuf, sizeof(buf), <answer> dmabuf[0], 
<token> HID_REQ_SET_REPORT); <answer> HID_FEATURE_REPORT, 
if (ret != <token> { <answer> sizeof(buf)) 
<token> "Asus failed to start multitouch: %d\n", ret); <answer> hid_err(hdev, 
<token> ret; <answer> return 
return <token> <answer> 0; 
static <token> __maybe_unused asus_resume(struct hid_device *hdev) { <answer> int 
<token> asus_drvdata *drvdata = hid_get_drvdata(hdev); <answer> struct 
<token> ret = 0; <answer> int 
if <token> { <answer> (drvdata->kbd_backlight) 
const u8 buf[] = { FEATURE_KBD_REPORT_ID, 0xba, <token> 0xc4, <answer> 0xc5, 
<token> }; <answer> drvdata->kbd_backlight->cdev.brightness 
ret = asus_kbd_set_report(hdev, <token> sizeof(buf)); <answer> buf, 
<token> (ret < 0) { <answer> if 
hid_err(hdev, "Asus failed to <token> keyboard backlight: %d\n", ret); <answer> set 
<token> asus_resume_err; <answer> goto 
return <token> <answer> ret; 
static int __maybe_unused asus_reset_resume(struct hid_device <token> <answer> *hdev) 
<token> asus_drvdata *drvdata = hid_get_drvdata(hdev); <answer> struct 
<token> (drvdata->tp) <answer> if 
return <token> <answer> asus_start_multitouch(hdev); 
return <token> <answer> 0; 
static int <token> hid_device *hdev, const struct hid_device_id *id) <answer> asus_probe(struct 
<token> ret; <answer> int 
struct asus_drvdata <token> <answer> *drvdata; 
drvdata = <token> sizeof(*drvdata), GFP_KERNEL); <answer> devm_kzalloc(&hdev->dev, 
if (drvdata == NULL) <token> <answer> { 
hid_err(hdev, "Can't alloc <token> descriptor\n"); <answer> Asus 
return <token> <answer> -ENOMEM; 
hid_set_drvdata(hdev, <token> <answer> drvdata); 
drvdata->quirks <token> id->driver_data; <answer> = 
<token> (strstr(hdev->name, "T90CHI")) { <answer> if 
drvdata->quirks <token> ~QUIRK_T100CHI; <answer> &= 
<token> |= QUIRK_T90CHI; <answer> drvdata->quirks 
if <token> & QUIRK_IS_MULTITOUCH) <answer> (drvdata->quirks 
drvdata->tp <token> &asus_i2c_tp; <answer> = 
if ((drvdata->quirks & QUIRK_T100_KEYBOARD) && hid_is_usb(hdev)) <token> <answer> { 
struct usb_interface *intf = <token> <answer> to_usb_interface(hdev->dev.parent); 
if (intf->altsetting->desc.bInterfaceNumber <token> T100_TPAD_INTF) { <answer> == 
drvdata->quirks <token> QUIRK_SKIP_INPUT_MAPPING; <answer> = 
if (dmi_match(DMI_PRODUCT_NAME, <token> <answer> "T100HAN")) 
drvdata->tp = <token> <answer> &asus_t100ha_tp; 
else if (dmi_match(DMI_PRODUCT_NAME, <token> <answer> "T200TA")) 
drvdata->tp = <token> <answer> &asus_t200ta_tp; 
<token> = &asus_t100ta_tp; <answer> drvdata->tp 
if (drvdata->quirks <token> QUIRK_T100CHI) { <answer> & 
hdev->quirks <token> HID_QUIRK_MULTI_INPUT; <answer> |= 
drvdata->tp = <token> <answer> &asus_t100chi_tp; 
<token> ((drvdata->quirks & QUIRK_MEDION_E1239T) && hid_is_usb(hdev)) { <answer> if 
<token> usb_host_interface *alt = <answer> struct 
if (alt->desc.bInterfaceNumber == MEDION_E1239T_TPAD_INTF) <token> <answer> { 
if (*rsize <token> rsize_orig && <answer> == 
rdesc[offs] == 0x09 && rdesc[offs + 1] <token> 0x76) { <answer> == 
*rsize = rsize_orig <token> 1; <answer> + 
<token> = kmemdup(rdesc, *rsize, GFP_KERNEL); <answer> rdesc 
<token> (!rdesc) <answer> if 
return <token> <answer> NULL; 
hid_info(hdev, <token> up %s keyb report descriptor\n", <answer> "Fixing 
drvdata->quirks <token> QUIRK_T100CHI ? <answer> & 
"T100CHI" : <token> <answer> "T90CHI"); 
memmove(rdesc + <token> + 4, rdesc + offs + 2, 12); <answer> offs 
rdesc[offs] <token> 0x19; <answer> = 
<token> + 1] = 0x00; <answer> rdesc[offs 
<token> + 2] = 0x29; <answer> rdesc[offs 
rdesc[offs <token> 3] = 0xff; <answer> + 
<token> + 14] = 0x00; <answer> rdesc[offs 
<token> (drvdata->quirks & QUIRK_G752_KEYBOARD && <answer> if 
*rsize == 75 && rdesc[61] <token> 0x15 && rdesc[62] == 0x00) { <answer> == 
<token> HID_DEVICE(BUS_USB, HID_GROUP_GENERIC, <answer> { 
USB_VENDOR_ID_ASUSTEK, USB_DEVICE_ID_ASUSTEK_T101HA_KEYBOARD) <token> <answer> }, 
<token> } <answer> { 
MODULE_DEVICE_TABLE(hid, <token> <answer> asus_devices); 
static struct hid_driver <token> = { <answer> asus_driver 
.name <token> "asus", <answer> = 
<token> = asus_devices, <answer> .id_table 
<token> = asus_report_fixup, <answer> .report_fixup 
<token> = asus_probe, <answer> .probe 
.remove = <token> <answer> asus_remove, 
<token> = asus_input_mapping, <answer> .input_mapping 
.input_configured <token> asus_input_configured, <answer> = 
<token> CONFIG_PM <answer> #ifdef 
.reset_resume <token> asus_reset_resume, <answer> = 
<token> = asus_resume, <answer> .resume 
<token> = asus_event, <answer> .event 
.raw_event <token> asus_raw_event <answer> = 
#include <token> <answer> "./bebob.h" 
int avc_audio_set_selector(struct fw_unit *unit, <token> int subunit_id, <answer> unsigned 
unsigned int fb_id, unsigned <token> num) <answer> int 
u8 <token> <answer> *buf; 
int <token> <answer> err; 
buf = <token> GFP_KERNEL); <answer> kzalloc(12, 
<token> (buf == NULL) <answer> if 
return <token> <answer> -ENOMEM; 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/export.h> 
<token> <linux/usb.h> <answer> #include 
#include <token> <answer> <linux/fs.h> 
<token> <linux/uaccess.h> <answer> #include 
<token> "usb_mon.h" <answer> #include 
#define STAT_BUF_SIZE <token> <answer> 80 
struct snap <token> <answer> { 
int <token> <answer> slen; 
<token> str[STAT_BUF_SIZE]; <answer> char 
static int mon_stat_open(struct inode *inode, struct file <token> <answer> *file) 
struct mon_bus <token> <answer> *mbus; 
struct snap <token> <answer> *sp; 
sp <token> kmalloc(sizeof(struct snap), GFP_KERNEL); <answer> = 
if (sp == <token> <answer> NULL) 
<token> -ENOMEM; <answer> return 
mbus <token> inode->i_private; <answer> = 
sp->slen = <token> STAT_BUF_SIZE, <answer> scnprintf(sp->str, 
"nreaders %d events %u <token> %u\n", <answer> text_lost 
mbus->nreaders, <token> mbus->cnt_text_lost); <answer> mbus->cnt_events, 
file->private_data = <token> <answer> sp; 
<token> 0; <answer> return 
static ssize_t mon_stat_read(struct file *file, char <token> *buf, <answer> __user 
size_t nbytes, loff_t <token> <answer> *ppos) 
struct snap *sp <token> file->private_data; <answer> = 
return simple_read_from_buffer(buf, nbytes, ppos, <token> sp->slen); <answer> sp->str, 
static int mon_stat_release(struct inode *inode, <token> file *file) <answer> struct 
struct snap *sp = <token> <answer> file->private_data; 
file->private_data = <token> <answer> NULL; 
<token> 0; <answer> return 
const struct <token> mon_fops_stat = { <answer> file_operations 
.owner <token> THIS_MODULE, <answer> = 
.open <token> mon_stat_open, <answer> = 
.llseek <token> no_llseek, <answer> = 
.read = <token> <answer> mon_stat_read, 
<token> <linux/delay.h> <answer> #include 
<token> <linux/gpio/consumer.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/of_graph.h> 
<token> <linux/regulator/consumer.h> <answer> #include 
#include <token> <answer> <drm/drm_connector.h> 
#include <token> <answer> <drm/drm_crtc.h> 
<token> <drm/drm_mipi_dsi.h> <answer> #include 
#include <token> <answer> <drm/drm_modes.h> 
<token> <drm/drm_panel.h> <answer> #include 
static int nt35950_set_cmd2_page(struct nt35950 *nt, u8 <token> <answer> page) 
<token> u8 mauc_cmd2_page[] = { MCS_CMD_MAUCCTR, 0x55, 0xaa, 0x52, <answer> const 
0x08, page <token> <answer> }; 
<token> ret; <answer> int 
ret = <token> mauc_cmd2_page, <answer> mipi_dsi_dcs_write_buffer(nt->dsi[0], 
if <token> < 0) <answer> (ret 
<token> ret; <answer> return 
nt->last_page = <token> <answer> page; 
return <token> <answer> 0; 
static int nt35950_set_data_compression(struct <token> *nt, u8 comp_mode) <answer> nt35950 
<token> cmd_data_compression[] = { MCS_PARAM_DATA_COMPRESSION, comp_mode }; <answer> u8 
u8 cmd_vesa_dsc_on[] = { MCS_PARAM_VESA_DSC_ON, <token> }; <answer> !!comp_mode 
u8 cmd_vesa_dsc_setting[] = { <token> 0x03 }; <answer> MCS_PARAM_VESA_DSC_SETTING, 
u8 <token> = nt->last_page; <answer> last_page 
int <token> <answer> ret; 
static int nt35950_set_scaler(struct <token> *nt, u8 scale_up) <answer> nt35950 
u8 cmd_scaler[] = { MCS_PARAM_SCALER_FUNCTION, <token> }; <answer> scale_up 
<token> mipi_dsi_dcs_write_buffer(nt->dsi[0], cmd_scaler, <answer> return 
static int nt35950_set_scale_mode(struct nt35950 <token> u8 mode) <answer> *nt, 
u8 cmd_scaler[] = { MCS_PARAM_SCALEUP_MODE, <token> }; <answer> mode 
<token> mipi_dsi_dcs_write_buffer(nt->dsi[0], cmd_scaler, <answer> return 
static int <token> nt35950 *nt) <answer> nt35950_inject_black_image(struct 
const u8 cmd0_black_img[] = { <token> 0x01 }; <answer> 0x6f, 
const u8 <token> = { 0xf3, 0x10 }; <answer> cmd1_black_img[] 
u8 cmd_test[] = <token> 0xff, 0xaa, 0x55, 0xa5, 0x80 }; <answer> { 
<token> ret; <answer> int 
static int nt35950_set_dispout(struct <token> *nt) <answer> nt35950 
u8 cmd_dispout[] = { MCS_PARAM_DISP_OUTPUT_CTRL, <token> }; <answer> 0x00 
const struct <token> *mode_data = nt->desc->mode_data; <answer> nt35950_panel_mode 
<token> (mode_data[nt->cur_mode].is_video_mode) <answer> if 
<token> |= MCS_DISP_OUT_VIDEO_MODE; <answer> cmd_dispout[1] 
<token> (mode_data[nt->cur_mode].enable_sram) <answer> if 
cmd_dispout[1] |= <token> <answer> MCS_DISP_OUT_SRAM_EN; 
<token> mipi_dsi_dcs_write_buffer(nt->dsi[0], cmd_dispout, <answer> return 
<token> int nt35950_get_current_mode(struct nt35950 *nt) <answer> static 
<token> drm_connector *connector = nt->connector; <answer> struct 
struct drm_crtc_state <token> <answer> *crtc_state; 
int <token> <answer> i; 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/mm.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/perf_event.h> <answer> #include 
#include <token> <answer> <linux/irq.h> 
<token> <linux/stringify.h> <answer> #include 
#include <token> <answer> <asm/processor.h> 
#include <token> <answer> <asm/ptrace.h> 
#include <token> <answer> <asm/csr.h> 
<token> <asm/entry-common.h> <answer> #include 
#include <token> <answer> <asm/hwprobe.h> 
<token> <asm/cpufeature.h> <answer> #include 
#define INSN_MATCH_LB <token> <answer> 0x3 
#define INSN_MASK_LB <token> <answer> 0x707f 
#define <token> 0x1003 <answer> INSN_MATCH_LH 
#define <token> 0x707f <answer> INSN_MASK_LH 
#define INSN_MATCH_LW <token> <answer> 0x2003 
#define <token> 0x707f <answer> INSN_MASK_LW 
#define <token> 0x3003 <answer> INSN_MATCH_LD 
<token> INSN_MASK_LD 0x707f <answer> #define 
#define <token> 0x4003 <answer> INSN_MATCH_LBU 
#define <token> 0x707f <answer> INSN_MASK_LBU 
#define <token> 0x5003 <answer> INSN_MATCH_LHU 
<token> INSN_MASK_LHU 0x707f <answer> #define 
<token> INSN_MATCH_LWU 0x6003 <answer> #define 
#define <token> 0x707f <answer> INSN_MASK_LWU 
#define <token> 0x23 <answer> INSN_MATCH_SB 
#define INSN_MASK_SB <token> <answer> 0x707f 
#define INSN_MATCH_SH <token> <answer> 0x1023 
#define <token> 0x707f <answer> INSN_MASK_SH 
#define <token> 0x2023 <answer> INSN_MATCH_SW 
#define INSN_MASK_SW <token> <answer> 0x707f 
#define <token> 0x3023 <answer> INSN_MATCH_SD 
#define INSN_MASK_SD <token> <answer> 0x707f 
#define INSN_MATCH_FLW <token> <answer> 0x2007 
<token> INSN_MASK_FLW 0x707f <answer> #define 
#define INSN_MATCH_FLD <token> <answer> 0x3007 
<token> INSN_MASK_FLD 0x707f <answer> #define 
#define <token> 0x4007 <answer> INSN_MATCH_FLQ 
<token> INSN_MASK_FLQ 0x707f <answer> #define 
<token> INSN_MATCH_FSW 0x2027 <answer> #define 
#define INSN_MASK_FSW <token> <answer> 0x707f 
#define <token> 0x3027 <answer> INSN_MATCH_FSD 
<token> INSN_MASK_FSD 0x707f <answer> #define 
#define <token> 0x4027 <answer> INSN_MATCH_FSQ 
<token> INSN_MASK_FSQ 0x707f <answer> #define 
#define <token> 0x6000 <answer> INSN_MATCH_C_LD 
#define <token> 0xe003 <answer> INSN_MASK_C_LD 
#define INSN_MATCH_C_SD <token> <answer> 0xe000 
<token> INSN_MASK_C_SD 0xe003 <answer> #define 
#define INSN_MATCH_C_LW <token> <answer> 0x4000 
#define <token> 0xe003 <answer> INSN_MASK_C_LW 
#define <token> 0xc000 <answer> INSN_MATCH_C_SW 
<token> INSN_MASK_C_SW 0xe003 <answer> #define 
#define <token> 0x6002 <answer> INSN_MATCH_C_LDSP 
#define <token> 0xe003 <answer> INSN_MASK_C_LDSP 
#define <token> 0xe002 <answer> INSN_MATCH_C_SDSP 
#define <token> 0xe003 <answer> INSN_MASK_C_SDSP 
<token> INSN_MATCH_C_LWSP 0x4002 <answer> #define 
#define INSN_MASK_C_LWSP <token> <answer> 0xe003 
#define <token> 0xc002 <answer> INSN_MATCH_C_SWSP 
#define <token> 0xe003 <answer> INSN_MASK_C_SWSP 
#define INSN_MATCH_C_FLD <token> <answer> 0x2000 
#define <token> 0xe003 <answer> INSN_MASK_C_FLD 
#define <token> 0x6000 <answer> INSN_MATCH_C_FLW 
<token> INSN_MASK_C_FLW 0xe003 <answer> #define 
#define INSN_MATCH_C_FSD <token> <answer> 0xa000 
#define <token> 0xe003 <answer> INSN_MASK_C_FSD 
#define INSN_MATCH_C_FSW <token> <answer> 0xe000 
<token> INSN_MASK_C_FSW 0xe003 <answer> #define 
#define INSN_MATCH_C_FLDSP <token> <answer> 0x2002 
#define <token> 0xe003 <answer> INSN_MASK_C_FLDSP 
<token> INSN_MATCH_C_FSDSP 0xa002 <answer> #define 
<token> INSN_MASK_C_FSDSP 0xe003 <answer> #define 
#define INSN_MATCH_C_FLWSP <token> <answer> 0x6002 
<token> INSN_MASK_C_FLWSP 0xe003 <answer> #define 
<token> INSN_MATCH_C_FSWSP 0xe002 <answer> #define 
<token> INSN_MASK_C_FSWSP 0xe003 <answer> #define 
#define INSN_LEN(insn) ((((insn) & 0x3) < 0x3) ? 2 : <token> <answer> 4) 
#if <token> <answer> defined(CONFIG_64BIT) 
#define <token> 3 <answer> LOG_REGBYTES 
#define <token> 64 <answer> XLEN 
<token> LOG_REGBYTES 2 <answer> #define 
#define XLEN <token> <answer> 32 
#define REGBYTES (1 << <token> <answer> LOG_REGBYTES) 
#define XLEN_MINUS_16 ((XLEN) <token> 16) <answer> - 
<token> SH_RD 7 <answer> #define 
#define <token> 15 <answer> SH_RS1 
#define SH_RS2 <token> <answer> 20 
#define <token> 2 <answer> SH_RS2C 
#define RV_X(x, s, n) <token> >> (s)) & ((1 << (n)) - 1)) <answer> (((x) 
#define RVC_LW_IMM(x) ((RV_X(x, 6, 1) << 2) | <token> <answer> \ 
(RV_X(x, 10, 3) <token> 3) | \ <answer> << 
<token> 5, 1) << 6)) <answer> (RV_X(x, 
#define RVC_LD_IMM(x) ((RV_X(x, 10, 3) <token> 3) | \ <answer> << 
(RV_X(x, 5, 2) << <token> <answer> 6)) 
#define RVC_LWSP_IMM(x) ((RV_X(x, 4, 3) << <token> | \ <answer> 2) 
(RV_X(x, 12, 1) << 5) <token> \ <answer> | 
(RV_X(x, 2, 2) <token> 6)) <answer> << 
<token> RVC_LDSP_IMM(x) ((RV_X(x, 5, 2) << 3) | \ <answer> #define 
(RV_X(x, <token> 1) << 5) | \ <answer> 12, 
(RV_X(x, 2, <token> << 6)) <answer> 3) 
#define <token> ((RV_X(x, 9, 4) << 2) | \ <answer> RVC_SWSP_IMM(x) 
(RV_X(x, <token> 2) << 6)) <answer> 7, 
#define RVC_SDSP_IMM(x) ((RV_X(x, 10, 3) << <token> | \ <answer> 3) 
(RV_X(x, 7, 3) <token> 6)) <answer> << 
<token> RVC_RS1S(insn) (8 + RV_X(insn, SH_RD, 3)) <answer> #define 
#define <token> (8 + RV_X(insn, SH_RS2C, 3)) <answer> RVC_RS2S(insn) 
#define RVC_RS2(insn) <token> SH_RS2C, 5) <answer> RV_X(insn, 
#define SHIFT_RIGHT(x, y) <token> <answer> \ 
((y) < 0 ? ((x) << -(y)) : ((x) >> <token> <answer> (y))) 
#define REG_MASK <token> <answer> \ 
((1 << (5 + LOG_REGBYTES)) - (1 <token> LOG_REGBYTES)) <answer> << 
#define REG_OFFSET(insn, <token> \ <answer> pos) 
(SHIFT_RIGHT((insn), (pos) - LOG_REGBYTES) <token> REG_MASK) <answer> & 
#define REG_PTR(insn, <token> regs) \ <answer> pos, 
(ulong *)((ulong)(regs) + REG_OFFSET(insn, <token> <answer> pos)) 
#define GET_RM(insn) (((insn) >> <token> & 7) <answer> 12) 
#define <token> regs) (*REG_PTR(insn, SH_RS1, regs)) <answer> GET_RS1(insn, 
#define GET_RS2(insn, regs) (*REG_PTR(insn, <token> regs)) <answer> SH_RS2, 
#define GET_RS1S(insn, regs) (*REG_PTR(RVC_RS1S(insn), <token> regs)) <answer> 0, 
#define GET_RS2S(insn, <token> (*REG_PTR(RVC_RS2S(insn), 0, regs)) <answer> regs) 
#define GET_RS2C(insn, regs) (*REG_PTR(insn, <token> regs)) <answer> SH_RS2C, 
#define <token> (*REG_PTR(2, 0, regs)) <answer> GET_SP(regs) 
#define SET_RD(insn, <token> val) (*REG_PTR(insn, SH_RD, regs) = (val)) <answer> regs, 
#define <token> ((s32)(insn) >> 20) <answer> IMM_I(insn) 
#define IMM_S(insn) (((s32)(insn) <token> 25 << 5) | \ <answer> >> 
(s32)(((insn) >> 7) <token> 0x1f)) <answer> & 
#define MASK_FUNCT3 <token> <answer> 0x7000 
#define GET_PRECISION(insn) (((insn) <token> 25) & 3) <answer> >> 
#define GET_RM(insn) (((insn) >> 12) <token> 7) <answer> & 
#define PRECISION_S <token> <answer> 0 
#define <token> 1 <answer> PRECISION_D 
<token> CONFIG_FPU <answer> #ifdef 
#define <token> (insn >> 7 & 0x1F) <answer> FP_GET_RD(insn) 
extern void put_f32_reg(unsigned <token> fp_reg, unsigned long value); <answer> long 
static int set_f32_rd(unsigned long <token> struct pt_regs *regs, <answer> insn, 
unsigned long <token> <answer> val) 
unsigned long fp_reg = <token> <answer> FP_GET_RD(insn); 
<token> val); <answer> put_f32_reg(fp_reg, 
<token> |= SR_FS_DIRTY; <answer> regs->status 
<token> 0; <answer> return 
extern void put_f64_reg(unsigned long fp_reg, unsigned long <token> <answer> value); 
static int set_f64_rd(unsigned long <token> struct pt_regs *regs, u64 val) <answer> insn, 
unsigned long fp_reg <token> FP_GET_RD(insn); <answer> = 
<token> long value; <answer> unsigned 
#if __riscv_xlen == <token> <answer> 32 
value = (unsigned long) <token> <answer> &val; 
value <token> val; <answer> = 
<token> value); <answer> put_f64_reg(fp_reg, 
regs->status <token> SR_FS_DIRTY; <answer> |= 
<token> 0; <answer> return 
#if <token> == 32 <answer> __riscv_xlen 
extern void <token> long fp_reg, u64 *value); <answer> get_f64_reg(unsigned 
static u64 get_f64_rs(unsigned <token> insn, u8 fp_reg_offset, <answer> long 
struct <token> *regs) <answer> pt_regs 
unsigned long fp_reg = (insn <token> fp_reg_offset) & 0x1F; <answer> >> 
<token> val; <answer> u64 
get_f64_reg(fp_reg, <token> <answer> &val); 
regs->status |= <token> <answer> SR_FS_DIRTY; 
<token> val; <answer> return 
extern unsigned <token> get_f64_reg(unsigned long fp_reg); <answer> long 
static unsigned long get_f64_rs(unsigned long <token> u8 fp_reg_offset, <answer> insn, 
struct <token> *regs) <answer> pt_regs 
unsigned <token> fp_reg = (insn >> fp_reg_offset) & 0x1F; <answer> long 
unsigned long <token> <answer> val; 
val = <token> <answer> get_f64_reg(fp_reg); 
<token> |= SR_FS_DIRTY; <answer> regs->status 
<token> val; <answer> return 
extern unsigned long <token> long fp_reg); <answer> get_f32_reg(unsigned 
<token> unsigned long get_f32_rs(unsigned long insn, u8 fp_reg_offset, <answer> static 
struct pt_regs <token> <answer> *regs) 
unsigned long fp_reg = <token> >> fp_reg_offset) & 0x1F; <answer> (insn 
unsigned long <token> <answer> val; 
val <token> get_f32_reg(fp_reg); <answer> = 
regs->status |= <token> <answer> SR_FS_DIRTY; 
return <token> <answer> val; 
insn &= <token> 0); <answer> GENMASK(15, 
if ((insn & __INSN_LENGTH_MASK) != <token> { <answer> __INSN_LENGTH_32) 
<token> = insn; <answer> *r_insn 
return <token> <answer> 0; 
if (__read_insn(regs, <token> insn_addr)) <answer> tmp, 
return <token> <answer> -EFAULT; 
*r_insn = (tmp << <token> | insn; <answer> 16) 
<token> 0; <answer> return 
<token> else { <answer> } 
u32 __user <token> = (u32 __user *)epc; <answer> *insn_addr 
if (__read_insn(regs, insn, <token> <answer> insn_addr)) 
return <token> <answer> -EFAULT; 
if <token> & __INSN_LENGTH_MASK) == __INSN_LENGTH_32) { <answer> ((insn 
<token> = insn; <answer> *r_insn 
return <token> <answer> 0; 
insn <token> GENMASK(15, 0); <answer> &= 
*r_insn <token> insn; <answer> = 
<token> 0; <answer> return 
<token> reg_data { <answer> union 
<token> data_bytes[8]; <answer> u8 
<token> data_ulong; <answer> ulong 
<token> data_u64; <answer> u64 
static bool unaligned_ctl <token> <answer> __read_mostly; 
if (unlikely(unaligned_ctl && <token> { <answer> !misaligned_emu_detected)) 
pr_crit("CPU misaligned accesses <token> homogeneous (expected all emulated)\n"); <answer> non 
<token> (true) <answer> while 
<token> misaligned_emu_detected; <answer> return 
bool <token> <answer> check_unaligned_access_emulated_all_cpus(void) 
<token> cpu; <answer> int 
if <token> <answer> (!check_unaligned_access_emulated(cpu)) 
return <token> <answer> false; 
unaligned_ctl <token> true; <answer> = 
return <token> <answer> true; 
bool <token> <answer> unaligned_ctl_available(void) 
<token> unaligned_ctl; <answer> return 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/moduleparam.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <asm/io.h> <answer> #include 
<token> <asm/page.h> <answer> #include 
#include <token> <answer> <linux/kmod.h> 
#include <token> <answer> <linux/vmalloc.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/device.h> <answer> #include 
#include <token> <answer> <linux/pci.h> 
#include <token> <answer> <asm/irq.h> 
<token> <linux/signal.h> <answer> #include 
<token> <linux/sched.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
<token> <media/dmxdev.h> <answer> #include 
<token> <media/dvbdev.h> <answer> #include 
<token> <media/dvb_demux.h> <answer> #include 
#include <token> <answer> <media/dvb_frontend.h> 
#include <token> <answer> <media/dvb_net.h> 
#include <token> <answer> "mantis_common.h" 
<token> "mantis_reg.h" <answer> #include 
#include <token> <answer> "mantis_pci.h" 
<token> DRIVER_NAME "Mantis Core" <answer> #define 
<token> mantis_pci_init(struct mantis_pci *mantis) <answer> int 
<token> latency; <answer> u8 
struct mantis_hwconfig *config = <token> <answer> mantis->hwconfig; 
struct pci_dev *pdev = <token> <answer> mantis->pdev; 
int err, ret = <token> <answer> 0; 
dprintk(MANTIS_ERROR, 0, "found a %s PCI %s device <token> (%02x:%02x.%x),\n", <answer> on 
err = <token> <answer> pci_enable_device(pdev); 
if (err <token> 0) { <answer> != 
<token> = -ENODEV; <answer> ret 
<token> 1, "ERROR: PCI enable failed <%i>", err); <answer> dprintk(MANTIS_ERROR, 
goto <token> <answer> fail0; 
err = dma_set_coherent_mask(&pdev->dev, <token> <answer> DMA_BIT_MASK(32)); 
if (err <token> 0) { <answer> != 
dprintk(MANTIS_ERROR, 1, "ERROR: <token> to obtain 32 bit DMA <%i>", err); <answer> Unable 
ret <token> -ENOMEM; <answer> = 
goto <token> <answer> fail1; 
if <token> 0), <answer> (!request_mem_region(pci_resource_start(pdev, 
<token> 0), <answer> pci_resource_len(pdev, 
<token> { <answer> DRIVER_NAME)) 
dprintk(MANTIS_ERROR, <token> "ERROR: BAR0 Request failed !"); <answer> 1, 
ret = <token> <answer> -ENODEV; 
goto <token> <answer> fail1; 
mantis->mmio = <token> 0), <answer> ioremap(pci_resource_start(pdev, 
<token> 0)); <answer> pci_resource_len(pdev, 
if (!mantis->mmio) <token> <answer> { 
dprintk(MANTIS_ERROR, 1, "ERROR: BAR0 remap <token> !"); <answer> failed 
ret = <token> <answer> -ENODEV; 
goto <token> <answer> fail2; 
pci_read_config_byte(pdev, <token> &latency); <answer> PCI_LATENCY_TIMER, 
<token> = latency; <answer> mantis->latency 
mantis->revision <token> pdev->revision; <answer> = 
<token> 0, " Mantis Rev %d [%04x:%04x], ", <answer> dprintk(MANTIS_ERROR, 
<token> 0, <answer> dprintk(MANTIS_ERROR, 
"irq: <token> latency: %d\n memory: 0x%lx, mmio: 0x%p\n", <answer> %d, 
err = <token> <answer> request_irq(pdev->irq, 
<token> (err != 0) { <answer> if 
dprintk(MANTIS_ERROR, 1, "ERROR: IRQ registration <token> ! <%d>", err); <answer> failed 
ret <token> -ENODEV; <answer> = 
goto <token> <answer> fail3; 
pci_set_drvdata(pdev, <token> <answer> mantis); 
<token> ret; <answer> return 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/ioport.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/errno.h> 
<token> <linux/list.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/proc_fs.h> 
<token> <linux/prefetch.h> <answer> #include 
#include <token> <answer> <linux/clk.h> 
<token> <linux/usb/gadget.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/dma-mapping.h> 
<token> "vhub.h" <answer> #include 
void ast_vhub_done(struct <token> *ep, struct ast_vhub_req *req, <answer> ast_vhub_ep 
<token> status) <answer> int 
bool internal <token> req->internal; <answer> = 
struct ast_vhub *vhub <token> ep->vhub; <answer> = 
EPVDBG(ep, "completing request @%p, <token> %d\n", req, status); <answer> status 
<token> ((req->req.status == -EINPROGRESS) || (status == -EOVERFLOW)) <answer> if 
req->req.status = <token> <answer> status; 
<token> (req->req.dma) { <answer> if 
<token> (!WARN_ON(!ep->dev)) <answer> if 
<token> ep->epn.is_in); <answer> &req->req, 
<token> = 0; <answer> req->req.dma 
if (!internal) <token> <answer> { 
usb_gadget_giveback_request(&ep->ep, <token> <answer> &req->req); 
void ast_vhub_nuke(struct <token> *ep, int status) <answer> ast_vhub_ep 
<token> ast_vhub_req *req; <answer> struct 
int count = <token> <answer> 0; 
ctrl |= <token> | VHUB_CTRL_SPLIT_IN; <answer> VHUB_CTRL_ISO_RSP_CTRL 
<token> vhub->regs + AST_VHUB_CTRL); <answer> writel(ctrl, 
vhub->ep0_bufs <token> dma_alloc_coherent(&pdev->dev, <answer> = 
AST_VHUB_EP0_MAX_PACKET <token> <answer> * 
(vhub->max_ports <token> 1), <answer> + 
<token> GFP_KERNEL); <answer> &vhub->ep0_bufs_dma, 
if <token> { <answer> (!vhub->ep0_bufs) 
<token> "Failed to allocate EP0 DMA buffers\n"); <answer> dev_err(&pdev->dev, 
rc = <token> <answer> -ENOMEM; 
goto <token> <answer> err; 
<token> "EP0 DMA buffers @%p (DMA 0x%08x)\n", <answer> UDCVDBG(vhub, 
vhub->ep0_bufs, <token> <answer> (u32)vhub->ep0_bufs_dma); 
<token> <linux/list.h> <answer> #include 
<token> <drm/drm_device.h> <answer> #include 
<token> <drm/drm_gem_shmem_helper.h> <answer> #include 
<token> "panfrost_device.h" <answer> #include 
<token> "panfrost_gem.h" <answer> #include 
#include <token> <answer> "panfrost_mmu.h" 
static <token> long <answer> unsigned 
<token> shrinker *shrinker, struct shrink_control *sc) <answer> panfrost_gem_shrinker_count(struct 
struct <token> *pfdev = shrinker->private_data; <answer> panfrost_device 
struct <token> *shmem; <answer> drm_gem_shmem_object 
<token> long count = 0; <answer> unsigned 
<token> (!mutex_trylock(&pfdev->shrinker_lock)) <answer> if 
return <token> <answer> 0; 
list_for_each_entry(shmem, &pfdev->shrinker_list, <token> { <answer> madv_list) 
if <token> <answer> (drm_gem_shmem_is_purgeable(shmem)) 
<token> += shmem->base.size >> PAGE_SHIFT; <answer> count 
return <token> <answer> count; 
static bool panfrost_gem_purge(struct <token> *obj) <answer> drm_gem_object 
struct drm_gem_shmem_object *shmem = <token> <answer> to_drm_gem_shmem_obj(obj); 
struct panfrost_gem_object *bo = <token> <answer> to_panfrost_bo(obj); 
bool ret <token> false; <answer> = 
if <token> <answer> (atomic_read(&bo->gpu_usecount)) 
<token> false; <answer> return 
<token> (!mutex_trylock(&bo->mappings.lock)) <answer> if 
return <token> <answer> false; 
if <token> <answer> (!dma_resv_trylock(shmem->base.resv)) 
<token> unlock_mappings; <answer> goto 
ret = <token> <answer> true; 
<token> ret; <answer> return 
static <token> long <answer> unsigned 
<token> shrinker *shrinker, struct shrink_control *sc) <answer> panfrost_gem_shrinker_scan(struct 
struct panfrost_device <token> = shrinker->private_data; <answer> *pfdev 
struct <token> *shmem, *tmp; <answer> drm_gem_shmem_object 
unsigned long freed <token> 0; <answer> = 
<token> (!mutex_trylock(&pfdev->shrinker_lock)) <answer> if 
return <token> <answer> SHRINK_STOP; 
list_for_each_entry_safe(shmem, tmp, &pfdev->shrinker_list, madv_list) <token> <answer> { 
if (freed <token> sc->nr_to_scan) <answer> >= 
<token> (drm_gem_shmem_is_purgeable(shmem) && <answer> if 
panfrost_gem_purge(&shmem->base)) <token> <answer> { 
freed += shmem->base.size >> <token> <answer> PAGE_SHIFT; 
if (freed > <token> <answer> 0) 
<token> %lu bytes\n", freed << PAGE_SHIFT); <answer> pr_info_ratelimited("Purging 
<token> freed; <answer> return 
<token> panfrost_gem_shrinker_init(struct drm_device *dev) <answer> int 
struct panfrost_device <token> = dev->dev_private; <answer> *pfdev 
pfdev->shrinker = <token> "drm-panfrost"); <answer> shrinker_alloc(0, 
if <token> <answer> (!pfdev->shrinker) 
return <token> <answer> -ENOMEM; 
pfdev->shrinker->count_objects = <token> <answer> panfrost_gem_shrinker_count; 
pfdev->shrinker->scan_objects = <token> <answer> panfrost_gem_shrinker_scan; 
pfdev->shrinker->private_data <token> pfdev; <answer> = 
<token> 0; <answer> return 
void panfrost_gem_shrinker_cleanup(struct <token> *dev) <answer> drm_device 
<token> panfrost_device *pfdev = dev->dev_private; <answer> struct 
<token> (pfdev->shrinker) <answer> if 
<token> <media/v4l2-common.h> <answer> #include 
#include <token> <answer> <media/v4l2-event.h> 
<token> <media/v4l2-ioctl.h> <answer> #include 
<token> <media/videobuf2-core.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/types.h> 
#include <token> <answer> <linux/device.h> 
<token> <linux/sysfs.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/power_supply.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/gpio/consumer.h> 
<token> <linux/usb/otg.h> <answer> #include 
<token> <linux/usb/ulpi.h> <answer> #include 
#include <token> <answer> <linux/usb/ch9.h> 
<token> <linux/usb/gadget.h> <answer> #include 
static inline <token> isp1704_charger_type(struct isp1704_charger *isp) <answer> int 
<token> reg; <answer> u8 
<token> func_ctrl; <answer> u8 
u8 <token> <answer> otg_ctrl; 
int type = <token> <answer> POWER_SUPPLY_TYPE_USB_DCP; 
<token> = isp1704_read(isp, ULPI_FUNC_CTRL); <answer> func_ctrl 
otg_ctrl = isp1704_read(isp, <token> <answer> ULPI_OTG_CTRL); 
static inline <token> isp1704_charger_verify(struct isp1704_charger *isp) <answer> int 
int ret <token> 0; <answer> = 
u8 <token> <answer> r; 
if <token> > 500) <answer> (isp->current_max 
isp->current_max = <token> <answer> 500; 
if <token> > 100) <answer> (isp->current_max 
<token> = POWER_SUPPLY_TYPE_USB_CDP; <answer> isp->psy_desc.type 
<token> USB_EVENT_NONE: <answer> case 
isp->online <token> false; <answer> = 
isp->present = <token> <answer> 0; 
isp->current_max = <token> <answer> 0; 
isp->psy_desc.type = <token> <answer> POWER_SUPPLY_TYPE_USB; 
if <token> <answer> (isp->phy->otg->gadget) 
isp1704_charger_set_power(isp, <token> <answer> 0); 
goto <token> <answer> out; 
static int isp1704_notifier_call(struct <token> *nb, <answer> notifier_block 
unsigned long val, void <token> <answer> *v) 
struct isp1704_charger *isp <token> <answer> = 
container_of(nb, struct <token> nb); <answer> isp1704_charger, 
return <token> <answer> NOTIFY_OK; 
static int isp1704_charger_get_property(struct <token> *psy, <answer> power_supply 
enum power_supply_property <token> <answer> psp, 
union <token> *val) <answer> power_supply_propval 
struct <token> *isp = power_supply_get_drvdata(psy); <answer> isp1704_charger 
switch (psp) <token> <answer> { 
<token> POWER_SUPPLY_PROP_PRESENT: <answer> case 
<token> = isp->present; <answer> val->intval 
<token> POWER_SUPPLY_PROP_ONLINE: <answer> case 
val->intval = <token> <answer> isp->online; 
case <token> <answer> POWER_SUPPLY_PROP_CURRENT_MAX: 
val->intval = <token> <answer> isp->current_max; 
case <token> <answer> POWER_SUPPLY_PROP_MODEL_NAME: 
val->strval = <token> <answer> isp->model; 
<token> POWER_SUPPLY_PROP_MANUFACTURER: <answer> case 
<token> = "NXP"; <answer> val->strval 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
<token> enum power_supply_property power_props[] = { <answer> static 
<token> inline int isp1704_test_ulpi(struct isp1704_charger *isp) <answer> static 
<token> vendor; <answer> int 
int <token> <answer> product; 
int <token> <answer> i; 
<token> ret; <answer> int 
INIT_WORK(&isp->work, <token> <answer> isp1704_charger_work); 
isp->nb.notifier_call <token> isp1704_notifier_call; <answer> = 
ret = usb_register_notifier(isp->phy, <token> <answer> &isp->nb); 
<token> (ret) { <answer> if 
dev_err(&pdev->dev, <token> failed\n"); <answer> "usb_register_notifier 
<token> fail2; <answer> goto 
dev_info(isp->dev, <token> with product id %s\n", isp->model); <answer> "registered 
if <token> <answer> (isp->phy->otg->gadget) 
<token> (isp->phy->last_event == USB_EVENT_NONE) <answer> if 
<token> 0); <answer> isp1704_charger_set_power(isp, 
#include <token> <answer> <stdio.h> 
#include <token> <answer> "util/pmu.h" 
<token> "util/pmus.h" <answer> #include 
#include <token> <answer> "util/evlist.h" 
<token> "util/parse-events.h" <answer> #include 
#include <token> <answer> "util/event.h" 
<token> "topdown.h" <answer> #include 
#include <token> <answer> "evsel.h" 
static <token> ___evlist__add_default_attrs(struct evlist *evlist, <answer> int 
struct perf_event_attr <token> <answer> *attrs, 
size_t <token> <answer> nr_attrs) 
<token> i = 0; <answer> size_t 
for (i = 0; <token> < nr_attrs; i++) <answer> i 
<token> + i); <answer> event_attr_init(attrs 
if <token> == 1) <answer> (perf_pmus__num_core_pmus() 
return <token> attrs, nr_attrs); <answer> evlist__add_attrs(evlist, 
for (i = 0; i < nr_attrs; <token> { <answer> i++) 
struct perf_pmu *pmu <token> NULL; <answer> = 
if <token> == PERF_TYPE_SOFTWARE) { <answer> (attrs[i].type 
<token> evsel *evsel = evsel__new(attrs + i); <answer> struct 
if (evsel == <token> <answer> NULL) 
<token> out_delete_partial_list; <answer> goto 
list_add_tail(&evsel->core.node, <token> <answer> &head); 
while ((pmu = perf_pmus__scan_core(pmu)) <token> NULL) { <answer> != 
struct <token> *cpus; <answer> perf_cpu_map 
struct evsel <token> <answer> *evsel; 
evsel = <token> + i); <answer> evsel__new(attrs 
if (evsel <token> NULL) <answer> == 
<token> out_delete_partial_list; <answer> goto 
evsel->core.attr.config |= (__u64)pmu->type << <token> <answer> PERF_PMU_TYPE_SHIFT; 
<token> = perf_cpu_map__get(pmu->cpus); <answer> cpus 
<token> = cpus; <answer> evsel->core.cpus 
evsel->core.own_cpus <token> perf_cpu_map__get(cpus); <answer> = 
<token> = strdup(pmu->name); <answer> evsel->pmu_name 
list_add_tail(&evsel->core.node, <token> <answer> &head); 
evlist__splice_list_tail(evlist, <token> <answer> &head); 
<token> 0; <answer> return 
struct evsel <token> *n; <answer> *evsel, 
__evlist__for_each_entry_safe(&head, n, <token> <answer> evsel) 
return <token> <answer> -1; 
int arch_evlist__add_default_attrs(struct evlist <token> <answer> *evlist, 
struct perf_event_attr <token> <answer> *attrs, 
<token> nr_attrs) <answer> size_t 
if <token> <answer> (!nr_attrs) 
<token> 0; <answer> return 
return <token> attrs, nr_attrs); <answer> ___evlist__add_default_attrs(evlist, 
int arch_evlist__cmp(const struct evsel *lhs, const struct evsel <token> <answer> *rhs) 
<token> (topdown_sys_has_perf_metrics() && <answer> if 
<token> || arch_evsel__must_be_in_group(rhs))) { <answer> (arch_evsel__must_be_in_group(lhs) 
#include <token> <answer> <linux/perf_event.h> 
<token> <linux/perf_regs.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/bug.h> 
<token> <asm/ptrace.h> <answer> #include 
<token> <asm/fpu.h> <answer> #include 
u64 <token> pt_regs *regs, int idx) <answer> perf_reg_value(struct 
freg_t <token> <answer> fp; 
<token> (idx >= PERF_REG_S390_R0 && idx <= PERF_REG_S390_R15) <answer> if 
<token> regs->gprs[idx]; <answer> return 
<token> (idx >= PERF_REG_S390_FP0 && idx <= PERF_REG_S390_FP15) { <answer> if 
if <token> <answer> (!user_mode(regs)) 
return <token> <answer> 0; 
idx <token> PERF_REG_S390_FP0; <answer> -= 
fp = *(freg_t *)(current->thread.ufpu.vxrs + <token> <answer> idx); 
<token> fp.ui; <answer> return 
if <token> == PERF_REG_S390_MASK) <answer> (idx 
return <token> <answer> regs->psw.mask; 
if (idx == <token> <answer> PERF_REG_S390_PC) 
<token> regs->psw.addr; <answer> return 
<token> >= PERF_REG_S390_MAX); <answer> WARN_ON_ONCE((u32)idx 
<token> 0; <answer> return 
#define REG_RESERVED (~((1UL << PERF_REG_S390_MAX) <token> 1)) <answer> - 
int perf_reg_validate(u64 <token> <answer> mask) 
if (!mask || mask & <token> <answer> REG_RESERVED) 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
u64 perf_reg_abi(struct <token> *task) <answer> task_struct 
<token> (test_tsk_thread_flag(task, TIF_31BIT)) <answer> if 
return <token> <answer> PERF_SAMPLE_REGS_ABI_32; 
return <token> <answer> PERF_SAMPLE_REGS_ABI_64; 
void perf_get_regs_user(struct perf_regs <token> <answer> *regs_user, 
struct <token> *regs) <answer> pt_regs 
regs_user->regs = <token> <answer> task_pt_regs(current); 
if <token> <answer> (user_mode(regs_user->regs)) 
regs_user->abi = <token> <answer> perf_reg_abi(current); 
#define pr_fmt(fmt) <token> " fmt, __func__, __LINE__ <answer> "[drm:%s:%d] 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/of_address.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> "dpu_hw_mdss.h" <answer> #include 
#include <token> <answer> "dpu_hw_interrupts.h" 
#include <token> <answer> "dpu_hw_catalog.h" 
#include <token> <answer> "dpu_kms.h" 
#define <token> \ <answer> VIG_BASE_MASK 
(BIT(DPU_SSPP_QOS) <token> <answer> |\ 
<token> |\ <answer> BIT(DPU_SSPP_CDP) 
BIT(DPU_SSPP_TS_PREFILL) <token> BIT(DPU_SSPP_EXCL_RECT)) <answer> | 
<token> VIG_MASK \ <answer> #define 
(VIG_BASE_MASK <token> \ <answer> | 
#define VIG_MSM8998_MASK <token> <answer> \ 
(VIG_MASK | <token> <answer> BIT(DPU_SSPP_SCALER_QSEED3_COMPATIBLE)) 
<token> VIG_SDM845_MASK \ <answer> #define 
(VIG_MASK | BIT(DPU_SSPP_QOS_8LVL) <token> BIT(DPU_SSPP_SCALER_QSEED3_COMPATIBLE)) <answer> | 
#define <token> \ <answer> VIG_SDM845_MASK_SDMA 
(VIG_SDM845_MASK | <token> <answer> BIT(DPU_SSPP_SMART_DMA_V2)) 
#define <token> (VIG_BASE_MASK | BIT(DPU_SSPP_QOS_8LVL)) <answer> VIG_QCM2290_MASK 
#define <token> \ <answer> DMA_MSM8998_MASK 
(BIT(DPU_SSPP_QOS) <token> <answer> |\ 
BIT(DPU_SSPP_TS_PREFILL) <token> BIT(DPU_SSPP_TS_PREFILL_REC1) |\ <answer> | 
BIT(DPU_SSPP_CDP) | <token> <answer> BIT(DPU_SSPP_EXCL_RECT)) 
<token> VIG_SC7280_MASK \ <answer> #define 
<token> | BIT(DPU_SSPP_INLINE_ROTATION)) <answer> (VIG_SDM845_MASK 
#define <token> \ <answer> VIG_SC7280_MASK_SDMA 
<token> | BIT(DPU_SSPP_SMART_DMA_V2)) <answer> (VIG_SC7280_MASK 
#define DMA_SDM845_MASK <token> <answer> \ 
<token> | BIT(DPU_SSPP_QOS_8LVL) |\ <answer> (BIT(DPU_SSPP_QOS) 
BIT(DPU_SSPP_TS_PREFILL) | BIT(DPU_SSPP_TS_PREFILL_REC1) <token> <answer> |\ 
BIT(DPU_SSPP_CDP) | <token> <answer> BIT(DPU_SSPP_EXCL_RECT)) 
#define DMA_CURSOR_SDM845_MASK <token> <answer> \ 
<token> | BIT(DPU_SSPP_CURSOR)) <answer> (DMA_SDM845_MASK 
<token> DMA_SDM845_MASK_SDMA \ <answer> #define 
<token> | BIT(DPU_SSPP_SMART_DMA_V2)) <answer> (DMA_SDM845_MASK 
<token> DMA_CURSOR_SDM845_MASK_SDMA \ <answer> #define 
(DMA_CURSOR_SDM845_MASK | <token> <answer> BIT(DPU_SSPP_SMART_DMA_V2)) 
<token> DMA_CURSOR_MSM8998_MASK \ <answer> #define 
(DMA_MSM8998_MASK | <token> <answer> BIT(DPU_SSPP_CURSOR)) 
<token> MIXER_MSM8998_MASK \ <answer> #define 
#define <token> \ <answer> MIXER_SDM845_MASK 
(BIT(DPU_MIXER_SOURCESPLIT) | BIT(DPU_DIM_LAYER) | <token> <answer> BIT(DPU_MIXER_COMBINED_ALPHA)) 
#define MIXER_QCM2290_MASK <token> <answer> \ 
(BIT(DPU_DIM_LAYER) <token> BIT(DPU_MIXER_COMBINED_ALPHA)) <answer> | 
#define <token> \ <answer> PINGPONG_SDM845_MASK 
(BIT(DPU_PINGPONG_DITHER) | <token> <answer> BIT(DPU_PINGPONG_DSC)) 
<token> PINGPONG_SDM845_TE2_MASK \ <answer> #define 
(PINGPONG_SDM845_MASK | <token> <answer> BIT(DPU_PINGPONG_TE2)) 
#define PINGPONG_SM8150_MASK <token> <answer> \ 
<token> | BIT(DPU_PINGPONG_DSC)) <answer> (BIT(DPU_PINGPONG_DITHER) 
#define CTL_SC7280_MASK <token> <answer> \ 
(BIT(DPU_CTL_ACTIVE_CFG) | <token> <answer> \ 
<token> | \ <answer> BIT(DPU_CTL_FETCH_ACTIVE) 
BIT(DPU_CTL_VM_CFG) | <token> <answer> \ 
#define CTL_SM8550_MASK <token> <answer> \ 
(CTL_SC7280_MASK | <token> <answer> BIT(DPU_CTL_HAS_LAYER_EXT4)) 
#define <token> BIT(DPU_DSPP_PCC) <answer> DSPP_SC7180_MASK 
#define <token> \ <answer> INTF_SC7180_MASK 
(BIT(DPU_INTF_INPUT_CTRL) | <token> <answer> \ 
<token> | \ <answer> BIT(DPU_INTF_STATUS_SUPPORTED) 
#define <token> (INTF_SC7180_MASK) <answer> INTF_SC7280_MASK 
#define WB_SM8250_MASK (BIT(DPU_WB_LINE_MODE) <token> \ <answer> | 
BIT(DPU_WB_UBWC) <token> \ <answer> | 
BIT(DPU_WB_YUV_CONFIG) <token> \ <answer> | 
BIT(DPU_WB_PIPE_ALPHA) | <token> <answer> \ 
<token> | \ <answer> BIT(DPU_WB_XY_ROI_OFFSET) 
BIT(DPU_WB_QOS) <token> \ <answer> | 
<token> | \ <answer> BIT(DPU_WB_QOS_8LVL) 
BIT(DPU_WB_CDP) <token> \ <answer> | 
<token> DEFAULT_PIXEL_RAM_SIZE (50 * 1024) <answer> #define 
<token> DEFAULT_DPU_LINE_WIDTH 2048 <answer> #define 
<token> DEFAULT_DPU_OUTPUT_LINE_WIDTH 2560 <answer> #define 
#define <token> 4 <answer> MAX_HORZ_DECIMATION 
#define MAX_VERT_DECIMATION <token> <answer> 4 
#define MAX_UPSCALE_RATIO <token> <answer> 20 
#define MAX_DOWNSCALE_RATIO <token> <answer> 4 
<token> SSPP_UNITY_SCALE 1 <answer> #define 
#define <token> Y) (X Y) <answer> STRCAT(X, 
static const uint32_t <token> = { <answer> plane_formats[] 
static const uint32_t <token> = { <answer> plane_formats_yuv[] 
<token> const u32 rotation_v2_formats[] = { <answer> static 
#define <token> min) (((maj) << 16) | (min)) <answer> SSPP_SCALER_VER(maj, 
<token> const struct dpu_dspp_sub_blks msm8998_dspp_sblk = { <answer> static 
.pcc <token> {.name = "pcc", .base = 0x1700, <answer> = 
.len = <token> .version = 0x10007}, <answer> 0x90, 
static const <token> dpu_dspp_sub_blks sdm845_dspp_sblk = { <answer> struct 
.pcc <token> {.name = "pcc", .base = 0x1700, <answer> = 
.len <token> 0x90, .version = 0x40000}, <answer> = 
static const struct dpu_pingpong_sub_blks <token> = { <answer> sdm845_pp_sblk_te 
.te2 = {.name = "te2", .base = 0x2000, <token> = 0x0, <answer> .len 
.version = <token> <answer> 0x1}, 
.dither = {.name = "dither", .base <token> 0x30e0, <answer> = 
.len = 0x20, .version = <token> <answer> 0x10000}, 
static <token> struct dpu_pingpong_sub_blks sdm845_pp_sblk = { <answer> const 
<token> = {.name = "dither", .base = 0x30e0, <answer> .dither 
<token> = 0x20, .version = 0x10000}, <answer> .len 
static const struct dpu_pingpong_sub_blks <token> = { <answer> sc7280_pp_sblk 
.dither = {.name = "dither", <token> = 0xe0, <answer> .base 
.len = <token> .version = 0x20000}, <answer> 0x20, 
<token> const struct dpu_dsc_sub_blks dsc_sblk_0 = { <answer> static 
.enc = {.name = "enc", .base = 0x100, <token> = 0x9c}, <answer> .len 
.ctl = {.name = "ctl", .base = 0xF00, <token> = 0x10}, <answer> .len 
static const struct <token> dsc_sblk_1 = { <answer> dpu_dsc_sub_blks 
.enc = {.name = "enc", .base = 0x200, .len = <token> <answer> 0x9c}, 
.ctl = {.name = "ctl", .base = 0xF80, .len = <token> <answer> 0x10}, 
static const <token> dpu_cdm_cfg sc7280_cdm = { <answer> struct 
.name <token> "cdm_0", <answer> = 
<token> = CDM_0, <answer> .id 
.len <token> 0x228, <answer> = 
.base = <token> <answer> 0x79200, 
#include <token> <answer> "catalog/dpu_3_0_msm8998.h" 
<token> "catalog/dpu_3_2_sdm660.h" <answer> #include 
<token> "catalog/dpu_3_3_sdm630.h" <answer> #include 
<token> "catalog/dpu_4_0_sdm845.h" <answer> #include 
<token> "catalog/dpu_4_1_sdm670.h" <answer> #include 
<token> "catalog/dpu_5_0_sm8150.h" <answer> #include 
#include <token> <answer> "catalog/dpu_5_1_sc8180x.h" 
<token> "catalog/dpu_5_4_sm6125.h" <answer> #include 
<token> "catalog/dpu_6_0_sm8250.h" <answer> #include 
#include <token> <answer> "catalog/dpu_6_2_sc7180.h" 
#include <token> <answer> "catalog/dpu_6_3_sm6115.h" 
#include <token> <answer> "catalog/dpu_6_4_sm6350.h" 
#include <token> <answer> "catalog/dpu_6_5_qcm2290.h" 
#include <token> <answer> "catalog/dpu_6_9_sm6375.h" 
#include <token> <answer> "catalog/dpu_7_0_sm8350.h" 
#include <token> <answer> "catalog/dpu_7_2_sc7280.h" 
<token> "catalog/dpu_8_0_sc8280xp.h" <answer> #include 
#include <token> <answer> "catalog/dpu_8_1_sm8450.h" 
<token> "catalog/dpu_9_0_sm8550.h" <answer> #include 
<token> "catalog/dpu_9_2_x1e80100.h" <answer> #include 
#include <token> <answer> "catalog/dpu_10_0_sm8650.h" 
<token> "bcachefs.h" <answer> #include 
<token> "btree_cache.h" <answer> #include 
<token> "btree_io.h" <answer> #include 
<token> "btree_journal_iter.h" <answer> #include 
<token> "btree_node_scan.h" <answer> #include 
#include <token> <answer> "btree_update_interior.h" 
<token> "buckets.h" <answer> #include 
<token> "error.h" <answer> #include 
<token> "journal_io.h" <answer> #include 
#include <token> <answer> "recovery_passes.h" 
#include <token> <answer> <linux/kthread.h> 
<token> <linux/sort.h> <answer> #include 
struct <token> { <answer> find_btree_nodes_worker 
struct <token> *cl; <answer> closure 
<token> find_btree_nodes *f; <answer> struct 
struct bch_dev <token> <answer> *ca; 
static void found_btree_node_to_text(struct printbuf *out, struct <token> *c, const struct found_btree_node *n) <answer> bch_fs 
prt_printf(out, "%s l=%u seq=%u cookie=%llx ", bch2_btree_id_str(n->btree_id), n->level, <token> n->cookie); <answer> n->seq, 
bch2_bpos_to_text(out, <token> <answer> n->min_key); 
prt_str(out, <token> <answer> "-"); 
bch2_bpos_to_text(out, <token> <answer> n->max_key); 
<token> (n->range_updated) <answer> if 
prt_str(out, " <token> updated"); <answer> range 
if <token> <answer> (n->overwritten) 
prt_str(out, <token> overwritten"); <answer> " 
for (unsigned i = <token> i < n->nr_ptrs; i++) { <answer> 0; 
prt_char(out, ' <token> <answer> '); 
<token> c, n->ptrs + i); <answer> bch2_extent_ptr_to_text(out, 
<token> void found_btree_nodes_to_text(struct printbuf *out, struct bch_fs *c, found_btree_nodes nodes) <answer> static 
<token> 2); <answer> printbuf_indent_add(out, 
darray_for_each(nodes, <token> { <answer> i) 
found_btree_node_to_text(out, <token> i); <answer> c, 
<token> 2); <answer> printbuf_indent_sub(out, 
static void found_btree_node_to_key(struct bkey_i *k, const struct <token> *f) <answer> found_btree_node 
<token> bkey_i_btree_ptr_v2 *bp = bkey_btree_ptr_v2_init(k); <answer> struct 
set_bkey_val_u64s(&bp->k, sizeof(struct bch_btree_ptr_v2) <token> sizeof(u64) + f->nr_ptrs); <answer> / 
bp->k.p = <token> <answer> f->max_key; 
<token> = cpu_to_le64(f->cookie); <answer> bp->v.seq 
bp->v.sectors_written = <token> <answer> 0; 
bp->v.flags <token> 0; <answer> = 
<token> = cpu_to_le16(f->sectors_written); <answer> bp->v.sectors_written 
bp->v.min_key = <token> <answer> f->min_key; 
<token> f->range_updated); <answer> SET_BTREE_PTR_RANGE_UPDATED(&bp->v, 
memcpy(bp->v.start, f->ptrs, sizeof(struct bch_extent_ptr) * <token> <answer> f->nr_ptrs); 
static bool <token> btree_trans *trans, <answer> found_btree_node_is_readable(struct 
struct found_btree_node <token> <answer> *f) 
struct { <token> BKEY_BTREE_PTR_VAL_U64s_MAX); } k; <answer> __BKEY_PADDED(k, 
<token> f); <answer> found_btree_node_to_key(&k.k, 
struct btree *b = bch2_btree_node_get_noiter(trans, &k.k, f->btree_id, <token> false); <answer> f->level, 
bool <token> = !IS_ERR_OR_NULL(b); <answer> ret 
if <token> { <answer> (ret) 
<token> = b->written; <answer> f->sectors_written 
if (b != <token> b)) <answer> btree_node_root(trans->c, 
<token> &k.k); <answer> bch2_btree_node_evict(trans, 
<token> ret; <answer> return 
static int <token> void *_l, const void *_r) <answer> found_btree_node_cmp_cookie(const 
const struct <token> *l = _l; <answer> found_btree_node 
<token> struct found_btree_node *r = _r; <answer> const 
<token> cmp_int(l->btree_id, r->btree_id) ?: <answer> return 
cmp_int(l->level, r->level) <token> <answer> ?: 
<token> r->cookie); <answer> cmp_int(l->cookie, 
static int found_btree_node_cmp_time(const <token> found_btree_node *l, <answer> struct 
const struct found_btree_node <token> <answer> *r) 
return cmp_int(l->seq, <token> <answer> r->seq); 
static int found_btree_node_cmp_pos(const <token> *_l, const void *_r) <answer> void 
const struct <token> *l = _l; <answer> found_btree_node 
const struct found_btree_node *r = <token> <answer> _r; 
return cmp_int(l->btree_id, <token> ?: <answer> r->btree_id) 
-cmp_int(l->level, r->level) <token> <answer> ?: 
<token> r->min_key) ?: <answer> bpos_cmp(l->min_key, 
-found_btree_node_cmp_time(l, <token> <answer> r); 
static void try_read_btree_node(struct find_btree_nodes <token> struct bch_dev *ca, <answer> *f, 
struct bio *bio, struct <token> *bn, u64 offset) <answer> btree_node 
struct bch_fs *c <token> container_of(f, struct bch_fs, found_btree_nodes); <answer> = 
bio_reset(bio, <token> REQ_OP_READ); <answer> ca->disk_sb.bdev, 
bio->bi_iter.bi_sector <token> offset; <answer> = 
bch2_bio_map(bio, <token> PAGE_SIZE); <answer> bn, 
if (bch2_dev_io_err_on(bio->bi_status, <token> BCH_MEMBER_ERROR_read, <answer> ca, 
"IO error <token> try_read_btree_node() at %llu: %s", <answer> in 
offset, <token> <answer> bch2_blk_status_to_str(bio->bi_status))) 
if (le64_to_cpu(bn->magic) != <token> <answer> bset_magic(c)) 
<token> (bch2_csum_type_is_encryption(BSET_CSUM_TYPE(&bn->keys))) { <answer> if 
struct nonce nonce <token> btree_nonce(&bn->keys, 0); <answer> = 
unsigned bytes = (void *) &bn->keys - <token> *) &bn->flags; <answer> (void 
bch2_encrypt(c, BSET_CSUM_TYPE(&bn->keys), nonce, &bn->flags, <token> <answer> bytes); 
if <token> <answer> (btree_id_is_alloc(BTREE_NODE_ID(bn))) 
if (BTREE_NODE_LEVEL(bn) >= <token> <answer> BTREE_MAX_DEPTH) 
<token> found_btree_node n = { <answer> struct 
.btree_id <token> BTREE_NODE_ID(bn), <answer> = 
.level = <token> <answer> BTREE_NODE_LEVEL(bn), 
.seq <token> BTREE_NODE_SEQ(bn), <answer> = 
<token> = le64_to_cpu(bn->keys.seq), <answer> .cookie 
<token> = bn->min_key, <answer> .min_key 
.max_key <token> bn->max_key, <answer> = 
<token> = 1, <answer> .nr_ptrs 
.ptrs[0].type = 1 << <token> <answer> BCH_EXTENT_ENTRY_ptr, 
.ptrs[0].offset <token> offset, <answer> = 
.ptrs[0].dev = <token> <answer> ca->dev_idx, 
.ptrs[0].gen <token> *bucket_gen(ca, sector_to_bucket(ca, offset)), <answer> = 
if (bch2_trans_run(c, found_btree_node_is_readable(trans, &n))) <token> <answer> { 
<token> (BSET_BIG_ENDIAN(&bn->keys) != CPU_BIG_ENDIAN) { <answer> if 
bch_err(c, <token> can't handle endian conversion"); <answer> "try_read_btree_node() 
f->ret <token> -EINVAL; <answer> = 
goto <token> <answer> unlock; 
if (darray_push(&f->nodes, <token> <answer> n)) 
f->ret = <token> <answer> -ENOMEM; 
static int read_btree_nodes_worker(void <token> <answer> *p) 
struct find_btree_nodes_worker <token> = p; <answer> *w 
struct <token> *c = container_of(w->f, struct bch_fs, found_btree_nodes); <answer> bch_fs 
struct <token> *ca = w->ca; <answer> bch_dev 
void *buf = (void <token> __get_free_page(GFP_KERNEL); <answer> *) 
struct bio *bio = <token> 1, 0, GFP_KERNEL); <answer> bio_alloc(NULL, 
<token> long last_print = jiffies; <answer> unsigned 
if (!buf <token> !bio) { <answer> || 
<token> "read_btree_nodes_worker: error allocating bio/buf"); <answer> bch_err(c, 
w->f->ret = <token> <answer> -ENOMEM; 
goto <token> <answer> err; 
for (u64 <token> = ca->mi.first_bucket; bucket < ca->mi.nbuckets; bucket++) <answer> bucket 
for (unsigned <token> = 0; <answer> bucket_offset 
bucket_offset + btree_sectors(c) <token> ca->mi.bucket_size; <answer> <= 
bucket_offset <token> btree_sectors(c)) { <answer> += 
if (time_after(jiffies, last_print + HZ * <token> { <answer> 30)) 
u64 <token> = bucket * ca->mi.bucket_size + bucket_offset; <answer> cur_sector 
u64 end_sector = ca->mi.nbuckets <token> ca->mi.bucket_size; <answer> * 
bch_info(ca, "%s: %2u%% <token> __func__, <answer> done", 
(unsigned) div64_u64(cur_sector * 100, <token> <answer> end_sector)); 
last_print = <token> <answer> jiffies; 
u64 sector <token> bucket * ca->mi.bucket_size + bucket_offset; <answer> = 
if (c->sb.version_upgrade_complete >= bcachefs_metadata_version_mi_btree_bitmap <token> <answer> && 
!bch2_dev_btree_bitmap_marked_sectors(ca, sector, <token> <answer> btree_sectors(c))) 
try_read_btree_node(w->f, ca, bio, <token> sector); <answer> buf, 
free_page((unsigned long) <token> <answer> buf); 
return <token> <answer> 0; 
static int read_btree_nodes(struct <token> *f) <answer> find_btree_nodes 
struct bch_fs *c = container_of(f, struct bch_fs, <token> <answer> found_btree_nodes); 
<token> closure cl; <answer> struct 
<token> ret = 0; <answer> int 
for_each_online_member(c, <token> { <answer> ca) 
if <token> & BIT(BCH_DATA_btree))) <answer> (!(ca->mi.data_allowed 
struct find_btree_nodes_worker *w <token> kmalloc(sizeof(*w), GFP_KERNEL); <answer> = 
<token> task_struct *t; <answer> struct 
if (!w) <token> <answer> { 
ret <token> -ENOMEM; <answer> = 
goto <token> <answer> err; 
<token> = &cl; <answer> w->cl 
w->f <token> f; <answer> = 
w->ca = <token> <answer> ca; 
t = kthread_run(read_btree_nodes_worker, w, "read_btree_nodes/%s", <token> <answer> ca->name); 
ret <token> IS_ERR_OR_NULL(t); <answer> = 
if <token> { <answer> (ret) 
f->ret <token> ret; <answer> = 
bch_err(c, "error starting <token> %i", ret); <answer> kthread: 
return f->ret ?: <token> <answer> ret; 
static void bubble_up(struct <token> *n, struct found_btree_node *end) <answer> found_btree_node 
while (n + 1 < <token> && <answer> end 
found_btree_node_cmp_pos(n, n + 1) > 0) <token> <answer> { 
<token> n[1]); <answer> swap(n[0], 
static <token> handle_overwrites(struct bch_fs *c, <answer> int 
<token> found_btree_node *start, <answer> struct 
struct found_btree_node <token> <answer> *end) 
struct <token> *n; <answer> found_btree_node 
for <token> = start + 1; <answer> (n 
n <token> end && <answer> < 
n->btree_id == start->btree_id <token> <answer> && 
n->level == <token> && <answer> start->level 
<token> start->max_key); <answer> bpos_lt(n->min_key, 
n++) <token> <answer> { 
int cmp <token> found_btree_node_cmp_time(start, n); <answer> = 
if (cmp > 0) <token> <answer> { 
<token> (bpos_cmp(start->max_key, n->max_key) >= 0) <answer> if 
n->overwritten = <token> <answer> true; 
else <token> <answer> { 
n->range_updated <token> true; <answer> = 
<token> = bpos_successor(start->max_key); <answer> n->min_key 
n->range_updated <token> true; <answer> = 
<token> end); <answer> bubble_up(n, 
goto <token> <answer> again; 
} else if (cmp < 0) <token> <answer> { 
<token> start->min_key) <= 0); <answer> BUG_ON(bpos_cmp(n->min_key, 
<token> = bpos_predecessor(n->min_key); <answer> start->max_key 
start->range_updated <token> true; <answer> = 
<token> else if (n->level) { <answer> } 
n->overwritten <token> true; <answer> = 
} <token> { <answer> else 
struct <token> buf = PRINTBUF; <answer> printbuf 
prt_str(&buf, "overlapping <token> nodes with same seq! halting\n "); <answer> btree 
found_btree_node_to_text(&buf, c, <token> <answer> start); 
prt_str(&buf, <token> "); <answer> "\n 
found_btree_node_to_text(&buf, c, <token> <answer> n); 
<token> "%s", buf.buf); <answer> bch_err(c, 
<token> -BCH_ERR_fsck_repair_unimplemented; <answer> return 
<token> 0; <answer> return 
<token> bch2_scan_for_btree_nodes(struct bch_fs *c) <answer> int 
<token> find_btree_nodes *f = &c->found_btree_nodes; <answer> struct 
struct printbuf buf = <token> <answer> PRINTBUF; 
size_t <token> <answer> dst; 
<token> ret = 0; <answer> int 
if <token> <answer> (f->nodes.nr) 
<token> 0; <answer> return 
ret = <token> <answer> read_btree_nodes(f); 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if (!f->nodes.nr) <token> <answer> { 
bch_err(c, "%s: no btree nodes <token> __func__); <answer> found", 
<token> = -EINVAL; <answer> ret 
goto <token> <answer> err; 
if <token> && c->opts.verbose) { <answer> (0 
prt_printf(&buf, "%s: nodes <token> __func__); <answer> found:\n", 
<token> c, f->nodes); <answer> found_btree_nodes_to_text(&buf, 
bch2_print_string_as_lines(KERN_INFO, <token> <answer> buf.buf); 
sort(f->nodes.data, f->nodes.nr, sizeof(f->nodes.data[0]), found_btree_node_cmp_cookie, <token> <answer> NULL); 
dst = <token> <answer> 0; 
<token> i) { <answer> darray_for_each(f->nodes, 
struct found_btree_node *prev = dst ? f->nodes.data + dst - <token> : NULL; <answer> 1 
if (prev <token> <answer> && 
prev->cookie == <token> { <answer> i->cookie) 
if (prev->nr_ptrs == <token> { <answer> ARRAY_SIZE(prev->ptrs)) 
bch_err(c, "%s: found too many replicas <token> btree node", __func__); <answer> for 
<token> = -EINVAL; <answer> ret 
<token> err; <answer> goto 
prev->ptrs[prev->nr_ptrs++] <token> i->ptrs[0]; <answer> = 
} else <token> <answer> { 
f->nodes.data[dst++] = <token> <answer> *i; 
<token> = dst; <answer> f->nodes.nr 
sort(f->nodes.data, <token> sizeof(f->nodes.data[0]), found_btree_node_cmp_pos, NULL); <answer> f->nodes.nr, 
if (0 && c->opts.verbose) <token> <answer> { 
<token> "%s: nodes after merging replicas:\n", __func__); <answer> prt_printf(&buf, 
found_btree_nodes_to_text(&buf, c, <token> <answer> f->nodes); 
bch2_print_string_as_lines(KERN_INFO, <token> <answer> buf.buf); 
dst = <token> <answer> 0; 
darray_for_each(f->nodes, <token> { <answer> i) 
<token> (i->overwritten) <answer> if 
ret = handle_overwrites(c, i, <token> <answer> &darray_top(f->nodes)); 
if <token> <answer> (ret) 
goto <token> <answer> err; 
<token> = *i; <answer> f->nodes.data[dst++] 
f->nodes.nr <token> dst; <answer> = 
if (c->opts.verbose) <token> <answer> { 
prt_printf(&buf, "%s: nodes found <token> overwrites:\n", __func__); <answer> after 
found_btree_nodes_to_text(&buf, c, <token> <answer> f->nodes); 
<token> buf.buf); <answer> bch2_print_string_as_lines(KERN_INFO, 
eytzinger0_sort(f->nodes.data, f->nodes.nr, sizeof(f->nodes.data[0]), <token> NULL); <answer> found_btree_node_cmp_pos, 
return <token> <answer> ret; 
static int <token> void *_l, const void *_r) <answer> found_btree_node_range_start_cmp(const 
const struct found_btree_node *l = <token> <answer> _l; 
const struct found_btree_node *r = <token> <answer> _r; 
return <token> r->btree_id) ?: <answer> cmp_int(l->btree_id, 
-cmp_int(l->level, <token> ?: <answer> r->level) 
bpos_cmp(l->max_key, <token> <answer> r->min_key); 
#define for_each_found_btree_node_in_range(_f, _search, <token> \ <answer> _idx) 
for (size_t _idx = <token> (_f)->nodes.nr, \ <answer> eytzinger0_find_gt((_f)->nodes.data, 
sizeof((_f)->nodes.data[0]), <token> <answer> \ 
found_btree_node_range_start_cmp, <token> \ <answer> &search); 
_idx <token> (_f)->nodes.nr && \ <answer> < 
<token> == _search.btree_id && \ <answer> (_f)->nodes.data[_idx].btree_id 
<token> == _search.level && \ <answer> (_f)->nodes.data[_idx].level 
bpos_lt((_f)->nodes.data[_idx].min_key, <token> \ <answer> _search.max_key); 
_idx = <token> (_f)->nodes.nr)) <answer> eytzinger0_next(_idx, 
bool <token> bch_fs *c, struct btree *b) <answer> bch2_btree_node_is_stale(struct 
struct find_btree_nodes *f = <token> <answer> &c->found_btree_nodes; 
struct found_btree_node search = <token> <answer> { 
.btree_id <token> b->c.btree_id, <answer> = 
.level <token> b->c.level, <answer> = 
.min_key <token> b->data->min_key, <answer> = 
.max_key <token> b->key.k.p, <answer> = 
for_each_found_btree_node_in_range(f, <token> idx) <answer> search, 
if (f->nodes.data[idx].seq > <token> <answer> BTREE_NODE_SEQ(b->data)) 
return <token> <answer> true; 
return <token> <answer> false; 
bool <token> bch_fs *c, enum btree_id btree) <answer> bch2_btree_has_scanned_nodes(struct 
struct found_btree_node <token> = { <answer> search 
.btree_id <token> btree, <answer> = 
.level = <token> <answer> 0, 
.min_key <token> POS_MIN, <answer> = 
.max_key = <token> <answer> SPOS_MAX, 
for_each_found_btree_node_in_range(&c->found_btree_nodes, search, <token> <answer> idx) 
return <token> <answer> true; 
return <token> <answer> false; 
int bch2_get_scanned_nodes(struct bch_fs *c, <token> btree_id btree, <answer> enum 
unsigned level, struct <token> node_min, struct bpos node_max) <answer> bpos 
<token> (btree_id_is_alloc(btree)) <answer> if 
<token> 0; <answer> return 
struct find_btree_nodes *f = <token> <answer> &c->found_btree_nodes; 
int ret = <token> BCH_RECOVERY_PASS_scan_for_btree_nodes); <answer> bch2_run_explicit_recovery_pass(c, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> (c->opts.verbose) { <answer> if 
struct printbuf buf <token> PRINTBUF; <answer> = 
prt_printf(&buf, "recovering %s l=%u ", bch2_btree_id_str(btree), <token> <answer> level); 
bch2_bpos_to_text(&buf, <token> <answer> node_min); 
<token> " - "); <answer> prt_str(&buf, 
bch2_bpos_to_text(&buf, <token> <answer> node_max); 
bch_info(c, "%s(): %s", __func__, <token> <answer> buf.buf); 
struct <token> search = { <answer> found_btree_node 
.btree_id <token> btree, <answer> = 
.level <token> level, <answer> = 
.min_key = <token> <answer> node_min, 
.max_key <token> node_max, <answer> = 
for_each_found_btree_node_in_range(f, search, <token> { <answer> idx) 
struct found_btree_node n <token> f->nodes.data[idx]; <answer> = 
n.range_updated <token> bpos_lt(n.min_key, node_min); <answer> |= 
n.min_key = <token> node_min); <answer> bpos_max(n.min_key, 
n.range_updated |= <token> node_max); <answer> bpos_gt(n.max_key, 
n.max_key = <token> node_max); <answer> bpos_min(n.max_key, 
<token> { __BKEY_PADDED(k, BKEY_BTREE_PTR_VAL_U64s_MAX); } tmp; <answer> struct 
found_btree_node_to_key(&tmp.k, <token> <answer> &n); 
struct printbuf buf = <token> <answer> PRINTBUF; 
<token> c, bkey_i_to_s_c(&tmp.k)); <answer> bch2_bkey_val_to_text(&buf, 
bch_verbose(c, "%s(): <token> %s", __func__, buf.buf); <answer> recovering 
BUG_ON(bch2_bkey_invalid(c, <token> BKEY_TYPE_btree, 0, NULL)); <answer> bkey_i_to_s_c(&tmp.k), 
ret = <token> btree, level + 1, &tmp.k); <answer> bch2_journal_key_insert(c, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
<token> 0; <answer> return 
void bch2_find_btree_nodes_exit(struct find_btree_nodes <token> <answer> *f) 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/device.h> 
<token> <linux/init.h> <answer> #include 
<token> <linux/rtc.h> <answer> #include 
#include <token> <answer> <linux/spi/spi.h> 
<token> <linux/bcd.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/bitops.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/types.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/sched.h> 
#include <token> <answer> <linux/sched/loadavg.h> 
<token> <linux/string.h> <answer> #include 
<token> <linux/skbuff.h> <answer> #include 
<token> <linux/random.h> <answer> #include 
#include <token> <answer> <linux/if_vlan.h> 
<token> <linux/tc_ematch/tc_em_meta.h> <answer> #include 
<token> <net/dst.h> <answer> #include 
#include <token> <answer> <net/route.h> 
<token> <net/pkt_cls.h> <answer> #include 
<token> <net/sock.h> <answer> #include 
<token> meta_obj { <answer> struct 
unsigned long <token> <answer> value; 
unsigned int <token> <answer> len; 
struct meta_value <token> <answer> { 
struct <token> hdr; <answer> tcf_meta_val 
unsigned <token> val; <answer> long 
unsigned int <token> <answer> len; 
struct <token> { <answer> meta_match 
struct meta_value <token> <answer> lvalue; 
<token> meta_value rvalue; <answer> struct 
static inline int <token> meta_value *v) <answer> meta_id(struct 
return <token> <answer> TCF_META_ID(v->hdr.kind); 
static inline <token> meta_type(struct meta_value *v) <answer> int 
return <token> <answer> TCF_META_TYPE(v->hdr.kind); 
#define META_COLLECTOR(FUNC) static void meta_##FUNC(struct sk_buff <token> \ <answer> *skb, 
struct tcf_pkt_info *info, struct meta_value *v, <token> <answer> \ 
struct meta_obj *dst, <token> *err) <answer> int 
get_random_bytes(&dst->value, <token> <answer> sizeof(dst->value)); 
static inline unsigned <token> fixed_loadavg(int load) <answer> long 
int rnd_load = <token> + (FIXED_1/200); <answer> load 
int rnd_frac = <token> & (FIXED_1-1)) * 100) >> FSHIFT; <answer> ((rnd_load 
return ((rnd_load >> FSHIFT) * 100) + <token> <answer> rnd_frac; 
<token> = fixed_loadavg(avenrun[0]); <answer> dst->value 
dst->value <token> fixed_loadavg(avenrun[1]); <answer> = 
dst->value <token> fixed_loadavg(avenrun[2]); <answer> = 
static inline <token> int_dev(struct net_device *dev, struct meta_obj *dst) <answer> int 
<token> (unlikely(dev == NULL)) <answer> if 
<token> -1; <answer> return 
dst->value = <token> <answer> dev->ifindex; 
return <token> <answer> 0; 
<token> inline int var_dev(struct net_device *dev, struct meta_obj *dst) <answer> static 
if (unlikely(dev == <token> <answer> NULL)) 
return <token> <answer> -1; 
dst->value = (unsigned <token> dev->name; <answer> long) 
<token> = strlen(dev->name); <answer> dst->len 
<token> 0; <answer> return 
*err <token> int_dev(skb->dev, dst); <answer> = 
*err <token> var_dev(skb->dev, dst); <answer> = 
unsigned short <token> <answer> tag; 
<token> (skb_vlan_tag_present(skb)) <answer> if 
dst->value <token> skb_vlan_tag_get(skb); <answer> = 
else <token> (!__vlan_get_tag(skb, &tag)) <answer> if 
dst->value <token> tag; <answer> = 
<token> = -1; <answer> *err 
<token> = skb->priority; <answer> dst->value 
dst->value <token> skb->mark; <answer> = 
dst->value <token> skb->tc_index; <answer> = 
<token> (unlikely(skb_dst(skb) == NULL)) <answer> if 
*err <token> -1; <answer> = 
#ifdef <token> <answer> CONFIG_IP_ROUTE_CLASSID 
dst->value = <token> <answer> skb_dst(skb)->tclassid; 
dst->value = <token> <answer> 0; 
if <token> == NULL)) <answer> (unlikely(skb_rtable(skb) 
*err = <token> <answer> -1; 
dst->value <token> inet_iif(skb); <answer> = 
#define <token> \ <answer> skip_nonlocal(skb) 
(unlikely(skb->sk <token> NULL)) <answer> == 
if (skip_nonlocal(skb)) <token> <answer> { 
*err = <token> <answer> -1; 
<token> = skb->sk->sk_family; <answer> dst->value 
if <token> { <answer> (skip_nonlocal(skb)) 
<token> = -1; <answer> *err 
<token> = skb->sk->sk_state; <answer> dst->value 
if <token> { <answer> (skip_nonlocal(skb)) 
*err = <token> <answer> -1; 
dst->value <token> skb->sk->sk_reuse; <answer> = 
if (skip_nonlocal(skb)) <token> <answer> { 
*err <token> -1; <answer> = 
struct <token> { <answer> meta_ops 
void <token> sk_buff *, struct tcf_pkt_info *, <answer> (*get)(struct 
struct meta_value *, <token> meta_obj *, int *); <answer> struct 
#define META_ID(name) <token> <answer> TCF_META_ID_##name 
<token> META_FUNC(name) { .get = meta_##name } <answer> #define 
static struct meta_ops __meta_ops[TCF_META_TYPE_MAX + 1][TCF_META_ID_MAX <token> 1] = { <answer> + 
<token> = { <answer> [TCF_META_TYPE_VAR] 
<token> = META_FUNC(var_dev), <answer> [META_ID(DEV)] 
<token> = META_FUNC(var_sk_bound_if), <answer> [META_ID(SK_BOUND_IF)] 
[TCF_META_TYPE_INT] <token> { <answer> = 
[META_ID(RANDOM)] = <token> <answer> META_FUNC(int_random), 
<token> = META_FUNC(int_loadavg_0), <answer> [META_ID(LOADAVG_0)] 
[META_ID(LOADAVG_1)] = <token> <answer> META_FUNC(int_loadavg_1), 
[META_ID(LOADAVG_2)] <token> META_FUNC(int_loadavg_2), <answer> = 
[META_ID(DEV)] <token> META_FUNC(int_dev), <answer> = 
[META_ID(PRIORITY)] <token> META_FUNC(int_priority), <answer> = 
<token> = META_FUNC(int_protocol), <answer> [META_ID(PROTOCOL)] 
<token> = META_FUNC(int_pkttype), <answer> [META_ID(PKTTYPE)] 
[META_ID(PKTLEN)] <token> META_FUNC(int_pktlen), <answer> = 
<token> = META_FUNC(int_datalen), <answer> [META_ID(DATALEN)] 
<token> = META_FUNC(int_maclen), <answer> [META_ID(MACLEN)] 
[META_ID(NFMARK)] = <token> <answer> META_FUNC(int_mark), 
[META_ID(TCINDEX)] = <token> <answer> META_FUNC(int_tcindex), 
[META_ID(RTCLASSID)] <token> META_FUNC(int_rtclassid), <answer> = 
[META_ID(RTIIF)] = <token> <answer> META_FUNC(int_rtiif), 
<token> = META_FUNC(int_sk_family), <answer> [META_ID(SK_FAMILY)] 
<token> = META_FUNC(int_sk_state), <answer> [META_ID(SK_STATE)] 
[META_ID(SK_REUSE)] <token> META_FUNC(int_sk_reuse), <answer> = 
[META_ID(SK_BOUND_IF)] <token> META_FUNC(int_sk_bound_if), <answer> = 
[META_ID(SK_REFCNT)] <token> META_FUNC(int_sk_refcnt), <answer> = 
[META_ID(SK_RCVBUF)] = <token> <answer> META_FUNC(int_sk_rcvbuf), 
<token> = META_FUNC(int_sk_sndbuf), <answer> [META_ID(SK_SNDBUF)] 
[META_ID(SK_SHUTDOWN)] = <token> <answer> META_FUNC(int_sk_shutdown), 
[META_ID(SK_PROTO)] = <token> <answer> META_FUNC(int_sk_proto), 
<token> = META_FUNC(int_sk_type), <answer> [META_ID(SK_TYPE)] 
<token> = META_FUNC(int_sk_rmem_alloc), <answer> [META_ID(SK_RMEM_ALLOC)] 
[META_ID(SK_WMEM_ALLOC)] = <token> <answer> META_FUNC(int_sk_wmem_alloc), 
[META_ID(SK_OMEM_ALLOC)] <token> META_FUNC(int_sk_omem_alloc), <answer> = 
<token> = META_FUNC(int_sk_wmem_queued), <answer> [META_ID(SK_WMEM_QUEUED)] 
<token> = META_FUNC(int_sk_rcv_qlen), <answer> [META_ID(SK_RCV_QLEN)] 
[META_ID(SK_SND_QLEN)] <token> META_FUNC(int_sk_snd_qlen), <answer> = 
[META_ID(SK_ERR_QLEN)] = <token> <answer> META_FUNC(int_sk_err_qlen), 
<token> = META_FUNC(int_sk_fwd_alloc), <answer> [META_ID(SK_FORWARD_ALLOCS)] 
[META_ID(SK_ALLOCS)] <token> META_FUNC(int_sk_alloc), <answer> = 
<token> = META_FUNC(int_sk_hash), <answer> [META_ID(SK_HASH)] 
<token> = META_FUNC(int_sk_lingertime), <answer> [META_ID(SK_LINGERTIME)] 
<token> = META_FUNC(int_sk_ack_bl), <answer> [META_ID(SK_ACK_BACKLOG)] 
<token> = META_FUNC(int_sk_max_ack_bl), <answer> [META_ID(SK_MAX_ACK_BACKLOG)] 
[META_ID(SK_PRIO)] <token> META_FUNC(int_sk_prio), <answer> = 
[META_ID(SK_RCVLOWAT)] <token> META_FUNC(int_sk_rcvlowat), <answer> = 
[META_ID(SK_RCVTIMEO)] <token> META_FUNC(int_sk_rcvtimeo), <answer> = 
[META_ID(SK_SNDTIMEO)] = <token> <answer> META_FUNC(int_sk_sndtimeo), 
<token> = META_FUNC(int_sk_sendmsg_off), <answer> [META_ID(SK_SENDMSG_OFF)] 
[META_ID(SK_WRITE_PENDING)] = <token> <answer> META_FUNC(int_sk_write_pend), 
[META_ID(VLAN_TAG)] <token> META_FUNC(int_vlan_tag), <answer> = 
<token> = META_FUNC(int_rxhash), <answer> [META_ID(RXHASH)] 
static inline struct meta_ops <token> meta_value *val) <answer> *meta_ops(struct 
<token> &__meta_ops[meta_type(val)][meta_id(val)]; <answer> return 
static int meta_var_compare(struct <token> *a, struct meta_obj *b) <answer> meta_obj 
int <token> = a->len - b->len; <answer> r 
if (r <token> 0) <answer> == 
r = memcmp((void *) a->value, (void <token> b->value, a->len); <answer> *) 
return <token> <answer> r; 
static int meta_var_change(struct meta_value <token> struct nlattr *nla) <answer> *dst, 
int len = <token> <answer> nla_len(nla); 
dst->val = (unsigned long)kmemdup(nla_data(nla), len, <token> <answer> GFP_KERNEL); 
if <token> == 0UL) <answer> (dst->val 
return <token> <answer> -ENOMEM; 
<token> = len; <answer> dst->len 
<token> 0; <answer> return 
static <token> meta_var_destroy(struct meta_value *v) <answer> void 
kfree((void *) <token> <answer> v->val); 
static <token> meta_var_apply_extras(struct meta_value *v, <answer> void 
struct <token> *dst) <answer> meta_obj 
int shift = <token> <answer> v->hdr.shift; 
<token> (shift && shift < dst->len) <answer> if 
dst->len -= <token> <answer> shift; 
static int meta_var_dump(struct sk_buff *skb, struct meta_value *v, <token> tlv) <answer> int 
if (v->val && <token> && <answer> v->len 
nla_put(skb, tlv, v->len, <token> *) v->val)) <answer> (void 
goto <token> <answer> nla_put_failure; 
return <token> <answer> 0; 
<token> -1; <answer> return 
<token> int meta_int_compare(struct meta_obj *a, struct meta_obj *b) <answer> static 
if <token> == b->value)) <answer> (unlikely(a->value 
<token> 0; <answer> return 
<token> if (a->value < b->value) <answer> else 
<token> -1; <answer> return 
<token> 1; <answer> return 
static int meta_int_change(struct meta_value <token> struct nlattr *nla) <answer> *dst, 
<token> (nla_len(nla) >= sizeof(unsigned long)) { <answer> if 
<token> = *(unsigned long *) nla_data(nla); <answer> dst->val 
dst->len <token> sizeof(unsigned long); <answer> = 
} else <token> (nla_len(nla) == sizeof(u32)) { <answer> if 
dst->val <token> nla_get_u32(nla); <answer> = 
dst->len = <token> <answer> sizeof(u32); 
<token> else <answer> } 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
static void <token> meta_value *v, <answer> meta_int_apply_extras(struct 
struct meta_obj <token> <answer> *dst) 
if <token> <answer> (v->hdr.shift) 
dst->value >>= <token> <answer> v->hdr.shift; 
<token> (v->val) <answer> if 
dst->value <token> v->val; <answer> &= 
static int meta_int_dump(struct sk_buff *skb, struct meta_value <token> int tlv) <answer> *v, 
if (v->len == sizeof(unsigned long)) <token> <answer> { 
<token> (nla_put(skb, tlv, sizeof(unsigned long), &v->val)) <answer> if 
goto <token> <answer> nla_put_failure; 
} else if <token> == sizeof(u32)) { <answer> (v->len 
if (nla_put_u32(skb, <token> v->val)) <answer> tlv, 
<token> nla_put_failure; <answer> goto 
<token> 0; <answer> return 
return <token> <answer> -1; 
struct <token> { <answer> meta_type_ops 
void (*destroy)(struct meta_value <token> <answer> *); 
int (*compare)(struct meta_obj *, <token> meta_obj *); <answer> struct 
int (*change)(struct meta_value *, struct <token> *); <answer> nlattr 
void (*apply_extras)(struct <token> *, struct meta_obj *); <answer> meta_value 
int (*dump)(struct <token> *, struct meta_value *, int); <answer> sk_buff 
static const struct meta_type_ops __meta_type_ops[TCF_META_TYPE_MAX + 1] = <token> <answer> { 
[TCF_META_TYPE_VAR] = <token> <answer> { 
<token> = meta_var_destroy, <answer> .destroy 
<token> = meta_var_compare, <answer> .compare 
.change = <token> <answer> meta_var_change, 
.apply_extras = <token> <answer> meta_var_apply_extras, 
.dump = <token> <answer> meta_var_dump 
<token> = { <answer> [TCF_META_TYPE_INT] 
<token> = meta_int_compare, <answer> .compare 
.change <token> meta_int_change, <answer> = 
.apply_extras <token> meta_int_apply_extras, <answer> = 
<token> = meta_int_dump <answer> .dump 
static inline const <token> meta_type_ops *meta_type_ops(struct meta_value *v) <answer> struct 
<token> &__meta_type_ops[meta_type(v)]; <answer> return 
static int <token> sk_buff *skb, struct tcf_pkt_info *info, <answer> meta_get(struct 
<token> meta_value *v, struct meta_obj *dst) <answer> struct 
int err <token> 0; <answer> = 
if (meta_id(v) == <token> { <answer> TCF_META_ID_VALUE) 
dst->value = <token> <answer> v->val; 
<token> = v->len; <answer> dst->len 
return <token> <answer> 0; 
meta_ops(v)->get(skb, info, v, <token> &err); <answer> dst, 
if <token> < 0) <answer> (err 
return <token> <answer> err; 
if <token> <answer> (meta_type_ops(v)->apply_extras) 
meta_type_ops(v)->apply_extras(v, <token> <answer> dst); 
return <token> <answer> 0; 
static int em_meta_match(struct sk_buff <token> struct tcf_ematch *m, <answer> *skb, 
struct tcf_pkt_info <token> <answer> *info) 
<token> r; <answer> int 
struct meta_match *meta = <token> meta_match *) m->data; <answer> (struct 
struct meta_obj <token> r_value; <answer> l_value, 
if <token> info, &meta->lvalue, &l_value) < 0 || <answer> (meta_get(skb, 
<token> info, &meta->rvalue, &r_value) < 0) <answer> meta_get(skb, 
return <token> <answer> 0; 
r <token> meta_type_ops(&meta->lvalue)->compare(&l_value, &r_value); <answer> = 
switch (meta->lvalue.hdr.op) <token> <answer> { 
case <token> <answer> TCF_EM_OPND_EQ: 
<token> !r; <answer> return 
case <token> <answer> TCF_EM_OPND_LT: 
return r <token> 0; <answer> < 
case <token> <answer> TCF_EM_OPND_GT: 
<token> r > 0; <answer> return 
<token> 0; <answer> return 
static void <token> meta_match *meta) <answer> meta_delete(struct 
<token> (meta) { <answer> if 
const struct meta_type_ops *ops = <token> <answer> meta_type_ops(&meta->lvalue); 
if <token> && ops->destroy) { <answer> (ops 
static inline int meta_change_data(struct <token> *dst, struct nlattr *nla) <answer> meta_value 
<token> (nla) { <answer> if 
if (nla_len(nla) == <token> <answer> 0) 
<token> -EINVAL; <answer> return 
return <token> nla); <answer> meta_type_ops(dst)->change(dst, 
return <token> <answer> 0; 
static inline int meta_is_supported(struct meta_value <token> <answer> *val) 
return <token> || meta_ops(val)->get; <answer> !meta_id(val) 
static const struct nla_policy meta_policy[TCA_EM_META_MAX + 1] = <token> <answer> { 
[TCA_EM_META_HDR] <token> { .len = sizeof(struct tcf_meta_hdr) }, <answer> = 
static int em_meta_change(struct net <token> void *data, int len, <answer> *net, 
struct tcf_ematch <token> <answer> *m) 
int <token> <answer> err; 
struct nlattr *tb[TCA_EM_META_MAX + <token> <answer> 1]; 
<token> tcf_meta_hdr *hdr; <answer> struct 
struct meta_match <token> = NULL; <answer> *meta 
err <token> nla_parse_deprecated(tb, TCA_EM_META_MAX, data, len, <answer> = 
meta_policy, <token> <answer> NULL); 
if (err <token> 0) <answer> < 
<token> errout; <answer> goto 
err <token> -EINVAL; <answer> = 
<token> (tb[TCA_EM_META_HDR] == NULL) <answer> if 
<token> errout; <answer> goto 
hdr <token> nla_data(tb[TCA_EM_META_HDR]); <answer> = 
<token> (TCF_META_TYPE(hdr->left.kind) != TCF_META_TYPE(hdr->right.kind) || <answer> if 
TCF_META_TYPE(hdr->left.kind) <token> TCF_META_TYPE_MAX || <answer> > 
<token> > TCF_META_ID_MAX || <answer> TCF_META_ID(hdr->left.kind) 
TCF_META_ID(hdr->right.kind) <token> TCF_META_ID_MAX) <answer> > 
<token> errout; <answer> goto 
meta = kzalloc(sizeof(*meta), <token> <answer> GFP_KERNEL); 
if <token> == NULL) { <answer> (meta 
<token> = -ENOMEM; <answer> err 
goto <token> <answer> errout; 
<token> &hdr->left, sizeof(hdr->left)); <answer> memcpy(&meta->lvalue.hdr, 
<token> &hdr->right, sizeof(hdr->right)); <answer> memcpy(&meta->rvalue.hdr, 
if (!meta_is_supported(&meta->lvalue) <token> <answer> || 
<token> { <answer> !meta_is_supported(&meta->rvalue)) 
err = <token> <answer> -EOPNOTSUPP; 
goto <token> <answer> errout; 
if <token> tb[TCA_EM_META_LVALUE]) < 0 || <answer> (meta_change_data(&meta->lvalue, 
meta_change_data(&meta->rvalue, <token> < 0) <answer> tb[TCA_EM_META_RVALUE]) 
<token> errout; <answer> goto 
<token> = sizeof(*meta); <answer> m->datalen 
m->data = (unsigned long) <token> <answer> meta; 
err <token> 0; <answer> = 
if <token> && meta) <answer> (err 
<token> err; <answer> return 
static void em_meta_destroy(struct <token> *m) <answer> tcf_ematch 
<token> (m) <answer> if 
meta_delete((struct <token> *) m->data); <answer> meta_match 
static int em_meta_dump(struct sk_buff *skb, <token> tcf_ematch *em) <answer> struct 
struct meta_match *meta = (struct meta_match <token> em->data; <answer> *) 
<token> tcf_meta_hdr hdr; <answer> struct 
<token> struct meta_type_ops *ops; <answer> const 
memset(&hdr, 0, <token> <answer> sizeof(hdr)); 
<token> &meta->lvalue.hdr, sizeof(hdr.left)); <answer> memcpy(&hdr.left, 
<token> &meta->rvalue.hdr, sizeof(hdr.right)); <answer> memcpy(&hdr.right, 
if (nla_put(skb, TCA_EM_META_HDR, <token> &hdr)) <answer> sizeof(hdr), 
<token> nla_put_failure; <answer> goto 
ops <token> meta_type_ops(&meta->lvalue); <answer> = 
if (ops->dump(skb, &meta->lvalue, <token> < 0 || <answer> TCA_EM_META_LVALUE) 
<token> &meta->rvalue, TCA_EM_META_RVALUE) < 0) <answer> ops->dump(skb, 
<token> nla_put_failure; <answer> goto 
return <token> <answer> 0; 
<token> -1; <answer> return 
static struct <token> em_meta_ops = { <answer> tcf_ematch_ops 
.kind = <token> <answer> TCF_EM_META, 
<token> = em_meta_change, <answer> .change 
.match <token> em_meta_match, <answer> = 
.destroy = <token> <answer> em_meta_destroy, 
.dump = <token> <answer> em_meta_dump, 
<token> = THIS_MODULE, <answer> .owner 
.link = <token> <answer> LIST_HEAD_INIT(em_meta_ops.link) 
static int __init <token> <answer> init_em_meta(void) 
return <token> <answer> tcf_em_register(&em_meta_ops); 
<token> void __exit exit_em_meta(void) <answer> static 
MODULE_DESCRIPTION("ematch classifier for various internal kernel <token> skb metadata and sk metadata"); <answer> metadata, 
<token> pr_fmt(fmt) KBUILD_MODNAME ": " fmt <answer> #define 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/skbuff.h> 
#include <token> <answer> <linux/netdevice.h> 
<token> <linux/ip.h> <answer> #include 
#include <token> <answer> <net/ip.h> 
<token> <net/ip_fib.h> <answer> #include 
<token> <net/route.h> <answer> #include 
<token> <linux/netfilter/xt_rpfilter.h> <answer> #include 
<token> <linux/netfilter/x_tables.h> <answer> #include 
MODULE_AUTHOR("Florian <token> <fw@strlen.de>"); <answer> Westphal 
MODULE_DESCRIPTION("iptables: ipv4 reverse <token> filter match"); <answer> path 
#include <token> <answer> "mt76x02.h" 
<token> "mt76x02_trace.h" <answer> #include 
#include <token> <answer> "trace.h" 
<token> mt76x02_mac_reset_counters(struct mt76x02_dev *dev) <answer> void 
<token> i; <answer> int 
mt76_rr(dev, <token> <answer> MT_RX_STAT_0); 
<token> MT_RX_STAT_1); <answer> mt76_rr(dev, 
<token> MT_RX_STAT_2); <answer> mt76_rr(dev, 
<token> MT_TX_STA_0); <answer> mt76_rr(dev, 
mt76_rr(dev, <token> <answer> MT_TX_STA_1); 
mt76_rr(dev, <token> <answer> MT_TX_STA_2); 
<token> (i = 0; i < 16; i++) <answer> for 
mt76_rr(dev, <token> <answer> MT_TX_AGG_CNT(i)); 
for (i = 0; <token> < 16; i++) <answer> i 
<token> MT_TX_STAT_FIFO); <answer> mt76_rr(dev, 
memset(dev->mphy.aggr_stats, <token> sizeof(dev->mphy.aggr_stats)); <answer> 0, 
<token> enum mt76x02_cipher_type <answer> static 
mt76x02_mac_get_key_info(struct <token> *key, u8 *key_data) <answer> ieee80211_key_conf 
<token> 0, 32); <answer> memset(key_data, 
if <token> <answer> (!key) 
<token> MT76X02_CIPHER_NONE; <answer> return 
if (key->keylen > <token> <answer> 32) 
return <token> <answer> MT76X02_CIPHER_NONE; 
memcpy(key_data, key->key, <token> <answer> key->keylen); 
<token> (key->cipher) { <answer> switch 
<token> WLAN_CIPHER_SUITE_WEP40: <answer> case 
return <token> <answer> MT76X02_CIPHER_WEP40; 
<token> WLAN_CIPHER_SUITE_WEP104: <answer> case 
<token> MT76X02_CIPHER_WEP104; <answer> return 
<token> WLAN_CIPHER_SUITE_TKIP: <answer> case 
return <token> <answer> MT76X02_CIPHER_TKIP; 
<token> WLAN_CIPHER_SUITE_CCMP: <answer> case 
<token> MT76X02_CIPHER_AES_CCMP; <answer> return 
return <token> <answer> MT76X02_CIPHER_NONE; 
int mt76x02_mac_shared_key_setup(struct mt76x02_dev <token> u8 vif_idx, <answer> *dev, 
u8 key_idx, struct ieee80211_key_conf <token> <answer> *key) 
<token> mt76x02_cipher_type cipher; <answer> enum 
<token> key_data[32]; <answer> u8 
u32 <token> <answer> val; 
cipher <token> mt76x02_mac_get_key_info(key, key_data); <answer> = 
if (cipher == MT76X02_CIPHER_NONE && <token> <answer> key) 
<token> -EOPNOTSUPP; <answer> return 
val <token> mt76_rr(dev, MT_SKEY_MODE(vif_idx)); <answer> = 
val &= ~(MT_SKEY_MODE_MASK <token> MT_SKEY_MODE_SHIFT(vif_idx, key_idx)); <answer> << 
val <token> cipher << MT_SKEY_MODE_SHIFT(vif_idx, key_idx); <answer> |= 
mt76_wr(dev, <token> val); <answer> MT_SKEY_MODE(vif_idx), 
mt76_wr_copy(dev, <token> key_idx), key_data, <answer> MT_SKEY(vif_idx, 
<token> 0; <answer> return 
void mt76x02_mac_wcid_sync_pn(struct mt76x02_dev *dev, u8 <token> <answer> idx, 
struct ieee80211_key_conf <token> <answer> *key) 
<token> mt76x02_cipher_type cipher; <answer> enum 
u8 <token> <answer> key_data[32]; 
<token> iv, eiv; <answer> u32 
u64 <token> <answer> pn; 
<token> = mt76x02_mac_get_key_info(key, key_data); <answer> cipher 
<token> = mt76_rr(dev, MT_WCID_IV(idx)); <answer> iv 
<token> = mt76_rr(dev, MT_WCID_IV(idx) + 4); <answer> eiv 
pn = <token> << 16; <answer> (u64)eiv 
if (cipher <token> MT76X02_CIPHER_TKIP) { <answer> == 
pn <token> (iv >> 16) & 0xff; <answer> |= 
pn |= (iv & 0xff) << <token> <answer> 8; 
} else <token> (cipher >= MT76X02_CIPHER_AES_CCMP) { <answer> if 
pn <token> iv & 0xffff; <answer> |= 
} <token> { <answer> else 
atomic64_set(&key->tx_pn, <token> <answer> pn); 
int mt76x02_mac_wcid_set_key(struct mt76x02_dev *dev, <token> idx, <answer> u8 
struct <token> *key) <answer> ieee80211_key_conf 
enum mt76x02_cipher_type <token> <answer> cipher; 
<token> key_data[32]; <answer> u8 
<token> iv_data[8]; <answer> u8 
u64 <token> <answer> pn; 
<token> = mt76x02_mac_get_key_info(key, key_data); <answer> cipher 
<token> (cipher == MT76X02_CIPHER_NONE && key) <answer> if 
return <token> <answer> -EOPNOTSUPP; 
mt76_wr_copy(dev, MT_WCID_KEY(idx), key_data, <token> <answer> sizeof(key_data)); 
<token> MT_WCID_ATTR(idx), MT_WCID_ATTR_PKEY_MODE, cipher); <answer> mt76_rmw_field(dev, 
memset(iv_data, <token> sizeof(iv_data)); <answer> 0, 
<token> (key) { <answer> if 
mt76_rmw_field(dev, MT_WCID_ATTR(idx), <token> <answer> MT_WCID_ATTR_PAIRWISE, 
!!(key->flags <token> IEEE80211_KEY_FLAG_PAIRWISE)); <answer> & 
<token> = atomic64_read(&key->tx_pn); <answer> pn 
<token> = key->keyidx << 6; <answer> iv_data[3] 
if <token> >= MT76X02_CIPHER_TKIP) { <answer> (cipher 
iv_data[3] <token> 0x20; <answer> |= 
put_unaligned_le32(pn >> <token> &iv_data[4]); <answer> 16, 
<token> (cipher == MT76X02_CIPHER_TKIP) { <answer> if 
iv_data[0] = (pn >> 8) <token> 0xff; <answer> & 
iv_data[1] = (iv_data[0] | 0x20) & <token> <answer> 0x7f; 
iv_data[2] = pn <token> 0xff; <answer> & 
} else if (cipher <token> MT76X02_CIPHER_AES_CCMP) { <answer> >= 
put_unaligned_le16((pn <token> 0xffff), &iv_data[0]); <answer> & 
<token> MT_WCID_IV(idx), iv_data, sizeof(iv_data)); <answer> mt76_wr_copy(dev, 
return <token> <answer> 0; 
void mt76x02_mac_wcid_setup(struct mt76x02_dev <token> u8 idx, <answer> *dev, 
u8 vif_idx, <token> *mac) <answer> u8 
<token> mt76_wcid_addr addr = {}; <answer> struct 
<token> attr; <answer> u32 
attr <token> FIELD_PREP(MT_WCID_ATTR_BSS_IDX, vif_idx & 7) | <answer> = 
<token> !!(vif_idx & 8)); <answer> FIELD_PREP(MT_WCID_ATTR_BSS_IDX_EXT, 
mt76_wr(dev, <token> attr); <answer> MT_WCID_ATTR(idx), 
if <token> >= 128) <answer> (idx 
if <token> <answer> (mac) 
<token> mac, ETH_ALEN); <answer> memcpy(addr.macaddr, 
mt76_wr_copy(dev, MT_WCID_ADDR(idx), &addr, <token> <answer> sizeof(addr)); 
void mt76x02_mac_wcid_set_drop(struct mt76x02_dev <token> u8 idx, bool drop) <answer> *dev, 
u32 val <token> mt76_rr(dev, MT_WCID_DROP(idx)); <answer> = 
u32 <token> = MT_WCID_DROP_MASK(idx); <answer> bit 
if <token> & MT_RXINFO_FRAG) { <answer> (rxinfo 
status->flag &= <token> <answer> ~RX_FLAG_IV_STRIPPED; 
} <token> { <answer> else 
<token> += pn_len << 2; <answer> pad_len 
<token> -= pn_len << 2; <answer> len 
<token> pad_len); <answer> mt76x02_remove_hdr_pad(skb, 
if ((rxinfo & MT_RXINFO_BA) && !(rxinfo & <token> <answer> MT_RXINFO_NULL)) 
status->aggr <token> true; <answer> = 
<token> (rxinfo & MT_RXINFO_AMPDU) { <answer> if 
status->flag <token> RX_FLAG_AMPDU_DETAILS; <answer> |= 
status->ampdu_ref <token> dev->ampdu_ref; <answer> = 
<token> (rxinfo & MT_RXINFO_RSSI) { <answer> if 
<token> (!++dev->ampdu_ref) <answer> if 
if (WARN_ON_ONCE(len > <token> <answer> skb->len)) 
return <token> <answer> -EINVAL; 
if <token> len)) <answer> (pskb_trim(skb, 
return <token> <answer> -EINVAL; 
status->chains <token> BIT(0); <answer> = 
signal <token> mt76x02_mac_get_rssi(dev, rxwi->rssi[0], 0); <answer> = 
status->chain_signal[0] = <token> <answer> signal; 
if (nstreams > <token> { <answer> 1) 
status->chains |= <token> <answer> BIT(1); 
<token> = mt76x02_mac_get_rssi(dev, <answer> status->chain_signal[1] 
status->freq <token> dev->mphy.chandef.chan->center_freq; <answer> = 
status->band <token> dev->mphy.chandef.chan->band; <answer> = 
hdr = (struct <token> *)skb->data; <answer> ieee80211_hdr 
status->qos_ctl = <token> <answer> *ieee80211_get_qos_ctl(hdr); 
status->seqno <token> FIELD_GET(MT_RXWI_SN, tid_sn); <answer> = 
return <token> status, rate); <answer> mt76x02_mac_process_rate(dev, 
void mt76x02_mac_poll_tx_status(struct mt76x02_dev <token> bool irq) <answer> *dev, 
<token> mt76x02_tx_status stat = {}; <answer> struct 
u8 update <token> 1; <answer> = 
bool <token> <answer> ret; 
if <token> &dev->mphy.state)) <answer> (!test_bit(MT76_STATE_RUNNING, 
while (!irq || <token> { <answer> !kfifo_is_full(&dev->txstatus_fifo)) 
<token> (!spin_trylock(&dev->txstatus_fifo_lock)) <answer> if 
ret = mt76x02_mac_load_tx_status(dev, <token> <answer> &stat); 
if <token> <answer> (!ret) 
if <token> { <answer> (!irq) 
mt76x02_send_tx_status(dev, <token> &update); <answer> &stat, 
kfifo_put(&dev->txstatus_fifo, <token> <answer> stat); 
void <token> mt76_dev *mdev, struct mt76_queue_entry *e) <answer> mt76x02_tx_complete_skb(struct 
struct mt76x02_dev *dev = container_of(mdev, struct <token> mt76); <answer> mt76x02_dev, 
<token> mt76x02_txwi *txwi; <answer> struct 
<token> *txwi_ptr; <answer> u8 
if (!e->txwi) <token> <answer> { 
mt76x02_mac_poll_tx_status(dev, <token> <answer> false); 
<token> = mt76_get_txwi_ptr(mdev, e->txwi); <answer> txwi_ptr 
<token> = (struct mt76x02_txwi *)txwi_ptr; <answer> txwi 
<token> txwi->wcid, txwi->pktid); <answer> trace_mac_txdone(mdev, 
mt76_tx_complete_skb(mdev, e->wcid, <token> <answer> e->skb); 
void mt76x02_mac_set_rts_thresh(struct mt76x02_dev *dev, u32 <token> <answer> val) 
u32 <token> = 0; <answer> data 
if (val != <token> <answer> ~0) 
data = FIELD_PREP(MT_PROT_CFG_CTRL, <token> | <answer> 1) 
mt76_rmw_field(dev, MT_TX_RTS_CFG, MT_TX_RTS_CFG_THRESH, <token> <answer> val); 
<token> MT_CCK_PROT_CFG, <answer> mt76_rmw(dev, 
MT_PROT_CFG_CTRL | MT_PROT_CFG_RTS_THRESH, <token> <answer> data); 
mt76_rmw(dev, <token> <answer> MT_OFDM_PROT_CFG, 
<token> | MT_PROT_CFG_RTS_THRESH, data); <answer> MT_PROT_CFG_CTRL 
void mt76x02_mac_set_tx_protection(struct <token> *dev, bool legacy_prot, <answer> mt76x02_dev 
int <token> <answer> ht_mode) 
int mode = ht_mode <token> IEEE80211_HT_OP_MODE_PROTECTION; <answer> & 
bool <token> = !!(ht_mode & IEEE80211_HT_OP_MODE_NON_GF_STA_PRSNT); <answer> non_gf 
u32 <token> <answer> prot[6]; 
u32 <token> <answer> vht_prot[3]; 
<token> i; <answer> int 
u16 <token> <answer> rts_thr; 
for (i = 0; i <token> ARRAY_SIZE(prot); i++) { <answer> < 
prot[i] = mt76_rr(dev, MT_CCK_PROT_CFG + i * <token> <answer> 4); 
prot[i] &= <token> <answer> ~MT_PROT_CFG_CTRL; 
if <token> >= 2) <answer> (i 
prot[i] &= <token> <answer> ~MT_PROT_CFG_RATE; 
for (i = 0; i < ARRAY_SIZE(vht_prot); <token> { <answer> i++) 
vht_prot[i] <token> mt76_rr(dev, MT_TX_PROT_CFG6 + i * 4); <answer> = 
<token> &= ~(MT_PROT_CFG_CTRL | MT_PROT_CFG_RATE); <answer> vht_prot[i] 
rts_thr <token> mt76_get_field(dev, MT_TX_RTS_CFG, MT_TX_RTS_CFG_THRESH); <answer> = 
if (rts_thr <token> 0xffff) <answer> != 
<token> |= MT_PROT_CTRL_RTS_CTS; <answer> prot[0] 
if (legacy_prot) <token> <answer> { 
<token> |= MT_PROT_CTRL_CTS2SELF; <answer> prot[1] 
prot[2] |= <token> <answer> MT_PROT_RATE_CCK_11; 
prot[3] |= <token> <answer> MT_PROT_RATE_CCK_11; 
prot[4] |= <token> <answer> MT_PROT_RATE_CCK_11; 
<token> |= MT_PROT_RATE_CCK_11; <answer> prot[5] 
<token> |= MT_PROT_RATE_CCK_11; <answer> vht_prot[0] 
vht_prot[1] <token> MT_PROT_RATE_CCK_11; <answer> |= 
vht_prot[2] <token> MT_PROT_RATE_CCK_11; <answer> |= 
} else <token> <answer> { 
if <token> != 0xffff) <answer> (rts_thr 
prot[1] |= <token> <answer> MT_PROT_CTRL_RTS_CTS; 
prot[2] <token> MT_PROT_RATE_OFDM_24; <answer> |= 
prot[3] |= <token> <answer> MT_PROT_RATE_DUP_OFDM_24; 
prot[4] <token> MT_PROT_RATE_OFDM_24; <answer> |= 
prot[5] <token> MT_PROT_RATE_DUP_OFDM_24; <answer> |= 
vht_prot[0] <token> MT_PROT_RATE_OFDM_24; <answer> |= 
vht_prot[1] |= <token> <answer> MT_PROT_RATE_DUP_OFDM_24; 
<token> |= MT_PROT_RATE_SGI_OFDM_24; <answer> vht_prot[2] 
switch (mode) <token> <answer> { 
case <token> <answer> IEEE80211_HT_OP_MODE_PROTECTION_NONMEMBER: 
<token> IEEE80211_HT_OP_MODE_PROTECTION_NONHT_MIXED: <answer> case 
prot[2] <token> MT_PROT_CTRL_RTS_CTS; <answer> |= 
prot[3] <token> MT_PROT_CTRL_RTS_CTS; <answer> |= 
prot[4] <token> MT_PROT_CTRL_RTS_CTS; <answer> |= 
<token> |= MT_PROT_CTRL_RTS_CTS; <answer> prot[5] 
vht_prot[0] |= <token> <answer> MT_PROT_CTRL_RTS_CTS; 
vht_prot[1] <token> MT_PROT_CTRL_RTS_CTS; <answer> |= 
vht_prot[2] |= <token> <answer> MT_PROT_CTRL_RTS_CTS; 
case <token> <answer> IEEE80211_HT_OP_MODE_PROTECTION_20MHZ: 
prot[3] <token> MT_PROT_CTRL_RTS_CTS; <answer> |= 
prot[5] <token> MT_PROT_CTRL_RTS_CTS; <answer> |= 
vht_prot[1] |= <token> <answer> MT_PROT_CTRL_RTS_CTS; 
<token> |= MT_PROT_CTRL_RTS_CTS; <answer> vht_prot[2] 
if (non_gf) <token> <answer> { 
prot[4] <token> MT_PROT_CTRL_RTS_CTS; <answer> |= 
prot[5] <token> MT_PROT_CTRL_RTS_CTS; <answer> |= 
for (i = <token> i < ARRAY_SIZE(prot); i++) <answer> 0; 
<token> MT_CCK_PROT_CFG + i * 4, prot[i]); <answer> mt76_wr(dev, 
for (i = 0; <token> < ARRAY_SIZE(vht_prot); i++) <answer> i 
mt76_wr(dev, MT_TX_PROT_CFG6 + i <token> 4, vht_prot[i]); <answer> * 
<token> mt76x02_update_channel(struct mt76_phy *mphy) <answer> void 
struct mt76x02_dev *dev = <token> struct mt76x02_dev, mt76); <answer> container_of(mphy->dev, 
struct <token> *state; <answer> mt76_channel_state 
state = <token> <answer> mphy->chan_state; 
state->cc_busy += mt76_rr(dev, <token> <answer> MT_CH_BUSY); 
state->cc_tx += <token> <answer> dev->tx_airtime; 
dev->tx_airtime <token> 0; <answer> = 
static void <token> mt76x02_dev *dev) <answer> mt76x02_check_mac_err(struct 
if <token> { <answer> (dev->mt76.beacon_mask) 
if (mt76_rr(dev, MT_TX_STA_0) & <token> { <answer> MT_TX_STA_0_BEACONS) 
<token> = 0; <answer> dev->beacon_hang_check 
if (dev->beacon_hang_check < <token> <answer> 10) 
} <token> { <answer> else 
u32 val <token> mt76_rr(dev, 0x10f4); <answer> = 
if (!(val & <token> || !(val & (BIT(7) | BIT(5)))) <answer> BIT(29)) 
dev_err(dev->mt76.dev, <token> error detected\n"); <answer> "MAC 
<token> MT_MAC_SYS_CTRL, 0); <answer> mt76_wr(dev, 
if <token> { <answer> (!mt76x02_wait_for_txrx_idle(&dev->mt76)) 
dev_err(dev->mt76.dev, "MAC <token> failed\n"); <answer> stop 
goto <token> <answer> out; 
<token> = 0; <answer> dev->beacon_hang_check 
mt76_set(dev, MT_MAC_SYS_CTRL, <token> <answer> MT_MAC_SYS_CTRL_RESET_CSR); 
mt76_wr(dev, <token> <answer> MT_MAC_SYS_CTRL, 
MT_MAC_SYS_CTRL_ENABLE_TX | <token> <answer> MT_MAC_SYS_CTRL_ENABLE_RX); 
static <token> <answer> void 
mt76x02_edcca_tx_enable(struct mt76x02_dev *dev, <token> enable) <answer> bool 
<token> (enable) { <answer> if 
<token> data; <answer> u32 
mt76_set(dev, <token> MT_MAC_SYS_CTRL_ENABLE_TX); <answer> MT_MAC_SYS_CTRL, 
mt76_set(dev, <token> MT_AUTO_RSP_EN); <answer> MT_AUTO_RSP_CFG, 
#include <token> <answer> <linux/device.h> 
#include <token> <answer> <linux/efi.h> 
<token> <linux/tpm_eventlog.h> <answer> #include 
<token> "../tpm.h" <answer> #include 
#include <token> <answer> "common.h" 
<token> -= log_tbl->final_events_preboot_size; <answer> final_events_log_size 
tmp = devm_krealloc(&chip->dev, <token> <answer> log->bios_event_log, 
log_size <token> final_events_log_size, <answer> + 
if <token> { <answer> (!tmp) 
devm_kfree(&chip->dev, <token> <answer> log->bios_event_log); 
ret = <token> <answer> -ENOMEM; 
<token> out; <answer> goto 
log->bios_event_log <token> tmp; <answer> = 
<token> *)log->bios_event_log + log_size, <answer> memcpy((void 
final_tbl->events + <token> <answer> log_tbl->final_events_preboot_size, 
log->bios_event_log_end = <token> + <answer> log->bios_event_log 
log_size + <token> <answer> final_events_log_size; 
return <token> <answer> ret; 
#include <token> <answer> <linux/device.h> 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/i2c.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/sysfs.h> 
#include <token> <answer> <linux/regulator/consumer.h> 
#include <token> <answer> <linux/iio/iio.h> 
<token> <linux/iio/sysfs.h> <answer> #include 
<token> <linux/iio/buffer.h> <answer> #include 
<token> <linux/iio/trigger.h> <answer> #include 
#include <token> <answer> <linux/iio/triggered_buffer.h> 
<token> <linux/iio/trigger_consumer.h> <answer> #include 
<token> "afe440x.h" <answer> #include 
<token> AFE4404_DRIVER_NAME "afe4404" <answer> #define 
struct <token> { <answer> afe4404_data 
struct device <token> <answer> *dev; 
struct regmap <token> <answer> *regmap; 
<token> regmap_field *fields[F_MAX_FIELDS]; <answer> struct 
struct regulator <token> <answer> *regulator; 
<token> iio_trigger *trig; <answer> struct 
<token> irq; <answer> int 
<token> buffer[10] __aligned(8); <answer> s32 
<token> afe4404_chan_id { <answer> enum 
LED2 <token> 1, <answer> = 
static const unsigned <token> afe4404_channel_values[] = { <answer> int 
[LED2] <token> AFE440X_LED2VAL, <answer> = 
<token> = AFE440X_ALED2VAL, <answer> [ALED2] 
<token> = AFE440X_LED1VAL, <answer> [LED1] 
<token> = AFE440X_ALED1VAL, <answer> [ALED1] 
[LED2_ALED2] = <token> <answer> AFE440X_LED2_ALED2VAL, 
<token> = AFE440X_LED1_ALED1VAL, <answer> [LED1_ALED1] 
static const unsigned int afe4404_channel_leds[] <token> { <answer> = 
<token> = F_ILED2, <answer> [LED2] 
<token> = F_ILED3, <answer> [ALED2] 
[LED1] <token> F_ILED1, <answer> = 
static const <token> int afe4404_channel_offdacs[] = { <answer> unsigned 
[LED2] = <token> <answer> F_OFFDAC_LED2, 
[ALED2] <token> F_OFFDAC_AMB2, <answer> = 
[LED1] <token> F_OFFDAC_LED1, <answer> = 
[ALED1] = <token> <answer> F_OFFDAC_AMB1, 
static const struct iio_chan_spec afe4404_channels[] = <token> <answer> { 
<token> <linux/module.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/dma-mapping.h> 
#include <token> <answer> "vt.h" 
#include <token> <answer> "cq.h" 
<token> "trace.h" <answer> #include 
<token> RVT_UVERBS_ABI_VERSION 2 <answer> #define 
MODULE_LICENSE("Dual <token> <answer> BSD/GPL"); 
MODULE_DESCRIPTION("RDMA Verbs <token> Library"); <answer> Transport 
<token> int __init rvt_init(void) <answer> static 
int <token> = rvt_driver_cq_init(); <answer> ret 
if <token> <answer> (ret) 
pr_err("Error in <token> CQ init.\n"); <answer> driver 
<token> ret; <answer> return 
static <token> __exit rvt_cleanup(void) <answer> void 
struct rvt_dev_info *rvt_alloc_device(size_t <token> int nports) <answer> size, 
<token> rvt_dev_info *rdi; <answer> struct 
rdi = container_of(_ib_alloc_device(size), <token> rvt_dev_info, ibdev); <answer> struct 
<token> (!rdi) <answer> if 
<token> rdi; <answer> return 
rdi->ports = <token> sizeof(*rdi->ports), GFP_KERNEL); <answer> kcalloc(nports, 
if <token> <answer> (!rdi->ports) 
return <token> <answer> rdi; 
void rvt_dealloc_device(struct rvt_dev_info <token> <answer> *rdi) 
static int <token> ib_device *ibdev, <answer> rvt_query_device(struct 
struct <token> *props, <answer> ib_device_attr 
struct ib_udata <token> <answer> *uhw) 
<token> rvt_dev_info *rdi = ib_to_rvt(ibdev); <answer> struct 
if (uhw->inlen || <token> <answer> uhw->outlen) 
return <token> <answer> -EINVAL; 
*props = <token> <answer> rdi->dparms.props; 
return <token> <answer> 0; 
static int rvt_get_numa_node(struct <token> *ibdev) <answer> ib_device 
struct rvt_dev_info *rdi <token> ib_to_rvt(ibdev); <answer> = 
<token> rdi->dparms.node; <answer> return 
static int <token> ib_device *device, <answer> rvt_modify_device(struct 
<token> device_modify_mask, <answer> int 
<token> ib_device_modify *device_modify) <answer> struct 
return <token> <answer> -EOPNOTSUPP; 
static <token> rvt_query_port(struct ib_device *ibdev, u32 port_num, <answer> int 
struct ib_port_attr <token> <answer> *props) 
struct <token> *rdi = ib_to_rvt(ibdev); <answer> rvt_dev_info 
struct <token> *rvp; <answer> rvt_ibport 
u32 port_index <token> ibport_num_to_idx(ibdev, port_num); <answer> = 
rvp <token> rdi->ports[port_index]; <answer> = 
static int <token> ib_device *ibdev, u32 port_num, <answer> rvt_modify_port(struct 
int port_modify_mask, <token> ib_port_modify *props) <answer> struct 
struct rvt_dev_info <token> = ib_to_rvt(ibdev); <answer> *rdi 
<token> rvt_ibport *rvp; <answer> struct 
<token> ret = 0; <answer> int 
u32 <token> = ibport_num_to_idx(ibdev, port_num); <answer> port_index 
rvp <token> rdi->ports[port_index]; <answer> = 
if (port_modify_mask & IB_PORT_OPA_MASK_CHG) <token> <answer> { 
rvp->port_cap3_flags |= <token> <answer> props->set_port_cap_mask; 
<token> &= ~props->clr_port_cap_mask; <answer> rvp->port_cap3_flags 
<token> else { <answer> } 
rvp->port_cap_flags |= <token> <answer> props->set_port_cap_mask; 
rvp->port_cap_flags &= <token> <answer> ~props->clr_port_cap_mask; 
if <token> || props->clr_port_cap_mask) <answer> (props->set_port_cap_mask 
<token> port_num); <answer> rdi->driver_f.cap_mask_chg(rdi, 
if <token> & IB_PORT_SHUTDOWN) <answer> (port_modify_mask 
ret = rdi->driver_f.shut_down_port(rdi, <token> <answer> port_num); 
if <token> & IB_PORT_RESET_QKEY_CNTR) <answer> (port_modify_mask 
rvp->qkey_violations <token> 0; <answer> = 
return <token> <answer> ret; 
static int <token> ib_device *ibdev, u32 port_num, u16 index, <answer> rvt_query_pkey(struct 
<token> *pkey) <answer> u16 
struct rvt_dev_info *rdi <token> ib_to_rvt(ibdev); <answer> = 
u32 <token> <answer> port_index; 
<token> = ibport_num_to_idx(ibdev, port_num); <answer> port_index 
if <token> >= rvt_get_npkeys(rdi)) <answer> (index 
return <token> <answer> -EINVAL; 
*pkey = rvt_get_pkey(rdi, port_index, <token> <answer> index); 
<token> 0; <answer> return 
static int rvt_query_gid(struct ib_device <token> u32 port_num, <answer> *ibdev, 
int guid_index, union ib_gid <token> <answer> *gid) 
struct <token> *rdi; <answer> rvt_dev_info 
struct <token> *rvp; <answer> rvt_ibport 
u32 <token> <answer> port_index; 
port_index = <token> port_num); <answer> ibport_num_to_idx(ibdev, 
rdi <token> ib_to_rvt(ibdev); <answer> = 
rvp <token> rdi->ports[port_index]; <answer> = 
gid->global.subnet_prefix <token> rvp->gid_prefix; <answer> = 
return rdi->driver_f.get_guid_be(rdi, <token> guid_index, <answer> rvp, 
static <token> rvt_alloc_ucontext(struct ib_ucontext *uctx, struct ib_udata *udata) <answer> int 
<token> 0; <answer> return 
<token> void rvt_dealloc_ucontext(struct ib_ucontext *context) <answer> static 
static int <token> ib_device *ibdev, u32 port_num, <answer> rvt_get_port_immutable(struct 
struct ib_port_immutable <token> <answer> *immutable) 
struct <token> *rdi = ib_to_rvt(ibdev); <answer> rvt_dev_info 
<token> ib_port_attr attr; <answer> struct 
<token> err; <answer> int 
immutable->core_cap_flags = <token> <answer> rdi->dparms.core_cap_flags; 
err = ib_query_port(ibdev, port_num, <token> <answer> &attr); 
if <token> <answer> (err) 
<token> err; <answer> return 
immutable->pkey_tbl_len <token> attr.pkey_tbl_len; <answer> = 
immutable->gid_tbl_len <token> attr.gid_tbl_len; <answer> = 
immutable->max_mad_size = <token> <answer> rdi->dparms.max_mad_size; 
return <token> <answer> 0; 
enum <token> <answer> { 
if <token> || <answer> ((!rdi->ibdev.ops.port_groups) 
<token> -EINVAL; <answer> return 
case <token> <answer> MODIFY_DEVICE: 
<token> (!rdi->ibdev.ops.modify_device) <answer> if 
<token> -EOPNOTSUPP; <answer> return 
<token> QUERY_PORT: <answer> case 
if <token> <answer> (!rdi->ibdev.ops.query_port) 
<token> (!rdi->driver_f.query_port_state) <answer> if 
return <token> <answer> -EINVAL; 
<token> MODIFY_PORT: <answer> case 
if <token> <answer> (!rdi->ibdev.ops.modify_port) 
if <token> || <answer> (!rdi->driver_f.cap_mask_chg 
return <token> <answer> -EINVAL; 
<token> QUERY_GID: <answer> case 
<token> (!rdi->ibdev.ops.query_gid) <answer> if 
if <token> <answer> (!rdi->driver_f.get_guid_be) 
<token> -EINVAL; <answer> return 
case <token> <answer> CREATE_QP: 
if <token> <answer> (!rdi->ibdev.ops.create_qp) 
if (!rdi->driver_f.qp_priv_alloc <token> <answer> || 
<token> || <answer> !rdi->driver_f.qp_priv_free 
<token> || <answer> !rdi->driver_f.notify_qp_reset 
<token> || <answer> !rdi->driver_f.flush_qp_waiters 
<token> || <answer> !rdi->driver_f.stop_send_queue 
return <token> <answer> -EINVAL; 
<token> MODIFY_QP: <answer> case 
<token> (!rdi->ibdev.ops.modify_qp) <answer> if 
if <token> || <answer> (!rdi->driver_f.notify_qp_reset 
!rdi->driver_f.schedule_send <token> <answer> || 
<token> || <answer> !rdi->driver_f.get_pmtu_from_attr 
<token> || <answer> !rdi->driver_f.flush_qp_waiters 
!rdi->driver_f.stop_send_queue <token> <answer> || 
<token> || <answer> !rdi->driver_f.quiesce_qp 
<token> || <answer> !rdi->driver_f.notify_error_qp 
<token> || <answer> !rdi->driver_f.mtu_from_qp 
return <token> <answer> -EINVAL; 
case <token> <answer> DESTROY_QP: 
if <token> <answer> (!rdi->ibdev.ops.destroy_qp) 
if <token> || <answer> (!rdi->driver_f.qp_priv_free 
<token> || <answer> !rdi->driver_f.notify_qp_reset 
<token> || <answer> !rdi->driver_f.flush_qp_waiters 
<token> || <answer> !rdi->driver_f.stop_send_queue 
<token> -EINVAL; <answer> return 
case <token> <answer> POST_SEND: 
<token> (!rdi->ibdev.ops.post_send) <answer> if 
<token> (!rdi->driver_f.schedule_send || <answer> if 
!rdi->driver_f.do_send <token> <answer> || 
<token> -EINVAL; <answer> return 
return <token> <answer> 0; 
int <token> rvt_dev_info *rdi) <answer> rvt_register_device(struct 
int ret = <token> i; <answer> 0, 
<token> (!rdi) <answer> if 
<token> -EINVAL; <answer> return 
for (i <token> 0; i < _VERB_IDX_MAX; i++) <answer> = 
if <token> i)) { <answer> (check_support(rdi, 
<token> support req not met at %d\n", i); <answer> pr_err("Driver 
return <token> <answer> -EINVAL; 
<token> &rvt_dev_ops); <answer> ib_set_device_ops(&rdi->ibdev, 
rdi->ibdev.uverbs_cmd_mask <token> <answer> |= 
<token> << IB_USER_VERBS_CMD_POLL_CQ) | <answer> (1ull 
(1ull <token> IB_USER_VERBS_CMD_REQ_NOTIFY_CQ) | <answer> << 
(1ull << <token> | <answer> IB_USER_VERBS_CMD_POST_SEND) 
(1ull << <token> | <answer> IB_USER_VERBS_CMD_POST_RECV) 
(1ull <token> IB_USER_VERBS_CMD_POST_SRQ_RECV); <answer> << 
rdi->ibdev.node_type = <token> <answer> RDMA_NODE_IB_CA; 
if <token> <answer> (!rdi->ibdev.num_comp_vectors) 
rdi->ibdev.num_comp_vectors <token> 1; <answer> = 
<token> rvt_unregister_device(struct rvt_dev_info *rdi) <answer> void 
trace_rvt_dbg(rdi, <token> is unregistering."); <answer> "Driver 
if <token> <answer> (!rdi) 
int <token> rvt_dev_info *rdi, struct rvt_ibport *port, <answer> rvt_init_port(struct 
int <token> u16 *pkey_table) <answer> port_index, 
rdi->ports[port_index] <token> port; <answer> = 
<token> = pkey_table; <answer> rdi->ports[port_index]->pkey_table 
return <token> <answer> 0; 
#include <token> <answer> "priv.h" 
#include <token> <answer> <subdev/gsp.h> 
#include <token> <answer> <nvif/class.h> 
<token> const struct nvkm_engine_func <answer> static 
tu102_nvenc <token> { <answer> = 
.sclass = <token> <answer> { 
<token> -1, -1, NVC4B7_VIDEO_ENCODER }, <answer> { 
tu102_nvenc_new(struct nvkm_device *device, enum <token> type, int inst, <answer> nvkm_subdev_type 
struct nvkm_nvenc <token> <answer> **pnvenc) 
<token> (nvkm_gsp_rm(device->gsp)) <answer> if 
<token> r535_nvenc_new(&tu102_nvenc, device, type, inst, pnvenc); <answer> return 
return nvkm_nvenc_new_(gm107_nvenc_fwif, device, <token> inst, pnvenc); <answer> type, 
#include <token> <answer> <linux/clk-provider.h> 
#include <token> <answer> <linux/mod_devicetable.h> 
#include <token> <answer> <linux/platform_device.h> 
<token> "clk-mtk.h" <answer> #include 
<token> "clk-gate.h" <answer> #include 
#include <token> <answer> <dt-bindings/clock/mt8167-clk.h> 
static const struct mtk_gate_regs <token> = { <answer> aud_cg_regs 
<token> = 0x0, <answer> .set_ofs 
.clr_ofs = <token> <answer> 0x0, 
.sta_ofs = <token> <answer> 0x0, 
<token> GATE_AUD(_id, _name, _parent, _shift) \ <answer> #define 
GATE_MTK(_id, <token> _parent, &aud_cg_regs, _shift, &mtk_clk_gate_ops_no_setclr) <answer> _name, 
static const struct mtk_gate <token> = { <answer> aud_clks[] 
<token> "aud_afe", "clk26m_ck", 2), <answer> GATE_AUD(CLK_AUD_AFE, 
GATE_AUD(CLK_AUD_I2S, <token> "i2s_infra_bck", 6), <answer> "aud_i2s", 
GATE_AUD(CLK_AUD_22M, "aud_22m", <token> 8), <answer> "rg_aud_engen1", 
GATE_AUD(CLK_AUD_24M, "aud_24m", "rg_aud_engen2", <token> <answer> 9), 
GATE_AUD(CLK_AUD_INTDIR, "aud_intdir", "rg_aud_spdif_in", <token> <answer> 15), 
GATE_AUD(CLK_AUD_APLL2_TUNER, <token> "rg_aud_engen2", 18), <answer> "aud_apll2_tuner", 
<token> "aud_apll_tuner", "rg_aud_engen1", 19), <answer> GATE_AUD(CLK_AUD_APLL_TUNER, 
GATE_AUD(CLK_AUD_HDMI, "aud_hdmi", "apll12_div4", <token> <answer> 20), 
<token> "aud_spdf", "apll12_div6", 21), <answer> GATE_AUD(CLK_AUD_SPDF, 
GATE_AUD(CLK_AUD_ADC, <token> "aud_afe", 24), <answer> "aud_adc", 
GATE_AUD(CLK_AUD_DAC, "aud_dac", <token> 25), <answer> "aud_afe", 
GATE_AUD(CLK_AUD_DAC_PREDIS, <token> "aud_afe", 26), <answer> "aud_dac_predis", 
GATE_AUD(CLK_AUD_TML, <token> "aud_afe", 27), <answer> "aud_tml", 
static const struct <token> aud_desc = { <answer> mtk_clk_desc 
.clks <token> aud_clks, <answer> = 
.num_clks <token> ARRAY_SIZE(aud_clks), <answer> = 
<token> const struct of_device_id of_match_clk_mt8167_audsys[] = { <answer> static 
{ .compatible <token> "mediatek,mt8167-audsys", .data = &aud_desc }, <answer> = 
<token> <linux/bitfield.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/irqdomain.h> <answer> #include 
<token> "chip.h" <answer> #include 
err = <token> 0xffff); <answer> mv88e6xxx_g2_mgmt_enable_0x(chip, 
if <token> <answer> (err) 
return <token> <answer> err; 
return mv88e6xxx_g2_switch_mgmt_rsvd2cpu(chip, <token> <answer> true); 
int mv88e6352_g2_mgmt_rsvd2cpu(struct mv88e6xxx_chip <token> <answer> *chip) 
<token> err; <answer> int 
<token> = mv88e6xxx_g2_mgmt_enable_2x(chip, 0xffff); <answer> err 
<token> (err) <answer> if 
<token> err; <answer> return 
return <token> <answer> mv88e6185_g2_mgmt_rsvd2cpu(chip); 
return mv88e6xxx_g2_write(chip, <token> <answer> MV88E6XXX_G2_DEVICE_MAPPING, 
MV88E6XXX_G2_DEVICE_MAPPING_UPDATE <token> val); <answer> | 
static <token> mv88e6xxx_g2_irl_wait(struct mv88e6xxx_chip *chip) <answer> int 
int bit <token> __bf_shf(MV88E6XXX_G2_IRL_CMD_BUSY); <answer> = 
return mv88e6xxx_g2_wait_bit(chip, MV88E6XXX_G2_IRL_CMD, <token> 0); <answer> bit, 
<token> int mv88e6xxx_g2_irl_op(struct mv88e6xxx_chip *chip, u16 op, int port, <answer> static 
int <token> int reg) <answer> res, 
<token> err; <answer> int 
<token> = mv88e6xxx_g2_write(chip, MV88E6XXX_G2_IRL_CMD, <answer> err 
MV88E6XXX_G2_IRL_CMD_BUSY <token> op | (port << 8) | <answer> | 
<token> << 5) | reg); <answer> (res 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> mv88e6xxx_g2_irl_wait(chip); <answer> return 
int mv88e6352_g2_irl_init_all(struct mv88e6xxx_chip *chip, int <token> <answer> port) 
return mv88e6xxx_g2_irl_op(chip, MV88E6352_G2_IRL_CMD_OP_INIT_ALL, <token> <answer> port, 
<token> 0); <answer> 0, 
<token> mv88e6390_g2_irl_init_all(struct mv88e6xxx_chip *chip, int port) <answer> int 
return mv88e6xxx_g2_irl_op(chip, <token> port, <answer> MV88E6390_G2_IRL_CMD_OP_INIT_ALL, 
0, <token> <answer> 0); 
static <token> mv88e6xxx_g2_pvt_op_wait(struct mv88e6xxx_chip *chip) <answer> int 
int <token> = __bf_shf(MV88E6XXX_G2_PVT_ADDR_BUSY); <answer> bit 
return mv88e6xxx_g2_wait_bit(chip, <token> bit, 0); <answer> MV88E6XXX_G2_PVT_ADDR, 
static int mv88e6xxx_g2_pvt_op(struct mv88e6xxx_chip *chip, <token> src_dev, <answer> int 
int <token> u16 op) <answer> src_port, 
<token> err; <answer> int 
op <token> MV88E6XXX_G2_PVT_ADDR_BUSY; <answer> |= 
op |= (src_dev & <token> << 4; <answer> 0x1f) 
<token> |= (src_port & 0xf); <answer> op 
err <token> mv88e6xxx_g2_write(chip, MV88E6XXX_G2_PVT_ADDR, op); <answer> = 
<token> (err) <answer> if 
<token> err; <answer> return 
<token> mv88e6xxx_g2_pvt_op_wait(chip); <answer> return 
int <token> mv88e6xxx_chip *chip, int src_dev, <answer> mv88e6xxx_g2_pvt_read(struct 
int src_port, u16 <token> <answer> *data) 
int <token> <answer> err; 
err = <token> <answer> mv88e6xxx_g2_pvt_op_wait(chip); 
<token> (err) <answer> if 
return <token> <answer> err; 
err = mv88e6xxx_g2_pvt_op(chip, <token> src_port, <answer> src_dev, 
<token> (err) <answer> if 
return <token> <answer> err; 
return <token> MV88E6XXX_G2_PVT_DATA, data); <answer> mv88e6xxx_g2_read(chip, 
int mv88e6xxx_g2_pvt_write(struct mv88e6xxx_chip *chip, <token> src_dev, <answer> int 
int src_port, u16 <token> <answer> data) 
int <token> <answer> err; 
err = <token> <answer> mv88e6xxx_g2_pvt_op_wait(chip); 
if <token> <answer> (err) 
<token> err; <answer> return 
err <token> mv88e6xxx_g2_write(chip, MV88E6XXX_G2_PVT_DATA, data); <answer> = 
if <token> <answer> (err) 
return <token> <answer> err; 
<token> mv88e6xxx_g2_pvt_op(chip, src_dev, src_port, <answer> return 
<token> mv88e6xxx_g2_eeprom_wait(struct mv88e6xxx_chip *chip) <answer> int 
int bit = <token> <answer> __bf_shf(MV88E6XXX_G2_EEPROM_CMD_BUSY); 
int <token> <answer> err; 
err = mv88e6xxx_g2_wait_bit(chip, MV88E6XXX_G2_EEPROM_CMD, <token> 0); <answer> bit, 
<token> (err) <answer> if 
return <token> <answer> err; 
bit <token> __bf_shf(MV88E6XXX_G2_EEPROM_CMD_RUNNING); <answer> = 
return mv88e6xxx_g2_wait_bit(chip, <token> bit, 0); <answer> MV88E6XXX_G2_EEPROM_CMD, 
static int <token> mv88e6xxx_chip *chip, u16 cmd) <answer> mv88e6xxx_g2_eeprom_cmd(struct 
int <token> <answer> err; 
err <token> mv88e6xxx_g2_write(chip, MV88E6XXX_G2_EEPROM_CMD, <answer> = 
MV88E6XXX_G2_EEPROM_CMD_BUSY | <token> <answer> cmd); 
if <token> <answer> (err) 
return <token> <answer> err; 
return <token> <answer> mv88e6xxx_g2_eeprom_wait(chip); 
static int mv88e6xxx_g2_eeprom_read8(struct <token> *chip, <answer> mv88e6xxx_chip 
u16 addr, u8 <token> <answer> *data) 
u16 cmd <token> MV88E6XXX_G2_EEPROM_CMD_OP_READ; <answer> = 
<token> err; <answer> int 
err <token> mv88e6xxx_g2_eeprom_wait(chip); <answer> = 
<token> (err) <answer> if 
return <token> <answer> err; 
<token> = mv88e6xxx_g2_write(chip, MV88E6390_G2_EEPROM_ADDR, addr); <answer> err 
<token> (err) <answer> if 
return <token> <answer> err; 
err <token> mv88e6xxx_g2_eeprom_cmd(chip, cmd); <answer> = 
if <token> <answer> (err) 
<token> err; <answer> return 
err = mv88e6xxx_g2_read(chip, MV88E6XXX_G2_EEPROM_CMD, <token> <answer> &cmd); 
<token> (err) <answer> if 
<token> err; <answer> return 
*data <token> cmd & 0xff; <answer> = 
<token> 0; <answer> return 
static int mv88e6xxx_g2_eeprom_write8(struct <token> *chip, <answer> mv88e6xxx_chip 
<token> addr, u8 data) <answer> u16 
u16 cmd <token> MV88E6XXX_G2_EEPROM_CMD_OP_WRITE | <answer> = 
<token> err; <answer> int 
<token> = mv88e6xxx_g2_eeprom_wait(chip); <answer> err 
if <token> <answer> (err) 
<token> err; <answer> return 
<token> = mv88e6xxx_g2_write(chip, MV88E6390_G2_EEPROM_ADDR, addr); <answer> err 
if <token> <answer> (err) 
return <token> <answer> err; 
return mv88e6xxx_g2_eeprom_cmd(chip, cmd | <token> <answer> data); 
static int mv88e6xxx_g2_eeprom_read16(struct <token> *chip, <answer> mv88e6xxx_chip 
u8 <token> u16 *data) <answer> addr, 
u16 cmd = MV88E6XXX_G2_EEPROM_CMD_OP_READ | <token> <answer> addr; 
<token> err; <answer> int 
<token> = mv88e6xxx_g2_eeprom_wait(chip); <answer> err 
<token> (err) <answer> if 
<token> err; <answer> return 
<token> = mv88e6xxx_g2_eeprom_cmd(chip, cmd); <answer> err 
<token> (err) <answer> if 
return <token> <answer> err; 
return <token> MV88E6352_G2_EEPROM_DATA, data); <answer> mv88e6xxx_g2_read(chip, 
static <token> mv88e6xxx_g2_eeprom_write16(struct mv88e6xxx_chip *chip, <answer> int 
u8 addr, <token> data) <answer> u16 
u16 cmd <token> MV88E6XXX_G2_EEPROM_CMD_OP_WRITE | addr; <answer> = 
int <token> <answer> err; 
err = <token> <answer> mv88e6xxx_g2_eeprom_wait(chip); 
<token> (err) <answer> if 
<token> err; <answer> return 
<token> = mv88e6xxx_g2_write(chip, MV88E6352_G2_EEPROM_DATA, data); <answer> err 
if <token> <answer> (err) 
return <token> <answer> err; 
return <token> cmd); <answer> mv88e6xxx_g2_eeprom_cmd(chip, 
int mv88e6xxx_g2_get_eeprom8(struct mv88e6xxx_chip <token> <answer> *chip, 
struct ethtool_eeprom *eeprom, u8 <token> <answer> *data) 
unsigned int <token> = eeprom->offset; <answer> offset 
unsigned int <token> = eeprom->len; <answer> len 
int <token> <answer> err; 
<token> = 0; <answer> eeprom->len 
while (len) <token> <answer> { 
err = mv88e6xxx_g2_eeprom_read8(chip, <token> data); <answer> offset, 
<token> (err) <answer> if 
<token> err; <answer> return 
<token> 0; <answer> return 
int mv88e6xxx_g2_set_eeprom8(struct mv88e6xxx_chip <token> <answer> *chip, 
struct ethtool_eeprom *eeprom, u8 <token> <answer> *data) 
<token> int offset = eeprom->offset; <answer> unsigned 
unsigned <token> len = eeprom->len; <answer> int 
<token> err; <answer> int 
eeprom->len = <token> <answer> 0; 
while (len) <token> <answer> { 
err = mv88e6xxx_g2_eeprom_write8(chip, <token> *data); <answer> offset, 
if <token> <answer> (err) 
<token> err; <answer> return 
return <token> <answer> 0; 
int mv88e6xxx_g2_get_eeprom16(struct <token> *chip, <answer> mv88e6xxx_chip 
struct <token> *eeprom, u8 *data) <answer> ethtool_eeprom 
unsigned int offset <token> eeprom->offset; <answer> = 
unsigned int len <token> eeprom->len; <answer> = 
u16 <token> <answer> val; 
int <token> <answer> err; 
<token> = 0; <answer> eeprom->len 
if (offset <token> 1) { <answer> & 
<token> = mv88e6xxx_g2_eeprom_read16(chip, offset >> 1, &val); <answer> err 
if <token> <answer> (err) 
<token> err; <answer> return 
*data++ = <token> >> 8) & 0xff; <answer> (val 
while (len >= 2) <token> <answer> { 
err <token> mv88e6xxx_g2_eeprom_read16(chip, offset >> 1, &val); <answer> = 
if <token> <answer> (err) 
return <token> <answer> err; 
*data++ = val & <token> <answer> 0xff; 
*data++ = (val >> 8) <token> 0xff; <answer> & 
offset += <token> <answer> 2; 
<token> -= 2; <answer> len 
<token> += 2; <answer> eeprom->len 
if (len) <token> <answer> { 
err = mv88e6xxx_g2_eeprom_read16(chip, offset >> 1, <token> <answer> &val); 
if <token> <answer> (err) 
<token> err; <answer> return 
*data++ = <token> & 0xff; <answer> val 
<token> 0; <answer> return 
int <token> mv88e6xxx_chip *chip, <answer> mv88e6xxx_g2_set_eeprom16(struct 
struct ethtool_eeprom <token> u8 *data) <answer> *eeprom, 
unsigned <token> offset = eeprom->offset; <answer> int 
unsigned <token> len = eeprom->len; <answer> int 
<token> val; <answer> u16 
int <token> <answer> err; 
static int mv88e6xxx_g2_smi_phy_wait(struct mv88e6xxx_chip <token> <answer> *chip) 
int bit = <token> <answer> __bf_shf(MV88E6XXX_G2_SMI_PHY_CMD_BUSY); 
return mv88e6xxx_g2_wait_bit(chip, MV88E6XXX_G2_SMI_PHY_CMD, bit, <token> <answer> 0); 
<token> int mv88e6xxx_g2_smi_phy_cmd(struct mv88e6xxx_chip *chip, u16 cmd) <answer> static 
<token> err; <answer> int 
err = <token> MV88E6XXX_G2_SMI_PHY_CMD, <answer> mv88e6xxx_g2_write(chip, 
<token> | cmd); <answer> MV88E6XXX_G2_SMI_PHY_CMD_BUSY 
if <token> <answer> (err) 
return <token> <answer> err; 
<token> mv88e6xxx_g2_smi_phy_wait(chip); <answer> return 
<token> int mv88e6xxx_g2_smi_phy_access(struct mv88e6xxx_chip *chip, <answer> static 
bool external, bool c45, u16 op, int <token> <answer> dev, 
<token> reg) <answer> int 
u16 cmd <token> op; <answer> = 
<token> (external) <answer> if 
<token> |= MV88E6390_G2_SMI_PHY_CMD_FUNC_EXTERNAL; <answer> cmd 
mv88e6xxx_g2_write(chip, <token> <answer> MV88E6390_G2_WDOG_CTL, 
<token> | <answer> MV88E6390_G2_WDOG_CTL_UPDATE 
return <token> <answer> IRQ_HANDLED; 
const struct mv88e6xxx_irq_ops mv88e6393x_watchdog_ops <token> { <answer> = 
<token> = mv88e6393x_watchdog_action, <answer> .irq_action 
.irq_setup <token> mv88e6390_watchdog_setup, <answer> = 
<token> = mv88e6390_watchdog_free, <answer> .irq_free 
static irqreturn_t mv88e6xxx_g2_watchdog_thread_fn(int irq, void <token> <answer> *dev_id) 
<token> mv88e6xxx_chip *chip = dev_id; <answer> struct 
<token> ret = IRQ_NONE; <answer> irqreturn_t 
<token> (chip->info->ops->watchdog_ops->irq_action) <answer> if 
ret <token> chip->info->ops->watchdog_ops->irq_action(chip, irq); <answer> = 
<token> ret; <answer> return 
static void mv88e6xxx_g2_watchdog_free(struct <token> *chip) <answer> mv88e6xxx_chip 
<token> (chip->info->ops->watchdog_ops->irq_free) <answer> if 
<token> chip); <answer> free_irq(chip->watchdog_irq, 
static int mv88e6xxx_g2_watchdog_setup(struct <token> *chip) <answer> mv88e6xxx_chip 
<token> err; <answer> int 
<token> = irq_find_mapping(chip->g2_irq.domain, <answer> chip->watchdog_irq 
if <token> < 0) <answer> (chip->watchdog_irq 
return <token> <answer> chip->watchdog_irq; 
<token> sizeof(chip->watchdog_irq_name), <answer> snprintf(chip->watchdog_irq_name, 
"mv88e6xxx-%s-watchdog", <token> <answer> dev_name(chip->dev)); 
err = request_threaded_irq(chip->watchdog_irq, <token> <answer> NULL, 
<token> | IRQF_TRIGGER_FALLING, <answer> IRQF_ONESHOT 
chip->watchdog_irq_name, <token> <answer> chip); 
if <token> <answer> (err) 
return <token> <answer> err; 
if <token> <answer> (chip->info->ops->watchdog_ops->irq_setup) 
<token> = chip->info->ops->watchdog_ops->irq_setup(chip); <answer> err 
<token> err; <answer> return 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/nfc.h> 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <net/nfc/nci.h> 
<token> <net/nfc/nci_core.h> <answer> #include 
#include <token> <answer> "st-nci.h" 
struct st_nci_pipe_info <token> <answer> { 
u8 <token> <answer> pipe_state; 
<token> src_host_id; <answer> u8 
u8 <token> <answer> src_gate_id; 
<token> dst_host_id; <answer> u8 
<token> dst_gate_id; <answer> u8 
} <token> <answer> __packed; 
#define ST_NCI_BWI_TO_TIMEOUT(x) <token> << x) * 200) <answer> ((1 
#define ST_NCI_ATR_GET_Y_FROM_TD(x) (x <token> 4) <answer> >> 
r = nci_hci_connect_gate(ndev, <token> <answer> ST_NCI_HOST_CONTROLLER_ID, 
<token> (r < 0) <answer> if 
return <token> <answer> r; 
dm_pipe_info <token> (struct st_nci_pipe_info *)skb_pipe_info->data; <answer> = 
<token> (dm_pipe_info->dst_gate_id == ST_NCI_APDU_READER_GATE && <answer> if 
dm_pipe_info->src_host_id == <token> { <answer> ST_NCI_UICC_HOST_ID) 
pr_err("Unexpected <token> pipe on host %x\n", <answer> apdu_reader 
for <token> = 3; (j < ARRAY_SIZE(st_nci_gates)) && <answer> (j 
(st_nci_gates[j].gate <token> dm_pipe_info->dst_gate_id); j++) <answer> != 
if (j <token> ARRAY_SIZE(st_nci_gates) && <answer> < 
<token> == dm_pipe_info->dst_gate_id && <answer> st_nci_gates[j].gate 
ST_NCI_DM_IS_PIPE_OPEN(dm_pipe_info->pipe_state)) <token> <answer> { 
ndev->hci_dev->init_data.gates[j].pipe <token> pipe_info[2]; <answer> = 
<token> = <answer> ndev->hci_dev->gate2pipe[st_nci_gates[j].gate] 
ndev->hci_dev->pipes[pipe_info[2]].gate <token> <answer> = 
<token> = <answer> ndev->hci_dev->pipes[pipe_info[2]].host 
r = nci_hci_connect_gate(ndev, <token> <answer> ST_NCI_HOST_CONTROLLER_ID, 
<token> r; <answer> return 
static void st_nci_hci_admin_event_received(struct <token> *ndev, <answer> nci_dev 
u8 event, struct <token> *skb) <answer> sk_buff 
struct st_nci_info <token> = nci_get_drvdata(ndev); <answer> *info 
switch <token> { <answer> (event) 
case <token> <answer> ST_NCI_EVT_HOT_PLUG: 
<token> (info->se_info.se_active) { <answer> if 
if (!ST_NCI_EVT_HOT_PLUG_IS_INHIBITED(skb)) <token> <answer> { 
<token> = false; <answer> info->se_info.se_active 
<token> else { <answer> } 
<token> + <answer> jiffies 
nfc_err(&ndev->nfc_dev->dev, "Unexpected <token> on admin gate\n"); <answer> event 
static int <token> nci_dev *ndev, <answer> st_nci_hci_apdu_reader_event_received(struct 
u8 <token> <answer> event, 
struct <token> *skb) <answer> sk_buff 
struct st_nci_info <token> = nci_get_drvdata(ndev); <answer> *info 
<token> reader gate event: %x\n", event); <answer> pr_debug("apdu 
switch (event) <token> <answer> { 
case <token> <answer> ST_NCI_EVT_TRANSMIT_DATA: 
info->se_info.bwi_active = <token> <answer> false; 
<token> skb->len, 0); <answer> skb->data, 
case <token> <answer> ST_NCI_EVT_WTX_REQUEST: 
<token> jiffies + <answer> mod_timer(&info->se_info.bwi_timer, 
nfc_err(&ndev->nfc_dev->dev, "Unexpected event on <token> reader gate\n"); <answer> apdu 
return <token> <answer> 1; 
<token> 0; <answer> return 
static int st_nci_hci_connectivity_event_received(struct nci_dev <token> <answer> *ndev, 
u8 host, <token> event, <answer> u8 
<token> sk_buff *skb) <answer> struct 
<token> r = 0; <answer> int 
struct device <token> = &ndev->nfc_dev->dev; <answer> *dev 
<token> nfc_evt_transaction *transaction; <answer> struct 
<token> aid_len; <answer> u32 
u8 <token> <answer> params_len; 
pr_debug("connectivity gate event: <token> event); <answer> %x\n", 
switch <token> { <answer> (event) 
<token> ST_NCI_EVT_CONNECTIVITY: <answer> case 
r = nfc_se_connectivity(ndev->nfc_dev, <token> <answer> host); 
case <token> <answer> ST_NCI_EVT_TRANSACTION: 
if (skb->len <token> 2 || skb->data[0] != NFC_EVT_TRANSACTION_AID_TAG) <answer> < 
return <token> <answer> -EPROTO; 
<token> = skb->data[1]; <answer> aid_len 
if (skb->len < aid_len <token> 4 || <answer> + 
<token> > sizeof(transaction->aid)) <answer> aid_len 
return <token> <answer> -EPROTO; 
params_len = skb->data[aid_len + <token> <answer> 3]; 
if (skb->data[aid_len + 2] != NFC_EVT_TRANSACTION_PARAMS_TAG <token> <answer> || 
<token> < aid_len + 4 + params_len) <answer> skb->len 
<token> -EPROTO; <answer> return 
<token> = devm_kzalloc(dev, sizeof(*transaction) + <answer> transaction 
params_len, <token> <answer> GFP_KERNEL); 
<token> (!transaction) <answer> if 
<token> -ENOMEM; <answer> return 
transaction->aid_len = <token> <answer> aid_len; 
<token> = params_len; <answer> transaction->params_len 
<token> &skb->data[2], aid_len); <answer> memcpy(transaction->aid, 
memcpy(transaction->params, &skb->data[aid_len <token> 4], <answer> + 
r <token> nfc_se_transaction(ndev->nfc_dev, host, transaction); <answer> = 
nfc_err(&ndev->nfc_dev->dev, "Unexpected <token> on connectivity gate\n"); <answer> event 
<token> 1; <answer> return 
<token> r; <answer> return 
void st_nci_hci_event_received(struct nci_dev *ndev, <token> pipe, <answer> u8 
u8 event, struct <token> *skb) <answer> sk_buff 
<token> gate = ndev->hci_dev->pipes[pipe].gate; <answer> u8 
u8 <token> = ndev->hci_dev->pipes[pipe].host; <answer> host 
switch (gate) <token> <answer> { 
<token> NCI_HCI_ADMIN_GATE: <answer> case 
st_nci_hci_admin_event_received(ndev, event, <token> <answer> skb); 
case <token> <answer> ST_NCI_APDU_READER_GATE: 
st_nci_hci_apdu_reader_event_received(ndev, event, <token> <answer> skb); 
case <token> <answer> ST_NCI_CONNECTIVITY_GATE: 
st_nci_hci_connectivity_event_received(ndev, host, event, <token> <answer> skb); 
void st_nci_hci_cmd_received(struct nci_dev *ndev, u8 pipe, u8 <token> <answer> cmd, 
<token> sk_buff *skb) <answer> struct 
<token> st_nci_info *info = nci_get_drvdata(ndev); <answer> struct 
u8 gate <token> ndev->hci_dev->pipes[pipe].gate; <answer> = 
pr_debug("cmd: <token> cmd); <answer> %x\n", 
<token> (cmd) { <answer> switch 
case <token> <answer> NCI_HCI_ANY_OPEN_PIPE: 
if (gate != <token> && <answer> ST_NCI_APDU_READER_GATE 
<token> != ST_NCI_UICC_HOST_ID) <answer> ndev->hci_dev->pipes[pipe].host 
<token> (ndev->hci_dev->count_pipes == <answer> if 
ndev->hci_dev->expected_pipes) <token> <answer> { 
<token> = false; <answer> info->se_info.se_active 
ndev->hci_dev->count_pipes = <token> <answer> 0; 
static int st_nci_control_se(struct nci_dev *ndev, u8 <token> <answer> se_idx, 
<token> state) <answer> u8 
struct <token> *info = nci_get_drvdata(ndev); <answer> st_nci_info 
<token> r, i; <answer> int 
struct sk_buff <token> <answer> *sk_host_list; 
<token> host_id; <answer> u8 
switch <token> { <answer> (se_idx) 
case <token> <answer> ST_NCI_UICC_HOST_ID: 
ndev->hci_dev->count_pipes = <token> <answer> 0; 
ndev->hci_dev->expected_pipes = <token> <answer> ST_NCI_SE_COUNT_PIPE_UICC; 
case <token> <answer> ST_NCI_ESE_HOST_ID: 
ndev->hci_dev->count_pipes = <token> <answer> 0; 
ndev->hci_dev->expected_pipes = <token> <answer> ST_NCI_SE_COUNT_PIPE_EMBEDDED; 
<token> -EINVAL; <answer> return 
r = nci_nfcee_mode_set(ndev, se_idx, <token> <answer> state); 
<token> (r != NCI_STATUS_OK) <answer> if 
return <token> <answer> r; 
mod_timer(&info->se_info.se_active_timer, jiffies <token> <answer> + 
info->se_info.se_active <token> true; <answer> = 
if (info->se_info.se_status->is_ese_present <token> <answer> && 
<token> 20000); <answer> usleep_range(15000, 
<token> = nci_hci_get_param(ndev, NCI_HCI_ADMIN_GATE, <answer> r 
<token> &sk_host_list); <answer> NCI_HCI_ADMIN_PARAM_HOST_LIST, 
<token> (r != NCI_HCI_ANY_OK) <answer> if 
<token> r; <answer> return 
for <token> = 0; i < sk_host_list->len && <answer> (i 
<token> != se_idx; i++) <answer> sk_host_list->data[i] 
<token> = sk_host_list->data[i]; <answer> host_id 
if (state == ST_NCI_SE_MODE_ON <token> host_id == se_idx) <answer> && 
return <token> <answer> se_idx; 
else <token> (state == ST_NCI_SE_MODE_OFF && host_id != se_idx) <answer> if 
<token> se_idx; <answer> return 
return <token> <answer> -1; 
int st_nci_disable_se(struct <token> *ndev, u32 se_idx) <answer> nci_dev 
int <token> <answer> r; 
r <token> st_nci_control_se(ndev, se_idx, ST_NCI_SE_MODE_OFF); <answer> = 
if (r <token> 0) { <answer> < 
r = <token> se_idx, ST_NCI_SE_MODE_ON); <answer> st_nci_control_se(ndev, 
if (r <token> ST_NCI_ESE_HOST_ID) { <answer> == 
<token> = nci_hci_send_event(ndev, ST_NCI_APDU_READER_GATE, <answer> r 
<token> NULL, 0); <answer> ST_NCI_EVT_SE_SOFT_RESET, 
if <token> < 0) { <answer> (r 
nfc_remove_se(ndev->nfc_dev, <token> <answer> se_idx); 
<token> r; <answer> return 
return <token> <answer> 0; 
static <token> st_nci_hci_network_init(struct nci_dev *ndev) <answer> int 
struct <token> *info = nci_get_drvdata(ndev); <answer> st_nci_info 
<token> core_conn_create_dest_spec_params *dest_params; <answer> struct 
struct <token> spec_params; <answer> dest_spec_params 
<token> nci_conn_info *conn_info; <answer> struct 
int r, <token> <answer> dev_num; 
<token> = <answer> dest_params 
kzalloc(sizeof(struct core_conn_create_dest_spec_params) <token> <answer> + 
<token> dest_spec_params), GFP_KERNEL); <answer> sizeof(struct 
if <token> == NULL) <answer> (dest_params 
return <token> <answer> -ENOMEM; 
<token> = NCI_DESTINATION_SPECIFIC_PARAM_NFCEE_TYPE; <answer> dest_params->type 
dest_params->length <token> sizeof(struct dest_spec_params); <answer> = 
spec_params.id <token> ndev->hci_dev->nfcee_id; <answer> = 
<token> = NCI_NFCEE_INTERFACE_HCI_ACCESS; <answer> spec_params.protocol 
<token> &spec_params, <answer> memcpy(dest_params->value, 
<token> dest_spec_params)); <answer> sizeof(struct 
<token> = nci_core_conn_create(ndev, NCI_DESTINATION_NFCEE, 1, <answer> r 
<token> core_conn_create_dest_spec_params) + <answer> sizeof(struct 
<token> dest_spec_params), <answer> sizeof(struct 
if <token> != NCI_STATUS_OK) <answer> (r 
goto <token> <answer> free_dest_params; 
conn_info <token> ndev->hci_dev->conn_info; <answer> = 
<token> (!conn_info) <answer> if 
<token> free_dest_params; <answer> goto 
ndev->hci_dev->init_data.gate_count = <token> <answer> ARRAY_SIZE(st_nci_gates); 
memcpy(ndev->hci_dev->init_data.gates, <token> <answer> st_nci_gates, 
dev_num = find_first_zero_bit(dev_mask, <token> <answer> ST_NCI_NUM_DEVICES); 
if (dev_num >= <token> { <answer> ST_NCI_NUM_DEVICES) 
r <token> -ENODEV; <answer> = 
<token> free_dest_params; <answer> goto 
<token> "ST21BH", dev_num); <answer> "%s%2x", 
r <token> nci_hci_dev_session_init(ndev); <answer> = 
if (r != <token> <answer> NCI_HCI_ANY_OK) 
<token> free_dest_params; <answer> goto 
<token> (test_bit(ST_NCI_FACTORY_MODE, &info->flags)) <answer> if 
<token> = nci_nfcee_mode_set(ndev, <answer> r 
r <token> nci_nfcee_mode_set(ndev, <answer> = 
<token> r; <answer> return 
int st_nci_discover_se(struct <token> *ndev) <answer> nci_dev 
u8 <token> <answer> white_list[2]; 
int r, wl_size = <token> <answer> 0; 
<token> se_count = 0; <answer> int 
struct st_nci_info *info = <token> <answer> nci_get_drvdata(ndev); 
r <token> st_nci_hci_network_init(ndev); <answer> = 
if (r != <token> <answer> 0) 
return <token> <answer> r; 
if <token> &info->flags)) <answer> (test_bit(ST_NCI_FACTORY_MODE, 
<token> 0; <answer> return 
if <token> <answer> (info->se_info.se_status->is_uicc_present) 
white_list[wl_size++] = <token> <answer> ST_NCI_UICC_HOST_ID; 
if <token> <answer> (info->se_info.se_status->is_ese_present) 
white_list[wl_size++] = <token> <answer> ST_NCI_ESE_HOST_ID; 
if <token> { <answer> (wl_size) 
r = nci_hci_set_param(ndev, <token> <answer> NCI_HCI_ADMIN_GATE, 
<token> wl_size); <answer> white_list, 
if (r != <token> <answer> NCI_HCI_ANY_OK) 
<token> r; <answer> return 
if (info->se_info.se_status->is_uicc_present) <token> <answer> { 
nfc_add_se(ndev->nfc_dev, ST_NCI_UICC_HOST_ID, <token> <answer> NFC_SE_UICC); 
<token> (info->se_info.se_status->is_ese_present) { <answer> if 
nfc_add_se(ndev->nfc_dev, <token> NFC_SE_EMBEDDED); <answer> ST_NCI_ESE_HOST_ID, 
<token> !se_count; <answer> return 
int st_nci_se_io(struct nci_dev *ndev, <token> se_idx, <answer> u32 
u8 *apdu, size_t <token> <answer> apdu_length, 
se_io_cb_t <token> void *cb_context) <answer> cb, 
<token> st_nci_info *info = nci_get_drvdata(ndev); <answer> struct 
switch (se_idx) <token> <answer> { 
case <token> <answer> ST_NCI_ESE_HOST_ID: 
info->se_info.cb = <token> <answer> cb; 
<token> = cb_context; <answer> info->se_info.cb_context 
mod_timer(&info->se_info.bwi_timer, jiffies <token> <answer> + 
info->se_info.bwi_active = <token> <answer> true; 
return <token> ST_NCI_APDU_READER_GATE, <answer> nci_hci_send_event(ndev, 
<token> apdu, <answer> ST_NCI_EVT_TRANSMIT_DATA, 
return <token> <answer> -ENODEV; 
static void <token> timer_list *t) <answer> st_nci_se_wt_timeout(struct 
<token> "dm_services.h" <answer> #include 
#include <token> <answer> "dc.h" 
#include <token> <answer> "core_status.h" 
#include <token> <answer> "core_types.h" 
#include <token> <answer> "resource.h" 
#define DC_LOGGER <token> <answer> \ 
#define <token> <answer> DC_LOGGER_INIT(logger) 
#define <token> do {\ <answer> SURFACE_TRACE(...) 
if (dc->debug.surface_trace) <token> <answer> \ 
<token> \ <answer> DC_LOG_IF_TRACE(__VA_ARGS__); 
} <token> (0) <answer> while 
#define TIMING_TRACE(...) do <token> <answer> {\ 
if <token> \ <answer> (dc->debug.timing_trace) 
<token> \ <answer> DC_LOG_SYNC(__VA_ARGS__); 
} <token> (0) <answer> while 
#define CLOCK_TRACE(...) <token> {\ <answer> do 
if <token> \ <answer> (dc->debug.clock_trace) 
DC_LOG_BANDWIDTH_CALCS(__VA_ARGS__); <token> <answer> \ 
<token> while (0) <answer> } 
<token> pre_surface_trace( <answer> void 
struct dc <token> <answer> *dc, 
const <token> dc_plane_state *const *plane_states, <answer> struct 
<token> surface_count) <answer> int 
int <token> <answer> i; 
for (i = 0; i < surface_count; i++) <token> <answer> { 
const struct dc_plane_state <token> = plane_states[i]; <answer> *plane_state 
<token> %d:\n", i); <answer> SURFACE_TRACE("Planes 
"plane_state->visible <token> %d;\n" <answer> = 
<token> = %d;\n" <answer> "plane_state->flip_immediate 
"plane_state->address.type = <token> <answer> %d;\n" 
<token> = 0x%llX;\n" <answer> "plane_state->address.grph.addr.quad_part 
"plane_state->address.grph.meta_addr.quad_part <token> 0x%llX;\n" <answer> = 
<token> = %d;\n" <answer> "plane_state->scaling_quality.h_taps 
<token> = %d;\n" <answer> "plane_state->scaling_quality.v_taps 
"plane_state->scaling_quality.h_taps_c = <token> <answer> %d;\n" 
"plane_state->scaling_quality.v_taps_c <token> %d;\n", <answer> = 
"plane_state->src_rect.x = <token> <answer> %d;\n" 
"plane_state->src_rect.y <token> %d;\n" <answer> = 
"plane_state->src_rect.width <token> %d;\n" <answer> = 
"plane_state->src_rect.height <token> %d;\n" <answer> = 
<token> = %d;\n" <answer> "plane_state->dst_rect.x 
<token> = %d;\n" <answer> "plane_state->dst_rect.y 
"plane_state->dst_rect.width = <token> <answer> %d;\n" 
"plane_state->dst_rect.height <token> %d;\n" <answer> = 
"plane_state->clip_rect.x <token> %d;\n" <answer> = 
<token> = %d;\n" <answer> "plane_state->clip_rect.y 
<token> = %d;\n" <answer> "plane_state->clip_rect.width 
"plane_state->clip_rect.height <token> %d;\n", <answer> = 
<token> = %d;\n" <answer> "plane_state->plane_size.surface_size.x 
"plane_state->plane_size.surface_size.y <token> %d;\n" <answer> = 
<token> = %d;\n" <answer> "plane_state->plane_size.surface_size.width 
<token> = %d;\n" <answer> "plane_state->plane_size.surface_size.height 
<token> = %d;\n", <answer> "plane_state->plane_size.surface_pitch 
"plane_state->tiling_info.gfx8.num_banks <token> %d;\n" <answer> = 
<token> = %d;\n" <answer> "plane_state->tiling_info.gfx8.bank_width 
"plane_state->tiling_info.gfx8.bank_width_c <token> %d;\n" <answer> = 
<token> = %d;\n" <answer> "plane_state->tiling_info.gfx8.bank_height 
"plane_state->tiling_info.gfx8.bank_height_c = <token> <answer> %d;\n" 
"plane_state->tiling_info.gfx8.tile_aspect = <token> <answer> %d;\n" 
"plane_state->tiling_info.gfx8.tile_aspect_c <token> %d;\n" <answer> = 
"plane_state->tiling_info.gfx8.tile_split = <token> <answer> %d;\n" 
<token> = %d;\n" <answer> "plane_state->tiling_info.gfx8.tile_split_c 
<token> = %d;\n" <answer> "plane_state->tiling_info.gfx8.tile_mode 
<token> = %d;\n", <answer> "plane_state->tiling_info.gfx8.tile_mode_c 
"plane_state->tiling_info.gfx8.pipe_config = <token> <answer> %d;\n" 
"plane_state->tiling_info.gfx8.array_mode = <token> <answer> %d;\n" 
"plane_state->color_space <token> %d;\n" <answer> = 
"plane_state->dcc.enable <token> %d;\n" <answer> = 
"plane_state->format <token> %d;\n" <answer> = 
<token> = %d;\n" <answer> "plane_state->rotation 
"plane_state->stereo_format = <token> <answer> %d;\n", 
SURFACE_TRACE("plane_state->tiling_info.gfx9.swizzle <token> %d;\n", <answer> = 
void <token> <answer> update_surface_trace( 
<token> dc *dc, <answer> struct 
const struct <token> *updates, <answer> dc_surface_update 
<token> surface_count) <answer> int 
<token> i; <answer> int 
for (i = 0; i < surface_count; i++) <token> <answer> { 
const struct <token> *update = &updates[i]; <answer> dc_surface_update 
SURFACE_TRACE("Update <token> i); <answer> %d\n", 
<token> (update->flip_addr) { <answer> if 
SURFACE_TRACE("flip_addr->address.type <token> %d;\n" <answer> = 
<token> = 0x%llX;\n" <answer> "flip_addr->address.grph.addr.quad_part 
"flip_addr->address.grph.meta_addr.quad_part <token> 0x%llX;\n" <answer> = 
"flip_addr->flip_immediate <token> %d;\n", <answer> = 
if (update->plane_info) <token> <answer> { 
"plane_info->color_space <token> %d;\n" <answer> = 
<token> = %d;\n" <answer> "plane_info->format 
"plane_info->plane_size.surface_pitch = <token> <answer> %d;\n" 
"plane_info->plane_size.surface_size.height <token> %d;\n" <answer> = 
"plane_info->plane_size.surface_size.width <token> %d;\n" <answer> = 
<token> = %d;\n" <answer> "plane_info->plane_size.surface_size.x 
<token> = %d;\n" <answer> "plane_info->plane_size.surface_size.y 
"plane_info->rotation = <token> <answer> %d;\n" 
<token> = %d;\n", <answer> "plane_info->stereo_format 
"plane_info->tiling_info.gfx8.num_banks = <token> <answer> %d;\n" 
"plane_info->tiling_info.gfx8.bank_width <token> %d;\n" <answer> = 
"plane_info->tiling_info.gfx8.bank_width_c <token> %d;\n" <answer> = 
"plane_info->tiling_info.gfx8.bank_height <token> %d;\n" <answer> = 
"plane_info->tiling_info.gfx8.bank_height_c = <token> <answer> %d;\n" 
"plane_info->tiling_info.gfx8.tile_aspect = <token> <answer> %d;\n" 
"plane_info->tiling_info.gfx8.tile_aspect_c <token> %d;\n" <answer> = 
<token> = %d;\n" <answer> "plane_info->tiling_info.gfx8.tile_split 
<token> = %d;\n" <answer> "plane_info->tiling_info.gfx8.tile_split_c 
"plane_info->tiling_info.gfx8.tile_mode <token> %d;\n" <answer> = 
<token> = %d;\n", <answer> "plane_info->tiling_info.gfx8.tile_mode_c 
<token> = %d;\n" <answer> "plane_info->tiling_info.gfx8.pipe_config 
"plane_info->tiling_info.gfx8.array_mode <token> %d;\n" <answer> = 
"plane_info->visible <token> %d;\n" <answer> = 
"plane_info->per_pixel_alpha <token> %d;\n", <answer> = 
SURFACE_TRACE("surface->tiling_info.gfx9.swizzle <token> %d;\n", <answer> = 
<token> (update->scaling_info) { <answer> if 
<token> = %d;\n" <answer> "scaling_info->src_rect.x 
"scaling_info->src_rect.y = <token> <answer> %d;\n" 
"scaling_info->src_rect.width = <token> <answer> %d;\n" 
"scaling_info->src_rect.height = <token> <answer> %d;\n" 
"scaling_info->dst_rect.x = <token> <answer> %d;\n" 
"scaling_info->dst_rect.y = <token> <answer> %d;\n" 
"scaling_info->dst_rect.width = <token> <answer> %d;\n" 
<token> = %d;\n" <answer> "scaling_info->dst_rect.height 
<token> = %d;\n" <answer> "scaling_info->clip_rect.x 
"scaling_info->clip_rect.y = <token> <answer> %d;\n" 
<token> = %d;\n" <answer> "scaling_info->clip_rect.width 
<token> = %d;\n" <answer> "scaling_info->clip_rect.height 
"scaling_info->scaling_quality.h_taps = <token> <answer> %d;\n" 
<token> = %d;\n" <answer> "scaling_info->scaling_quality.v_taps 
<token> = %d;\n" <answer> "scaling_info->scaling_quality.h_taps_c 
"scaling_info->scaling_quality.v_taps_c <token> %d;\n", <answer> = 
<token> post_surface_trace(struct dc *dc) <answer> void 
SURFACE_TRACE("post <token> process.\n"); <answer> surface 
void <token> <answer> context_timing_trace( 
<token> dc *dc, <answer> struct 
struct <token> *res_ctx) <answer> resource_context 
<token> i; <answer> int 
int h_pos[MAX_PIPES] = {0}, <token> = {0}; <answer> v_pos[MAX_PIPES] 
struct crtc_position <token> <answer> position; 
unsigned int underlay_idx <token> dc->res_pool->underlay_pipe_index; <answer> = 
for (i = <token> i < dc->res_pool->pipe_count; i++) { <answer> 0; 
struct <token> *pipe_ctx = &res_ctx->pipe_ctx[i]; <answer> pipe_ctx 
if (pipe_ctx->stream == NULL || <token> == underlay_idx) <answer> pipe_ctx->pipe_idx 
pipe_ctx->stream_res.tg->funcs->get_position(pipe_ctx->stream_res.tg, <token> <answer> &position); 
h_pos[i] <token> position.horizontal_count; <answer> = 
v_pos[i] <token> position.vertical_count; <answer> = 
for (i = 0; i < dc->res_pool->pipe_count; i++) <token> <answer> { 
struct pipe_ctx *pipe_ctx <token> &res_ctx->pipe_ctx[i]; <answer> = 
if (pipe_ctx->stream == NULL || pipe_ctx->pipe_idx == <token> <answer> underlay_idx) 
TIMING_TRACE("OTG_%d H_tot:%d <token> H_pos:%d V_pos:%d\n", <answer> V_tot:%d 
<token> v_pos[i]); <answer> h_pos[i], 
<token> context_clock_trace( <answer> void 
struct dc <token> <answer> *dc, 
struct <token> *context) <answer> dc_state 
CLOCK_TRACE("Current: dispclk_khz:%d <token> dcfclk_khz:%d\n" <answer> max_dppclk_khz:%d 
"dcfclk_deep_sleep_khz:%d <token> socclk_khz:%d\n", <answer> fclk_khz:%d 
<token> dispclk_khz:%d max_dppclk_khz:%d dcfclk_khz:%d\n" <answer> CLOCK_TRACE("Calculated: 
<token> fclk_khz:%d socclk_khz:%d\n", <answer> "dcfclk_deep_sleep_khz:%d 
char *dc_status_to_str(enum dc_status <token> <answer> status) 
<token> (status) { <answer> switch 
<token> DC_OK: <answer> case 
<token> "DC OK"; <answer> return 
<token> DC_NO_CONTROLLER_RESOURCE: <answer> case 
return "No controller <token> <answer> resource"; 
<token> DC_NO_STREAM_ENC_RESOURCE: <answer> case 
return "No <token> encoder"; <answer> stream 
case <token> <answer> DC_NO_CLOCK_SOURCE_RESOURCE: 
return "No clock <token> <answer> source"; 
case <token> <answer> DC_FAIL_CONTROLLER_VALIDATE: 
return "Controller validation <token> <answer> failure"; 
<token> DC_FAIL_ENC_VALIDATE: <answer> case 
<token> "Encoder validation failure"; <answer> return 
<token> DC_FAIL_ATTACH_SURFACES: <answer> case 
return "Surfaces attachment <token> <answer> failure"; 
case <token> <answer> DC_FAIL_DETACH_SURFACES: 
return <token> detachment failure"; <answer> "Surfaces 
case <token> <answer> DC_FAIL_SURFACE_VALIDATE: 
<token> "Surface validation failure"; <answer> return 
case <token> <answer> DC_NO_DP_LINK_BANDWIDTH: 
return "No DP <token> bandwidth"; <answer> link 
case <token> <answer> DC_EXCEED_DONGLE_CAP: 
return "Exceed <token> capability"; <answer> dongle 
<token> DC_SURFACE_PIXEL_FORMAT_UNSUPPORTED: <answer> case 
return <token> pixel format"; <answer> "Unsupported 
<token> DC_FAIL_BANDWIDTH_VALIDATE: <answer> case 
return "Bandwidth validation failure <token> and Watermark)"; <answer> (BW 
<token> DC_FAIL_SCALING: <answer> case 
<token> "Scaling failure"; <answer> return 
case <token> <answer> DC_FAIL_DP_LINK_TRAINING: 
<token> "DP link training failure"; <answer> return 
<token> DC_FAIL_DSC_VALIDATE: <answer> case 
<token> "DSC validation failure"; <answer> return 
case <token> <answer> DC_NO_DSC_RESOURCE: 
return "No <token> resource"; <answer> DSC 
case <token> <answer> DC_FAIL_UNSUPPORTED_1: 
<token> "Unsupported"; <answer> return 
<token> DC_FAIL_CLK_EXCEED_MAX: <answer> case 
<token> "Clk exceed max failure"; <answer> return 
<token> DC_FAIL_CLK_BELOW_MIN: <answer> case 
return <token> clk below minimum"; <answer> "Fail 
case <token> <answer> DC_FAIL_CLK_BELOW_CFG_REQUIRED: 
return "Fail clk below required <token> (hard_min in PPLIB)"; <answer> CFG 
<token> DC_NOT_SUPPORTED: <answer> case 
return "The operation <token> not supported."; <answer> is 
<token> DC_UNSUPPORTED_VALUE: <answer> case 
<token> "The value specified is not supported."; <answer> return 
<token> DC_NO_LINK_ENC_RESOURCE: <answer> case 
<token> "No link encoder resource"; <answer> return 
<token> DC_FAIL_DP_PAYLOAD_ALLOCATION: <answer> case 
return "Fail <token> payload allocation"; <answer> dp 
<token> DC_FAIL_DP_LINK_BANDWIDTH: <answer> case 
return "Insufficient DP link <token> <answer> bandwidth"; 
<token> DC_ERROR_UNEXPECTED: <answer> case 
return <token> error"; <answer> "Unexpected 
return "Unexpected status <token> <answer> error"; 
#include <token> <answer> <linux/cpu.h> 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/irqchip.h> 
#include <token> <answer> <linux/irqchip/chained_irq.h> 
#include <token> <answer> <linux/irqdomain.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_address.h> 
<token> <linux/of_irq.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/syscore_ops.h> <answer> #include 
<token> <asm/smp.h> <answer> #include 
<token> MAX_DEVICES 1024 <answer> #define 
#define MAX_CONTEXTS <token> <answer> 15872 
#define PRIORITY_BASE <token> <answer> 0 
<token> PRIORITY_PER_ID 4 <answer> #define 
#define CONTEXT_ENABLE_BASE <token> <answer> 0x2000 
#define <token> 0x80 <answer> CONTEXT_ENABLE_SIZE 
<token> CONTEXT_BASE 0x200000 <answer> #define 
#define <token> 0x1000 <answer> CONTEXT_SIZE 
<token> CONTEXT_THRESHOLD 0x00 <answer> #define 
#define <token> 0x04 <answer> CONTEXT_CLAIM 
#define <token> 0x7 <answer> PLIC_DISABLE_THRESHOLD 
#define PLIC_ENABLE_THRESHOLD <token> <answer> 0 
#define <token> 0 <answer> PLIC_QUIRK_EDGE_INTERRUPT 
<token> plic_priv { <answer> struct 
struct <token> *dev; <answer> device 
struct cpumask <token> <answer> lmask; 
<token> irq_domain *irqdomain; <answer> struct 
void <token> *regs; <answer> __iomem 
<token> long plic_quirks; <answer> unsigned 
unsigned <token> nr_irqs; <answer> int 
unsigned <token> *prio_save; <answer> long 
struct <token> { <answer> plic_handler 
<token> present; <answer> bool 
void <token> *hart_base; <answer> __iomem 
<token> enable_lock; <answer> raw_spinlock_t 
void <token> *enable_base; <answer> __iomem 
u32 <token> <answer> *enable_save; 
struct <token> *priv; <answer> plic_priv 
static <token> plic_parent_irq __ro_after_init; <answer> int 
static <token> plic_cpuhp_setup_done __ro_after_init; <answer> bool 
static <token> plic_handler, plic_handlers); <answer> DEFINE_PER_CPU(struct 
static int plic_irq_set_type(struct irq_data *d, unsigned int <token> <answer> type); 
static void <token> __iomem *enable_base, int hwirq, int enable) <answer> __plic_toggle(void 
u32 __iomem *reg = <token> + (hwirq / 32) * sizeof(u32); <answer> enable_base 
u32 hwirq_mask = 1 << (hwirq % <token> <answer> 32); 
<token> (enable) <answer> if 
<token> | hwirq_mask, reg); <answer> writel(readl(reg) 
writel(readl(reg) & <token> reg); <answer> ~hwirq_mask, 
<token> void plic_toggle(struct plic_handler *handler, int hwirq, int enable) <answer> static 
unsigned <token> flags; <answer> long 
raw_spin_lock_irqsave(&handler->enable_lock, <token> <answer> flags); 
__plic_toggle(handler->enable_base, hwirq, <token> <answer> enable); 
raw_spin_unlock_irqrestore(&handler->enable_lock, <token> <answer> flags); 
static inline <token> plic_irq_toggle(const struct cpumask *mask, <answer> void 
struct irq_data *d, int <token> <answer> enable) 
int <token> <answer> cpu; 
for_each_cpu(cpu, mask) <token> <answer> { 
struct plic_handler *handler = per_cpu_ptr(&plic_handlers, <token> <answer> cpu); 
<token> d->hwirq, enable); <answer> plic_toggle(handler, 
<token> void plic_irq_enable(struct irq_data *d) <answer> static 
plic_irq_toggle(irq_data_get_effective_affinity_mask(d), <token> 1); <answer> d, 
static void plic_irq_disable(struct <token> *d) <answer> irq_data 
plic_irq_toggle(irq_data_get_effective_affinity_mask(d), d, <token> <answer> 0); 
static void plic_irq_unmask(struct <token> *d) <answer> irq_data 
<token> plic_priv *priv = irq_data_get_irq_chip_data(d); <answer> struct 
writel(1, priv->regs + PRIORITY_BASE + <token> * PRIORITY_PER_ID); <answer> d->hwirq 
static void <token> irq_data *d) <answer> plic_irq_mask(struct 
struct plic_priv *priv = <token> <answer> irq_data_get_irq_chip_data(d); 
writel(0, <token> + PRIORITY_BASE + d->hwirq * PRIORITY_PER_ID); <answer> priv->regs 
static <token> plic_irq_eoi(struct irq_data *d) <answer> void 
struct plic_handler <token> = this_cpu_ptr(&plic_handlers); <answer> *handler 
if (unlikely(irqd_irq_disabled(d))) <token> <answer> { 
<token> d->hwirq, 1); <answer> plic_toggle(handler, 
<token> handler->hart_base + CONTEXT_CLAIM); <answer> writel(d->hwirq, 
plic_toggle(handler, d->hwirq, <token> <answer> 0); 
} else <token> <answer> { 
<token> handler->hart_base + CONTEXT_CLAIM); <answer> writel(d->hwirq, 
<token> CONFIG_SMP <answer> #ifdef 
static <token> plic_set_affinity(struct irq_data *d, <answer> int 
const struct cpumask <token> bool force) <answer> *mask_val, 
unsigned <token> cpu; <answer> int 
struct <token> amask; <answer> cpumask 
struct plic_priv *priv <token> irq_data_get_irq_chip_data(d); <answer> = 
cpumask_and(&amask, &priv->lmask, <token> <answer> mask_val); 
<token> (force) <answer> if 
cpu <token> cpumask_first(&amask); <answer> = 
cpu <token> cpumask_any_and(&amask, cpu_online_mask); <answer> = 
if <token> >= nr_cpu_ids) <answer> (cpu 
return <token> <answer> -EINVAL; 
irq_data_update_effective_affinity(d, <token> <answer> cpumask_of(cpu)); 
<token> (!irqd_irq_disabled(d)) <answer> if 
<token> IRQ_SET_MASK_OK_DONE; <answer> return 
static struct irq_chip plic_edge_chip <token> { <answer> = 
.name = "SiFive <token> <answer> PLIC", 
.irq_enable <token> plic_irq_enable, <answer> = 
.irq_disable <token> plic_irq_disable, <answer> = 
.irq_ack = <token> <answer> plic_irq_eoi, 
<token> = plic_irq_mask, <answer> .irq_mask 
<token> = plic_irq_unmask, <answer> .irq_unmask 
<token> CONFIG_SMP <answer> #ifdef 
<token> = plic_set_affinity, <answer> .irq_set_affinity 
.irq_set_type = <token> <answer> plic_irq_set_type, 
.flags <token> IRQCHIP_SKIP_SET_WAKE | <answer> = 
static struct irq_chip <token> = { <answer> plic_chip 
.name = <token> PLIC", <answer> "SiFive 
.irq_enable = <token> <answer> plic_irq_enable, 
.irq_disable <token> plic_irq_disable, <answer> = 
<token> = plic_irq_mask, <answer> .irq_mask 
.irq_unmask = <token> <answer> plic_irq_unmask, 
.irq_eoi = <token> <answer> plic_irq_eoi, 
<token> CONFIG_SMP <answer> #ifdef 
.irq_set_affinity <token> plic_set_affinity, <answer> = 
.irq_set_type <token> plic_irq_set_type, <answer> = 
.flags <token> IRQCHIP_SKIP_SET_WAKE | <answer> = 
static <token> plic_irq_set_type(struct irq_data *d, unsigned int type) <answer> int 
struct plic_priv <token> = irq_data_get_irq_chip_data(d); <answer> *priv 
if (!test_bit(PLIC_QUIRK_EDGE_INTERRUPT, <token> <answer> &priv->plic_quirks)) 
return <token> <answer> IRQ_SET_MASK_OK_NOCOPY; 
<token> (type) { <answer> switch 
case <token> <answer> IRQ_TYPE_EDGE_RISING: 
irq_set_chip_handler_name_locked(d, <token> <answer> &plic_edge_chip, 
handle_edge_irq, <token> <answer> NULL); 
<token> IRQ_TYPE_LEVEL_HIGH: <answer> case 
<token> &plic_chip, <answer> irq_set_chip_handler_name_locked(d, 
handle_fasteoi_irq, <token> <answer> NULL); 
return <token> <answer> -EINVAL; 
<token> IRQ_SET_MASK_OK; <answer> return 
<token> int plic_irq_suspend(void) <answer> static 
unsigned int <token> cpu; <answer> i, 
unsigned <token> flags; <answer> long 
u32 <token> *reg; <answer> __iomem 
struct <token> *priv; <answer> plic_priv 
<token> = per_cpu_ptr(&plic_handlers, smp_processor_id())->priv; <answer> priv 
for (i = 0; i < priv->nr_irqs; <token> <answer> i++) 
if (readl(priv->regs + PRIORITY_BASE + i * <token> <answer> PRIORITY_PER_ID)) 
__set_bit(i, <token> <answer> priv->prio_save); 
<token> priv->prio_save); <answer> __clear_bit(i, 
for_each_cpu(cpu, cpu_present_mask) <token> <answer> { 
struct <token> *handler = per_cpu_ptr(&plic_handlers, cpu); <answer> plic_handler 
<token> (!handler->present) <answer> if 
<token> flags); <answer> raw_spin_lock_irqsave(&handler->enable_lock, 
for (i = 0; i <token> DIV_ROUND_UP(priv->nr_irqs, 32); i++) { <answer> < 
reg = handler->enable_base + <token> * sizeof(u32); <answer> i 
handler->enable_save[i] <token> readl(reg); <answer> = 
<token> flags); <answer> raw_spin_unlock_irqrestore(&handler->enable_lock, 
<token> 0; <answer> return 
static void <token> <answer> plic_irq_resume(void) 
unsigned int i, index, <token> <answer> cpu; 
unsigned <token> flags; <answer> long 
u32 __iomem <token> <answer> *reg; 
<token> plic_priv *priv; <answer> struct 
priv = per_cpu_ptr(&plic_handlers, <token> <answer> smp_processor_id())->priv; 
for (i = 0; i < priv->nr_irqs; i++) <token> <answer> { 
index = <token> <answer> BIT_WORD(i); 
<token> & BIT_MASK(i)) ? 1 : 0, <answer> writel((priv->prio_save[index] 
priv->regs + PRIORITY_BASE + <token> * PRIORITY_PER_ID); <answer> i 
for_each_cpu(cpu, <token> { <answer> cpu_present_mask) 
struct plic_handler *handler = <token> cpu); <answer> per_cpu_ptr(&plic_handlers, 
if <token> <answer> (!handler->present) 
raw_spin_lock_irqsave(&handler->enable_lock, <token> <answer> flags); 
for (i = <token> i < DIV_ROUND_UP(priv->nr_irqs, 32); i++) { <answer> 0; 
reg <token> handler->enable_base + i * sizeof(u32); <answer> = 
writel(handler->enable_save[i], <token> <answer> reg); 
<token> flags); <answer> raw_spin_unlock_irqrestore(&handler->enable_lock, 
static struct <token> plic_irq_syscore_ops = { <answer> syscore_ops 
<token> = plic_irq_suspend, <answer> .suspend 
<token> = plic_irq_resume, <answer> .resume 
static int plic_irqdomain_map(struct irq_domain *d, <token> int irq, <answer> unsigned 
<token> hwirq) <answer> irq_hw_number_t 
<token> plic_priv *priv = d->host_data; <answer> struct 
<token> irq, hwirq, &plic_chip, d->host_data, <answer> irq_domain_set_info(d, 
handle_fasteoi_irq, <token> NULL); <answer> NULL, 
<token> &priv->lmask); <answer> irq_set_affinity(irq, 
<token> 0; <answer> return 
static int plic_irq_domain_translate(struct irq_domain <token> <answer> *d, 
struct <token> *fwspec, <answer> irq_fwspec 
<token> long *hwirq, <answer> unsigned 
unsigned int <token> <answer> *type) 
struct plic_priv *priv = <token> <answer> d->host_data; 
if (test_bit(PLIC_QUIRK_EDGE_INTERRUPT, <token> <answer> &priv->plic_quirks)) 
return irq_domain_translate_twocell(d, fwspec, hwirq, <token> <answer> type); 
<token> irq_domain_translate_onecell(d, fwspec, hwirq, type); <answer> return 
static int plic_irq_domain_alloc(struct irq_domain <token> unsigned int virq, <answer> *domain, 
unsigned int nr_irqs, <token> *arg) <answer> void 
int i, <token> <answer> ret; 
<token> hwirq; <answer> irq_hw_number_t 
unsigned <token> type; <answer> int 
struct irq_fwspec *fwspec <token> arg; <answer> = 
<token> = plic_irq_domain_translate(domain, fwspec, &hwirq, &type); <answer> ret 
<token> (ret) <answer> if 
return <token> <answer> ret; 
for (i = 0; i < <token> i++) { <answer> nr_irqs; 
ret = plic_irqdomain_map(domain, virq + <token> hwirq + i); <answer> i, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
return <token> <answer> 0; 
static const struct <token> plic_irqdomain_ops = { <answer> irq_domain_ops 
.translate <token> plic_irq_domain_translate, <answer> = 
.alloc <token> plic_irq_domain_alloc, <answer> = 
.free = <token> <answer> irq_domain_free_irqs_top, 
static void plic_handle_irq(struct irq_desc <token> <answer> *desc) 
struct plic_handler <token> = this_cpu_ptr(&plic_handlers); <answer> *handler 
struct <token> *chip = irq_desc_get_chip(desc); <answer> irq_chip 
void __iomem *claim <token> handler->hart_base + CONTEXT_CLAIM; <answer> = 
<token> hwirq; <answer> irq_hw_number_t 
<token> desc); <answer> chained_irq_enter(chip, 
while ((hwirq = readl(claim))) <token> <answer> { 
int err = <token> <answer> generic_handle_domain_irq(handler->priv->irqdomain, 
if <token> { <answer> (unlikely(err)) 
"can't find mapping for <token> %lu\n", hwirq); <answer> hwirq 
chained_irq_exit(chip, <token> <answer> desc); 
<token> void plic_set_threshold(struct plic_handler *handler, u32 threshold) <answer> static 
<token> (!is_of_node(dev->fwnode)) <answer> if 
return <token> <answer> -EINVAL; 
rc = of_property_read_u32(to_of_node(dev->fwnode), <token> nr_irqs); <answer> "riscv,ndev", 
<token> (rc) { <answer> if 
dev_err(dev, "riscv,ndev <token> not available\n"); <answer> property 
return <token> <answer> rc; 
*nr_contexts <token> of_irq_count(to_of_node(dev->fwnode)); <answer> = 
if (WARN_ON(!(*nr_contexts))) <token> <answer> { 
dev_err(dev, <token> PLIC context available\n"); <answer> "no 
<token> -EINVAL; <answer> return 
<token> 0; <answer> return 
static int <token> platform_device *pdev, u32 context, <answer> plic_parse_context_parent(struct 
u32 *parent_hwirq, <token> *parent_cpu) <answer> int 
struct device *dev = <token> <answer> &pdev->dev; 
<token> of_phandle_args parent; <answer> struct 
unsigned <token> hartid; <answer> long 
<token> rc; <answer> int 
if <token> <answer> (!is_of_node(dev->fwnode)) 
return <token> <answer> -EINVAL; 
rc = of_irq_parse_one(to_of_node(dev->fwnode), <token> &parent); <answer> context, 
if <token> <answer> (rc) 
return <token> <answer> rc; 
<token> = riscv_of_parent_hartid(parent.np, &hartid); <answer> rc 
<token> (rc) <answer> if 
return <token> <answer> rc; 
*parent_hwirq = <token> <answer> parent.args[0]; 
*parent_cpu = <token> <answer> riscv_hartid_to_cpuid(hartid); 
return <token> <answer> 0; 
<token> int plic_probe(struct platform_device *pdev) <answer> static 
int error = 0, nr_contexts, nr_handlers = 0, cpu, <token> <answer> i; 
struct device <token> = &pdev->dev; <answer> *dev 
unsigned <token> plic_quirks = 0; <answer> long 
struct <token> *handler; <answer> plic_handler 
u32 <token> parent_hwirq; <answer> nr_irqs, 
struct irq_domain <token> <answer> *domain; 
struct <token> *priv; <answer> plic_priv 
irq_hw_number_t <token> <answer> hwirq; 
<token> cpuhp_setup; <answer> bool 
<token> (is_of_node(dev->fwnode)) { <answer> if 
const struct <token> *id; <answer> of_device_id 
id = <token> to_of_node(dev->fwnode)); <answer> of_match_node(plic_match, 
<token> (id) <answer> if 
<token> = (unsigned long)id->data; <answer> plic_quirks 
error = <token> &nr_irqs, &nr_contexts); <answer> plic_parse_nr_irqs_and_contexts(pdev, 
<token> (error) <answer> if 
return <token> <answer> error; 
priv = devm_kzalloc(dev, <token> GFP_KERNEL); <answer> sizeof(*priv), 
if <token> <answer> (!priv) 
<token> -ENOMEM; <answer> return 
priv->dev = <token> <answer> dev; 
priv->plic_quirks = <token> <answer> plic_quirks; 
priv->nr_irqs = <token> <answer> nr_irqs; 
priv->regs = <token> 0); <answer> devm_platform_ioremap_resource(pdev, 
if <token> <answer> (WARN_ON(!priv->regs)) 
<token> -EIO; <answer> return 
priv->prio_save = devm_bitmap_zalloc(dev, <token> GFP_KERNEL); <answer> nr_irqs, 
if <token> <answer> (!priv->prio_save) 
<token> -ENOMEM; <answer> return 
for (i = <token> i < nr_contexts; i++) { <answer> 0; 
error = <token> i, &parent_hwirq, &cpu); <answer> plic_parse_context_parent(pdev, 
if (error) <token> <answer> { 
dev_warn(dev, "hwirq for <token> not found\n", i); <answer> context%d 
if <token> != RV_IRQ_EXT) { <answer> (parent_hwirq 
handler = <token> cpu); <answer> per_cpu_ptr(&plic_handlers, 
if <token> { <answer> (handler->present) 
dev_warn(dev, "handler already <token> for context %d.\n", i); <answer> present 
plic_set_threshold(handler, <token> <answer> PLIC_DISABLE_THRESHOLD); 
<token> done; <answer> goto 
<token> &priv->lmask); <answer> cpumask_set_cpu(cpu, 
handler->present = <token> <answer> true; 
<token> = priv->regs + CONTEXT_BASE + <answer> handler->hart_base 
i * <token> <answer> CONTEXT_SIZE; 
<token> = priv->regs + CONTEXT_ENABLE_BASE + <answer> handler->enable_base 
<token> * CONTEXT_ENABLE_SIZE; <answer> i 
<token> = priv; <answer> handler->priv 
<token> = devm_kcalloc(dev, DIV_ROUND_UP(nr_irqs, 32), <answer> handler->enable_save 
sizeof(*handler->enable_save), <token> <answer> GFP_KERNEL); 
<token> (!handler->enable_save) <answer> if 
<token> fail_cleanup_contexts; <answer> goto 
for (hwirq = 1; hwirq <= nr_irqs; <token> { <answer> hwirq++) 
<token> hwirq, 0); <answer> plic_toggle(handler, 
<token> priv->regs + PRIORITY_BASE + <answer> writel(1, 
hwirq * <token> <answer> PRIORITY_PER_ID); 
priv->irqdomain = <token> nr_irqs + 1, <answer> irq_domain_add_linear(to_of_node(dev->fwnode), 
&plic_irqdomain_ops, <token> <answer> priv); 
<token> (WARN_ON(!priv->irqdomain)) <answer> if 
goto <token> <answer> fail_cleanup_contexts; 
<token> (!plic_cpuhp_setup_done) { <answer> if 
cpuhp_setup <token> true; <answer> = 
<token> { <answer> for_each_online_cpu(cpu) 
handler = per_cpu_ptr(&plic_handlers, <token> <answer> cpu); 
<token> (!handler->present) { <answer> if 
<token> = false; <answer> cpuhp_setup 
<token> (cpuhp_setup) { <answer> if 
<token> plic_dying_cpu); <answer> plic_starting_cpu, 
plic_cpuhp_setup_done <token> true; <answer> = 
dev_info(dev, "mapped %d interrupts <token> %d handlers for %d contexts.\n", <answer> with 
<token> nr_handlers, nr_contexts); <answer> nr_irqs, 
<token> 0; <answer> return 
for (i = 0; <token> < nr_contexts; i++) { <answer> i 
if (plic_parse_context_parent(pdev, i, &parent_hwirq, <token> <answer> &cpu)) 
if (parent_hwirq <token> RV_IRQ_EXT || cpu < 0) <answer> != 
handler = per_cpu_ptr(&plic_handlers, <token> <answer> cpu); 
handler->present <token> false; <answer> = 
handler->hart_base = <token> <answer> NULL; 
handler->enable_base = <token> <answer> NULL; 
<token> = NULL; <answer> handler->enable_save 
<token> = NULL; <answer> handler->priv 
return <token> <answer> -ENOMEM; 
<token> struct platform_driver plic_driver = { <answer> static 
.driver = <token> <answer> { 
<token> = "riscv-plic", <answer> .name 
.of_match_table <token> plic_match, <answer> = 
<token> = plic_probe, <answer> .probe 
#include <token> <answer> <linux/io.h> 
<token> <linux/pm.h> <answer> #include 
<token> <linux/reboot.h> <answer> #include 
<token> <asm/mach-types.h> <answer> #include 
<token> <asm/mach/arch.h> <answer> #include 
#include <token> <answer> <asm/mach/time.h> 
#include <token> <answer> <asm/mach/map.h> 
<token> <linux/of.h> <answer> #include 
<token> <linux/of_address.h> <answer> #include 
#include <token> <answer> <linux/of_irq.h> 
#define <token> 0xD8110000 <answer> LEGACY_GPIO_BASE 
#define LEGACY_PMC_BASE <token> <answer> 0xD8130000 
#include <token> <answer> <linux/hid.h> 
#include <token> <answer> <linux/input/mt.h> 
#include <token> <answer> <linux/leds.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/usb.h> 
#include <token> <answer> "hid-ids.h" 
#define <token> 0x5d <answer> ELAN_MT_I2C 
<token> ELAN_SINGLE_FINGER 0x81 <answer> #define 
<token> ELAN_MT_FIRST_FINGER 0x82 <answer> #define 
#define <token> 0x83 <answer> ELAN_MT_SECOND_FINGER 
#define <token> 8 <answer> ELAN_INPUT_REPORT_SIZE 
#define ELAN_I2C_REPORT_SIZE <token> <answer> 32 
#define ELAN_FINGER_DATA_LEN <token> <answer> 5 
#define <token> 5 <answer> ELAN_MAX_FINGERS 
#define <token> 255 <answer> ELAN_MAX_PRESSURE 
#define <token> 1 <answer> ELAN_TP_USB_INTF 
<token> ELAN_FEATURE_REPORT 0x0d <answer> #define 
#define ELAN_FEATURE_SIZE <token> <answer> 5 
#define ELAN_PARAM_MAX_X <token> <answer> 6 
#define <token> 7 <answer> ELAN_PARAM_MAX_Y 
<token> ELAN_PARAM_RES 8 <answer> #define 
<token> ELAN_MUTE_LED_REPORT 0xBC <answer> #define 
#define <token> 8 <answer> ELAN_LED_REPORT_SIZE 
#define <token> BIT(0) <answer> ELAN_HAS_LED 
<token> elan_drvdata { <answer> struct 
<token> input_dev *input; <answer> struct 
u8 <token> <answer> prev_report[ELAN_INPUT_REPORT_SIZE]; 
struct led_classdev <token> <answer> mute_led; 
u8 <token> <answer> mute_led_state; 
<token> max_x; <answer> u16 
u16 <token> <answer> max_y; 
<token> res_x; <answer> u16 
<token> res_y; <answer> u16 
<token> int is_not_elan_touchpad(struct hid_device *hdev) <answer> static 
<token> (hid_is_usb(hdev)) { <answer> if 
struct usb_interface *intf = <token> <answer> to_usb_interface(hdev->dev.parent); 
<token> (intf->altsetting->desc.bInterfaceNumber != <answer> return 
<token> 0; <answer> return 
static int elan_input_mapping(struct hid_device *hdev, struct <token> *hi, <answer> hid_input 
struct hid_field *field, struct <token> *usage, <answer> hid_usage 
unsigned long **bit, int <token> <answer> *max) 
<token> (is_not_elan_touchpad(hdev)) <answer> if 
<token> 0; <answer> return 
if (field->report->id <token> ELAN_SINGLE_FINGER || <answer> == 
field->report->id == ELAN_MT_FIRST_FINGER <token> <answer> || 
field->report->id == <token> || <answer> ELAN_MT_SECOND_FINGER 
field->report->id == <token> <answer> ELAN_MT_I2C) 
return <token> <answer> -1; 
<token> 0; <answer> return 
static int <token> hid_device *hdev, <answer> elan_get_device_param(struct 
unsigned char *dmabuf, unsigned <token> param) <answer> char 
<token> ret; <answer> int 
dmabuf[0] = <token> <answer> ELAN_FEATURE_REPORT; 
dmabuf[1] <token> 0x05; <answer> = 
dmabuf[2] = <token> <answer> 0x03; 
dmabuf[3] <token> param; <answer> = 
dmabuf[4] = <token> <answer> 0x01; 
ret <token> hid_hw_raw_request(hdev, ELAN_FEATURE_REPORT, dmabuf, <answer> = 
<token> HID_FEATURE_REPORT, <answer> ELAN_FEATURE_SIZE, 
<token> (ret != ELAN_FEATURE_SIZE) { <answer> if 
hid_err(hdev, "Set report error for <token> %d: %d\n", param, ret); <answer> parm 
return <token> <answer> ret; 
ret = hid_hw_raw_request(hdev, <token> dmabuf, <answer> ELAN_FEATURE_REPORT, 
ELAN_FEATURE_SIZE, <token> <answer> HID_FEATURE_REPORT, 
if (ret <token> ELAN_FEATURE_SIZE) { <answer> != 
hid_err(hdev, <token> report error for parm %d: %d\n", param, ret); <answer> "Get 
<token> ret; <answer> return 
return <token> <answer> 0; 
static unsigned int <token> val) <answer> elan_convert_res(char 
return (val * 10 + 790) * 10 / <token> <answer> 254; 
<token> int elan_get_device_params(struct hid_device *hdev) <answer> static 
struct elan_drvdata *drvdata = <token> <answer> hid_get_drvdata(hdev); 
<token> char *dmabuf; <answer> unsigned 
<token> ret; <answer> int 
dmabuf <token> kmalloc(ELAN_FEATURE_SIZE, GFP_KERNEL); <answer> = 
<token> (!dmabuf) <answer> if 
<token> -ENOMEM; <answer> return 
ret = <token> dmabuf, ELAN_PARAM_MAX_X); <answer> elan_get_device_param(hdev, 
<token> (ret) <answer> if 
<token> err; <answer> goto 
drvdata->max_x <token> (dmabuf[4] << 8) | dmabuf[3]; <answer> = 
ret = <token> dmabuf, ELAN_PARAM_MAX_Y); <answer> elan_get_device_param(hdev, 
<token> (ret) <answer> if 
<token> err; <answer> goto 
drvdata->max_y = (dmabuf[4] << 8) | <token> <answer> dmabuf[3]; 
ret = elan_get_device_param(hdev, dmabuf, <token> <answer> ELAN_PARAM_RES); 
if <token> <answer> (ret) 
<token> err; <answer> goto 
drvdata->res_x = <token> <answer> elan_convert_res(dmabuf[3]); 
drvdata->res_y <token> elan_convert_res(dmabuf[4]); <answer> = 
<token> ret; <answer> return 
<token> int elan_input_configured(struct hid_device *hdev, struct hid_input *hi) <answer> static 
int <token> <answer> ret; 
struct input_dev <token> <answer> *input; 
struct elan_drvdata *drvdata <token> hid_get_drvdata(hdev); <answer> = 
<token> (is_not_elan_touchpad(hdev)) <answer> if 
<token> 0; <answer> return 
ret = <token> <answer> elan_get_device_params(hdev); 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> = devm_input_allocate_device(&hdev->dev); <answer> input 
if <token> <answer> (!input) 
return <token> <answer> -ENOMEM; 
<token> = "Elan Touchpad"; <answer> input->name 
input->phys = <token> <answer> hdev->phys; 
<token> = hdev->uniq; <answer> input->uniq 
input->id.bustype <token> hdev->bus; <answer> = 
input->id.vendor <token> hdev->vendor; <answer> = 
input->id.product <token> hdev->product; <answer> = 
input->id.version <token> hdev->version; <answer> = 
input->dev.parent <token> &hdev->dev; <answer> = 
input_set_abs_params(input, ABS_MT_POSITION_X, 0, <token> <answer> drvdata->max_x, 
<token> 0); <answer> 0, 
<token> ABS_MT_POSITION_Y, 0, drvdata->max_y, <answer> input_set_abs_params(input, 
0, <token> <answer> 0); 
input_set_abs_params(input, ABS_MT_PRESSURE, <token> ELAN_MAX_PRESSURE, <answer> 0, 
0, <token> <answer> 0); 
__set_bit(BTN_LEFT, <token> <answer> input->keybit); 
<token> input->propbit); <answer> __set_bit(INPUT_PROP_BUTTONPAD, 
ret = input_mt_init_slots(input, <token> INPUT_MT_POINTER); <answer> ELAN_MAX_FINGERS, 
if <token> { <answer> (ret) 
hid_err(hdev, <token> to init elan MT slots: %d\n", ret); <answer> "Failed 
<token> ret; <answer> return 
input_abs_set_res(input, <token> drvdata->res_x); <answer> ABS_X, 
input_abs_set_res(input, ABS_Y, <token> <answer> drvdata->res_y); 
ret = <token> <answer> input_register_device(input); 
<token> (ret) { <answer> if 
hid_err(hdev, "Failed to register elan input <token> %d\n", <answer> device: 
<token> ret; <answer> return 
drvdata->input = <token> <answer> input; 
<token> 0; <answer> return 
static void elan_report_mt_slot(struct elan_drvdata *drvdata, u8 <token> <answer> *data, 
unsigned <token> slot_num) <answer> int 
struct input_dev *input <token> drvdata->input; <answer> = 
<token> x, y, p; <answer> int 
bool active = <token> <answer> !!data; 
<token> slot_num); <answer> input_mt_slot(input, 
input_mt_report_slot_state(input, MT_TOOL_FINGER, <token> <answer> active); 
if (active) <token> <answer> { 
x = ((data[0] & 0xF0) <token> 4) | data[1]; <answer> << 
y <token> drvdata->max_y - <answer> = 
<token> & 0x07) << 8) | data[2]); <answer> (((data[0] 
<token> = data[4]; <answer> p 
input_report_abs(input, <token> x); <answer> ABS_MT_POSITION_X, 
input_report_abs(input, ABS_MT_POSITION_Y, <token> <answer> y); 
input_report_abs(input, <token> p); <answer> ABS_MT_PRESSURE, 
static <token> elan_usb_report_input(struct elan_drvdata *drvdata, u8 *data) <answer> void 
int <token> <answer> i; 
struct input_dev *input = <token> <answer> drvdata->input; 
if (data[0] == <token> { <answer> ELAN_SINGLE_FINGER) 
for (i = 0; i < ELAN_MAX_FINGERS; <token> { <answer> i++) 
if <token> & BIT(i + 3)) <answer> (data[2] 
elan_report_mt_slot(drvdata, data <token> 3, i); <answer> + 
<token> NULL, i); <answer> elan_report_mt_slot(drvdata, 
input_report_key(input, <token> data[2] & 0x01); <answer> BTN_LEFT, 
<token> (data[0] == ELAN_MT_FIRST_FINGER) { <answer> if 
<token> data, <answer> memcpy(drvdata->prev_report, 
if (data[0] == ELAN_MT_SECOND_FINGER) <token> <answer> { 
int <token> = 0; <answer> first 
u8 *prev_report <token> drvdata->prev_report; <answer> = 
<token> (prev_report[0] != ELAN_MT_FIRST_FINGER) <answer> if 
for (i = 0; i < ELAN_MAX_FINGERS; i++) <token> <answer> { 
if (prev_report[2] & BIT(i + 3)) <token> <answer> { 
<token> (!first) { <answer> if 
<token> = 1; <answer> first 
elan_report_mt_slot(drvdata, <token> + 3, i); <answer> prev_report 
} <token> { <answer> else 
elan_report_mt_slot(drvdata, data + 1, <token> <answer> i); 
<token> else { <answer> } 
<token> NULL, i); <answer> elan_report_mt_slot(drvdata, 
input_report_key(input, BTN_LEFT, prev_report[2] <token> 0x01); <answer> & 
static void elan_i2c_report_input(struct elan_drvdata *drvdata, <token> *data) <answer> u8 
struct <token> *input = drvdata->input; <answer> input_dev 
<token> *finger_data; <answer> u8 
<token> i; <answer> int 
finger_data = data + <token> <answer> 2; 
for (i = 0; i <token> ELAN_MAX_FINGERS; i++) { <answer> < 
if (data[1] <token> BIT(i + 3)) { <answer> & 
<token> finger_data, i); <answer> elan_report_mt_slot(drvdata, 
finger_data += <token> <answer> ELAN_FINGER_DATA_LEN; 
} else <token> <answer> { 
<token> NULL, i); <answer> elan_report_mt_slot(drvdata, 
input_report_key(input, BTN_LEFT, <token> & 0x01); <answer> data[1] 
static <token> elan_raw_event(struct hid_device *hdev, <answer> int 
<token> hid_report *report, u8 *data, int size) <answer> struct 
<token> elan_drvdata *drvdata = hid_get_drvdata(hdev); <answer> struct 
if <token> <answer> (is_not_elan_touchpad(hdev)) 
return <token> <answer> 0; 
if (data[0] == ELAN_SINGLE_FINGER <token> <answer> || 
data[0] == ELAN_MT_FIRST_FINGER <token> <answer> || 
<token> == ELAN_MT_SECOND_FINGER) { <answer> data[0] 
if (size == ELAN_INPUT_REPORT_SIZE) <token> <answer> { 
elan_usb_report_input(drvdata, <token> <answer> data); 
return <token> <answer> 1; 
if <token> == ELAN_MT_I2C && size == ELAN_I2C_REPORT_SIZE) { <answer> (data[0] 
<token> data); <answer> elan_i2c_report_input(drvdata, 
<token> 1; <answer> return 
return <token> <answer> 0; 
static int elan_start_multitouch(struct hid_device <token> <answer> *hdev) 
<token> ret; <answer> int 
static const unsigned char <token> = { 0x0D, 0x00, 0x03, 0x21, 0x00 }; <answer> buf[] 
unsigned char *dmabuf = kmemdup(buf, sizeof(buf), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!dmabuf) 
return <token> <answer> -ENOMEM; 
ret = hid_hw_raw_request(hdev, dmabuf[0], dmabuf, <token> <answer> sizeof(buf), 
<token> HID_REQ_SET_REPORT); <answer> HID_FEATURE_REPORT, 
if <token> != sizeof(buf)) { <answer> (ret 
hid_err(hdev, "Failed <token> start multitouch: %d\n", ret); <answer> to 
return <token> <answer> ret; 
<token> 0; <answer> return 
<token> int elan_mute_led_set_brigtness(struct led_classdev *led_cdev, <answer> static 
<token> led_brightness value) <answer> enum 
int <token> <answer> ret; 
u8 <token> <answer> led_state; 
struct device *dev = <token> <answer> led_cdev->dev->parent; 
<token> hid_device *hdev = to_hid_device(dev); <answer> struct 
struct elan_drvdata *drvdata = <token> <answer> hid_get_drvdata(hdev); 
unsigned char <token> = kzalloc(ELAN_LED_REPORT_SIZE, GFP_KERNEL); <answer> *dmabuf 
if <token> <answer> (!dmabuf) 
<token> -ENOMEM; <answer> return 
led_state = <token> <answer> !!value; 
dmabuf[0] = <token> <answer> ELAN_MUTE_LED_REPORT; 
dmabuf[1] <token> 0x02; <answer> = 
dmabuf[2] <token> led_state; <answer> = 
ret <token> hid_hw_raw_request(hdev, dmabuf[0], dmabuf, ELAN_LED_REPORT_SIZE, <answer> = 
<token> HID_REQ_SET_REPORT); <answer> HID_FEATURE_REPORT, 
if <token> != ELAN_LED_REPORT_SIZE) { <answer> (ret 
if (ret <token> -ENODEV) <answer> != 
hid_err(hdev, "Failed to set mute led brightness: %d\n", <token> <answer> ret); 
return ret < 0 <token> ret : -EIO; <answer> ? 
<token> = led_state; <answer> drvdata->mute_led_state 
<token> 0; <answer> return 
<token> int elan_init_mute_led(struct hid_device *hdev) <answer> static 
struct elan_drvdata *drvdata = <token> <answer> hid_get_drvdata(hdev); 
struct <token> *mute_led = &drvdata->mute_led; <answer> led_classdev 
<token> = "elan:red:mute"; <answer> mute_led->name 
mute_led->default_trigger <token> "audio-mute"; <answer> = 
<token> = elan_mute_led_set_brigtness; <answer> mute_led->brightness_set_blocking 
<token> = LED_ON; <answer> mute_led->max_brightness 
mute_led->flags <token> LED_HW_PLUGGABLE; <answer> = 
mute_led->dev <token> &hdev->dev; <answer> = 
<token> devm_led_classdev_register(&hdev->dev, mute_led); <answer> return 
static int elan_probe(struct hid_device *hdev, <token> struct hid_device_id *id) <answer> const 
int <token> <answer> ret; 
struct elan_drvdata <token> <answer> *drvdata; 
drvdata <token> devm_kzalloc(&hdev->dev, sizeof(*drvdata), GFP_KERNEL); <answer> = 
<token> (!drvdata) <answer> if 
<token> -ENOMEM; <answer> return 
hid_set_drvdata(hdev, <token> <answer> drvdata); 
ret <token> hid_parse(hdev); <answer> = 
if <token> { <answer> (ret) 
hid_err(hdev, "Hid Parse <token> <answer> failed\n"); 
<token> ret; <answer> return 
ret <token> hid_hw_start(hdev, HID_CONNECT_DEFAULT); <answer> = 
<token> (ret) { <answer> if 
<token> "Hid hw start failed\n"); <answer> hid_err(hdev, 
<token> ret; <answer> return 
if <token> <answer> (is_not_elan_touchpad(hdev)) 
<token> 0; <answer> return 
<token> (!drvdata->input) { <answer> if 
hid_err(hdev, <token> device is not registered\n"); <answer> "Input 
<token> = -ENAVAIL; <answer> ret 
goto <token> <answer> err; 
<token> = elan_start_multitouch(hdev); <answer> ret 
<token> (ret) <answer> if 
goto <token> <answer> err; 
if <token> & ELAN_HAS_LED) { <answer> (id->driver_data 
ret = <token> <answer> elan_init_mute_led(hdev); 
if <token> <answer> (ret) 
<token> err; <answer> goto 
return <token> <answer> 0; 
return <token> <answer> ret; 
<token> const struct hid_device_id elan_devices[] = { <answer> static 
{ <token> USB_DEVICE_ID_HP_X2), <answer> HID_USB_DEVICE(USB_VENDOR_ID_ELAN, 
.driver_data <token> ELAN_HAS_LED }, <answer> = 
{ HID_USB_DEVICE(USB_VENDOR_ID_ELAN, <token> <answer> USB_DEVICE_ID_HP_X2_10_COVER), 
<token> = ELAN_HAS_LED }, <answer> .driver_data 
<token> HID_I2C_DEVICE(USB_VENDOR_ID_ELAN, USB_DEVICE_ID_TOSHIBA_CLICK_L9W) }, <answer> { 
{ <token> <answer> } 
MODULE_DEVICE_TABLE(hid, <token> <answer> elan_devices); 
static struct hid_driver <token> = { <answer> elan_driver 
<token> = "elan", <answer> .name 
.id_table <token> elan_devices, <answer> = 
.input_mapping = <token> <answer> elan_input_mapping, 
.input_configured = <token> <answer> elan_input_configured, 
.raw_event <token> elan_raw_event, <answer> = 
.probe <token> elan_probe, <answer> = 
MODULE_AUTHOR("Alexandrov <token> <answer> Stanislav"); 
MODULE_DESCRIPTION("Driver for HID ELAN <token> <answer> Touchpads"); 
return <token> <answer> NULL; 
static void llist_abort_desc(struct idxd_wq <token> struct idxd_irq_entry *ie, <answer> *wq, 
<token> idxd_desc *desc) <answer> struct 
struct idxd_desc *d, *t, <token> = NULL; <answer> *found 
struct llist_node <token> <answer> *head; 
desc->completion->status = <token> <answer> IDXD_COMP_DESC_ABORT; 
head = <token> <answer> llist_del_all(&ie->pending_llist); 
if (head) <token> <answer> { 
llist_for_each_entry_safe(d, t, <token> llnode) { <answer> head, 
if (d == desc) <token> <answer> { 
found <token> desc; <answer> = 
if <token> <answer> (d->completion->status) 
list_add_tail(&d->list, <token> <answer> &flist); 
list_add_tail(&d->list, <token> <answer> &ie->work_list); 
if <token> <answer> (!found) 
found = list_abort_desc(wq, <token> desc); <answer> ie, 
if <token> <answer> (found) 
idxd_dma_complete_txd(found, IDXD_COMPLETE_ABORT, <token> <answer> false, 
NULL, <token> <answer> NULL); 
<token> t, &flist, list) { <answer> list_for_each_entry_safe(d, 
<token> IDXD_COMPLETE_ABORT, true, <answer> idxd_dma_complete_txd(found, 
NULL, <token> <answer> NULL); 
int idxd_enqcmds(struct idxd_wq *wq, void __iomem *portal, <token> void *desc) <answer> const 
unsigned int retries = <token> <answer> wq->enqcmds_retries; 
<token> rc; <answer> int 
do <token> <answer> { 
rc = enqcmds(portal, <token> <answer> desc); 
<token> (rc == 0) <answer> if 
<token> while (retries--); <answer> } 
return <token> <answer> rc; 
int idxd_submit_desc(struct idxd_wq <token> struct idxd_desc *desc) <answer> *wq, 
struct idxd_device <token> = wq->idxd; <answer> *idxd 
struct idxd_irq_entry *ie <token> NULL; <answer> = 
u32 desc_flags <token> desc->hw->flags; <answer> = 
void __iomem <token> <answer> *portal; 
int <token> <answer> rc; 
if (idxd->state <token> IDXD_DEV_ENABLED) <answer> != 
<token> -EIO; <answer> return 
if (!percpu_ref_tryget_live(&wq->wq_active)) <token> <answer> { 
<token> (!percpu_ref_tryget_live(&wq->wq_active)) <answer> if 
return <token> <answer> -ENXIO; 
<token> = idxd_wq_portal_addr(wq); <answer> portal 
if (desc_flags <token> IDXD_OP_FLAG_RCI) { <answer> & 
ie <token> &wq->ie; <answer> = 
<token> = ie->int_handle; <answer> desc->hw->int_handle 
<token> &ie->pending_llist); <answer> llist_add(&desc->llnode, 
if <token> { <answer> (wq_dedicated(wq)) 
iosubmit_cmds512(portal, desc->hw, <token> <answer> 1); 
<token> else { <answer> } 
rc = idxd_enqcmds(wq, <token> desc->hw); <answer> portal, 
if <token> < 0) { <answer> (rc 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <linux/types.h> 
#include <token> <answer> <linux/pci.h> 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> "vnic_dev.h" 
<token> "vnic_wq.h" <answer> #include 
static inline int vnic_wq_get_ctrl(struct <token> *vdev, struct vnic_wq *wq, <answer> vnic_dev 
unsigned int <token> enum vnic_res_type res_type) <answer> index, 
wq->ctrl = svnic_dev_get_res(vdev, <token> index); <answer> res_type, 
if <token> <answer> (!wq->ctrl) 
return <token> <answer> -EINVAL; 
<token> 0; <answer> return 
<token> inline int vnic_wq_alloc_ring(struct vnic_dev *vdev, struct vnic_wq *wq, <answer> static 
<token> int index, unsigned int desc_count, unsigned int desc_size) <answer> unsigned 
return svnic_dev_alloc_desc_ring(vdev, <token> desc_count, <answer> &wq->ring, 
static int vnic_wq_alloc_bufs(struct vnic_wq <token> <answer> *wq) 
struct vnic_wq_buf <token> <answer> *buf; 
<token> int i, j, count = wq->ring.desc_count; <answer> unsigned 
unsigned <token> blks = VNIC_WQ_BUF_BLKS_NEEDED(count); <answer> int 
for (i = 0; i < blks; i++) <token> <answer> { 
wq->bufs[i] <token> kzalloc(VNIC_WQ_BUF_BLK_SZ, GFP_ATOMIC); <answer> = 
if <token> { <answer> (!wq->bufs[i]) 
pr_err("Failed to alloc <token> <answer> wq_bufs\n"); 
return <token> <answer> -ENOMEM; 
for (i <token> 0; i < blks; i++) { <answer> = 
<token> = wq->bufs[i]; <answer> buf 
for (j = 0; j < <token> j++) { <answer> VNIC_WQ_BUF_DFLT_BLK_ENTRIES; 
buf->index <token> i * VNIC_WQ_BUF_DFLT_BLK_ENTRIES + j; <answer> = 
buf->desc <token> (u8 *)wq->ring.descs + <answer> = 
wq->ring.desc_size <token> buf->index; <answer> * 
if (buf->index + 1 == count) <token> <answer> { 
buf->next <token> wq->bufs[0]; <answer> = 
<token> else if (j + 1 == VNIC_WQ_BUF_DFLT_BLK_ENTRIES) { <answer> } 
<token> = wq->bufs[i + 1]; <answer> buf->next 
<token> else { <answer> } 
buf->next = buf + <token> <answer> 1; 
wq->to_use = <token> = wq->bufs[0]; <answer> wq->to_clean 
return <token> <answer> 0; 
void svnic_wq_free(struct vnic_wq <token> <answer> *wq) 
struct vnic_dev <token> <answer> *vdev; 
<token> int i; <answer> unsigned 
<token> = wq->vdev; <answer> vdev 
<token> &wq->ring); <answer> svnic_dev_free_desc_ring(vdev, 
for (i = 0; i < VNIC_WQ_BUF_BLKS_MAX; i++) <token> <answer> { 
wq->bufs[i] <token> NULL; <answer> = 
wq->ctrl <token> NULL; <answer> = 
int vnic_wq_devcmd2_alloc(struct vnic_dev *vdev, struct <token> *wq, <answer> vnic_wq 
<token> int desc_count, unsigned int desc_size) <answer> unsigned 
int <token> <answer> err; 
wq->index <token> 0; <answer> = 
wq->vdev = <token> <answer> vdev; 
err <token> vnic_wq_get_ctrl(vdev, wq, 0, RES_TYPE_DEVCMD2); <answer> = 
if <token> { <answer> (err) 
pr_err("Failed to <token> devcmd2 resource\n"); <answer> get 
<token> err; <answer> return 
<token> = vnic_wq_alloc_ring(vdev, wq, 0, desc_count, desc_size); <answer> err 
if <token> <answer> (err) 
return <token> <answer> err; 
<token> 0; <answer> return 
int svnic_wq_alloc(struct vnic_dev *vdev, struct vnic_wq <token> <answer> *wq, 
unsigned int index, unsigned int desc_count, <token> int desc_size) <answer> unsigned 
<token> err; <answer> int 
<token> = index; <answer> wq->index 
<token> = vdev; <answer> wq->vdev 
err = vnic_wq_get_ctrl(vdev, wq, <token> RES_TYPE_WQ); <answer> index, 
if (err) <token> <answer> { 
pr_err("Failed to hook WQ[%d] resource\n", <token> <answer> index); 
<token> err; <answer> return 
err = vnic_wq_alloc_ring(vdev, wq, <token> desc_count, desc_size); <answer> index, 
if <token> <answer> (err) 
return <token> <answer> err; 
err = <token> <answer> vnic_wq_alloc_bufs(wq); 
if <token> { <answer> (err) 
return <token> <answer> err; 
<token> 0; <answer> return 
<token> vnic_wq_init_start(struct vnic_wq *wq, unsigned int cq_index, <answer> void 
unsigned int fetch_index, unsigned int <token> <answer> posted_index, 
<token> int error_interrupt_enable, <answer> unsigned 
<token> int error_interrupt_offset) <answer> unsigned 
<token> paddr; <answer> u64 
unsigned int count <token> wq->ring.desc_count; <answer> = 
paddr <token> (u64)wq->ring.base_addr | VNIC_PADDR_TARGET; <answer> = 
<token> &wq->ctrl->ring_base); <answer> writeq(paddr, 
iowrite32(count, <token> <answer> &wq->ctrl->ring_size); 
<token> &wq->ctrl->fetch_index); <answer> iowrite32(fetch_index, 
iowrite32(posted_index, <token> <answer> &wq->ctrl->posted_index); 
iowrite32(cq_index, <token> <answer> &wq->ctrl->cq_index); 
<token> &wq->ctrl->error_interrupt_enable); <answer> iowrite32(error_interrupt_enable, 
<token> &wq->ctrl->error_interrupt_offset); <answer> iowrite32(error_interrupt_offset, 
iowrite32(0, <token> <answer> &wq->ctrl->error_status); 
wq->to_use <token> wq->to_clean = <answer> = 
&wq->bufs[fetch_index <token> VNIC_WQ_BUF_BLK_ENTRIES(count)] <answer> / 
[fetch_index % <token> <answer> VNIC_WQ_BUF_BLK_ENTRIES(count)]; 
void svnic_wq_init(struct vnic_wq *wq, unsigned <token> cq_index, <answer> int 
unsigned <token> error_interrupt_enable, <answer> int 
unsigned int <token> <answer> error_interrupt_offset) 
vnic_wq_init_start(wq, cq_index, 0, 0, <token> <answer> error_interrupt_enable, 
unsigned int svnic_wq_error_status(struct <token> *wq) <answer> vnic_wq 
return <token> <answer> ioread32(&wq->ctrl->error_status); 
void <token> vnic_wq *wq) <answer> svnic_wq_enable(struct 
iowrite32(1, <token> <answer> &wq->ctrl->enable); 
int <token> vnic_wq *wq) <answer> svnic_wq_disable(struct 
unsigned int <token> <answer> wait; 
<token> &wq->ctrl->enable); <answer> iowrite32(0, 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/export.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/errno.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <asm/mach-au1x00/au1000.h> <answer> #include 
<token> <asm/mach-au1x00/au1000_dma.h> <answer> #include 
int request_au1000_dma(int dev_id, const char <token> <answer> *dev_str, 
<token> irqhandler, <answer> irq_handler_t 
unsigned <token> irqflags, <answer> long 
<token> *irq_dev_id) <answer> void 
struct <token> *chan; <answer> dma_chan 
const <token> dma_dev *dev; <answer> struct 
<token> i, ret; <answer> int 
if (alchemy_get_cputype() == <token> { <answer> ALCHEMY_CPU_AU1100) 
if (dev_id < <token> || dev_id >= (DMA_NUM_DEV + DMA_NUM_DEV_BANK2)) <answer> 0 
<token> -EINVAL; <answer> return 
} <token> { <answer> else 
if (dev_id < 0 || <token> >= DMA_NUM_DEV) <answer> dev_id 
return <token> <answer> -EINVAL; 
for (i = 0; <token> < NUM_AU1000_DMA_CHANNELS; i++) <answer> i 
if (au1000_dma_table[i].dev_id <token> 0) <answer> < 
if (i <token> NUM_AU1000_DMA_CHANNELS) <answer> == 
<token> -ENODEV; <answer> return 
<token> = &au1000_dma_table[i]; <answer> chan 
if <token> >= DMA_NUM_DEV) { <answer> (dev_id 
dev_id <token> DMA_NUM_DEV; <answer> -= 
<token> = &dma_dev_table_bank2[dev_id]; <answer> dev 
<token> else <answer> } 
<token> = &dma_dev_table[dev_id]; <answer> dev 
if <token> { <answer> (irqhandler) 
chan->irq_dev = <token> <answer> irq_dev_id; 
ret = request_irq(chan->irq, <token> irqflags, dev_str, <answer> irqhandler, 
if <token> { <answer> (ret) 
chan->irq_dev = <token> <answer> NULL; 
return <token> <answer> ret; 
<token> else { <answer> } 
chan->irq_dev <token> NULL; <answer> = 
#include <token> <answer> <linux/bits.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/mod_devicetable.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/pm_wakeup.h> <answer> #include 
<token> <linux/pm_wakeirq.h> <answer> #include 
#include <token> <answer> <linux/regmap.h> 
<token> <linux/regulator/consumer.h> <answer> #include 
<token> <linux/usb/tcpci.h> <answer> #include 
<token> <linux/usb/tcpm.h> <answer> #include 
#define <token> 0x9B <answer> MT6370_REG_SYSCTRL8 
#define MT6370_AUTOIDLE_MASK <token> <answer> BIT(3) 
<token> MT6370_VENDOR_ID 0x29CF <answer> #define 
#define <token> 0x2170 <answer> MT6370_TCPC_DID_A 
struct <token> { <answer> mt6370_priv 
struct device <token> <answer> *dev; 
<token> regulator *vbus; <answer> struct 
<token> tcpci *tcpci; <answer> struct 
struct <token> tcpci_data; <answer> tcpci_data 
<token> const struct reg_sequence mt6370_reg_init[] = { <answer> static 
REG_SEQ(0xA0, <token> 1000), <answer> 0x1, 
<token> 0x38, 0), <answer> REG_SEQ(0x81, 
REG_SEQ(0x82, 0x82, <token> <answer> 0), 
REG_SEQ(0xBA, <token> 0), <answer> 0xFC, 
<token> 0x50, 0), <answer> REG_SEQ(0xBB, 
REG_SEQ(0x9E, 0x8F, <token> <answer> 0), 
REG_SEQ(0xA1, <token> 0), <answer> 0x5, 
REG_SEQ(0xA2, <token> 0), <answer> 0x4, 
REG_SEQ(0xA3, 0x4A, <token> <answer> 0), 
REG_SEQ(0xA4, <token> 0), <answer> 0x01, 
REG_SEQ(0x95, <token> 0), <answer> 0x01, 
<token> 0x71, 0), <answer> REG_SEQ(0x80, 
<token> 0x3A, 1000), <answer> REG_SEQ(0x9B, 
static int mt6370_tcpc_init(struct tcpci *tcpci, <token> tcpci_data *data) <answer> struct 
u16 <token> <answer> did; 
<token> ret; <answer> int 
ret = <token> mt6370_reg_init, <answer> regmap_register_patch(data->regmap, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> = regmap_raw_read(data->regmap, TCPC_BCD_DEV, &did, sizeof(u16)); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if (did == <token> <answer> MT6370_TCPC_DID_A) 
return regmap_write(data->regmap, <token> 0x80); <answer> TCPC_FAULT_CTRL, 
<token> 0; <answer> return 
static int <token> tcpci *tcpci, struct tcpci_data *data, <answer> mt6370_tcpc_set_vconn(struct 
bool <token> <answer> enable) 
return regmap_update_bits(data->regmap, <token> <answer> MT6370_REG_SYSCTRL8, 
<token> ? 0 : MT6370_AUTOIDLE_MASK); <answer> enable 
static int <token> tcpci *tcpci, struct tcpci_data *data, <answer> mt6370_tcpc_set_vbus(struct 
bool <token> bool sink) <answer> source, 
<token> mt6370_priv *priv = container_of(data, struct mt6370_priv, <answer> struct 
<token> ret; <answer> int 
<token> = regulator_is_enabled(priv->vbus); <answer> ret 
if (ret < <token> <answer> 0) 
return <token> <answer> ret; 
if (ret && <token> <answer> !source) 
<token> regulator_disable(priv->vbus); <answer> return 
if <token> && source) <answer> (!ret 
return <token> <answer> regulator_enable(priv->vbus); 
<token> 0; <answer> return 
<token> irqreturn_t mt6370_irq_handler(int irq, void *dev_id) <answer> static 
struct mt6370_priv *priv <token> dev_id; <answer> = 
return <token> <answer> tcpci_irq(priv->tcpci); 
static int mt6370_check_vendor_info(struct mt6370_priv <token> <answer> *priv) 
struct regmap <token> = priv->tcpci_data.regmap; <answer> *regmap 
u16 <token> <answer> vid; 
<token> ret; <answer> int 
<token> = regmap_raw_read(regmap, TCPC_VENDOR_ID, &vid, sizeof(u16)); <answer> ret 
<token> (ret) <answer> if 
return <token> <answer> ret; 
if (vid <token> MT6370_VENDOR_ID) <answer> != 
return dev_err_probe(priv->dev, <token> <answer> -ENODEV, 
"Vendor <token> not correct 0x%02x\n", vid); <answer> ID 
<token> 0; <answer> return 
<token> void mt6370_unregister_tcpci_port(void *tcpci) <answer> static 
static int <token> platform_device *pdev) <answer> mt6370_tcpc_probe(struct 
struct <token> *priv; <answer> mt6370_priv 
<token> device *dev = &pdev->dev; <answer> struct 
int irq, <token> <answer> ret; 
priv = devm_kzalloc(dev, <token> GFP_KERNEL); <answer> sizeof(*priv), 
if <token> <answer> (!priv) 
<token> -ENOMEM; <answer> return 
<token> = dev; <answer> priv->dev 
priv->tcpci_data.regmap = <token> NULL); <answer> dev_get_regmap(dev->parent, 
if <token> <answer> (!priv->tcpci_data.regmap) 
return <token> -ENODEV, "Failed to init regmap\n"); <answer> dev_err_probe(dev, 
ret = <token> <answer> mt6370_check_vendor_info(priv); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
irq = platform_get_irq(pdev, <token> <answer> 0); 
if (irq <token> 0) <answer> < 
<token> irq; <answer> return 
<token> <linux/kvm.h> <answer> #include 
#include <token> <answer> <linux/kvm_host.h> 
#include <token> <answer> <asm/kvm_emulate.h> 
#include <token> <answer> <asm/kvm_nested.h> 
<token> <asm/sysreg.h> <answer> #include 
#include <token> <answer> "sys_regs.h" 
static u64 limit_nv_id_reg(u32 id, u64 <token> <answer> val) 
u64 <token> <answer> tmp; 
switch <token> { <answer> (id) 
case <token> <answer> SYS_ID_AA64ISAR0_EL1: 
<token> (PAGE_SIZE) { <answer> switch 
<token> SZ_4K: <answer> case 
val |= FIELD_PREP(NV_FTR(MMFR0, <token> 0b0010); <answer> TGRAN4_2), 
case <token> <answer> SZ_16K: 
val |= <token> TGRAN16_2), 0b0010); <answer> FIELD_PREP(NV_FTR(MMFR0, 
case <token> <answer> SZ_64K: 
val <token> FIELD_PREP(NV_FTR(MMFR0, TGRAN64_2), 0b0010); <answer> |= 
<token> <stdio.h> <answer> #include 
<token> <unistd.h> <answer> #include 
<token> <stdlib.h> <answer> #include 
#include <token> <answer> <ctype.h> 
#include <token> <answer> <stdbool.h> 
#include <token> <answer> <stdarg.h> 
<token> <setjmp.h> <answer> #include 
<token> <linux/filter.h> <answer> #include 
#include <token> <answer> <linux/if_packet.h> 
<token> <readline/readline.h> <answer> #include 
#include <token> <answer> <readline/history.h> 
#include <token> <answer> <sys/types.h> 
#include <token> <answer> <sys/socket.h> 
#include <token> <answer> <sys/stat.h> 
#include <token> <answer> <sys/mman.h> 
#include <token> <answer> <fcntl.h> 
<token> <errno.h> <answer> #include 
#include <token> <answer> <signal.h> 
<token> <arpa/inet.h> <answer> #include 
#include <token> <answer> <net/ethernet.h> 
#define <token> 0xa1b2c3d4 <answer> TCPDUMP_MAGIC 
<token> BPF_LDX_B (BPF_LDX | BPF_B) <answer> #define 
<token> BPF_LDX_W (BPF_LDX | BPF_W) <answer> #define 
#define BPF_JMP_JA (BPF_JMP | <token> <answer> BPF_JA) 
#define <token> (BPF_JMP | BPF_JEQ) <answer> BPF_JMP_JEQ 
<token> BPF_JMP_JGT (BPF_JMP | BPF_JGT) <answer> #define 
#define <token> (BPF_JMP | BPF_JGE) <answer> BPF_JMP_JGE 
<token> BPF_JMP_JSET (BPF_JMP | BPF_JSET) <answer> #define 
#define BPF_ALU_ADD (BPF_ALU <token> BPF_ADD) <answer> | 
#define <token> (BPF_ALU | BPF_SUB) <answer> BPF_ALU_SUB 
#define BPF_ALU_MUL <token> | BPF_MUL) <answer> (BPF_ALU 
<token> BPF_ALU_DIV (BPF_ALU | BPF_DIV) <answer> #define 
#define BPF_ALU_MOD <token> | BPF_MOD) <answer> (BPF_ALU 
#define BPF_ALU_NEG (BPF_ALU <token> BPF_NEG) <answer> | 
#define BPF_ALU_AND (BPF_ALU | <token> <answer> BPF_AND) 
#define BPF_ALU_OR (BPF_ALU | <token> <answer> BPF_OR) 
#define <token> (BPF_ALU | BPF_XOR) <answer> BPF_ALU_XOR 
#define <token> (BPF_ALU | BPF_LSH) <answer> BPF_ALU_LSH 
#define BPF_ALU_RSH <token> | BPF_RSH) <answer> (BPF_ALU 
#define BPF_MISC_TAX <token> | BPF_TAX) <answer> (BPF_MISC 
#define BPF_MISC_TXA <token> | BPF_TXA) <answer> (BPF_MISC 
<token> BPF_LD_B (BPF_LD | BPF_B) <answer> #define 
<token> BPF_LD_H (BPF_LD | BPF_H) <answer> #define 
#define <token> (BPF_LD | BPF_W) <answer> BPF_LD_W 
<token> array_size <answer> #ifndef 
# define <token> (sizeof(x) / sizeof((x)[0])) <answer> array_size(x) 
#ifndef <token> <answer> __check_format_printf 
# define <token> pos_fmtargs) \ <answer> __check_format_printf(pos_fmtstr, 
__attribute__ ((format (printf, <token> (pos_fmtargs)))) <answer> (pos_fmtstr), 
<token> { <answer> enum 
struct <token> { <answer> shell_cmd 
<token> char *name; <answer> const 
int (*func)(char <token> <answer> *args); 
<token> pcap_filehdr { <answer> struct 
uint32_t <token> <answer> magic; 
<token> version_major; <answer> uint16_t 
uint16_t <token> <answer> version_minor; 
int32_t <token> <answer> thiszone; 
<token> sigfigs; <answer> uint32_t 
uint32_t <token> <answer> snaplen; 
<token> linktype; <answer> uint32_t 
struct pcap_timeval <token> <answer> { 
int32_t <token> <answer> tv_sec; 
int32_t <token> <answer> tv_usec; 
<token> pcap_pkthdr { <answer> struct 
<token> pcap_timeval ts; <answer> struct 
<token> caplen; <answer> uint32_t 
<token> len; <answer> uint32_t 
struct <token> { <answer> bpf_regs 
uint32_t <token> <answer> A; 
<token> X; <answer> uint32_t 
uint32_t <token> <answer> M[BPF_MEMWORDS]; 
<token> R; <answer> uint32_t 
<token> Rs; <answer> bool 
uint16_t <token> <answer> Pc; 
<token> struct sock_filter bpf_image[BPF_MAXINSNS + 1]; <answer> static 
static <token> int bpf_prog_len; <answer> unsigned 
static <token> bpf_breakpoints[64]; <answer> int 
static struct bpf_regs bpf_regs[BPF_MAXINSNS <token> 1]; <answer> + 
static struct <token> bpf_curr; <answer> bpf_regs 
<token> unsigned int bpf_regs_len; <answer> static 
static int pcap_fd <token> -1; <answer> = 
static unsigned <token> pcap_packet; <answer> int 
<token> size_t pcap_map_size; <answer> static 
static char <token> *pcap_ptr_va_curr; <answer> *pcap_ptr_va_start, 
static const char * const op_table[] = <token> <answer> { 
[BPF_ST] <token> "st", <answer> = 
[BPF_STX] <token> "stx", <answer> = 
[BPF_LD_B] <token> "ldb", <answer> = 
<token> = "ldh", <answer> [BPF_LD_H] 
<token> = "ld", <answer> [BPF_LD_W] 
<token> = "ldx", <answer> [BPF_LDX] 
[BPF_LDX_B] <token> "ldxb", <answer> = 
[BPF_JMP_JA] = <token> <answer> "ja", 
[BPF_JMP_JEQ] <token> "jeq", <answer> = 
[BPF_JMP_JGT] = <token> <answer> "jgt", 
[BPF_JMP_JGE] = <token> <answer> "jge", 
[BPF_JMP_JSET] <token> "jset", <answer> = 
<token> = "add", <answer> [BPF_ALU_ADD] 
[BPF_ALU_SUB] = <token> <answer> "sub", 
[BPF_ALU_MUL] = <token> <answer> "mul", 
[BPF_ALU_DIV] <token> "div", <answer> = 
<token> = "mod", <answer> [BPF_ALU_MOD] 
[BPF_ALU_NEG] <token> "neg", <answer> = 
[BPF_ALU_AND] = <token> <answer> "and", 
[BPF_ALU_OR] = <token> <answer> "or", 
[BPF_ALU_XOR] = <token> <answer> "xor", 
<token> = "lsh", <answer> [BPF_ALU_LSH] 
[BPF_ALU_RSH] = <token> <answer> "rsh", 
[BPF_MISC_TAX] <token> "tax", <answer> = 
[BPF_MISC_TXA] <token> "txa", <answer> = 
[BPF_RET] <token> "ret", <answer> = 
static __check_format_printf(1, 2) int rl_printf(const char *fmt, <token> <answer> ...) 
<token> ret; <answer> int 
va_list <token> <answer> vl; 
<token> fmt); <answer> va_start(vl, 
ret = <token> fmt, vl); <answer> vfprintf(rl_outstream, 
<token> ret; <answer> return 
static int matches(const char *cmd, <token> char *pattern) <answer> const 
<token> len = strlen(cmd); <answer> int 
if (len <token> strlen(pattern)) <answer> > 
<token> -1; <answer> return 
return memcmp(pattern, cmd, <token> <answer> len); 
static void hex_dump(const uint8_t *buf, <token> len) <answer> size_t 
<token> i; <answer> int 
rl_printf("%3u: <token> 0); <answer> ", 
for (i = <token> i < len; i++) { <answer> 0; 
if (i && !(i % <token> <answer> 16)) 
rl_printf("\n%3u: <token> i); <answer> ", 
<token> ", buf[i]); <answer> rl_printf("%02x 
static bool <token> <answer> bpf_prog_loaded(void) 
<token> (bpf_prog_len == 0) <answer> if 
rl_printf("no bpf program <token> <answer> loaded!\n"); 
return <token> > 0; <answer> bpf_prog_len 
static void bpf_disasm(const struct sock_filter f, unsigned int <token> <answer> i) 
const char *op, <token> <answer> *fmt; 
int <token> = f.k; <answer> val 
char <token> <answer> buf[256]; 
<token> (f.code) { <answer> switch 
case BPF_RET | <token> <answer> BPF_K: 
<token> = op_table[BPF_RET]; <answer> op 
fmt = <token> <answer> "#%#x"; 
<token> BPF_RET | BPF_A: <answer> case 
<token> = op_table[BPF_RET]; <answer> op 
<token> = "a"; <answer> fmt 
case BPF_RET <token> BPF_X: <answer> | 
op <token> op_table[BPF_RET]; <answer> = 
fmt = <token> <answer> "x"; 
<token> BPF_MISC_TAX: <answer> case 
<token> = op_table[BPF_MISC_TAX]; <answer> op 
fmt <token> ""; <answer> = 
case <token> <answer> BPF_MISC_TXA: 
op = <token> <answer> op_table[BPF_MISC_TXA]; 
fmt <token> ""; <answer> = 
case <token> <answer> BPF_ST: 
<token> = op_table[BPF_ST]; <answer> op 
fmt = <token> <answer> "M[%d]"; 
<token> BPF_STX: <answer> case 
<token> = op_table[BPF_STX]; <answer> op 
fmt = <token> <answer> "M[%d]"; 
case BPF_LD_W <token> BPF_ABS: <answer> | 
op = <token> <answer> op_table[BPF_LD_W]; 
fmt = <token> <answer> "[%d]"; 
case <token> | BPF_ABS: <answer> BPF_LD_H 
op <token> op_table[BPF_LD_H]; <answer> = 
fmt = <token> <answer> "[%d]"; 
case BPF_LD_B | <token> <answer> BPF_ABS: 
op <token> op_table[BPF_LD_B]; <answer> = 
fmt = <token> <answer> "[%d]"; 
case BPF_LD_W | <token> <answer> BPF_LEN: 
op <token> op_table[BPF_LD_W]; <answer> = 
fmt = <token> <answer> "#len"; 
case <token> | BPF_IND: <answer> BPF_LD_W 
<token> = op_table[BPF_LD_W]; <answer> op 
fmt <token> "[x+%d]"; <answer> = 
case BPF_LD_H | <token> <answer> BPF_IND: 
op <token> op_table[BPF_LD_H]; <answer> = 
fmt = <token> <answer> "[x+%d]"; 
case <token> | BPF_IND: <answer> BPF_LD_B 
<token> = op_table[BPF_LD_B]; <answer> op 
<token> = "[x+%d]"; <answer> fmt 
case BPF_LD <token> BPF_IMM: <answer> | 
<token> = op_table[BPF_LD_W]; <answer> op 
fmt <token> "#%#x"; <answer> = 
case BPF_LDX <token> BPF_IMM: <answer> | 
op = <token> <answer> op_table[BPF_LDX]; 
fmt <token> "#%#x"; <answer> = 
case BPF_LDX_B | <token> <answer> BPF_MSH: 
op <token> op_table[BPF_LDX_B]; <answer> = 
fmt <token> "4*([%d]&0xf)"; <answer> = 
case BPF_LD | <token> <answer> BPF_MEM: 
op = <token> <answer> op_table[BPF_LD_W]; 
fmt <token> "M[%d]"; <answer> = 
case BPF_LDX | <token> <answer> BPF_MEM: 
<token> = op_table[BPF_LDX]; <answer> op 
<token> = "M[%d]"; <answer> fmt 
<token> BPF_JMP_JA: <answer> case 
op = <token> <answer> op_table[BPF_JMP_JA]; 
fmt = <token> <answer> "%d"; 
val = i + 1 <token> f.k; <answer> + 
case BPF_JMP_JGT <token> BPF_X: <answer> | 
op = <token> <answer> op_table[BPF_JMP_JGT]; 
fmt <token> "x"; <answer> = 
<token> BPF_JMP_JGT | BPF_K: <answer> case 
<token> = op_table[BPF_JMP_JGT]; <answer> op 
fmt <token> "#%#x"; <answer> = 
case <token> | BPF_X: <answer> BPF_JMP_JGE 
op = <token> <answer> op_table[BPF_JMP_JGE]; 
<token> = "x"; <answer> fmt 
case BPF_JMP_JGE <token> BPF_K: <answer> | 
<token> = op_table[BPF_JMP_JGE]; <answer> op 
<token> = "#%#x"; <answer> fmt 
<token> BPF_JMP_JEQ | BPF_X: <answer> case 
<token> = op_table[BPF_JMP_JEQ]; <answer> op 
fmt = <token> <answer> "x"; 
case BPF_JMP_JEQ <token> BPF_K: <answer> | 
op <token> op_table[BPF_JMP_JEQ]; <answer> = 
fmt = <token> <answer> "#%#x"; 
case <token> | BPF_X: <answer> BPF_JMP_JSET 
<token> = op_table[BPF_JMP_JSET]; <answer> op 
fmt <token> "x"; <answer> = 
case BPF_JMP_JSET <token> BPF_K: <answer> | 
op <token> op_table[BPF_JMP_JSET]; <answer> = 
<token> = "#%#x"; <answer> fmt 
<token> BPF_ALU_NEG: <answer> case 
<token> = op_table[BPF_ALU_NEG]; <answer> op 
<token> = ""; <answer> fmt 
case BPF_ALU_LSH <token> BPF_X: <answer> | 
<token> = op_table[BPF_ALU_LSH]; <answer> op 
fmt <token> "x"; <answer> = 
<token> BPF_ALU_LSH | BPF_K: <answer> case 
<token> = op_table[BPF_ALU_LSH]; <answer> op 
fmt = <token> <answer> "#%d"; 
case <token> | BPF_X: <answer> BPF_ALU_RSH 
op <token> op_table[BPF_ALU_RSH]; <answer> = 
fmt <token> "x"; <answer> = 
case BPF_ALU_RSH <token> BPF_K: <answer> | 
<token> = op_table[BPF_ALU_RSH]; <answer> op 
fmt = <token> <answer> "#%d"; 
case BPF_ALU_ADD | <token> <answer> BPF_X: 
op <token> op_table[BPF_ALU_ADD]; <answer> = 
fmt = <token> <answer> "x"; 
case <token> | BPF_K: <answer> BPF_ALU_ADD 
op = <token> <answer> op_table[BPF_ALU_ADD]; 
<token> = "#%d"; <answer> fmt 
case <token> | BPF_X: <answer> BPF_ALU_SUB 
op = <token> <answer> op_table[BPF_ALU_SUB]; 
<token> = "x"; <answer> fmt 
case BPF_ALU_SUB <token> BPF_K: <answer> | 
op = <token> <answer> op_table[BPF_ALU_SUB]; 
<token> = "#%d"; <answer> fmt 
case BPF_ALU_MUL | <token> <answer> BPF_X: 
<token> = op_table[BPF_ALU_MUL]; <answer> op 
<token> = "x"; <answer> fmt 
case <token> | BPF_K: <answer> BPF_ALU_MUL 
op = <token> <answer> op_table[BPF_ALU_MUL]; 
<token> = "#%d"; <answer> fmt 
case <token> | BPF_X: <answer> BPF_ALU_DIV 
<token> = op_table[BPF_ALU_DIV]; <answer> op 
<token> = "x"; <answer> fmt 
case BPF_ALU_DIV <token> BPF_K: <answer> | 
op = <token> <answer> op_table[BPF_ALU_DIV]; 
fmt <token> "#%d"; <answer> = 
case <token> | BPF_X: <answer> BPF_ALU_MOD 
op <token> op_table[BPF_ALU_MOD]; <answer> = 
<token> = "x"; <answer> fmt 
<token> BPF_ALU_MOD | BPF_K: <answer> case 
op <token> op_table[BPF_ALU_MOD]; <answer> = 
fmt = <token> <answer> "#%d"; 
case BPF_ALU_AND | <token> <answer> BPF_X: 
<token> = op_table[BPF_ALU_AND]; <answer> op 
<token> = "x"; <answer> fmt 
case BPF_ALU_AND <token> BPF_K: <answer> | 
op = <token> <answer> op_table[BPF_ALU_AND]; 
<token> = "#%#x"; <answer> fmt 
case BPF_ALU_OR | <token> <answer> BPF_X: 
op = <token> <answer> op_table[BPF_ALU_OR]; 
fmt = <token> <answer> "x"; 
case BPF_ALU_OR | <token> <answer> BPF_K: 
<token> = op_table[BPF_ALU_OR]; <answer> op 
fmt = <token> <answer> "#%#x"; 
case <token> | BPF_X: <answer> BPF_ALU_XOR 
<token> = op_table[BPF_ALU_XOR]; <answer> op 
<token> = "x"; <answer> fmt 
case BPF_ALU_XOR | <token> <answer> BPF_K: 
op = <token> <answer> op_table[BPF_ALU_XOR]; 
fmt <token> "#%#x"; <answer> = 
op = <token> <answer> "nosup"; 
<token> = "%#x"; <answer> fmt 
val = <token> <answer> f.code; 
memset(buf, <token> sizeof(buf)); <answer> 0, 
snprintf(buf, sizeof(buf), fmt, <token> <answer> val); 
buf[sizeof(buf) - 1] <token> 0; <answer> = 
if ((BPF_CLASS(f.code) == BPF_JMP && BPF_OP(f.code) <token> BPF_JA)) <answer> != 
<token> %s, l%d, l%d\n", i, op, buf, <answer> rl_printf("l%d:\t%s 
i + 1 + f.jt, i + <token> + f.jf); <answer> 1 
rl_printf("l%d:\t%s %s\n", i, op, <token> <answer> buf); 
<token> void bpf_dump_curr(struct bpf_regs *r, struct sock_filter *f) <answer> static 
int i, m <token> 0; <answer> = 
rl_printf("pc: [%u]\n", <token> <answer> r->Pc); 
<token> [%u] jt[%u] jf[%u] k[%u]\n", <answer> rl_printf("code: 
f->code, f->jt, f->jf, <token> <answer> f->k); 
<token> "); <answer> rl_printf("curr: 
bpf_disasm(*f, <token> <answer> r->Pc); 
if (f->jt || <token> { <answer> f->jf) 
<token> "); <answer> rl_printf("jt: 
bpf_disasm(*(f + f->jt + 1), r->Pc + <token> + 1); <answer> f->jt 
rl_printf("jf: <token> <answer> "); 
bpf_disasm(*(f + f->jf + 1), r->Pc <token> f->jf + 1); <answer> + 
rl_printf("A: <token> r->A, r->A); <answer> [%#08x][%u]\n", 
rl_printf("X: <token> r->X, r->X); <answer> [%#08x][%u]\n", 
if <token> <answer> (r->Rs) 
<token> [%#08x][%u]!\n", r->R, r->R); <answer> rl_printf("ret: 
for (i = 0; i < BPF_MEMWORDS; i++) <token> <answer> { 
if (r->M[i]) <token> <answer> { 
rl_printf("M[%d]: [%#08x][%u]\n", i, r->M[i], <token> <answer> r->M[i]); 
if (m == <token> <answer> 0) 
rl_printf("M[0,%d]: <token> BPF_MEMWORDS - 1, 0, 0); <answer> [%#08x][%u]\n", 
static void bpf_dump_pkt(uint8_t <token> uint32_t pkt_caplen, uint32_t pkt_len) <answer> *pkt, 
<token> (pkt_caplen != pkt_len) <answer> if 
rl_printf("cap: %u, len: %u\n", pkt_caplen, <token> <answer> pkt_len); 
rl_printf("len: %u\n", <token> <answer> pkt_len); 
<token> pkt_caplen); <answer> hex_dump(pkt, 
static void bpf_disasm_all(const struct sock_filter <token> unsigned int len) <answer> *f, 
unsigned int <token> <answer> i; 
for (i = 0; <token> < len; i++) <answer> i 
bpf_disasm(f[i], <token> <answer> i); 
static <token> bpf_dump_all(const struct sock_filter *f, unsigned int len) <answer> void 
unsigned int <token> <answer> i; 
#include <token> <answer> "dm_services.h" 
#include <token> <answer> "include/logger_interface.h" 
#include <token> <answer> "../dce110/irq_service_dce110.h" 
<token> "dcn/dcn_3_1_5_offset.h" <answer> #include 
<token> "dcn/dcn_3_1_5_sh_mask.h" <answer> #include 
#include <token> <answer> "irq_service_dcn315.h" 
<token> "ivsrcid/dcn/irqsrcs_dcn_1_0.h" <answer> #include 
#define DCN_BASE__INST0_SEG0 <token> <answer> 0x00000012 
<token> DCN_BASE__INST0_SEG1 0x000000C0 <answer> #define 
<token> DCN_BASE__INST0_SEG2 0x000034C0 <answer> #define 
#define <token> 0x00009000 <answer> DCN_BASE__INST0_SEG3 
<token> DCN_BASE__INST0_SEG4 0x02403C00 <answer> #define 
<token> DCN_BASE__INST0_SEG5 0 <answer> #define 
static enum <token> to_dal_irq_source_dcn315( <answer> dc_irq_source 
struct <token> *irq_service, <answer> irq_service 
<token> src_id, <answer> uint32_t 
<token> ext_id) <answer> uint32_t 
switch <token> { <answer> (src_id) 
case <token> <answer> DCN_1_0__SRCID__DC_D1_OTG_VSTARTUP: 
return <token> <answer> DC_IRQ_SOURCE_VBLANK1; 
<token> DCN_1_0__SRCID__DC_D2_OTG_VSTARTUP: <answer> case 
<token> DC_IRQ_SOURCE_VBLANK2; <answer> return 
case <token> <answer> DCN_1_0__SRCID__DC_D3_OTG_VSTARTUP: 
<token> DC_IRQ_SOURCE_VBLANK3; <answer> return 
case <token> <answer> DCN_1_0__SRCID__DC_D4_OTG_VSTARTUP: 
<token> DC_IRQ_SOURCE_VBLANK4; <answer> return 
<token> DCN_1_0__SRCID__DC_D5_OTG_VSTARTUP: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_VBLANK5; 
<token> DCN_1_0__SRCID__DC_D6_OTG_VSTARTUP: <answer> case 
<token> DC_IRQ_SOURCE_VBLANK6; <answer> return 
<token> DCN_1_0__SRCID__OTG1_VERTICAL_INTERRUPT0_CONTROL: <answer> case 
<token> DC_IRQ_SOURCE_DC1_VLINE0; <answer> return 
case <token> <answer> DCN_1_0__SRCID__OTG2_VERTICAL_INTERRUPT0_CONTROL: 
<token> DC_IRQ_SOURCE_DC2_VLINE0; <answer> return 
<token> DCN_1_0__SRCID__OTG3_VERTICAL_INTERRUPT0_CONTROL: <answer> case 
<token> DC_IRQ_SOURCE_DC3_VLINE0; <answer> return 
<token> DCN_1_0__SRCID__OTG4_VERTICAL_INTERRUPT0_CONTROL: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_DC4_VLINE0; 
<token> DCN_1_0__SRCID__OTG5_VERTICAL_INTERRUPT0_CONTROL: <answer> case 
<token> DC_IRQ_SOURCE_DC5_VLINE0; <answer> return 
<token> DCN_1_0__SRCID__OTG6_VERTICAL_INTERRUPT0_CONTROL: <answer> case 
<token> DC_IRQ_SOURCE_DC6_VLINE0; <answer> return 
case <token> <answer> DCN_1_0__SRCID__HUBP0_FLIP_INTERRUPT: 
<token> DC_IRQ_SOURCE_PFLIP1; <answer> return 
case <token> <answer> DCN_1_0__SRCID__HUBP1_FLIP_INTERRUPT: 
<token> DC_IRQ_SOURCE_PFLIP2; <answer> return 
<token> DCN_1_0__SRCID__HUBP2_FLIP_INTERRUPT: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_PFLIP3; 
case <token> <answer> DCN_1_0__SRCID__HUBP3_FLIP_INTERRUPT: 
<token> DC_IRQ_SOURCE_PFLIP4; <answer> return 
<token> DCN_1_0__SRCID__HUBP4_FLIP_INTERRUPT: <answer> case 
<token> DC_IRQ_SOURCE_PFLIP5; <answer> return 
<token> DCN_1_0__SRCID__HUBP5_FLIP_INTERRUPT: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_PFLIP6; 
<token> DCN_1_0__SRCID__OTG0_IHC_V_UPDATE_NO_LOCK_INTERRUPT: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_VUPDATE1; 
<token> DCN_1_0__SRCID__OTG1_IHC_V_UPDATE_NO_LOCK_INTERRUPT: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_VUPDATE2; 
<token> DCN_1_0__SRCID__OTG2_IHC_V_UPDATE_NO_LOCK_INTERRUPT: <answer> case 
<token> DC_IRQ_SOURCE_VUPDATE3; <answer> return 
<token> DCN_1_0__SRCID__OTG3_IHC_V_UPDATE_NO_LOCK_INTERRUPT: <answer> case 
return <token> <answer> DC_IRQ_SOURCE_VUPDATE4; 
case <token> <answer> DCN_1_0__SRCID__OTG4_IHC_V_UPDATE_NO_LOCK_INTERRUPT: 
return <token> <answer> DC_IRQ_SOURCE_VUPDATE5; 
case <token> <answer> DCN_1_0__SRCID__OTG5_IHC_V_UPDATE_NO_LOCK_INTERRUPT: 
<token> DC_IRQ_SOURCE_VUPDATE6; <answer> return 
<token> DCN_1_0__SRCID__DMCUB_OUTBOX_LOW_PRIORITY_READY_INT: <answer> case 
<token> DC_IRQ_SOURCE_DMCUB_OUTBOX; <answer> return 
<token> DCN_1_0__SRCID__DC_HPD1_INT: <answer> case 
<token> vupdate_no_lock_int_entry(reg_num)\ <answer> #define 
[DC_IRQ_SOURCE_VUPDATE1 + reg_num] = <token> <answer> {\ 
<token> reg_num,\ <answer> IRQ_REG_ENTRY(OTG, 
OTG_GLOBAL_SYNC_STATUS, <token> <answer> VUPDATE_NO_LOCK_INT_EN,\ 
OTG_GLOBAL_SYNC_STATUS, <token> <answer> VUPDATE_NO_LOCK_EVENT_CLEAR),\ 
.funcs <token> &vupdate_no_lock_irq_info_funcs\ <answer> = 
#define <token> <answer> vblank_int_entry(reg_num)\ 
[DC_IRQ_SOURCE_VBLANK1 + reg_num] <token> {\ <answer> = 
<token> reg_num,\ <answer> IRQ_REG_ENTRY(OTG, 
OTG_GLOBAL_SYNC_STATUS, <token> <answer> VSTARTUP_INT_EN,\ 
OTG_GLOBAL_SYNC_STATUS, <token> <answer> VSTARTUP_EVENT_CLEAR),\ 
.funcs <token> &vblank_irq_info_funcs\ <answer> = 
#define <token> <answer> vline0_int_entry(reg_num)\ 
[DC_IRQ_SOURCE_DC1_VLINE0 <token> reg_num] = {\ <answer> + 
<token> reg_num,\ <answer> IRQ_REG_ENTRY(OTG, 
OTG_VERTICAL_INTERRUPT0_CONTROL, <token> <answer> OTG_VERTICAL_INTERRUPT0_INT_ENABLE,\ 
OTG_VERTICAL_INTERRUPT0_CONTROL, <token> <answer> OTG_VERTICAL_INTERRUPT0_CLEAR),\ 
<token> = &vline0_irq_info_funcs\ <answer> .funcs 
#define <token> <answer> dmub_outbox_int_entry()\ 
[DC_IRQ_SOURCE_DMCUB_OUTBOX] = <token> <answer> {\ 
<token> DMCUB_OUTBOX1_READY_INT_EN,\ <answer> DMCUB_INTERRUPT_ENABLE, 
<token> DMCUB_OUTBOX1_READY_INT_ACK),\ <answer> DMCUB_INTERRUPT_ACK, 
.funcs = <token> <answer> &outbox_irq_info_funcs\ 
#define dummy_irq_entry() <token> <answer> \ 
.funcs <token> &dummy_irq_info_funcs\ <answer> = 
#define i2c_int_entry(reg_num) <token> <answer> \ 
[DC_IRQ_SOURCE_I2C_DDC ## <token> = dummy_irq_entry() <answer> reg_num] 
<token> dp_sink_int_entry(reg_num) \ <answer> #define 
<token> ## reg_num] = dummy_irq_entry() <answer> [DC_IRQ_SOURCE_DPSINK 
#define <token> \ <answer> gpio_pad_int_entry(reg_num) 
[DC_IRQ_SOURCE_GPIOPAD ## reg_num] <token> dummy_irq_entry() <answer> = 
<token> dc_underflow_int_entry(reg_num) \ <answer> #define 
[DC_IRQ_SOURCE_DC ## reg_num <token> UNDERFLOW] = dummy_irq_entry() <answer> ## 
static struct irq_source_info_funcs <token> = { <answer> dummy_irq_info_funcs 
<token> = dal_irq_service_dummy_set, <answer> .set 
.ack <token> dal_irq_service_dummy_ack <answer> = 
<token> const struct irq_source_info <answer> static 
irq_source_info_dcn315[DAL_IRQ_SOURCES_NUMBER] <token> { <answer> = 
[DC_IRQ_SOURCE_INVALID] = <token> <answer> dummy_irq_entry(), 
[DC_IRQ_SOURCE_TIMER] = <token> <answer> dummy_irq_entry(), 
<token> = dummy_irq_entry(), <answer> [DC_IRQ_SOURCE_PFLIP5] 
<token> = dummy_irq_entry(), <answer> [DC_IRQ_SOURCE_PFLIP6] 
[DC_IRQ_SOURCE_PFLIP_UNDERLAY0] = <token> <answer> dummy_irq_entry(), 
<token> = dummy_irq_entry(), <answer> [DC_IRQ_SOURCE_DMCU_SCP] 
<token> = dummy_irq_entry(), <answer> [DC_IRQ_SOURCE_VBIOS_SW] 
[DC_IRQ_SOURCE_DC5_VLINE1] = <token> <answer> dummy_irq_entry(), 
<token> = dummy_irq_entry(), <answer> [DC_IRQ_SOURCE_DC6_VLINE1] 
static const struct irq_service_funcs <token> = { <answer> irq_service_funcs_dcn315 
<token> = to_dal_irq_source_dcn315 <answer> .to_dal_irq_source 
<token> void dcn315_irq_construct( <answer> static 
struct <token> *irq_service, <answer> irq_service 
struct irq_service_init_data <token> <answer> *init_data) 
<token> init_data); <answer> dal_irq_service_construct(irq_service, 
<token> = irq_source_info_dcn315; <answer> irq_service->info 
irq_service->funcs <token> &irq_service_funcs_dcn315; <answer> = 
<token> irq_service *dal_irq_service_dcn315_create( <answer> struct 
struct irq_service_init_data <token> <answer> *init_data) 
struct irq_service <token> = kzalloc(sizeof(*irq_service), <answer> *irq_service 
if <token> <answer> (!irq_service) 
return <token> <answer> NULL; 
<token> init_data); <answer> dcn315_irq_construct(irq_service, 
<token> irq_service; <answer> return 
<token> <linux/delay.h> <answer> #include 
#define <token> <answer> VIRTIO_PCI_NO_LEGACY 
#define <token> <answer> VIRTIO_RING_NO_LEGACY 
#include <token> <answer> "virtio_pci_common.h" 
#define <token> 4 <answer> VIRTIO_AVQ_SGS_MAX 
<token> u64 vp_get_features(struct virtio_device *vdev) <answer> static 
struct virtio_pci_device *vp_dev = <token> <answer> to_vp_device(vdev); 
<token> vp_modern_get_features(&vp_dev->mdev); <answer> return 
static bool vp_is_avq(struct <token> *vdev, unsigned int index) <answer> virtio_device 
struct <token> *vp_dev = to_vp_device(vdev); <answer> virtio_pci_device 
if (!virtio_has_feature(vdev, <token> <answer> VIRTIO_F_ADMIN_VQ)) 
<token> false; <answer> return 
return index <token> vp_dev->admin_vq.vq_index; <answer> == 
<token> int virtqueue_exec_admin_cmd(struct virtio_pci_admin_vq *admin_vq, <answer> static 
<token> opcode, <answer> u16 
<token> scatterlist **sgs, <answer> struct 
unsigned <token> out_num, <answer> int 
unsigned int <token> <answer> in_num, 
void <token> <answer> *data) 
struct virtqueue <token> <answer> *vq; 
int ret, <token> <answer> len; 
vq <token> admin_vq->info.vq; <answer> = 
if <token> <answer> (!vq) 
<token> -EIO; <answer> return 
if (opcode != VIRTIO_ADMIN_CMD_LIST_QUERY <token> <answer> && 
<token> != VIRTIO_ADMIN_CMD_LIST_USE && <answer> opcode 
!((1ULL << <token> & admin_vq->supported_cmds)) <answer> opcode) 
<token> -EOPNOTSUPP; <answer> return 
<token> = virtqueue_add_sgs(vq, sgs, out_num, in_num, data, GFP_KERNEL); <answer> ret 
if <token> < 0) <answer> (ret 
<token> -EIO; <answer> return 
if <token> <answer> (unlikely(!virtqueue_kick(vq))) 
<token> -EIO; <answer> return 
while (!virtqueue_get_buf(vq, &len) <token> <answer> && 
<token> (virtqueue_is_broken(vq)) <answer> if 
return <token> <answer> -EIO; 
<token> 0; <answer> return 
int vp_modern_admin_cmd_exec(struct virtio_device <token> <answer> *vdev, 
struct virtio_admin_cmd <token> <answer> *cmd) 
struct scatterlist <token> hdr, stat; <answer> *sgs[VIRTIO_AVQ_SGS_MAX], 
struct <token> *vp_dev = to_vp_device(vdev); <answer> virtio_pci_device 
struct virtio_admin_cmd_status <token> <answer> *va_status; 
unsigned int out_num = 0, in_num = <token> <answer> 0; 
struct virtio_admin_cmd_hdr <token> <answer> *va_hdr; 
u16 <token> <answer> status; 
int <token> <answer> ret; 
if (!virtio_has_feature(vdev, <token> <answer> VIRTIO_F_ADMIN_VQ)) 
return <token> <answer> -EOPNOTSUPP; 
va_status <token> kzalloc(sizeof(*va_status), GFP_KERNEL); <answer> = 
<token> (!va_status) <answer> if 
<token> -ENOMEM; <answer> return 
va_hdr = kzalloc(sizeof(*va_hdr), <token> <answer> GFP_KERNEL); 
if (!va_hdr) <token> <answer> { 
ret = <token> <answer> -ENOMEM; 
<token> err_alloc; <answer> goto 
<token> = cmd->opcode; <answer> va_hdr->opcode 
va_hdr->group_type = <token> <answer> cmd->group_type; 
<token> = cmd->group_member_id; <answer> va_hdr->group_member_id 
static void vp_set(struct virtio_device <token> unsigned int offset, <answer> *vdev, 
const void *buf, <token> int len) <answer> unsigned 
struct virtio_pci_device *vp_dev = <token> <answer> to_vp_device(vdev); 
struct virtio_pci_modern_device *mdev <token> &vp_dev->mdev; <answer> = 
void __iomem <token> = mdev->device; <answer> *device 
u8 <token> <answer> b; 
<token> w; <answer> __le16 
<token> l; <answer> __le32 
BUG_ON(offset <token> len > mdev->device_len); <answer> + 
<token> (len) { <answer> switch 
<token> 1: <answer> case 
<token> buf, sizeof b); <answer> memcpy(&b, 
iowrite8(b, device + <token> <answer> offset); 
<token> 2: <answer> case 
memcpy(&w, buf, sizeof <token> <answer> w); 
iowrite16(le16_to_cpu(w), device <token> offset); <answer> + 
case <token> <answer> 4: 
memcpy(&l, buf, <token> l); <answer> sizeof 
<token> device + offset); <answer> iowrite32(le32_to_cpu(l), 
case <token> <answer> 8: 
memcpy(&l, buf, sizeof <token> <answer> l); 
iowrite32(le32_to_cpu(l), device + <token> <answer> offset); 
memcpy(&l, buf <token> sizeof l, sizeof l); <answer> + 
iowrite32(le32_to_cpu(l), <token> + offset + sizeof l); <answer> device 
static u32 vp_generation(struct virtio_device <token> <answer> *vdev) 
struct virtio_pci_device *vp_dev <token> to_vp_device(vdev); <answer> = 
<token> vp_modern_generation(&vp_dev->mdev); <answer> return 
while <token> <answer> (vp_modern_get_status(mdev)) 
if (vp_dev->per_vq_vectors && <token> != VIRTIO_MSI_NO_VECTOR) <answer> info->msix_vector 
synchronize_irq(pci_irq_vector(vp_dev->pci_dev, <token> <answer> info->msix_vector)); 
vq->reset <token> true; <answer> = 
return <token> <answer> 0; 
static <token> vp_modern_enable_vq_after_reset(struct virtqueue *vq) <answer> int 
struct virtio_pci_device <token> = to_vp_device(vq->vdev); <answer> *vp_dev 
struct <token> *mdev = &vp_dev->mdev; <answer> virtio_pci_modern_device 
struct <token> *info; <answer> virtio_pci_vq_info 
unsigned long flags, <token> <answer> index; 
int <token> <answer> err; 
<token> (!vq->reset) <answer> if 
return <token> <answer> -EBUSY; 
index <token> vq->index; <answer> = 
<token> = vp_dev->vqs[index]; <answer> info 
if (vp_modern_get_queue_reset(mdev, <token> <answer> index)) 
return <token> <answer> -EBUSY; 
if (vp_modern_get_queue_enable(mdev, <token> <answer> index)) 
return <token> <answer> -EBUSY; 
err = vp_active_vq(vq, <token> <answer> info->msix_vector); 
if <token> <answer> (err) 
<token> err; <answer> return 
<token> (vq->callback) { <answer> if 
<token> flags); <answer> spin_lock_irqsave(&vp_dev->lock, 
<token> &vp_dev->virtqueues); <answer> list_add(&info->node, 
<token> flags); <answer> spin_unlock_irqrestore(&vp_dev->lock, 
} <token> { <answer> else 
<token> CONFIG_VIRTIO_HARDEN_NOTIFICATION <answer> #ifdef 
vp_modern_set_queue_enable(&vp_dev->mdev, index, <token> <answer> true); 
<token> = false; <answer> vq->reset 
<token> 0; <answer> return 
static <token> vp_config_vector(struct virtio_pci_device *vp_dev, u16 vector) <answer> u16 
return vp_modern_config_vector(&vp_dev->mdev, <token> <answer> vector); 
static bool vp_notify_with_data(struct <token> *vq) <answer> virtqueue 
u32 data <token> vring_notification_data(vq); <answer> = 
<token> (void __iomem *)vq->priv); <answer> iowrite32(data, 
return <token> <answer> true; 
static struct virtqueue <token> virtio_pci_device *vp_dev, <answer> *setup_vq(struct 
struct <token> *info, <answer> virtio_pci_vq_info 
unsigned <token> index, <answer> int 
<token> (*callback)(struct virtqueue *vq), <answer> void 
const <token> *name, <answer> char 
bool <token> <answer> ctx, 
<token> msix_vec) <answer> u16 
<token> virtio_pci_modern_device *mdev = &vp_dev->mdev; <answer> struct 
bool (*notify)(struct virtqueue <token> <answer> *vq); 
<token> virtqueue *vq; <answer> struct 
bool <token> <answer> is_avq; 
<token> num; <answer> u16 
int <token> <answer> err; 
if <token> VIRTIO_F_NOTIFICATION_DATA)) <answer> (__virtio_test_bit(&vp_dev->vdev, 
<token> = vp_notify_with_data; <answer> notify 
notify = <token> <answer> vp_notify; 
is_avq = <token> index); <answer> vp_is_avq(&vp_dev->vdev, 
if (index >= vp_modern_get_num_queues(mdev) && <token> <answer> !is_avq) 
<token> ERR_PTR(-EINVAL); <answer> return 
num = is_avq <token> <answer> ? 
VIRTIO_AVQ_SGS_MAX : vp_modern_get_queue_size(mdev, <token> <answer> index); 
<token> &vdev->vqs, list) <answer> list_for_each_entry(vq, 
vp_modern_set_queue_enable(&vp_dev->mdev, vq->index, <token> <answer> true); 
<token> 0; <answer> return 
static void <token> virtio_pci_vq_info *info) <answer> del_vq(struct 
struct virtqueue *vq = <token> <answer> info->vq; 
struct <token> *vp_dev = to_vp_device(vq->vdev); <answer> virtio_pci_device 
struct virtio_pci_modern_device <token> = &vp_dev->mdev; <answer> *mdev 
if (vp_is_avq(&vp_dev->vdev, <token> { <answer> vq->index)) 
<token> = NULL; <answer> vp_dev->admin_vq.info.vq 
<token> (vp_dev->msix_enabled) <answer> if 
vp_modern_queue_vector(mdev, <token> <answer> vq->index, 
if <token> <answer> (!mdev->notify_base) 
pci_iounmap(mdev->pci_dev, (void __force <token> *)vq->priv); <answer> __iomem 
static <token> virtio_pci_find_shm_cap(struct pci_dev *dev, u8 required_id, <answer> int 
u8 *bar, u64 *offset, u64 <token> <answer> *len) 
int <token> <answer> pos; 
for (pos = pci_find_capability(dev, PCI_CAP_ID_VNDR); pos <token> 0; <answer> > 
pos = pci_find_next_capability(dev, pos, <token> { <answer> PCI_CAP_ID_VNDR)) 
u8 type, cap_len, <token> res_bar; <answer> id, 
u32 <token> <answer> tmp32; 
u64 <token> res_length; <answer> res_offset, 
pci_read_config_byte(dev, pos <token> offsetof(struct virtio_pci_cap, <answer> + 
<token> &type); <answer> cfg_type), 
if <token> != VIRTIO_PCI_CAP_SHARED_MEMORY_CFG) <answer> (type 
pci_read_config_byte(dev, <token> + offsetof(struct virtio_pci_cap, <answer> pos 
<token> &cap_len); <answer> cap_len), 
<token> (cap_len != sizeof(struct virtio_pci_cap64)) { <answer> if 
dev_err(&dev->dev, "%s: <token> cap with bad size offset:" <answer> shm 
<token> %d size: %d\n", __func__, pos, cap_len); <answer> " 
pci_read_config_byte(dev, pos + <token> virtio_pci_cap, <answer> offsetof(struct 
id), <token> <answer> &id); 
<token> (id != required_id) <answer> if 
pci_read_config_byte(dev, <token> + offsetof(struct virtio_pci_cap, <answer> pos 
<token> &res_bar); <answer> bar), 
if (res_bar <token> PCI_STD_NUM_BARS) <answer> >= 
#include <token> <answer> <linux/cma.h> 
<token> <linux/debugfs.h> <answer> #include 
<token> <linux/dma-map-ops.h> <answer> #include 
#include <token> <answer> <linux/dma-direct.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/genalloc.h> <answer> #include 
<token> <linux/set_memory.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/workqueue.h> 
static struct <token> *atomic_pool_dma __ro_after_init; <answer> gen_pool 
static unsigned <token> pool_size_dma; <answer> long 
static struct gen_pool *atomic_pool_dma32 <token> <answer> __ro_after_init; 
<token> unsigned long pool_size_dma32; <answer> static 
static struct gen_pool <token> __ro_after_init; <answer> *atomic_pool_kernel 
static unsigned <token> pool_size_kernel; <answer> long 
ret = set_memory_decrypted((unsigned <token> <answer> long)page_to_virt(page), 
<token> << order); <answer> 1 
<token> (ret) <answer> if 
<token> remove_mapping; <answer> goto 
<token> = gen_pool_add_virt(pool, (unsigned long)addr, page_to_phys(page), <answer> ret 
<token> NUMA_NO_NODE); <answer> pool_size, 
if <token> <answer> (ret) 
goto <token> <answer> encrypt_mapping; 
dma_atomic_pool_size_add(gfp, <token> <answer> pool_size); 
return <token> <answer> 0; 
ret = set_memory_encrypted((unsigned <token> <answer> long)page_to_virt(page), 
1 << <token> <answer> order); 
if (WARN_ON_ONCE(ret)) <token> <answer> { 
<token> (!atomic_pool_size) { <answer> if 
<token> long pages = totalram_pages() / (SZ_1G / SZ_128K); <answer> unsigned 
pages = <token> long, pages, MAX_ORDER_NR_PAGES); <answer> min_t(unsigned 
<token> = max_t(size_t, pages << PAGE_SHIFT, SZ_128K); <answer> atomic_pool_size 
<token> atomic_pool_work_fn); <answer> INIT_WORK(&atomic_pool_work, 
<token> = __dma_atomic_pool_init(atomic_pool_size, <answer> atomic_pool_kernel 
if <token> <answer> (!atomic_pool_kernel) 
<token> = -ENOMEM; <answer> ret 
<token> (has_managed_dma()) { <answer> if 
atomic_pool_dma <token> __dma_atomic_pool_init(atomic_pool_size, <answer> = 
GFP_KERNEL | <token> <answer> GFP_DMA); 
<token> (!atomic_pool_dma) <answer> if 
<token> = -ENOMEM; <answer> ret 
if (IS_ENABLED(CONFIG_ZONE_DMA32)) <token> <answer> { 
<token> = __dma_atomic_pool_init(atomic_pool_size, <answer> atomic_pool_dma32 
GFP_KERNEL | <token> <answer> GFP_DMA32); 
<token> (!atomic_pool_dma32) <answer> if 
ret <token> -ENOMEM; <answer> = 
<token> ret; <answer> return 
<token> inline struct gen_pool *dma_guess_pool(struct gen_pool *prev, gfp_t gfp) <answer> static 
if (prev == NULL) <token> <answer> { 
if (IS_ENABLED(CONFIG_ZONE_DMA32) && (gfp & <token> <answer> GFP_DMA32)) 
<token> atomic_pool_dma32; <answer> return 
if <token> && (gfp & GFP_DMA)) <answer> (atomic_pool_dma 
return <token> <answer> atomic_pool_dma; 
return <token> <answer> atomic_pool_kernel; 
if (prev <token> atomic_pool_kernel) <answer> == 
return atomic_pool_dma32 ? atomic_pool_dma32 <token> atomic_pool_dma; <answer> : 
if (prev <token> atomic_pool_dma32) <answer> == 
return <token> <answer> atomic_pool_dma; 
<token> NULL; <answer> return 
static <token> page *__dma_alloc_from_pool(struct device *dev, size_t size, <answer> struct 
struct <token> *pool, void **cpu_addr, <answer> gen_pool 
<token> (*phys_addr_ok)(struct device *, phys_addr_t, size_t)) <answer> bool 
unsigned long <token> <answer> addr; 
<token> phys; <answer> phys_addr_t 
addr = gen_pool_alloc(pool, <token> <answer> size); 
<token> (!addr) <answer> if 
return <token> <answer> NULL; 
<token> = gen_pool_virt_to_phys(pool, addr); <answer> phys 
if <token> && !phys_addr_ok(dev, phys, size)) { <answer> (phys_addr_ok 
<token> addr, size); <answer> gen_pool_free(pool, 
<token> NULL; <answer> return 
<token> (gen_pool_avail(pool) < atomic_pool_size) <answer> if 
*cpu_addr <token> (void *)addr; <answer> = 
memset(*cpu_addr, 0, <token> <answer> size); 
return <token> <answer> pfn_to_page(__phys_to_pfn(phys)); 
struct page *dma_alloc_from_pool(struct <token> *dev, size_t size, <answer> device 
void **cpu_addr, <token> gfp, <answer> gfp_t 
bool (*phys_addr_ok)(struct <token> *, phys_addr_t, size_t)) <answer> device 
struct <token> *pool = NULL; <answer> gen_pool 
<token> page *page; <answer> struct 
while <token> = dma_guess_pool(pool, gfp))) { <answer> ((pool 
page = <token> size, pool, cpu_addr, <answer> __dma_alloc_from_pool(dev, 
<token> (page) <answer> if 
return <token> <answer> page; 
WARN(1, "Failed to get suitable pool for %s\n", <token> <answer> dev_name(dev)); 
return <token> <answer> NULL; 
bool dma_free_from_pool(struct device *dev, void <token> size_t size) <answer> *start, 
struct gen_pool <token> = NULL; <answer> *pool 
while ((pool = <token> 0))) { <answer> dma_guess_pool(pool, 
<token> (!gen_pool_has_addr(pool, (unsigned long)start, size)) <answer> if 
gen_pool_free(pool, (unsigned long)start, <token> <answer> size); 
<token> true; <answer> return 
<token> false; <answer> return 
<token> <linux/sched.h> <answer> #include 
#include <token> <answer> <linux/pagemap.h> 
<token> <linux/writeback.h> <answer> #include 
#include <token> <answer> <linux/blkdev.h> 
<token> <linux/rbtree.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/workqueue.h> <answer> #include 
<token> <linux/btrfs.h> <answer> #include 
<token> <linux/sched/mm.h> <answer> #include 
#include <token> <answer> "ctree.h" 
#include <token> <answer> "transaction.h" 
#include <token> <answer> "disk-io.h" 
<token> "locking.h" <answer> #include 
<token> "ulist.h" <answer> #include 
<token> "backref.h" <answer> #include 
#include <token> <answer> "extent_io.h" 
#include <token> <answer> "qgroup.h" 
#include <token> <answer> "block-group.h" 
#include <token> <answer> "sysfs.h" 
<token> "tree-mod-log.h" <answer> #include 
<token> "fs.h" <answer> #include 
#include <token> <answer> "accessors.h" 
#include <token> <answer> "extent-tree.h" 
<token> "root-tree.h" <answer> #include 
#include <token> <answer> "tree-checker.h" 
enum btrfs_qgroup_mode btrfs_qgroup_mode(struct <token> *fs_info) <answer> btrfs_fs_info 
<token> (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags)) <answer> if 
return <token> <answer> BTRFS_QGROUP_MODE_DISABLED; 
if (fs_info->qgroup_flags <token> BTRFS_QGROUP_STATUS_FLAG_SIMPLE_MODE) <answer> & 
<token> BTRFS_QGROUP_MODE_SIMPLE; <answer> return 
return <token> <answer> BTRFS_QGROUP_MODE_FULL; 
<token> btrfs_qgroup_enabled(struct btrfs_fs_info *fs_info) <answer> bool 
return btrfs_qgroup_mode(fs_info) != <token> <answer> BTRFS_QGROUP_MODE_DISABLED; 
bool <token> btrfs_fs_info *fs_info) <answer> btrfs_qgroup_full_accounting(struct 
return btrfs_qgroup_mode(fs_info) == <token> <answer> BTRFS_QGROUP_MODE_FULL; 
static <token> qgroup_rsv_total(const struct btrfs_qgroup *qgroup) <answer> u64 
<token> ret = 0; <answer> u64 
int <token> <answer> i; 
for (i = 0; i <token> BTRFS_QGROUP_RSV_LAST; i++) <answer> < 
ret <token> qgroup->rsv.values[i]; <answer> += 
<token> ret; <answer> return 
#ifdef <token> <answer> CONFIG_BTRFS_DEBUG 
static const <token> *qgroup_rsv_type_str(enum btrfs_qgroup_rsv_type type) <answer> char 
if (type <token> BTRFS_QGROUP_RSV_DATA) <answer> == 
<token> "data"; <answer> return 
if <token> == BTRFS_QGROUP_RSV_META_PERTRANS) <answer> (type 
return <token> <answer> "meta_pertrans"; 
<token> (type == BTRFS_QGROUP_RSV_META_PREALLOC) <answer> if 
<token> "meta_prealloc"; <answer> return 
return <token> <answer> NULL; 
<token> void qgroup_rsv_add(struct btrfs_fs_info *fs_info, <answer> static 
struct btrfs_qgroup <token> u64 num_bytes, <answer> *qgroup, 
<token> btrfs_qgroup_rsv_type type) <answer> enum 
<token> qgroup, num_bytes, type); <answer> trace_qgroup_update_reserve(fs_info, 
qgroup->rsv.values[type] <token> num_bytes; <answer> += 
static void qgroup_rsv_release(struct btrfs_fs_info <token> <answer> *fs_info, 
<token> btrfs_qgroup *qgroup, u64 num_bytes, <answer> struct 
enum btrfs_qgroup_rsv_type <token> <answer> type) 
<token> qgroup, -(s64)num_bytes, type); <answer> trace_qgroup_update_reserve(fs_info, 
if (qgroup->rsv.values[type] >= num_bytes) <token> <answer> { 
<token> -= num_bytes; <answer> qgroup->rsv.values[type] 
#ifdef <token> <answer> CONFIG_BTRFS_DEBUG 
"qgroup %llu %s reserved <token> underflow, have %llu to free %llu", <answer> space 
<token> qgroup_rsv_type_str(type), <answer> qgroup->qgroupid, 
qgroup->rsv.values[type], <token> <answer> num_bytes); 
qgroup->rsv.values[type] = <token> <answer> 0; 
static void qgroup_rsv_add_by_qgroup(struct <token> *fs_info, <answer> btrfs_fs_info 
<token> btrfs_qgroup *dest, <answer> struct 
<token> btrfs_qgroup *src) <answer> struct 
int <token> <answer> i; 
for (i = 0; i < BTRFS_QGROUP_RSV_LAST; <token> <answer> i++) 
qgroup_rsv_add(fs_info, dest, <token> i); <answer> src->rsv.values[i], 
<token> void qgroup_rsv_release_by_qgroup(struct btrfs_fs_info *fs_info, <answer> static 
<token> btrfs_qgroup *dest, <answer> struct 
struct btrfs_qgroup <token> <answer> *src) 
<token> i; <answer> int 
for (i = 0; <token> < BTRFS_QGROUP_RSV_LAST; i++) <answer> i 
qgroup_rsv_release(fs_info, dest, <token> i); <answer> src->rsv.values[i], 
static void btrfs_qgroup_update_old_refcnt(struct <token> *qg, u64 seq, <answer> btrfs_qgroup 
<token> mod) <answer> int 
if <token> < seq) <answer> (qg->old_refcnt 
qg->old_refcnt = <token> <answer> seq; 
<token> += mod; <answer> qg->old_refcnt 
<token> void btrfs_qgroup_update_new_refcnt(struct btrfs_qgroup *qg, u64 seq, <answer> static 
<token> mod) <answer> int 
if <token> < seq) <answer> (qg->new_refcnt 
qg->new_refcnt <token> seq; <answer> = 
qg->new_refcnt += <token> <answer> mod; 
static inline u64 btrfs_qgroup_get_old_refcnt(struct btrfs_qgroup *qg, u64 <token> <answer> seq) 
<token> (qg->old_refcnt < seq) <answer> if 
<token> 0; <answer> return 
return <token> - seq; <answer> qg->old_refcnt 
static inline <token> btrfs_qgroup_get_new_refcnt(struct btrfs_qgroup *qg, u64 seq) <answer> u64 
<token> (qg->new_refcnt < seq) <answer> if 
return <token> <answer> 0; 
<token> qg->new_refcnt - seq; <answer> return 
struct btrfs_qgroup_list <token> <answer> { 
<token> list_head next_group; <answer> struct 
struct list_head <token> <answer> next_member; 
<token> btrfs_qgroup *group; <answer> struct 
struct <token> *member; <answer> btrfs_qgroup 
static <token> <answer> int 
qgroup_rescan_init(struct <token> *fs_info, u64 progress_objectid, <answer> btrfs_fs_info 
int <token> <answer> init_flags); 
static void <token> btrfs_fs_info *fs_info); <answer> qgroup_rescan_zero_tracking(struct 
static struct btrfs_qgroup *add_qgroup_rb(struct <token> *fs_info, <answer> btrfs_fs_info 
<token> btrfs_qgroup *prealloc, <answer> struct 
<token> qgroupid) <answer> u64 
struct rb_node **p <token> &fs_info->qgroup_tree.rb_node; <answer> = 
struct rb_node *parent <token> NULL; <answer> = 
<token> btrfs_qgroup *qgroup; <answer> struct 
<token> int __add_relation_rb(struct btrfs_qgroup_list *prealloc, <answer> static 
struct <token> *member, <answer> btrfs_qgroup 
struct <token> *parent) <answer> btrfs_qgroup 
if (!member || !parent) <token> <answer> { 
<token> -ENOENT; <answer> return 
<token> = parent; <answer> prealloc->group 
prealloc->member = <token> <answer> member; 
list_add_tail(&prealloc->next_group, <token> <answer> &member->groups); 
<token> &parent->members); <answer> list_add_tail(&prealloc->next_member, 
<token> 0; <answer> return 
static int add_relation_rb(struct <token> *fs_info, <answer> btrfs_fs_info 
<token> btrfs_qgroup_list *prealloc, <answer> struct 
u64 <token> u64 parentid) <answer> memberid, 
struct <token> *member; <answer> btrfs_qgroup 
struct btrfs_qgroup <token> <answer> *parent; 
<token> = find_qgroup_rb(fs_info, memberid); <answer> member 
parent <token> find_qgroup_rb(fs_info, parentid); <answer> = 
<token> __add_relation_rb(prealloc, member, parent); <answer> return 
int btrfs_read_qgroup_config(struct <token> *fs_info) <answer> btrfs_fs_info 
struct <token> key; <answer> btrfs_key 
struct <token> found_key; <answer> btrfs_key 
struct btrfs_root *quota_root = <token> <answer> fs_info->quota_root; 
<token> btrfs_path *path = NULL; <answer> struct 
struct extent_buffer <token> <answer> *l; 
int <token> <answer> slot; 
int <token> = 0; <answer> ret 
<token> flags = 0; <answer> u64 
u64 rescan_progress <token> 0; <answer> = 
if <token> <answer> (!fs_info->quota_root) 
return <token> <answer> 0; 
<token> = ulist_alloc(GFP_KERNEL); <answer> fs_info->qgroup_ulist 
if <token> { <answer> (!fs_info->qgroup_ulist) 
ret <token> -ENOMEM; <answer> = 
goto <token> <answer> out; 
path = <token> <answer> btrfs_alloc_path(); 
if <token> { <answer> (!path) 
<token> = -ENOMEM; <answer> ret 
<token> out; <answer> goto 
<token> = btrfs_sysfs_add_qgroups(fs_info); <answer> ret 
<token> (ret < 0) <answer> if 
goto <token> <answer> out; 
<token> = 0; <answer> key.objectid 
<token> = 0; <answer> key.type 
<token> = 0; <answer> key.offset 
ret = btrfs_search_slot_for_read(quota_root, &key, path, 1, <token> <answer> 1); 
if <token> <answer> (ret) 
goto <token> <answer> out; 
<token> (1) { <answer> while 
<token> btrfs_qgroup *qgroup; <answer> struct 
<token> = path->slots[0]; <answer> slot 
l = <token> <answer> path->nodes[0]; 
<token> &found_key, slot); <answer> btrfs_item_key_to_cpu(l, 
<token> (found_key.type == BTRFS_QGROUP_STATUS_KEY) { <answer> if 
struct <token> *ptr; <answer> btrfs_qgroup_status_item 
<token> = btrfs_item_ptr(l, slot, <answer> ptr 
<token> btrfs_qgroup_status_item); <answer> struct 
<token> (btrfs_qgroup_status_version(l, ptr) != <answer> if 
<token> { <answer> BTRFS_QGROUP_STATUS_VERSION) 
"old qgroup version, <token> disabled"); <answer> quota 
goto <token> <answer> out; 
fs_info->qgroup_flags = btrfs_qgroup_status_flags(l, <token> <answer> ptr); 
if (fs_info->qgroup_flags & <token> { <answer> BTRFS_QGROUP_STATUS_FLAG_SIMPLE_MODE) 
qgroup_read_enable_gen(fs_info, l, <token> ptr); <answer> slot, 
} else if (btrfs_qgroup_status_generation(l, ptr) <token> fs_info->generation) { <answer> != 
<token> generation mismatch, marked as inconsistent"); <answer> "qgroup 
rescan_progress <token> btrfs_qgroup_status_rescan(l, ptr); <answer> = 
<token> next1; <answer> goto 
if (found_key.type != <token> && <answer> BTRFS_QGROUP_INFO_KEY 
found_key.type != <token> <answer> BTRFS_QGROUP_LIMIT_KEY) 
goto <token> <answer> next1; 
<token> = find_qgroup_rb(fs_info, found_key.offset); <answer> qgroup 
if ((qgroup && found_key.type <token> BTRFS_QGROUP_INFO_KEY) || <answer> == 
(!qgroup && found_key.type <token> BTRFS_QGROUP_LIMIT_KEY)) { <answer> == 
btrfs_err(fs_info, "inconsistent qgroup <token> <answer> config"); 
if <token> { <answer> (!qgroup) 
struct <token> *prealloc; <answer> btrfs_qgroup 
prealloc <token> kzalloc(sizeof(*prealloc), GFP_KERNEL); <answer> = 
if <token> { <answer> (!prealloc) 
ret <token> -ENOMEM; <answer> = 
<token> out; <answer> goto 
qgroup = add_qgroup_rb(fs_info, prealloc, <token> <answer> found_key.offset); 
ret = btrfs_sysfs_add_one_qgroup(fs_info, <token> <answer> qgroup); 
if (ret < <token> <answer> 0) 
goto <token> <answer> out; 
<token> (found_key.type) { <answer> switch 
<token> BTRFS_QGROUP_INFO_KEY: { <answer> case 
struct btrfs_qgroup_info_item <token> <answer> *ptr; 
ptr = btrfs_item_ptr(l, <token> <answer> slot, 
<token> btrfs_qgroup_info_item); <answer> struct 
qgroup->rfer = <token> ptr); <answer> btrfs_qgroup_info_rfer(l, 
qgroup->rfer_cmpr = btrfs_qgroup_info_rfer_cmpr(l, <token> <answer> ptr); 
qgroup->excl = btrfs_qgroup_info_excl(l, <token> <answer> ptr); 
qgroup->excl_cmpr = btrfs_qgroup_info_excl_cmpr(l, <token> <answer> ptr); 
key.objectid = <token> <answer> 0; 
<token> = BTRFS_QGROUP_RELATION_KEY; <answer> key.type 
<token> = 0; <answer> key.offset 
ret = <token> &key, path, 1, 0); <answer> btrfs_search_slot_for_read(quota_root, 
<token> (ret) <answer> if 
goto <token> <answer> out; 
<token> (1) { <answer> while 
<token> btrfs_qgroup_list *list = NULL; <answer> struct 
slot <token> path->slots[0]; <answer> = 
l <token> path->nodes[0]; <answer> = 
btrfs_item_key_to_cpu(l, &found_key, <token> <answer> slot); 
<token> (found_key.type != BTRFS_QGROUP_RELATION_KEY) <answer> if 
<token> next2; <answer> goto 
if (found_key.objectid > found_key.offset) <token> <answer> { 
bool btrfs_check_quota_leak(struct <token> *fs_info) <answer> btrfs_fs_info 
<token> rb_node *node; <answer> struct 
<token> ret = false; <answer> bool 
if (btrfs_qgroup_mode(fs_info) <token> BTRFS_QGROUP_MODE_DISABLED) <answer> == 
return <token> <answer> ret; 
for (node = <token> node; node = rb_next(node)) { <answer> rb_first(&fs_info->qgroup_tree); 
struct <token> *qgroup; <answer> btrfs_qgroup 
int <token> <answer> i; 
qgroup = <token> struct btrfs_qgroup, node); <answer> rb_entry(node, 
<token> (i = 0; i < BTRFS_QGROUP_RSV_LAST; i++) { <answer> for 
<token> (qgroup->rsv.values[i]) { <answer> if 
<token> = true; <answer> ret 
"qgroup %hu/%llu has unreleased space, <token> %d rsv %llu", <answer> type 
i, <token> <answer> qgroup->rsv.values[i]); 
return <token> <answer> ret; 
void btrfs_free_qgroup_config(struct <token> *fs_info) <answer> btrfs_fs_info 
struct <token> *n; <answer> rb_node 
struct btrfs_qgroup <token> <answer> *qgroup; 
while ((n = rb_first(&fs_info->qgroup_tree))) <token> <answer> { 
qgroup <token> rb_entry(n, struct btrfs_qgroup, node); <answer> = 
<token> &fs_info->qgroup_tree); <answer> rb_erase(n, 
__del_qgroup_rb(fs_info, <token> <answer> qgroup); 
btrfs_sysfs_del_one_qgroup(fs_info, <token> <answer> qgroup); 
<token> = NULL; <answer> fs_info->qgroup_ulist 
static int add_qgroup_relation_item(struct <token> *trans, u64 src, <answer> btrfs_trans_handle 
u64 <token> <answer> dst) 
<token> ret; <answer> int 
<token> btrfs_root *quota_root = trans->fs_info->quota_root; <answer> struct 
struct <token> *path; <answer> btrfs_path 
struct <token> key; <answer> btrfs_key 
<token> = btrfs_alloc_path(); <answer> path 
if <token> <answer> (!path) 
<token> -ENOMEM; <answer> return 
key.objectid = <token> <answer> src; 
<token> = BTRFS_QGROUP_RELATION_KEY; <answer> key.type 
key.offset <token> dst; <answer> = 
ret <token> btrfs_insert_empty_item(trans, quota_root, path, &key, 0); <answer> = 
btrfs_mark_buffer_dirty(trans, <token> <answer> path->nodes[0]); 
<token> ret; <answer> return 
static int del_qgroup_relation_item(struct btrfs_trans_handle *trans, u64 <token> <answer> src, 
<token> dst) <answer> u64 
<token> ret; <answer> int 
struct <token> *quota_root = trans->fs_info->quota_root; <answer> btrfs_root 
struct <token> *path; <answer> btrfs_path 
<token> btrfs_key key; <answer> struct 
<token> = btrfs_alloc_path(); <answer> path 
if <token> <answer> (!path) 
<token> -ENOMEM; <answer> return 
key.objectid <token> src; <answer> = 
<token> = BTRFS_QGROUP_RELATION_KEY; <answer> key.type 
<token> = dst; <answer> key.offset 
ret = btrfs_search_slot(trans, quota_root, &key, path, <token> 1); <answer> -1, 
if <token> < 0) <answer> (ret 
goto <token> <answer> out; 
<token> (ret > 0) { <answer> if 
ret <token> -ENOENT; <answer> = 
<token> out; <answer> goto 
<token> = btrfs_del_item(trans, quota_root, path); <answer> ret 
<token> ret; <answer> return 
<token> int add_qgroup_item(struct btrfs_trans_handle *trans, <answer> static 
struct btrfs_root *quota_root, <token> qgroupid) <answer> u64 
int <token> <answer> ret; 
<token> btrfs_path *path; <answer> struct 
struct btrfs_qgroup_info_item <token> <answer> *qgroup_info; 
struct <token> *qgroup_limit; <answer> btrfs_qgroup_limit_item 
struct <token> *leaf; <answer> extent_buffer 
struct <token> key; <answer> btrfs_key 
if <token> <answer> (btrfs_is_testing(quota_root->fs_info)) 
return <token> <answer> 0; 
<token> = btrfs_alloc_path(); <answer> path 
<token> (!path) <answer> if 
return <token> <answer> -ENOMEM; 
key.objectid <token> 0; <answer> = 
key.type = <token> <answer> BTRFS_QGROUP_INFO_KEY; 
key.offset = <token> <answer> qgroupid; 
ret <token> btrfs_insert_empty_item(trans, quota_root, path, &key, <answer> = 
if <token> && ret != -EEXIST) <answer> (ret 
<token> out; <answer> goto 
leaf <token> path->nodes[0]; <answer> = 
<token> = btrfs_item_ptr(leaf, path->slots[0], <answer> qgroup_info 
<token> btrfs_qgroup_info_item); <answer> struct 
btrfs_set_qgroup_info_generation(leaf, <token> trans->transid); <answer> qgroup_info, 
btrfs_set_qgroup_info_rfer(leaf, qgroup_info, <token> <answer> 0); 
<token> qgroup_info, 0); <answer> btrfs_set_qgroup_info_rfer_cmpr(leaf, 
btrfs_set_qgroup_info_excl(leaf, <token> 0); <answer> qgroup_info, 
btrfs_set_qgroup_info_excl_cmpr(leaf, qgroup_info, <token> <answer> 0); 
<token> leaf); <answer> btrfs_mark_buffer_dirty(trans, 
<token> = BTRFS_QGROUP_LIMIT_KEY; <answer> key.type 
ret = btrfs_insert_empty_item(trans, quota_root, <token> &key, <answer> path, 
if (ret && ret != <token> <answer> -EEXIST) 
<token> out; <answer> goto 
<token> = path->nodes[0]; <answer> leaf 
qgroup_limit <token> btrfs_item_ptr(leaf, path->slots[0], <answer> = 
<token> btrfs_qgroup_limit_item); <answer> struct 
<token> qgroup_limit, 0); <answer> btrfs_set_qgroup_limit_flags(leaf, 
<token> qgroup_limit, 0); <answer> btrfs_set_qgroup_limit_max_rfer(leaf, 
btrfs_set_qgroup_limit_max_excl(leaf, qgroup_limit, <token> <answer> 0); 
<token> qgroup_limit, 0); <answer> btrfs_set_qgroup_limit_rsv_rfer(leaf, 
btrfs_set_qgroup_limit_rsv_excl(leaf, qgroup_limit, <token> <answer> 0); 
btrfs_mark_buffer_dirty(trans, <token> <answer> leaf); 
ret <token> 0; <answer> = 
<token> ret; <answer> return 
static int del_qgroup_item(struct btrfs_trans_handle *trans, <token> qgroupid) <answer> u64 
<token> ret; <answer> int 
struct btrfs_root *quota_root <token> trans->fs_info->quota_root; <answer> = 
struct <token> *path; <answer> btrfs_path 
<token> btrfs_key key; <answer> struct 
path = <token> <answer> btrfs_alloc_path(); 
if <token> <answer> (!path) 
return <token> <answer> -ENOMEM; 
key.objectid = <token> <answer> 0; 
<token> = BTRFS_QGROUP_INFO_KEY; <answer> key.type 
key.offset = <token> <answer> qgroupid; 
<token> = btrfs_search_slot(trans, quota_root, &key, path, -1, 1); <answer> ret 
<token> (ret < 0) <answer> if 
<token> out; <answer> goto 
if (ret <token> 0) { <answer> > 
<token> = -ENOENT; <answer> ret 
goto <token> <answer> out; 
ret <token> btrfs_del_item(trans, quota_root, path); <answer> = 
<token> (ret) <answer> if 
goto <token> <answer> out; 
key.type <token> BTRFS_QGROUP_LIMIT_KEY; <answer> = 
ret = <token> quota_root, &key, path, -1, 1); <answer> btrfs_search_slot(trans, 
<token> (ret < 0) <answer> if 
<token> out; <answer> goto 
if <token> > 0) { <answer> (ret 
ret <token> -ENOENT; <answer> = 
goto <token> <answer> out; 
ret = btrfs_del_item(trans, <token> path); <answer> quota_root, 
<token> ret; <answer> return 
<token> int update_qgroup_limit_item(struct btrfs_trans_handle *trans, <answer> static 
<token> btrfs_qgroup *qgroup) <answer> struct 
struct btrfs_root *quota_root = <token> <answer> trans->fs_info->quota_root; 
struct <token> *path; <answer> btrfs_path 
struct <token> key; <answer> btrfs_key 
<token> extent_buffer *l; <answer> struct 
struct btrfs_qgroup_limit_item <token> <answer> *qgroup_limit; 
int <token> <answer> ret; 
int <token> <answer> slot; 
<token> = 0; <answer> key.objectid 
key.type <token> BTRFS_QGROUP_LIMIT_KEY; <answer> = 
key.offset <token> qgroup->qgroupid; <answer> = 
path = <token> <answer> btrfs_alloc_path(); 
if <token> <answer> (!path) 
return <token> <answer> -ENOMEM; 
<token> = btrfs_search_slot(trans, quota_root, &key, path, 0, 1); <answer> ret 
if (ret <token> 0) <answer> > 
ret <token> -ENOENT; <answer> = 
<token> (ret) <answer> if 
goto <token> <answer> out; 
l = <token> <answer> path->nodes[0]; 
slot = <token> <answer> path->slots[0]; 
qgroup_limit = btrfs_item_ptr(l, <token> struct btrfs_qgroup_limit_item); <answer> slot, 
<token> qgroup_limit, qgroup->lim_flags); <answer> btrfs_set_qgroup_limit_flags(l, 
btrfs_set_qgroup_limit_max_rfer(l, <token> qgroup->max_rfer); <answer> qgroup_limit, 
<token> qgroup_limit, qgroup->max_excl); <answer> btrfs_set_qgroup_limit_max_excl(l, 
btrfs_set_qgroup_limit_rsv_rfer(l, qgroup_limit, <token> <answer> qgroup->rsv_rfer); 
btrfs_set_qgroup_limit_rsv_excl(l, qgroup_limit, <token> <answer> qgroup->rsv_excl); 
<token> l); <answer> btrfs_mark_buffer_dirty(trans, 
return <token> <answer> ret; 
static int <token> btrfs_trans_handle *trans, <answer> update_qgroup_info_item(struct 
<token> btrfs_qgroup *qgroup) <answer> struct 
struct btrfs_fs_info *fs_info <token> trans->fs_info; <answer> = 
<token> btrfs_root *quota_root = fs_info->quota_root; <answer> struct 
struct <token> *path; <answer> btrfs_path 
struct <token> key; <answer> btrfs_key 
struct extent_buffer <token> <answer> *l; 
<token> btrfs_qgroup_info_item *qgroup_info; <answer> struct 
int <token> <answer> ret; 
<token> slot; <answer> int 
if <token> <answer> (btrfs_is_testing(fs_info)) 
return <token> <answer> 0; 
key.objectid <token> 0; <answer> = 
<token> = BTRFS_QGROUP_INFO_KEY; <answer> key.type 
key.offset = <token> <answer> qgroup->qgroupid; 
path = <token> <answer> btrfs_alloc_path(); 
if <token> <answer> (!path) 
<token> -ENOMEM; <answer> return 
ret = btrfs_search_slot(trans, <token> &key, path, 0, 1); <answer> quota_root, 
if <token> > 0) <answer> (ret 
ret = <token> <answer> -ENOENT; 
if <token> <answer> (ret) 
goto <token> <answer> out; 
l <token> path->nodes[0]; <answer> = 
<token> = path->slots[0]; <answer> slot 
<token> = btrfs_item_ptr(l, slot, struct btrfs_qgroup_info_item); <answer> qgroup_info 
btrfs_set_qgroup_info_generation(l, <token> trans->transid); <answer> qgroup_info, 
btrfs_set_qgroup_info_rfer(l, <token> qgroup->rfer); <answer> qgroup_info, 
btrfs_set_qgroup_info_rfer_cmpr(l, qgroup_info, <token> <answer> qgroup->rfer_cmpr); 
btrfs_set_qgroup_info_excl(l, <token> qgroup->excl); <answer> qgroup_info, 
<token> qgroup_info, qgroup->excl_cmpr); <answer> btrfs_set_qgroup_info_excl_cmpr(l, 
<token> l); <answer> btrfs_mark_buffer_dirty(trans, 
<token> ret; <answer> return 
<token> int update_qgroup_status_item(struct btrfs_trans_handle *trans) <answer> static 
<token> btrfs_fs_info *fs_info = trans->fs_info; <answer> struct 
struct <token> *quota_root = fs_info->quota_root; <answer> btrfs_root 
struct btrfs_path <token> <answer> *path; 
struct <token> key; <answer> btrfs_key 
struct extent_buffer <token> <answer> *l; 
<token> btrfs_qgroup_status_item *ptr; <answer> struct 
<token> ret; <answer> int 
int <token> <answer> slot; 
key.objectid = <token> <answer> 0; 
<token> = BTRFS_QGROUP_STATUS_KEY; <answer> key.type 
key.offset <token> 0; <answer> = 
path = <token> <answer> btrfs_alloc_path(); 
<token> (!path) <answer> if 
return <token> <answer> -ENOMEM; 
ret = btrfs_search_slot(trans, quota_root, &key, path, <token> 1); <answer> 0, 
<token> (ret > 0) <answer> if 
ret <token> -ENOENT; <answer> = 
<token> (ret) <answer> if 
<token> out; <answer> goto 
l = <token> <answer> path->nodes[0]; 
<token> = path->slots[0]; <answer> slot 
ptr = btrfs_item_ptr(l, slot, <token> btrfs_qgroup_status_item); <answer> struct 
btrfs_set_qgroup_status_flags(l, ptr, fs_info->qgroup_flags <token> <answer> & 
btrfs_set_qgroup_status_generation(l, <token> trans->transid); <answer> ptr, 
btrfs_set_qgroup_status_rescan(l, <token> <answer> ptr, 
btrfs_mark_buffer_dirty(trans, <token> <answer> l); 
<token> ret; <answer> return 
<token> int btrfs_clean_quota_tree(struct btrfs_trans_handle *trans, <answer> static 
struct <token> *root) <answer> btrfs_root 
<token> btrfs_path *path; <answer> struct 
<token> btrfs_key key; <answer> struct 
<token> extent_buffer *leaf = NULL; <answer> struct 
int <token> <answer> ret; 
<token> nr = 0; <answer> int 
path = <token> <answer> btrfs_alloc_path(); 
<token> (!path) <answer> if 
return <token> <answer> -ENOMEM; 
key.objectid = <token> <answer> 0; 
<token> = 0; <answer> key.offset 
key.type = <token> <answer> 0; 
while <token> { <answer> (1) 
ret <token> btrfs_search_slot(trans, root, &key, path, -1, 1); <answer> = 
if <token> < 0) <answer> (ret 
goto <token> <answer> out; 
<token> = path->nodes[0]; <answer> leaf 
nr = <token> <answer> btrfs_header_nritems(leaf); 
