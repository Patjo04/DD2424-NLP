#define TEST <token> <answer> \ 
memmove(instance.buf, <token> sizeof(large_src)) <answer> large_src, 
<token> "test_fortify.h" <answer> #include 
<token> <linux/types.h> <answer> #include 
#include <token> <answer> <linux/socket.h> 
<token> <linux/stddef.h> <answer> #include 
#include <token> <answer> <net/sock.h> 
<token> "vmci_transport_notify.h" <answer> #include 
<token> PKT_FIELD(vsk, field_name) \ <answer> #define 
static bool vmci_transport_notify_waiting_write(struct vsock_sock <token> <answer> *vsk) 
<token> retval; <answer> bool 
<token> notify_limit; <answer> u64 
if <token> peer_waiting_write)) <answer> (!PKT_FIELD(vsk, 
return <token> <answer> false; 
if <token> peer_waiting_write_detected)) { <answer> (!PKT_FIELD(vsk, 
<token> peer_waiting_write_detected) = true; <answer> PKT_FIELD(vsk, 
if (PKT_FIELD(vsk, write_notify_window) < <token> { <answer> PAGE_SIZE) 
PKT_FIELD(vsk, <token> = <answer> write_notify_window) 
<token> write_notify_min_window); <answer> PKT_FIELD(vsk, 
} else <token> <answer> { 
<token> write_notify_window) -= PAGE_SIZE; <answer> PKT_FIELD(vsk, 
<token> (PKT_FIELD(vsk, write_notify_window) < <answer> if 
PKT_FIELD(vsk, <token> <answer> write_notify_min_window)) 
PKT_FIELD(vsk, write_notify_window) <token> <answer> = 
PKT_FIELD(vsk, <token> <answer> write_notify_min_window); 
notify_limit = vmci_trans(vsk)->consume_size <token> <answer> - 
<token> write_notify_window); <answer> PKT_FIELD(vsk, 
retval = vmci_qpair_consume_free_space(vmci_trans(vsk)->qpair) <token> <answer> > 
if (retval) <token> <answer> { 
PKT_FIELD(vsk, peer_waiting_write_detected) = <token> <answer> false; 
<token> retval; <answer> return 
<token> void <answer> static 
<token> sock *sk, <answer> vmci_transport_handle_read(struct 
<token> vmci_transport_packet *pkt, <answer> struct 
bool <token> <answer> bottom_half, 
struct sockaddr_vm *dst, struct <token> *src) <answer> sockaddr_vm 
static <token> <answer> void 
vmci_transport_handle_wrote(struct <token> *sk, <answer> sock 
struct vmci_transport_packet <token> <answer> *pkt, 
<token> bottom_half, <answer> bool 
struct sockaddr_vm *dst, <token> sockaddr_vm *src) <answer> struct 
<token> void vsock_block_update_write_window(struct sock *sk) <answer> static 
struct vsock_sock *vsk = <token> <answer> vsock_sk(sk); 
if (PKT_FIELD(vsk, <token> < vmci_trans(vsk)->consume_size) <answer> write_notify_window) 
PKT_FIELD(vsk, <token> = <answer> write_notify_window) 
min(PKT_FIELD(vsk, write_notify_window) <token> PAGE_SIZE, <answer> + 
static <token> vmci_transport_send_read_notification(struct sock *sk) <answer> int 
<token> vsock_sock *vsk; <answer> struct 
<token> sent_read; <answer> bool 
unsigned int <token> <answer> retries; 
<token> err; <answer> int 
vsk = <token> <answer> vsock_sk(sk); 
<token> = false; <answer> sent_read 
<token> = 0; <answer> retries 
<token> = 0; <answer> err 
if <token> { <answer> (vmci_transport_notify_waiting_write(vsk)) 
<token> (!(vsk->peer_shutdown & RCV_SHUTDOWN) && <answer> while 
<token> && <answer> !sent_read 
retries <token> VMCI_TRANSPORT_MAX_DGRAM_RESENDS) { <answer> < 
err <token> vmci_transport_send_read(sk); <answer> = 
if <token> >= 0) <answer> (err 
<token> = true; <answer> sent_read 
if (retries >= VMCI_TRANSPORT_MAX_DGRAM_RESENDS <token> !sent_read) <answer> && 
pr_err("%p unable to <token> read notification to peer\n", <answer> send 
PKT_FIELD(vsk, peer_waiting_write) <token> false; <answer> = 
return <token> <answer> err; 
static void <token> sock *sk) <answer> vmci_transport_notify_pkt_socket_init(struct 
struct vsock_sock *vsk <token> vsock_sk(sk); <answer> = 
PKT_FIELD(vsk, write_notify_window) <token> PAGE_SIZE; <answer> = 
PKT_FIELD(vsk, <token> = PAGE_SIZE; <answer> write_notify_min_window) 
PKT_FIELD(vsk, <token> = false; <answer> peer_waiting_write) 
PKT_FIELD(vsk, <token> = false; <answer> peer_waiting_write_detected) 
static void vmci_transport_notify_pkt_socket_destruct(struct <token> *vsk) <answer> vsock_sock 
PKT_FIELD(vsk, write_notify_window) = <token> <answer> PAGE_SIZE; 
PKT_FIELD(vsk, write_notify_min_window) = <token> <answer> PAGE_SIZE; 
PKT_FIELD(vsk, peer_waiting_write) = <token> <answer> false; 
PKT_FIELD(vsk, peer_waiting_write_detected) <token> false; <answer> = 
static <token> <answer> int 
vmci_transport_notify_pkt_poll_in(struct <token> *sk, <answer> sock 
size_t target, bool <token> <answer> *data_ready_now) 
struct vsock_sock *vsk = <token> <answer> vsock_sk(sk); 
if (vsock_stream_has_data(vsk) <token> target) { <answer> >= 
*data_ready_now <token> true; <answer> = 
} <token> { <answer> else 
if (sk->sk_state == <token> <answer> TCP_ESTABLISHED) 
*data_ready_now = <token> <answer> false; 
<token> 0; <answer> return 
static <token> <answer> int 
<token> sock *sk, <answer> vmci_transport_notify_pkt_poll_out(struct 
size_t target, bool <token> <answer> *space_avail_now) 
<token> produce_q_free_space; <answer> s64 
struct vsock_sock *vsk = <token> <answer> vsock_sk(sk); 
produce_q_free_space <token> vsock_stream_has_space(vsk); <answer> = 
if (produce_q_free_space > 0) <token> <answer> { 
*space_avail_now = <token> <answer> true; 
<token> 0; <answer> return 
} <token> if (produce_q_free_space == 0) { <answer> else 
*space_avail_now = <token> <answer> false; 
<token> 0; <answer> return 
<token> int <answer> static 
struct sock <token> <answer> *sk, 
<token> target, <answer> size_t 
<token> vmci_transport_recv_notify_data *data) <answer> struct 
struct vsock_sock *vsk <token> vsock_sk(sk); <answer> = 
<token> = 0; <answer> data->consume_head 
data->produce_tail <token> 0; <answer> = 
data->notify_on_block = <token> <answer> false; 
<token> (PKT_FIELD(vsk, write_notify_min_window) < target + 1) { <answer> if 
PKT_FIELD(vsk, <token> = target + 1; <answer> write_notify_min_window) 
<token> (PKT_FIELD(vsk, write_notify_window) < <answer> if 
PKT_FIELD(vsk, <token> { <answer> write_notify_min_window)) 
<token> write_notify_window) = <answer> PKT_FIELD(vsk, 
PKT_FIELD(vsk, <token> <answer> write_notify_min_window); 
<token> = true; <answer> data->notify_on_block 
<token> 0; <answer> return 
<token> int <answer> static 
struct <token> *sk, <answer> sock 
size_t <token> <answer> target, 
struct vmci_transport_recv_notify_data <token> <answer> *data) 
<token> err = 0; <answer> int 
if (data->notify_on_block) <token> <answer> { 
err <token> vmci_transport_send_read_notification(sk); <answer> = 
if (err <token> 0) <answer> < 
return <token> <answer> err; 
data->notify_on_block <token> false; <answer> = 
<token> err; <answer> return 
<token> int <answer> static 
struct sock <token> <answer> *sk, 
<token> target, <answer> size_t 
ssize_t <token> <answer> copied, 
bool <token> <answer> data_read, 
struct <token> *data) <answer> vmci_transport_recv_notify_data 
struct <token> *vsk; <answer> vsock_sock 
<token> err; <answer> int 
bool was_full = <token> <answer> false; 
<token> free_space; <answer> u64 
<token> = vsock_sk(sk); <answer> vsk 
err = <token> <answer> 0; 
if <token> { <answer> (data_read) 
<token> = <answer> free_space 
was_full = free_space <token> copied; <answer> == 
if <token> <answer> (was_full) 
PKT_FIELD(vsk, <token> = true; <answer> peer_waiting_write) 
<token> = vmci_transport_send_read_notification(sk); <answer> err 
if (err <token> 0) <answer> < 
<token> err; <answer> return 
<token> err; <answer> return 
<token> int <answer> static 
<token> sock *sk, <answer> struct 
struct vmci_transport_send_notify_data <token> <answer> *data) 
<token> = 0; <answer> data->consume_head 
data->produce_tail <token> 0; <answer> = 
<token> 0; <answer> return 
<token> int <answer> static 
<token> sock *sk, <answer> struct 
ssize_t <token> <answer> written, 
<token> vmci_transport_send_notify_data *data) <answer> struct 
int <token> = 0; <answer> err 
struct <token> *vsk; <answer> vsock_sock 
bool <token> = false; <answer> sent_wrote 
bool <token> <answer> was_empty; 
<token> retries = 0; <answer> int 
vsk = <token> <answer> vsock_sk(sk); 
was_empty <token> <answer> = 
vmci_qpair_produce_buf_ready(vmci_trans(vsk)->qpair) == <token> <answer> written; 
<token> (was_empty) { <answer> if 
while (!(vsk->peer_shutdown <token> RCV_SHUTDOWN) && <answer> & 
!sent_wrote <token> <answer> && 
<token> < VMCI_TRANSPORT_MAX_DGRAM_RESENDS) { <answer> retries 
err = <token> <answer> vmci_transport_send_wrote(sk); 
if <token> >= 0) <answer> (err 
<token> = true; <answer> sent_wrote 
if (retries >= VMCI_TRANSPORT_MAX_DGRAM_RESENDS && <token> { <answer> !sent_wrote) 
pr_err("%p unable to send wrote <token> to peer\n", <answer> notification 
<token> err; <answer> return 
<token> err; <answer> return 
<token> void <answer> static 
struct <token> *sk, <answer> sock 
<token> vmci_transport_packet *pkt, <answer> struct 
<token> bottom_half, <answer> bool 
<token> sockaddr_vm *dst, <answer> struct 
struct sockaddr_vm <token> bool *pkt_processed) <answer> *src, 
<token> processed = false; <answer> bool 
switch <token> { <answer> (pkt->type) 
case <token> <answer> VMCI_TRANSPORT_PACKET_TYPE_WROTE: 
vmci_transport_handle_wrote(sk, pkt, <token> dst, src); <answer> bottom_half, 
processed <token> true; <answer> = 
case <token> <answer> VMCI_TRANSPORT_PACKET_TYPE_READ: 
vmci_transport_handle_read(sk, pkt, bottom_half, <token> src); <answer> dst, 
<token> = true; <answer> processed 
if <token> <answer> (pkt_processed) 
*pkt_processed = <token> <answer> processed; 
static void vmci_transport_notify_pkt_process_request(struct sock <token> <answer> *sk) 
struct vsock_sock *vsk <token> vsock_sk(sk); <answer> = 
<token> write_notify_window) = vmci_trans(vsk)->consume_size; <answer> PKT_FIELD(vsk, 
<token> (vmci_trans(vsk)->consume_size < <answer> if 
PKT_FIELD(vsk, <token> <answer> write_notify_min_window)) 
PKT_FIELD(vsk, write_notify_min_window) <token> <answer> = 
static void vmci_transport_notify_pkt_process_negotiate(struct <token> *sk) <answer> sock 
<token> vsock_sock *vsk = vsock_sk(sk); <answer> struct 
<token> write_notify_window) = vmci_trans(vsk)->consume_size; <answer> PKT_FIELD(vsk, 
if <token> < <answer> (vmci_trans(vsk)->consume_size 
<token> write_notify_min_window)) <answer> PKT_FIELD(vsk, 
PKT_FIELD(vsk, write_notify_min_window) <token> <answer> = 
<token> int <answer> static 
<token> sock *sk, <answer> struct 
<token> target, <answer> size_t 
<token> vmci_transport_recv_notify_data *data) <answer> struct 
#include <token> <answer> "wndw.h" 
#include <token> <answer> "atom.h" 
<token> <nvif/pushc37b.h> <answer> #include 
#include <token> <answer> <nvhw/class/clc57e.h> 
<token> int <answer> static 
wndwc67e_image_set(struct nv50_wndw *wndw, struct nv50_wndw_atom <token> <answer> *asyw) 
struct nvif_push <token> = wndw->wndw.push; <answer> *push 
int <token> <answer> ret; 
if ((ret = PUSH_WAIT(push, <token> <answer> 17))) 
return <token> <answer> ret; 
PUSH_MTHD(push, <token> SET_PRESENT_CONTROL, <answer> NVC57E, 
NVVAL(NVC57E, SET_PRESENT_CONTROL, MIN_PRESENT_INTERVAL, asyw->image.interval) <token> <answer> | 
NVVAL(NVC57E, <token> BEGIN_MODE, asyw->image.mode) | <answer> SET_PRESENT_CONTROL, 
NVDEF(NVC57E, <token> TIMESTAMP_MODE, DISABLE)); <answer> SET_PRESENT_CONTROL, 
PUSH_MTHD(push, <token> SET_SIZE, <answer> NVC57E, 
<token> SET_SIZE, WIDTH, asyw->image.w) | <answer> NVVAL(NVC57E, 
NVVAL(NVC57E, SET_SIZE, HEIGHT, <token> <answer> asyw->image.h), 
NVVAL(NVC57E, <token> BLOCK_HEIGHT, asyw->image.blockh), <answer> SET_STORAGE, 
NVVAL(NVC57E, SET_PARAMS, <token> asyw->image.format) | <answer> FORMAT, 
NVDEF(NVC57E, SET_PARAMS, CLAMP_BEFORE_BLEND, DISABLE) <token> <answer> | 
<token> SET_PARAMS, SWAP_UV, DISABLE) | <answer> NVDEF(NVC57E, 
NVDEF(NVC57E, SET_PARAMS, <token> ROUND_TO_NEAREST), <answer> FMT_ROUNDING_MODE, 
NVVAL(NVC57E, SET_PLANAR_STORAGE, <token> asyw->image.blocks[0]) | <answer> PITCH, 
NVVAL(NVC57E, SET_PLANAR_STORAGE, PITCH, asyw->image.pitch[0] >> <token> <answer> 6)); 
PUSH_MTHD(push, <token> SET_CONTEXT_DMA_ISO(0), asyw->image.handle, 1); <answer> NVC57E, 
PUSH_MTHD(push, NVC57E, <token> asyw->image.offset[0] >> 8); <answer> SET_OFFSET(0), 
<token> NVC57E, SET_POINT_IN(0), <answer> PUSH_MTHD(push, 
NVVAL(NVC57E, SET_POINT_IN, X, <token> >> 16) | <answer> asyw->state.src_x 
<token> SET_POINT_IN, Y, asyw->state.src_y >> 16)); <answer> NVVAL(NVC57E, 
PUSH_MTHD(push, <token> SET_SIZE_IN, <answer> NVC57E, 
NVVAL(NVC57E, SET_SIZE_IN, WIDTH, asyw->state.src_w >> <token> | <answer> 16) 
NVVAL(NVC57E, SET_SIZE_IN, HEIGHT, <token> >> 16)); <answer> asyw->state.src_h 
<token> NVC57E, SET_SIZE_OUT, <answer> PUSH_MTHD(push, 
NVVAL(NVC57E, <token> WIDTH, asyw->state.crtc_w) | <answer> SET_SIZE_OUT, 
NVVAL(NVC57E, SET_SIZE_OUT, <token> asyw->state.crtc_h)); <answer> HEIGHT, 
<token> 0; <answer> return 
<token> const struct nv50_wndw_func <answer> static 
wndwc67e <token> { <answer> = 
.acquire = <token> <answer> wndwc37e_acquire, 
.release <token> wndwc37e_release, <answer> = 
.sema_set = <token> <answer> wndwc37e_sema_set, 
<token> = wndwc37e_sema_clr, <answer> .sema_clr 
<token> = wndwc37e_ntfy_set, <answer> .ntfy_set 
<token> = wndwc37e_ntfy_clr, <answer> .ntfy_clr 
.ntfy_reset = <token> <answer> corec37d_ntfy_init, 
.ntfy_wait_begun <token> base507c_ntfy_wait_begun, <answer> = 
<token> = wndwc57e_ilut, <answer> .ilut 
<token> = true, <answer> .ilut_identity 
.ilut_size = <token> <answer> 1024, 
.xlut_set <token> wndwc57e_ilut_set, <answer> = 
<token> = wndwc57e_ilut_clr, <answer> .xlut_clr 
.csc <token> base907c_csc, <answer> = 
.csc_set = <token> <answer> wndwc57e_csc_set, 
.csc_clr <token> wndwc57e_csc_clr, <answer> = 
.image_set = <token> <answer> wndwc67e_image_set, 
.image_clr = <token> <answer> wndwc37e_image_clr, 
<token> = wndwc37e_blend_set, <answer> .blend_set 
<token> = wndwc37e_update, <answer> .update 
wndwc67e_new(struct nouveau_drm *drm, enum drm_plane_type type, <token> index, <answer> int 
s32 oclass, <token> nv50_wndw **pwndw) <answer> struct 
return wndwc37e_new_(&wndwc67e, drm, type, index, oclass, <token> >> 1), pwndw); <answer> BIT(index 
#include <token> <answer> <linux/clk.h> 
<token> <linux/io.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/platform_data/usb-ohci-s3c2410.h> <answer> #include 
<token> <linux/usb.h> <answer> #include 
<token> <linux/usb/hcd.h> <answer> #include 
<token> "ohci.h" <answer> #include 
<token> valid_port(idx) ((idx) == 1 || (idx) == 2) <answer> #define 
<token> int <answer> static 
ohci_s3c2410_hub_status_data(struct <token> *hcd, char *buf) <answer> usb_hcd 
struct <token> *info = to_s3c2410_info(hcd); <answer> s3c2410_hcd_info 
<token> s3c2410_hcd_port *port; <answer> struct 
<token> orig; <answer> int 
<token> portno; <answer> int 
orig <token> ohci_hub_status_data(hcd, buf); <answer> = 
if <token> == NULL) <answer> (info 
<token> orig; <answer> return 
port = <token> <answer> &info->port[0]; 
<token> void s3c2410_usb_set_power(struct s3c2410_hcd_info *info, <answer> static 
int port, int <token> <answer> to) 
<token> (info == NULL) <answer> if 
<token> (info->power_control != NULL) { <answer> if 
<token> = to; <answer> info->port[port-1].power 
<token> to); <answer> (info->power_control)(port-1, 
static <token> ohci_s3c2410_hub_control( <answer> int 
<token> usb_hcd *hcd, <answer> struct 
u16 <token> <answer> typeReq, 
<token> wValue, <answer> u16 
u16 <token> <answer> wIndex, 
<token> *buf, <answer> char 
<token> wLength) <answer> u16 
struct <token> *info = to_s3c2410_info(hcd); <answer> s3c2410_hcd_info 
struct usb_hub_descriptor <token> <answer> *desc; 
int ret = <token> <answer> -EINVAL; 
u32 *data <token> (u32 *)buf; <answer> = 
hcd, typeReq, wValue, wIndex, buf, <token> <answer> wLength); 
<token> (info == NULL) { <answer> if 
<token> = ohci_hub_control(hcd, typeReq, wValue, <answer> ret 
wIndex, buf, <token> <answer> wLength); 
goto <token> <answer> out; 
desc->wHubCharacteristics &= <token> <answer> ~cpu_to_le16(HUB_CHAR_LPSM); 
<token> |= cpu_to_le16( <answer> desc->wHubCharacteristics 
if <token> { <answer> (info->enable_oc) 
desc->wHubCharacteristics <token> ~cpu_to_le16( <answer> &= 
<token> |= cpu_to_le16( <answer> desc->wHubCharacteristics 
<token> "wHubCharacteristics after 0x%04x\n", <answer> dev_dbg(hcd->self.controller, 
<token> ret; <answer> return 
case <token> <answer> GetPortStatus: 
static void s3c2410_hcd_oc(struct s3c2410_hcd_info <token> int port_oc) <answer> *info, 
struct <token> *port; <answer> s3c2410_hcd_port 
<token> long flags; <answer> unsigned 
<token> portno; <answer> int 
if <token> == NULL) <answer> (info 
port <token> &info->port[0]; <answer> = 
for (portno = 0; portno < 2; port++, <token> { <answer> portno++) 
if (port_oc <token> (1<<portno) && <answer> & 
port->flags & S3C_HCDFLG_USED) <token> <answer> { 
port->oc_status <token> 1; <answer> = 
<token> = 1; <answer> port->oc_changed 
<token> portno+1, 0); <answer> s3c2410_usb_set_power(info, 
static <token> <answer> void 
ohci_hcd_s3c2410_remove(struct <token> *dev) <answer> platform_device 
struct <token> *hcd = platform_get_drvdata(dev); <answer> usb_hcd 
static int ohci_hcd_s3c2410_probe(struct <token> *dev) <answer> platform_device 
struct <token> *hcd = NULL; <answer> usb_hcd 
struct s3c2410_hcd_info *info = <token> <answer> dev_get_platdata(&dev->dev); 
int retval, <token> <answer> irq; 
s3c2410_usb_set_power(info, 1, <token> <answer> 1); 
s3c2410_usb_set_power(info, 2, <token> <answer> 1); 
hcd = usb_create_hcd(&ohci_s3c2410_hc_driver, &dev->dev, <token> <answer> "s3c24xx"); 
if (hcd == <token> <answer> NULL) 
return <token> <answer> -ENOMEM; 
hcd->rsrc_start <token> dev->resource[0].start; <answer> = 
hcd->rsrc_len = <token> <answer> resource_size(&dev->resource[0]); 
<token> = devm_ioremap_resource(&dev->dev, &dev->resource[0]); <answer> hcd->regs 
if (IS_ERR(hcd->regs)) <token> <answer> { 
<token> = PTR_ERR(hcd->regs); <answer> retval 
<token> err_put; <answer> goto 
clk = devm_clk_get(&dev->dev, <token> <answer> "usb-host"); 
if (IS_ERR(clk)) <token> <answer> { 
dev_err(&dev->dev, "cannot get <token> clock\n"); <answer> usb-host 
retval <token> PTR_ERR(clk); <answer> = 
<token> err_put; <answer> goto 
usb_clk <token> devm_clk_get(&dev->dev, "usb-bus-host"); <answer> = 
if <token> { <answer> (IS_ERR(usb_clk)) 
dev_err(&dev->dev, "cannot <token> usb-bus-host clock\n"); <answer> get 
retval <token> PTR_ERR(usb_clk); <answer> = 
goto <token> <answer> err_put; 
irq = platform_get_irq(dev, <token> <answer> 0); 
if (irq < 0) <token> <answer> { 
<token> = irq; <answer> retval 
<token> err_put; <answer> goto 
<token> hcd); <answer> s3c2410_start_hc(dev, 
<token> = usb_add_hcd(hcd, irq, 0); <answer> retval 
<token> (retval != 0) <answer> if 
<token> err_ioremap; <answer> goto 
return <token> <answer> 0; 
<token> retval; <answer> return 
<token> = ohci_s3c2410_hub_status_data; <answer> ohci_s3c2410_hc_driver.hub_status_data 
ohci_s3c2410_hc_driver.hub_control <token> ohci_s3c2410_hub_control; <answer> = 
return <token> <answer> platform_driver_register(&ohci_hcd_s3c2410_driver); 
static <token> __exit ohci_s3c2410_cleanup(void) <answer> void 
#define pr_fmt(fmt) <token> " fmt <answer> "xen-blkback: 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/kthread.h> <answer> #include 
#include <token> <answer> <linux/list.h> 
#include <token> <answer> <linux/delay.h> 
<token> <linux/freezer.h> <answer> #include 
<token> <linux/bitmap.h> <answer> #include 
<token> <xen/events.h> <answer> #include 
<token> <xen/page.h> <answer> #include 
#include <token> <answer> <xen/xen.h> 
<token> <asm/xen/hypervisor.h> <answer> #include 
#include <token> <answer> <asm/xen/hypercall.h> 
<token> <xen/balloon.h> <answer> #include 
#include <token> <answer> <xen/grant_table.h> 
<token> "common.h" <answer> #include 
static int max_buffer_pages = <token> <answer> 1024; 
module_param_named(max_buffer_pages, max_buffer_pages, <token> 0644); <answer> int, 
"Maximum number of free pages to keep in each <token> backend buffer"); <answer> block 
static int max_pgrants = <token> <answer> 1056; 
module_param_named(max_persistent_grants, <token> int, 0644); <answer> max_pgrants, 
"Maximum number of grants to map <token> <answer> persistently"); 
static unsigned int <token> = 60; <answer> pgrant_timeout 
module_param_named(persistent_grant_unused_seconds, <token> <answer> pgrant_timeout, 
<token> 0644); <answer> uint, 
"Time in seconds an unused persistent <token> is allowed to " <answer> grant 
"remain allocated. Default <token> 60, 0 means unlimited."); <answer> is 
unsigned <token> xenblk_max_queues; <answer> int 
module_param_named(max_queues, xenblk_max_queues, <token> 0644); <answer> uint, 
"Maximum number of hardware queues <token> virtual disk." \ <answer> per 
"By default it <token> the number of online CPUs."); <answer> is 
unsigned int xen_blkif_max_ring_order = <token> <answer> XENBUS_MAX_RING_GRANT_ORDER; 
module_param_named(max_ring_page_order, <token> int, 0444); <answer> xen_blkif_max_ring_order, 
MODULE_PARM_DESC(max_ring_page_order, "Maximum order of pages to be used for <token> shared ring"); <answer> the 
#define LRU_INTERVAL <token> <answer> 100 
#define <token> 5 <answer> LRU_PERCENT_CLEAN 
static <token> add_persistent_gnt(struct xen_blkif_ring *ring, <answer> int 
struct persistent_gnt <token> <answer> *persistent_gnt) 
struct rb_node **new = NULL, *parent = <token> <answer> NULL; 
struct <token> *this; <answer> persistent_gnt 
<token> xen_blkif *blkif = ring->blkif; <answer> struct 
<token> (ring->persistent_gnt_c >= max_pgrants) { <answer> if 
if <token> <answer> (!blkif->vbd.overflow_max_grants) 
blkif->vbd.overflow_max_grants = <token> <answer> 1; 
<token> -EBUSY; <answer> return 
<token> = 0; <answer> total 
<token> = &ring->persistent_gnts; <answer> root 
<token> n, root, node) { <answer> foreach_grant_safe(persistent_gnt, 
<token> == <answer> BUG_ON(persistent_gnt->handle 
if <token> <answer> (persistent_gnt->active) 
<token> (!scan_used && !persistent_gnt_timeout(persistent_gnt)) <answer> if 
if <token> && total >= num_clean) <answer> (scan_used 
rb_erase(&persistent_gnt->node, <token> <answer> root); 
if (!scan_used <token> total < num_clean) { <answer> && 
pr_debug("Still missing %u purged frames\n", num_clean - <token> <answer> total); 
scan_used = <token> <answer> true; 
goto <token> <answer> purge_list; 
if (total) <token> <answer> { 
ring->persistent_gnt_c -= <token> <answer> total; 
ring->blkif->vbd.overflow_max_grants <token> 0; <answer> = 
static struct pending_req *alloc_req(struct xen_blkif_ring <token> <answer> *ring) 
struct pending_req *req <token> NULL; <answer> = 
<token> long flags; <answer> unsigned 
spin_lock_irqsave(&ring->pending_free_lock, <token> <answer> flags); 
<token> (!list_empty(&ring->pending_free)) { <answer> if 
<token> = list_entry(ring->pending_free.next, struct pending_req, <answer> req 
spin_unlock_irqrestore(&ring->pending_free_lock, <token> <answer> flags); 
return <token> <answer> req; 
static void free_req(struct xen_blkif_ring *ring, <token> pending_req *req) <answer> struct 
unsigned long <token> <answer> flags; 
int <token> <answer> was_empty; 
spin_lock_irqsave(&ring->pending_free_lock, <token> <answer> flags); 
<token> = list_empty(&ring->pending_free); <answer> was_empty 
list_add(&req->free_list, <token> <answer> &ring->pending_free); 
spin_unlock_irqrestore(&ring->pending_free_lock, <token> <answer> flags); 
if <token> <answer> (was_empty) 
static int xen_vbd_translate(struct phys_req <token> struct xen_blkif *blkif, <answer> *req, 
<token> req_op operation) <answer> enum 
struct xen_vbd <token> = &blkif->vbd; <answer> *vbd 
int rc = <token> <answer> -EACCES; 
<token> ((operation != REQ_OP_READ) && vbd->readonly) <answer> if 
<token> out; <answer> goto 
if (likely(req->nr_sects)) <token> <answer> { 
blkif_sector_t end = <token> + req->nr_sects; <answer> req->sector_number 
if <token> < req->sector_number)) <answer> (unlikely(end 
<token> out; <answer> goto 
if (unlikely(end <token> vbd_sz(vbd))) <answer> > 
<token> out; <answer> goto 
req->dev <token> vbd->pdevice; <answer> = 
req->bdev <token> file_bdev(vbd->bdev_file); <answer> = 
rc = <token> <answer> 0; 
return <token> <answer> rc; 
static void xen_vbd_resize(struct <token> *blkif) <answer> xen_blkif 
struct xen_vbd *vbd = <token> <answer> &blkif->vbd; 
struct <token> xbt; <answer> xenbus_transaction 
int <token> <answer> err; 
struct xenbus_device <token> = xen_blkbk_xenbus(blkif->be); <answer> *dev 
unsigned long long new_size <token> vbd_sz(vbd); <answer> = 
pr_info("VBD Resize: Domid: %d, <token> (%d, %d)\n", <answer> Device: 
blkif->domid, <token> MINOR(vbd->pdevice)); <answer> MAJOR(vbd->pdevice), 
pr_info("VBD Resize: <token> size %llu\n", new_size); <answer> new 
vbd->size = <token> <answer> new_size; 
err = <token> <answer> xenbus_transaction_start(&xbt); 
<token> (err) { <answer> if 
pr_warn("Error starting <token> <answer> transaction\n"); 
err = xenbus_printf(xbt, dev->nodename, <token> "%llu", <answer> "sectors", 
<token> long long)vbd_sz(vbd)); <answer> (unsigned 
if (err) <token> <answer> { 
pr_warn("Error writing new <token> <answer> size\n"); 
goto <token> <answer> abort; 
err = xenbus_printf(xbt, dev->nodename, "state", "%d", <token> <answer> dev->state); 
if <token> { <answer> (err) 
pr_warn("Error <token> the state\n"); <answer> writing 
goto <token> <answer> abort; 
err = xenbus_transaction_end(xbt, <token> <answer> 0); 
<token> (err == -EAGAIN) <answer> if 
<token> again; <answer> goto 
<token> (err) <answer> if 
pr_warn("Error ending <token> <answer> transaction\n"); 
xenbus_transaction_end(xbt, <token> <answer> 1); 
static void <token> xen_blkif_ring *ring) <answer> blkif_notify_work(struct 
ring->waiting_reqs <token> 1; <answer> = 
irqreturn_t <token> irq, void *dev_id) <answer> xen_blkif_be_int(int 
return <token> <answer> IRQ_HANDLED; 
static void <token> xen_blkif_ring *ring) <answer> print_stats(struct 
pr_info("(%s): oo %3llu | rd %4llu | wr %4llu | <token> %4llu" <answer> f 
" | ds %4llu <token> pg: %4u/%4d\n", <answer> | 
current->comm, <token> <answer> ring->st_oo_req, 
ring->st_rd_req, <token> <answer> ring->st_wr_req, 
ring->st_f_req, <token> <answer> ring->st_ds_req, 
<token> max_pgrants); <answer> ring->persistent_gnt_c, 
ring->st_print = jiffies + msecs_to_jiffies(10 * <token> <answer> 1000); 
<token> = 0; <answer> ring->st_rd_req 
ring->st_wr_req = <token> <answer> 0; 
ring->st_oo_req <token> 0; <answer> = 
<token> = 0; <answer> ring->st_ds_req 
<token> xen_blkif_schedule(void *arg) <answer> int 
struct <token> *ring = arg; <answer> xen_blkif_ring 
<token> xen_blkif *blkif = ring->blkif; <answer> struct 
struct <token> *vbd = &blkif->vbd; <answer> xen_vbd 
unsigned long <token> <answer> timeout; 
<token> ret; <answer> int 
<token> do_eoi; <answer> bool 
unsigned <token> eoi_flags = XEN_EOI_FLAG_SPURIOUS; <answer> int 
while <token> { <answer> (!kthread_should_stop()) 
if <token> <answer> (try_to_freeze()) 
if (unlikely(vbd->size <token> vbd_sz(vbd))) <answer> != 
timeout = <token> <answer> msecs_to_jiffies(LRU_INTERVAL); 
timeout <token> wait_event_interruptible_timeout( <answer> = 
ring->waiting_reqs || <token> <answer> kthread_should_stop(), 
if <token> == 0) <answer> (timeout 
<token> purge_gnt_list; <answer> goto 
timeout <token> wait_event_interruptible_timeout( <answer> = 
<token> || <answer> !list_empty(&ring->pending_free) 
if (timeout == <token> <answer> 0) 
<token> purge_gnt_list; <answer> goto 
<token> = ring->waiting_reqs; <answer> do_eoi 
ring->waiting_reqs = <token> <answer> 0; 
void <token> xen_blkif_ring *ring) <answer> xen_blkbk_free_caches(struct 
gnttab_page_cache_put(&ring->free_pages, <token> data->count); <answer> data->pages, 
make_response(ring, <token> <answer> pending_req->id, 
pending_req->operation, <token> <answer> pending_req->status); 
free_req(ring, <token> <answer> pending_req); 
if (atomic_dec_and_test(&ring->inflight) && <token> { <answer> atomic_read(&blkif->drain)) 
static void xen_blkbk_unmap_and_respond(struct <token> *req) <answer> pending_req 
struct gntab_unmap_queue_data* work <token> &req->gnttab_unmap_data; <answer> = 
<token> xen_blkif_ring *ring = req->ring; <answer> struct 
<token> grant_page **pages = req->segments; <answer> struct 
<token> int invcount; <answer> unsigned 
invcount = xen_blkbk_unmap_prepare(ring, pages, <token> <answer> req->nr_segs, 
req->unmap, <token> <answer> req->unmap_pages); 
work->data <token> req; <answer> = 
<token> = xen_blkbk_unmap_and_respond_callback; <answer> work->done 
<token> = req->unmap; <answer> work->unmap_ops 
work->kunmap_ops <token> NULL; <answer> = 
work->pages <token> req->unmap_pages; <answer> = 
<token> = invcount; <answer> work->count 
static void xen_blkbk_unmap(struct <token> *ring, <answer> xen_blkif_ring 
<token> grant_page *pages[], <answer> struct 
int <token> <answer> num) 
struct <token> unmap[BLKIF_MAX_SEGMENTS_PER_REQUEST]; <answer> gnttab_unmap_grant_ref 
struct <token> *unmap_pages[BLKIF_MAX_SEGMENTS_PER_REQUEST]; <answer> page 
unsigned <token> invcount = 0; <answer> int 
<token> ret; <answer> int 
while <token> { <answer> (num) 
unsigned int batch <token> min(num, BLKIF_MAX_SEGMENTS_PER_REQUEST); <answer> = 
invcount = xen_blkbk_unmap_prepare(ring, pages, <token> <answer> batch, 
unmap, <token> <answer> unmap_pages); 
if (invcount) <token> <answer> { 
ret = gnttab_unmap_refs(unmap, <token> unmap_pages, invcount); <answer> NULL, 
<token> unmap_pages, <answer> gnttab_page_cache_put(&ring->free_pages, 
pages <token> batch; <answer> += 
num -= <token> <answer> batch; 
<token> int xen_blkbk_map(struct xen_blkif_ring *ring, <answer> static 
struct <token> *pages[], <answer> grant_page 
int num, bool <token> <answer> ro) 
struct <token> map[BLKIF_MAX_SEGMENTS_PER_REQUEST]; <answer> gnttab_map_grant_ref 
<token> page *pages_to_gnt[BLKIF_MAX_SEGMENTS_PER_REQUEST]; <answer> struct 
struct <token> *persistent_gnt = NULL; <answer> persistent_gnt 
phys_addr_t addr <token> 0; <answer> = 
<token> i, seg_idx, new_map_idx; <answer> int 
int <token> = 0; <answer> segs_to_map 
int ret <token> 0; <answer> = 
int last_map = <token> map_until = 0; <answer> 0, 
<token> use_persistent_gnts; <answer> int 
struct xen_blkif *blkif <token> ring->blkif; <answer> = 
use_persistent_gnts = <token> <answer> (blkif->vbd.feature_gnt_persistent); 
for (i = <token> i < num; i++) { <answer> map_until; 
<token> flags; <answer> uint32_t 
if <token> { <answer> (use_persistent_gnts) 
persistent_gnt <token> get_persistent_gnt( <answer> = 
if <token> { <answer> (persistent_gnt) 
pages[i]->page <token> persistent_gnt->page; <answer> = 
pages[i]->persistent_gnt = <token> <answer> persistent_gnt; 
<token> else { <answer> } 
if <token> <answer> (gnttab_page_cache_get(&ring->free_pages, 
&pages[i]->page)) <token> <answer> { 
ret = <token> <answer> -ENOMEM; 
<token> out; <answer> goto 
<token> = vaddr(pages[i]->page); <answer> addr 
<token> = pages[i]->page; <answer> pages_to_gnt[segs_to_map] 
pages[i]->persistent_gnt <token> NULL; <answer> = 
flags = <token> <answer> GNTMAP_host_map; 
if (!use_persistent_gnts <token> ro) <answer> && 
flags <token> GNTMAP_readonly; <answer> |= 
<token> addr, <answer> gnttab_set_map_op(&map[segs_to_map++], 
<token> pages[i]->gref, <answer> flags, 
map_until = i <token> 1; <answer> + 
<token> (segs_to_map == BLKIF_MAX_SEGMENTS_PER_REQUEST) <answer> if 
if <token> <answer> (segs_to_map) 
ret = <token> NULL, pages_to_gnt, segs_to_map); <answer> gnttab_map_refs(map, 
for (seg_idx = last_map, new_map_idx = <token> seg_idx < map_until; seg_idx++) { <answer> 0; 
if (!pages[seg_idx]->persistent_gnt) <token> <answer> { 
<token> = kmalloc(sizeof(struct persistent_gnt), <answer> persistent_gnt 
if (!persistent_gnt) <token> <answer> { 
goto <token> <answer> next; 
persistent_gnt->gnt = <token> <answer> map[new_map_idx].ref; 
persistent_gnt->handle = <token> <answer> map[new_map_idx].handle; 
<token> = pages[seg_idx]->page; <answer> persistent_gnt->page 
<token> (add_persistent_gnt(ring, <answer> if 
persistent_gnt)) <token> <answer> { 
persistent_gnt = <token> <answer> NULL; 
goto <token> <answer> next; 
pages[seg_idx]->persistent_gnt = <token> <answer> persistent_gnt; 
pr_debug("grant %u added to the <token> of persistent grants, using %u/%u\n", <answer> tree 
persistent_gnt->gnt, <token> <answer> ring->persistent_gnt_c, 
<token> next; <answer> goto 
if (use_persistent_gnts && !blkif->vbd.overflow_max_grants) <token> <answer> { 
blkif->vbd.overflow_max_grants <token> 1; <answer> = 
pr_debug("domain %u, device %#x <token> using maximum number of persistent grants\n", <answer> is 
<token> blkif->vbd.handle); <answer> blkif->domid, 
<token> = 0; <answer> segs_to_map 
last_map <token> map_until; <answer> = 
if <token> && map_until != num) <answer> (!ret 
<token> again; <answer> goto 
for (i = last_map; i < <token> i++) { <answer> num; 
<token> (atomic_dec_and_test(&pending_req->pendcnt)) <answer> if 
static void end_block_io_op(struct <token> *bio) <answer> bio 
<token> bio->bi_status); <answer> __end_block_io_op(bio->bi_private, 
static void blkif_get_x86_32_req(struct blkif_request <token> <answer> *dst, 
const <token> blkif_x86_32_request *src) <answer> struct 
unsigned int <token> n; <answer> i, 
dst->operation = <token> <answer> READ_ONCE(src->operation); 
switch (dst->operation) <token> <answer> { 
case <token> <answer> BLKIF_OP_READ: 
case <token> <answer> BLKIF_OP_WRITE: 
case <token> <answer> BLKIF_OP_WRITE_BARRIER: 
case <token> <answer> BLKIF_OP_FLUSH_DISKCACHE: 
dst->u.rw.nr_segments <token> READ_ONCE(src->u.rw.nr_segments); <answer> = 
dst->u.rw.handle = <token> <answer> src->u.rw.handle; 
dst->u.rw.id = <token> <answer> src->u.rw.id; 
dst->u.rw.sector_number <token> src->u.rw.sector_number; <answer> = 
n <token> min_t(unsigned int, BLKIF_MAX_SEGMENTS_PER_REQUEST, <answer> = 
for (i = <token> i < n; i++) <answer> 0; 
dst->u.rw.seg[i] = <token> <answer> src->u.rw.seg[i]; 
case <token> <answer> BLKIF_OP_DISCARD: 
dst->u.discard.flag = <token> <answer> src->u.discard.flag; 
dst->u.discard.id <token> src->u.discard.id; <answer> = 
dst->u.discard.sector_number <token> src->u.discard.sector_number; <answer> = 
<token> = src->u.discard.nr_sectors; <answer> dst->u.discard.nr_sectors 
case <token> <answer> BLKIF_OP_INDIRECT: 
dst->u.indirect.indirect_op <token> src->u.indirect.indirect_op; <answer> = 
dst->u.indirect.nr_segments <token> <answer> = 
dst->u.indirect.handle <token> src->u.indirect.handle; <answer> = 
dst->u.indirect.id <token> src->u.indirect.id; <answer> = 
dst->u.indirect.sector_number <token> src->u.indirect.sector_number; <answer> = 
n = <token> <answer> min(MAX_INDIRECT_PAGES, 
for (i = 0; <token> < n; i++) <answer> i 
<token> = <answer> dst->u.indirect.indirect_grefs[i] 
dst->u.other.id = <token> <answer> src->u.other.id; 
static void blkif_get_x86_64_req(struct blkif_request <token> <answer> *dst, 
const struct <token> *src) <answer> blkif_x86_64_request 
unsigned int i, <token> <answer> n; 
<token> = READ_ONCE(src->operation); <answer> dst->operation 
switch (dst->operation) <token> <answer> { 
<token> BLKIF_OP_READ: <answer> case 
<token> BLKIF_OP_WRITE: <answer> case 
case <token> <answer> BLKIF_OP_WRITE_BARRIER: 
<token> BLKIF_OP_FLUSH_DISKCACHE: <answer> case 
dst->u.rw.nr_segments <token> READ_ONCE(src->u.rw.nr_segments); <answer> = 
dst->u.rw.handle <token> src->u.rw.handle; <answer> = 
dst->u.rw.id = <token> <answer> src->u.rw.id; 
dst->u.rw.sector_number = <token> <answer> src->u.rw.sector_number; 
n = <token> int, BLKIF_MAX_SEGMENTS_PER_REQUEST, <answer> min_t(unsigned 
for (i <token> 0; i < n; i++) <answer> = 
dst->u.rw.seg[i] <token> src->u.rw.seg[i]; <answer> = 
<token> BLKIF_OP_DISCARD: <answer> case 
dst->u.discard.flag = <token> <answer> src->u.discard.flag; 
dst->u.discard.id = <token> <answer> src->u.discard.id; 
dst->u.discard.sector_number <token> src->u.discard.sector_number; <answer> = 
dst->u.discard.nr_sectors <token> src->u.discard.nr_sectors; <answer> = 
case <token> <answer> BLKIF_OP_INDIRECT: 
dst->u.indirect.indirect_op = <token> <answer> src->u.indirect.indirect_op; 
<token> = <answer> dst->u.indirect.nr_segments 
dst->u.indirect.handle <token> src->u.indirect.handle; <answer> = 
dst->u.indirect.id = <token> <answer> src->u.indirect.id; 
dst->u.indirect.sector_number <token> src->u.indirect.sector_number; <answer> = 
n = <token> <answer> min(MAX_INDIRECT_PAGES, 
for <token> = 0; i < n; i++) <answer> (i 
<token> = <answer> dst->u.indirect.indirect_grefs[i] 
dst->u.other.id = <token> <answer> src->u.other.id; 
<token> int <answer> static 
__do_block_io_op(struct <token> *ring, unsigned int *eoi_flags) <answer> xen_blkif_ring 
union blkif_back_rings *blk_rings = <token> <answer> &ring->blk_rings; 
<token> blkif_request req; <answer> struct 
<token> pending_req *pending_req; <answer> struct 
<token> rc, rp; <answer> RING_IDX 
<token> more_to_do = 0; <answer> int 
<token> = blk_rings->common.req_cons; <answer> rc 
rp <token> blk_rings->common.sring->req_prod; <answer> = 
static <token> dispatch_rw_block_io(struct xen_blkif_ring *ring, <answer> int 
struct blkif_request <token> <answer> *req, 
struct <token> *pending_req) <answer> pending_req 
struct phys_req <token> <answer> preq; 
struct <token> *seg = pending_req->seg; <answer> seg_buf 
unsigned int <token> <answer> nseg; 
struct <token> *bio = NULL; <answer> bio 
struct bio **biolist = <token> <answer> pending_req->biolist; 
int i, nbio = <token> <answer> 0; 
<token> req_op operation; <answer> enum 
<token> operation_flags = 0; <answer> blk_opf_t 
<token> blk_plug plug; <answer> struct 
<token> drain = false; <answer> bool 
struct grant_page **pages <token> pending_req->segments; <answer> = 
unsigned short <token> <answer> req_operation; 
req_operation = req->operation <token> BLKIF_OP_INDIRECT ? <answer> == 
req->u.indirect.indirect_op <token> req->operation; <answer> : 
if <token> == BLKIF_OP_INDIRECT) && <answer> ((req->operation 
<token> != BLKIF_OP_READ) && <answer> (req_operation 
(req_operation <token> BLKIF_OP_WRITE)) { <answer> != 
pr_debug("Invalid indirect <token> (%u)\n", req_operation); <answer> operation 
<token> fail_response; <answer> goto 
switch <token> { <answer> (req_operation) 
<token> BLKIF_OP_READ: <answer> case 
operation = <token> <answer> REQ_OP_READ; 
<token> BLKIF_OP_WRITE: <answer> case 
operation <token> REQ_OP_WRITE; <answer> = 
operation_flags = REQ_SYNC | <token> <answer> REQ_IDLE; 
<token> BLKIF_OP_WRITE_BARRIER: <answer> case 
<token> = true; <answer> drain 
case <token> <answer> BLKIF_OP_FLUSH_DISKCACHE: 
operation <token> REQ_OP_WRITE; <answer> = 
<token> = REQ_PREFLUSH; <answer> operation_flags 
for (i = 0; i < <token> i++) { <answer> nseg; 
if <token> & <answer> (((int)preq.sector_number|(int)seg[i].nsec) 
<token> >> 9) - 1)) { <answer> ((bdev_logical_block_size(preq.bdev) 
pr_debug("Misaligned I/O request <token> domain %d\n", <answer> from 
<token> fail_response; <answer> goto 
if <token> <answer> (drain) 
if <token> <answer> (xen_blkbk_map_seg(pending_req)) 
goto <token> <answer> fail_flush; 
for (i = 0; i < nseg; i++) <token> <answer> { 
while ((bio == NULL) <token> <answer> || 
seg[i].nsec <token> 9, <answer> << 
seg[i].offset) == 0)) <token> <answer> { 
bio = bio_alloc(preq.bdev, bio_max_segs(nseg <token> i), <answer> - 
operation | <token> <answer> operation_flags, 
biolist[nbio++] = <token> <answer> bio; 
bio->bi_private <token> pending_req; <answer> = 
bio->bi_end_io = <token> <answer> end_block_io_op; 
bio->bi_iter.bi_sector <token> preq.sector_number; <answer> = 
preq.sector_number += <token> <answer> seg[i].nsec; 
static void make_response(struct xen_blkif_ring *ring, u64 <token> <answer> id, 
<token> short op, int st) <answer> unsigned 
<token> blkif_response *resp; <answer> struct 
<token> long flags; <answer> unsigned 
<token> blkif_back_rings *blk_rings; <answer> union 
<token> notify; <answer> int 
spin_lock_irqsave(&ring->blk_ring_lock, <token> <answer> flags); 
blk_rings <token> &ring->blk_rings; <answer> = 
#include <token> <answer> <linux/delay.h> 
<token> "iosm_ipc_chnl_cfg.h" <answer> #include 
#include <token> <answer> "iosm_ipc_devlink.h" 
#include <token> <answer> "iosm_ipc_imem.h" 
<token> "iosm_ipc_imem_ops.h" <answer> #include 
#include <token> <answer> "iosm_ipc_port.h" 
#include <token> <answer> "iosm_ipc_task_queue.h" 
if (channel->state != IMEM_CHANNEL_RESERVED) <token> <answer> { 
"ch[%d]:invalid channel state <token> %d", <answer> %d,expected 
<token> channel->state, <answer> channel->channel_id, 
goto <token> <answer> channel_unavailable; 
<token> channel_available; <answer> goto 
<token> ipc_imem_sys_port_close(struct iosm_imem *ipc_imem, <answer> void 
struct <token> *channel) <answer> ipc_mem_channel 
<token> ipc_phase curr_phase; <answer> enum 
int <token> = 0; <answer> status 
<token> tail = 0; <answer> u32 
curr_phase <token> ipc_imem->phase; <answer> = 
if (curr_phase == <token> { <answer> IPC_P_OFF) 
"nothing to <token> Current Phase: %s", <answer> do. 
if (channel->state == <token> { <answer> IMEM_CHANNEL_FREE) 
dev_err(ipc_imem->dev, <token> invalid channel state %d", <answer> "ch[%d]: 
channel->channel_id, <token> <answer> channel->state); 
if (channel->ul_pipe.old_tail != <token> { <answer> channel->ul_pipe.old_head) 
ipc_imem->app_notify_ul_pend <token> 1; <answer> = 
status <token> wait_for_completion_interruptible_timeout <answer> = 
if (status <token> 0) { <answer> == 
"Pend data Timeout UL-Pipe:%d Head:%d <token> <answer> Tail:%d", 
<token> = 0; <answer> ipc_imem->app_notify_ul_pend 
<token> NULL, &tail); <answer> &channel->dl_pipe, 
<token> (tail != channel->dl_pipe.old_tail) { <answer> if 
ipc_imem->app_notify_dl_pend <token> 1; <answer> = 
status <token> wait_for_completion_interruptible_timeout <answer> = 
<token> (status == 0) { <answer> if 
"Pend data Timeout DL-Pipe:%d Head:%d <token> <answer> Tail:%d", 
<token> = 0; <answer> ipc_imem->app_notify_dl_pend 
channel->state <token> IMEM_CHANNEL_CLOSING; <answer> = 
ipc_imem_pipe_close(ipc_imem, <token> <answer> &channel->ul_pipe); 
ipc_imem_pipe_close(ipc_imem, <token> <answer> &channel->dl_pipe); 
if <token> != channel->ul_pipe.old_head) { <answer> (channel->ul_pipe.old_tail 
status <token> wait_for_completion_interruptible_timeout <answer> = 
if (status == <token> { <answer> 0) 
<token> Timeout on UL-Pipe:%d Head:%d Tail:%d", <answer> "Data 
<token> NULL, &tail); <answer> &channel->dl_pipe, 
if (tail != <token> { <answer> channel->dl_pipe.old_tail) 
status <token> wait_for_completion_interruptible_timeout <answer> = 
if (status <token> 0) { <answer> == 
"Data Timeout on <token> Head:%d Tail:%d", <answer> DL-Pipe:%d 
channel->state = <token> <answer> IMEM_CHANNEL_CLOSING; 
ipc_mmio_set_psi_addr_and_size(ipc_imem->mmio, mapping, <token> <answer> count); 
ipc_doorbell_fire(ipc_imem->pcie, 0, <token> <answer> IPC_MEM_EXEC_STAGE_BOOT); 
ret = <token> <answer> wait_for_completion_interruptible_timeout 
if (ret <token> 0) { <answer> <= 
dev_err(ipc_imem->dev, "Failed PSI transfer <token> CP, Error-%d", <answer> to 
<token> psi_transfer_fail; <answer> goto 
do <token> <answer> { 
<token> = ipc_mmio_get_exec_stage(ipc_imem->mmio); <answer> exec_stage 
if (exec_stage == <token> <answer> IPC_MEM_EXEC_STAGE_PSI) 
psi_start_timeout -= <token> <answer> 20; 
} while <token> > 0); <answer> (psi_start_timeout 
if <token> != IPC_MEM_EXEC_STAGE_PSI) <answer> (exec_stage 
ret <token> wait_for_completion_interruptible_timeout <answer> = 
(&channel->ul_sem, <token> <answer> msecs_to_jiffies(IPC_PSI_TRANSFER_TIMEOUT)); 
<token> (ret <= 0) { <answer> if 
<token> PSI RUNNING state on CP, Error-%d", ret); <answer> "Failed 
<token> psi_transfer_fail; <answer> goto 
if <token> != <answer> (ipc_mmio_get_ipc_state(ipc_imem->mmio) 
IPC_MEM_DEVICE_IPC_RUNNING) <token> <answer> { 
"ch[%d] <token> unexpected CP IPC state %d, not RUNNING", <answer> %s: 
goto <token> <answer> psi_transfer_fail; 
if (ipc_imem->phase <token> IPC_P_ROM) { <answer> == 
<token> = ipc_imem_sys_psi_transfer(ipc_imem, channel, buf, count); <answer> ret 
if <token> > 0) <answer> (ret 
goto <token> <answer> out; 
<token> <linux/bitfield.h> <answer> #include 
<token> <linux/bits.h> <answer> #include 
#include <token> <answer> <linux/device.h> 
<token> <linux/err.h> <answer> #include 
<token> <linux/gpio/regmap.h> <answer> #include 
#include <token> <answer> <linux/i8254.h> 
<token> <linux/iio/iio.h> <answer> #include 
#include <token> <answer> <linux/iio/types.h> 
#include <token> <answer> <linux/isa.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/limits.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/moduleparam.h> <answer> #include 
<token> <linux/mutex.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/types.h> 
<token> STX104_OUT_CHAN(chan) { \ <answer> #define 
.type = <token> \ <answer> IIO_VOLTAGE, 
<token> = chan, \ <answer> .channel 
.info_mask_separate = BIT(IIO_CHAN_INFO_RAW), <token> <answer> \ 
.indexed = 1, <token> <answer> \ 
.output = 1 <token> <answer> \ 
#define STX104_IN_CHAN(chan, <token> { \ <answer> diff) 
.type = <token> \ <answer> IIO_VOLTAGE, 
.channel = <token> \ <answer> chan, 
.channel2 = chan, <token> <answer> \ 
.info_mask_shared_by_type = BIT(IIO_CHAN_INFO_HARDWAREGAIN) <token> \ <answer> | 
BIT(IIO_CHAN_INFO_OFFSET) <token> BIT(IIO_CHAN_INFO_SCALE), \ <answer> | 
<token> = BIT(IIO_CHAN_INFO_RAW), \ <answer> .info_mask_separate 
.indexed = 1, <token> <answer> \ 
.differential = <token> \ <answer> diff 
<token> STX104_NUM_OUT_CHAN 2 <answer> #define 
#define STX104_EXTENT <token> <answer> 16 
static unsigned <token> base[max_num_isa_dev(STX104_EXTENT)]; <answer> int 
static unsigned <token> num_stx104; <answer> int 
<token> uint, ioport, &num_stx104, 0); <answer> module_param_hw_array(base, 
<token> "Apex Embedded Systems STX104 base addresses"); <answer> MODULE_PARM_DESC(base, 
#define STX104_AIO_BASE <token> <answer> 0x0 
<token> STX104_SOFTWARE_STROBE STX104_AIO_BASE <answer> #define 
#define STX104_ADC_DATA <token> <answer> STX104_AIO_BASE 
<token> STX104_ADC_CHANNEL (STX104_AIO_BASE + 0x2) <answer> #define 
<token> STX104_DIO_REG (STX104_AIO_BASE + 0x3) <answer> #define 
#define STX104_DAC_BASE (STX104_AIO_BASE <token> 0x4) <answer> + 
#define STX104_ADC_STATUS (STX104_AIO_BASE + <token> <answer> 0x8) 
<token> STX104_ADC_CONTROL (STX104_AIO_BASE + 0x9) <answer> #define 
<token> STX104_ADC_CONFIGURATION (STX104_AIO_BASE + 0x11) <answer> #define 
<token> STX104_I8254_BASE (STX104_AIO_BASE + 0x12) <answer> #define 
<token> STX104_AIO_DATA_STRIDE 2 <answer> #define 
#define STX104_DAC_OFFSET(_channel) <token> + STX104_AIO_DATA_STRIDE * (_channel)) <answer> (STX104_DAC_BASE 
struct stx104_iio <token> <answer> { 
struct mutex <token> <answer> lock; 
struct <token> *aio_data_map; <answer> regmap 
struct <token> *aio_ctl_map; <answer> regmap 
<token> const struct regmap_range aio_ctl_wr_ranges[] = { <answer> static 
regmap_reg_range(0x0, 0x0), regmap_reg_range(0x2, 0x2), regmap_reg_range(0x9, <token> <answer> 0x9), 
<token> 0x11), <answer> regmap_reg_range(0x11, 
static const struct regmap_range aio_ctl_rd_ranges[] <token> { <answer> = 
regmap_reg_range(0x2, 0x2), <token> 0x9), regmap_reg_range(0x11, 0x11), <answer> regmap_reg_range(0x8, 
static <token> struct regmap_range aio_ctl_volatile_ranges[] = { <answer> const 
regmap_reg_range(0x8, <token> <answer> 0x8), 
static const struct regmap_access_table aio_ctl_wr_table <token> { <answer> = 
<token> = aio_ctl_wr_ranges, <answer> .yes_ranges 
<token> = ARRAY_SIZE(aio_ctl_wr_ranges), <answer> .n_yes_ranges 
static const struct regmap_access_table aio_ctl_rd_table = <token> <answer> { 
<token> = aio_ctl_rd_ranges, <answer> .yes_ranges 
.n_yes_ranges <token> ARRAY_SIZE(aio_ctl_rd_ranges), <answer> = 
static const struct regmap_access_table aio_ctl_volatile_table <token> { <answer> = 
<token> = aio_ctl_volatile_ranges, <answer> .yes_ranges 
.n_yes_ranges = <token> <answer> ARRAY_SIZE(aio_ctl_volatile_ranges), 
static const struct regmap_config <token> = { <answer> aio_ctl_regmap_config 
.name = <token> <answer> "aio_ctl", 
.reg_bits = <token> <answer> 8, 
.reg_stride <token> 1, <answer> = 
.reg_base <token> STX104_AIO_BASE, <answer> = 
.val_bits <token> 8, <answer> = 
.io_port = <token> <answer> true, 
<token> = &aio_ctl_wr_table, <answer> .wr_table 
.rd_table <token> &aio_ctl_rd_table, <answer> = 
.volatile_table = <token> <answer> &aio_ctl_volatile_table, 
.cache_type = <token> <answer> REGCACHE_FLAT, 
static const struct regmap_range aio_data_wr_ranges[] <token> { <answer> = 
regmap_reg_range(0x4, <token> <answer> 0x6), 
static const struct <token> aio_data_rd_ranges[] = { <answer> regmap_range 
<token> 0x0), <answer> regmap_reg_range(0x0, 
static const <token> regmap_access_table aio_data_wr_table = { <answer> struct 
.yes_ranges = <token> <answer> aio_data_wr_ranges, 
<token> = ARRAY_SIZE(aio_data_wr_ranges), <answer> .n_yes_ranges 
static const struct regmap_access_table aio_data_rd_table <token> { <answer> = 
<token> = aio_data_rd_ranges, <answer> .yes_ranges 
<token> = ARRAY_SIZE(aio_data_rd_ranges), <answer> .n_yes_ranges 
static <token> struct regmap_config aio_data_regmap_config = { <answer> const 
.name <token> "aio_data", <answer> = 
.reg_bits = <token> <answer> 16, 
<token> = STX104_AIO_DATA_STRIDE, <answer> .reg_stride 
.reg_base = <token> <answer> STX104_AIO_BASE, 
<token> = 16, <answer> .val_bits 
.io_port <token> true, <answer> = 
.wr_table <token> &aio_data_wr_table, <answer> = 
<token> = &aio_data_rd_table, <answer> .rd_table 
.volatile_table = <token> <answer> &aio_data_rd_table, 
<token> = REGCACHE_FLAT, <answer> .cache_type 
static const struct regmap_config dio_regmap_config = <token> <answer> { 
<token> = "dio", <answer> .name 
.reg_bits <token> 8, <answer> = 
.reg_stride = <token> <answer> 1, 
.reg_base = <token> <answer> STX104_DIO_REG, 
.val_bits = <token> <answer> 8, 
.io_port <token> true, <answer> = 
static const <token> regmap_range pit_wr_ranges[] = { <answer> struct 
<token> 0x3), <answer> regmap_reg_range(0x0, 
static const struct regmap_range pit_rd_ranges[] = <token> <answer> { 
<token> 0x2), <answer> regmap_reg_range(0x0, 
static const struct regmap_access_table pit_wr_table = <token> <answer> { 
.yes_ranges = <token> <answer> pit_wr_ranges, 
.n_yes_ranges <token> ARRAY_SIZE(pit_wr_ranges), <answer> = 
static const struct regmap_access_table <token> = { <answer> pit_rd_table 
.yes_ranges <token> pit_rd_ranges, <answer> = 
.n_yes_ranges <token> ARRAY_SIZE(pit_rd_ranges), <answer> = 
static const struct <token> pit_regmap_config = { <answer> regmap_config 
.name = <token> <answer> "i8254", 
.reg_bits = <token> <answer> 8, 
.reg_stride <token> 1, <answer> = 
.reg_base = <token> <answer> STX104_I8254_BASE, 
.val_bits = <token> <answer> 8, 
.io_port = <token> <answer> true, 
.wr_table <token> &pit_wr_table, <answer> = 
.rd_table = <token> <answer> &pit_rd_table, 
static int <token> iio_dev *indio_dev, <answer> stx104_read_raw(struct 
struct iio_chan_spec const *chan, int *val, int <token> long mask) <answer> *val2, 
struct <token> *const priv = iio_priv(indio_dev); <answer> stx104_iio 
<token> err; <answer> int 
unsigned int <token> <answer> adc_config; 
<token> int value; <answer> unsigned 
unsigned int <token> <answer> adc_status; 
switch (mask) <token> <answer> { 
case <token> <answer> IIO_CHAN_INFO_HARDWAREGAIN: 
err = regmap_read(priv->aio_ctl_map, <token> &adc_config); <answer> STX104_ADC_CONFIGURATION, 
if <token> <answer> (err) 
<token> err; <answer> return 
*val <token> BIT(u8_get_bits(adc_config, STX104_GAIN)); <answer> = 
<token> IIO_VAL_INT; <answer> return 
case <token> <answer> IIO_CHAN_INFO_RAW: 
if <token> { <answer> (chan->output) 
err <token> regmap_read(priv->aio_data_map, STX104_DAC_OFFSET(chan->channel), <answer> = 
<token> (err) <answer> if 
return <token> <answer> err; 
*val = <token> <answer> value; 
<token> IIO_VAL_INT; <answer> return 
err <token> regmap_write(priv->aio_ctl_map, STX104_SOFTWARE_STROBE, 0); <answer> = 
if (err) <token> <answer> { 
return <token> <answer> err; 
<token> = regmap_read_poll_timeout(priv->aio_ctl_map, STX104_ADC_STATUS, adc_status, <answer> err 
!u8_get_bits(adc_status, STX104_CNV), <token> 53687092); <answer> 0, 
if <token> { <answer> (err) 
<token> err; <answer> return 
err = <token> STX104_ADC_DATA, &value); <answer> regmap_read(priv->aio_data_map, 
<token> (err) { <answer> if 
<token> err; <answer> return 
<token> = value; <answer> *val 
<token> IIO_VAL_INT; <answer> return 
<token> IIO_CHAN_INFO_OFFSET: <answer> case 
<token> <linux/acpi.h> <answer> #include 
<token> <linux/cacheinfo.h> <answer> #include 
#include <token> <answer> <linux/cpu.h> 
#include <token> <answer> <linux/cpufreq.h> 
<token> <linux/device.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/sched/topology.h> 
#include <token> <answer> <linux/cpuset.h> 
<token> <linux/cpumask.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
<token> <linux/rcupdate.h> <answer> #include 
#include <token> <answer> <linux/sched.h> 
<token> <linux/units.h> <answer> #include 
<token> CREATE_TRACE_POINTS <answer> #define 
#include <token> <answer> <trace/events/thermal_pressure.h> 
static DEFINE_PER_CPU(struct scale_freq_data __rcu *, <token> <answer> sft_data); 
static <token> cpumask scale_freq_counters_mask; <answer> struct 
static bool <token> <answer> scale_freq_invariant; 
DEFINE_PER_CPU(unsigned <token> capacity_freq_ref) = 1; <answer> long, 
static bool supports_scale_freq_counters(const <token> cpumask *cpus) <answer> struct 
<token> cpumask_subset(cpus, &scale_freq_counters_mask); <answer> return 
<token> topology_scale_freq_invariant(void) <answer> bool 
return <token> || <answer> cpufreq_supports_freq_invariance() 
<token> void update_scale_freq_invariant(bool status) <answer> static 
if (scale_freq_invariant <token> status) <answer> == 
if (topology_scale_freq_invariant() == <token> { <answer> status) 
<token> = status; <answer> scale_freq_invariant 
void topology_set_scale_freq_source(struct scale_freq_data <token> <answer> *data, 
const struct <token> *cpus) <answer> cpumask 
struct <token> *sfd; <answer> scale_freq_data 
<token> cpu; <answer> int 
if <token> <answer> (cpumask_empty(&scale_freq_counters_mask)) 
scale_freq_invariant = <token> <answer> topology_scale_freq_invariant(); 
<token> cpus) { <answer> for_each_cpu(cpu, 
sfd = rcu_dereference(*per_cpu_ptr(&sft_data, <token> <answer> cpu)); 
void <token> <answer> topology_scale_freq_tick(void) 
struct scale_freq_data <token> = rcu_dereference_sched(*this_cpu_ptr(&sft_data)); <answer> *sfd 
if <token> <answer> (sfd) 
DEFINE_PER_CPU(unsigned long, arch_freq_scale) = <token> <answer> SCHED_CAPACITY_SCALE; 
void <token> struct cpumask *cpus, unsigned long cur_freq, <answer> topology_set_freq_scale(const 
unsigned long <token> <answer> max_freq) 
<token> long scale; <answer> unsigned 
int <token> <answer> i; 
<token> (WARN_ON_ONCE(!cur_freq || !max_freq)) <answer> if 
if <token> <answer> (supports_scale_freq_counters(cpus)) 
scale = (cur_freq << <token> / max_freq; <answer> SCHED_CAPACITY_SHIFT) 
<token> cpus) <answer> for_each_cpu(i, 
per_cpu(arch_freq_scale, i) <token> scale; <answer> = 
DEFINE_PER_CPU(unsigned long, cpu_scale) <token> SCHED_CAPACITY_SCALE; <answer> = 
void topology_set_cpu_scale(unsigned int <token> unsigned long capacity) <answer> cpu, 
per_cpu(cpu_scale, <token> = capacity; <answer> cpu) 
DEFINE_PER_CPU(unsigned long, <token> <answer> thermal_pressure); 
void <token> struct cpumask *cpus, <answer> topology_update_thermal_pressure(const 
<token> long capped_freq) <answer> unsigned 
unsigned long <token> capacity, th_pressure; <answer> max_capacity, 
u32 <token> <answer> max_freq; 
int <token> <answer> cpu; 
cpu = <token> <answer> cpumask_first(cpus); 
max_capacity = <token> <answer> arch_scale_cpu_capacity(cpu); 
max_freq <token> arch_scale_freq_ref(cpu); <answer> = 
if (max_freq <token> capped_freq) <answer> <= 
<token> = max_capacity; <answer> capacity 
capacity = mult_frac(max_capacity, <token> max_freq); <answer> capped_freq, 
th_pressure = max_capacity <token> capacity; <answer> - 
trace_thermal_pressure_update(cpu, <token> <answer> th_pressure); 
<token> cpus) <answer> for_each_cpu(cpu, 
<token> cpu), th_pressure); <answer> WRITE_ONCE(per_cpu(thermal_pressure, 
static ssize_t <token> device *dev, <answer> cpu_capacity_show(struct 
struct device_attribute <token> <answer> *attr, 
<token> *buf) <answer> char 
struct cpu *cpu = <token> struct cpu, dev); <answer> container_of(dev, 
return <token> "%lu\n", topology_get_cpu_scale(cpu->dev.id)); <answer> sysfs_emit(buf, 
<token> void update_topology_flags_workfn(struct work_struct *work); <answer> static 
<token> DECLARE_WORK(update_topology_flags_work, update_topology_flags_workfn); <answer> static 
static <token> <answer> DEVICE_ATTR_RO(cpu_capacity); 
static <token> cpu_capacity_sysctl_add(unsigned int cpu) <answer> int 
struct device *cpu_dev <token> get_cpu_device(cpu); <answer> = 
if <token> <answer> (!cpu_dev) 
<token> -ENOENT; <answer> return 
<token> &dev_attr_cpu_capacity); <answer> device_create_file(cpu_dev, 
<token> 0; <answer> return 
<token> int cpu_capacity_sysctl_remove(unsigned int cpu) <answer> static 
struct device <token> = get_cpu_device(cpu); <answer> *cpu_dev 
<token> (!cpu_dev) <answer> if 
<token> -ENOENT; <answer> return 
<token> &dev_attr_cpu_capacity); <answer> device_remove_file(cpu_dev, 
<token> 0; <answer> return 
static <token> register_cpu_capacity_sysctl(void) <answer> int 
cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, <token> <answer> "topology/cpu-capacity", 
<token> cpu_capacity_sysctl_remove); <answer> cpu_capacity_sysctl_add, 
<token> 0; <answer> return 
static <token> update_topology; <answer> int 
int <token> <answer> topology_update_cpu_topology(void) 
return <token> <answer> update_topology; 
static void <token> work_struct *work) <answer> update_topology_flags_workfn(struct 
update_topology = <token> <answer> 1; 
pr_debug("sched_domain hierarchy rebuilt, <token> updated\n"); <answer> flags 
<token> = 0; <answer> update_topology 
<token> u32 *raw_capacity; <answer> static 
static int <token> <answer> free_raw_capacity(void) 
raw_capacity <token> NULL; <answer> = 
<token> 0; <answer> return 
void <token> <answer> topology_normalize_cpu_scale(void) 
u64 <token> <answer> capacity; 
<token> capacity_scale; <answer> u64 
<token> cpu; <answer> int 
<token> (!raw_capacity) <answer> if 
capacity_scale = <token> <answer> 1; 
for_each_possible_cpu(cpu) <token> <answer> { 
<token> = raw_capacity[cpu] * per_cpu(capacity_freq_ref, cpu); <answer> capacity 
capacity_scale = max(capacity, <token> <answer> capacity_scale); 
pr_debug("cpu_capacity: capacity_scale=%llu\n", <token> <answer> capacity_scale); 
for_each_possible_cpu(cpu) <token> <answer> { 
capacity = <token> * per_cpu(capacity_freq_ref, cpu); <answer> raw_capacity[cpu] 
<token> = div64_u64(capacity << SCHED_CAPACITY_SHIFT, <answer> capacity 
<token> capacity); <answer> topology_set_cpu_scale(cpu, 
pr_debug("cpu_capacity: CPU%d <token> <answer> cpu_capacity=%lu\n", 
cpu, <token> <answer> topology_get_cpu_scale(cpu)); 
bool __init topology_parse_cpu_capacity(struct device_node <token> int cpu) <answer> *cpu_node, 
<token> clk *cpu_clk; <answer> struct 
<token> bool cap_parsing_failed; <answer> static 
<token> ret; <answer> int 
<token> cpu_capacity; <answer> u32 
if <token> <answer> (cap_parsing_failed) 
<token> false; <answer> return 
ret = <token> "capacity-dmips-mhz", <answer> of_property_read_u32(cpu_node, 
<token> (!ret) { <answer> if 
if <token> { <answer> (!raw_capacity) 
<token> = kcalloc(num_possible_cpus(), <answer> raw_capacity 
<token> (!raw_capacity) { <answer> if 
<token> = true; <answer> cap_parsing_failed 
<token> false; <answer> return 
<token> = cpu_capacity; <answer> raw_capacity[cpu] 
pr_debug("cpu_capacity: %pOF <token> (raw)\n", <answer> cpu_capacity=%u 
cpu_node, <token> <answer> raw_capacity[cpu]); 
<token> = of_clk_get(cpu_node, 0); <answer> cpu_clk 
if (!PTR_ERR_OR_ZERO(cpu_clk)) <token> <answer> { 
per_cpu(capacity_freq_ref, <token> = <answer> cpu) 
<token> / HZ_PER_KHZ; <answer> clk_get_rate(cpu_clk) 
} else <token> <answer> { 
if (raw_capacity) <token> <answer> { 
pr_err("cpu_capacity: <token> %pOF raw capacity\n", <answer> missing 
pr_err("cpu_capacity: partial <token> fallback to 1024 for all CPUs\n"); <answer> information: 
<token> = true; <answer> cap_parsing_failed 
return <token> <answer> !ret; 
void __weak <token> cpu, u64 max_rate) <answer> freq_inv_set_max_ratio(int 
#ifdef <token> <answer> CONFIG_ACPI_CPPC_LIB 
<token> <acpi/cppc_acpi.h> <answer> #include 
<token> topology_init_cpu_capacity_cppc(void) <answer> void 
u64 capacity, capacity_scale <token> 0; <answer> = 
struct <token> perf_caps; <answer> cppc_perf_caps 
<token> cpu; <answer> int 
if <token> <answer> (likely(!acpi_cpc_valid())) 
raw_capacity <token> kcalloc(num_possible_cpus(), sizeof(*raw_capacity), <answer> = 
<token> (!raw_capacity) <answer> if 
for_each_possible_cpu(cpu) <token> <answer> { 
<token> (!cppc_get_perf_caps(cpu, &perf_caps) && <answer> if 
(perf_caps.highest_perf >= perf_caps.nominal_perf) <token> <answer> && 
(perf_caps.highest_perf <token> perf_caps.lowest_perf)) { <answer> >= 
<token> = perf_caps.highest_perf; <answer> raw_capacity[cpu] 
capacity_scale = <token> capacity_scale, raw_capacity[cpu]); <answer> max_t(u64, 
per_cpu(capacity_freq_ref, cpu) <token> cppc_perf_to_khz(&perf_caps, raw_capacity[cpu]); <answer> = 
<token> CPU%d cpu_capacity=%u (raw).\n", <answer> pr_debug("cpu_capacity: 
cpu, <token> <answer> raw_capacity[cpu]); 
pr_err("cpu_capacity: CPU%d missing/invalid <token> performance.\n", cpu); <answer> highest 
pr_err("cpu_capacity: partial information: fallback to <token> for all CPUs\n"); <answer> 1024 
goto <token> <answer> exit; 
<token> { <answer> for_each_possible_cpu(cpu) 
per_cpu(capacity_freq_ref, <token> * HZ_PER_KHZ); <answer> cpu) 
capacity = <token> <answer> raw_capacity[cpu]; 
capacity = <token> << SCHED_CAPACITY_SHIFT, <answer> div64_u64(capacity 
<token> capacity); <answer> topology_set_cpu_scale(cpu, 
<token> CPU%d cpu_capacity=%lu\n", <answer> pr_debug("cpu_capacity: 
<token> topology_get_cpu_scale(cpu)); <answer> cpu, 
pr_debug("cpu_capacity: cpu_capacity initialization <token> <answer> done\n"); 
#ifdef <token> <answer> CONFIG_CPU_FREQ 
static <token> cpus_to_visit; <answer> cpumask_var_t 
static <token> parsing_done_workfn(struct work_struct *work); <answer> void 
static DECLARE_WORK(parsing_done_work, <token> <answer> parsing_done_workfn); 
<token> int <answer> static 
init_cpu_capacity_callback(struct <token> *nb, <answer> notifier_block 
unsigned long <token> <answer> val, 
void <token> <answer> *data) 
struct cpufreq_policy <token> = data; <answer> *policy 
<token> cpu; <answer> int 
if <token> != CPUFREQ_CREATE_POLICY) <answer> (val 
<token> 0; <answer> return 
pr_debug("cpu_capacity: init cpu capacity <token> CPUs [%*pbl] (to_visit=%*pbl)\n", <answer> for 
cpumask_andnot(cpus_to_visit, <token> policy->related_cpus); <answer> cpus_to_visit, 
for_each_cpu(cpu, <token> { <answer> policy->related_cpus) 
per_cpu(capacity_freq_ref, cpu) <token> policy->cpuinfo.max_freq; <answer> = 
per_cpu(capacity_freq_ref, <token> * HZ_PER_KHZ); <answer> cpu) 
<token> (cpumask_empty(cpus_to_visit)) { <answer> if 
if (raw_capacity) <token> <answer> { 
pr_debug("cpu_capacity: parsing <token> <answer> done\n"); 
<token> 0; <answer> return 
static <token> notifier_block init_cpu_capacity_notifier = { <answer> struct 
.notifier_call <token> init_cpu_capacity_callback, <answer> = 
static <token> __init register_cpufreq_notifier(void) <answer> int 
<token> ret; <answer> int 
<token> (!acpi_disabled) <answer> if 
return <token> <answer> -EINVAL; 
<token> (!alloc_cpumask_var(&cpus_to_visit, GFP_KERNEL)) <answer> if 
<token> -ENOMEM; <answer> return 
cpumask_copy(cpus_to_visit, <token> <answer> cpu_possible_mask); 
ret <token> cpufreq_register_notifier(&init_cpu_capacity_notifier, <answer> = 
if <token> <answer> (ret) 
<token> ret; <answer> return 
static void <token> work_struct *work) <answer> parsing_done_workfn(struct 
<token> defined(CONFIG_ARM64) || defined(CONFIG_RISCV) <answer> #if 
static int __init get_cpu_for_node(struct <token> *node) <answer> device_node 
<token> device_node *cpu_node; <answer> struct 
int <token> <answer> cpu; 
cpu_node <token> of_parse_phandle(node, "cpu", 0); <answer> = 
if <token> <answer> (!cpu_node) 
return <token> <answer> -1; 
cpu = <token> <answer> of_cpu_node_to_id(cpu_node); 
if (cpu >= <token> <answer> 0) 
<token> cpu); <answer> topology_parse_cpu_capacity(cpu_node, 
pr_info("CPU node for %pOF exist but the possible cpu <token> is :%*pbl\n", <answer> range 
<token> cpumask_pr_args(cpu_possible_mask)); <answer> cpu_node, 
return <token> <answer> cpu; 
static int __init parse_core(struct device_node *core, int <token> <answer> package_id, 
<token> cluster_id, int core_id) <answer> int 
<token> name[20]; <answer> char 
<token> leaf = true; <answer> bool 
int <token> = 0; <answer> i 
int <token> <answer> cpu; 
struct <token> *t; <answer> device_node 
<token> { <answer> do 
snprintf(name, sizeof(name), <token> i); <answer> "thread%d", 
<token> = of_get_child_by_name(core, name); <answer> t 
if (t) <token> <answer> { 
<token> = false; <answer> leaf 
<token> = get_cpu_for_node(t); <answer> cpu 
if (cpu >= 0) <token> <answer> { 
cpu_topology[cpu].package_id = <token> <answer> package_id; 
cpu_topology[cpu].cluster_id <token> cluster_id; <answer> = 
cpu_topology[cpu].core_id = <token> <answer> core_id; 
<token> = i; <answer> cpu_topology[cpu].thread_id 
} else if (cpu <token> -ENODEV) { <answer> != 
pr_err("%pOF: Can't <token> CPU for thread\n", t); <answer> get 
<token> -EINVAL; <answer> return 
} <token> (t); <answer> while 
cpu = <token> <answer> get_cpu_for_node(core); 
<token> (cpu >= 0) { <answer> if 
if (!leaf) <token> <answer> { 
<token> Core has both threads and CPU\n", <answer> pr_err("%pOF: 
return <token> <answer> -EINVAL; 
cpu_topology[cpu].package_id <token> package_id; <answer> = 
<token> = cluster_id; <answer> cpu_topology[cpu].cluster_id 
cpu_topology[cpu].core_id = <token> <answer> core_id; 
} else <token> (leaf && cpu != -ENODEV) { <answer> if 
pr_err("%pOF: Can't get CPU for leaf <token> core); <answer> core\n", 
<token> -EINVAL; <answer> return 
<token> 0; <answer> return 
static int __init parse_cluster(struct device_node *cluster, int <token> <answer> package_id, 
int cluster_id, int <token> <answer> depth) 
char <token> <answer> name[20]; 
bool <token> = true; <answer> leaf 
<token> has_cores = false; <answer> bool 
struct device_node <token> <answer> *c; 
int core_id = <token> <answer> 0; 
int i, <token> <answer> ret; 
i <token> 0; <answer> = 
do <token> <answer> { 
snprintf(name, <token> "cluster%d", i); <answer> sizeof(name), 
c = <token> name); <answer> of_get_child_by_name(cluster, 
<token> (c) { <answer> if 
<token> = false; <answer> leaf 
ret = parse_cluster(c, package_id, <token> depth + 1); <answer> i, 
if (depth <token> 0) <answer> > 
pr_warn("Topology for clusters of clusters not <token> supported\n"); <answer> yet 
if (ret <token> 0) <answer> != 
return <token> <answer> ret; 
<token> while (c); <answer> } 
map = of_get_child_by_name(cn, <token> <answer> "cpu-map"); 
if <token> <answer> (!map) 
<token> out; <answer> goto 
ret <token> parse_socket(map); <answer> = 
if (ret <token> 0) <answer> != 
goto <token> <answer> out_map; 
if (cpu_topology[cpu].package_id < 0) <token> <answer> { 
ret = <token> <answer> -EINVAL; 
<token> ret; <answer> return 
struct <token> cpu_topology[NR_CPUS]; <answer> cpu_topology 
const struct cpumask <token> cpu) <answer> *cpu_coregroup_mask(int 
const cpumask_t *core_mask <token> cpumask_of_node(cpu_to_node(cpu)); <answer> = 
if (IS_ENABLED(CONFIG_SCHED_CLUSTER) <token> <answer> && 
cpumask_subset(core_mask, <token> <answer> &cpu_topology[cpu].cluster_sibling)) 
core_mask <token> &cpu_topology[cpu].cluster_sibling; <answer> = 
<token> core_mask; <answer> return 
const struct cpumask <token> cpu) <answer> *cpu_clustergroup_mask(int 
<token> (cpumask_subset(cpu_coregroup_mask(cpu), <answer> if 
<token> topology_sibling_cpumask(cpu); <answer> return 
return <token> <answer> &cpu_topology[cpu].cluster_sibling; 
void <token> int cpuid) <answer> update_siblings_masks(unsigned 
<token> cpu_topology *cpu_topo, *cpuid_topo = &cpu_topology[cpuid]; <answer> struct 
int <token> ret; <answer> cpu, 
ret <token> detect_cache_attributes(cpuid); <answer> = 
<token> (ret && ret != -ENOENT) <answer> if 
<token> cacheinfo allocation failed, ret = %d\n", ret); <answer> pr_info("Early 
<token> { <answer> for_each_possible_cpu(cpu) 
ret = <token> <answer> fetch_cache_info(cpu); 
if <token> <answer> (!ret) 
<token> if (ret != -ENOENT) <answer> else 
pr_err("Early cacheinfo failed, <token> = %d\n", ret); <answer> ret 
void <token> int cpuid) <answer> store_cpu_topology(unsigned 
<token> cpu_topology *cpuid_topo = &cpu_topology[cpuid]; <answer> struct 
<token> (cpuid_topo->package_id != -1) <answer> if 
<token> topology_populated; <answer> goto 
cpuid_topo->thread_id = <token> <answer> -1; 
<token> = cpuid; <answer> cpuid_topo->core_id 
cpuid_topo->package_id <token> cpu_to_node(cpuid); <answer> = 
pr_debug("CPU%u: package %d core %d thread <token> <answer> %d\n", 
cpuid, <token> cpuid_topo->core_id, <answer> cpuid_topo->package_id, 
<token> "ops.h" <answer> #include 
<token> "sof-priv.h" <answer> #include 
#include <token> <answer> "sof-audio.h" 
static u32 snd_sof_dsp_power_target(struct <token> *sdev) <answer> snd_sof_dev 
u32 <token> <answer> target_dsp_state; 
switch (sdev->system_suspend_target) <token> <answer> { 
case <token> <answer> SOF_SUSPEND_S5: 
<token> SOF_SUSPEND_S4: <answer> case 
<token> (snd_sof_stream_suspend_ignored(sdev)) <answer> if 
<token> = SOF_DSP_PM_D0; <answer> target_dsp_state 
target_dsp_state <token> SOF_DSP_PM_D3; <answer> = 
<token> (runtime_resume) <answer> if 
<token> = snd_sof_dsp_runtime_resume(sdev); <answer> ret 
ret <token> snd_sof_dsp_resume(sdev); <answer> = 
if <token> < 0) { <answer> (ret 
"error: failed to power <token> DSP after resume\n"); <answer> up 
<token> ret; <answer> return 
<token> (sdev->dspless_mode_selected) { <answer> if 
sof_set_fw_state(sdev, <token> <answer> SOF_DSPLESS_MODE); 
<token> 0; <answer> return 
if (!runtime_resume && <token> && <answer> sof_ops(sdev)->set_power_state 
old_state <token> SOF_DSP_PM_D0) { <answer> == 
<token> = sof_fw_trace_resume(sdev); <answer> ret 
<token> (ret < 0) <answer> if 
ret = <token> <answer> snd_sof_run_firmware(sdev); 
if <token> < 0) { <answer> (ret 
"error: failed to boot DSP <token> after resume %d\n", <answer> firmware 
<token> SOF_FW_BOOT_FAILED); <answer> sof_set_fw_state(sdev, 
return <token> <answer> ret; 
<token> ret; <answer> return 
static int sof_suspend(struct <token> *dev, bool runtime_suspend) <answer> device 
struct snd_sof_dev *sdev <token> dev_get_drvdata(dev); <answer> = 
<token> struct sof_ipc_pm_ops *pm_ops = sof_ipc_get_ops(sdev, pm); <answer> const 
const struct sof_ipc_tplg_ops <token> = sof_ipc_get_ops(sdev, tplg); <answer> *tplg_ops 
pm_message_t <token> <answer> pm_state; 
u32 <token> = snd_sof_dsp_power_target(sdev); <answer> target_state 
u32 <token> = sdev->dsp_power_state.state; <answer> old_state 
<token> ret; <answer> int 
if <token> && tplg_ops->tear_down_all_pipelines && (old_state == SOF_DSP_PM_D0)) <answer> (tplg_ops 
tplg_ops->tear_down_all_pipelines(sdev, <token> <answer> false); 
if (sdev->fw_state <token> SOF_FW_BOOT_COMPLETE) <answer> != 
<token> suspend; <answer> goto 
dev_err(sdev->dev, <token> IPC error during suspend: %d\n", ret); <answer> "ctx_save 
return <token> <answer> ret; 
} else if (ret < <token> { <answer> 0) 
<token> (sdev->fw_state == SOF_FW_CRASHED || <answer> if 
sdev->fw_state <token> SOF_FW_BOOT_FAILED) <answer> == 
return <token> <answer> 0; 
<token> (!desc->use_acpi_target_states) <answer> if 
<token> 0; <answer> return 
<token> defined(CONFIG_ACPI) <answer> #if 
switch <token> { <answer> (acpi_target_system_state()) 
case <token> <answer> ACPI_STATE_S0: 
sdev->system_suspend_target = <token> <answer> SOF_SUSPEND_S0IX; 
case <token> <answer> ACPI_STATE_S1: 
<token> ACPI_STATE_S2: <answer> case 
case <token> <answer> ACPI_STATE_S3: 
<token> = SOF_SUSPEND_S3; <answer> sdev->system_suspend_target 
<token> ACPI_STATE_S4: <answer> case 
sdev->system_suspend_target <token> SOF_SUSPEND_S4; <answer> = 
<token> ACPI_STATE_S5: <answer> case 
sdev->system_suspend_target <token> SOF_SUSPEND_S5; <answer> = 
return <token> <answer> 0; 
void snd_sof_complete(struct device <token> <answer> *dev) 
struct snd_sof_dev *sdev <token> dev_get_drvdata(dev); <answer> = 
sdev->system_suspend_target <token> SOF_SUSPEND_NONE; <answer> = 
#include <token> <answer> <linux/overflow.h> 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <linux/hash.h> 
#include <token> <answer> "hfi_cmds.h" 
<token> enum hfi_version hfi_ver; <answer> static 
void pkt_sys_init(struct <token> *pkt, u32 arch_type) <answer> hfi_sys_init_pkt 
pkt->hdr.size <token> sizeof(*pkt); <answer> = 
pkt->hdr.pkt_type = <token> <answer> HFI_CMD_SYS_INIT; 
pkt->arch_type <token> arch_type; <answer> = 
<token> pkt_sys_pc_prep(struct hfi_sys_pc_prep_pkt *pkt) <answer> void 
pkt->hdr.size = <token> <answer> sizeof(*pkt); 
pkt->hdr.pkt_type <token> HFI_CMD_SYS_PC_PREP; <answer> = 
void pkt_sys_idle_indicator(struct <token> *pkt, u32 enable) <answer> hfi_sys_set_property_pkt 
struct <token> *hfi = (struct hfi_enable *)&pkt->data[1]; <answer> hfi_enable 
pkt->hdr.size = struct_size(pkt, data, 1) + <token> <answer> sizeof(*hfi); 
<token> = HFI_CMD_SYS_SET_PROPERTY; <answer> pkt->hdr.pkt_type 
pkt->num_properties = <token> <answer> 1; 
pkt->data[0] <token> HFI_PROPERTY_SYS_IDLE_INDICATOR; <answer> = 
hfi->enable = <token> <answer> enable; 
void pkt_sys_debug_config(struct <token> *pkt, u32 mode, <answer> hfi_sys_set_property_pkt 
<token> config) <answer> u32 
<token> hfi_debug_config *hfi; <answer> struct 
<token> = struct_size(pkt, data, 1) + sizeof(*hfi); <answer> pkt->hdr.size 
pkt->hdr.pkt_type <token> HFI_CMD_SYS_SET_PROPERTY; <answer> = 
pkt->num_properties = <token> <answer> 1; 
pkt->data[0] = <token> <answer> HFI_PROPERTY_SYS_DEBUG_CONFIG; 
hfi = (struct <token> *)&pkt->data[1]; <answer> hfi_debug_config 
hfi->config <token> config; <answer> = 
<token> = mode; <answer> hfi->mode 
void pkt_sys_coverage_config(struct <token> *pkt, u32 mode) <answer> hfi_sys_set_property_pkt 
pkt->hdr.size <token> struct_size(pkt, data, 2); <answer> = 
pkt->hdr.pkt_type <token> HFI_CMD_SYS_SET_PROPERTY; <answer> = 
<token> = 1; <answer> pkt->num_properties 
<token> = HFI_PROPERTY_SYS_CONFIG_COVERAGE; <answer> pkt->data[0] 
<token> = mode; <answer> pkt->data[1] 
void pkt_sys_ubwc_config(struct hfi_sys_set_property_pkt <token> const struct hfi_ubwc_config *hfi) <answer> *pkt, 
pkt->hdr.size <token> struct_size(pkt, data, 1) + sizeof(*hfi); <answer> = 
pkt->hdr.pkt_type = <token> <answer> HFI_CMD_SYS_SET_PROPERTY; 
pkt->num_properties <token> 1; <answer> = 
pkt->data[0] = <token> <answer> HFI_PROPERTY_SYS_UBWC_CONFIG; 
memcpy(&pkt->data[1], <token> sizeof(*hfi)); <answer> hfi, 
int pkt_sys_set_resource(struct hfi_sys_set_resource_pkt *pkt, u32 id, u32 <token> <answer> size, 
<token> addr, void *cookie) <answer> u32 
pkt->hdr.size <token> sizeof(*pkt); <answer> = 
pkt->hdr.pkt_type = <token> <answer> HFI_CMD_SYS_SET_RESOURCE; 
pkt->resource_handle = <token> <answer> hash32_ptr(cookie); 
switch <token> { <answer> (id) 
<token> VIDC_RESOURCE_OCMEM: <answer> case 
case VIDC_RESOURCE_VMEM: <token> <answer> { 
struct <token> *res = <answer> hfi_resource_ocmem 
(struct hfi_resource_ocmem <token> <answer> *)&pkt->resource_data[0]; 
<token> = size; <answer> res->size 
res->mem <token> addr; <answer> = 
pkt->resource_type = <token> <answer> HFI_RESOURCE_OCMEM; 
<token> += sizeof(*res); <answer> pkt->hdr.size 
case <token> <answer> VIDC_RESOURCE_NONE: 
<token> -ENOTSUPP; <answer> return 
return <token> <answer> 0; 
int pkt_sys_unset_resource(struct <token> *pkt, u32 id, <answer> hfi_sys_release_resource_pkt 
u32 size, void <token> <answer> *cookie) 
<token> = sizeof(*pkt); <answer> pkt->hdr.size 
pkt->hdr.pkt_type = <token> <answer> HFI_CMD_SYS_RELEASE_RESOURCE; 
pkt->resource_handle <token> hash32_ptr(cookie); <answer> = 
switch <token> { <answer> (id) 
case <token> <answer> VIDC_RESOURCE_OCMEM: 
case <token> <answer> VIDC_RESOURCE_VMEM: 
pkt->resource_type <token> HFI_RESOURCE_OCMEM; <answer> = 
<token> VIDC_RESOURCE_NONE: <answer> case 
return <token> <answer> -ENOTSUPP; 
return <token> <answer> 0; 
void <token> hfi_sys_ping_pkt *pkt, u32 cookie) <answer> pkt_sys_ping(struct 
pkt->hdr.size = <token> <answer> sizeof(*pkt); 
<token> = HFI_CMD_SYS_PING; <answer> pkt->hdr.pkt_type 
pkt->client_data = <token> <answer> cookie; 
void pkt_sys_power_control(struct hfi_sys_set_property_pkt <token> u32 enable) <answer> *pkt, 
struct hfi_enable *hfi <token> (struct hfi_enable *)&pkt->data[1]; <answer> = 
pkt->hdr.size = struct_size(pkt, data, 1) + <token> <answer> sizeof(*hfi); 
pkt->hdr.pkt_type = <token> <answer> HFI_CMD_SYS_SET_PROPERTY; 
<token> = 1; <answer> pkt->num_properties 
pkt->data[0] <token> HFI_PROPERTY_SYS_CODEC_POWER_PLANE_CTRL; <answer> = 
hfi->enable = <token> <answer> enable; 
int pkt_sys_ssr_cmd(struct hfi_sys_test_ssr_pkt *pkt, <token> trigger_type) <answer> u32 
<token> (trigger_type) { <answer> switch 
<token> HFI_TEST_SSR_SW_ERR_FATAL: <answer> case 
case <token> <answer> HFI_TEST_SSR_SW_DIV_BY_ZERO: 
<token> HFI_TEST_SSR_HW_WDOG_IRQ: <answer> case 
return <token> <answer> -EINVAL; 
<token> = sizeof(*pkt); <answer> pkt->hdr.size 
pkt->hdr.pkt_type <token> HFI_CMD_SYS_TEST_SSR; <answer> = 
<token> = trigger_type; <answer> pkt->trigger_type 
return <token> <answer> 0; 
<token> pkt_sys_image_version(struct hfi_sys_get_property_pkt *pkt) <answer> void 
pkt->hdr.size <token> sizeof(*pkt); <answer> = 
pkt->hdr.pkt_type = <token> <answer> HFI_CMD_SYS_GET_PROPERTY; 
pkt->num_properties = <token> <answer> 1; 
pkt->data[0] = <token> <answer> HFI_PROPERTY_SYS_IMAGE_VERSION; 
int pkt_session_init(struct hfi_session_init_pkt *pkt, <token> *cookie, <answer> void 
u32 session_type, <token> codec) <answer> u32 
if (!pkt || !cookie || <token> <answer> !codec) 
<token> -EINVAL; <answer> return 
<token> = sizeof(*pkt); <answer> pkt->shdr.hdr.size 
pkt->shdr.hdr.pkt_type <token> HFI_CMD_SYS_SESSION_INIT; <answer> = 
pkt->shdr.session_id = <token> <answer> hash32_ptr(cookie); 
pkt->session_domain <token> session_type; <answer> = 
pkt->session_codec = <token> <answer> codec; 
<token> 0; <answer> return 
void pkt_session_cmd(struct <token> *pkt, u32 pkt_type, void *cookie) <answer> hfi_session_pkt 
pkt->shdr.hdr.size = <token> <answer> sizeof(*pkt); 
pkt->shdr.hdr.pkt_type = <token> <answer> pkt_type; 
pkt->shdr.session_id = <token> <answer> hash32_ptr(cookie); 
<token> pkt_session_set_buffers(struct hfi_session_set_buffers_pkt *pkt, <answer> int 
void *cookie, struct hfi_buffer_desc <token> <answer> *bd) 
<token> int i; <answer> unsigned 
if (!cookie || <token> || !bd) <answer> !pkt 
<token> -EINVAL; <answer> return 
pkt->shdr.hdr.pkt_type <token> HFI_CMD_SESSION_SET_BUFFERS; <answer> = 
pkt->shdr.session_id <token> hash32_ptr(cookie); <answer> = 
pkt->buffer_size = <token> <answer> bd->buffer_size; 
pkt->min_buffer_size = <token> <answer> bd->buffer_size; 
pkt->num_buffers <token> bd->num_buffers; <answer> = 
if (bd->buffer_type == <token> || <answer> HFI_BUFFER_OUTPUT 
bd->buffer_type <token> HFI_BUFFER_OUTPUT2) { <answer> == 
struct <token> *bi; <answer> hfi_buffer_info 
pkt->extradata_size <token> bd->extradata_size; <answer> = 
pkt->shdr.hdr.size = sizeof(*pkt) <token> <answer> + 
bd->num_buffers * <token> <answer> sizeof(*bi); 
<token> = (struct hfi_buffer_info *)pkt->buffer_info; <answer> bi 
for (i = 0; i < <token> i++) { <answer> pkt->num_buffers; 
bi->buffer_addr = <token> <answer> bd->device_addr; 
<token> = bd->extradata_addr; <answer> bi->extradata_addr 
} else <token> <answer> { 
pkt->extradata_size = <token> <answer> 0; 
pkt->shdr.hdr.size <token> struct_size(pkt, buffer_info, <answer> = 
for (i = 0; i < <token> i++) <answer> pkt->num_buffers; 
pkt->buffer_info[i] <token> bd->device_addr; <answer> = 
pkt->buffer_type = <token> <answer> bd->buffer_type; 
<token> 0; <answer> return 
int <token> hfi_session_release_buffer_pkt *pkt, <answer> pkt_session_unset_buffers(struct 
<token> *cookie, struct hfi_buffer_desc *bd) <answer> void 
<token> int i; <answer> unsigned 
if (!cookie || <token> || !bd) <answer> !pkt 
<token> -EINVAL; <answer> return 
pkt->shdr.hdr.pkt_type = <token> <answer> HFI_CMD_SESSION_RELEASE_BUFFERS; 
pkt->shdr.session_id = <token> <answer> hash32_ptr(cookie); 
pkt->buffer_size = <token> <answer> bd->buffer_size; 
pkt->num_buffers = <token> <answer> bd->num_buffers; 
if <token> == HFI_BUFFER_OUTPUT || <answer> (bd->buffer_type 
bd->buffer_type == <token> { <answer> HFI_BUFFER_OUTPUT2) 
struct <token> *bi; <answer> hfi_buffer_info 
bi <token> (struct hfi_buffer_info *)pkt->buffer_info; <answer> = 
for (i = 0; i < pkt->num_buffers; <token> { <answer> i++) 
bi->buffer_addr = <token> <answer> bd->device_addr; 
bi->extradata_addr = <token> <answer> bd->extradata_addr; 
pkt->shdr.hdr.size <token> <answer> = 
<token> hfi_session_set_buffers_pkt) + <answer> sizeof(struct 
bd->num_buffers * <token> <answer> sizeof(*bi); 
<token> else { <answer> } 
for (i <token> 0; i < pkt->num_buffers; i++) <answer> = 
pkt->buffer_info[i] <token> bd->device_addr; <answer> = 
pkt->extradata_size <token> 0; <answer> = 
<token> = <answer> pkt->shdr.hdr.size 
<token> hfi_session_set_buffers_pkt, <answer> struct_size_t(struct 
buffer_info, <token> <answer> bd->num_buffers); 
<token> = bd->response_required; <answer> pkt->response_req 
pkt->buffer_type = <token> <answer> bd->buffer_type; 
return <token> <answer> 0; 
int <token> hfi_session_empty_buffer_compressed_pkt *pkt, <answer> pkt_session_etb_decoder(struct 
<token> *cookie, struct hfi_frame_data *in_frame) <answer> void 
<token> (!cookie) <answer> if 
return <token> <answer> -EINVAL; 
pkt->shdr.hdr.size <token> sizeof(*pkt); <answer> = 
pkt->shdr.hdr.pkt_type <token> HFI_CMD_SESSION_EMPTY_BUFFER; <answer> = 
<token> = hash32_ptr(cookie); <answer> pkt->shdr.session_id 
pkt->time_stamp_hi <token> upper_32_bits(in_frame->timestamp); <answer> = 
<token> = lower_32_bits(in_frame->timestamp); <answer> pkt->time_stamp_lo 
<token> = in_frame->flags; <answer> pkt->flags 
<token> = in_frame->mark_target; <answer> pkt->mark_target 
pkt->mark_data = <token> <answer> in_frame->mark_data; 
pkt->offset <token> in_frame->offset; <answer> = 
pkt->alloc_len <token> in_frame->alloc_len; <answer> = 
pkt->filled_len <token> in_frame->filled_len; <answer> = 
pkt->input_tag <token> in_frame->clnt_data; <answer> = 
pkt->packet_buffer = <token> <answer> in_frame->device_addr; 
<token> 0; <answer> return 
int <token> <answer> pkt_session_etb_encoder( 
<token> hfi_session_empty_buffer_uncompressed_plane0_pkt *pkt, <answer> struct 
void *cookie, <token> hfi_frame_data *in_frame) <answer> struct 
<token> (!cookie || !in_frame->device_addr) <answer> if 
<token> -EINVAL; <answer> return 
<token> = sizeof(*pkt); <answer> pkt->shdr.hdr.size 
<token> = HFI_CMD_SESSION_EMPTY_BUFFER; <answer> pkt->shdr.hdr.pkt_type 
<token> = hash32_ptr(cookie); <answer> pkt->shdr.session_id 
<token> = 0; <answer> pkt->view_id 
<token> = upper_32_bits(in_frame->timestamp); <answer> pkt->time_stamp_hi 
<token> = lower_32_bits(in_frame->timestamp); <answer> pkt->time_stamp_lo 
pkt->flags = <token> <answer> in_frame->flags; 
pkt->mark_target <token> in_frame->mark_target; <answer> = 
<token> = in_frame->mark_data; <answer> pkt->mark_data 
pkt->offset = <token> <answer> in_frame->offset; 
<token> = in_frame->alloc_len; <answer> pkt->alloc_len 
pkt->filled_len <token> in_frame->filled_len; <answer> = 
pkt->input_tag = <token> <answer> in_frame->clnt_data; 
pkt->packet_buffer <token> in_frame->device_addr; <answer> = 
pkt->extradata_buffer <token> in_frame->extradata_addr; <answer> = 
return <token> <answer> 0; 
int pkt_session_ftb(struct hfi_session_fill_buffer_pkt *pkt, void <token> <answer> *cookie, 
struct <token> *out_frame) <answer> hfi_frame_data 
if (!cookie || !out_frame <token> !out_frame->device_addr) <answer> || 
<token> -EINVAL; <answer> return 
pkt->shdr.hdr.size = <token> <answer> sizeof(*pkt); 
<token> = HFI_CMD_SESSION_FILL_BUFFER; <answer> pkt->shdr.hdr.pkt_type 
<token> = hash32_ptr(cookie); <answer> pkt->shdr.session_id 
if (out_frame->buffer_type <token> HFI_BUFFER_OUTPUT) <answer> == 
<token> = 0; <answer> pkt->stream_id 
else if (out_frame->buffer_type == <token> <answer> HFI_BUFFER_OUTPUT2) 
pkt->stream_id = <token> <answer> 1; 
<token> = out_frame->clnt_data; <answer> pkt->output_tag 
pkt->packet_buffer <token> out_frame->device_addr; <answer> = 
pkt->extradata_buffer = <token> <answer> out_frame->extradata_addr; 
pkt->alloc_len <token> out_frame->alloc_len; <answer> = 
pkt->filled_len = <token> <answer> out_frame->filled_len; 
<token> = out_frame->offset; <answer> pkt->offset 
<token> = out_frame->extradata_size; <answer> pkt->data[0] 
<token> 0; <answer> return 
<token> pkt_session_parse_seq_header( <answer> int 
struct <token> *pkt, <answer> hfi_session_parse_sequence_header_pkt 
void *cookie, u32 seq_hdr, <token> seq_hdr_len) <answer> u32 
<token> (!cookie || !seq_hdr || !seq_hdr_len) <answer> if 
return <token> <answer> -EINVAL; 
pkt->shdr.hdr.size = <token> <answer> sizeof(*pkt); 
pkt->shdr.hdr.pkt_type = <token> <answer> HFI_CMD_SESSION_PARSE_SEQUENCE_HEADER; 
pkt->shdr.session_id <token> hash32_ptr(cookie); <answer> = 
pkt->header_len <token> seq_hdr_len; <answer> = 
<token> = seq_hdr; <answer> pkt->packet_buffer 
return <token> <answer> 0; 
int <token> hfi_session_get_sequence_header_pkt *pkt, <answer> pkt_session_get_seq_hdr(struct 
<token> *cookie, u32 seq_hdr, u32 seq_hdr_len) <answer> void 
<token> (!cookie || !seq_hdr || !seq_hdr_len) <answer> if 
<token> -EINVAL; <answer> return 
<token> = sizeof(*pkt); <answer> pkt->shdr.hdr.size 
pkt->shdr.hdr.pkt_type = <token> <answer> HFI_CMD_SESSION_GET_SEQUENCE_HEADER; 
<token> = hash32_ptr(cookie); <answer> pkt->shdr.session_id 
pkt->buffer_len <token> seq_hdr_len; <answer> = 
pkt->packet_buffer = <token> <answer> seq_hdr; 
return <token> <answer> 0; 
int pkt_session_flush(struct hfi_session_flush_pkt <token> void *cookie, u32 type) <answer> *pkt, 
<token> (type) { <answer> switch 
case <token> <answer> HFI_FLUSH_INPUT: 
case <token> <answer> HFI_FLUSH_OUTPUT: 
case <token> <answer> HFI_FLUSH_OUTPUT2: 
case <token> <answer> HFI_FLUSH_ALL: 
return <token> <answer> -EINVAL; 
pkt->shdr.hdr.size <token> sizeof(*pkt); <answer> = 
<token> = HFI_CMD_SESSION_FLUSH; <answer> pkt->shdr.hdr.pkt_type 
pkt->shdr.session_id = <token> <answer> hash32_ptr(cookie); 
<token> = type; <answer> pkt->flush_type 
return <token> <answer> 0; 
static int pkt_session_get_property_1x(struct hfi_session_get_property_pkt <token> <answer> *pkt, 
void <token> u32 ptype) <answer> *cookie, 
switch <token> { <answer> (ptype) 
case <token> <answer> HFI_PROPERTY_PARAM_PROFILE_LEVEL_CURRENT: 
case <token> <answer> HFI_PROPERTY_CONFIG_BUFFER_REQUIREMENTS: 
return <token> <answer> -EINVAL; 
pkt->shdr.hdr.size = <token> <answer> sizeof(*pkt); 
pkt->shdr.hdr.pkt_type <token> HFI_CMD_SESSION_GET_PROPERTY; <answer> = 
pkt->shdr.session_id = <token> <answer> hash32_ptr(cookie); 
pkt->num_properties = <token> <answer> 1; 
pkt->data[0] <token> ptype; <answer> = 
<token> 0; <answer> return 
static int pkt_session_set_property_1x(struct <token> *pkt, <answer> hfi_session_set_property_pkt 
void *cookie, <token> ptype, void *pdata) <answer> u32 
<token> *prop_data; <answer> void 
<token> ret = 0; <answer> int 
if (!pkt || <token> || !pdata) <answer> !cookie 
return <token> <answer> -EINVAL; 
<token> = &pkt->data[1]; <answer> prop_data 
<token> = sizeof(*pkt); <answer> pkt->shdr.hdr.size 
<token> = HFI_CMD_SESSION_SET_PROPERTY; <answer> pkt->shdr.hdr.pkt_type 
pkt->shdr.session_id = <token> <answer> hash32_ptr(cookie); 
<token> = 1; <answer> pkt->num_properties 
pkt->data[0] <token> ptype; <answer> = 
switch <token> { <answer> (ptype) 
<token> HFI_PROPERTY_CONFIG_FRAME_RATE: { <answer> case 
<token> hfi_framerate *in = pdata, *frate = prop_data; <answer> struct 
frate->buffer_type = <token> <answer> in->buffer_type; 
<token> = in->framerate; <answer> frate->framerate 
pkt->shdr.hdr.size += <token> + sizeof(*frate); <answer> sizeof(u32) 
case <token> { <answer> HFI_PROPERTY_PARAM_UNCOMPRESSED_FORMAT_SELECT: 
struct hfi_uncompressed_format_select *in = <token> <answer> pdata; 
<token> hfi_uncompressed_format_select *hfi = prop_data; <answer> struct 
<token> = in->buffer_type; <answer> hfi->buffer_type 
hfi->format <token> in->format; <answer> = 
<token> += sizeof(u32) + sizeof(*hfi); <answer> pkt->shdr.hdr.size 
case HFI_PROPERTY_PARAM_FRAME_SIZE: <token> <answer> { 
struct hfi_framesize *in = pdata, *fsize = <token> <answer> prop_data; 
fsize->buffer_type <token> in->buffer_type; <answer> = 
fsize->height = <token> <answer> in->height; 
fsize->width <token> in->width; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*fsize); <answer> + 
case HFI_PROPERTY_CONFIG_REALTIME: <token> <answer> { 
<token> hfi_enable *in = pdata, *en = prop_data; <answer> struct 
en->enable = <token> <answer> in->enable; 
pkt->shdr.hdr.size += sizeof(u32) * <token> <answer> 2; 
case HFI_PROPERTY_PARAM_BUFFER_COUNT_ACTUAL: <token> <answer> { 
struct hfi_buffer_count_actual *in = pdata, *count = <token> <answer> prop_data; 
<token> = in->count_actual; <answer> count->count_actual 
count->type <token> in->type; <answer> = 
<token> += sizeof(u32) + sizeof(*count); <answer> pkt->shdr.hdr.size 
case <token> { <answer> HFI_PROPERTY_PARAM_BUFFER_SIZE_ACTUAL: 
struct hfi_buffer_size_actual *in = pdata, *sz <token> prop_data; <answer> = 
<token> = in->size; <answer> sz->size 
sz->type <token> in->type; <answer> = 
pkt->shdr.hdr.size += <token> + sizeof(*sz); <answer> sizeof(u32) 
case HFI_PROPERTY_PARAM_BUFFER_DISPLAY_HOLD_COUNT_ACTUAL: <token> <answer> { 
struct hfi_buffer_display_hold_count_actual *in = <token> <answer> pdata; 
struct hfi_buffer_display_hold_count_actual <token> = prop_data; <answer> *count 
count->hold_count <token> in->hold_count; <answer> = 
<token> = in->type; <answer> count->type 
<token> += sizeof(u32) + sizeof(*count); <answer> pkt->shdr.hdr.size 
case HFI_PROPERTY_PARAM_NAL_STREAM_FORMAT_SELECT: <token> <answer> { 
<token> hfi_nal_stream_format_select *in = pdata; <answer> struct 
struct <token> *fmt = prop_data; <answer> hfi_nal_stream_format_select 
fmt->format = <token> <answer> in->format; 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*fmt); <answer> + 
<token> HFI_PROPERTY_PARAM_VDEC_OUTPUT_ORDER: { <answer> case 
<token> *in = pdata; <answer> u32 
switch (*in) <token> <answer> { 
<token> HFI_OUTPUT_ORDER_DECODE: <answer> case 
<token> HFI_OUTPUT_ORDER_DISPLAY: <answer> case 
ret = <token> <answer> -EINVAL; 
pkt->data[1] = <token> <answer> *in; 
pkt->shdr.hdr.size += sizeof(u32) <token> 2; <answer> * 
case <token> { <answer> HFI_PROPERTY_PARAM_VDEC_PICTURE_TYPE_DECODE: 
<token> hfi_enable_picture *in = pdata, *en = prop_data; <answer> struct 
<token> = in->picture_type; <answer> en->picture_type 
pkt->shdr.hdr.size <token> sizeof(u32) + sizeof(*en); <answer> += 
case HFI_PROPERTY_PARAM_VDEC_OUTPUT2_KEEP_ASPECT_RATIO: <token> <answer> { 
struct hfi_enable *in = pdata, *en = <token> <answer> prop_data; 
<token> = in->enable; <answer> en->enable 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*en); 
case <token> <answer> HFI_PROPERTY_PARAM_VDEC_ENABLE_SUFFICIENT_SEQCHANGE_EVENT: 
case HFI_PROPERTY_CONFIG_VDEC_POST_LOOP_DEBLOCKER: <token> <answer> { 
struct hfi_enable <token> = pdata; <answer> *in 
struct <token> *en = prop_data; <answer> hfi_enable 
en->enable = <token> <answer> in->enable; 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*en); <answer> + 
case HFI_PROPERTY_PARAM_VDEC_MULTI_STREAM: <token> <answer> { 
struct hfi_multi_stream *in <token> pdata, *multi = prop_data; <answer> = 
multi->buffer_type = <token> <answer> in->buffer_type; 
multi->enable = <token> <answer> in->enable; 
multi->width = <token> <answer> in->width; 
multi->height <token> in->height; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*multi); 
case HFI_PROPERTY_PARAM_VDEC_DISPLAY_PICTURE_BUFFER_COUNT: <token> <answer> { 
struct hfi_display_picture_buffer_count *in = <token> <answer> pdata; 
struct <token> *count = prop_data; <answer> hfi_display_picture_buffer_count 
<token> = in->count; <answer> count->count 
count->enable = <token> <answer> in->enable; 
<token> += sizeof(u32) + sizeof(*count); <answer> pkt->shdr.hdr.size 
<token> HFI_PROPERTY_PARAM_DIVX_FORMAT: { <answer> case 
u32 <token> = pdata; <answer> *in 
<token> (*in) { <answer> switch 
case <token> <answer> HFI_DIVX_FORMAT_4: 
case <token> <answer> HFI_DIVX_FORMAT_5: 
case <token> <answer> HFI_DIVX_FORMAT_6: 
<token> = -EINVAL; <answer> ret 
pkt->data[1] = <token> <answer> *in; 
<token> += sizeof(u32) * 2; <answer> pkt->shdr.hdr.size 
case <token> { <answer> HFI_PROPERTY_CONFIG_VDEC_MB_ERROR_MAP_REPORTING: 
struct hfi_enable *in <token> pdata, *en = prop_data; <answer> = 
<token> = in->enable; <answer> en->enable 
pkt->shdr.hdr.size += <token> + sizeof(*en); <answer> sizeof(u32) 
case HFI_PROPERTY_PARAM_VDEC_CONTINUE_DATA_TRANSFER: <token> <answer> { 
struct hfi_enable *in = pdata, *en <token> prop_data; <answer> = 
<token> = in->enable; <answer> en->enable 
pkt->shdr.hdr.size += <token> + sizeof(*en); <answer> sizeof(u32) 
case <token> { <answer> HFI_PROPERTY_PARAM_VDEC_THUMBNAIL_MODE: 
struct hfi_enable *in = <token> *en = prop_data; <answer> pdata, 
en->enable = <token> <answer> in->enable; 
pkt->shdr.hdr.size += <token> + sizeof(*en); <answer> sizeof(u32) 
case <token> { <answer> HFI_PROPERTY_CONFIG_VENC_SYNC_FRAME_SEQUENCE_HEADER: 
struct hfi_enable <token> = pdata, *en = prop_data; <answer> *in 
<token> = in->enable; <answer> en->enable 
pkt->shdr.hdr.size <token> sizeof(u32) + sizeof(*en); <answer> += 
<token> HFI_PROPERTY_CONFIG_VENC_REQUEST_SYNC_FRAME: <answer> case 
pkt->shdr.hdr.size <token> sizeof(u32); <answer> += 
case <token> <answer> HFI_PROPERTY_PARAM_VENC_MPEG4_SHORT_HEADER: 
case <token> <answer> HFI_PROPERTY_PARAM_VENC_MPEG4_AC_PREDICTION: 
case <token> { <answer> HFI_PROPERTY_CONFIG_VENC_TARGET_BITRATE: 
<token> hfi_bitrate *in = pdata, *brate = prop_data; <answer> struct 
brate->bitrate <token> in->bitrate; <answer> = 
brate->layer_id = <token> <answer> in->layer_id; 
pkt->shdr.hdr.size <token> sizeof(u32) + sizeof(*brate); <answer> += 
case <token> { <answer> HFI_PROPERTY_CONFIG_VENC_MAX_BITRATE: 
struct hfi_bitrate *in = <token> *hfi = prop_data; <answer> pdata, 
hfi->bitrate = <token> <answer> in->bitrate; 
hfi->layer_id <token> in->layer_id; <answer> = 
<token> += sizeof(u32) + sizeof(*hfi); <answer> pkt->shdr.hdr.size 
<token> HFI_PROPERTY_PARAM_PROFILE_LEVEL_CURRENT: { <answer> case 
struct hfi_profile_level *in = pdata, *pl = <token> <answer> prop_data; 
pl->level = <token> <answer> in->level; 
pl->profile = <token> <answer> in->profile; 
if (pl->profile <token> 0) <answer> <= 
if (min_qp > <token> || max_qp > 0xff) { <answer> 0xff 
ret <token> -ERANGE; <answer> = 
range->min_qp = min_qp | min_qp << <token> | min_qp << 16; <answer> 8 
range->max_qp = max_qp | max_qp << 8 <token> max_qp << 16; <answer> | 
range->layer_id = <token> <answer> in->layer_id; 
pkt->shdr.hdr.size <token> sizeof(u32) + sizeof(*range); <answer> += 
<token> HFI_PROPERTY_PARAM_VENC_VC1_PERF_CFG: { <answer> case 
struct hfi_vc1e_perf_cfg_type <token> = pdata, *perf = prop_data; <answer> *in 
pkt->shdr.hdr.size += <token> + sizeof(*perf); <answer> sizeof(u32) 
case <token> { <answer> HFI_PROPERTY_PARAM_VENC_MAX_NUM_B_FRAMES: 
struct hfi_max_num_b_frames <token> = prop_data; <answer> *bframes 
<token> *in = pdata; <answer> u32 
bframes->max_num_b_frames = <token> <answer> *in; 
pkt->shdr.hdr.size += <token> + sizeof(*bframes); <answer> sizeof(u32) 
case HFI_PROPERTY_CONFIG_VENC_INTRA_PERIOD: <token> <answer> { 
struct hfi_intra_period *in = pdata, *intra = <token> <answer> prop_data; 
intra->pframes = <token> <answer> in->pframes; 
intra->bframes <token> in->bframes; <answer> = 
pkt->shdr.hdr.size <token> sizeof(u32) + sizeof(*intra); <answer> += 
case <token> { <answer> HFI_PROPERTY_CONFIG_VENC_IDR_PERIOD: 
struct hfi_idr_period *in = pdata, *idr = <token> <answer> prop_data; 
<token> = in->idr_period; <answer> idr->idr_period 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*idr); 
<token> HFI_PROPERTY_PARAM_VDEC_CONCEAL_COLOR: { <answer> case 
struct hfi_conceal_color *color = <token> <answer> prop_data; 
u32 *in = <token> <answer> pdata; 
<token> = *in & 0xff; <answer> color->conceal_color 
color->conceal_color |= ((*in >> <token> & 0xff) << 8; <answer> 10) 
color->conceal_color |= ((*in >> <token> & 0xff) << 16; <answer> 20) 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*color); 
case <token> { <answer> HFI_PROPERTY_CONFIG_VPE_OPERATIONS: 
<token> hfi_operations_type *in = pdata, *ops = prop_data; <answer> struct 
switch (in->rotation) <token> <answer> { 
<token> HFI_ROTATE_NONE: <answer> case 
<token> HFI_ROTATE_90: <answer> case 
case <token> <answer> HFI_ROTATE_180: 
<token> HFI_ROTATE_270: <answer> case 
ret <token> -EINVAL; <answer> = 
<token> (in->flip) { <answer> switch 
<token> HFI_FLIP_NONE: <answer> case 
case <token> <answer> HFI_FLIP_HORIZONTAL: 
case <token> <answer> HFI_FLIP_VERTICAL: 
ret = <token> <answer> -EINVAL; 
ops->rotation = <token> <answer> in->rotation; 
ops->flip <token> in->flip; <answer> = 
<token> += sizeof(u32) + sizeof(*ops); <answer> pkt->shdr.hdr.size 
<token> HFI_PROPERTY_PARAM_VENC_INTRA_REFRESH: { <answer> case 
struct hfi_intra_refresh *in = pdata, <token> = prop_data; <answer> *intra 
<token> (in->mode) { <answer> switch 
<token> HFI_INTRA_REFRESH_NONE: <answer> case 
<token> HFI_INTRA_REFRESH_ADAPTIVE: <answer> case 
case <token> <answer> HFI_INTRA_REFRESH_CYCLIC: 
case <token> <answer> HFI_INTRA_REFRESH_CYCLIC_ADAPTIVE: 
<token> HFI_INTRA_REFRESH_RANDOM: <answer> case 
ret = <token> <answer> -EINVAL; 
intra->mode = <token> <answer> in->mode; 
intra->air_mbs <token> in->air_mbs; <answer> = 
intra->air_ref = <token> <answer> in->air_ref; 
intra->cir_mbs <token> in->cir_mbs; <answer> = 
pkt->shdr.hdr.size += <token> + sizeof(*intra); <answer> sizeof(u32) 
case <token> { <answer> HFI_PROPERTY_PARAM_VENC_MULTI_SLICE_CONTROL: 
struct hfi_multi_slice_control *in = pdata, <token> = prop_data; <answer> *multi 
switch <token> { <answer> (in->multi_slice) 
case <token> <answer> HFI_MULTI_SLICE_OFF: 
case <token> <answer> HFI_MULTI_SLICE_GOB: 
<token> HFI_MULTI_SLICE_BY_MB_COUNT: <answer> case 
case <token> <answer> HFI_MULTI_SLICE_BY_BYTE_COUNT: 
ret = <token> <answer> -EINVAL; 
multi->multi_slice = <token> <answer> in->multi_slice; 
multi->slice_size <token> in->slice_size; <answer> = 
pkt->shdr.hdr.size <token> sizeof(u32) + sizeof(*multi); <answer> += 
case <token> { <answer> HFI_PROPERTY_PARAM_VENC_SLICE_DELIVERY_MODE: 
struct hfi_enable *in = <token> *en = prop_data; <answer> pdata, 
en->enable <token> in->enable; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*en); 
<token> HFI_PROPERTY_PARAM_VENC_H264_VUI_TIMING_INFO: { <answer> case 
struct hfi_h264_vui_timing_info *in <token> pdata, *vui = prop_data; <answer> = 
vui->enable = <token> <answer> in->enable; 
vui->fixed_framerate = <token> <answer> in->fixed_framerate; 
vui->time_scale <token> in->time_scale; <answer> = 
<token> += sizeof(u32) + sizeof(*vui); <answer> pkt->shdr.hdr.size 
<token> HFI_PROPERTY_CONFIG_VPE_DEINTERLACE: { <answer> case 
struct hfi_enable <token> = pdata, *en = prop_data; <answer> *in 
en->enable <token> in->enable; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*en); <answer> + 
<token> HFI_PROPERTY_PARAM_VENC_H264_GENERATE_AUDNAL: { <answer> case 
struct hfi_enable *in = pdata, <token> = prop_data; <answer> *en 
<token> = in->enable; <answer> en->enable 
<token> += sizeof(u32) + sizeof(*en); <answer> pkt->shdr.hdr.size 
case HFI_PROPERTY_PARAM_BUFFER_ALLOC_MODE: <token> <answer> { 
struct hfi_buffer_alloc_mode *in = pdata, *mode = <token> <answer> prop_data; 
mode->type <token> in->type; <answer> = 
<token> = in->mode; <answer> mode->mode 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*mode); <answer> + 
case <token> { <answer> HFI_PROPERTY_PARAM_VDEC_FRAME_ASSEMBLY: 
struct hfi_enable *in = <token> *en = prop_data; <answer> pdata, 
en->enable <token> in->enable; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*en); <answer> + 
case HFI_PROPERTY_PARAM_VENC_H264_VUI_BITSTREAM_RESTRC: <token> <answer> { 
struct hfi_enable *in <token> pdata, *en = prop_data; <answer> = 
<token> = in->enable; <answer> en->enable 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*en); 
case HFI_PROPERTY_PARAM_VENC_PRESERVE_TEXT_QUALITY: <token> <answer> { 
struct <token> *in = pdata, *en = prop_data; <answer> hfi_enable 
<token> = in->enable; <answer> en->enable 
pkt->shdr.hdr.size += <token> + sizeof(*en); <answer> sizeof(u32) 
<token> HFI_PROPERTY_PARAM_VDEC_SCS_THRESHOLD: { <answer> case 
struct hfi_scs_threshold *thres = <token> <answer> prop_data; 
u32 <token> = pdata; <answer> *in 
thres->threshold_value = <token> <answer> *in; 
pkt->shdr.hdr.size += <token> + sizeof(*thres); <answer> sizeof(u32) 
case <token> { <answer> HFI_PROPERTY_PARAM_MVC_BUFFER_LAYOUT: 
struct hfi_mvc_buffer_layout_descp_type <token> = pdata; <answer> *in 
struct hfi_mvc_buffer_layout_descp_type *mvc <token> prop_data; <answer> = 
switch (in->layout_type) <token> <answer> { 
<token> HFI_MVC_BUFFER_LAYOUT_TOP_BOTTOM: <answer> case 
case <token> <answer> HFI_MVC_BUFFER_LAYOUT_SEQ: 
ret = <token> <answer> -EINVAL; 
mvc->layout_type = <token> <answer> in->layout_type; 
<token> = in->bright_view_first; <answer> mvc->bright_view_first 
mvc->ngap <token> in->ngap; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*mvc); 
case <token> { <answer> HFI_PROPERTY_PARAM_VENC_LTRMODE: 
struct hfi_ltr_mode *in = pdata, <token> = prop_data; <answer> *ltr 
switch <token> { <answer> (in->ltr_mode) 
<token> HFI_LTR_MODE_DISABLE: <answer> case 
case <token> <answer> HFI_LTR_MODE_MANUAL: 
<token> HFI_LTR_MODE_PERIODIC: <answer> case 
ret <token> -EINVAL; <answer> = 
ltr->ltr_mode <token> in->ltr_mode; <answer> = 
<token> = in->ltr_count; <answer> ltr->ltr_count 
ltr->trust_mode <token> in->trust_mode; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*ltr); <answer> + 
case <token> { <answer> HFI_PROPERTY_CONFIG_VENC_USELTRFRAME: 
struct hfi_ltr_use <token> = pdata, *ltr_use = prop_data; <answer> *in 
<token> = in->frames; <answer> ltr_use->frames 
ltr_use->ref_ltr <token> in->ref_ltr; <answer> = 
ltr_use->use_constrnt = <token> <answer> in->use_constrnt; 
<token> += sizeof(u32) + sizeof(*ltr_use); <answer> pkt->shdr.hdr.size 
<token> HFI_PROPERTY_CONFIG_VENC_MARKLTRFRAME: { <answer> case 
struct hfi_ltr_mark <token> = pdata, *ltr_mark = prop_data; <answer> *in 
ltr_mark->mark_frame <token> in->mark_frame; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*ltr_mark); <answer> + 
<token> HFI_PROPERTY_PARAM_VENC_HIER_P_MAX_NUM_ENH_LAYER: { <answer> case 
u32 *in = <token> <answer> pdata; 
pkt->data[1] = <token> <answer> *in; 
pkt->shdr.hdr.size += <token> * 2; <answer> sizeof(u32) 
<token> HFI_PROPERTY_CONFIG_VENC_HIER_P_ENH_LAYER: { <answer> case 
u32 *in <token> pdata; <answer> = 
pkt->data[1] = <token> <answer> *in; 
pkt->shdr.hdr.size += sizeof(u32) <token> 2; <answer> * 
case <token> { <answer> HFI_PROPERTY_PARAM_VENC_DISABLE_RC_TIMESTAMP: 
struct hfi_enable <token> = pdata, *en = prop_data; <answer> *in 
en->enable <token> in->enable; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*en); <answer> + 
case HFI_PROPERTY_PARAM_VENC_INITIAL_QP: <token> <answer> { 
<token> hfi_initial_quantization *in = pdata, *quant = prop_data; <answer> struct 
<token> = in->init_qp_enable; <answer> quant->init_qp_enable 
<token> = in->qp_i; <answer> quant->qp_i 
<token> = in->qp_p; <answer> quant->qp_p 
quant->qp_b <token> in->qp_b; <answer> = 
pkt->shdr.hdr.size <token> sizeof(u32) + sizeof(*quant); <answer> += 
<token> HFI_PROPERTY_PARAM_VPE_COLOR_SPACE_CONVERSION: { <answer> case 
<token> hfi_vpe_color_space_conversion *in = pdata; <answer> struct 
struct hfi_vpe_color_space_conversion *csc = <token> <answer> prop_data; 
<token> in->csc_matrix, <answer> memcpy(csc->csc_matrix, 
memcpy(csc->csc_bias, <token> sizeof(csc->csc_bias)); <answer> in->csc_bias, 
<token> in->csc_limit, sizeof(csc->csc_limit)); <answer> memcpy(csc->csc_limit, 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*csc); 
<token> HFI_PROPERTY_PARAM_VENC_VPX_ERROR_RESILIENCE_MODE: { <answer> case 
struct hfi_enable *in = pdata, *en <token> prop_data; <answer> = 
en->enable = <token> <answer> in->enable; 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*en); <answer> + 
<token> HFI_PROPERTY_PARAM_VENC_H264_NAL_SVC_EXT: { <answer> case 
struct hfi_enable *in = pdata, *en <token> prop_data; <answer> = 
en->enable <token> in->enable; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*en); 
<token> HFI_PROPERTY_CONFIG_VENC_PERF_MODE: { <answer> case 
u32 *in <token> pdata; <answer> = 
pkt->data[1] <token> *in; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) <token> 2; <answer> * 
<token> HFI_PROPERTY_PARAM_VENC_HIER_B_MAX_NUM_ENH_LAYER: { <answer> case 
<token> *in = pdata; <answer> u32 
<token> = *in; <answer> pkt->data[1] 
<token> += sizeof(u32) * 2; <answer> pkt->shdr.hdr.size 
case HFI_PROPERTY_PARAM_VDEC_NONCP_OUTPUT2: <token> <answer> { 
struct hfi_enable *in <token> pdata, *en = prop_data; <answer> = 
en->enable <token> in->enable; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*en); 
case HFI_PROPERTY_PARAM_VENC_HIER_P_HYBRID_MODE: <token> <answer> { 
struct hfi_hybrid_hierp *in <token> pdata, *hierp = prop_data; <answer> = 
hierp->layers <token> in->layers; <answer> = 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*hierp); <answer> + 
case HFI_PROPERTY_PARAM_UNCOMPRESSED_PLANE_ACTUAL_INFO: <token> <answer> { 
struct hfi_uncompressed_plane_actual_info <token> = pdata; <answer> *in 
struct <token> *info = prop_data; <answer> hfi_uncompressed_plane_actual_info 
info->buffer_type <token> in->buffer_type; <answer> = 
info->num_planes <token> in->num_planes; <answer> = 
info->plane_format[0] = <token> <answer> in->plane_format[0]; 
<token> (in->num_planes > 1) <answer> if 
info->plane_format[1] = <token> <answer> in->plane_format[1]; 
pkt->shdr.hdr.size += <token> + sizeof(*info); <answer> sizeof(u32) 
case <token> <answer> HFI_PROPERTY_PARAM_VENC_HDR10_PQ_SEI: 
<token> -ENOTSUPP; <answer> return 
switch (ptype) <token> <answer> { 
case HFI_PROPERTY_PARAM_VDEC_MULTI_STREAM: <token> <answer> { 
struct hfi_multi_stream *in <token> pdata; <answer> = 
struct hfi_multi_stream_3x *multi <token> prop_data; <answer> = 
<token> = in->buffer_type; <answer> multi->buffer_type 
multi->enable = <token> <answer> in->enable; 
pkt->shdr.hdr.size += <token> + sizeof(*multi); <answer> sizeof(u32) 
case <token> { <answer> HFI_PROPERTY_PARAM_VENC_INTRA_REFRESH: 
struct hfi_intra_refresh *in <token> pdata; <answer> = 
struct <token> *intra = prop_data; <answer> hfi_intra_refresh_3x 
<token> (in->mode) { <answer> switch 
<token> HFI_INTRA_REFRESH_NONE: <answer> case 
case <token> <answer> HFI_INTRA_REFRESH_ADAPTIVE: 
<token> HFI_INTRA_REFRESH_CYCLIC: <answer> case 
case <token> <answer> HFI_INTRA_REFRESH_CYCLIC_ADAPTIVE: 
case <token> <answer> HFI_INTRA_REFRESH_RANDOM: 
<token> = -EINVAL; <answer> ret 
<token> = in->mode; <answer> intra->mode 
intra->mbs = <token> <answer> in->cir_mbs; 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*intra); 
<token> HFI_PROPERTY_PARAM_VDEC_CONTINUE_DATA_TRANSFER: <answer> case 
<token> (ptype) { <answer> switch 
case <token> { <answer> HFI_PROPERTY_PARAM_BUFFER_COUNT_ACTUAL: 
struct hfi_buffer_count_actual *in = <token> <answer> pdata; 
struct <token> *count = prop_data; <answer> hfi_buffer_count_actual_4xx 
<token> = in->count_actual; <answer> count->count_actual 
<token> = in->type; <answer> count->type 
count->count_min_host = <token> <answer> in->count_actual; 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*count); 
case HFI_PROPERTY_PARAM_WORK_MODE: <token> <answer> { 
<token> hfi_video_work_mode *in = pdata, *wm = prop_data; <answer> struct 
wm->video_work_mode = <token> <answer> in->video_work_mode; 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*wm); <answer> + 
case <token> { <answer> HFI_PROPERTY_CONFIG_VIDEOCORES_USAGE: 
struct hfi_videocores_usage_type *in = <token> *cu = prop_data; <answer> pdata, 
cu->video_core_enable_mask = <token> <answer> in->video_core_enable_mask; 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*cu); <answer> + 
case HFI_PROPERTY_PARAM_VENC_HDR10_PQ_SEI: <token> <answer> { 
struct hfi_hdr10_pq_sei *in = pdata, *hdr10 = <token> <answer> prop_data; 
memcpy(hdr10, <token> sizeof(*hdr10)); <answer> in, 
pkt->shdr.hdr.size += sizeof(u32) + <token> <answer> sizeof(*hdr10); 
case <token> { <answer> HFI_PROPERTY_PARAM_VDEC_CONCEAL_COLOR: 
struct hfi_conceal_color_v4 *color = <token> <answer> prop_data; 
u32 <token> = pdata; <answer> *in 
color->conceal_color_8bit = *in & <token> <answer> 0xff; 
color->conceal_color_8bit <token> ((*in >> 10) & 0xff) << 8; <answer> |= 
color->conceal_color_8bit |= ((*in >> 20) & 0xff) << <token> <answer> 16; 
color->conceal_color_10bit <token> *in; <answer> = 
<token> += sizeof(u32) + sizeof(*color); <answer> pkt->shdr.hdr.size 
case <token> { <answer> HFI_PROPERTY_PARAM_VENC_H264_TRANSFORM_8X8: 
struct hfi_h264_8x8_transform *in = pdata, *tm = <token> <answer> prop_data; 
<token> = in->enable_type; <answer> tm->enable_type 
pkt->shdr.hdr.size += <token> + sizeof(*tm); <answer> sizeof(u32) 
case <token> { <answer> HFI_PROPERTY_PARAM_VENC_SESSION_QP_RANGE_V2: 
struct hfi_quantization_range_v2 *in = pdata, <token> = prop_data; <answer> *range 
<token> min_qp, max_qp; <answer> u32 
min_qp <token> in->min_qp.qp_packed; <answer> = 
max_qp <token> in->max_qp.qp_packed; <answer> = 
if (min_qp > 0xff || <token> > 0xff) <answer> max_qp 
return <token> <answer> -ERANGE; 
range->min_qp.layer_id <token> 0xFF; <answer> = 
range->max_qp.layer_id = <token> <answer> 0xFF; 
range->min_qp.qp_packed = (min_qp & 0xFF) | ((min_qp <token> 0xFF) << 8) | <answer> & 
((min_qp <token> 0xFF) << 16); <answer> & 
range->max_qp.qp_packed = (max_qp & 0xFF) | <token> & 0xFF) << 8) | <answer> ((max_qp 
((max_qp <token> 0xFF) << 16); <answer> & 
range->min_qp.enable <token> 7; <answer> = 
<token> = 7; <answer> range->max_qp.enable 
pkt->shdr.hdr.size += sizeof(u32) <token> sizeof(*range); <answer> + 
case <token> <answer> HFI_PROPERTY_CONFIG_VENC_MAX_BITRATE: 
<token> HFI_PROPERTY_CONFIG_VDEC_POST_LOOP_DEBLOCKER: <answer> case 
case <token> <answer> HFI_PROPERTY_PARAM_BUFFER_ALLOC_MODE: 
<token> HFI_PROPERTY_PARAM_VENC_SESSION_QP: <answer> case 
case <token> <answer> HFI_PROPERTY_PARAM_VENC_SESSION_QP_RANGE: 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <sound/core.h> 
<token> <sound/pcm.h> <answer> #include 
#include <token> <answer> <sound/pcm_params.h> 
<token> <sound/soc.h> <answer> #include 
<token> <sound/tlv.h> <answer> #include 
#include <token> <answer> <linux/i2c.h> 
#include <token> <answer> <linux/spi/spi.h> 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> <asm/unaligned.h> 
<token> "sigmadsp.h" <answer> #include 
<token> "adau17x1.h" <answer> #include 
#include <token> <answer> "adau-utils.h" 
#define ADAU17X1_SAFELOAD_TARGET_ADDRESS <token> <answer> 0x0006 
#define <token> 0x0007 <answer> ADAU17X1_SAFELOAD_TRIGGER 
#define <token> 0x0001 <answer> ADAU17X1_SAFELOAD_DATA 
#define <token> 20 <answer> ADAU17X1_SAFELOAD_DATA_SIZE 
#define <token> 4 <answer> ADAU17X1_WORD_SIZE 
static const <token> * const adau17x1_capture_mixer_boost_text[] = { <answer> char 
"Normal operation", "Boost Level 1", "Boost Level 2", "Boost Level <token> <answer> 3", 
static <token> <answer> SOC_ENUM_SINGLE_DECL(adau17x1_capture_boost_enum, 
<token> 5, adau17x1_capture_mixer_boost_text); <answer> ADAU17X1_REC_POWER_MGMT, 
static <token> char * const adau17x1_mic_bias_mode_text[] = { <answer> const 
"Normal <token> "High performance", <answer> operation", 
<token> SOC_ENUM_SINGLE_DECL(adau17x1_mic_bias_mode_enum, <answer> static 
ADAU17X1_MICBIAS, 3, <token> <answer> adau17x1_mic_bias_mode_text); 
static const <token> -9563, 0); <answer> DECLARE_TLV_DB_MINMAX(adau17x1_digital_tlv, 
static <token> struct snd_kcontrol_new adau17x1_controls[] = { <answer> const 
SOC_DOUBLE_R_TLV("Digital Capture <token> <answer> Volume", 
0, <token> 1, adau17x1_digital_tlv), <answer> 0xff, 
SOC_DOUBLE_R_TLV("Digital Playback <token> ADAU17X1_DAC_CONTROL1, <answer> Volume", 
ADAU17X1_DAC_CONTROL2, 0, <token> 1, adau17x1_digital_tlv), <answer> 0xff, 
SOC_SINGLE("ADC <token> Pass Filter Switch", ADAU17X1_ADC_CONTROL, <answer> High 
<token> 1, 0), <answer> 5, 
SOC_SINGLE("Playback De-emphasis <token> ADAU17X1_DAC_CONTROL0, <answer> Switch", 
<token> 1, 0), <answer> 2, 
SOC_ENUM("Capture Boost", <token> <answer> adau17x1_capture_boost_enum), 
SOC_ENUM("Mic <token> Mode", adau17x1_mic_bias_mode_enum), <answer> Bias 
<token> int adau17x1_setup_firmware(struct snd_soc_component *component, <answer> static 
unsigned <token> rate); <answer> int 
static <token> adau17x1_pll_event(struct snd_soc_dapm_widget *w, <answer> int 
struct snd_kcontrol *kcontrol, <token> event) <answer> int 
struct snd_soc_component <token> = snd_soc_dapm_to_component(w->dapm); <answer> *component 
struct adau *adau = <token> <answer> snd_soc_component_get_drvdata(component); 
if <token> { <answer> (SND_SOC_DAPM_EVENT_ON(event)) 
adau->pll_regs[5] = <token> <answer> 1; 
} else <token> <answer> { 
<token> = 0; <answer> adau->pll_regs[5] 
<token> ADAU17X1_CLOCK_CONTROL, <answer> regmap_update_bits(adau->regmap, 
<token> 0); <answer> ADAU17X1_CLOCK_CONTROL_CORECLK_SRC_PLL, 
regmap_update_bits(adau->regmap, <token> <answer> ADAU17X1_CONVERTER0, 
ADAU17X1_CONVERTER0_ADOSR, <token> <answer> ADAU17X1_CONVERTER0_ADOSR); 
regmap_update_bits(adau->regmap, <token> <answer> ADAU17X1_CONVERTER0, 
<token> 0); <answer> ADAU17X1_CONVERTER0_ADOSR, 
<token> 0; <answer> return 
static <token> char * const adau17x1_mono_stereo_text[] = { <answer> const 
"Mono Left Channel <token> <answer> (L+R)", 
<token> Right Channel (L+R)", <answer> "Mono 
<token> (L+R)", <answer> "Mono 
<token> SOC_ENUM_SINGLE_DECL(adau17x1_dac_mode_enum, <answer> static 
ADAU17X1_DAC_CONTROL0, <token> adau17x1_mono_stereo_text); <answer> 6, 
static const struct snd_kcontrol_new adau17x1_dac_mode_mux <token> <answer> = 
<token> Mono-Stereo-Mode", adau17x1_dac_mode_enum); <answer> SOC_DAPM_ENUM("DAC 
static const struct <token> adau17x1_dapm_widgets[] = { <answer> snd_soc_dapm_widget 
SND_SOC_DAPM_SUPPLY_S("PLL", 3, SND_SOC_NOPM, <token> 0, adau17x1_pll_event, <answer> 0, 
SND_SOC_DAPM_PRE_PMU | <token> <answer> SND_SOC_DAPM_POST_PMD), 
<token> SND_SOC_NOPM, 0, 0, NULL, 0), <answer> SND_SOC_DAPM_SUPPLY("AIFCLK", 
SND_SOC_DAPM_SUPPLY("MICBIAS", ADAU17X1_MICBIAS, 0, 0, <token> 0), <answer> NULL, 
<token> Playback Enable", ADAU17X1_PLAY_POWER_MGMT, <answer> SND_SOC_DAPM_SUPPLY("Left 
<token> 0, NULL, 0), <answer> 0, 
SND_SOC_DAPM_SUPPLY("Right <token> Enable", ADAU17X1_PLAY_POWER_MGMT, <answer> Playback 
1, 0, <token> 0), <answer> NULL, 
<token> DAC Mode Mux", SND_SOC_NOPM, 0, 0, <answer> SND_SOC_DAPM_MUX("Left 
SND_SOC_DAPM_MUX("Right DAC <token> Mux", SND_SOC_NOPM, 0, 0, <answer> Mode 
<token> Decimator", NULL, ADAU17X1_ADC_CONTROL, 0, 0, <answer> SND_SOC_DAPM_ADC_E("Left 
adau17x1_adc_fixup, <token> <answer> SND_SOC_DAPM_POST_PMU), 
SND_SOC_DAPM_ADC("Right Decimator", NULL, ADAU17X1_ADC_CONTROL, 1, <token> <answer> 0), 
SND_SOC_DAPM_DAC("Left DAC", <token> ADAU17X1_DAC_CONTROL0, 0, 0), <answer> NULL, 
<token> DAC", NULL, ADAU17X1_DAC_CONTROL0, 1, 0), <answer> SND_SOC_DAPM_DAC("Right 
<token> const struct snd_soc_dapm_route adau17x1_dapm_routes[] = { <answer> static 
{ "Left Decimator", NULL, <token> }, <answer> "SYSCLK" 
{ "Right <token> NULL, "SYSCLK" }, <answer> Decimator", 
<token> "Left DAC", NULL, "SYSCLK" }, <answer> { 
<token> "Right DAC", NULL, "SYSCLK" }, <answer> { 
<token> "Capture", NULL, "SYSCLK" }, <answer> { 
{ "Playback", <token> "SYSCLK" }, <answer> NULL, 
{ "Left DAC", NULL, "Left DAC <token> Mux" }, <answer> Mode 
<token> "Right DAC", NULL, "Right DAC Mode Mux" }, <answer> { 
<token> "Capture", NULL, "AIFCLK" }, <answer> { 
{ "Playback", NULL, <token> }, <answer> "AIFCLK" 
static const struct snd_soc_dapm_route adau17x1_dapm_pll_route <token> { <answer> = 
<token> NULL, "PLL", <answer> "SYSCLK", 
<token> int adau17x1_dsp_mux_enum_put(struct snd_kcontrol *kcontrol, <answer> static 
struct snd_ctl_elem_value <token> <answer> *ucontrol) 
struct snd_soc_component <token> = snd_soc_dapm_kcontrol_component(kcontrol); <answer> *component 
struct snd_soc_dapm_context *dapm = <token> <answer> snd_soc_component_get_dapm(component); 
struct adau *adau <token> snd_soc_component_get_drvdata(component); <answer> = 
struct soc_enum *e <token> (struct soc_enum *)kcontrol->private_value; <answer> = 
struct snd_soc_dapm_update update <token> {}; <answer> = 
<token> int stream = e->shift_l; <answer> unsigned 
<token> int val, change; <answer> unsigned 
int <token> <answer> reg; 
if <token> >= e->items) <answer> (ucontrol->value.enumerated.item[0] 
<token> -EINVAL; <answer> return 
<token> (ucontrol->value.enumerated.item[0]) { <answer> switch 
case <token> <answer> 0: 
<token> = 0; <answer> val 
<token> = false; <answer> adau->dsp_bypass[stream] 
<token> = (adau->tdm_slot[stream] * 2) + 1; <answer> val 
<token> = true; <answer> adau->dsp_bypass[stream] 
if (stream == <token> <answer> SNDRV_PCM_STREAM_PLAYBACK) 
reg <token> ADAU17X1_SERIAL_INPUT_ROUTE; <answer> = 
reg <token> ADAU17X1_SERIAL_OUTPUT_ROUTE; <answer> = 
change = <token> reg, 0xff, val); <answer> snd_soc_component_test_bits(component, 
if <token> { <answer> (change) 
<token> = kcontrol; <answer> update.kcontrol 
<token> = 0xff; <answer> update.mask 
update.reg = <token> <answer> reg; 
<token> = val; <answer> update.val 
snd_soc_dapm_mux_update_power(dapm, <token> <answer> kcontrol, 
ucontrol->value.enumerated.item[0], e, <token> <answer> &update); 
return <token> <answer> change; 
static int adau17x1_dsp_mux_enum_get(struct <token> *kcontrol, <answer> snd_kcontrol 
struct <token> *ucontrol) <answer> snd_ctl_elem_value 
struct snd_soc_component <token> = snd_soc_dapm_kcontrol_component(kcontrol); <answer> *component 
<token> adau *adau = snd_soc_component_get_drvdata(component); <answer> struct 
struct soc_enum *e <token> (struct soc_enum *)kcontrol->private_value; <answer> = 
<token> int stream = e->shift_l; <answer> unsigned 
<token> int reg, val; <answer> unsigned 
int <token> <answer> ret; 
<token> (stream == SNDRV_PCM_STREAM_PLAYBACK) <answer> if 
reg <token> ADAU17X1_SERIAL_INPUT_ROUTE; <answer> = 
<token> = ADAU17X1_SERIAL_OUTPUT_ROUTE; <answer> reg 
ret = regmap_read(adau->regmap, <token> &val); <answer> reg, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
if (val <token> 0) <answer> != 
val <token> 1; <answer> = 
ucontrol->value.enumerated.item[0] <token> val; <answer> = 
<token> 0; <answer> return 
<token> DECLARE_ADAU17X1_DSP_MUX_CTRL(_name, _label, _stream, _text) \ <answer> #define 
const struct snd_kcontrol_new _name <token> \ <answer> = 
SOC_DAPM_ENUM_EXT(_label, <token> struct soc_enum)\ <answer> (const 
SOC_ENUM_SINGLE(SND_SOC_NOPM, <token> \ <answer> _stream, 
ARRAY_SIZE(_text), <token> \ <answer> _text), 
adau17x1_dsp_mux_enum_get, <token> <answer> adau17x1_dsp_mux_enum_put) 
static const char <token> const adau17x1_dac_mux_text[] = { <answer> * 
static const <token> * const adau17x1_capture_mux_text[] = { <answer> char 
static DECLARE_ADAU17X1_DSP_MUX_CTRL(adau17x1_dac_mux, <token> Playback Mux", <answer> "DAC 
SNDRV_PCM_STREAM_PLAYBACK, <token> <answer> adau17x1_dac_mux_text); 
static DECLARE_ADAU17X1_DSP_MUX_CTRL(adau17x1_capture_mux, <token> Mux", <answer> "Capture 
<token> adau17x1_capture_mux_text); <answer> SNDRV_PCM_STREAM_CAPTURE, 
static const <token> snd_soc_dapm_widget adau17x1_dsp_dapm_widgets[] = { <answer> struct 
SND_SOC_DAPM_PGA("DSP", ADAU17X1_DSP_RUN, 0, 0, <token> 0), <answer> NULL, 
SND_SOC_DAPM_SIGGEN("DSP <token> <answer> Siggen"), 
SND_SOC_DAPM_MUX("DAC <token> Mux", SND_SOC_NOPM, 0, 0, <answer> Playback 
SND_SOC_DAPM_MUX("Capture Mux", SND_SOC_NOPM, 0, <token> <answer> 0, 
static const struct snd_soc_dapm_route adau17x1_dsp_dapm_routes[] <token> { <answer> = 
{ "DAC Playback Mux", "DSP", <token> }, <answer> "DSP" 
{ "DAC Playback <token> "AIFIN", "Playback" }, <answer> Mux", 
{ "Left DAC Mode Mux", "Stereo", <token> Playback Mux" }, <answer> "DAC 
<token> "Left DAC Mode Mux", "Mono (L+R)", "DAC Playback Mux" }, <answer> { 
{ "Left DAC Mode Mux", "Mono Left Channel (L+R)", "DAC Playback Mux" <token> <answer> }, 
{ "Right DAC Mode Mux", "Stereo", <token> Playback Mux" }, <answer> "DAC 
{ "Right DAC Mode Mux", <token> (L+R)", "DAC Playback Mux" }, <answer> "Mono 
{ "Right DAC Mode Mux", <token> Right Channel (L+R)", "DAC Playback Mux" }, <answer> "Mono 
{ "Capture Mux", "DSP", "DSP" <token> <answer> }, 
{ "Capture Mux", <token> "Left Decimator" }, <answer> "Decimator", 
{ "Capture Mux", "Decimator", "Right Decimator" <token> <answer> }, 
{ "Capture", NULL, <token> Mux" }, <answer> "Capture 
{ "DSP", NULL, "DSP Siggen" <token> <answer> }, 
{ "DSP", NULL, "Left <token> }, <answer> Decimator" 
{ "DSP", NULL, "Right Decimator" <token> <answer> }, 
{ "DSP", NULL, "Playback" <token> <answer> }, 
<token> const struct snd_soc_dapm_route adau17x1_no_dsp_dapm_routes[] = { <answer> static 
{ "Left DAC Mode <token> "Stereo", "Playback" }, <answer> Mux", 
{ "Left DAC Mode Mux", <token> (L+R)", "Playback" }, <answer> "Mono 
{ "Left DAC Mode <token> "Mono Left Channel (L+R)", "Playback" }, <answer> Mux", 
{ "Right DAC Mode Mux", <token> "Playback" }, <answer> "Stereo", 
<token> "Right DAC Mode Mux", "Mono (L+R)", "Playback" }, <answer> { 
{ <token> DAC Mode Mux", "Mono Right Channel (L+R)", "Playback" }, <answer> "Right 
{ "Capture", <token> "Left Decimator" }, <answer> NULL, 
{ "Capture", <token> "Right Decimator" }, <answer> NULL, 
static <token> adau17x1_has_dsp(struct adau *adau) <answer> bool 
switch (adau->type) <token> <answer> { 
case <token> <answer> ADAU1761: 
<token> ADAU1381: <answer> case 
case <token> <answer> ADAU1781: 
<token> true; <answer> return 
return <token> <answer> false; 
if <token> == rate) <answer> (adau->sigmadsp->current_samplerate 
<token> 0; <answer> return 
ret = regmap_read(adau->regmap, <token> &dspsr); <answer> ADAU17X1_DSP_SAMPLING_RATE, 
if <token> <answer> (ret) 
<token> err; <answer> goto 
ret = <token> ADAU17X1_DSP_RUN, &dsp_run); <answer> regmap_read(adau->regmap, 
if <token> <answer> (ret) 
<token> err; <answer> goto 
regmap_write(adau->regmap, <token> 1); <answer> ADAU17X1_DSP_ENABLE, 
regmap_write(adau->regmap, <token> 0xf); <answer> ADAU17X1_DSP_SAMPLING_RATE, 
regmap_write(adau->regmap, <token> 0); <answer> ADAU17X1_DSP_RUN, 
<token> = sigmadsp_setup(adau->sigmadsp, rate); <answer> ret 
<token> (ret) { <answer> if 
regmap_write(adau->regmap, ADAU17X1_DSP_ENABLE, <token> <answer> 0); 
<token> err; <answer> goto 
regmap_write(adau->regmap, ADAU17X1_DSP_SAMPLING_RATE, <token> <answer> dspsr); 
regmap_write(adau->regmap, ADAU17X1_DSP_RUN, <token> <answer> dsp_run); 
<token> ret; <answer> return 
int adau17x1_add_widgets(struct <token> *component) <answer> snd_soc_component 
struct <token> *dapm = snd_soc_component_get_dapm(component); <answer> snd_soc_dapm_context 
<token> adau *adau = snd_soc_component_get_drvdata(component); <answer> struct 
int <token> <answer> ret; 
ret <token> snd_soc_add_component_controls(component, adau17x1_controls, <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
ret <token> snd_soc_dapm_new_controls(dapm, adau17x1_dapm_widgets, <answer> = 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> (adau17x1_has_dsp(adau)) { <answer> if 
ret = snd_soc_dapm_new_controls(dapm, <token> <answer> adau17x1_dsp_dapm_widgets, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> (!adau->sigmadsp) <answer> if 
<token> 0; <answer> return 
ret <token> sigmadsp_attach(adau->sigmadsp, component); <answer> = 
<token> (ret) { <answer> if 
dev_err(component->dev, "Failed <token> attach firmware: %d\n", <answer> to 
<token> ret; <answer> return 
return <token> <answer> 0; 
int <token> snd_soc_component *component) <answer> adau17x1_add_routes(struct 
struct snd_soc_dapm_context *dapm = <token> <answer> snd_soc_component_get_dapm(component); 
<token> adau *adau = snd_soc_component_get_drvdata(component); <answer> struct 
int <token> <answer> ret; 
ret <token> snd_soc_dapm_add_routes(dapm, adau17x1_dapm_routes, <answer> = 
if <token> <answer> (ret) 
return <token> <answer> ret; 
if <token> { <answer> (adau17x1_has_dsp(adau)) 
<token> = snd_soc_dapm_add_routes(dapm, adau17x1_dsp_dapm_routes, <answer> ret 
} <token> { <answer> else 
ret <token> snd_soc_dapm_add_routes(dapm, adau17x1_no_dsp_dapm_routes, <answer> = 
if <token> != ADAU17X1_CLK_SRC_MCLK) <answer> (adau->clk_src 
<token> &adau17x1_dapm_pll_route, 1); <answer> snd_soc_dapm_add_routes(dapm, 
return <token> <answer> ret; 
int adau17x1_resume(struct <token> *component) <answer> snd_soc_component 
struct <token> *adau = snd_soc_component_get_drvdata(component); <answer> adau 
if <token> <answer> (adau->switch_mode) 
<token> 0; <answer> return 
static int adau17x1_safeload(struct sigmadsp *sigmadsp, unsigned <token> addr, <answer> int 
const uint8_t <token> size_t len) <answer> bytes[], 
<token> buf[ADAU17X1_WORD_SIZE]; <answer> uint8_t 
uint8_t <token> <answer> data[ADAU17X1_SAFELOAD_DATA_SIZE]; 
unsigned <token> addr_offset; <answer> int 
unsigned <token> nbr_words; <answer> int 
int <token> <answer> ret; 
nbr_words = <token> / ADAU17X1_WORD_SIZE; <answer> len 
if ((len <token> nbr_words * ADAU17X1_WORD_SIZE) == 0) { <answer> - 
<token> = regmap_raw_write(sigmadsp->control_data, <answer> ret 
<token> bytes, len); <answer> ADAU17X1_SAFELOAD_DATA, 
<token> else { <answer> } 
<token> 0, ADAU17X1_SAFELOAD_DATA_SIZE); <answer> memset(data, 
<token> bytes, len); <answer> memcpy(data, 
ret <token> regmap_raw_write(sigmadsp->control_data, <answer> = 
ADAU17X1_SAFELOAD_DATA, <token> <answer> data, 
<token> * ADAU17X1_WORD_SIZE); <answer> nbr_words 
if <token> < 0) <answer> (ret 
<token> ret; <answer> return 
ret = adau_calc_pll_cfg(clk_get_rate(adau->mclk), 48000 * <token> <answer> 1024, 
if <token> < 0) <answer> (ret 
return <token> <answer> ret; 
ret <token> clk_prepare_enable(adau->mclk); <answer> = 
if <token> <answer> (ret) 
return <token> <answer> ret; 
adau->regmap <token> regmap; <answer> = 
adau->switch_mode <token> switch_mode; <answer> = 
adau->type = <token> <answer> type; 
dev_set_drvdata(dev, <token> <answer> adau); 
<token> (firmware_name) { <answer> if 
if <token> { <answer> (adau17x1_has_safeload(adau)) 
<token> = devm_sigmadsp_init_regmap(dev, regmap, <answer> adau->sigmadsp 
<token> firmware_name); <answer> &adau17x1_sigmadsp_ops, 
<token> else { <answer> } 
<token> = devm_sigmadsp_init_regmap(dev, regmap, <answer> adau->sigmadsp 
NULL, <token> <answer> firmware_name); 
<token> (IS_ERR(adau->sigmadsp)) { <answer> if 
dev_warn(dev, "Could <token> find firmware file: %ld\n", <answer> not 
adau->sigmadsp = <token> <answer> NULL; 
if <token> <answer> (switch_mode) 
<token> 0; <answer> return 
void <token> device *dev) <answer> adau17x1_remove(struct 
struct adau *adau = <token> <answer> dev_get_drvdata(dev); 
MODULE_DESCRIPTION("ASoC <token> common code"); <answer> ADAU1X61/ADAU1X81 
MODULE_AUTHOR("Lars-Peter <token> <lars@metafoo.de>"); <answer> Clausen 
<token> bool cc_get_tee_fips_status(struct cc_drvdata *drvdata) <answer> static 
<token> reg; <answer> u32 
reg = <token> CC_REG(GPR_HOST)); <answer> cc_ioread(drvdata, 
void cc_set_ree_fips_status(struct cc_drvdata *drvdata, bool <token> <answer> status) 
int val <token> CC_FIPS_SYNC_REE_STATUS; <answer> = 
<token> (drvdata->hw_rev < CC_HW_REV_712) <answer> if 
val |= (status ? CC_FIPS_SYNC_MODULE_OK : <token> <answer> CC_FIPS_SYNC_MODULE_ERROR); 
cc_iowrite(drvdata, <token> val); <answer> CC_REG(HOST_GPR0), 
void cc_tee_handle_fips_error(struct cc_drvdata <token> <answer> *p_drvdata) 
struct device *dev = <token> <answer> drvdata_to_dev(p_drvdata); 
<token> (!cc_get_tee_fips_status(p_drvdata)) <answer> if 
val = (CC_REG(HOST_IMR) <token> ~irq); <answer> & 
<token> CC_REG(HOST_IMR), val); <answer> cc_iowrite(drvdata, 
#include <token> <answer> "amdgpu.h" 
<token> "soc15.h" <answer> #include 
<token> "soc15_hw_ip.h" <answer> #include 
#include <token> <answer> "vega10_ip_offset.h" 
#include <token> <answer> "soc15_common.h" 
<token> "vega10_inc.h" <answer> #include 
#include <token> <answer> "vega10_ppsmc.h" 
#include <token> <answer> "vega10_baco.h" 
static const struct <token> pre_baco_tbl[] = { <answer> soc15_baco_cmd_entry 
{CMD_READMODIFYWRITE, <token> 0, mmBIF_DOORBELL_CNTL), BIF_DOORBELL_CNTL__DOORBELL_MONITOR_EN_MASK, BIF_DOORBELL_CNTL__DOORBELL_MONITOR_EN__SHIFT, 0, 1}, <answer> SOC15_REG_ENTRY(NBIF, 
<token> SOC15_REG_ENTRY(NBIF, 0, mmBIF_FB_EN), 0, 0, 0, 0}, <answer> {CMD_WRITE, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(NBIF, <token> mmBACO_CNTL), BACO_CNTL__BACO_DSTATE_BYPASS_MASK, BACO_CNTL__BACO_DSTATE_BYPASS__SHIFT, 0, 1}, <answer> 0, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(NBIF, <token> mmBACO_CNTL), BACO_CNTL__BACO_RST_INTR_MASK_MASK, BACO_CNTL__BACO_RST_INTR_MASK__SHIFT, 0, 1} <answer> 0, 
static <token> struct soc15_baco_cmd_entry enter_baco_tbl[] = { <answer> const 
{CMD_WAITFOR, SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), <token> THM_BACO_CNTL__SOC_DOMAIN_IDLE__SHIFT, 0xffffffff, 0x80000000}, <answer> THM_BACO_CNTL__SOC_DOMAIN_IDLE_MASK, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(NBIF, 0, mmBACO_CNTL), BACO_CNTL__BACO_EN_MASK, <token> 0, 1}, <answer> BACO_CNTL__BACO_EN__SHIFT, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(NBIF, 0, mmBACO_CNTL), <token> BACO_CNTL__BACO_BIF_LCLK_SWITCH__SHIFT, 0, 1}, <answer> BACO_CNTL__BACO_BIF_LCLK_SWITCH_MASK, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(NBIF, 0, mmBACO_CNTL), <token> BACO_CNTL__BACO_DUMMY_EN__SHIFT, 0, 1}, <answer> BACO_CNTL__BACO_DUMMY_EN_MASK, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_SOC_VDCI_RESET_MASK, THM_BACO_CNTL__BACO_SOC_VDCI_RESET__SHIFT, 0, <token> <answer> 1}, 
{CMD_READMODIFYWRITE, <token> 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_SMNCLK_MUX_MASK, THM_BACO_CNTL__BACO_SMNCLK_MUX__SHIFT, 0, 1}, <answer> SOC15_REG_ENTRY(THM, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_ISO_EN_MASK, THM_BACO_CNTL__BACO_ISO_EN__SHIFT, 0, <token> <answer> 1}, 
{CMD_READMODIFYWRITE, <token> 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_AEB_ISO_EN_MASK, THM_BACO_CNTL__BACO_AEB_ISO_EN__SHIFT, 0, 1}, <answer> SOC15_REG_ENTRY(THM, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, 0, <token> THM_BACO_CNTL__BACO_ANA_ISO_EN_MASK, THM_BACO_CNTL__BACO_ANA_ISO_EN__SHIFT, 0, 1}, <answer> mmTHM_BACO_CNTL), 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, <token> mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_SOC_REFCLK_OFF_MASK, THM_BACO_CNTL__BACO_SOC_REFCLK_OFF__SHIFT, 0, 1}, <answer> 0, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(NBIF, 0, mmBACO_CNTL), BACO_CNTL__BACO_POWER_OFF_MASK, <token> 0, 1}, <answer> BACO_CNTL__BACO_POWER_OFF__SHIFT, 
{CMD_DELAY_MS, 0, 0, 0, 0, 0, <token> 5, 0}, <answer> 0, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, 0, <token> THM_BACO_CNTL__BACO_RESET_EN_MASK, THM_BACO_CNTL__BACO_RESET_EN__SHIFT, 0, 1}, <answer> mmTHM_BACO_CNTL), 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), <token> THM_BACO_CNTL__BACO_PWROKRAW_CNTL__SHIFT, 0, 0}, <answer> THM_BACO_CNTL__BACO_PWROKRAW_CNTL_MASK, 
{CMD_WAITFOR, <token> 0, mmBACO_CNTL), BACO_CNTL__BACO_MODE_MASK, BACO_CNTL__BACO_MODE__SHIFT, 0xffffffff, 0x100} <answer> SOC15_REG_ENTRY(NBIF, 
static const struct soc15_baco_cmd_entry exit_baco_tbl[] = <token> <answer> { 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(NBIF, <token> mmBACO_CNTL), BACO_CNTL__BACO_POWER_OFF_MASK, BACO_CNTL__BACO_POWER_OFF__SHIFT, 0, 0}, <answer> 0, 
{CMD_DELAY_MS, 0, 0, 0, 0, 0, 0, 10, <token> <answer> 0}, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, <token> mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_SOC_REFCLK_OFF_MASK, THM_BACO_CNTL__BACO_SOC_REFCLK_OFF__SHIFT, 0, 0}, <answer> 0, 
<token> SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_ANA_ISO_EN_MASK, THM_BACO_CNTL__BACO_ANA_ISO_EN__SHIFT, 0, 0}, <answer> {CMD_READMODIFYWRITE, 
<token> SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_AEB_ISO_EN_MASK, THM_BACO_CNTL__BACO_AEB_ISO_EN__SHIFT, 0, 0}, <answer> {CMD_READMODIFYWRITE, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, <token> mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_ISO_EN_MASK, THM_BACO_CNTL__BACO_ISO_EN__SHIFT, 0, 0}, <answer> 0, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_PWROKRAW_CNTL_MASK, <token> 0, 1}, <answer> THM_BACO_CNTL__BACO_PWROKRAW_CNTL__SHIFT, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_SMNCLK_MUX_MASK, <token> 0, 0}, <answer> THM_BACO_CNTL__BACO_SMNCLK_MUX__SHIFT, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_SOC_VDCI_RESET_MASK, <token> 0, 0}, <answer> THM_BACO_CNTL__BACO_SOC_VDCI_RESET__SHIFT, 
{CMD_READMODIFYWRITE, <token> 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_EXIT_MASK, THM_BACO_CNTL__BACO_EXIT__SHIFT, 0, 1}, <answer> SOC15_REG_ENTRY(THM, 
<token> SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_RESET_EN_MASK, THM_BACO_CNTL__BACO_RESET_EN__SHIFT, 0, 0}, <answer> {CMD_READMODIFYWRITE, 
<token> SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_EXIT_MASK, 0, 0xffffffff, 0}, <answer> {CMD_WAITFOR, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(THM, 0, mmTHM_BACO_CNTL), THM_BACO_CNTL__BACO_SB_AXI_FENCE_MASK, THM_BACO_CNTL__BACO_SB_AXI_FENCE__SHIFT, 0, <token> <answer> 0}, 
{CMD_READMODIFYWRITE, <token> 0, mmBACO_CNTL), BACO_CNTL__BACO_DUMMY_EN_MASK, BACO_CNTL__BACO_DUMMY_EN__SHIFT, 0, 0}, <answer> SOC15_REG_ENTRY(NBIF, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(NBIF, <token> mmBACO_CNTL), BACO_CNTL__BACO_BIF_LCLK_SWITCH_MASK, BACO_CNTL__BACO_BIF_LCLK_SWITCH__SHIFT, 0, 0}, <answer> 0, 
{CMD_READMODIFYWRITE, SOC15_REG_ENTRY(NBIF, 0, mmBACO_CNTL), <token> BACO_CNTL__BACO_EN__SHIFT, 0, 0}, <answer> BACO_CNTL__BACO_EN_MASK, 
{CMD_WAITFOR, SOC15_REG_ENTRY(NBIF, 0, mmBACO_CNTL), <token> 0, 0xffffffff, 0} <answer> BACO_CNTL__BACO_MODE_MASK, 
<token> const struct soc15_baco_cmd_entry clean_baco_tbl[] = { <answer> static 
{CMD_WRITE, <token> 0, mmBIOS_SCRATCH_6), 0, 0, 0, 0}, <answer> SOC15_REG_ENTRY(NBIF, 
{CMD_WRITE, <token> 0, mmBIOS_SCRATCH_7), 0, 0, 0, 0}, <answer> SOC15_REG_ENTRY(NBIF, 
int <token> pp_hwmgr *hwmgr, enum BACO_STATE state) <answer> vega10_baco_set_state(struct 
<token> BACO_STATE cur_state; <answer> enum 
smu9_baco_get_state(hwmgr, <token> <answer> &cur_state); 
if (cur_state == <token> <answer> state) 
#define <token> KBUILD_MODNAME ": " fmt <answer> pr_fmt(fmt) 
#include <token> <answer> <linux/acpi.h> 
#include <token> <answer> <linux/dmi.h> 
<token> <linux/gpio/consumer.h> <answer> #include 
#include <token> <answer> <linux/gpio/machine.h> 
<token> <linux/irq.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/serdev.h> 
<token> <linux/string.h> <answer> #include 
<token> "x86-android-tablets.h" <answer> #include 
<token> "../serdev_helpers.h" <answer> #include 
<token> struct platform_device *x86_android_tablet_device; <answer> static 
int x86_android_tablet_get_gpiod(const char *chip, int pin, const char <token> <answer> *con_id, 
<token> active_low, enum gpiod_flags dflags, <answer> bool 
struct gpio_desc <token> <answer> **desc) 
struct <token> *lookup; <answer> gpiod_lookup_table 
struct <token> *gpiod; <answer> gpio_desc 
<token> = kzalloc(struct_size(lookup, table, 2), GFP_KERNEL); <answer> lookup 
<token> (!lookup) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = KBUILD_MODNAME; <answer> lookup->dev_id 
lookup->table[0].key <token> chip; <answer> = 
lookup->table[0].chip_hwnum = <token> <answer> pin; 
lookup->table[0].con_id <token> con_id; <answer> = 
lookup->table[0].flags = <token> ? GPIO_ACTIVE_LOW : GPIO_ACTIVE_HIGH; <answer> active_low 
<token> = devm_gpiod_get(&x86_android_tablet_device->dev, con_id, dflags); <answer> gpiod 
if <token> { <answer> (IS_ERR(gpiod)) 
pr_err("error %ld getting GPIO %s <token> PTR_ERR(gpiod), chip, pin); <answer> %d\n", 
<token> PTR_ERR(gpiod); <answer> return 
<token> (desc) <answer> if 
*desc = <token> <answer> gpiod; 
return <token> <answer> 0; 
<token> x86_acpi_irq_helper_get(const struct x86_acpi_irq_data *data) <answer> int 
<token> irq_fwspec fwspec = { }; <answer> struct 
struct <token> *domain; <answer> irq_domain 
struct <token> *adev; <answer> acpi_device 
struct <token> *gpiod; <answer> gpio_desc 
<token> int irq_type; <answer> unsigned 
<token> handle; <answer> acpi_handle 
<token> status; <answer> acpi_status 
int <token> ret; <answer> irq, 
switch <token> { <answer> (data->type) 
case <token> <answer> X86_ACPI_IRQ_TYPE_APIC: 
irq = acpi_register_gsi(NULL, <token> data->trigger, data->polarity); <answer> data->index, 
if (irq < <token> <answer> 0) 
pr_err("error %d getting APIC IRQ %d\n", irq, <token> <answer> data->index); 
return <token> <answer> irq; 
<token> X86_ACPI_IRQ_TYPE_GPIOINT: <answer> case 
for (i = 0; <token> && dev_info->modules[i]; i++) <answer> dev_info->modules 
<token> = dev_info->bat_swnode; <answer> bat_swnode 
if <token> { <answer> (bat_swnode) 
ret = <token> <answer> software_node_register(bat_swnode); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
<token> = dev_info->gpiod_lookup_tables; <answer> gpiod_lookup_tables 
for (i = 0; gpiod_lookup_tables && <token> i++) <answer> gpiod_lookup_tables[i]; 
<token> (dev_info->init) { <answer> if 
ret <token> dev_info->init(); <answer> = 
if (ret <token> 0) { <answer> < 
<token> ret; <answer> return 
exit_handler <token> dev_info->exit; <answer> = 
i2c_clients = <token> sizeof(*i2c_clients), GFP_KERNEL); <answer> kcalloc(dev_info->i2c_client_count, 
if (!i2c_clients) <token> <answer> { 
<token> -ENOMEM; <answer> return 
<token> = dev_info->i2c_client_count; <answer> i2c_client_count 
for (i <token> 0; i < i2c_client_count; i++) { <answer> = 
ret = <token> i); <answer> x86_instantiate_i2c_client(dev_info, 
<token> (ret < 0) { <answer> if 
<token> ret; <answer> return 
spi_devs = kcalloc(dev_info->spi_dev_count, sizeof(*spi_devs), <token> <answer> GFP_KERNEL); 
<token> (!spi_devs) { <answer> if 
<token> -ENOMEM; <answer> return 
spi_dev_count = <token> <answer> dev_info->spi_dev_count; 
for (i = 0; i < spi_dev_count; <token> { <answer> i++) 
<token> = x86_instantiate_spi_dev(dev_info, i); <answer> ret 
<token> (ret < 0) { <answer> if 
<token> ret; <answer> return 
#define pr_fmt(fmt) KBUILD_MODNAME ": " <token> <answer> fmt 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/input.h> <answer> #include 
<token> <linux/input/sparse-keymap.h> <answer> #include 
<token> <linux/acpi.h> <answer> #include 
#include <token> <answer> <linux/backlight.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/module.h> 
<token> <acpi/video.h> <answer> #include 
MODULE_AUTHOR("Thomas <token> <trenn@suse.de>"); <answer> Renninger 
MODULE_DESCRIPTION("MSI <token> WMI hotkeys driver"); <answer> laptop 
#define <token> "msi-wmi" <answer> DRV_NAME 
<token> MSIWMI_BIOS_GUID "551A1F84-FBDD-4125-91DB-3EA8F44F1D45" <answer> #define 
#define <token> "B6F3EEF2-3D2F-49DC-9DE3-85BCE18C62F2" <answer> MSIWMI_MSI_EVENT_GUID 
<token> MSIWMI_WIND_EVENT_GUID "5B3CC38A-40D9-7245-8AE6-1145B751BE3F" <answer> #define 
<token> MSIWMI_BIOS_GUID); <answer> MODULE_ALIAS("wmi:" 
<token> MSIWMI_MSI_EVENT_GUID); <answer> MODULE_ALIAS("wmi:" 
MODULE_ALIAS("wmi:" <token> <answer> MSIWMI_WIND_EVENT_GUID); 
enum msi_scancodes <token> <answer> { 
if (ktime_to_us(diff) <token> 1000 * 50) { <answer> < 
pr_debug("Suppressed key event 0x%X <token> " <answer> - 
"Last press was <token> us ago\n", <answer> %lld 
key->code, <token> <answer> ktime_to_us(diff)); 
<token> msi_wmi_notify_exit; <answer> goto 
<token> = cur; <answer> last_pressed 
if (key->type == <token> && <answer> KE_KEY 
<token> <linux/bpf.h> <answer> #include 
#include <token> <answer> <linux/filter.h> 
<token> <net/xdp_sock.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/sched.h> <answer> #include 
#include <token> <answer> <linux/btf_ids.h> 
<token> "xsk.h" <answer> #include 
static struct <token> *xsk_map_node_alloc(struct xsk_map *map, <answer> xsk_map_node 
struct <token> __rcu **map_entry) <answer> xdp_sock 
struct xsk_map_node <token> <answer> *node; 
node = <token> sizeof(*node), <answer> bpf_map_kzalloc(&map->map, 
GFP_ATOMIC | <token> <answer> __GFP_NOWARN); 
<token> (!node) <answer> if 
return <token> <answer> ERR_PTR(-ENOMEM); 
node->map <token> map; <answer> = 
<token> = map_entry; <answer> node->map_entry 
<token> node; <answer> return 
static <token> xsk_map_node_free(struct xsk_map_node *node) <answer> void 
struct xsk_map *map = <token> <answer> node->map; 
static void xsk_map_sock_add(struct <token> *xs, struct xsk_map_node *node) <answer> xdp_sock 
list_add_tail(&node->node, <token> <answer> &xs->map_list); 
<token> void xsk_map_sock_delete(struct xdp_sock *xs, <answer> static 
struct <token> __rcu **map_entry) <answer> xdp_sock 
struct xsk_map_node <token> *tmp; <answer> *n, 
list_for_each_entry_safe(n, tmp, <token> node) { <answer> &xs->map_list, 
if (map_entry == <token> { <answer> n->map_entry) 
static struct bpf_map *xsk_map_alloc(union bpf_attr <token> <answer> *attr) 
<token> xsk_map *m; <answer> struct 
int <token> <answer> numa_node; 
u64 <token> <answer> size; 
if (attr->max_entries == <token> || attr->key_size != 4 || <answer> 0 
<token> != 4 || <answer> attr->value_size 
<token> & ~(BPF_F_NUMA_NODE | BPF_F_RDONLY | BPF_F_WRONLY)) <answer> attr->map_flags 
<token> ERR_PTR(-EINVAL); <answer> return 
numa_node = <token> <answer> bpf_map_attr_numa_node(attr); 
size = struct_size(m, <token> attr->max_entries); <answer> xsk_map, 
m = <token> numa_node); <answer> bpf_map_area_alloc(size, 
if <token> <answer> (!m) 
<token> ERR_PTR(-ENOMEM); <answer> return 
bpf_map_init_from_attr(&m->map, <token> <answer> attr); 
<token> &m->map; <answer> return 
static u64 xsk_map_mem_usage(const struct <token> *map) <answer> bpf_map 
struct xsk_map *m = <token> struct xsk_map, map); <answer> container_of(map, 
return <token> xsk_map, map->max_entries) + <answer> struct_size(m, 
(u64)atomic_read(&m->count) <token> sizeof(struct xsk_map_node); <answer> * 
static void xsk_map_free(struct bpf_map <token> <answer> *map) 
struct xsk_map *m <token> container_of(map, struct xsk_map, map); <answer> = 
static int xsk_map_get_next_key(struct bpf_map *map, void *key, void <token> <answer> *next_key) 
struct <token> *m = container_of(map, struct xsk_map, map); <answer> xsk_map 
u32 <token> = key ? *(u32 *)key : U32_MAX; <answer> index 
u32 <token> = next_key; <answer> *next 
if (index >= m->map.max_entries) <token> <answer> { 
*next <token> 0; <answer> = 
<token> 0; <answer> return 
if (index == m->map.max_entries - <token> <answer> 1) 
return <token> <answer> -ENOENT; 
*next = index <token> 1; <answer> + 
<token> 0; <answer> return 
static int <token> bpf_map *map, struct bpf_insn *insn_buf) <answer> xsk_map_gen_lookup(struct 
const int ret = BPF_REG_0, mp = BPF_REG_1, index <token> BPF_REG_2; <answer> = 
<token> bpf_insn *insn = insn_buf; <answer> struct 
<token> = BPF_LDX_MEM(BPF_W, ret, index, 0); <answer> *insn++ 
*insn++ = BPF_JMP_IMM(BPF_JGE, ret, <token> 5); <answer> map->max_entries, 
*insn++ = BPF_ALU64_IMM(BPF_LSH, ret, <token> xsk_sock *))); <answer> ilog2(sizeof(struct 
*insn++ = BPF_ALU64_IMM(BPF_ADD, <token> offsetof(struct xsk_map, xsk_map)); <answer> mp, 
*insn++ = BPF_ALU64_REG(BPF_ADD, <token> mp); <answer> ret, 
*insn++ = BPF_LDX_MEM(BPF_SIZEOF(struct xsk_sock <token> ret, ret, 0); <answer> *), 
*insn++ = BPF_JMP_IMM(BPF_JA, <token> 0, 1); <answer> 0, 
*insn++ <token> BPF_MOV64_IMM(ret, 0); <answer> = 
<token> insn - insn_buf; <answer> return 
<token> void *__xsk_map_lookup_elem(struct bpf_map *map, u32 key) <answer> static 
struct xsk_map *m = container_of(map, struct <token> map); <answer> xsk_map, 
if (key >= <token> <answer> map->max_entries) 
<token> NULL; <answer> return 
return rcu_dereference_check(m->xsk_map[key], <token> <answer> rcu_read_lock_bh_held()); 
static void *xsk_map_lookup_elem(struct bpf_map *map, <token> *key) <answer> void 
<token> __xsk_map_lookup_elem(map, *(u32 *)key); <answer> return 
static void *xsk_map_lookup_elem_sys_only(struct bpf_map *map, <token> *key) <answer> void 
return <token> <answer> ERR_PTR(-EOPNOTSUPP); 
static <token> xsk_map_update_elem(struct bpf_map *map, void *key, void *value, <answer> long 
<token> map_flags) <answer> u64 
struct xsk_map *m = container_of(map, <token> xsk_map, map); <answer> struct 
struct xdp_sock __rcu <token> <answer> **map_entry; 
struct xdp_sock *xs, <token> <answer> *old_xs; 
u32 i = *(u32 *)key, fd = <token> *)value; <answer> *(u32 
struct xsk_map_node <token> <answer> *node; 
struct <token> *sock; <answer> socket 
<token> err; <answer> int 
if <token> > BPF_EXIST)) <answer> (unlikely(map_flags 
<token> -EINVAL; <answer> return 
if <token> >= m->map.max_entries)) <answer> (unlikely(i 
<token> -E2BIG; <answer> return 
sock = sockfd_lookup(fd, <token> <answer> &err); 
<token> (!sock) <answer> if 
return <token> <answer> err; 
<token> (sock->sk->sk_family != PF_XDP) { <answer> if 
return <token> <answer> -EOPNOTSUPP; 
<token> = (struct xdp_sock *)sock->sk; <answer> xs 
<token> = &m->xsk_map[i]; <answer> map_entry 
node = <token> map_entry); <answer> xsk_map_node_alloc(m, 
if <token> { <answer> (IS_ERR(node)) 
<token> PTR_ERR(node); <answer> return 
<token> = rcu_dereference_protected(*map_entry, lockdep_is_held(&m->lock)); <answer> old_xs 
if (old_xs == <token> { <answer> xs) 
err <token> 0; <answer> = 
goto <token> <answer> out; 
} else if <token> && map_flags == BPF_NOEXIST) { <answer> (old_xs 
err <token> -EEXIST; <answer> = 
goto <token> <answer> out; 
} else if (!old_xs && map_flags == <token> { <answer> BPF_EXIST) 
err <token> -ENOENT; <answer> = 
<token> out; <answer> goto 
<token> node); <answer> xsk_map_sock_add(xs, 
<token> xs); <answer> rcu_assign_pointer(*map_entry, 
if <token> <answer> (old_xs) 
xsk_map_sock_delete(old_xs, <token> <answer> map_entry); 
<token> 0; <answer> return 
<token> err; <answer> return 
<token> long xsk_map_delete_elem(struct bpf_map *map, void *key) <answer> static 
struct xsk_map *m = <token> struct xsk_map, map); <answer> container_of(map, 
struct xdp_sock <token> **map_entry; <answer> __rcu 
<token> xdp_sock *old_xs; <answer> struct 
<token> k = *(u32 *)key; <answer> int 
if (k <token> map->max_entries) <answer> >= 
return <token> <answer> -EINVAL; 
map_entry <token> &m->xsk_map[k]; <answer> = 
old_xs = <token> NULL)); <answer> unrcu_pointer(xchg(map_entry, 
if <token> <answer> (old_xs) 
xsk_map_sock_delete(old_xs, <token> <answer> map_entry); 
<token> 0; <answer> return 
static long xsk_map_redirect(struct bpf_map *map, u64 index, u64 <token> <answer> flags) 
return __bpf_xdp_redirect_map(map, index, flags, <token> <answer> 0, 
void xsk_map_try_sock_delete(struct xsk_map *map, struct <token> *xs, <answer> xdp_sock 
struct xdp_sock <token> **map_entry) <answer> __rcu 
if <token> == xs) { <answer> (rcu_access_pointer(*map_entry) 
<token> NULL); <answer> rcu_assign_pointer(*map_entry, 
<token> map_entry); <answer> xsk_map_sock_delete(xs, 
static bool <token> struct bpf_map *meta0, <answer> xsk_map_meta_equal(const 
const struct bpf_map <token> <answer> *meta1) 
return meta0->max_entries <token> meta1->max_entries && <answer> == 
<token> meta1); <answer> bpf_map_meta_equal(meta0, 
BTF_ID_LIST_SINGLE(xsk_map_btf_ids, struct, <token> <answer> xsk_map) 
const struct bpf_map_ops <token> = { <answer> xsk_map_ops 
.map_meta_equal = <token> <answer> xsk_map_meta_equal, 
.map_alloc = <token> <answer> xsk_map_alloc, 
.map_free <token> xsk_map_free, <answer> = 
.map_get_next_key <token> xsk_map_get_next_key, <answer> = 
<token> = xsk_map_lookup_elem, <answer> .map_lookup_elem 
.map_gen_lookup = <token> <answer> xsk_map_gen_lookup, 
.map_lookup_elem_sys_only = <token> <answer> xsk_map_lookup_elem_sys_only, 
.map_update_elem = <token> <answer> xsk_map_update_elem, 
<token> = xsk_map_delete_elem, <answer> .map_delete_elem 
.map_check_btf = <token> <answer> map_check_no_btf, 
.map_mem_usage = <token> <answer> xsk_map_mem_usage, 
.map_btf_id <token> &xsk_map_btf_ids[0], <answer> = 
<token> = xsk_map_redirect, <answer> .map_redirect 
<token> <linux/bitfield.h> <answer> #include 
#include <token> <answer> "rvu.h" 
static void <token> rvu *rvu, u16 pcifunc, bool enable) <answer> rvu_switch_enable_lbk_link(struct 
<token> rvu_pfvf *pfvf = rvu_get_pfvf(rvu, pcifunc); <answer> struct 
struct nix_hw <token> <answer> *nix_hw; 
nix_hw <token> get_nix_hw(rvu->hw, pfvf->nix_blkaddr); <answer> = 
if (!test_bit(NIXLF_INITIALIZED, <token> <answer> &pfvf->flags)) 
<token> 0; <answer> return 
<token> pfvf->mac_addr); <answer> ether_addr_copy(req.packet.dmac, 
eth_broadcast_addr((u8 <token> <answer> *)&req.mask.dmac); 
if (!test_bit(NIXLF_INITIALIZED, <token> <answer> &pfvf->flags)) 
return <token> <answer> 0; 
rvu_switch_enable_lbk_link(rvu, pcifunc, <token> <answer> true); 
lbkid = pfvf->nix_blkaddr == BLKADDR_NIX0 <token> 0 : 1; <answer> ? 
ether_addr_copy(req.packet.dmac, <token> <answer> pfvf->mac_addr); 
<token> *)&req.mask.dmac); <answer> eth_broadcast_addr((u8 
rvu_get_nix_blkaddr(rvu, <token> <answer> pcifunc); 
err = rvu_switch_install_rx_rule(rvu, pcifunc, <token> <answer> 0x0); 
if (err) <token> <answer> { 
dev_err(rvu->dev, "RX rule <token> PF%d failed(%d)\n", <answer> for 
pf, <token> <answer> err); 
<token> err; <answer> return 
err = rvu_switch_install_tx_rule(rvu, pcifunc, start <token> entry); <answer> + 
if <token> { <answer> (err) 
dev_err(rvu->dev, "TX rule for <token> failed(%d)\n", <answer> PF%d 
<token> err); <answer> pf, 
return <token> <answer> err; 
rswitch->entry2pcifunc[entry++] <token> pcifunc; <answer> = 
rvu_get_pf_numvfs(rvu, pf, &numvfs, <token> <answer> NULL); 
for (vf = 0; vf < numvfs; <token> { <answer> vf++) 
pcifunc = pf << 10 | ((vf + <token> & 0x3FF); <answer> 1) 
<token> pcifunc); <answer> rvu_get_nix_blkaddr(rvu, 
err = rvu_switch_install_rx_rule(rvu, <token> 0x0); <answer> pcifunc, 
if <token> { <answer> (err) 
"RX <token> for PF%dVF%d failed(%d)\n", <answer> rule 
pf, <token> err); <answer> vf, 
return <token> <answer> err; 
<token> = rvu_switch_install_tx_rule(rvu, pcifunc, <answer> err 
start + <token> <answer> entry); 
if <token> { <answer> (err) 
"TX <token> for PF%dVF%d failed(%d)\n", <answer> rule 
<token> vf, err); <answer> pf, 
<token> err; <answer> return 
rswitch->entry2pcifunc[entry++] = <token> <answer> pcifunc; 
<token> 0; <answer> return 
void <token> rvu *rvu) <answer> rvu_switch_enable(struct 
struct <token> alloc_req = { 0 }; <answer> npc_mcam_alloc_entry_req 
struct npc_mcam_alloc_entry_rsp <token> = { 0 }; <answer> alloc_rsp 
struct npc_delete_flow_req uninstall_req = <token> 0 }; <answer> { 
struct npc_delete_flow_rsp uninstall_rsp = { 0 <token> <answer> }; 
struct <token> free_req = { 0 }; <answer> npc_mcam_free_entry_req 
<token> rvu_switch *rswitch = &rvu->rswitch; <answer> struct 
struct <token> rsp; <answer> msg_rsp 
int <token> <answer> ret; 
<token> = true; <answer> alloc_req.contig 
alloc_req.count = rvu->cgx_mapped_pfs + <token> <answer> rvu->cgx_mapped_vfs; 
ret = <token> &alloc_req, <answer> rvu_mbox_handler_npc_mcam_alloc_entry(rvu, 
<token> (ret) { <answer> if 
"Unable to allocate MCAM <token> <answer> entries\n"); 
goto <token> <answer> exit; 
if (alloc_rsp.count != alloc_req.count) <token> <answer> { 
"Unable to allocate <token> MCAM entries, got %d\n", <answer> %d 
<token> alloc_rsp.count); <answer> alloc_req.count, 
goto <token> <answer> free_entries; 
<token> = kcalloc(alloc_req.count, sizeof(u16), <answer> rswitch->entry2pcifunc 
if <token> <answer> (!rswitch->entry2pcifunc) 
<token> free_entries; <answer> goto 
rswitch->used_entries = <token> <answer> alloc_rsp.count; 
rswitch->start_entry <token> alloc_rsp.entry; <answer> = 
<token> = rvu_switch_install_rules(rvu); <answer> ret 
if <token> <answer> (ret) 
goto <token> <answer> uninstall_rules; 
<token> = rswitch->start_entry; <answer> uninstall_req.start 
uninstall_req.end = rswitch->start_entry + rswitch->used_entries <token> 1; <answer> - 
<token> &uninstall_req, &uninstall_rsp); <answer> rvu_mbox_handler_npc_delete_flow(rvu, 
free_req.all = <token> <answer> 1; 
rvu_mbox_handler_npc_mcam_free_entry(rvu, <token> &rsp); <answer> &free_req, 
void rvu_switch_disable(struct rvu <token> <answer> *rvu) 
struct npc_delete_flow_req uninstall_req = <token> 0 }; <answer> { 
struct npc_delete_flow_rsp <token> = { 0 }; <answer> uninstall_rsp 
struct npc_mcam_free_entry_req free_req = <token> 0 }; <answer> { 
struct rvu_switch *rswitch <token> &rvu->rswitch; <answer> = 
struct <token> *hw = rvu->hw; <answer> rvu_hwinfo 
int <token> vf, numvfs; <answer> pf, 
struct msg_rsp <token> <answer> rsp; 
u16 <token> <answer> pcifunc; 
<token> err; <answer> int 
if <token> <answer> (!rswitch->used_entries) 
for <token> = 1; pf < hw->total_pfs; pf++) { <answer> (pf 
<token> (!is_pf_cgxmapped(rvu, pf)) <answer> if 
pcifunc <token> pf << 10; <answer> = 
err = rvu_switch_install_rx_rule(rvu, <token> 0xFFF); <answer> pcifunc, 
<token> (err) <answer> if 
"Reverting RX rule for PF%d <token> <answer> failed(%d)\n", 
pf, <token> <answer> err); 
#define pr_fmt(fmt) KBUILD_MODNAME ": " <token> <answer> fmt 
<token> <linux/i2c.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/videodev2.h> 
#include <token> <answer> "tuner-i2c.h" 
#include <token> <answer> "tea5767.h" 
<token> int debug; <answer> static 
module_param(debug, <token> 0644); <answer> int, 
<token> "enable verbose debug messages"); <answer> MODULE_PARM_DESC(debug, 
if (((buffer[3] & <token> != 0x00) || (buffer[4] != 0x00)) { <answer> 0x0f) 
pr_warn("Chip ID <token> not zero. It is not a TEA5767\n"); <answer> is 
return <token> <answer> -EINVAL; 
<token> 0; <answer> return 
static void tea5767_release(struct dvb_frontend <token> <answer> *fe) 
<token> = NULL; <answer> fe->tuner_priv 
static int tea5767_get_frequency(struct dvb_frontend *fe, <token> *frequency) <answer> u32 
struct tea5767_priv *priv = <token> <answer> fe->tuner_priv; 
<token> = priv->frequency; <answer> *frequency 
<token> 0; <answer> return 
static int tea5767_set_config (struct dvb_frontend *fe, void <token> <answer> *priv_cfg) 
<token> tea5767_priv *priv = fe->tuner_priv; <answer> struct 
<token> priv_cfg, sizeof(priv->ctrl)); <answer> memcpy(&priv->ctrl, 
return <token> <answer> 0; 
static <token> struct dvb_tuner_ops tea5767_tuner_ops = { <answer> const 
.info <token> { <answer> = 
.name <token> "tea5767", <answer> = 
<token> = set_radio_freq, <answer> .set_analog_params 
.set_config <token> tea5767_set_config, <answer> = 
.sleep = <token> <answer> tea5767_standby, 
<token> = tea5767_release, <answer> .release 
<token> = tea5767_get_frequency, <answer> .get_frequency 
.get_status <token> tea5767_get_status, <answer> = 
.get_rf_strength <token> tea5767_get_rf_strength, <answer> = 
struct <token> *tea5767_attach(struct dvb_frontend *fe, <answer> dvb_frontend 
struct <token> i2c_adap, <answer> i2c_adapter* 
<token> i2c_addr) <answer> u8 
struct tea5767_priv *priv = <token> <answer> NULL; 
<token> = kzalloc(sizeof(struct tea5767_priv), GFP_KERNEL); <answer> priv 
<token> (priv == NULL) <answer> if 
return <token> <answer> NULL; 
<token> = priv; <answer> fe->tuner_priv 
<token> = i2c_addr; <answer> priv->i2c_props.addr 
<token> = i2c_adap; <answer> priv->i2c_props.adap 
priv->i2c_props.name <token> "tea5767"; <answer> = 
<token> = TEA5767_HIGH_LO_32768; <answer> priv->ctrl.xtal_freq 
priv->ctrl.port1 = <token> <answer> 1; 
<token> = 1; <answer> priv->ctrl.port2 
priv->ctrl.high_cut <token> 1; <answer> = 
priv->ctrl.st_noise <token> 1; <answer> = 
priv->ctrl.japan_band <token> 1; <answer> = 
memcpy(&fe->ops.tuner_ops, <token> <answer> &tea5767_tuner_ops, 
sizeof(struct <token> <answer> dvb_tuner_ops)); 
tuner_info("type set to %s\n", "Philips TEA5767HN <token> Radio"); <answer> FM 
<token> fe; <answer> return 
<token> TEA5767 FM tuner driver"); <answer> MODULE_DESCRIPTION("Philips 
MODULE_AUTHOR("Mauro Carvalho <token> <mchehab@kernel.org>"); <answer> Chehab 
MODULE_LICENSE("GPL <token> <answer> v2"); 
#include <token> <answer> <linux/ctype.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/types.h> 
<token> <linux/string.h> <answer> #include 
#ifndef <token> <answer> EFI_HAVE_STRLEN 
size_t strlen(const char <token> <answer> *s) 
<token> char *sc; <answer> const 
for (sc = s; <token> != '\0'; ++sc) <answer> *sc 
size_t strnlen(const char *s, size_t <token> <answer> count) 
<token> char *sc; <answer> const 
for (sc = s; count-- && *sc <token> '\0'; ++sc) <answer> != 
char <token> char *s1, const char *s2) <answer> *strstr(const 
<token> l1, l2; <answer> size_t 
l2 = <token> <answer> strlen(s2); 
if <token> <answer> (!l2) 
return (char <token> <answer> *)s1; 
l1 <token> strlen(s1); <answer> = 
while (l1 >= l2) <token> <answer> { 
if (!memcmp(s1, s2, <token> <answer> l2)) 
return <token> *)s1; <answer> (char 
return <token> <answer> NULL; 
#ifndef <token> <answer> EFI_HAVE_STRCMP 
int strcmp(const char *cs, <token> char *ct) <answer> const 
unsigned char c1, <token> <answer> c2; 
while (1) <token> <answer> { 
<token> = *cs++; <answer> c1 
c2 = <token> <answer> *ct++; 
<token> (c1 != c2) <answer> if 
return c1 < c2 <token> -1 : 1; <answer> ? 
if <token> <answer> (!c1) 
return <token> <answer> 0; 
int strncmp(const char *cs, const char *ct, size_t <token> <answer> count) 
<token> char c1, c2; <answer> unsigned 
<token> (count) { <answer> while 
c1 <token> *cs++; <answer> = 
c2 = <token> <answer> *ct++; 
if <token> != c2) <answer> (c1 
return <token> < c2 ? -1 : 1; <answer> c1 
<token> (!c1) <answer> if 
return <token> <answer> 0; 
unsigned long long simple_strtoull(const char <token> char **endp, unsigned int base) <answer> *cp, 
unsigned <token> long result = 0; <answer> long 
<token> (!base) <answer> if 
base <token> simple_guess_base(cp); <answer> = 
if (base == 16 <token> cp[0] == '0' && TOLOWER(cp[1]) == 'x') <answer> && 
<token> += 2; <answer> cp 
<token> (isxdigit(*cp)) { <answer> while 
unsigned int <token> <answer> value; 
value = isdigit(*cp) ? *cp - '0' : <token> - 'a' + 10; <answer> TOLOWER(*cp) 
if (value <token> base) <answer> >= 
<token> = result * base + value; <answer> result 
<token> (endp) <answer> if 
*endp = <token> *)cp; <answer> (char 
<token> result; <answer> return 
<token> simple_strtol(const char *cp, char **endp, unsigned int base) <answer> long 
<token> (*cp == '-') <answer> if 
return -simple_strtoull(cp + 1, <token> base); <answer> endp, 
return simple_strtoull(cp, <token> base); <answer> endp, 
#ifdef <token> <answer> CONFIG_EFI_PARAMS_FROM_FDT 
#ifndef <token> <answer> EFI_HAVE_STRRCHR 
char *strrchr(const <token> *s, int c) <answer> char 
const char <token> = NULL; <answer> *last 
do <token> <answer> { 
<token> (*s == (char)c) <answer> if 
last = <token> <answer> s; 
<token> while (*s++); <answer> } 
<token> (char *)last; <answer> return 
<token> EFI_HAVE_MEMCHR <answer> #ifndef 
void *memchr(const <token> *s, int c, size_t n) <answer> void 
const unsigned char <token> = s; <answer> *p 
while (n-- != 0) <token> <answer> { 
if ((unsigned char)c == <token> { <answer> *p++) 
return <token> *)(p - 1); <answer> (void 
<token> NULL; <answer> return 
#include <token> <answer> <errno.h> 
#include <token> <answer> <unistd.h> 
#include <token> <answer> <stdio.h> 
<token> <string.h> <answer> #include 
#include <token> <answer> <sys/types.h> 
#include <token> <answer> <sys/stat.h> 
<token> <fcntl.h> <answer> #include 
#include <token> <answer> <stdlib.h> 
#include <token> <answer> <linux/kernel.h> 
<token> "vdso.h" <answer> #include 
#include <token> <answer> "dso.h" 
#include <token> <answer> <internal/lib.h> 
#include <token> <answer> "map.h" 
#include <token> <answer> "symbol.h" 
<token> "machine.h" <answer> #include 
<token> "thread.h" <answer> #include 
<token> "linux/string.h" <answer> #include 
<token> <linux/zalloc.h> <answer> #include 
#include <token> <answer> "debug.h" 
#include <token> <answer> "find-map.c" 
#define VDSO__TEMP_FILE_NAME <token> <answer> "/tmp/perf-vdso.so-XXXXXX" 
struct vdso_file <token> <answer> { 
<token> found; <answer> bool 
bool <token> <answer> error; 
char <token> <answer> temp_file_name[sizeof(VDSO__TEMP_FILE_NAME)]; 
const char <token> <answer> *dso_name; 
<token> char *read_prog; <answer> const 
struct vdso_info <token> <answer> { 
struct <token> vdso; <answer> vdso_file 
#if <token> == 64 <answer> BITS_PER_LONG 
struct <token> vdso32; <answer> vdso_file 
struct vdso_file <token> <answer> vdsox32; 
<token> struct vdso_info *vdso_info__new(void) <answer> static 
static const struct vdso_info vdso_info_init = <token> <answer> { 
<token> = { <answer> .vdso 
.temp_file_name = <token> <answer> VDSO__TEMP_FILE_NAME, 
.dso_name = <token> <answer> DSO__NAME_VDSO, 
#if BITS_PER_LONG <token> 64 <answer> == 
.vdso32 = <token> <answer> { 
.temp_file_name <token> VDSO__TEMP_FILE_NAME, <answer> = 
.dso_name <token> DSO__NAME_VDSO32, <answer> = 
.read_prog <token> "perf-read-vdso32", <answer> = 
<token> = { <answer> .vdsox32 
.temp_file_name = <token> <answer> VDSO__TEMP_FILE_NAME, 
.dso_name <token> DSO__NAME_VDSOX32, <answer> = 
.read_prog = <token> <answer> "perf-read-vdsox32", 
return <token> sizeof(vdso_info_init)); <answer> memdup(&vdso_info_init, 
static char *get_file(struct <token> *vdso_file) <answer> vdso_file 
<token> *vdso = NULL; <answer> char 
char <token> = NULL; <answer> *buf 
void <token> *end; <answer> *start, 
size_t <token> <answer> size; 
int <token> <answer> fd; 
<token> (vdso_file->found) <answer> if 
<token> vdso_file->temp_file_name; <answer> return 
if (vdso_file->error || <token> &end, VDSO__MAP_NAME)) <answer> find_map(&start, 
<token> NULL; <answer> return 
size = <token> - start; <answer> end 
buf <token> memdup(start, size); <answer> = 
<token> (!buf) <answer> if 
<token> NULL; <answer> return 
fd = <token> <answer> mkstemp(vdso_file->temp_file_name); 
if <token> < 0) <answer> (fd 
<token> out; <answer> goto 
if <token> == (size_t) write(fd, buf, size)) <answer> (size 
<token> = vdso_file->temp_file_name; <answer> vdso 
vdso_file->found <token> (vdso != NULL); <answer> = 
vdso_file->error = <token> <answer> !vdso_file->found; 
return <token> <answer> vdso; 
void machine__exit_vdso(struct machine <token> <answer> *machine) 
<token> vdso_info *vdso_info = machine->vdso_info; <answer> struct 
<token> (!vdso_info) <answer> if 
if <token> <answer> (vdso_info->vdso.found) 
#if BITS_PER_LONG == <token> <answer> 64 
if <token> <answer> (vdso_info->vdso32.found) 
if <token> <answer> (vdso_info->vdsox32.found) 
static struct dso *__machine__addnew_vdso(struct machine <token> const char *short_name, <answer> *machine, 
const <token> *long_name) <answer> char 
<token> dso *dso; <answer> struct 
dso <token> dso__new(short_name); <answer> = 
if (dso != NULL) <token> <answer> { 
<token> dso); <answer> __dsos__add(&machine->dsos, 
dso__set_long_name(dso, long_name, <token> <answer> false); 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> "../vdec_drv_if.h" 
<token> "../mtk_vcodec_dec.h" <answer> #include 
<token> "../../common/mtk_vcodec_intr.h" <answer> #include 
<token> "../vdec_vpu_if.h" <answer> #include 
#include <token> <answer> "../vdec_drv_base.h" 
<token> vdec_vp8_dec_info { <answer> struct 
uint64_t <token> <answer> working_buf_dma; 
uint64_t <token> <answer> prev_y_dma; 
uint64_t <token> <answer> cur_y_fb_dma; 
uint64_t <token> <answer> cur_c_fb_dma; 
uint64_t <token> <answer> bs_dma; 
<token> bs_sz; <answer> uint32_t 
uint32_t <token> <answer> resolution_changed; 
<token> show_frame; <answer> uint32_t 
<token> wait_key_frame; <answer> uint32_t 
struct <token> { <answer> vdec_vp8_vsi 
<token> vdec_vp8_dec_info dec; <answer> struct 
<token> vdec_pic_info pic; <answer> struct 
<token> dec_table[VP8_DEC_TABLE_SZ]; <answer> uint32_t 
uint32_t <token> <answer> segment_buf[VP8_HW_SEGMENT_DATA_SZ][VP8_HW_SEGMENT_UINT]; 
uint32_t <token> <answer> load_data; 
struct <token> { <answer> vdec_vp8_hw_reg_base 
void __iomem <token> <answer> *misc; 
void __iomem <token> <answer> *ld; 
void __iomem <token> <answer> *top; 
void <token> *cm; <answer> __iomem 
<token> __iomem *hwd; <answer> void 
<token> __iomem *hwb; <answer> void 
struct vdec_vp8_vpu_inst <token> <answer> { 
<token> wq_hd; <answer> wait_queue_head_t 
int <token> <answer> signaled; 
<token> failure; <answer> int 
<token> inst_addr; <answer> uint32_t 
struct vdec_vp8_inst <token> <answer> { 
struct <token> *cur_fb; <answer> vdec_fb 
<token> vdec_fb_node dec_fb[VP8_MAX_FRM_BUF_NODE_NUM]; <answer> struct 
<token> list_head available_fb_node_list; <answer> struct 
<token> list_head fb_use_list; <answer> struct 
<token> list_head fb_free_list; <answer> struct 
<token> list_head fb_disp_list; <answer> struct 
struct mtk_vcodec_mem <token> <answer> working_buf; 
struct <token> reg_base; <answer> vdec_vp8_hw_reg_base 
unsigned int <token> <answer> frm_cnt; 
struct mtk_vcodec_dec_ctx <token> <answer> *ctx; 
struct <token> vpu; <answer> vdec_vpu_inst 
<token> vdec_vp8_vsi *vsi; <answer> struct 
static void get_hw_reg_base(struct vdec_vp8_inst <token> <answer> *inst) 
<token> __iomem **reg_base = inst->ctx->dev->reg_base; <answer> void 
<token> = mtk_vcodec_get_reg_addr(reg_base, VDEC_TOP); <answer> inst->reg_base.top 
inst->reg_base.cm = <token> VDEC_CM); <answer> mtk_vcodec_get_reg_addr(reg_base, 
inst->reg_base.hwd = mtk_vcodec_get_reg_addr(reg_base, <token> <answer> VDEC_HWD); 
inst->reg_base.misc = <token> VDEC_MISC); <answer> mtk_vcodec_get_reg_addr(reg_base, 
inst->reg_base.ld <token> mtk_vcodec_get_reg_addr(reg_base, VDEC_LD); <answer> = 
<token> = mtk_vcodec_get_reg_addr(reg_base, VDEC_HWB); <answer> inst->reg_base.hwb 
static void write_hw_segmentation_data(struct <token> *inst) <answer> vdec_vp8_inst 
int <token> j; <answer> i, 
<token> seg_id_addr; <answer> u32 
u32 <token> <answer> val; 
void __iomem *cm <token> inst->reg_base.cm; <answer> = 
<token> vdec_vp8_vsi *vsi = inst->vsi; <answer> struct 
seg_id_addr = readl(inst->reg_base.top + VP8_SEGID_DRAM_ADDR) >> <token> <answer> 4; 
for (i <token> 0; i < ARRAY_SIZE(vsi->segment_buf); i++) { <answer> = 
for (j = ARRAY_SIZE(vsi->segment_buf[i]) - <token> j >= 0; j--) { <answer> 1; 
val = <token> << 16) + ((seg_id_addr + i) << 2) + j; <answer> (1 
writel(val, <token> + VP8_HW_VLD_ADDR); <answer> cm 
val = <token> <answer> vsi->segment_buf[i][j]; 
writel(val, <token> + VP8_HW_VLD_VALUE); <answer> cm 
static void read_hw_segmentation_data(struct vdec_vp8_inst <token> <answer> *inst) 
int i, <token> <answer> j; 
u32 <token> <answer> seg_id_addr; 
<token> val; <answer> u32 
void __iomem <token> = inst->reg_base.cm; <answer> *cm 
struct vdec_vp8_vsi *vsi <token> inst->vsi; <answer> = 
seg_id_addr = readl(inst->reg_base.top <token> VP8_SEGID_DRAM_ADDR) >> 4; <answer> + 
for (i <token> 0; i < ARRAY_SIZE(vsi->segment_buf); i++) { <answer> = 
for (j = ARRAY_SIZE(vsi->segment_buf[i]) - <token> j >= 0; j--) { <answer> 1; 
<token> = ((seg_id_addr + i) << 2) + j; <answer> val 
writel(val, <token> + VP8_HW_VLD_ADDR); <answer> cm 
val <token> readl(cm + VP8_HW_VLD_VALUE); <answer> = 
vsi->segment_buf[i][j] <token> val; <answer> = 
<token> <linux/clk.h> <answer> #include 
<token> <linux/clk/sunxi-ng.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
<token> <linux/device.h> <answer> #include 
<token> <linux/dma-mapping.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/mmc/card.h> 
<token> <linux/mmc/core.h> <answer> #include 
<token> <linux/mmc/host.h> <answer> #include 
#include <token> <answer> <linux/mmc/mmc.h> 
<token> <linux/mmc/sd.h> <answer> #include 
<token> <linux/mmc/sdio.h> <answer> #include 
#include <token> <answer> <linux/mmc/slot-gpio.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/mod_devicetable.h> 
<token> <linux/of_address.h> <answer> #include 
<token> <linux/of_platform.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/pm_runtime.h> 
#include <token> <answer> <linux/regulator/consumer.h> 
#include <token> <answer> <linux/reset.h> 
<token> <linux/scatterlist.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/spinlock.h> <answer> #include 
<token> needs_new_timings; <answer> bool 
mmc_writel(host, REG_FTRGL, <token> <answer> 0x20070008); 
static int <token> sunxi_mmc_host *host, <answer> sunxi_mmc_map_dma(struct 
struct <token> *data) <answer> mmc_data 
u32 i, <token> <answer> dma_len; 
struct scatterlist <token> <answer> *sg; 
dma_len = dma_map_sg(mmc_dev(host->mmc), data->sg, <token> <answer> data->sg_len, 
if (dma_len == 0) <token> <answer> { 
<token> "dma_map_sg failed\n"); <answer> dev_err(mmc_dev(host->mmc), 
<token> -ENOMEM; <answer> return 
<token> sg, data->sg_len, i) { <answer> for_each_sg(data->sg, 
if (sg->offset & <token> || sg->length & 3) { <answer> 3 
"unaligned scatterlist: os <token> length %d\n", <answer> %x 
sg->offset, <token> <answer> sg->length); 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
static void <token> sunxi_mmc_host *host, <answer> sunxi_mmc_start_dma(struct 
<token> mmc_data *data) <answer> struct 
<token> rval; <answer> u32 
<token> data); <answer> sunxi_mmc_init_idma_des(host, 
rval <token> mmc_readl(host, REG_GCTRL); <answer> = 
<token> |= SDXC_DMA_ENABLE_BIT; <answer> rval 
<token> REG_GCTRL, rval); <answer> mmc_writel(host, 
<token> |= SDXC_DMA_RESET; <answer> rval 
mmc_writel(host, <token> rval); <answer> REG_GCTRL, 
mmc_writel(host, REG_DMAC, <token> <answer> SDXC_IDMAC_SOFT_RESET); 
if (!(data->flags <token> MMC_DATA_WRITE)) <answer> & 
mmc_writel(host, REG_IDIE, <token> <answer> SDXC_IDMAC_RECEIVE_INTERRUPT); 
<token> REG_DMAC, <answer> mmc_writel(host, 
<token> | SDXC_IDMAC_IDMA_ON); <answer> SDXC_IDMAC_FIX_BURST 
static void sunxi_mmc_send_manual_stop(struct <token> *host, <answer> sunxi_mmc_host 
<token> mmc_request *req) <answer> struct 
u32 arg, cmd_val, <token> <answer> ri; 
unsigned long expire <token> jiffies + msecs_to_jiffies(1000); <answer> = 
<token> = SDXC_START | SDXC_RESP_EXPIRE | <answer> cmd_val 
SDXC_STOP_ABORT_CMD <token> SDXC_CHECK_RESPONSE_CRC; <answer> | 
if (req->cmd->opcode <token> SD_IO_RW_EXTENDED) { <answer> == 
<token> |= SD_IO_RW_DIRECT; <answer> cmd_val 
arg = (1 << 31) | (0 << 28) | (SDIO_CCCR_ABORT << 9) <token> <answer> | 
<token> >> 28) & 0x7); <answer> ((req->cmd->arg 
} <token> { <answer> else 
cmd_val |= <token> <answer> MMC_STOP_TRANSMISSION; 
arg <token> 0; <answer> = 
<token> REG_CARG, arg); <answer> mmc_writel(host, 
mmc_writel(host, REG_CMDR, <token> <answer> cmd_val); 
do <token> <answer> { 
ri = <token> REG_RINTR); <answer> mmc_readl(host, 
} <token> (!(ri & (SDXC_COMMAND_DONE | SDXC_INTERRUPT_ERROR_BIT)) && <answer> while 
time_before(jiffies, <token> <answer> expire)); 
if (!(ri & SDXC_COMMAND_DONE) || (ri <token> SDXC_INTERRUPT_ERROR_BIT)) { <answer> & 
dev_err(mmc_dev(host->mmc), "send stop command <token> <answer> failed\n"); 
<token> (req->stop) <answer> if 
req->stop->resp[0] <token> -ETIMEDOUT; <answer> = 
} <token> { <answer> else 
if <token> <answer> (req->stop) 
req->stop->resp[0] = mmc_readl(host, <token> <answer> REG_RESP0); 
mmc_writel(host, REG_RINTR, <token> <answer> 0xffff); 
static void <token> sunxi_mmc_host *host) <answer> sunxi_mmc_dump_errinfo(struct 
struct <token> *cmd = host->mrq->cmd; <answer> mmc_command 
struct mmc_data *data = <token> <answer> host->mrq->data; 
<token> mrq); <answer> sunxi_mmc_send_manual_stop(host, 
<token> iflags); <answer> spin_lock_irqsave(&host->lock, 
host->manual_stop_mrq = <token> <answer> NULL; 
spin_unlock_irqrestore(&host->lock, <token> <answer> iflags); 
<token> mrq); <answer> mmc_request_done(host->mmc, 
return <token> <answer> IRQ_HANDLED; 
static int sunxi_mmc_oclk_onoff(struct <token> *host, u32 oclk_en) <answer> sunxi_mmc_host 
unsigned long expire = jiffies + <token> <answer> msecs_to_jiffies(750); 
u32 <token> <answer> rval; 
dev_dbg(mmc_dev(host->mmc), "%sabling <token> clock\n", <answer> the 
<token> ? "en" : "dis"); <answer> oclk_en 
rval = mmc_readl(host, <token> <answer> REG_CLKCR); 
rval &= ~(SDXC_CARD_CLOCK_ON <token> SDXC_LOW_POWER_ON | SDXC_MASK_DATA0); <answer> | 
if <token> <answer> (oclk_en) 
rval <token> SDXC_CARD_CLOCK_ON; <answer> |= 
<token> (host->cfg->mask_data0) <answer> if 
rval <token> SDXC_MASK_DATA0; <answer> |= 
mmc_writel(host, <token> rval); <answer> REG_CLKCR, 
rval = SDXC_START | SDXC_UPCLK_ONLY <token> SDXC_WAIT_PRE_OVER; <answer> | 
mmc_writel(host, <token> rval); <answer> REG_CMDR, 
<token> { <answer> do 
rval = mmc_readl(host, <token> <answer> REG_CMDR); 
} <token> (time_before(jiffies, expire) && (rval & SDXC_START)); <answer> while 
writel(SDXC_CAL_DL_SW_EN, host->reg_base <token> reg_off); <answer> + 
<token> 0; <answer> return 
static int <token> sunxi_mmc_host *host, <answer> sunxi_mmc_clk_set_phase(struct 
struct mmc_ios *ios, u32 <token> <answer> rate) 
int <token> <answer> index; 
if <token> == MMC_TIMING_MMC_DDR52 && <answer> (ios->timing 
(host->use_new_timings <token> <answer> || 
<token> == MMC_BUS_WIDTH_8)) { <answer> ios->bus_width 
div <token> 2; <answer> = 
clock <<= <token> <answer> 1; 
if <token> && host->cfg->ccu_has_timings_switch) { <answer> (host->use_new_timings 
ret <token> sunxi_ccu_set_mmc_timing_mode(host->clk_mmc, true); <answer> = 
if <token> { <answer> (ret) 
"error setting new timing <token> <answer> mode\n"); 
<token> ret; <answer> return 
<token> = clk_round_rate(host->clk_mmc, clock); <answer> rate 
<token> (rate < 0) { <answer> if 
dev_err(mmc_dev(mmc), "error rounding <token> to %d: %ld\n", <answer> clk 
<token> rate); <answer> clock, 
<token> rate; <answer> return 
dev_dbg(mmc_dev(mmc), "setting clk to <token> rounded %ld\n", <answer> %d, 
<token> rate); <answer> clock, 
<token> (host->use_new_timings) { <answer> if 
ret <token> sunxi_mmc_oclk_onoff(host, 1); <answer> = 
<token> (ret) <answer> if 
return <token> <answer> ret; 
ret = <token> <answer> sunxi_mmc_reset_host(host); 
<token> (ret) <answer> if 
<token> error_disable_clk_sample; <answer> goto 
return <token> <answer> 0; 
<token> (!IS_ERR(host->reset)) <answer> if 
<token> ret; <answer> return 
static <token> sunxi_mmc_disable(struct sunxi_mmc_host *host) <answer> void 
<token> (!IS_ERR(host->reset)) <answer> if 
<token> int sunxi_mmc_resource_request(struct sunxi_mmc_host *host, <answer> static 
struct platform_device <token> <answer> *pdev) 
int <token> <answer> ret; 
<token> = of_device_get_match_data(&pdev->dev); <answer> host->cfg 
<token> (!host->cfg) <answer> if 
<token> -EINVAL; <answer> return 
ret <token> mmc_regulator_get_supply(host->mmc); <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
host->reg_base <token> devm_platform_ioremap_resource(pdev, 0); <answer> = 
<token> (IS_ERR(host->reg_base)) <answer> if 
<token> PTR_ERR(host->reg_base); <answer> return 
<token> = devm_clk_get(&pdev->dev, "ahb"); <answer> host->clk_ahb 
<token> (IS_ERR(host->clk_ahb)) { <answer> if 
dev_err(&pdev->dev, <token> not get ahb clock\n"); <answer> "Could 
return <token> <answer> PTR_ERR(host->clk_ahb); 
host->clk_mmc = devm_clk_get(&pdev->dev, <token> <answer> "mmc"); 
if (IS_ERR(host->clk_mmc)) <token> <answer> { 
dev_err(&pdev->dev, "Could <token> get mmc clock\n"); <answer> not 
return <token> <answer> PTR_ERR(host->clk_mmc); 
<token> (host->cfg->clk_delays) { <answer> if 
<token> = devm_clk_get(&pdev->dev, "output"); <answer> host->clk_output 
<token> (IS_ERR(host->clk_output)) { <answer> if 
<token> "Could not get output clock\n"); <answer> dev_err(&pdev->dev, 
return <token> <answer> PTR_ERR(host->clk_output); 
host->clk_sample = <token> "sample"); <answer> devm_clk_get(&pdev->dev, 
<token> (IS_ERR(host->clk_sample)) { <answer> if 
dev_err(&pdev->dev, "Could <token> get sample clock\n"); <answer> not 
<token> PTR_ERR(host->clk_sample); <answer> return 
host->reset <token> devm_reset_control_get_optional_exclusive(&pdev->dev, <answer> = 
<token> (PTR_ERR(host->reset) == -EPROBE_DEFER) <answer> if 
return <token> <answer> PTR_ERR(host->reset); 
<token> = sunxi_mmc_enable(host); <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ret; 
host->irq = platform_get_irq(pdev, <token> <answer> 0); 
<token> (host->irq < 0) { <answer> if 
<token> = host->irq; <answer> ret 
<token> error_disable_mmc; <answer> goto 
return devm_request_threaded_irq(&pdev->dev, <token> sunxi_mmc_irq, <answer> host->irq, 
<token> 0, "sunxi-mmc", host); <answer> sunxi_mmc_handle_manual_stop, 
return <token> <answer> ret; 
<token> int sunxi_mmc_probe(struct platform_device *pdev) <answer> static 
struct sunxi_mmc_host <token> <answer> *host; 
<token> mmc_host *mmc; <answer> struct 
<token> ret; <answer> int 
mmc = mmc_alloc_host(sizeof(struct sunxi_mmc_host), <token> <answer> &pdev->dev); 
if (!mmc) <token> <answer> { 
dev_err(&pdev->dev, <token> alloc host failed\n"); <answer> "mmc 
return <token> <answer> -ENOMEM; 
platform_set_drvdata(pdev, <token> <answer> mmc); 
host <token> mmc_priv(mmc); <answer> = 
host->dev = <token> <answer> &pdev->dev; 
host->mmc = <token> <answer> mmc; 
ret = <token> pdev); <answer> sunxi_mmc_resource_request(host, 
<token> (ret) <answer> if 
goto <token> <answer> error_free_host; 
host->sg_cpu <token> dma_alloc_coherent(&pdev->dev, PAGE_SIZE, <answer> = 
<token> GFP_KERNEL); <answer> &host->sg_dma, 
if (!host->sg_cpu) <token> <answer> { 
dev_err(&pdev->dev, <token> to allocate DMA descriptor mem\n"); <answer> "Failed 
ret <token> -ENOMEM; <answer> = 
<token> error_free_host; <answer> goto 
if (host->cfg->ccu_has_timings_switch) <token> <answer> { 
sunxi_ccu_set_mmc_timing_mode(host->clk_mmc, <token> <answer> true); 
dev_warn(&pdev->dev, "MMC clk timing mode <token> <answer> unknown\n"); 
host->use_new_timings = <token> <answer> false; 
<token> else { <answer> } 
host->use_new_timings = <token> <answer> !!ret; 
<token> else if (host->cfg->needs_new_timings) { <answer> } 
if <token> || host->use_new_timings) && <answer> ((host->cfg->clk_delays 
mmc->caps <token> MMC_CAP_1_8V_DDR | MMC_CAP_3_3V_DDR; <answer> |= 
<token> = mmc_of_parse(mmc); <answer> ret 
if <token> <answer> (ret) 
<token> error_free_dma; <answer> goto 
<token> (!(host->cfg->clk_delays || host->use_new_timings)) { <answer> if 
mmc->caps &= ~(MMC_CAP_3_3V_DDR | MMC_CAP_1_8V_DDR <token> <answer> | 
<token> | MMC_CAP_UHS); <answer> MMC_CAP_1_2V_DDR 
mmc->caps2 &= <token> <answer> ~MMC_CAP2_HS200; 
return <token> <answer> 0; 
static const struct dev_pm_ops sunxi_mmc_pm_ops = <token> <answer> { 
static struct platform_driver sunxi_mmc_driver <token> { <answer> = 
.driver = <token> <answer> { 
.name <token> "sunxi-mmc", <answer> = 
.probe_type = <token> <answer> PROBE_PREFER_ASYNCHRONOUS, 
.of_match_table = <token> <answer> sunxi_mmc_of_match, 
<token> = &sunxi_mmc_pm_ops, <answer> .pm 
.probe = <token> <answer> sunxi_mmc_probe, 
<token> = sunxi_mmc_remove, <answer> .remove_new 
MODULE_DESCRIPTION("Allwinner's SD/MMC Card <token> Driver"); <answer> Controller 
<token> v2"); <answer> MODULE_LICENSE("GPL 
MODULE_AUTHOR("David <token> <david.lanzendoerfer@o2s.ch>"); <answer> Lanzendrfer 
<token> <linux/slab.h> <answer> #include 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
<token> <linux/ktime.h> <answer> #include 
#include <token> <answer> "tb.h" 
static void tb_dump_hop(const struct tb_path_hop *hop, const struct <token> *regs) <answer> tb_regs_hop 
const struct <token> *port = hop->in_port; <answer> tb_port 
tb_port_dbg(port, <token> In HopID: %d => Out port: %d Out HopID: %d\n", <answer> " 
hop->in_hop_index, regs->out_port, <token> <answer> regs->next_hop); 
tb_port_dbg(port, " Weight: %d <token> %d Credits: %d Drop: %d PM: %d\n", <answer> Priority: 
regs->weight, <token> regs->initial_credits, <answer> regs->priority, 
regs->drop_packages, <token> <answer> regs->pmps); 
tb_port_dbg(port, <token> Counter enabled: %d Counter index: %d\n", <answer> " 
<token> regs->counter); <answer> regs->counter_enable, 
tb_port_dbg(port, " Flow Control (In/Eg): %d/%d Shared <token> (In/Eg): %d/%d\n", <answer> Buffer 
regs->ingress_fc, <token> <answer> regs->egress_fc, 
regs->ingress_shared_buffer, <token> <answer> regs->egress_shared_buffer); 
tb_port_dbg(port, " Unknown1: <token> Unknown2: %#x Unknown3: %#x\n", <answer> %#x 
<token> regs->unknown2, regs->unknown3); <answer> regs->unknown1, 
static struct tb_port *tb_path_find_dst_port(struct <token> *src, int src_hopid, <answer> tb_port 
int <token> <answer> dst_hopid) 
struct <token> *port, *out_port = NULL; <answer> tb_port 
<token> tb_regs_hop hop; <answer> struct 
struct <token> *sw; <answer> tb_switch 
int i, <token> hopid; <answer> ret, 
hopid = <token> <answer> src_hopid; 
<token> = src; <answer> port 
for (i = 0; <token> && i < TB_PATH_MAX_HOPS; i++) { <answer> port 
<token> = port->sw; <answer> sw 
<token> = tb_port_read(port, &hop, TB_CFG_HOPS, 2 * hopid, 2); <answer> ret 
if (ret) <token> <answer> { 
<token> "failed to read path at %d\n", hopid); <answer> tb_port_warn(port, 
return <token> <answer> NULL; 
if <token> <answer> (!hop.enable) 
<token> NULL; <answer> return 
out_port = <token> <answer> &sw->ports[hop.out_port]; 
hopid = <token> <answer> hop.next_hop; 
<token> = out_port->remote; <answer> port 
return <token> && hopid == dst_hopid ? out_port : NULL; <answer> out_port 
static <token> tb_path_find_src_hopid(struct tb_port *src, <answer> int 
const <token> tb_port *dst, int dst_hopid) <answer> struct 
struct tb_port <token> <answer> *out; 
<token> i; <answer> int 
for <token> = TB_PATH_MIN_HOPID; i <= src->config.max_in_hop_id; i++) { <answer> (i 
out = <token> i, dst_hopid); <answer> tb_path_find_dst_port(src, 
<token> (out == dst) <answer> if 
return <token> <answer> i; 
<token> 0; <answer> return 
struct <token> *tb_path_discover(struct tb_port *src, int src_hopid, <answer> tb_path 
struct <token> *dst, int dst_hopid, <answer> tb_port 
struct tb_port **last, const <token> *name, <answer> char 
<token> alloc_hopid) <answer> bool 
struct tb_port <token> <answer> *out_port; 
struct <token> hop; <answer> tb_regs_hop 
struct <token> *path; <answer> tb_path 
struct tb_switch <token> <answer> *sw; 
struct <token> *p; <answer> tb_port 
<token> num_hops; <answer> size_t 
int ret, i, <token> <answer> h; 
if (src_hopid < 0 && <token> { <answer> dst) 
src_hopid = <token> dst, dst_hopid); <answer> tb_path_find_src_hopid(src, 
if <token> <answer> (!src_hopid) 
return <token> <answer> NULL; 
p = <token> <answer> src; 
<token> = src_hopid; <answer> h 
num_hops = <token> <answer> 0; 
for (i = 0; p <token> i < TB_PATH_MAX_HOPS; i++) { <answer> && 
sw = <token> <answer> p->sw; 
ret = tb_port_read(p, &hop, TB_CFG_HOPS, 2 * <token> 2); <answer> h, 
if <token> { <answer> (ret) 
tb_port_warn(p, "failed to read path at <token> h); <answer> %d\n", 
return <token> <answer> NULL; 
struct tb_path *tb_path_alloc(struct tb *tb, struct tb_port *src, <token> src_hopid, <answer> int 
struct tb_port *dst, <token> dst_hopid, int link_nr, <answer> int 
<token> char *name) <answer> const 
struct tb_port *in_port, *out_port, *first_port, <token> <answer> *last_port; 
<token> in_hopid, out_hopid; <answer> int 
struct tb_path <token> <answer> *path; 
<token> num_hops; <answer> size_t 
int i, <token> <answer> ret; 
path = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*path), 
<token> (!path) <answer> if 
<token> NULL; <answer> return 
first_port = <token> = NULL; <answer> last_port 
i <token> 0; <answer> = 
<token> dst, in_port) { <answer> tb_for_each_port_on_path(src, 
<token> (!first_port) <answer> if 
first_port = <token> <answer> in_port; 
<token> = in_port; <answer> last_port 
if <token> { <answer> (out_port->dual_link_port) 
<token> (!in_port->bonded && out_port->bonded && <answer> if 
<token> { <answer> out_port->link_nr) 
<token> = out_port->dual_link_port; <answer> out_port 
} else if <token> && <answer> (!out_port->bonded 
out_port->link_nr != link_nr) <token> <answer> { 
<token> = out_port->dual_link_port; <answer> out_port 
if (i == num_hops <token> 1) <answer> - 
ret = <token> dst_hopid, <answer> tb_port_alloc_out_hopid(out_port, 
ret = tb_port_alloc_out_hopid(out_port, <token> -1); <answer> -1, 
if (ret <token> 0) <answer> < 
<token> err; <answer> goto 
<token> = ret; <answer> out_hopid 
path->hops[i].in_hop_index <token> in_hopid; <answer> = 
<token> = in_port; <answer> path->hops[i].in_port 
path->hops[i].in_counter_index = <token> <answer> -1; 
path->hops[i].out_port <token> out_port; <answer> = 
<token> = out_hopid; <answer> path->hops[i].next_hop_index 
in_hopid = <token> <answer> out_hopid; 
path->tb = <token> <answer> tb; 
path->path_length <token> num_hops; <answer> = 
path->name = <token> <answer> name; 
return <token> <answer> path; 
<token> NULL; <answer> return 
<token> tb_path_free(struct tb_path *path) <answer> void 
if <token> { <answer> (path->alloc_hopid) 
<token> i; <answer> int 
for (i = 0; i <token> path->path_length; i++) { <answer> < 
const struct tb_path_hop <token> = &path->hops[i]; <answer> *hop 
<token> (hop->in_port) <answer> if 
<token> (hop->out_port) <answer> if 
static void <token> tb_path *path, int first_hop) <answer> __tb_path_deallocate_nfc(struct 
int <token> res; <answer> i, 
for (i = first_hop; <token> < path->path_length; i++) { <answer> i 
res = <token> <answer> tb_port_add_nfc_credits(path->hops[i].in_port, 
<token> (res) <answer> if 
"nfc credits deallocation failed for <token> %d\n", <answer> hop 
static int <token> tb_port *port, int hop_index, <answer> __tb_path_deactivate_hop(struct 
<token> clear_fc) <answer> bool 
<token> tb_regs_hop hop; <answer> struct 
<token> timeout; <answer> ktime_t 
int <token> <answer> ret; 
if <token> { <answer> (!tb_switch_is_usb4(port->sw)) 
hop.ingress_fc = <token> <answer> 0; 
hop.ingress_shared_buffer <token> 0; <answer> = 
hop.egress_fc = <token> <answer> 0; 
hop.egress_shared_buffer <token> 0; <answer> = 
return tb_port_write(port, <token> TB_CFG_HOPS, <answer> &hop, 
2 <token> hop_index, 2); <answer> * 
<token> 0; <answer> return 
<token> 20); <answer> usleep_range(10, 
} while (ktime_before(ktime_get(), <token> <answer> timeout)); 
<token> -ETIMEDOUT; <answer> return 
int tb_path_deactivate_hop(struct tb_port *port, int <token> <answer> hop_index) 
return <token> hop_index, true); <answer> __tb_path_deactivate_hop(port, 
static void <token> tb_path *path, int first_hop) <answer> __tb_path_deactivate_hops(struct 
int i, <token> <answer> res; 
for (i = first_hop; i < path->path_length; i++) <token> <answer> { 
res <token> __tb_path_deactivate_hop(path->hops[i].in_port, <answer> = 
if <token> && res != -ENODEV) <answer> (res 
"hop deactivation failed for <token> %d, index %d\n", <answer> hop 
i, <token> <answer> path->hops[i].in_hop_index); 
void tb_path_deactivate(struct tb_path <token> <answer> *path) 
if (!path->activated) <token> <answer> { 
tb_WARN(path->tb, "trying to deactivate an <token> path\n"); <answer> inactive 
"deactivating %s path <token> %llx:%u to %llx:%u\n", <answer> from 
path->name, <token> <answer> tb_route(path->hops[0].in_port->sw), 
<token> - 1].out_port->sw), <answer> tb_route(path->hops[path->path_length 
path->hops[path->path_length - <token> <answer> 1].out_port->port); 
__tb_path_deactivate_hops(path, <token> <answer> 0); 
<token> 0); <answer> __tb_path_deallocate_nfc(path, 
path->activated <token> false; <answer> = 
int tb_path_activate(struct tb_path <token> <answer> *path) 
<token> i, res; <answer> int 
<token> tb_path_port out_mask, in_mask; <answer> enum 
if <token> { <answer> (path->activated) 
tb_WARN(path->tb, "trying to activate <token> activated path\n"); <answer> already 
return <token> <answer> -EINVAL; 
"activating %s <token> from %llx:%u to %llx:%u\n", <answer> path 
path->name, <token> <answer> tb_route(path->hops[0].in_port->sw), 
tb_route(path->hops[path->path_length - <token> <answer> 1].out_port->sw), 
path->hops[path->path_length <token> 1].out_port->port); <answer> - 
<token> tb_path_is_invalid(struct tb_path *path) <answer> bool 
int i = <token> <answer> 0; 
for (i = 0; i < path->path_length; <token> { <answer> i++) 
<token> (path->hops[i].in_port->sw->is_unplugged) <answer> if 
return <token> <answer> true; 
if <token> <answer> (path->hops[i].out_port->sw->is_unplugged) 
<token> true; <answer> return 
<token> false; <answer> return 
bool tb_path_port_on_path(const struct tb_path *path, const struct tb_port <token> <answer> *port) 
int <token> <answer> i; 
for (i = 0; i <token> path->path_length; i++) { <answer> < 
if (path->hops[i].in_port <token> port || <answer> == 
<token> == port) <answer> path->hops[i].out_port 
<token> true; <answer> return 
return <token> <answer> false; 
#include <token> <answer> <linux/bitfield.h> 
#include <token> <answer> <linux/bitops.h> 
<token> <linux/clk.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
<token> <linux/iopoll.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/reset.h> 
#include <token> <answer> <linux/phy/phy.h> 
#include <token> <answer> <linux/phy/phy-mipi-dphy.h> 
#define REG_WAKEUP_TIME_NS <token> <answer> 800 
<token> DPHY_PLL_RATE_HZ 108000000 <answer> #define 
<token> POLL_TIMEOUT_US 1000 <answer> #define 
writel(DPHY_CMN_PWM_HIGH(6) | <token> | <answer> DPHY_CMN_PWM_LOW(0x101) 
<token> + DPHY_CMN_PWM); <answer> dphy->regs 
<token> cfg->pll_ipdiv) | <answer> writel((FIELD_PREP(DPHY_TX_J721E_WIZ_IPDIV, 
FIELD_PREP(DPHY_TX_J721E_WIZ_OPDIV, <token> | <answer> cfg->pll_opdiv) 
<token> cfg->pll_fbdiv)), <answer> FIELD_PREP(DPHY_TX_J721E_WIZ_FBDIV, 
dphy->regs <token> DPHY_TX_J721E_WIZ_PLL_CTRL); <answer> + 
dphy->regs <token> DPHY_TX_J721E_WIZ_RST_CTRL); <answer> + 
readl_poll_timeout(dphy->regs + DPHY_TX_J721E_WIZ_PLL_CTRL, <token> <answer> status, 
(status & DPHY_TX_WIZ_PLL_LOCK), <token> POLL_TIMEOUT_US); <answer> 0, 
readl_poll_timeout(dphy->regs + <token> status, <answer> DPHY_TX_J721E_WIZ_STATUS, 
(status & <token> 0, <answer> DPHY_TX_WIZ_O_CMN_READY), 
static <token> cdns_dphy_j721e_set_psm_div(struct cdns_dphy *dphy, u8 div) <answer> void 
writel(div, <token> + DPHY_TX_J721E_WIZ_PSM_FREQ); <answer> dphy->regs 
static const struct <token> ref_dphy_ops = { <answer> cdns_dphy_ops 
.get_wakeup_time_ns <token> cdns_dphy_ref_get_wakeup_time_ns, <answer> = 
<token> = cdns_dphy_ref_set_pll_cfg, <answer> .set_pll_cfg 
.set_psm_div <token> cdns_dphy_ref_set_psm_div, <answer> = 
static const struct cdns_dphy_ops <token> = { <answer> j721e_dphy_ops 
.get_wakeup_time_ns <token> cdns_dphy_j721e_get_wakeup_time_ns, <answer> = 
<token> = cdns_dphy_j721e_set_pll_cfg, <answer> .set_pll_cfg 
<token> = cdns_dphy_j721e_set_psm_div, <answer> .set_psm_div 
static <token> cdns_dphy_config_from_opts(struct phy *phy, <answer> int 
<token> phy_configure_opts_mipi_dphy *opts, <answer> struct 
<token> cdns_dphy_cfg *cfg) <answer> struct 
struct <token> *dphy = phy_get_drvdata(phy); <answer> cdns_dphy 
unsigned int <token> = 0; <answer> dsi_hfp_ext 
int <token> <answer> ret; 
ret = <token> <answer> phy_mipi_dphy_config_validate(opts); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
ret = <token> cfg, <answer> cdns_dsi_get_dphy_pll_cfg(dphy, 
<token> &dsi_hfp_ext); <answer> opts, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
opts->wakeup = cdns_dphy_get_wakeup_time_ns(dphy) <token> 1000; <answer> / 
return <token> <answer> 0; 
static int <token> long hs_clk_rate) <answer> cdns_dphy_tx_get_band_ctrl(unsigned 
unsigned int <token> <answer> rate; 
int <token> <answer> i; 
rate = hs_clk_rate <token> 1000000UL; <answer> / 
if (rate < <token> <answer> tx_bands[0]) 
return <token> <answer> -EOPNOTSUPP; 
for <token> = 0; i < ARRAY_SIZE(tx_bands) - 1; i++) { <answer> (i 
if <token> >= tx_bands[i] && rate < tx_bands[i + 1]) <answer> (rate 
<token> i; <answer> return 
return <token> <answer> -EOPNOTSUPP; 
static int cdns_dphy_validate(struct phy *phy, enum phy_mode mode, int <token> <answer> submode, 
union <token> *opts) <answer> phy_configure_opts 
struct cdns_dphy_cfg cfg = { <token> }; <answer> 0 
if (mode != <token> <answer> PHY_MODE_MIPI_DPHY) 
<token> -EINVAL; <answer> return 
return cdns_dphy_config_from_opts(phy, &opts->mipi_dphy, <token> <answer> &cfg); 
static int cdns_dphy_configure(struct phy *phy, union <token> *opts) <answer> phy_configure_opts 
struct <token> *dphy = phy_get_drvdata(phy); <answer> cdns_dphy 
struct cdns_dphy_cfg cfg <token> { 0 }; <answer> = 
int ret, <token> <answer> band_ctrl; 
<token> int reg; <answer> unsigned 
<token> = cdns_dphy_config_from_opts(phy, &opts->mipi_dphy, &cfg); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> = cdns_dphy_setup_psm(dphy); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
cdns_dphy_set_clk_lane_cfg(dphy, <token> <answer> DPHY_CLK_CFG_LEFT_DRIVES_LEFT); 
cdns_dphy_set_pll_cfg(dphy, <token> <answer> &cfg); 
band_ctrl <token> cdns_dphy_tx_get_band_ctrl(opts->mipi_dphy.hs_clk_rate); <answer> = 
<token> (band_ctrl < 0) <answer> if 
<token> band_ctrl; <answer> return 
<token> = FIELD_PREP(DPHY_BAND_CFG_LEFT_BAND, band_ctrl) | <answer> reg 
FIELD_PREP(DPHY_BAND_CFG_RIGHT_BAND, <token> <answer> band_ctrl); 
<token> dphy->regs + DPHY_BAND_CFG); <answer> writel(reg, 
return <token> <answer> 0; 
<token> int cdns_dphy_power_on(struct phy *phy) <answer> static 
struct <token> *dphy = phy_get_drvdata(phy); <answer> cdns_dphy 
#include <token> <answer> <linux/i2c.h> 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/mfd/core.h> 
<token> <linux/mfd/max77541.h> <answer> #include 
<token> <linux/property.h> <answer> #include 
#include <token> <answer> <linux/regmap.h> 
static const struct <token> max77541_regmap_config = { <answer> regmap_config 
.reg_bits <token> 8, <answer> = 
.val_bits <token> 8, <answer> = 
static const struct regmap_irq <token> = { <answer> max77541_src_irqs[] 
{ .mask = <token> }, <answer> MAX77541_BIT_INT_SRC_TOPSYS 
<token> .mask = MAX77541_BIT_INT_SRC_BUCK }, <answer> { 
static <token> struct regmap_irq_chip max77541_src_irq_chip = { <answer> const 
<token> = "max77541-src", <answer> .name 
<token> = MAX77541_REG_INT_SRC, <answer> .status_base 
.mask_base = <token> <answer> MAX77541_REG_INT_SRC_M, 
.num_regs = <token> <answer> 1, 
.irqs = <token> <answer> max77541_src_irqs, 
<token> = ARRAY_SIZE(max77541_src_irqs), <answer> .num_irqs 
static const struct regmap_irq max77541_topsys_irqs[] <token> { <answer> = 
<token> .mask = MAX77541_BIT_TOPSYS_INT_TJ_120C }, <answer> { 
{ .mask = <token> }, <answer> MAX77541_BIT_TOPSYS_INT_TJ_140C 
<token> .mask = MAX77541_BIT_TOPSYS_INT_TSHDN }, <answer> { 
<token> .mask = MAX77541_BIT_TOPSYS_INT_UVLO }, <answer> { 
{ <token> = MAX77541_BIT_TOPSYS_INT_ALT_SWO }, <answer> .mask 
{ .mask = <token> }, <answer> MAX77541_BIT_TOPSYS_INT_EXT_FREQ_DET 
static const struct regmap_irq_chip max77541_topsys_irq_chip = <token> <answer> { 
.name = <token> <answer> "max77541-topsys", 
.status_base = <token> <answer> MAX77541_REG_TOPSYS_INT, 
<token> = MAX77541_REG_TOPSYS_INT_M, <answer> .mask_base 
.num_regs = <token> <answer> 1, 
.irqs = <token> <answer> max77541_topsys_irqs, 
.num_irqs = <token> <answer> ARRAY_SIZE(max77541_topsys_irqs), 
static const struct regmap_irq max77541_buck_irqs[] = <token> <answer> { 
{ .mask = MAX77541_BIT_BUCK_INT_M1_POK_FLT <token> <answer> }, 
{ <token> = MAX77541_BIT_BUCK_INT_M2_POK_FLT }, <answer> .mask 
{ .mask = MAX77541_BIT_BUCK_INT_M1_SCFLT <token> <answer> }, 
{ .mask = MAX77541_BIT_BUCK_INT_M2_SCFLT <token> <answer> }, 
static const struct regmap_irq_chip <token> = { <answer> max77541_buck_irq_chip 
<token> = "max77541-buck", <answer> .name 
.status_base <token> MAX77541_REG_BUCK_INT, <answer> = 
<token> = MAX77541_REG_BUCK_INT_M, <answer> .mask_base 
.num_regs <token> 1, <answer> = 
.irqs <token> max77541_buck_irqs, <answer> = 
<token> = ARRAY_SIZE(max77541_buck_irqs), <answer> .num_irqs 
static <token> struct regmap_irq max77541_adc_irqs[] = { <answer> const 
{ .mask <token> MAX77541_BIT_ADC_INT_CH1_I }, <answer> = 
{ .mask = <token> }, <answer> MAX77541_BIT_ADC_INT_CH2_I 
{ <token> = MAX77541_BIT_ADC_INT_CH3_I }, <answer> .mask 
{ <token> = MAX77541_BIT_ADC_INT_CH6_I }, <answer> .mask 
static const struct regmap_irq_chip <token> = { <answer> max77541_adc_irq_chip 
.name = <token> <answer> "max77541-adc", 
.status_base <token> MAX77541_REG_ADC_INT, <answer> = 
.mask_base <token> MAX77541_REG_ADC_INT_M, <answer> = 
<token> = 1, <answer> .num_regs 
<token> = max77541_adc_irqs, <answer> .irqs 
<token> = ARRAY_SIZE(max77541_adc_irqs), <answer> .num_irqs 
static const struct mfd_cell max77540_devs[] = <token> <answer> { 
MFD_CELL_OF("max77540-regulator", NULL, NULL, <token> 0, NULL), <answer> 0, 
static const struct <token> max77541_devs[] = { <answer> mfd_cell 
MFD_CELL_OF("max77541-regulator", NULL, NULL, <token> 0, NULL), <answer> 0, 
MFD_CELL_OF("max77541-adc", NULL, <token> 0, 0, NULL), <answer> NULL, 
static <token> max77541_pmic_irq_init(struct device *dev) <answer> int 
struct <token> *max77541 = dev_get_drvdata(dev); <answer> max77541 
int irq = <token> <answer> max77541->i2c->irq; 
<token> ret; <answer> int 
ret = <token> max77541->regmap, irq, <answer> devm_regmap_add_irq_chip(dev, 
IRQF_ONESHOT | <token> 0, <answer> IRQF_SHARED, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> = devm_regmap_add_irq_chip(dev, max77541->regmap, irq, <answer> ret 
<token> | IRQF_SHARED, 0, <answer> IRQF_ONESHOT 
if <token> <answer> (ret) 
<token> ret; <answer> return 
ret = devm_regmap_add_irq_chip(dev, max77541->regmap, <token> <answer> irq, 
IRQF_ONESHOT | <token> 0, <answer> IRQF_SHARED, 
if <token> <answer> (ret) 
return <token> <answer> ret; 
if (max77541->id == <token> { <answer> MAX77541) 
ret = devm_regmap_add_irq_chip(dev, max77541->regmap, <token> <answer> irq, 
IRQF_ONESHOT | IRQF_SHARED, <token> <answer> 0, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> 0; <answer> return 
static int <token> device *dev) <answer> max77541_pmic_setup(struct 
<token> max77541 *max77541 = dev_get_drvdata(dev); <answer> struct 
const struct <token> *cells; <answer> mfd_cell 
<token> n_devs; <answer> int 
int <token> <answer> ret; 
switch <token> { <answer> (max77541->id) 
case <token> <answer> MAX77540: 
cells = <token> <answer> max77540_devs; 
<token> = ARRAY_SIZE(max77540_devs); <answer> n_devs 
case <token> <answer> MAX77541: 
cells <token> max77541_devs; <answer> = 
<token> = ARRAY_SIZE(max77541_devs); <answer> n_devs 
return <token> <answer> -EINVAL; 
ret = <token> <answer> max77541_pmic_irq_init(dev); 
if <token> <answer> (ret) 
return <token> ret, "Failed to initialize IRQ\n"); <answer> dev_err_probe(dev, 
ret = <token> true); <answer> device_init_wakeup(dev, 
<token> (ret) <answer> if 
return dev_err_probe(dev, ret, "Unable to init <token> <answer> wakeup\n"); 
return devm_mfd_add_devices(dev, <token> <answer> PLATFORM_DEVID_NONE, 
<token> n_devs, NULL, 0, NULL); <answer> cells, 
<token> int max77541_probe(struct i2c_client *client) <answer> static 
<token> device *dev = &client->dev; <answer> struct 
struct max77541 <token> <answer> *max77541; 
max77541 <token> devm_kzalloc(dev, sizeof(*max77541), GFP_KERNEL); <answer> = 
<token> (!max77541) <answer> if 
<token> -ENOMEM; <answer> return 
<token> max77541); <answer> i2c_set_clientdata(client, 
max77541->i2c <token> client; <answer> = 
<token> = (uintptr_t)i2c_get_match_data(client); <answer> max77541->id 
if <token> <answer> (!max77541->id) 
return <token> <answer> -EINVAL; 
max77541->regmap <token> devm_regmap_init_i2c(client, <answer> = 
<token> (IS_ERR(max77541->regmap)) <answer> if 
return <token> PTR_ERR(max77541->regmap), <answer> dev_err_probe(dev, 
"Failed to <token> register map\n"); <answer> allocate 
return <token> <answer> max77541_pmic_setup(dev); 
static const struct of_device_id <token> = { <answer> max77541_of_id[] 
.compatible <token> "adi,max77540", <answer> = 
.data = (void <token> <answer> *)MAX77540, 
.compatible <token> "adi,max77541", <answer> = 
.data = (void <token> <answer> *)MAX77541, 
{ <token> <answer> } 
MODULE_DEVICE_TABLE(of, <token> <answer> max77541_of_id); 
static const struct i2c_device_id <token> = { <answer> max77541_id[] 
{ <token> MAX77540 }, <answer> "max77540", 
{ "max77541", <token> }, <answer> MAX77541 
<token> } <answer> { 
MODULE_DEVICE_TABLE(i2c, <token> <answer> max77541_id); 
static <token> i2c_driver max77541_driver = { <answer> struct 
<token> = { <answer> .driver 
.name = <token> <answer> "max77541", 
.of_match_table = <token> <answer> max77541_of_id, 
.probe = <token> <answer> max77541_probe, 
<token> = max77541_id, <answer> .id_table 
<token> Driver"); <answer> MODULE_DESCRIPTION("MAX7740/MAX7741 
<token> Sahin <okan.sahin@analog.com>"); <answer> MODULE_AUTHOR("Okan 
#include <token> <answer> <linux/export.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/types.h> <answer> #include 
<token> <asm/io.h> <answer> #include 
<token> <asm/sgi/hpc3.h> <answer> #include 
#include <token> <answer> <asm/sgi/ioc.h> 
#include <token> <answer> <asm/sgi/ip22.h> 
struct <token> *hpc3c0, *hpc3c1; <answer> hpc3_regs 
struct sgioc_regs <token> <answer> *sgioc; 
sgint = (struct <token> *)hpc3c0->pbus_extregs[4]; <answer> sgint_regs 
<token> = "SGI Indigo2"; <answer> system_type 
<token> else { <answer> } 
#define pr_fmt(fmt) KBUILD_MODNAME <token> " fmt <answer> ": 
<token> <linux/acpi.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/err.h> 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
#include <token> <answer> <linux/jiffies.h> 
#include <token> <answer> <linux/hwmon.h> 
<token> <linux/hwmon-sysfs.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/mutex.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
enum kinds <token> nct6683, nct6686, nct6687 }; <answer> { 
<token> bool force; <answer> static 
module_param(force, <token> 0); <answer> bool, 
MODULE_PARM_DESC(force, "Set to one to enable support for unknown <token> <answer> vendors"); 
<token> const char * const nct6683_device_names[] = { <answer> static 
static const char * const nct6683_chip_names[] <token> { <answer> = 
#define DRVNAME <token> <answer> "nct6683" 
#define <token> 0x0a <answer> NCT6683_LD_ACPI 
<token> NCT6683_LD_HWM 0x0b <answer> #define 
#define <token> 0x0d <answer> NCT6683_LD_VID 
if (!request_muxed_region(ioreg, 2, <token> <answer> DRVNAME)) 
<token> -EBUSY; <answer> return 
outb(0x87, <token> <answer> ioreg); 
<token> ioreg); <answer> outb(0x87, 
<token> 0; <answer> return 
static <token> void <answer> inline 
superio_exit(int <token> <answer> ioreg) 
<token> ioreg); <answer> outb(0xaa, 
outb(0x02, <token> <answer> ioreg); 
outb(0x02, ioreg + <token> <answer> 1); 
<token> 2); <answer> release_region(ioreg, 
#define <token> (~7) <answer> IOREGION_ALIGNMENT 
<token> ssize_t <answer> static 
show_in_label(struct device <token> struct device_attribute *attr, char *buf) <answer> *dev, 
struct sensor_device_attribute <token> = to_sensor_dev_attr(attr); <answer> *sattr 
struct nct6683_data <token> = nct6683_update_device(dev); <answer> *data 
int nr <token> sattr->index; <answer> = 
return <token> "%s\n", nct6683_mon_label[data->in_src[nr]]); <answer> sprintf(buf, 
static <token> <answer> ssize_t 
show_in_reg(struct device *dev, struct device_attribute <token> char *buf) <answer> *attr, 
struct sensor_device_attribute_2 *sattr = <token> <answer> to_sensor_dev_attr_2(attr); 
struct nct6683_data *data = <token> <answer> nct6683_update_device(dev); 
<token> index = sattr->index; <answer> int 
int <token> = sattr->nr; <answer> nr 
<token> sprintf(buf, "%ld\n", <answer> return 
<token> data->in_index[index])); <answer> in_from_reg(data->in[index][nr], 
static umode_t nct6683_in_is_visible(struct kobject <token> <answer> *kobj, 
struct attribute *attr, <token> index) <answer> int 
struct device *dev <token> kobj_to_dev(kobj); <answer> = 
struct nct6683_data *data <token> dev_get_drvdata(dev); <answer> = 
if ((nr == <token> || nr == 3) && <answer> 2 
data->customer_id <token> NCT6683_CUSTOMER_ID_INTEL) <answer> == 
<token> 0; <answer> return 
<token> attr->mode; <answer> return 
SENSOR_TEMPLATE(in_label, <token> S_IRUGO, show_in_label, NULL, 0); <answer> "in%d_label", 
SENSOR_TEMPLATE_2(in_input, "in%d_input", S_IRUGO, show_in_reg, NULL, 0, <token> <answer> 0); 
SENSOR_TEMPLATE_2(in_min, "in%d_min", <token> show_in_reg, NULL, 0, 1); <answer> S_IRUGO, 
<token> "in%d_max", S_IRUGO, show_in_reg, NULL, 0, 2); <answer> SENSOR_TEMPLATE_2(in_max, 
static struct <token> *nct6683_attributes_in_template[] = { <answer> sensor_device_template 
static <token> struct sensor_template_group nct6683_in_template_group = { <answer> const 
<token> = nct6683_attributes_in_template, <answer> .templates 
.is_visible = <token> <answer> nct6683_in_is_visible, 
<token> ssize_t <answer> static 
show_fan(struct <token> *dev, struct device_attribute *attr, char *buf) <answer> device 
<token> sensor_device_attribute *sattr = to_sensor_dev_attr(attr); <answer> struct 
struct nct6683_data *data <token> nct6683_update_device(dev); <answer> = 
return <token> "%d\n", data->rpm[sattr->index]); <answer> sprintf(buf, 
<token> ssize_t <answer> static 
show_fan_min(struct device *dev, struct device_attribute *attr, char <token> <answer> *buf) 
struct nct6683_data *data = <token> <answer> nct6683_update_device(dev); 
<token> sensor_device_attribute *sattr = to_sensor_dev_attr(attr); <answer> struct 
int nr <token> sattr->index; <answer> = 
return sprintf(buf, "%d\n", <token> <answer> data->fan_min[nr]); 
<token> ssize_t <answer> static 
show_fan_pulses(struct device *dev, struct device_attribute <token> char *buf) <answer> *attr, 
struct <token> *sattr = to_sensor_dev_attr(attr); <answer> sensor_device_attribute 
struct nct6683_data *data <token> nct6683_update_device(dev); <answer> = 
return sprintf(buf, <token> <answer> "%d\n", 
((data->fanin_cfg[sattr->index] >> 5) & 0x03) + <token> <answer> 1); 
<token> umode_t nct6683_fan_is_visible(struct kobject *kobj, <answer> static 
struct <token> *attr, int index) <answer> attribute 
struct device *dev <token> kobj_to_dev(kobj); <answer> = 
struct <token> *data = dev_get_drvdata(dev); <answer> nct6683_data 
if (nr == 2 && <token> == NCT6683_CUSTOMER_ID_INTEL) <answer> data->customer_id 
return <token> <answer> 0; 
<token> attr->mode; <answer> return 
SENSOR_TEMPLATE(fan_input, "fan%d_input", S_IRUGO, show_fan, <token> 0); <answer> NULL, 
SENSOR_TEMPLATE(fan_pulses, "fan%d_pulses", <token> show_fan_pulses, NULL, 0); <answer> S_IRUGO, 
SENSOR_TEMPLATE(fan_min, "fan%d_min", <token> show_fan_min, NULL, 0); <answer> S_IRUGO, 
static struct sensor_device_template <token> = { <answer> *nct6683_attributes_fan_template[] 
static const struct <token> nct6683_fan_template_group = { <answer> sensor_template_group 
.templates = <token> <answer> nct6683_attributes_fan_template, 
<token> = nct6683_fan_is_visible, <answer> .is_visible 
.base = <token> <answer> 1, 
<token> ssize_t <answer> static 
show_temp_label(struct <token> *dev, struct device_attribute *attr, char *buf) <answer> device 
struct sensor_device_attribute *sattr = <token> <answer> to_sensor_dev_attr(attr); 
struct nct6683_data *data = <token> <answer> nct6683_update_device(dev); 
int nr <token> sattr->index; <answer> = 
return sprintf(buf, <token> nct6683_mon_label[data->temp_src[nr]]); <answer> "%s\n", 
static <token> <answer> ssize_t 
show_temp8(struct device *dev, <token> device_attribute *attr, char *buf) <answer> struct 
struct <token> *sattr = to_sensor_dev_attr_2(attr); <answer> sensor_device_attribute_2 
struct nct6683_data *data <token> nct6683_update_device(dev); <answer> = 
<token> index = sattr->index; <answer> int 
int nr <token> sattr->nr; <answer> = 
<token> sprintf(buf, "%d\n", data->temp[index][nr] * 1000); <answer> return 
<token> ssize_t <answer> static 
<token> device *dev, struct device_attribute *attr, char *buf) <answer> show_temp_hyst(struct 
struct sensor_device_attribute *sattr <token> to_sensor_dev_attr(attr); <answer> = 
<token> nct6683_data *data = nct6683_update_device(dev); <answer> struct 
int nr <token> sattr->index; <answer> = 
int temp = data->temp[1][nr] <token> data->temp[2][nr]; <answer> - 
return sprintf(buf, "%d\n", temp * <token> <answer> 1000); 
static <token> <answer> ssize_t 
show_temp16(struct device *dev, struct device_attribute <token> char *buf) <answer> *attr, 
struct sensor_device_attribute *sattr = <token> <answer> to_sensor_dev_attr(attr); 
<token> nct6683_data *data = nct6683_update_device(dev); <answer> struct 
int index <token> sattr->index; <answer> = 
return sprintf(buf, "%d\n", (data->temp_in[index] / 128) * <token> <answer> 500); 
static int <token> src) <answer> get_temp_type(u8 
if (src >= 0x02 && <token> <= 0x07) <answer> src 
if ((nr == 2 <token> nr == 4) && <answer> || 
<token> == NCT6683_CUSTOMER_ID_INTEL) <answer> data->customer_id 
<token> 0; <answer> return 
if (nr == 6 && <token> == 0) <answer> get_temp_type(data->temp_src[temp]) 
static struct sensor_device_template *nct6683_attributes_temp_template[] <token> { <answer> = 
ret <token> superio_enter(data->sioreg); <answer> = 
if <token> { <answer> (ret) 
<token> = ret; <answer> count 
<token> error; <answer> goto 
superio_select(data->sioreg, <token> <answer> NCT6683_LD_ACPI); 
<token> = superio_inb(data->sioreg, NCT6683_REG_CR_CASEOPEN); <answer> reg 
reg |= <token> <answer> NCT6683_CR_CASEOPEN_MASK; 
superio_outb(data->sioreg, NCT6683_REG_CR_CASEOPEN, <token> <answer> reg); 
reg &= <token> <answer> ~NCT6683_CR_CASEOPEN_MASK; 
superio_outb(data->sioreg, <token> reg); <answer> NCT6683_REG_CR_CASEOPEN, 
<token> void <answer> static 
nct6683_setup_fans(struct <token> *data) <answer> nct6683_data 
int <token> <answer> i; 
<token> reg; <answer> u8 
for (i = <token> i < NCT6683_NUM_REG_FAN; i++) { <answer> 0; 
<token> = nct6683_read(data, NCT6683_REG_FANIN_CFG(i)); <answer> reg 
if (reg <token> 0x80) <answer> & 
data->have_fan |= 1 <token> i; <answer> << 
data->fanin_cfg[i] = <token> <answer> reg; 
for (i = 0; i < NCT6683_NUM_REG_PWM; <token> { <answer> i++) 
reg = nct6683_read(data, <token> <answer> NCT6683_REG_FANOUT_CFG(i)); 
if <token> & 0x80) <answer> (reg 
data->have_pwm |= 1 << <token> <answer> i; 
data->fanout_cfg[i] <token> reg; <answer> = 
static <token> nct6683_setup_sensors(struct nct6683_data *data) <answer> void 
<token> reg; <answer> u8 
int <token> <answer> i; 
data->temp_num <token> 0; <answer> = 
<token> = 0; <answer> data->in_num 
<token> (i = 0; i < NCT6683_NUM_REG_MON; i++) { <answer> for 
reg = nct6683_read(data, <token> & 0x7f; <answer> NCT6683_REG_MON_CFG(i)) 
static struct <token> *pdev[2]; <answer> platform_device 
static int __init <token> <answer> sensors_nct6683_init(void) 
<token> nct6683_sio_data sio_data; <answer> struct 
int sioaddr[2] = { 0x2e, <token> }; <answer> 0x4e 
struct <token> res; <answer> resource 
bool found <token> false; <answer> = 
int <token> <answer> address; 
<token> i, err; <answer> int 
err <token> platform_driver_register(&nct6683_driver); <answer> = 
if <token> <answer> (err) 
return <token> <answer> err; 
for <token> = 0; i < ARRAY_SIZE(pdev); i++) { <answer> (i 
<token> = nct6683_find(sioaddr[i], &sio_data); <answer> address 
if (address <= <token> <answer> 0) 
found = <token> <answer> true; 
pdev[i] = <token> address); <answer> platform_device_alloc(DRVNAME, 
if <token> { <answer> (!pdev[i]) 
<token> = -ENOMEM; <answer> err 
<token> exit_device_unregister; <answer> goto 
<token> = platform_device_add_data(pdev[i], &sio_data, <answer> err 
<token> nct6683_sio_data)); <answer> sizeof(struct 
if <token> <answer> (err) 
<token> exit_device_put; <answer> goto 
<token> 0, sizeof(res)); <answer> memset(&res, 
<token> = DRVNAME; <answer> res.name 
res.start = <token> + IOREGION_OFFSET; <answer> address 
res.end = <token> + IOREGION_OFFSET + IOREGION_LENGTH - 1; <answer> address 
<token> = IORESOURCE_IO; <answer> res.flags 
err <token> acpi_check_resource_conflict(&res); <answer> = 
<token> (err) { <answer> if 
pdev[i] = <token> <answer> NULL; 
err = <token> &res, 1); <answer> platform_device_add_resources(pdev[i], 
<token> (err) <answer> if 
goto <token> <answer> exit_device_put; 
<token> <linux/types.h> <answer> #include 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/time.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/poll.h> <answer> #include 
<token> <linux/proc_fs.h> <answer> #include 
#include <token> <answer> <linux/fs.h> 
<token> <linux/syslog.h> <answer> #include 
<token> <asm/io.h> <answer> #include 
static int kmsg_open(struct inode * inode, <token> file * file) <answer> struct 
return do_syslog(SYSLOG_ACTION_OPEN, NULL, 0, <token> <answer> SYSLOG_FROM_PROC); 
<token> int kmsg_release(struct inode * inode, struct file * file) <answer> static 
(void) do_syslog(SYSLOG_ACTION_CLOSE, NULL, <token> SYSLOG_FROM_PROC); <answer> 0, 
<token> 0; <answer> return 
static <token> kmsg_read(struct file *file, char __user *buf, <answer> ssize_t 
size_t <token> loff_t *ppos) <answer> count, 
if ((file->f_flags & <token> && <answer> O_NONBLOCK) 
!do_syslog(SYSLOG_ACTION_SIZE_UNREAD, NULL, <token> SYSLOG_FROM_PROC)) <answer> 0, 
<token> -EAGAIN; <answer> return 
<token> do_syslog(SYSLOG_ACTION_READ, buf, count, SYSLOG_FROM_PROC); <answer> return 
static __poll_t kmsg_poll(struct file *file, poll_table <token> <answer> *wait) 
poll_wait(file, <token> wait); <answer> &log_wait, 
if (do_syslog(SYSLOG_ACTION_SIZE_UNREAD, NULL, <token> SYSLOG_FROM_PROC)) <answer> 0, 
return <token> | EPOLLRDNORM; <answer> EPOLLIN 
<token> 0; <answer> return 
<token> const struct proc_ops kmsg_proc_ops = { <answer> static 
<token> = PROC_ENTRY_PERMANENT, <answer> .proc_flags 
.proc_read = <token> <answer> kmsg_read, 
.proc_poll <token> kmsg_poll, <answer> = 
.proc_open = <token> <answer> kmsg_open, 
.proc_release <token> kmsg_release, <answer> = 
<token> = generic_file_llseek, <answer> .proc_lseek 
static int __init <token> <answer> proc_kmsg_init(void) 
<token> S_IRUSR, NULL, &kmsg_proc_ops); <answer> proc_create("kmsg", 
<token> 0; <answer> return 
<token> _GNU_SOURCE <answer> #define 
<token> <errno.h> <answer> #include 
<token> <fcntl.h> <answer> #include 
<token> <sched.h> <answer> #include 
#include <token> <answer> <signal.h> 
<token> <stdbool.h> <answer> #include 
<token> <stdio.h> <answer> #include 
<token> <string.h> <answer> #include 
#include <token> <answer> <unistd.h> 
#include <token> <answer> <sys/ptrace.h> 
#include <token> <answer> <sys/stat.h> 
#include <token> <answer> <sys/timerfd.h> 
#include <token> <answer> <sys/types.h> 
#include <token> <answer> <sys/wait.h> 
#include <token> <answer> "../kselftest.h" 
<token> child(int cpu) <answer> void 
<token> set; <answer> cpu_set_t 
<token> &set); <answer> CPU_SET(cpu, 
if (sched_setaffinity(0, sizeof(set), <token> != 0) { <answer> &set) 
<token> failed: %s\n", <answer> ksft_print_msg("sched_setaffinity() 
if (ptrace(PTRACE_TRACEME, 0, NULL, NULL) <token> 0) { <answer> != 
ksft_print_msg("ptrace(PTRACE_TRACEME) failed: <token> <answer> %s\n", 
if <token> != 0) { <answer> (raise(SIGSTOP) 
ksft_print_msg("raise(SIGSTOP) <token> %s\n", strerror(errno)); <answer> failed: 
<token> run_test(int cpu) <answer> int 
int <token> <answer> status; 
pid_t pid = <token> <answer> fork(); 
<token> wpid; <answer> pid_t 
<token> (pid < 0) { <answer> if 
ksft_print_msg("fork() <token> %s\n", strerror(errno)); <answer> failed: 
return <token> <answer> KSFT_FAIL; 
if (pid <token> 0) <answer> == 
wpid = <token> &status, __WALL); <answer> waitpid(pid, 
if (wpid != <token> { <answer> pid) 
ksft_print_msg("waitpid() <token> %s\n", strerror(errno)); <answer> failed: 
return <token> <answer> KSFT_FAIL; 
if <token> { <answer> (!WIFSTOPPED(status)) 
ksft_print_msg("child did not stop: %s\n", <token> <answer> strerror(errno)); 
<token> KSFT_FAIL; <answer> return 
if (WSTOPSIG(status) != <token> { <answer> SIGSTOP) 
ksft_print_msg("child did not stop with <token> %s\n", <answer> SIGSTOP: 
return <token> <answer> KSFT_FAIL; 
if (ptrace(PTRACE_SINGLESTEP, pid, NULL, NULL) < 0) <token> <answer> { 
<token> (errno == EIO) { <answer> if 
"ptrace(PTRACE_SINGLESTEP) not supported <token> this architecture: %s\n", <answer> on 
<token> KSFT_SKIP; <answer> return 
ksft_print_msg("ptrace(PTRACE_SINGLESTEP) <token> %s\n", <answer> failed: 
return <token> <answer> KSFT_FAIL; 
wpid <token> waitpid(pid, &status, __WALL); <answer> = 
if (wpid <token> pid) { <answer> != 
ksft_print_msg("waitpid() failed: <token> strerror(errno)); <answer> %s\n", 
<token> KSFT_FAIL; <answer> return 
if <token> { <answer> (WIFEXITED(status)) 
ksft_print_msg("child <token> not single-step: %s\n", <answer> did 
<token> KSFT_FAIL; <answer> return 
<token> (!WIFSTOPPED(status)) { <answer> if 
ksft_print_msg("child did not stop: <token> strerror(errno)); <answer> %s\n", 
return <token> <answer> KSFT_FAIL; 
if (WSTOPSIG(status) <token> SIGTRAP) { <answer> != 
ksft_print_msg("child did not stop with SIGTRAP: <token> <answer> %s\n", 
return <token> <answer> KSFT_FAIL; 
if (ptrace(PTRACE_CONT, pid, NULL, NULL) < 0) <token> <answer> { 
ksft_print_msg("ptrace(PTRACE_CONT) <token> %s\n", <answer> failed: 
<token> KSFT_FAIL; <answer> return 
wpid = waitpid(pid, &status, <token> <answer> __WALL); 
if <token> != pid) { <answer> (wpid 
ksft_print_msg("waitpid() failed: %s\n", <token> <answer> strerror(errno)); 
<token> KSFT_FAIL; <answer> return 
if <token> { <answer> (!WIFEXITED(status)) 
ksft_print_msg("child did <token> exit after PTRACE_CONT: %s\n", <answer> not 
<token> KSFT_FAIL; <answer> return 
return <token> <answer> KSFT_PASS; 
<token> suspend(void) <answer> void 
int <token> <answer> power_state_fd; 
<token> sigevent event = {}; <answer> struct 
int <token> <answer> timerfd; 
<token> err; <answer> int 
struct itimerspec spec = <token> <answer> {}; 
if <token> != 0) <answer> (getuid() 
ksft_exit_skip("Please run the <token> as root - Exiting.\n"); <answer> test 
power_state_fd = <token> O_RDWR); <answer> open("/sys/power/state", 
<token> (power_state_fd < 0) <answer> if 
"open(\"/sys/power/state\") <token> %s)\n", <answer> failed 
timerfd = timerfd_create(CLOCK_BOOTTIME_ALARM, <token> <answer> 0); 
if (timerfd <token> 0) <answer> < 
ksft_exit_fail_msg("timerfd_create() <token> <answer> failed\n"); 
spec.it_value.tv_sec <token> 5; <answer> = 
err <token> timerfd_settime(timerfd, 0, &spec, NULL); <answer> = 
if (err <token> 0) <answer> < 
<token> failed\n"); <answer> ksft_exit_fail_msg("timerfd_settime() 
if (write(power_state_fd, <token> strlen("mem")) != strlen("mem")) <answer> "mem", 
ksft_exit_fail_msg("Failed to enter Suspend <token> <answer> state\n"); 
<token> main(int argc, char **argv) <answer> int 
<token> opt; <answer> int 
bool do_suspend = <token> <answer> true; 
bool <token> = true; <answer> succeeded 
<token> int tests = 0; <answer> unsigned 
<token> available_cpus; <answer> cpu_set_t 
int <token> <answer> err; 
<token> cpu; <answer> int 
while ((opt = getopt(argc, argv, <token> != -1) { <answer> "n")) 
switch (opt) <token> <answer> { 
case <token> <answer> 'n': 
do_suspend = <token> <answer> false; 
printf("Usage: %s <token> argv[0]); <answer> [-n]\n", 
printf(" <token> do not trigger a suspend/resume cycle before the test\n"); <answer> -n: 
return <token> <answer> -1; 
err <token> sched_getaffinity(0, sizeof(available_cpus), &available_cpus); <answer> = 
if (err < <token> <answer> 0) 
<token> failed\n"); <answer> ksft_exit_fail_msg("sched_getaffinity() 
for (cpu = 0; cpu < <token> cpu++) { <answer> CPU_SETSIZE; 
if (!CPU_ISSET(cpu, <token> <answer> &available_cpus)) 
<token> (do_suspend) <answer> if 
for (cpu = 0; cpu < CPU_SETSIZE; cpu++) <token> <answer> { 
<token> test_success; <answer> int 
if <token> &available_cpus)) <answer> (!CPU_ISSET(cpu, 
test_success = <token> <answer> run_test(cpu); 
<token> (test_success) { <answer> switch 
case <token> <answer> KSFT_PASS: 
ksft_test_result_pass("CPU %d\n", <token> <answer> cpu); 
case <token> <answer> KSFT_SKIP: 
<token> %d\n", cpu); <answer> ksft_test_result_skip("CPU 
<token> KSFT_FAIL: <answer> case 
ksft_test_result_fail("CPU <token> cpu); <answer> %d\n", 
succeeded = <token> <answer> false; 
if <token> <answer> (succeeded) 
#include <token> <answer> "priv.h" 
#include <token> <answer> <subdev/gsp.h> 
#include <token> <answer> <nvif/class.h> 
<token> const struct nvkm_intr_data <answer> static 
ga100_vfn_intrs[] = <token> <answer> { 
{ NVKM_ENGINE_DISP , 0, 4, 0x04000000, true <token> <answer> }, 
{ NVKM_SUBDEV_GPIO , <token> 4, 0x00200000, true }, <answer> 0, 
{ NVKM_SUBDEV_I2C , <token> 4, 0x00200000, true }, <answer> 0, 
<token> NVKM_SUBDEV_PRIVRING, 0, 4, 0x40000000, true }, <answer> { 
static const struct <token> <answer> nvkm_vfn_func 
ga100_vfn = <token> <answer> { 
.intr <token> &tu102_vfn_intr, <answer> = 
.intrs = <token> <answer> ga100_vfn_intrs, 
.user = { 0x030000, 0x010000, { <token> -1, AMPERE_USERMODE_A } }, <answer> -1, 
ga100_vfn_new(struct <token> *device, <answer> nvkm_device 
enum nvkm_subdev_type type, int <token> struct nvkm_vfn **pvfn) <answer> inst, 
<token> (nvkm_gsp_rm(device->gsp)) <answer> if 
return r535_vfn_new(&ga100_vfn, device, type, inst, 0xb80000, <token> <answer> pvfn); 
return nvkm_vfn_new_(&ga100_vfn, device, <token> inst, 0xb80000, pvfn); <answer> type, 
<token> DEBUG <answer> #undef 
<token> <linux/irq.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
<token> <linux/of_address.h> <answer> #include 
<token> <linux/of_irq.h> <answer> #include 
#include <token> <answer> <asm/time.h> 
<token> <asm/machdep.h> <answer> #include 
<token> <asm/mpc52xx.h> <answer> #include 
<token> const struct of_device_id mpc5200_gpio_ids[] __initconst = { <answer> static 
{ .compatible = <token> }, <answer> "fsl,mpc5200-gpio", 
{ .compatible = <token> }, <answer> "mpc5200-gpio", 
<token> = in_be32(media5200_irq.regs + MEDIA5200_IRQ_ENABLE); <answer> status 
enable = <token> + MEDIA5200_IRQ_STATUS); <answer> in_be32(media5200_irq.regs 
val <token> ffs((status & enable) >> MEDIA5200_IRQ_SHIFT); <answer> = 
if <token> { <answer> (val) 
generic_handle_domain_irq(media5200_irq.irqhost, <token> - 1); <answer> val 
<token> void __init media5200_init_irq(void) <answer> static 
struct device_node <token> <answer> *fpga_np; 
int <token> <answer> cascade_virq; 
<token> void __init media5200_setup_arch(void) <answer> static 
<token> device_node *np; <answer> struct 
<token> mpc52xx_gpio __iomem *gpio; <answer> struct 
u32 <token> <answer> port_config; 
<token> (ppc_md.progress) <answer> if 
ppc_md.progress("media5200_setup_arch()", <token> <answer> 0); 
<token> "kfd_device_queue_manager.h" <answer> #include 
#include <token> <answer> "navi10_enum.h" 
#include <token> <answer> "gc/gc_10_1_0_offset.h" 
<token> "gc/gc_10_1_0_sh_mask.h" <answer> #include 
static <token> update_qpd_v10(struct device_queue_manager *dqm, <answer> int 
struct <token> *qpd); <answer> qcm_process_device 
<token> void init_sdma_vm_v10(struct device_queue_manager *dqm, struct queue *q, <answer> static 
<token> qcm_process_device *qpd); <answer> struct 
void <token> <answer> device_queue_manager_init_v10( 
<token> device_queue_manager_asic_ops *asic_ops) <answer> struct 
<token> = update_qpd_v10; <answer> asic_ops->update_qpd 
asic_ops->init_sdma_vm <token> init_sdma_vm_v10; <answer> = 
<token> = mqd_manager_init_v10; <answer> asic_ops->mqd_manager_init 
static uint32_t compute_sh_mem_bases_64bit(struct <token> *pdd) <answer> kfd_process_device 
uint32_t shared_base = pdd->lds_base >> <token> <answer> 48; 
<token> private_base = pdd->scratch_base >> 48; <answer> uint32_t 
return <token> << SH_MEM_BASES__SHARED_BASE__SHIFT) | <answer> (shared_base 
<token> int update_qpd_v10(struct device_queue_manager *dqm, <answer> static 
struct <token> *qpd) <answer> qcm_process_device 
<token> kfd_process_device *pdd; <answer> struct 
pdd = <token> <answer> qpd_to_pdd(qpd); 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/shdma-base.h> 
#include <token> <answer> <linux/dmaengine.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/pm_runtime.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
#include <token> <answer> "../dmaengine.h" 
static unsigned <token> slave_num = 256; <answer> int 
module_param(slave_num, uint, <token> <answer> 0444); 
if (chunk != desc && (chunk->mark <token> DESC_IDLE || <answer> == 
<token> > 0 || <answer> chunk->async_tx.cookie 
<token> == -EBUSY || <answer> chunk->async_tx.cookie 
&chunk->node == <token> <answer> &schan->ld_free)) 
chunk->mark <token> DESC_SUBMITTED; <answer> = 
<token> (chunk->chunks == 1) { <answer> if 
chunk->async_tx.callback = <token> <answer> callback; 
<token> = tx->callback_param; <answer> chunk->async_tx.callback_param 
<token> else { <answer> } 
ops->setup_xfer(schan, <token> <answer> schan->slave_id); 
<token> (schan->pm_state == SHDMA_PM_PENDING) <answer> if 
schan->pm_state = <token> <answer> SHDMA_PM_ESTABLISHED; 
<token> else { <answer> } 
<token> = SHDMA_PM_PENDING; <answer> schan->pm_state 
return <token> <answer> cookie; 
if (slave) <token> <answer> { 
bool shdma_chan_filter(struct dma_chan *chan, void <token> <answer> *arg) 
struct shdma_chan <token> <answer> *schan; 
<token> shdma_dev *sdev; <answer> struct 
int slave_id = <token> <answer> (long)arg; 
int <token> <answer> ret; 
if <token> { <answer> (schan->dev->of_node) 
ret <token> sdev->ops->set_slave(schan, slave_id, 0, true); <answer> = 
if <token> < 0) <answer> (ret 
<token> false; <answer> return 
<token> = schan->slave_id; <answer> schan->real_slave_id 
<token> true; <answer> return 
if (slave_id < <token> { <answer> 0) 
if (!all && desc->mark == DESC_SUBMITTED <token> <answer> && 
desc->cookie <token> cookie) <answer> != 
if <token> > 0) <answer> (tx->cookie 
cookie = <token> <answer> tx->cookie; 
if (desc->mark == DESC_COMPLETED <token> desc->chunks == 1) { <answer> && 
if <token> != desc->cookie - 1) <answer> (schan->dma_chan.completed_cookie 
<token> cookie %d, expected %d\n", <answer> "Completing 
schan->dma_chan.completed_cookie + <token> <answer> 1); 
schan->dma_chan.completed_cookie = <token> <answer> desc->cookie; 
schan->dma_chan.completed_cookie = <token> <answer> schan->dma_chan.cookie; 
list_splice_tail(&cyclic_list, <token> <answer> &schan->ld_queue); 
spin_unlock_irqrestore(&schan->chan_lock, <token> <answer> flags); 
dmaengine_desc_callback_invoke(&cb, <token> <answer> NULL); 
return <token> <answer> callback; 
static void shdma_chan_ld_cleanup(struct shdma_chan <token> bool all) <answer> *schan, 
while <token> all)) <answer> (__ld_cleanup(schan, 
static <token> shdma_free_chan_resources(struct dma_chan *chan) <answer> void 
struct shdma_chan *schan <token> to_shdma_chan(chan); <answer> = 
struct shdma_dev <token> = to_shdma_dev(chan->device); <answer> *sdev 
const struct shdma_ops *ops = <token> <answer> sdev->ops; 
static struct shdma_desc *shdma_add_desc(struct shdma_chan <token> <answer> *schan, 
unsigned long flags, dma_addr_t *dst, dma_addr_t *src, size_t <token> <answer> *len, 
struct <token> **first, enum dma_transfer_direction direction) <answer> shdma_desc 
struct shdma_dev *sdev <token> to_shdma_dev(schan->dma_chan.device); <answer> = 
const struct shdma_ops *ops = <token> <answer> sdev->ops; 
struct shdma_desc <token> <answer> *new; 
size_t copy_size = <token> <answer> *len; 
<token> (!copy_size) <answer> if 
<token> NULL; <answer> return 
<token> struct dma_async_tx_descriptor *shdma_prep_sg(struct shdma_chan *schan, <answer> static 
struct scatterlist *sgl, unsigned <token> sg_len, dma_addr_t *addr, <answer> int 
enum dma_transfer_direction direction, <token> long flags, bool cyclic) <answer> unsigned 
struct scatterlist <token> <answer> *sg; 
for_each_sg(sgl, sg, <token> i) { <answer> sg_len, 
<token> sg_addr = sg_dma_address(sg); <answer> dma_addr_t 
size_t len = <token> <answer> sg_dma_len(sg); 
if <token> <answer> (!len) 
goto <token> <answer> err_get_desc; 
do <token> <answer> { 
dev_dbg(schan->dev, <token> SG #%d@%p[%zu], dma %pad\n", <answer> "Add 
<token> sg, len, &sg_addr); <answer> i, 
if (direction <token> DMA_DEV_TO_MEM) <answer> == 
<token> = shdma_add_desc(schan, flags, <answer> new 
&sg_addr, addr, &len, <token> <answer> &first, 
new = <token> flags, <answer> shdma_add_desc(schan, 
addr, &sg_addr, <token> &first, <answer> &len, 
if <token> <answer> (!new) 
goto <token> <answer> err_get_desc; 
new->cyclic = <token> <answer> cyclic; 
<token> (cyclic) <answer> if 
<token> = 1; <answer> new->chunks 
<token> = chunks--; <answer> new->chunks 
list_add_tail(&new->node, <token> <answer> &tx_list); 
} while <token> <answer> (len); 
<token> (new != first) <answer> if 
<token> = -ENOSPC; <answer> new->async_tx.cookie 
<token> = kmalloc_array(sg_len, sizeof(*sgl), GFP_KERNEL); <answer> sgl 
if <token> <answer> (!sgl) 
<token> NULL; <answer> return 
<token> sg_len); <answer> sg_init_table(sgl, 
for (i <token> 0; i < sg_len; i++) { <answer> = 
dma_addr_t src = buf_addr + (period_len * <token> <answer> i); 
sg_set_page(&sgl[i], <token> period_len, <answer> pfn_to_page(PFN_DOWN(src)), 
sg_dma_address(&sgl[i]) <token> src; <answer> = 
sg_dma_len(&sgl[i]) = <token> <answer> period_len; 
<token> = shdma_prep_sg(schan, sgl, sg_len, &slave_addr, <answer> desc 
direction, <token> true); <answer> flags, 
<token> desc; <answer> return 
static int shdma_terminate_all(struct <token> *chan) <answer> dma_chan 
struct shdma_chan *schan <token> to_shdma_chan(chan); <answer> = 
struct <token> *sdev = to_shdma_dev(chan->device); <answer> shdma_dev 
const struct shdma_ops *ops <token> sdev->ops; <answer> = 
unsigned long <token> <answer> flags; 
spin_lock_irqsave(&schan->chan_lock, <token> <answer> flags); 
if (ops->get_partial <token> !list_empty(&schan->ld_queue)) { <answer> && 
if <token> <answer> (!config) 
return <token> <answer> -EINVAL; 
return <token> <answer> shdma_setup_slave(schan, 
config->direction == <token> ? <answer> DMA_DEV_TO_MEM 
config->src_addr : <token> <answer> config->dst_addr); 
static void shdma_issue_pending(struct dma_chan <token> <answer> *chan) 
struct shdma_chan *schan = <token> <answer> to_shdma_chan(chan); 
if (schan->pm_state <token> SHDMA_PM_ESTABLISHED) <answer> == 
schan->pm_state = <token> <answer> SHDMA_PM_PENDING; 
static <token> dma_status shdma_tx_status(struct dma_chan *chan, <answer> enum 
dma_cookie_t <token> <answer> cookie, 
<token> dma_tx_state *txstate) <answer> struct 
struct shdma_chan *schan <token> to_shdma_chan(chan); <answer> = 
enum <token> status; <answer> dma_status 
unsigned <token> flags; <answer> long 
shdma_chan_ld_cleanup(schan, <token> <answer> false); 
spin_lock_irqsave(&schan->chan_lock, <token> <answer> flags); 
<token> = dma_cookie_status(chan, cookie, txstate); <answer> status 
if <token> != DMA_COMPLETE) { <answer> (status 
struct <token> *sdesc; <answer> shdma_desc 
<token> = DMA_ERROR; <answer> status 
<token> &schan->ld_queue, node) <answer> list_for_each_entry(sdesc, 
<token> (sdesc->cookie == cookie) { <answer> if 
<token> = DMA_IN_PROGRESS; <answer> status 
<token> flags); <answer> spin_unlock_irqrestore(&schan->chan_lock, 
return <token> <answer> status; 
if (!sdev->ops <token> <answer> || 
<token> || <answer> !sdev->desc_size 
<token> || <answer> !sdev->ops->embedded_desc 
<token> || <answer> !sdev->ops->start_xfer 
<token> || <answer> !sdev->ops->setup_xfer 
!sdev->ops->set_slave <token> <answer> || 
<token> || <answer> !sdev->ops->desc_setup 
!sdev->ops->slave_addr <token> <answer> || 
<token> || <answer> !sdev->ops->channel_busy 
!sdev->ops->halt_channel <token> <answer> || 
return <token> <answer> -EINVAL; 
<token> = kcalloc(chan_num, sizeof(*sdev->schan), GFP_KERNEL); <answer> sdev->schan 
if <token> <answer> (!sdev->schan) 
<token> -ENOMEM; <answer> return 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/mfd/madera/core.h> 
#include <token> <answer> "pinctrl-madera.h" 
static const unsigned int cs47l15_aif1_pins[] = { 0, <token> 2, 3 }; <answer> 1, 
<token> const unsigned int cs47l15_aif2_pins[] = { 4, 5, 6, 7 }; <answer> static 
static const unsigned int cs47l15_aif3_pins[] = <token> 8, 9, 10, 11 }; <answer> { 
static const unsigned int <token> = { 12, 13, 14 }; <answer> cs47l15_spk1_pins[] 
static const struct madera_pin_groups <token> = { <answer> cs47l15_pin_groups[] 
<token> "aif1", cs47l15_aif1_pins, ARRAY_SIZE(cs47l15_aif1_pins) }, <answer> { 
<token> "aif2", cs47l15_aif2_pins, ARRAY_SIZE(cs47l15_aif2_pins) }, <answer> { 
{ "aif3", cs47l15_aif3_pins, <token> }, <answer> ARRAY_SIZE(cs47l15_aif3_pins) 
{ "pdmspk1", cs47l15_spk1_pins, <token> }, <answer> ARRAY_SIZE(cs47l15_spk1_pins) 
<token> struct madera_pin_chip cs47l15_pin_chip = { <answer> const 
.n_pins = <token> <answer> CS47L15_NUM_GPIOS, 
.pin_groups = <token> <answer> cs47l15_pin_groups, 
.n_pin_groups <token> ARRAY_SIZE(cs47l15_pin_groups), <answer> = 
<token> <net/mac80211.h> <answer> #include 
<token> "ieee80211_i.h" <answer> #include 
<token> "trace.h" <answer> #include 
<token> "driver-ops.h" <answer> #include 
<token> "debugfs_sta.h" <answer> #include 
<token> "debugfs_netdev.h" <answer> #include 
int drv_start(struct <token> *local) <answer> ieee80211_local 
<token> ret; <answer> int 
if <token> <answer> (WARN_ON(local->started)) 
<token> -EALREADY; <answer> return 
local->started <token> true; <answer> = 
"%s: <token> CW_min/CW_max: %d/%d\n", <answer> invalid 
sdata->name, <token> params->cw_max); <answer> params->cw_min, 
<token> -EINVAL; <answer> return 
trace_drv_conf_tx(local, <token> link->link_id, ac, params); <answer> sdata, 
<token> (local->ops->conf_tx) <answer> if 
ret <token> local->ops->conf_tx(&local->hw, &sdata->vif, <answer> = 
<token> ac, params); <answer> link->link_id, 
trace_drv_return_int(local, <token> <answer> ret); 
<token> ret; <answer> return 
u64 drv_get_tsf(struct ieee80211_local <token> <answer> *local, 
struct <token> *sdata) <answer> ieee80211_sub_if_data 
u64 ret <token> -1ULL; <answer> = 
<token> (!check_sdata_in_driver(sdata)) <answer> if 
return <token> <answer> ret; 
trace_drv_get_tsf(local, <token> <answer> sdata); 
<token> (local->ops->get_tsf) <answer> if 
ret = local->ops->get_tsf(&local->hw, <token> <answer> &sdata->vif); 
<token> ret); <answer> trace_drv_return_u64(local, 
return <token> <answer> ret; 
void drv_set_tsf(struct <token> *local, <answer> ieee80211_local 
<token> ieee80211_sub_if_data *sdata, <answer> struct 
<token> tsf) <answer> u64 
if <token> <answer> (!check_sdata_in_driver(sdata)) 
<token> sdata, tsf); <answer> trace_drv_set_tsf(local, 
if <token> <answer> (local->ops->set_tsf) 
local->ops->set_tsf(&local->hw, &sdata->vif, <token> <answer> tsf); 
void <token> ieee80211_local *local, <answer> drv_offset_tsf(struct 
struct ieee80211_sub_if_data <token> <answer> *sdata, 
s64 <token> <answer> offset) 
if <token> <answer> (!check_sdata_in_driver(sdata)) 
<token> sdata, offset); <answer> trace_drv_offset_tsf(local, 
if <token> <answer> (local->ops->offset_tsf) 
local->ops->offset_tsf(&local->hw, <token> offset); <answer> &sdata->vif, 
void drv_reset_tsf(struct ieee80211_local <token> <answer> *local, 
struct <token> *sdata) <answer> ieee80211_sub_if_data 
if <token> <answer> (!check_sdata_in_driver(sdata)) 
trace_drv_reset_tsf(local, <token> <answer> sdata); 
<token> (local->ops->reset_tsf) <answer> if 
<token> &sdata->vif); <answer> local->ops->reset_tsf(&local->hw, 
int drv_assign_vif_chanctx(struct ieee80211_local <token> <answer> *local, 
struct <token> *sdata, <answer> ieee80211_sub_if_data 
struct ieee80211_bss_conf <token> <answer> *link_conf, 
struct ieee80211_chanctx <token> <answer> *ctx) 
int ret = <token> <answer> 0; 
if <token> <answer> (!check_sdata_in_driver(sdata)) 
<token> -EIO; <answer> return 
<token> (!ieee80211_vif_link_active(&sdata->vif, link_conf->link_id)) <answer> if 
<token> 0; <answer> return 
trace_drv_assign_vif_chanctx(local, <token> link_conf, ctx); <answer> sdata, 
<token> (local->ops->assign_vif_chanctx) { <answer> if 
ret = <token> <answer> local->ops->assign_vif_chanctx(&local->hw, 
<token> ret); <answer> trace_drv_return_int(local, 
<token> ret; <answer> return 
void drv_unassign_vif_chanctx(struct ieee80211_local <token> <answer> *local, 
<token> ieee80211_sub_if_data *sdata, <answer> struct 
<token> ieee80211_bss_conf *link_conf, <answer> struct 
<token> ieee80211_chanctx *ctx) <answer> struct 
if <token> <answer> (!check_sdata_in_driver(sdata)) 
if (!ieee80211_vif_link_active(&sdata->vif, <token> <answer> link_conf->link_id)) 
trace_drv_unassign_vif_chanctx(local, sdata, <token> ctx); <answer> link_conf, 
if <token> { <answer> (local->ops->unassign_vif_chanctx) 
int drv_switch_vif_chanctx(struct ieee80211_local <token> <answer> *local, 
struct <token> *vifs, <answer> ieee80211_vif_chanctx_switch 
int n_vifs, enum <token> mode) <answer> ieee80211_chanctx_switch_mode 
int <token> = 0; <answer> ret 
<token> i; <answer> int 
if <token> <answer> (!local->ops->switch_vif_chanctx) 
return <token> <answer> -EOPNOTSUPP; 
for (i = 0; <token> < n_vifs; i++) { <answer> i 
struct ieee80211_chanctx *new_ctx <token> <answer> = 
struct <token> <answer> ieee80211_chanctx, 
struct ieee80211_chanctx <token> = <answer> *old_ctx 
<token> ieee80211_chanctx, <answer> struct 
WARN_ON_ONCE((mode == CHANCTX_SWMODE_SWAP_CONTEXTS <token> <answer> && 
<token> || <answer> new_ctx->driver_present) 
(mode == CHANCTX_SWMODE_REASSIGN_VIF <token> <answer> && 
trace_drv_switch_vif_chanctx(local, vifs, <token> mode); <answer> n_vifs, 
ret = <token> <answer> local->ops->switch_vif_chanctx(&local->hw, 
vifs, <token> mode); <answer> n_vifs, 
<token> ret); <answer> trace_drv_return_int(local, 
if (!ret && mode == <token> { <answer> CHANCTX_SWMODE_SWAP_CONTEXTS) 
for (i = 0; <token> < n_vifs; i++) { <answer> i 
struct <token> *new_ctx = <answer> ieee80211_chanctx 
<token> ieee80211_chanctx, <answer> struct 
struct <token> *old_ctx = <answer> ieee80211_chanctx 
struct <token> <answer> ieee80211_chanctx, 
new_ctx->driver_present <token> true; <answer> = 
old_ctx->driver_present <token> false; <answer> = 
return <token> <answer> ret; 
int drv_ampdu_action(struct ieee80211_local <token> <answer> *local, 
struct <token> *sdata, <answer> ieee80211_sub_if_data 
<token> ieee80211_ampdu_params *params) <answer> struct 
int ret = <token> <answer> -EOPNOTSUPP; 
sdata <token> get_bss_sdata(sdata); <answer> = 
<token> (!check_sdata_in_driver(sdata)) <answer> if 
<token> -EIO; <answer> return 
<token> sdata, params); <answer> trace_drv_ampdu_action(local, 
if <token> <answer> (local->ops->ampdu_action) 
ret <token> local->ops->ampdu_action(&local->hw, &sdata->vif, params); <answer> = 
trace_drv_return_int(local, <token> <answer> ret); 
<token> ret; <answer> return 
void <token> ieee80211_local *local, <answer> drv_link_info_changed(struct 
struct <token> *sdata, <answer> ieee80211_sub_if_data 
struct <token> *info, <answer> ieee80211_bss_conf 
int link_id, <token> changed) <answer> u64 
if (WARN_ON_ONCE(changed & (BSS_CHANGED_BEACON <token> <answer> | 
BSS_CHANGED_BEACON_ENABLED) <token> <answer> && 
sdata->vif.type <token> NL80211_IFTYPE_AP && <answer> != 
sdata->vif.type != <token> && <answer> NL80211_IFTYPE_ADHOC 
<token> != NL80211_IFTYPE_MESH_POINT && <answer> sdata->vif.type 
<token> != NL80211_IFTYPE_OCB)) <answer> sdata->vif.type 
if (WARN_ON_ONCE(sdata->vif.type == NL80211_IFTYPE_P2P_DEVICE <token> <answer> || 
<token> == NL80211_IFTYPE_NAN || <answer> sdata->vif.type 
<token> == NL80211_IFTYPE_MONITOR && <answer> (sdata->vif.type 
<token> && <answer> !sdata->vif.bss_conf.mu_mimo_owner 
<token> & BSS_CHANGED_TXPOWER)))) <answer> !(changed 
if <token> <answer> (!check_sdata_in_driver(sdata)) 
if (!ieee80211_vif_link_active(&sdata->vif, <token> <answer> link_id)) 
<token> sdata, info, changed); <answer> trace_drv_link_info_changed(local, 
if <token> <answer> (local->ops->link_info_changed) 
<token> &sdata->vif, <answer> local->ops->link_info_changed(&local->hw, 
<token> changed); <answer> info, 
else <token> (local->ops->bss_info_changed) <answer> if 
<token> &sdata->vif, <answer> local->ops->bss_info_changed(&local->hw, 
info, <token> <answer> changed); 
int <token> ieee80211_local *local, <answer> drv_set_key(struct 
enum set_key_cmd <token> <answer> cmd, 
struct ieee80211_sub_if_data <token> <answer> *sdata, 
struct <token> *sta, <answer> ieee80211_sta 
struct ieee80211_key_conf <token> <answer> *key) 
<token> ret; <answer> int 
<token> = get_bss_sdata(sdata); <answer> sdata 
<token> (!check_sdata_in_driver(sdata)) <answer> if 
return <token> <answer> -EIO; 
if (WARN_ON(key->link_id >= 0 && <token> && <answer> sdata->vif.active_links 
<token> & BIT(key->link_id)))) <answer> !(sdata->vif.active_links 
return <token> <answer> -ENOLINK; 
trace_drv_set_key(local, cmd, sdata, sta, <token> <answer> key); 
ret = <token> cmd, &sdata->vif, sta, key); <answer> local->ops->set_key(&local->hw, 
trace_drv_return_int(local, <token> <answer> ret); 
return <token> <answer> ret; 
int drv_change_vif_links(struct ieee80211_local <token> <answer> *local, 
<token> ieee80211_sub_if_data *sdata, <answer> struct 
<token> old_links, u16 new_links, <answer> u16 
<token> ieee80211_bss_conf *old[IEEE80211_MLD_MAX_NUM_LINKS]) <answer> struct 
struct <token> *link; <answer> ieee80211_link_data 
unsigned long <token> <answer> links_to_add; 
unsigned <token> links_to_rem; <answer> long 
<token> int link_id; <answer> unsigned 
int ret = <token> <answer> -EOPNOTSUPP; 
<token> (!check_sdata_in_driver(sdata)) <answer> if 
return <token> <answer> -EIO; 
if (old_links == <token> <answer> new_links) 
<token> 0; <answer> return 
links_to_add = ~old_links <token> new_links; <answer> & 
links_to_rem <token> old_links & ~new_links; <answer> = 
for_each_set_bit(link_id, &links_to_rem, IEEE80211_MLD_MAX_NUM_LINKS) <token> <answer> { 
<token> = rcu_access_pointer(sdata->link[link_id]); <answer> link 
trace_drv_change_vif_links(local, sdata, <token> new_links); <answer> old_links, 
<token> (local->ops->change_vif_links) <answer> if 
<token> = local->ops->change_vif_links(&local->hw, &sdata->vif, <answer> ret 
old_links, new_links, <token> <answer> old); 
<token> ret); <answer> trace_drv_return_int(local, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if (!local->in_reconfig && <token> { <answer> !local->resuming) 
<token> &links_to_add, <answer> for_each_set_bit(link_id, 
IEEE80211_MLD_MAX_NUM_LINKS) <token> <answer> { 
<token> = rcu_access_pointer(sdata->link[link_id]); <answer> link 
<token> 0; <answer> return 
int drv_change_sta_links(struct <token> *local, <answer> ieee80211_local 
struct <token> *sdata, <answer> ieee80211_sub_if_data 
struct <token> *sta, <answer> ieee80211_sta 
u16 old_links, <token> new_links) <answer> u16 
struct sta_info *info = container_of(sta, struct <token> sta); <answer> sta_info, 
struct <token> *link_sta; <answer> link_sta_info 
unsigned long <token> <answer> links_to_add; 
unsigned long <token> <answer> links_to_rem; 
<token> int link_id; <answer> unsigned 
<token> ret = -EOPNOTSUPP; <answer> int 
if <token> <answer> (!check_sdata_in_driver(sdata)) 
return <token> <answer> -EIO; 
old_links <token> sdata->vif.active_links; <answer> &= 
<token> &= sdata->vif.active_links; <answer> new_links 
if (old_links <token> new_links) <answer> == 
<token> 0; <answer> return 
links_to_add = <token> & new_links; <answer> ~old_links 
links_to_rem = old_links & <token> <answer> ~new_links; 
for_each_set_bit(link_id, &links_to_rem, IEEE80211_MLD_MAX_NUM_LINKS) <token> <answer> { 
<token> = rcu_dereference_protected(info->link[link_id], <answer> link_sta 
trace_drv_change_sta_links(local, <token> sta, old_links, new_links); <answer> sdata, 
<token> (local->ops->change_sta_links) <answer> if 
ret = local->ops->change_sta_links(&local->hw, <token> sta, <answer> &sdata->vif, 
<token> new_links); <answer> old_links, 
<token> ret); <answer> trace_drv_return_int(local, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
#define <token> "%s: " fmt, __func__ <answer> pr_fmt(fmt) 
<token> <linux/device.h> <answer> #include 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
<token> <linux/iopoll.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/mailbox_controller.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/of_irq.h> 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/property.h> <answer> #include 
<token> <linux/soc/ti/ti-msgmgr.h> <answer> #include 
#define Q_DATA_OFFSET(proxy, <token> reg) \ <answer> queue, 
((0x10000 * (proxy)) + (0x80 * (queue)) <token> ((reg) * 4)) <answer> + 
#define <token> ((queue) * 0x4) <answer> Q_STATE_OFFSET(queue) 
#define Q_STATE_ENTRY_COUNT_MASK <token> <answer> (0xFFF000) 
#define SPROXY_THREAD_OFFSET(tid) <token> * (tid)) <answer> (0x1000 
#define SPROXY_THREAD_DATA_OFFSET(tid, reg) <token> <answer> \ 
(SPROXY_THREAD_OFFSET(tid) + ((reg) * 0x4) + <token> <answer> 0x4) 
#define SPROXY_THREAD_STATUS_OFFSET(tid) <token> <answer> (SPROXY_THREAD_OFFSET(tid)) 
#define SPROXY_THREAD_STATUS_COUNT_MASK <token> <answer> (0xFF) 
<token> SPROXY_THREAD_CTRL_OFFSET(tid) (0x1000 + SPROXY_THREAD_OFFSET(tid)) <answer> #define 
#define SPROXY_THREAD_CTRL_DIR_MASK (0x1 << <token> <answer> 31) 
struct <token> { <answer> ti_msgmgr_valid_queue_desc 
u8 <token> <answer> queue_id; 
u8 <token> <answer> proxy_id; 
bool <token> <answer> is_tx; 
struct ti_msgmgr_desc <token> <answer> { 
<token> queue_count; <answer> u8 
<token> max_message_size; <answer> u8 
u8 <token> <answer> max_messages; 
u8 <token> <answer> data_first_reg; 
u8 <token> <answer> data_last_reg; 
u32 <token> <answer> status_cnt_mask; 
u32 <token> <answer> status_err_mask; 
<token> tx_polled; <answer> bool 
<token> tx_poll_timeout_ms; <answer> int 
<token> struct ti_msgmgr_valid_queue_desc *valid_queues; <answer> const 
const char <token> <answer> *data_region_name; 
const <token> *status_region_name; <answer> char 
<token> char *ctrl_region_name; <answer> const 
<token> num_valid_queues; <answer> int 
bool <token> <answer> is_sproxy; 
<token> ti_queue_inst { <answer> struct 
<token> name[30]; <answer> char 
<token> queue_id; <answer> u8 
u8 <token> <answer> proxy_id; 
<token> irq; <answer> int 
<token> is_tx; <answer> bool 
<token> __iomem *queue_buff_start; <answer> void 
void <token> *queue_buff_end; <answer> __iomem 
<token> __iomem *queue_state; <answer> void 
<token> __iomem *queue_ctrl; <answer> void 
<token> mbox_chan *chan; <answer> struct 
u32 <token> <answer> *rx_buff; 
bool <token> <answer> polled_rx_mode; 
struct <token> { <answer> ti_msgmgr_inst 
<token> device *dev; <answer> struct 
const <token> ti_msgmgr_desc *desc; <answer> struct 
<token> __iomem *queue_proxy_region; <answer> void 
void <token> *queue_state_debug_region; <answer> __iomem 
<token> __iomem *queue_ctrl_region; <answer> void 
<token> num_valid_queues; <answer> u8 
<token> ti_queue_inst *qinsts; <answer> struct 
<token> mbox_controller mbox; <answer> struct 
struct <token> *chans; <answer> mbox_chan 
<token> inline int <answer> static 
ti_msgmgr_queue_get_num_messages(const struct <token> *d, <answer> ti_msgmgr_desc 
struct ti_queue_inst <token> <answer> *qinst) 
u32 <token> <answer> val; 
<token> status_cnt_mask = d->status_cnt_mask; <answer> u32 
<token> = readl(qinst->queue_state) & status_cnt_mask; <answer> val 
val <token> __ffs(status_cnt_mask); <answer> >>= 
<token> val; <answer> return 
static inline bool <token> struct ti_msgmgr_desc *d, <answer> ti_msgmgr_queue_is_error(const 
struct <token> *qinst) <answer> ti_queue_inst 
u32 <token> <answer> val; 
val = readl(qinst->queue_state) <token> d->status_err_mask; <answer> & 
return val ? true : <token> <answer> false; 
static int ti_msgmgr_queue_rx_data(struct <token> *chan, struct ti_queue_inst *qinst, <answer> mbox_chan 
const <token> ti_msgmgr_desc *desc) <answer> struct 
<token> num_words; <answer> int 
struct <token> message; <answer> ti_msgmgr_message 
<token> __iomem *data_reg; <answer> void 
u32 <token> <answer> *word_data; 
<token> = desc->max_message_size; <answer> message.len 
message.buf <token> (u8 *)qinst->rx_buff; <answer> = 
for (data_reg <token> qinst->queue_buff_start, word_data = qinst->rx_buff, <answer> = 
num_words <token> (desc->max_message_size / sizeof(u32)); <answer> = 
<token> num_words--, data_reg += sizeof(u32), word_data++) <answer> num_words; 
*word_data <token> readl(data_reg); <answer> = 
<token> (void *)&message); <answer> mbox_chan_received_data(chan, 
<token> 0; <answer> return 
<token> int ti_msgmgr_queue_rx_poll_timeout(struct mbox_chan *chan, int timeout_us) <answer> static 
struct <token> *dev = chan->mbox->dev; <answer> device 
struct <token> *inst = dev_get_drvdata(dev); <answer> ti_msgmgr_inst 
struct <token> *qinst = chan->con_priv; <answer> ti_queue_inst 
const <token> ti_msgmgr_desc *desc = inst->desc; <answer> struct 
int <token> <answer> msg_count; 
<token> ret; <answer> int 
ret = <token> msg_count, <answer> readl_poll_timeout_atomic(qinst->queue_state, 
(msg_count <token> desc->status_cnt_mask), <answer> & 
<token> timeout_us); <answer> 10, 
if (ret <token> 0) <answer> != 
return <token> <answer> ret; 
<token> qinst, desc); <answer> ti_msgmgr_queue_rx_data(chan, 
<token> 0; <answer> return 
static irqreturn_t <token> irq, void *p) <answer> ti_msgmgr_queue_rx_interrupt(int 
<token> mbox_chan *chan = p; <answer> struct 
struct device *dev <token> chan->mbox->dev; <answer> = 
struct ti_msgmgr_inst *inst = <token> <answer> dev_get_drvdata(dev); 
<token> ti_queue_inst *qinst = chan->con_priv; <answer> struct 
const struct <token> *desc; <answer> ti_msgmgr_desc 
int <token> <answer> msg_count; 
if <token> { <answer> (WARN_ON(!inst)) 
dev_err(dev, "no <token> drv data??\n"); <answer> platform 
return <token> <answer> -EINVAL; 
static bool ti_msgmgr_queue_peek_data(struct mbox_chan <token> <answer> *chan) 
struct ti_queue_inst *qinst <token> chan->con_priv; <answer> = 
struct device <token> = chan->mbox->dev; <answer> *dev 
<token> ti_msgmgr_inst *inst = dev_get_drvdata(dev); <answer> struct 
const struct <token> *desc = inst->desc; <answer> ti_msgmgr_desc 
int <token> <answer> msg_count; 
if <token> <answer> (qinst->is_tx) 
<token> false; <answer> return 
if <token> qinst)) { <answer> (ti_msgmgr_queue_is_error(desc, 
dev_err(dev, "Error <token> channel %s\n", qinst->name); <answer> on 
<token> false; <answer> return 
msg_count <token> ti_msgmgr_queue_get_num_messages(desc, qinst); <answer> = 
return <token> ? true : false; <answer> msg_count 
static bool ti_msgmgr_last_tx_done(struct mbox_chan <token> <answer> *chan) 
struct ti_queue_inst *qinst <token> chan->con_priv; <answer> = 
struct <token> *dev = chan->mbox->dev; <answer> device 
struct ti_msgmgr_inst *inst <token> dev_get_drvdata(dev); <answer> = 
const struct <token> *desc = inst->desc; <answer> ti_msgmgr_desc 
int <token> <answer> msg_count; 
<token> (!qinst->is_tx) <answer> if 
return <token> <answer> false; 
if (ti_msgmgr_queue_is_error(desc, qinst)) <token> <answer> { 
dev_err(dev, "Error on channel %s\n", <token> <answer> qinst->name); 
return <token> <answer> false; 
msg_count = <token> qinst); <answer> ti_msgmgr_queue_get_num_messages(desc, 
if <token> { <answer> (desc->is_sproxy) 
static int ti_msgmgr_send_data(struct mbox_chan *chan, void <token> <answer> *data) 
<token> device *dev = chan->mbox->dev; <answer> struct 
struct ti_msgmgr_inst <token> = dev_get_drvdata(dev); <answer> *inst 
const struct ti_msgmgr_desc <token> <answer> *desc; 
struct <token> *qinst = chan->con_priv; <answer> ti_queue_inst 
<token> num_words, trail_bytes; <answer> int 
<token> ti_msgmgr_message *message = data; <answer> struct 
void __iomem <token> <answer> *data_reg; 
<token> *word_data; <answer> u32 
<token> ret = 0; <answer> int 
<token> (WARN_ON(!inst)) { <answer> if 
<token> "no platform drv data??\n"); <answer> dev_err(dev, 
return <token> <answer> -EINVAL; 
desc <token> inst->desc; <answer> = 
if <token> qinst)) { <answer> (ti_msgmgr_queue_is_error(desc, 
dev_err(dev, "Error on <token> %s\n", qinst->name); <answer> channel 
<token> false; <answer> return 
if (desc->max_message_size < message->len) <token> <answer> { 
dev_err(dev, "Queue %s message length %zu > max <token> <answer> %d\n", 
qinst->name, <token> desc->max_message_size); <answer> message->len, 
return <token> <answer> -EINVAL; 
<token> (data_reg <= qinst->queue_buff_end) { <answer> while 
writel(0, <token> <answer> data_reg); 
<token> += sizeof(u32); <answer> data_reg 
static int <token> device *dev, <answer> ti_msgmgr_queue_rx_irq_req(struct 
const struct ti_msgmgr_desc <token> <answer> *d, 
<token> ti_queue_inst *qinst, <answer> struct 
struct mbox_chan <token> <answer> *chan) 
<token> ret = 0; <answer> int 
char <token> <answer> of_rx_irq_name[7]; 
struct device_node <token> <answer> *np; 
<token> sizeof(of_rx_irq_name), <answer> snprintf(of_rx_irq_name, 
"rx_%03d", <token> ? qinst->proxy_id : qinst->queue_id); <answer> d->is_sproxy 
static int ti_msgmgr_queue_startup(struct mbox_chan <token> <answer> *chan) 
<token> device *dev = chan->mbox->dev; <answer> struct 
struct ti_msgmgr_inst *inst <token> dev_get_drvdata(dev); <answer> = 
<token> ti_queue_inst *qinst = chan->con_priv; <answer> struct 
const struct ti_msgmgr_desc <token> = inst->desc; <answer> *d 
<token> ret; <answer> int 
int <token> <answer> msg_count; 
if <token> { <answer> (d->is_sproxy) 
<token> = (readl(qinst->queue_ctrl) & <answer> qinst->is_tx 
<token> ? false : true; <answer> SPROXY_THREAD_CTRL_DIR_MASK) 
msg_count <token> ti_msgmgr_queue_get_num_messages(d, qinst); <answer> = 
if <token> && qinst->is_tx) { <answer> (!msg_count 
<token> "%s: Cannot transmit with 0 credits!\n", <answer> dev_err(dev, 
<token> -EINVAL; <answer> return 
if (!qinst->is_tx) <token> <answer> { 
static void ti_msgmgr_queue_shutdown(struct <token> *chan) <answer> mbox_chan 
struct ti_queue_inst <token> = chan->con_priv; <answer> *qinst 
if (!qinst->is_tx) <token> <answer> { 
<token> chan); <answer> free_irq(qinst->irq, 
<token> struct mbox_chan *ti_msgmgr_of_xlate(struct mbox_controller *mbox, <answer> static 
const <token> of_phandle_args *p) <answer> struct 
<token> ti_msgmgr_inst *inst; <answer> struct 
int req_qid, <token> <answer> req_pid; 
<token> ti_queue_inst *qinst; <answer> struct 
const struct ti_msgmgr_desc <token> <answer> *d; 
<token> i, ncells; <answer> int 
inst <token> container_of(mbox, struct ti_msgmgr_inst, mbox); <answer> = 
<token> (WARN_ON(!inst)) <answer> if 
return <token> <answer> ERR_PTR(-EINVAL); 
<token> = inst->desc; <answer> d 
<token> (d->is_sproxy) <answer> if 
ncells <token> 1; <answer> = 
ncells = <token> <answer> 2; 
if (p->args_count != <token> { <answer> ncells) 
dev_err(inst->dev, "Invalid arguments in dt[%d]. Must be <token> <answer> %d\n", 
<token> ncells); <answer> p->args_count, 
return <token> <answer> ERR_PTR(-EINVAL); 
if (ncells == 1) <token> <answer> { 
req_qid <token> 0; <answer> = 
req_pid <token> p->args[0]; <answer> = 
<token> else { <answer> } 
req_qid <token> p->args[0]; <answer> = 
<token> = p->args[1]; <answer> req_pid 
<token> (d->is_sproxy) { <answer> if 
if (req_pid <token> d->num_valid_queues) <answer> >= 
goto <token> <answer> err; 
qinst = <token> <answer> &inst->qinsts[req_pid]; 
<token> qinst->chan; <answer> return 
for (qinst = inst->qinsts, i = <token> i < inst->num_valid_queues; <answer> 0; 
<token> qinst++) { <answer> i++, 
if (req_qid == qinst->queue_id && req_pid == <token> <answer> qinst->proxy_id) 
<token> qinst->chan; <answer> return 
dev_err(inst->dev, "Queue ID %d, Proxy ID %d <token> wrong on %pOFn\n", <answer> is 
<token> req_pid, p->np); <answer> req_qid, 
return <token> <answer> ERR_PTR(-ENOENT); 
static int ti_msgmgr_queue_setup(int <token> struct device *dev, <answer> idx, 
<token> device_node *np, <answer> struct 
<token> ti_msgmgr_inst *inst, <answer> struct 
const <token> ti_msgmgr_desc *d, <answer> struct 
<token> struct ti_msgmgr_valid_queue_desc *qd, <answer> const 
<token> ti_queue_inst *qinst, <answer> struct 
struct mbox_chan <token> <answer> *chan) 
char <token> <answer> *dir; 
<token> = qd->proxy_id; <answer> qinst->proxy_id 
<token> = qd->queue_id; <answer> qinst->queue_id 
if (qinst->queue_id > d->queue_count) <token> <answer> { 
dev_err(dev, "Queue Data [idx=%d] queuid %d <token> %d\n", <answer> > 
idx, qinst->queue_id, <token> <answer> d->queue_count); 
return <token> <answer> -ERANGE; 
if <token> { <answer> (d->is_sproxy) 
qinst->queue_buff_start = inst->queue_proxy_region <token> <answer> + 
qinst->queue_buff_end = <token> + <answer> inst->queue_proxy_region 
<token> = inst->queue_state_debug_region + <answer> qinst->queue_state 
qinst->queue_ctrl <token> inst->queue_ctrl_region + <answer> = 
for (qinst = inst->qinsts, i <token> 0; i < inst->num_valid_queues; qinst++, i++) { <answer> = 
if <token> <answer> (!qinst->is_tx) 
ti_msgmgr_queue_rx_set_polled_mode(qinst, <token> <answer> true); 
return <token> <answer> 0; 
static int ti_msgmgr_resume(struct device <token> <answer> *dev) 
struct ti_msgmgr_inst *inst = <token> <answer> dev_get_drvdata(dev); 
struct <token> *qinst; <answer> ti_queue_inst 
int <token> <answer> i; 
for (qinst = inst->qinsts, i = 0; i < inst->num_valid_queues; qinst++, i++) <token> <answer> { 
if <token> <answer> (!qinst->is_tx) 
<token> false); <answer> ti_msgmgr_queue_rx_set_polled_mode(qinst, 
<token> 0; <answer> return 
static DEFINE_SIMPLE_DEV_PM_OPS(ti_msgmgr_pm_ops, <token> ti_msgmgr_resume); <answer> ti_msgmgr_suspend, 
#include <token> <answer> "amdgpu.h" 
#include <token> <answer> "soc15.h" 
<token> "soc15_common.h" <answer> #include 
<token> "vega10_ip_offset.h" <answer> #include 
int vega10_reg_base_init(struct amdgpu_device <token> <answer> *adev) 
#include <token> <answer> <stdio.h> 
<token> <stdlib.h> <answer> #include 
#include <token> <answer> <string.h> 
<token> <linux/userfaultfd.h> <answer> #include 
<token> <poll.h> <answer> #include 
#include <token> <answer> <unistd.h> 
#include <token> <answer> <sys/ioctl.h> 
#include <token> <answer> <sys/syscall.h> 
<token> <fcntl.h> <answer> #include 
<token> <sys/mman.h> <answer> #include 
#include <token> <answer> <pthread.h> 
#include <token> <answer> <signal.h> 
#include <token> <answer> <errno.h> 
<token> "tm.h" <answer> #include 
static char <token> <answer> backing_mem[UF_MEM_SIZE]; 
static size_t <token> <answer> pagesize; 
void *get_uf_mem(size_t size, void <token> <answer> *backing_data) 
void <token> <answer> *ret; 
if <token> + size > UF_MEM_SIZE) { <answer> (uf_mem_offset 
fprintf(stderr, "Requesting more uf_mem <token> expected!\n"); <answer> than 
ret <token> &uf_mem[uf_mem_offset]; <answer> = 
uffdio_copy.dst = msg.arg.pagefault.address <token> ~(pagesize-1); <answer> & 
offset = (char *) uffdio_copy.dst <token> uf_mem; <answer> - 
uffdio_copy.src = (unsigned long) <token> <answer> &backing_mem[offset]; 
uffdio_copy.len <token> pagesize; <answer> = 
uffdio_copy.mode = <token> <answer> 0; 
<token> = 0; <answer> uffdio_copy.copy 
<token> (ioctl(uffd, UFFDIO_COPY, &uffdio_copy) == -1) { <answer> if 
<token> failed"); <answer> perror("ioctl-UFFDIO_COPY 
<token> setup_uf_mem(void) <answer> void 
uf_mem = mmap(NULL, UF_MEM_SIZE, PROT_READ | <token> <answer> PROT_WRITE, 
MAP_PRIVATE | MAP_ANONYMOUS, <token> 0); <answer> -1, 
if <token> == MAP_FAILED) { <answer> (uf_mem 
perror("mmap() <token> <answer> failed"); 
uffdio_register.range.start = <token> long) uf_mem; <answer> (unsigned 
<token> = UF_MEM_SIZE; <answer> uffdio_register.range.len 
<token> = UFFDIO_REGISTER_MODE_MISSING; <answer> uffdio_register.mode 
if (ioctl(uffd, UFFDIO_REGISTER, &uffdio_register) == -1) <token> <answer> { 
void signal_handler(int signo, siginfo_t *si, <token> *uc) <answer> void 
ucontext_t <token> = uc; <answer> *ucp 
ss.ss_sp = <token> NULL); <answer> get_uf_mem(SIGSTKSZ, 
ss.ss_size = <token> <answer> SIGSTKSZ; 
ss.ss_flags = <token> <answer> 0; 
if (sigaltstack(&ss, NULL) <token> -1) { <answer> == 
<token> failed"); <answer> perror("sigaltstack() 
sa.sa_flags = <token> | SA_ONSTACK; <answer> SA_SIGINFO 
<token> = signal_handler; <answer> sa.sa_sigaction 
if (sigaction(SIGTRAP, &sa, NULL) == -1) <token> <answer> { 
perror("sigaction() <token> <answer> failed"); 
return test_harness(tm_signal_pagefault, <token> <answer> "tm_signal_pagefault"); 
#include <token> <answer> <linux/clk.h> 
<token> <linux/media-bus-format.h> <answer> #include 
#include <token> <answer> <linux/mfd/syscon.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/of_graph.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> <drm/drm_atomic_helper.h> 
<token> <drm/drm_bridge.h> <answer> #include 
#include <token> <answer> <drm/drm_of.h> 
#include <token> <answer> <drm/drm_panel.h> 
#define LDB_CTRL_CH0_ENABLE <token> <answer> BIT(0) 
#define LDB_CTRL_CH0_DI_SELECT <token> <answer> BIT(1) 
<token> LDB_CTRL_CH1_ENABLE BIT(2) <answer> #define 
#define LDB_CTRL_CH1_DI_SELECT <token> <answer> BIT(3) 
#define <token> BIT(4) <answer> LDB_CTRL_SPLIT_MODE 
#define LDB_CTRL_CH0_DATA_WIDTH <token> <answer> BIT(5) 
#define <token> BIT(6) <answer> LDB_CTRL_CH0_BIT_MAPPING 
#define <token> BIT(7) <answer> LDB_CTRL_CH1_DATA_WIDTH 
#define <token> BIT(8) <answer> LDB_CTRL_CH1_BIT_MAPPING 
#define <token> BIT(9) <answer> LDB_CTRL_DI0_VSYNC_POLARITY 
#define LDB_CTRL_DI1_VSYNC_POLARITY <token> <answer> BIT(10) 
#define <token> BIT(11) <answer> LDB_CTRL_REG_CH0_FIFO_RESET 
#define LDB_CTRL_REG_CH1_FIFO_RESET <token> <answer> BIT(12) 
#define LDB_CTRL_ASYNC_FIFO_ENABLE <token> <answer> BIT(24) 
#define <token> GENMASK(27, 25) <answer> LDB_CTRL_ASYNC_FIFO_THRESHOLD_MASK 
#define <token> BIT(0) <answer> LVDS_CTRL_CH0_EN 
<token> LVDS_CTRL_CH1_EN BIT(1) <answer> #define 
#define LVDS_CTRL_LVDS_EN <token> <answer> BIT(1) 
#define <token> BIT(2) <answer> LVDS_CTRL_VBG_EN 
<token> LVDS_CTRL_HS_EN BIT(3) <answer> #define 
#define LVDS_CTRL_PRE_EMPH_EN <token> <answer> BIT(4) 
#define <token> (((n) & 0x7) << 5) <answer> LVDS_CTRL_PRE_EMPH_ADJ(n) 
#define LVDS_CTRL_PRE_EMPH_ADJ_MASK GENMASK(7, <token> <answer> 5) 
#define <token> (((n) & 0x7) << 8) <answer> LVDS_CTRL_CM_ADJ(n) 
#define LVDS_CTRL_CM_ADJ_MASK <token> 8) <answer> GENMASK(10, 
#define LVDS_CTRL_CC_ADJ(n) (((n) & <token> << 11) <answer> 0x7) 
#define LVDS_CTRL_CC_ADJ_MASK GENMASK(13, <token> <answer> 11) 
#define LVDS_CTRL_SLEW_ADJ(n) (((n) & 0x7) << <token> <answer> 14) 
#define LVDS_CTRL_SLEW_ADJ_MASK <token> 14) <answer> GENMASK(16, 
#define LVDS_CTRL_VBG_ADJ(n) (((n) & <token> << 17) <answer> 0x7) 
#define LVDS_CTRL_VBG_ADJ_MASK <token> 17) <answer> GENMASK(19, 
<token> fsl_ldb_devtype { <answer> enum 
struct fsl_ldb_devdata <token> <answer> { 
<token> ldb_ctrl; <answer> u32 
u32 <token> <answer> lvds_ctrl; 
bool <token> <answer> lvds_en_bit; 
bool <token> <answer> single_ctrl_reg; 
<token> const struct fsl_ldb_devdata fsl_ldb_devdata[] = { <answer> static 
[IMX6SX_LDB] <token> { <answer> = 
.ldb_ctrl = <token> <answer> 0x18, 
.single_ctrl_reg = <token> <answer> true, 
[IMX8MP_LDB] <token> { <answer> = 
<token> = 0x5c, <answer> .ldb_ctrl 
.lvds_ctrl = <token> <answer> 0x128, 
[IMX93_LDB] <token> { <answer> = 
<token> = 0x20, <answer> .ldb_ctrl 
<token> = 0x24, <answer> .lvds_ctrl 
.lvds_en_bit <token> true, <answer> = 
struct fsl_ldb <token> <answer> { 
<token> device *dev; <answer> struct 
struct drm_bridge <token> <answer> bridge; 
struct drm_bridge <token> <answer> *panel_bridge; 
struct clk <token> <answer> *clk; 
<token> regmap *regmap; <answer> struct 
const struct fsl_ldb_devdata <token> <answer> *devdata; 
<token> ch0_enabled; <answer> bool 
<token> ch1_enabled; <answer> bool 
<token> bool fsl_ldb_is_dual(const struct fsl_ldb *fsl_ldb) <answer> static 
return (fsl_ldb->ch0_enabled <token> fsl_ldb->ch1_enabled); <answer> && 
static inline <token> fsl_ldb *to_fsl_ldb(struct drm_bridge *bridge) <answer> struct 
return <token> struct fsl_ldb, bridge); <answer> container_of(bridge, 
static unsigned long fsl_ldb_link_frequency(struct fsl_ldb *fsl_ldb, <token> clock) <answer> int 
if <token> <answer> (fsl_ldb_is_dual(fsl_ldb)) 
return clock * <token> <answer> 3500; 
return clock * <token> <answer> 7000; 
static int <token> drm_bridge *bridge, <answer> fsl_ldb_attach(struct 
<token> drm_bridge_attach_flags flags) <answer> enum 
struct fsl_ldb *fsl_ldb <token> to_fsl_ldb(bridge); <answer> = 
return <token> fsl_ldb->panel_bridge, <answer> drm_bridge_attach(bridge->encoder, 
bridge, <token> <answer> flags); 
static void <token> drm_bridge *bridge, <answer> fsl_ldb_atomic_enable(struct 
struct drm_bridge_state <token> <answer> *old_bridge_state) 
struct fsl_ldb <token> = to_fsl_ldb(bridge); <answer> *fsl_ldb 
struct drm_atomic_state *state <token> old_bridge_state->base.state; <answer> = 
const struct drm_bridge_state <token> <answer> *bridge_state; 
const struct <token> *crtc_state; <answer> drm_crtc_state 
<token> struct drm_display_mode *mode; <answer> const 
struct drm_connector <token> <answer> *connector; 
struct <token> *crtc; <answer> drm_crtc 
<token> long configured_link_freq; <answer> unsigned 
unsigned long <token> <answer> requested_link_freq; 
<token> lvds_format_24bpp; <answer> bool 
<token> lvds_format_jeida; <answer> bool 
<token> reg; <answer> u32 
<token> = true; <answer> lvds_format_24bpp 
lvds_format_jeida = <token> <answer> false; 
"Unsupported LVDS bus format 0x%04x, please check <token> bridge driver. Falling back to SPWG24.\n", <answer> output 
<token> = drm_atomic_get_new_connector_for_encoder(state, <answer> connector 
crtc = <token> connector)->crtc; <answer> drm_atomic_get_new_connector_state(state, 
crtc_state = <token> crtc); <answer> drm_atomic_get_new_crtc_state(state, 
<token> = &crtc_state->adjusted_mode; <answer> mode 
requested_link_freq = <token> mode->clock); <answer> fsl_ldb_link_frequency(fsl_ldb, 
<token> requested_link_freq); <answer> clk_set_rate(fsl_ldb->clk, 
configured_link_freq = <token> <answer> clk_get_rate(fsl_ldb->clk); 
if <token> != requested_link_freq) <answer> (configured_link_freq 
dev_warn(fsl_ldb->dev, "Configured LDB clock (%lu Hz) does not match requested LVDS clock: %lu <token> <answer> Hz\n", 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> "debug.h" <answer> #include 
<token> "init.h" <answer> #include 
#include <token> <answer> "wl12xx_80211.h" 
#include <token> <answer> "acx.h" 
<token> "cmd.h" <answer> #include 
<token> "tx.h" <answer> #include 
<token> "io.h" <answer> #include 
<token> "hw_ops.h" <answer> #include 
int wl1271_init_templates_config(struct <token> *wl) <answer> wl1271 
<token> ret, i; <answer> int 
<token> max_size; <answer> size_t 
<token> = wl1271_cmd_template_set(wl, WL12XX_INVALID_ROLE_ID, <answer> ret 
<token> NULL, <answer> CMD_TEMPL_AP_PROBE_RESPONSE, 
<token> WL1271_RATE_AUTOMATIC); <answer> 0, 
<token> (ret < 0) <answer> if 
<token> ret; <answer> return 
ret = <token> WL12XX_INVALID_ROLE_ID, <answer> wl1271_cmd_template_set(wl, 
CMD_TEMPL_AP_BEACON, <token> <answer> NULL, 
0, <token> <answer> WL1271_RATE_AUTOMATIC); 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
ret <token> wl1271_cmd_template_set(wl, WL12XX_INVALID_ROLE_ID, <answer> = 
CMD_TEMPL_DEAUTH_AP, <token> <answer> NULL, 
(struct <token> <answer> wl12xx_disconn_template), 
<token> WL1271_RATE_AUTOMATIC); <answer> 0, 
if (ret <token> 0) <answer> < 
<token> ret; <answer> return 
for <token> = 0; i < WLCORE_MAX_KLV_TEMPLATES; i++) { <answer> (i 
ret = <token> WL12XX_INVALID_ROLE_ID, <answer> wl1271_cmd_template_set(wl, 
CMD_TEMPL_KLV, <token> <answer> NULL, 
<token> ieee80211_qos_hdr), <answer> sizeof(struct 
i, <token> <answer> WL1271_RATE_AUTOMATIC); 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
return <token> <answer> 0; 
static int wl1271_ap_init_deauth_template(struct <token> *wl, <answer> wl1271 
struct wl12xx_vif <token> <answer> *wlvif) 
struct wl12xx_disconn_template <token> <answer> *tmpl; 
int <token> <answer> ret; 
<token> rate; <answer> u32 
<token> = kzalloc(sizeof(*tmpl), GFP_KERNEL); <answer> tmpl 
if (!tmpl) <token> <answer> { 
<token> = -ENOMEM; <answer> ret 
<token> out; <answer> goto 
tmpl->header.frame_ctl = cpu_to_le16(IEEE80211_FTYPE_MGMT <token> <answer> | 
rate = wl1271_tx_min_rate_get(wl, <token> <answer> wlvif->basic_rate_set); 
ret <token> wl1271_cmd_template_set(wl, wlvif->role_id, <answer> = 
tmpl, sizeof(*tmpl), 0, <token> <answer> rate); 
<token> ret; <answer> return 
static int <token> wl1271 *wl, <answer> wl1271_ap_init_null_template(struct 
struct ieee80211_vif <token> <answer> *vif) 
struct wl12xx_vif *wlvif = <token> <answer> wl12xx_vif_to_data(vif); 
struct ieee80211_hdr_3addr <token> <answer> *nullfunc; 
int <token> <answer> ret; 
<token> rate; <answer> u32 
nullfunc = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*nullfunc), 
<token> (!nullfunc) { <answer> if 
ret <token> -ENOMEM; <answer> = 
goto <token> <answer> out; 
nullfunc->frame_control <token> cpu_to_le16(IEEE80211_FTYPE_DATA | <answer> = 
<token> | <answer> IEEE80211_STYPE_NULLFUNC 
ret = wl1271_acx_beacon_filter_opt(wl, <token> false); <answer> wlvif, 
if <token> < 0) <answer> (ret 
<token> ret; <answer> return 
return <token> <answer> 0; 
static int <token> wl1271 *wl, <answer> wl1271_ap_hw_init_post_mem(struct 
<token> ieee80211_vif *vif) <answer> struct 
return <token> vif); <answer> wl1271_ap_init_templates(wl, 
int <token> wl1271 *wl, struct wl12xx_vif *wlvif) <answer> wl1271_init_ap_rates(struct 
<token> i, ret; <answer> int 
<token> conf_tx_rate_class rc; <answer> struct 
<token> supported_rates; <answer> u32 
wl1271_debug(DEBUG_AP, "AP basic rate <token> 0x%x", <answer> set: 
<token> (wlvif->basic_rate_set == 0) <answer> if 
<token> -EINVAL; <answer> return 
rc.enabled_rates <token> wlvif->basic_rate_set; <answer> = 
<token> = 10; <answer> rc.long_retry_limit 
<token> = 10; <answer> rc.short_retry_limit 
rc.aflags = <token> <answer> 0; 
ret <token> wl1271_acx_ap_rate_policy(wl, &rc, wlvif->ap.mgmt_rate_idx); <answer> = 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
if (wl->ofdm_only_ap && (wlvif->basic_rate_set <token> CONF_TX_OFDM_RATES)) <answer> & 
supported_rates = <token> <answer> CONF_TX_OFDM_RATES; 
supported_rates <token> CONF_TX_ENABLED_RATES; <answer> = 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/delay.h> 
<token> <linux/eeprom_93cx6.h> <answer> #include 
<token> 93cx6 chip driver"); <answer> MODULE_DESCRIPTION("EEPROM 
static inline <token> eeprom_93cx6_pulse_high(struct eeprom_93cx6 *eeprom) <answer> void 
<token> = 1; <answer> eeprom->reg_data_clock 
static inline void eeprom_93cx6_pulse_low(struct <token> *eeprom) <answer> eeprom_93cx6 
<token> = 0; <answer> eeprom->reg_data_clock 
static void <token> eeprom_93cx6 *eeprom) <answer> eeprom_93cx6_startup(struct 
eeprom->reg_data_in = <token> <answer> 0; 
<token> = 0; <answer> eeprom->reg_data_out 
<token> = 0; <answer> eeprom->reg_data_clock 
eeprom->reg_chip_select = <token> <answer> 1; 
eeprom->drive_data = <token> <answer> 1; 
<token> void eeprom_93cx6_cleanup(struct eeprom_93cx6 *eeprom) <answer> static 
eeprom->reg_data_in = <token> <answer> 0; 
eeprom->reg_chip_select <token> 0; <answer> = 
static void eeprom_93cx6_write_bits(struct <token> *eeprom, <answer> eeprom_93cx6 
const u16 <token> const u16 count) <answer> data, 
unsigned <token> i; <answer> int 
eeprom->reg_data_in = <token> <answer> 0; 
eeprom->reg_data_out <token> 0; <answer> = 
<token> = 1; <answer> eeprom->drive_data 
for (i = count; i > <token> i--) { <answer> 0; 
eeprom->reg_data_in = !!(data <token> (1 << (i - 1))); <answer> & 
eeprom->reg_data_in <token> 0; <answer> = 
<token> void eeprom_93cx6_read_bits(struct eeprom_93cx6 *eeprom, <answer> static 
u16 <token> const u16 count) <answer> *data, 
<token> int i; <answer> unsigned 
<token> buf = 0; <answer> u16 
eeprom->reg_data_in = <token> <answer> 0; 
eeprom->reg_data_out <token> 0; <answer> = 
<token> = 0; <answer> eeprom->drive_data 
for <token> = count; i > 0; i--) { <answer> (i 
eeprom->reg_data_in <token> 0; <answer> = 
if <token> <answer> (eeprom->reg_data_out) 
buf <token> (1 << (i - 1)); <answer> |= 
<token> = buf; <answer> *data 
void eeprom_93cx6_read(struct eeprom_93cx6 *eeprom, const <token> word, <answer> u8 
u16 <token> <answer> *data) 
<token> command; <answer> u16 
command = (PCI_EEPROM_READ_OPCODE << <token> | word; <answer> eeprom->width) 
eeprom_93cx6_write_bits(eeprom, <token> <answer> command, 
<token> + eeprom->width); <answer> PCI_EEPROM_WIDTH_OPCODE 
<token> data, 16); <answer> eeprom_93cx6_read_bits(eeprom, 
void eeprom_93cx6_multiread(struct eeprom_93cx6 *eeprom, <token> u8 word, <answer> const 
<token> *data, const u16 words) <answer> __le16 
unsigned int <token> <answer> i; 
u16 <token> <answer> tmp; 
for (i <token> 0; i < words; i++) { <answer> = 
tmp <token> 0; <answer> = 
eeprom_93cx6_read(eeprom, word <token> i, &tmp); <answer> + 
data[i] <token> cpu_to_le16(tmp); <answer> = 
void <token> eeprom_93cx6 *eeprom, const u8 byte, <answer> eeprom_93cx6_readb(struct 
<token> *data) <answer> u8 
u16 <token> <answer> command; 
u16 <token> <answer> tmp; 
command = (PCI_EEPROM_READ_OPCODE <token> (eeprom->width + 1)) | byte; <answer> << 
<token> command, <answer> eeprom_93cx6_write_bits(eeprom, 
PCI_EEPROM_WIDTH_OPCODE + eeprom->width <token> 1); <answer> + 
<token> &tmp, 8); <answer> eeprom_93cx6_read_bits(eeprom, 
<token> = tmp & 0xff; <answer> *data 
void eeprom_93cx6_multireadb(struct <token> *eeprom, const u8 byte, <answer> eeprom_93cx6 
u8 *data, const <token> bytes) <answer> u16 
unsigned <token> i; <answer> int 
for (i <token> 0; i < bytes; i++) <answer> = 
eeprom_93cx6_readb(eeprom, byte + i, <token> <answer> &data[i]); 
void eeprom_93cx6_wren(struct <token> *eeprom, bool enable) <answer> eeprom_93cx6 
<token> command; <answer> u16 
void eeprom_93cx6_write(struct <token> *eeprom, u8 addr, u16 data) <answer> eeprom_93cx6 
int timeout = <token> <answer> 100; 
<token> command; <answer> u16 
#include <token> <answer> <linux/bitops.h> 
<token> <linux/clk.h> <answer> #include 
<token> <linux/etherdevice.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/iopoll.h> 
#include <token> <answer> <linux/mfd/syscon.h> 
#include <token> <answer> <linux/mii.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/netdevice.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_net.h> <answer> #include 
#include <token> <answer> <linux/of_mdio.h> 
#include <token> <answer> <linux/phy.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/regmap.h> <answer> #include 
<token> <linux/reset.h> <answer> #include 
<token> <linux/types.h> <answer> #include 
<token> <linux/u64_stats_sync.h> <answer> #include 
<token> = ave_dma_map(ndev, &priv->rx.desc[entry], <answer> ret 
skb->data <token> AVE_FRAME_HEADROOM, <answer> - 
<token> + AVE_FRAME_HEADROOM, <answer> AVE_MAX_ETHFRAME 
DMA_FROM_DEVICE, <token> <answer> &paddr); 
if <token> { <answer> (ret) 
netdev_err(ndev, "can't map skb <token> Rx\n"); <answer> for 
<token> ret; <answer> return 
<token> = skb; <answer> priv->rx.desc[entry].skbs 
ret <token> ave_dma_map(ndev, &priv->tx.desc[proc_idx], <answer> = 
<token> skb->len, DMA_TO_DEVICE, &paddr); <answer> skb->data, 
if <token> { <answer> (ret) 
<token> NETDEV_TX_OK; <answer> return 
priv->tx.desc[proc_idx].skbs <token> skb; <answer> = 
ave_desc_write_addr(ndev, AVE_DESCID_TX, <token> paddr); <answer> proc_idx, 
cmdsts <token> AVE_STS_OWN | AVE_STS_1ST | AVE_STS_LAST | <answer> = 
(skb->len & <token> <answer> AVE_STS_PKTLEN_TX_MASK); 
<token> "nv50.h" <answer> #include 
#include <token> <answer> "ram.h" 
<token> const struct nv50_fb_func <answer> static 
g84_fb = <token> <answer> { 
.ram_new = <token> <answer> nv50_ram_new, 
<token> = nv20_fb_tags, <answer> .tags 
.trap <token> 0x001d07ff, <answer> = 
g84_fb_new(struct nvkm_device *device, enum nvkm_subdev_type type, int <token> struct nvkm_fb **pfb) <answer> inst, 
return <token> device, type, inst, pfb); <answer> nv50_fb_new_(&g84_fb, 
#include <token> <answer> <linux/kobject.h> 
<token> <linux/pci.h> <answer> #include 
<token> <linux/fs.h> <answer> #include 
<token> <linux/firmware.h> <answer> #include 
#include <token> <answer> <linux/pm_runtime.h> 
<token> <linux/sched.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <sound/asound.h> 
#include <token> <answer> <sound/core.h> 
#include <token> <answer> <sound/pcm.h> 
<token> <sound/soc.h> <answer> #include 
#include <token> <answer> <sound/compress_driver.h> 
#include <token> <answer> <asm/platform_sst_audio.h> 
<token> "../sst-mfld-platform.h" <answer> #include 
#include <token> <answer> "sst.h" 
<token> sst_shim_write(void __iomem *addr, int offset, int value) <answer> int 
writel(value, addr + <token> <answer> offset); 
<token> 0; <answer> return 
<token> sst_shim_read(void __iomem *addr, int offset) <answer> u32 
return readl(addr + <token> <answer> offset); 
u64 sst_reg_read64(void <token> *addr, int offset) <answer> __iomem 
u64 <token> = 0; <answer> val 
memcpy_fromio(&val, addr <token> offset, sizeof(val)); <answer> + 
return <token> <answer> val; 
int sst_shim_write64(void __iomem *addr, int offset, <token> value) <answer> u64 
memcpy_toio(addr + <token> &value, sizeof(value)); <answer> offset, 
return <token> <answer> 0; 
u64 sst_shim_read64(void <token> *addr, int offset) <answer> __iomem 
u64 val = <token> <answer> 0; 
<token> addr + offset, sizeof(val)); <answer> memcpy_fromio(&val, 
<token> val; <answer> return 
<token> sst_set_fw_state_locked( <answer> void 
struct intel_sst_drv *sst_drv_ctx, int <token> <answer> sst_state) 
sst_drv_ctx->sst_state <token> sst_state; <answer> = 
<token> sst_wait_interruptible(struct intel_sst_drv *sst_drv_ctx, <answer> int 
struct sst_block <token> <answer> *block) 
int <token> = 0; <answer> retval 
if <token> <answer> (!wait_event_interruptible(sst_drv_ctx->wait_queue, 
<token> { <answer> block->condition)) 
<token> sst_wait_timeout(struct intel_sst_drv *sst_drv_ctx, struct sst_block *block) <answer> int 
int <token> = 0; <answer> retval 
"waiting for condition <token> ipc %d drv_id %d\n", <answer> %x 
block->condition, <token> block->drv_id); <answer> block->msg_id, 
if <token> <answer> (wait_event_timeout(sst_drv_ctx->wait_queue, 
msecs_to_jiffies(SST_BLOCK_TIMEOUT))) <token> <answer> { 
<token> sst_create_ipc_msg(struct ipc_post **arg, bool large) <answer> int 
struct <token> *msg; <answer> ipc_post 
msg = <token> GFP_ATOMIC); <answer> kzalloc(sizeof(*msg), 
<token> (!msg) <answer> if 
<token> -ENOMEM; <answer> return 
if <token> { <answer> (large) 
<token> = kzalloc(SST_MAILBOX_SIZE, GFP_ATOMIC); <answer> msg->mailbox_data 
if (!msg->mailbox_data) <token> <answer> { 
<token> -ENOMEM; <answer> return 
} <token> { <answer> else 
<token> = NULL; <answer> msg->mailbox_data 
<token> = large; <answer> msg->is_large 
*arg = <token> <answer> msg; 
<token> 0; <answer> return 
<token> sst_create_block_and_ipc_msg(struct ipc_post **arg, bool large, <answer> int 
struct <token> *sst_drv_ctx, struct sst_block **block, <answer> intel_sst_drv 
u32 msg_id, <token> drv_id) <answer> u32 
int <token> <answer> retval; 
retval <token> sst_create_ipc_msg(arg, large); <answer> = 
if <token> <answer> (retval) 
<token> retval; <answer> return 
*block = sst_create_block(sst_drv_ctx, msg_id, <token> <answer> drv_id); 
if <token> == NULL) { <answer> (*block 
<token> -ENOMEM; <answer> return 
return <token> <answer> 0; 
<token> sst_clean_stream(struct stream_info *stream) <answer> void 
<token> = STREAM_UN_INIT; <answer> stream->status 
stream->prev = <token> <answer> STREAM_UN_INIT; 
stream->cumm_bytes <token> 0; <answer> = 
int sst_prepare_and_post_msg(struct intel_sst_drv <token> <answer> *sst, 
int task_id, int <token> int cmd_id, int pipe_id, <answer> ipc_msg, 
size_t <token> const void *mbox_data, void **data, <answer> mbox_data_len, 
bool large, bool fill_dsp, bool <token> bool response) <answer> sync, 
struct sst_block *block = <token> <answer> NULL; 
struct ipc_post *msg <token> NULL; <answer> = 
<token> ipc_dsp_hdr dsp_hdr; <answer> struct 
int ret = <token> pvt_id; <answer> 0, 
<token> = sst_assign_pvt_id(sst); <answer> pvt_id 
<token> (pvt_id < 0) <answer> if 
<token> pvt_id; <answer> return 
if <token> <answer> (response) 
<token> = sst_create_block_and_ipc_msg( <answer> ret 
<token> large, sst, &block, ipc_msg, pvt_id); <answer> &msg, 
ret <token> sst_create_ipc_msg(&msg, large); <answer> = 
if (ret < <token> { <answer> 0) 
test_and_clear_bit(pvt_id, <token> <answer> &sst->pvt_id); 
<token> -ENOMEM; <answer> return 
dev_dbg(sst->dev, "pvt_id = %d, pipe id = %d, task = %d <token> %d\n", <answer> ipc_msg: 
pvt_id, pipe_id, task_id, <token> <answer> ipc_msg); 
sst_fill_header_mrfld(&msg->mrfld_header, <token> <answer> ipc_msg, 
task_id, large, <token> <answer> pvt_id); 
msg->mrfld_header.p.header_low_payload = <token> + mbox_data_len; <answer> sizeof(dsp_hdr) 
msg->mrfld_header.p.header_high.part.res_rqd = <token> <answer> !sync; 
dev_dbg(sst->dev, <token> <answer> "header:%x\n", 
dev_dbg(sst->dev, "response rqd: <token> <answer> %x", 
dev_dbg(sst->dev, <token> <answer> "msg->mrfld_header.p.header_low_payload:%d", 
if <token> { <answer> (fill_dsp) 
sst_fill_header_dsp(&dsp_hdr, <token> pipe_id, mbox_data_len); <answer> cmd_id, 
memcpy(msg->mailbox_data, &dsp_hdr, <token> <answer> sizeof(dsp_hdr)); 
<token> (mbox_data_len) { <answer> if 
memcpy(msg->mailbox_data + <token> <answer> sizeof(dsp_hdr), 
<token> mbox_data_len); <answer> mbox_data, 
if <token> <answer> (sync) 
<token> msg, true); <answer> sst->ops->post_message(sst, 
<token> msg); <answer> sst_add_to_dispatch_list_and_post(sst, 
if (response) <token> <answer> { 
ret = sst_wait_timeout(sst, <token> <answer> block); 
if (ret <token> 0) <answer> < 
<token> out; <answer> goto 
if (data && block->data) <token> <answer> { 
*data = kmemdup(block->data, <token> GFP_KERNEL); <answer> block->size, 
<token> (!*data) { <answer> if 
<token> = -ENOMEM; <answer> ret 
<token> out; <answer> goto 
if <token> <answer> (response) 
sst_free_block(sst, <token> <answer> block); 
test_and_clear_bit(pvt_id, <token> <answer> &sst->pvt_id); 
<token> ret; <answer> return 
int sst_pm_runtime_put(struct intel_sst_drv <token> <answer> *sst_drv) 
int <token> <answer> ret; 
<token> = pm_runtime_put_autosuspend(sst_drv->dev); <answer> ret 
if (ret < <token> <answer> 0) 
<token> ret; <answer> return 
<token> 0; <answer> return 
void sst_fill_header_mrfld(union ipc_header_mrfld <token> <answer> *header, 
int msg, int task_id, int <token> int drv_id) <answer> large, 
header->full <token> 0; <answer> = 
<token> = msg; <answer> header->p.header_high.part.msg_id 
<token> = task_id; <answer> header->p.header_high.part.task_id 
header->p.header_high.part.large = <token> <answer> large; 
header->p.header_high.part.drv_id = <token> <answer> drv_id; 
<token> = 0; <answer> header->p.header_high.part.done 
header->p.header_high.part.busy = <token> <answer> 1; 
header->p.header_high.part.res_rqd <token> 1; <answer> = 
<token> sst_fill_header_dsp(struct ipc_dsp_hdr *dsp, int msg, <answer> void 
<token> pipe_id, int len) <answer> int 
dsp->cmd_id <token> msg; <answer> = 
dsp->mod_index_id = <token> <answer> 0xff; 
dsp->pipe_id <token> pipe_id; <answer> = 
<token> = len; <answer> dsp->length 
dsp->mod_id <token> 0; <answer> = 
#define <token> 15 <answer> SST_MAX_BLOCKS 
<token> sst_assign_pvt_id(struct intel_sst_drv *drv) <answer> int 
int <token> <answer> local; 
<token> (sk->family != AF_INET6 || !is_loopback6(sk->src_ip6) || <answer> if 
sk->state == <token> <answer> BPF_TCP_LISTEN) 
return <token> <answer> CG_OK; 
if (sk->src_port <token> bpf_ntohs(srv_sa6.sin6_port)) { <answer> == 
pkt_out_cnt->cnt += <token> <answer> 1; 
<token> += 10; <answer> pkt_out_cnt10->cnt 
return <token> <answer> CG_OK; 
int ingress_read_sock_fields(struct __sk_buff <token> <answer> *skb) 
<token> bpf_tcp_sock *tp; <answer> struct 
__u32 linum, <token> <answer> linum_idx; 
struct <token> *sk; <answer> bpf_sock 
<token> = INGRESS_LINUM_IDX; <answer> linum_idx 
<token> = skb->sk; <answer> sk 
if <token> <answer> (!sk) 
static <token> bool sk_dst_port__load_word(struct bpf_sock *sk) <answer> __noinline 
__u32 *word = <token> *)&sk->dst_port; <answer> (__u32 
return <token> == bpf_htons(0xcafe); <answer> word[0] 
static __noinline bool sk_dst_port__load_half(struct bpf_sock <token> <answer> *sk) 
__u16 <token> <answer> *half; 
<token> volatile (""); <answer> asm 
half = (__u16 <token> <answer> *)&sk->dst_port; 
return half[0] == <token> <answer> bpf_htons(0xcafe); 
static __noinline bool <token> bpf_sock *sk) <answer> sk_dst_port__load_byte(struct 
__u8 *byte <token> (__u8 *)&sk->dst_port; <answer> = 
return byte[0] == <token> && byte[1] == 0xfe; <answer> 0xca 
<token> read_sk_dst_port(struct __sk_buff *skb) <answer> int 
__u32 <token> linum_idx; <answer> linum, 
struct bpf_sock <token> <answer> *sk; 
linum_idx <token> READ_SK_DST_PORT_LINUM_IDX; <answer> = 
<token> = skb->sk; <answer> sk 
if <token> <answer> (!sk) 
<token> <linux/clk.h> <answer> #include 
#include <token> <answer> <linux/clk-provider.h> 
#include <token> <answer> <linux/io.h> 
<token> <dt-bindings/clock/r7s9210-cpg-mssr.h> <answer> #include 
<token> "renesas-cpg-mssr.h" <answer> #include 
#define <token> 0x00 <answer> CPG_FRQCR 
static <token> cpg_mode; <answer> u8 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/ethtool.h> 
#include <token> <answer> <linux/ethtool_netlink.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/mii.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/phy.h> <answer> #include 
<token> <linux/processor.h> <answer> #include 
<token> <linux/property.h> <answer> #include 
#include <token> <answer> <linux/ptp_classify.h> 
<token> <linux/net_tstamp.h> <answer> #include 
#include <token> <answer> "nxp-c45-tja11xx.h" 
<token> PHY_ID_TJA_1103 0x001BB010 <answer> #define 
#define PHY_ID_TJA_1120 <token> <answer> 0x001BB031 
#define <token> 0x0040 <answer> VEND1_DEVICE_CONTROL 
#define <token> BIT(15) <answer> DEVICE_CONTROL_RESET 
#define <token> BIT(14) <answer> DEVICE_CONTROL_CONFIG_GLOBAL_EN 
#define <token> BIT(13) <answer> DEVICE_CONTROL_CONFIG_ALL_EN 
#define <token> 0x0048 <answer> VEND1_DEVICE_CONFIG 
#define TJA1120_VEND1_EXT_TS_MODE <token> <answer> 0x1012 
#define <token> 0x2C08 <answer> TJA1120_GLOBAL_INFRA_IRQ_ACK 
<token> TJA1120_GLOBAL_INFRA_IRQ_EN 0x2C0A <answer> #define 
#define <token> 0x2C0C <answer> TJA1120_GLOBAL_INFRA_IRQ_STATUS 
<token> TJA1120_DEV_BOOT_DONE BIT(1) <answer> #define 
#define <token> 0x1070 <answer> TJA1120_VEND1_PTP_TRIG_DATA_S 
<token> TJA1120_EGRESS_TS_DATA_S 0x9060 <answer> #define 
#define TJA1120_EGRESS_TS_END <token> <answer> 0x9067 
#define TJA1120_TS_VALID <token> <answer> BIT(0) 
#define <token> BIT(15) <answer> TJA1120_MORE_TS 
#define VEND1_PHY_IRQ_ACK <token> <answer> 0x80A0 
#define VEND1_PHY_IRQ_EN <token> <answer> 0x80A1 
#define VEND1_PHY_IRQ_STATUS <token> <answer> 0x80A2 
#define PHY_IRQ_LINK_EVENT <token> <answer> BIT(1) 
<token> VEND1_ALWAYS_ACCESSIBLE 0x801F <answer> #define 
#define FUSA_PASS <token> <answer> BIT(4) 
#define <token> 0x8100 <answer> VEND1_PHY_CONTROL 
#define <token> BIT(14) <answer> PHY_CONFIG_EN 
<token> PHY_START_OP BIT(0) <answer> #define 
<token> VEND1_PHY_CONFIG 0x8108 <answer> #define 
#define <token> BIT(0) <answer> PHY_CONFIG_AUTO 
#define TJA1120_EPHY_RESETS <token> <answer> 0x810A 
<token> EPHY_PCS_RESET BIT(3) <answer> #define 
#define VEND1_SIGNAL_QUALITY <token> <answer> 0x8320 
#define <token> BIT(14) <answer> SQI_VALID 
#define SQI_MASK <token> 0) <answer> GENMASK(2, 
#define <token> SQI_MASK <answer> MAX_SQI 
<token> CABLE_TEST_ENABLE BIT(15) <answer> #define 
<token> CABLE_TEST_START BIT(14) <answer> #define 
#define <token> 0x00 <answer> CABLE_TEST_OK 
#define CABLE_TEST_SHORTED <token> <answer> 0x01 
#define CABLE_TEST_OPEN <token> <answer> 0x02 
#define CABLE_TEST_UNKNOWN <token> <answer> 0x07 
#define VEND1_PORT_CONTROL <token> <answer> 0x8040 
#define <token> BIT(14) <answer> PORT_CONTROL_EN 
#define <token> 0x8046 <answer> VEND1_PORT_ABILITIES 
#define MACSEC_ABILITY <token> <answer> BIT(5) 
#define <token> BIT(3) <answer> PTP_ABILITY 
#define VEND1_PORT_FUNC_IRQ_EN <token> <answer> 0x807A 
<token> MACSEC_IRQS BIT(5) <answer> #define 
<token> PTP_IRQS BIT(3) <answer> #define 
#define VEND1_PTP_IRQ_ACK <token> <answer> 0x9008 
#define EGR_TS_IRQ <token> <answer> BIT(1) 
#define VEND1_PORT_INFRA_CONTROL <token> <answer> 0xAC00 
#define <token> BIT(14) <answer> PORT_INFRA_CONTROL_EN 
#define VEND1_RXID <token> <answer> 0xAFCC 
#define <token> 0xAFCD <answer> VEND1_TXID 
#define ID_ENABLE <token> <answer> BIT(15) 
#define <token> 0xAFC4 <answer> VEND1_ABILITIES 
<token> RGMII_ID_ABILITY BIT(15) <answer> #define 
<token> RGMII_ABILITY BIT(14) <answer> #define 
#define <token> BIT(10) <answer> RMII_ABILITY 
<token> REVMII_ABILITY BIT(9) <answer> #define 
<token> MII_ABILITY BIT(8) <answer> #define 
#define <token> BIT(0) <answer> SGMII_ABILITY 
#define <token> 0xAFC6 <answer> VEND1_MII_BASIC_CONFIG 
#define MII_BASIC_CONFIG_REV <token> <answer> BIT(4) 
#define <token> 0x9 <answer> MII_BASIC_CONFIG_SGMII 
<token> MII_BASIC_CONFIG_RGMII 0x7 <answer> #define 
#define MII_BASIC_CONFIG_RMII <token> <answer> 0x5 
#define MII_BASIC_CONFIG_MII <token> <answer> 0x4 
#define <token> 0x8351 <answer> VEND1_SYMBOL_ERROR_CNT_XTD 
<token> EXTENDED_CNT_EN BIT(15) <answer> #define 
#define VEND1_MONITOR_STATUS <token> <answer> 0xAC80 
<token> MONITOR_RESET BIT(15) <answer> #define 
#define <token> 0xAC86 <answer> VEND1_MONITOR_CONFIG 
#define LOST_FRAMES_CNT_EN <token> <answer> BIT(9) 
#define <token> BIT(8) <answer> ALL_FRAMES_CNT_EN 
<token> VEND1_SYMBOL_ERROR_COUNTER 0x8350 <answer> #define 
#define VEND1_LINK_DROP_COUNTER <token> <answer> 0x8352 
#define <token> 0x8353 <answer> VEND1_LINK_LOSSES_AND_FAILURES 
<token> VEND1_RX_PREAMBLE_COUNT 0xAFCE <answer> #define 
#define <token> 0xAFCF <answer> VEND1_TX_PREAMBLE_COUNT 
#define <token> 0xAFD0 <answer> VEND1_RX_IPG_LENGTH 
#define VEND1_TX_IPG_LENGTH <token> <answer> 0xAFD1 
#define COUNTER_EN <token> <answer> BIT(15) 
#define <token> 0x1102 <answer> VEND1_PTP_CONFIG 
#define EXT_TRG_EDGE <token> <answer> BIT(1) 
#define <token> 0x1010 <answer> TJA1120_SYNC_TRIG_FILTER 
#define <token> BIT(3) <answer> PTP_TRIG_RISE_TS 
#define <token> BIT(2) <answer> PTP_TRIG_FALLING_TS 
#define <token> BIT(15) <answer> CLK_RATE_ADJ_LD 
<token> CLK_RATE_ADJ_DIR BIT(14) <answer> #define 
#define <token> 0x114D <answer> VEND1_RX_TS_INSRT_CTRL 
#define TJA1103_RX_TS_INSRT_MODE2 <token> <answer> 0x02 
#define TJA1120_RX_TS_INSRT_CTRL <token> <answer> 0x9012 
#define <token> BIT(15) <answer> TJA1120_RX_TS_INSRT_EN 
#define <token> BIT(4) <answer> TJA1120_TS_INSRT_MODE 
#define VEND1_EGR_RING_DATA_0 <token> <answer> 0x114E 
#define <token> 0x1154 <answer> VEND1_EGR_RING_CTRL 
#define <token> BIT(15) <answer> RING_DATA_0_TS_VALID 
#define RING_DONE <token> <answer> BIT(0) 
<token> TS_SEC_MASK GENMASK(1, 0) <answer> #define 
<token> PTP_ENABLE BIT(3) <answer> #define 
#define <token> BIT(0) <answer> PHY_TEST_ENABLE 
#define <token> 0x9000 <answer> VEND1_PORT_PTP_CONTROL 
<token> PORT_PTP_CONTROL_BYPASS BIT(11) <answer> #define 
#define PTP_CLK_PERIOD_100BT1 <token> <answer> 15ULL 
#define <token> 8ULL <answer> PTP_CLK_PERIOD_1000BT1 
#define <token> 0x0F <answer> EVENT_MSG_FILT_ALL 
#define EVENT_MSG_FILT_NONE <token> <answer> 0x00 
<token> VEND1_GPIO_FUNC_CONFIG_BASE 0x2C40 <answer> #define 
#define GPIO_FUNC_EN <token> <answer> BIT(15) 
#define <token> BIT(6) <answer> GPIO_FUNC_PTP 
#define <token> 0x01 <answer> GPIO_SIGNAL_PTP_TRIGGER 
#define GPIO_SIGNAL_PPS_OUT <token> <answer> 0x12 
#define GPIO_DISABLE <token> <answer> 0 
#define GPIO_PPS_OUT_CFG (GPIO_FUNC_EN | <token> | \ <answer> GPIO_FUNC_PTP 
#define GPIO_EXTTS_OUT_CFG (GPIO_FUNC_EN | GPIO_FUNC_PTP | <token> <answer> \ 
#define <token> 8000U <answer> RGMII_PERIOD_PS 
#define PS_PER_DEGREE <token> 360) <answer> div_u64(RGMII_PERIOD_PS, 
<token> MIN_ID_PS 1644U <answer> #define 
#define <token> 2260U <answer> MAX_ID_PS 
<token> DEFAULT_ID_PS 2000U <answer> #define 
#define PPM_TO_SUBNS_INC(ppb, <token> div_u64(GENMASK_ULL(31, 0) * \ <answer> ptp_clk_period) 
<token> * (ptp_clk_period), NSEC_PER_SEC) <answer> (ppb) 
#define NXP_C45_SKB_CB(skb) <token> nxp_c45_skb_cb *)(skb)->cb) <answer> ((struct 
struct <token> <answer> nxp_c45_phy; 
struct nxp_c45_skb_cb <token> <answer> { 
struct ptp_header <token> <answer> *header; 
<token> int type; <answer> unsigned 
#define NXP_C45_REG_FIELD(_reg, <token> _offset, _size) \ <answer> _devad, 
<token> nxp_c45_reg_field) { \ <answer> ((struct 
.reg = _reg, <token> <answer> \ 
.devad = _devad, <token> <answer> \ 
<token> = _offset, \ <answer> .offset 
.size <token> _size, \ <answer> = 
struct nxp_c45_reg_field <token> <answer> { 
<token> reg; <answer> u16 
u8 <token> <answer> devad; 
<token> offset; <answer> u8 
<token> size; <answer> u8 
struct <token> { <answer> nxp_c45_hwts 
<token> nsec; <answer> u32 
<token> sec; <answer> u32 
u8 <token> <answer> domain_number; 
<token> sequence_id; <answer> u16 
u8 <token> <answer> msg_type; 
struct nxp_c45_regmap <token> <answer> { 
phy_write_mmd(phydev, <token> <answer> MDIO_MMD_VEND1, 
<token> RING_DONE); <answer> regmap->vend1_ext_trg_ctrl, 
valid = <token> <answer> tja1120_extts_is_valid(phydev); 
<token> (!valid) <answer> if 
goto <token> <answer> tja1120_get_extts_out; 
<token> extts); <answer> nxp_c45_get_extts(priv, 
return <token> <answer> valid; 
static void nxp_c45_read_egress_ts(struct <token> *priv, <answer> nxp_c45_phy 
struct nxp_c45_hwts <token> <answer> *hwts) 
const <token> nxp_c45_regmap *regmap = nxp_c45_get_regmap(priv->phydev); <answer> struct 
struct phy_device <token> = priv->phydev; <answer> *phydev 
hwts->domain_number <token> <answer> = 
nxp_c45_read_reg_field(phydev, <token> <answer> &regmap->domain_number); 
hwts->msg_type <token> <answer> = 
<token> &regmap->msg_type); <answer> nxp_c45_read_reg_field(phydev, 
hwts->sequence_id <token> <answer> = 
nxp_c45_read_reg_field(phydev, <token> <answer> &regmap->sequence_id); 
hwts->nsec <token> <answer> = 
nxp_c45_read_reg_field(phydev, <token> <answer> &regmap->nsec_15_0); 
<token> |= <answer> hwts->nsec 
nxp_c45_read_reg_field(phydev, &regmap->nsec_29_16) << <token> <answer> 16; 
<token> = nxp_c45_read_reg_field(phydev, &regmap->sec_1_0); <answer> hwts->sec 
hwts->sec <token> nxp_c45_read_reg_field(phydev, &regmap->sec_4_2) << 2; <answer> |= 
static bool <token> nxp_c45_phy *priv, <answer> nxp_c45_get_hwtxts(struct 
struct nxp_c45_hwts <token> <answer> *hwts) 
bool <token> <answer> valid; 
u16 <token> <answer> reg; 
<token> MDIO_MMD_VEND1, VEND1_EGR_RING_CTRL, <answer> phy_write_mmd(priv->phydev, 
reg <token> phy_read_mmd(priv->phydev, MDIO_MMD_VEND1, VEND1_EGR_RING_DATA_0); <answer> = 
valid <token> !!(reg & RING_DATA_0_TS_VALID); <answer> = 
if <token> <answer> (!valid) 
goto <token> <answer> nxp_c45_get_hwtxts_out; 
<token> hwts); <answer> nxp_c45_read_egress_ts(priv, 
<token> valid; <answer> return 
static <token> tja1120_egress_ts_is_valid(struct phy_device *phydev) <answer> bool 
bool <token> <answer> valid; 
<token> reg; <answer> u16 
reg = <token> MDIO_MMD_VEND1, TJA1120_EGRESS_TS_DATA_S); <answer> phy_read_mmd(phydev, 
valid = !!(reg & <token> <answer> TJA1120_TS_VALID); 
return <token> <answer> valid; 
static bool <token> nxp_c45_phy *priv, <answer> tja1120_get_hwtxts(struct 
struct <token> *hwts) <answer> nxp_c45_hwts 
struct phy_device *phydev <token> priv->phydev; <answer> = 
<token> more_ts; <answer> bool 
bool <token> <answer> valid; 
<token> reg; <answer> u16 
reg <token> phy_read_mmd(phydev, MDIO_MMD_VEND1, TJA1120_EGRESS_TS_END); <answer> = 
<token> = !!(reg & TJA1120_MORE_TS); <answer> more_ts 
valid = <token> <answer> tja1120_egress_ts_is_valid(phydev); 
<token> (!valid) { <answer> if 
if <token> <answer> (!more_ts) 
goto <token> <answer> tja1120_get_hwtxts_out; 
phy_write_mmd(phydev, <token> <answer> MDIO_MMD_VEND1, 
<token> TJA1120_TS_VALID); <answer> TJA1120_EGRESS_TS_END, 
<token> = tja1120_egress_ts_is_valid(phydev); <answer> valid 
<token> (!valid) <answer> if 
goto <token> <answer> tja1120_get_hwtxts_out; 
nxp_c45_read_egress_ts(priv, <token> <answer> hwts); 
<token> MDIO_MMD_VEND1, TJA1120_EGRESS_TS_DATA_S, <answer> phy_clear_bits_mmd(phydev, 
<token> valid; <answer> return 
static void <token> nxp_c45_phy *priv, <answer> nxp_c45_process_txts(struct 
struct <token> *txts) <answer> nxp_c45_hwts 
struct sk_buff *skb, <token> *skb_match = NULL; <answer> *tmp, 
struct <token> shhwtstamps; <answer> skb_shared_hwtstamps 
<token> timespec64 ts; <answer> struct 
unsigned <token> flags; <answer> long 
bool <token> <answer> ts_match; 
s64 <token> <answer> ts_ns; 
spin_lock_irqsave(&priv->tx_queue.lock, <token> <answer> flags); 
<token> skb, tmp) { <answer> skb_queue_walk_safe(&priv->tx_queue, 
<token> = nxp_c45_match_ts(NXP_C45_SKB_CB(skb)->header, txts, <answer> ts_match 
if <token> <answer> (!ts_match) 
skb_match = <token> <answer> skb; 
__skb_unlink(skb, <token> <answer> &priv->tx_queue); 
spin_unlock_irqrestore(&priv->tx_queue.lock, <token> <answer> flags); 
if (skb_match) <token> <answer> { 
nxp_c45_ptp_gettimex64(&priv->caps, <token> NULL); <answer> &ts, 
<token> txts); <answer> nxp_c45_reconstruct_ts(&ts, 
memset(&shhwtstamps, <token> sizeof(shhwtstamps)); <answer> 0, 
ts_ns = <token> <answer> timespec64_to_ns(&ts); 
<token> = ns_to_ktime(ts_ns); <answer> shhwtstamps.hwtstamp 
skb_complete_tx_timestamp(skb_match, <token> <answer> &shhwtstamps); 
} else <token> <answer> { 
"the tx timestamp doesn't match with <token> skb\n"); <answer> any 
static long nxp_c45_do_aux_work(struct ptp_clock_info <token> <answer> *ptp) 
<token> nxp_c45_phy *priv = container_of(ptp, struct nxp_c45_phy, caps); <answer> struct 
<token> struct nxp_c45_phy_data *data = nxp_c45_get_data(priv->phydev); <answer> const 
bool <token> = nxp_c45_poll_txts(priv->phydev); <answer> poll_txts 
struct <token> *shhwtstamps_rx; <answer> skb_shared_hwtstamps 
struct ptp_clock_event <token> <answer> event; 
struct <token> hwts; <answer> nxp_c45_hwts 
bool reschedule = <token> <answer> false; 
struct timespec64 <token> <answer> ts; 
struct <token> *skb; <answer> sk_buff 
<token> ts_valid; <answer> bool 
u32 <token> <answer> ts_raw; 
<token> (!skb_queue_empty_lockless(&priv->tx_queue) && poll_txts) { <answer> while 
<token> = data->get_egressts(priv, &hwts); <answer> ts_valid 
if <token> { <answer> (unlikely(!ts_valid)) 
if <token> != 1 || perout->period.nsec != 0) { <answer> (perout->period.sec 
phydev_warn(phydev, "The period can <token> set only to 1 second."); <answer> be 
return <token> <answer> -EINVAL; 
if <token> & PTP_PEROUT_PHASE)) { <answer> (!(perout->flags 
if (perout->start.sec != 0 || perout->start.nsec != <token> { <answer> 0) 
phydev_warn(phydev, "The start time is <token> configurable. Should be set to 0 seconds and 0 nanoseconds."); <answer> not 
return <token> <answer> -EINVAL; 
<token> else { <answer> } 
if (perout->phase.nsec != 0 <token> <answer> && 
perout->phase.nsec != (NSEC_PER_SEC >> 1)) <token> <answer> { 
phydev_warn(phydev, "The phase can be set only <token> 0 or 500000000 nanoseconds."); <answer> to 
<token> -EINVAL; <answer> return 
if (perout->phase.nsec == <token> <answer> 0) 
nxp_c45_gpio_config(priv, pin, <token> <answer> GPIO_PPS_OUT_CFG); 
<token> &regmap->pps_enable); <answer> nxp_c45_set_reg_field(priv->phydev, 
return <token> <answer> 0; 
static void nxp_c45_set_rising_or_falling(struct <token> *phydev, <answer> phy_device 
struct ptp_extts_request <token> <answer> *extts) 
<token> (extts->flags & PTP_RISING_EDGE) <answer> if 
<token> MDIO_MMD_VEND1, <answer> phy_clear_bits_mmd(phydev, 
VEND1_PTP_CONFIG, <token> <answer> EXT_TRG_EDGE); 
if (extts->flags <token> PTP_FALLING_EDGE) <answer> & 
phy_set_bits_mmd(phydev, <token> <answer> MDIO_MMD_VEND1, 
<token> EXT_TRG_EDGE); <answer> VEND1_PTP_CONFIG, 
static void <token> phy_device *phydev, <answer> nxp_c45_set_rising_and_falling(struct 
struct <token> *extts) <answer> ptp_extts_request 
if (extts->flags <token> PTP_RISING_EDGE || <answer> & 
<token> == PTP_ENABLE_FEATURE) <answer> extts->flags 
phy_set_bits_mmd(phydev, <token> <answer> MDIO_MMD_VEND1, 
<token> MDIO_MMD_VEND1, <answer> phy_clear_bits_mmd(phydev, 
if (extts->flags & <token> <answer> PTP_FALLING_EDGE) 
phy_set_bits_mmd(phydev, <token> <answer> MDIO_MMD_VEND1, 
<token> MDIO_MMD_VEND1, <answer> phy_clear_bits_mmd(phydev, 
static int <token> nxp_c45_phy *priv, <answer> nxp_c45_extts_enable(struct 
<token> ptp_extts_request *extts, int on) <answer> struct 
const struct <token> *data = nxp_c45_get_data(priv->phydev); <answer> nxp_c45_phy_data 
int <token> <answer> pin; 
if (extts->flags & ~(PTP_ENABLE_FEATURE <token> <answer> | 
<token> | <answer> PTP_RISING_EDGE 
<token> | <answer> PTP_FALLING_EDGE 
return <token> <answer> -EOPNOTSUPP; 
if <token> <answer> (data->ack_ptp_irq) 
phy_write_mmd(phydev, <token> <answer> MDIO_MMD_VEND1, 
<token> EGR_TS_IRQ); <answer> VEND1_PTP_IRQ_ACK, 
while (data->get_egressts(priv, <token> <answer> &hwts)) 
<token> &hwts); <answer> nxp_c45_process_txts(priv, 
<token> = IRQ_HANDLED; <answer> ret 
<token> &ret); <answer> data->nmi_handler(phydev, 
nxp_c45_handle_macsec_interrupt(phydev, <token> <answer> &ret); 
<token> ret; <answer> return 
static int nxp_c45_soft_reset(struct <token> *phydev) <answer> phy_device 
int <token> <answer> ret; 
ret = phy_write_mmd(phydev, <token> VEND1_DEVICE_CONTROL, <answer> MDIO_MMD_VEND1, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> phy_read_mmd_poll_timeout(phydev, MDIO_MMD_VEND1, <answer> return 
VEND1_DEVICE_CONTROL, <token> <answer> ret, 
!(ret <token> DEVICE_CONTROL_RESET), 20000, <answer> & 
240000, <token> <answer> false); 
<token> int nxp_c45_cable_test_start(struct phy_device *phydev) <answer> static 
const <token> nxp_c45_regmap *regmap = nxp_c45_get_regmap(phydev); <answer> struct 
<token> MDIO_MMD_VEND1, <answer> phy_set_bits_mmd(phydev, 
<token> PHY_TEST_ENABLE); <answer> VEND1_PORT_FUNC_ENABLES, 
return phy_set_bits_mmd(phydev, MDIO_MMD_VEND1, <token> <answer> regmap->cable_test, 
CABLE_TEST_ENABLE | <token> <answer> CABLE_TEST_START); 
static <token> nxp_c45_cable_test_get_status(struct phy_device *phydev, <answer> int 
bool <token> <answer> *finished) 
const struct nxp_c45_regmap *regmap <token> nxp_c45_get_regmap(phydev); <answer> = 
<token> ret; <answer> int 
<token> cable_test_result; <answer> u8 
ret = nxp_c45_read_reg_field(phydev, <token> <answer> &regmap->cable_test_valid); 
if (!ret) <token> <answer> { 
<token> = false; <answer> *finished 
return <token> <answer> 0; 
*finished <token> true; <answer> = 
cable_test_result = <token> <answer> nxp_c45_read_reg_field(phydev, 
switch (cable_test_result) <token> <answer> { 
case <token> <answer> CABLE_TEST_OK: 
<token> ETHTOOL_A_CABLE_PAIR_A, <answer> ethnl_cable_test_result(phydev, 
case <token> <answer> CABLE_TEST_SHORTED: 
ethnl_cable_test_result(phydev, <token> <answer> ETHTOOL_A_CABLE_PAIR_A, 
case <token> <answer> CABLE_TEST_OPEN: 
<token> ETHTOOL_A_CABLE_PAIR_A, <answer> ethnl_cable_test_result(phydev, 
<token> ETHTOOL_A_CABLE_PAIR_A, <answer> ethnl_cable_test_result(phydev, 
phy_clear_bits_mmd(phydev, MDIO_MMD_VEND1, <token> <answer> regmap->cable_test, 
<token> MDIO_MMD_VEND1, <answer> phy_clear_bits_mmd(phydev, 
<token> PHY_TEST_ENABLE); <answer> VEND1_PORT_FUNC_ENABLES, 
return <token> <answer> nxp_c45_start_op(phydev); 
static int nxp_c45_get_sqi(struct phy_device <token> <answer> *phydev) 
<token> reg; <answer> int 
reg = phy_read_mmd(phydev, <token> VEND1_SIGNAL_QUALITY); <answer> MDIO_MMD_VEND1, 
if (!(reg & <token> <answer> SQI_VALID)) 
return <token> <answer> -EINVAL; 
reg <token> SQI_MASK; <answer> &= 
return <token> <answer> reg; 
static void tja1120_link_change_notify(struct phy_device <token> <answer> *phydev) 
if (phydev->state <token> PHY_NOLINK) { <answer> == 
phy_set_bits_mmd(phydev, <token> <answer> MDIO_MMD_VEND1, 
<token> EPHY_PCS_RESET); <answer> TJA1120_EPHY_RESETS, 
<token> MDIO_MMD_VEND1, <answer> phy_clear_bits_mmd(phydev, 
<token> EPHY_PCS_RESET); <answer> TJA1120_EPHY_RESETS, 
static int <token> phy_device *phydev) <answer> nxp_c45_get_sqi_max(struct 
<token> MAX_SQI; <answer> return 
static <token> nxp_c45_check_delay(struct phy_device *phydev, u32 delay) <answer> int 
if (delay <token> MIN_ID_PS) { <answer> < 
phydev_err(phydev, "delay value <token> than %u\n", MIN_ID_PS); <answer> smaller 
return <token> <answer> -EINVAL; 
if (delay > <token> { <answer> MAX_ID_PS) 
phydev_err(phydev, "delay value higher than <token> MAX_ID_PS); <answer> %u\n", 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
static <token> nxp_c45_counters_enable(struct phy_device *phydev) <answer> void 
const struct nxp_c45_phy_data *data = <token> <answer> nxp_c45_get_data(phydev); 
<token> MDIO_MMD_VEND1, VEND1_LINK_DROP_COUNTER, <answer> phy_set_bits_mmd(phydev, 
static <token> nxp_c45_ptp_init(struct phy_device *phydev) <answer> void 
const struct <token> *data = nxp_c45_get_data(phydev); <answer> nxp_c45_phy_data 
phy_write_mmd(phydev, <token> <answer> MDIO_MMD_VEND1, 
<token> &data->regmap->ltc_lock_ctrl); <answer> nxp_c45_clear_reg_field(phydev, 
<token> u64 nxp_c45_get_phase_shift(u64 phase_offset_raw) <answer> static 
phase_offset_raw *= <token> <answer> 10; 
phase_offset_raw <token> 738; <answer> -= 
return <token> 9); <answer> div_u64(phase_offset_raw, 
static void <token> phy_device *phydev) <answer> nxp_c45_disable_delays(struct 
phy_clear_bits_mmd(phydev, <token> VEND1_TXID, ID_ENABLE); <answer> MDIO_MMD_VEND1, 
phy_clear_bits_mmd(phydev, <token> VEND1_RXID, ID_ENABLE); <answer> MDIO_MMD_VEND1, 
static void nxp_c45_set_delays(struct <token> *phydev) <answer> phy_device 
struct nxp_c45_phy <token> = phydev->priv; <answer> *priv 
u64 <token> = priv->tx_delay; <answer> tx_delay 
u64 rx_delay = <token> <answer> priv->rx_delay; 
u64 <token> <answer> degree; 
if (phydev->interface <token> PHY_INTERFACE_MODE_RGMII_ID || <answer> == 
<token> == PHY_INTERFACE_MODE_RGMII_TXID) { <answer> phydev->interface 
degree = <token> PS_PER_DEGREE); <answer> div_u64(tx_delay, 
<token> MDIO_MMD_VEND1, VEND1_TXID, <answer> phy_write_mmd(phydev, 
ID_ENABLE <token> nxp_c45_get_phase_shift(degree)); <answer> | 
} else <token> <answer> { 
<token> MDIO_MMD_VEND1, VEND1_TXID, <answer> phy_clear_bits_mmd(phydev, 
if (phydev->interface == PHY_INTERFACE_MODE_RGMII_ID <token> <answer> || 
<token> == PHY_INTERFACE_MODE_RGMII_RXID) { <answer> phydev->interface 
degree <token> div_u64(rx_delay, PS_PER_DEGREE); <answer> = 
phy_write_mmd(phydev, <token> VEND1_RXID, <answer> MDIO_MMD_VEND1, 
ID_ENABLE | <token> <answer> nxp_c45_get_phase_shift(degree)); 
} <token> { <answer> else 
phy_clear_bits_mmd(phydev, MDIO_MMD_VEND1, <token> <answer> VEND1_RXID, 
static int nxp_c45_get_delays(struct <token> *phydev) <answer> phy_device 
struct nxp_c45_phy *priv = <token> <answer> phydev->priv; 
int <token> <answer> ret; 
if (phydev->interface == PHY_INTERFACE_MODE_RGMII_ID <token> <answer> || 
<token> == PHY_INTERFACE_MODE_RGMII_TXID) { <answer> phydev->interface 
ret = <token> <answer> device_property_read_u32(&phydev->mdio.dev, 
if <token> <answer> (ret) 
<token> = DEFAULT_ID_PS; <answer> priv->tx_delay 
<token> = nxp_c45_check_delay(phydev, priv->tx_delay); <answer> ret 
if <token> { <answer> (ret) 
<token> invalid value\n"); <answer> "tx-internal-delay-ps 
return <token> <answer> ret; 
if (phydev->interface <token> PHY_INTERFACE_MODE_RGMII_ID || <answer> == 
phydev->interface == PHY_INTERFACE_MODE_RGMII_RXID) <token> <answer> { 
<token> = device_property_read_u32(&phydev->mdio.dev, <answer> ret 
if <token> <answer> (ret) 
priv->rx_delay = <token> <answer> DEFAULT_ID_PS; 
<token> = nxp_c45_check_delay(phydev, priv->rx_delay); <answer> ret 
if <token> { <answer> (ret) 
"rx-internal-delay-ps <token> value\n"); <answer> invalid 
<token> ret; <answer> return 
<token> 0; <answer> return 
<token> int nxp_c45_set_phy_mode(struct phy_device *phydev) <answer> static 
int <token> <answer> ret; 
ret <token> phy_read_mmd(phydev, MDIO_MMD_VEND1, VEND1_ABILITIES); <answer> = 
phydev_dbg(phydev, "Clause 45 managed <token> abilities 0x%x\n", ret); <answer> PHY 
switch (phydev->interface) <token> <answer> { 
case <token> <answer> PHY_INTERFACE_MODE_RGMII: 
if (!(ret & RGMII_ABILITY)) <token> <answer> { 
phydev_err(phydev, "rgmii <token> not supported\n"); <answer> mode 
<token> -EINVAL; <answer> return 
phy_write_mmd(phydev, MDIO_MMD_VEND1, <token> <answer> VEND1_MII_BASIC_CONFIG, 
case <token> <answer> PHY_INTERFACE_MODE_RGMII_ID: 
<token> PHY_INTERFACE_MODE_RGMII_TXID: <answer> case 
case <token> <answer> PHY_INTERFACE_MODE_RGMII_RXID: 
<token> (!(ret & RGMII_ID_ABILITY)) { <answer> if 
phydev_err(phydev, "rgmii-id, rgmii-txid, rgmii-rxid modes are not <token> <answer> supported\n"); 
return <token> <answer> -EINVAL; 
phy_write_mmd(phydev, <token> VEND1_MII_BASIC_CONFIG, <answer> MDIO_MMD_VEND1, 
ret <token> nxp_c45_get_delays(phydev); <answer> = 
if <token> <answer> (ret) 
return <token> <answer> ret; 
case <token> <answer> PHY_INTERFACE_MODE_MII: 
if (!(ret & <token> { <answer> MII_ABILITY)) 
phydev_err(phydev, "mii mode not <token> <answer> supported\n"); 
<token> -EINVAL; <answer> return 
phy_write_mmd(phydev, MDIO_MMD_VEND1, <token> <answer> VEND1_MII_BASIC_CONFIG, 
case <token> <answer> PHY_INTERFACE_MODE_REVMII: 
if (!(ret <token> REVMII_ABILITY)) { <answer> & 
phydev_err(phydev, "rev-mii mode <token> supported\n"); <answer> not 
return <token> <answer> -EINVAL; 
<token> MDIO_MMD_VEND1, VEND1_MII_BASIC_CONFIG, <answer> phy_write_mmd(phydev, 
MII_BASIC_CONFIG_MII | <token> <answer> MII_BASIC_CONFIG_REV); 
<token> PHY_INTERFACE_MODE_RMII: <answer> case 
if (!(ret & RMII_ABILITY)) <token> <answer> { 
phydev_err(phydev, "rmii <token> not supported\n"); <answer> mode 
return <token> <answer> -EINVAL; 
phy_write_mmd(phydev, <token> VEND1_MII_BASIC_CONFIG, <answer> MDIO_MMD_VEND1, 
case <token> <answer> PHY_INTERFACE_MODE_SGMII: 
<token> (!(ret & SGMII_ABILITY)) { <answer> if 
<token> "sgmii mode not supported\n"); <answer> phydev_err(phydev, 
return <token> <answer> -EINVAL; 
<token> MDIO_MMD_VEND1, VEND1_MII_BASIC_CONFIG, <answer> phy_write_mmd(phydev, 
case <token> <answer> PHY_INTERFACE_MODE_INTERNAL: 
return <token> <answer> -EINVAL; 
<token> 0; <answer> return 
static int nxp_c45_config_init(struct phy_device <token> <answer> *phydev) 
<token> ret; <answer> int 
ret = <token> <answer> nxp_c45_config_enable(phydev); 
<token> (ret) { <answer> if 
<token> "Failed to enable config\n"); <answer> phydev_err(phydev, 
return <token> <answer> ret; 
phy_write_mmd(phydev, MDIO_MMD_VEND1, 0x01F8, <token> <answer> 1); 
phy_write_mmd(phydev, MDIO_MMD_VEND1, <token> 2); <answer> 0x01F9, 
phy_set_bits_mmd(phydev, MDIO_MMD_VEND1, <token> <answer> VEND1_PHY_CONFIG, 
<token> = nxp_c45_set_phy_mode(phydev); <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ret; 
<token> = AUTONEG_DISABLE; <answer> phydev->autoneg 
ret <token> nxp_c45_macsec_config_init(phydev); <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
return <token> <answer> nxp_c45_start_op(phydev); 
<token> int nxp_c45_get_features(struct phy_device *phydev) <answer> static 
linkmode_set_bit(ETHTOOL_LINK_MODE_TP_BIT, <token> <answer> phydev->supported); 
<token> phydev->supported); <answer> linkmode_set_bit(ETHTOOL_LINK_MODE_MII_BIT, 
<token> genphy_c45_pma_read_abilities(phydev); <answer> return 
static <token> nxp_c45_probe(struct phy_device *phydev) <answer> int 
<token> nxp_c45_phy *priv; <answer> struct 
bool <token> <answer> macsec_ability; 
<token> phy_abilities; <answer> int 
<token> ptp_ability; <answer> bool 
<token> ret = 0; <answer> int 
priv = devm_kzalloc(&phydev->mdio.dev, <token> GFP_KERNEL); <answer> sizeof(*priv), 
if <token> <answer> (!priv) 
return <token> <answer> -ENOMEM; 
<token> = phydev; <answer> priv->phydev 
phydev->priv = <token> <answer> priv; 
phy_abilities = phy_read_mmd(phydev, <token> <answer> MDIO_MMD_VEND1, 
ptp_ability = <token> & PTP_ABILITY); <answer> !!(phy_abilities 
if <token> { <answer> (!ptp_ability) 
phydev_dbg(phydev, "the <token> does not support PTP"); <answer> phy 
<token> no_ptp_support; <answer> goto 
if <token> && <answer> (IS_ENABLED(CONFIG_PTP_1588_CLOCK) 
<token> { <answer> IS_ENABLED(CONFIG_NETWORK_PHY_TIMESTAMPING)) 
priv->mii_ts.rxtstamp = <token> <answer> nxp_c45_rxtstamp; 
<token> = nxp_c45_txtstamp; <answer> priv->mii_ts.txtstamp 
priv->mii_ts.hwtstamp = <token> <answer> nxp_c45_hwtstamp; 
priv->mii_ts.ts_info = <token> <answer> nxp_c45_ts_info; 
phydev->mii_ts = <token> <answer> &priv->mii_ts; 
ret <token> nxp_c45_init_ptp_clock(priv); <answer> = 
} else <token> <answer> { 
phydev_dbg(phydev, "PTP support not enabled even <token> the phy supports it"); <answer> if 
macsec_ability <token> !!(phy_abilities & MACSEC_ABILITY); <answer> = 
if (!macsec_ability) <token> <answer> { 
phydev_info(phydev, "the phy does not support <token> <answer> MACsec\n"); 
goto <token> <answer> no_macsec_support; 
if <token> { <answer> (IS_ENABLED(CONFIG_MACSEC)) 
ret <token> nxp_c45_macsec_probe(phydev); <answer> = 
phydev_dbg(phydev, <token> support enabled."); <answer> "MACsec 
} <token> { <answer> else 
phydev_dbg(phydev, "MACsec support not enabled <token> if the phy supports it"); <answer> even 
return <token> <answer> ret; 
static <token> nxp_c45_remove(struct phy_device *phydev) <answer> void 
<token> nxp_c45_phy *priv = phydev->priv; <answer> struct 
if <token> <answer> (priv->ptp_clock) 
static <token> tja1103_counters_enable(struct phy_device *phydev) <answer> void 
<token> MDIO_MMD_VEND1, VEND1_RX_PREAMBLE_COUNT, <answer> phy_set_bits_mmd(phydev, 
phy_set_bits_mmd(phydev, MDIO_MMD_VEND1, <token> <answer> VEND1_TX_PREAMBLE_COUNT, 
<token> MDIO_MMD_VEND1, VEND1_RX_IPG_LENGTH, <answer> phy_set_bits_mmd(phydev, 
phy_set_bits_mmd(phydev, MDIO_MMD_VEND1, <token> <answer> VEND1_TX_IPG_LENGTH, 
static void tja1103_ptp_init(struct phy_device <token> <answer> *phydev) 
<token> MDIO_MMD_VEND1, VEND1_RX_TS_INSRT_CTRL, <answer> phy_write_mmd(phydev, 
<token> MDIO_MMD_VEND1, VEND1_PORT_FUNC_ENABLES, <answer> phy_set_bits_mmd(phydev, 
static void tja1103_ptp_enable(struct phy_device <token> bool enable) <answer> *phydev, 
if <token> <answer> (enable) 
<token> MDIO_MMD_VEND1, <answer> phy_clear_bits_mmd(phydev, 
phy_set_bits_mmd(phydev, <token> <answer> MDIO_MMD_VEND1, 
static <token> tja1103_nmi_handler(struct phy_device *phydev, <answer> void 
<token> *irq_status) <answer> irqreturn_t 
int <token> <answer> ret; 
ret = <token> MDIO_MMD_VEND1, <answer> phy_read_mmd(phydev, 
if <token> & FUSA_PASS) { <answer> (ret 
<token> MDIO_MMD_VEND1, <answer> phy_write_mmd(phydev, 
<token> = IRQ_HANDLED; <answer> *irq_status 
static const struct nxp_c45_regmap <token> = { <answer> tja1103_regmap 
<token> = 0x1104, <answer> .vend1_ptp_clk_period 
.vend1_event_msg_filt = <token> <answer> 0x1148, 
<token> = <answer> .pps_enable 
NXP_C45_REG_FIELD(0x1102, MDIO_MMD_VEND1, 3, <token> <answer> 1), 
.pps_polarity <token> <answer> = 
NXP_C45_REG_FIELD(0x1102, MDIO_MMD_VEND1, <token> 1), <answer> 2, 
.ltc_lock_ctrl <token> <answer> = 
NXP_C45_REG_FIELD(0x1115, <token> 0, 1), <answer> MDIO_MMD_VEND1, 
.ltc_read <token> <answer> = 
NXP_C45_REG_FIELD(0x1105, MDIO_MMD_VEND1, <token> 1), <answer> 2, 
.ltc_write <token> <answer> = 
<token> MDIO_MMD_VEND1, 0, 1), <answer> NXP_C45_REG_FIELD(0x1105, 
.vend1_ltc_wr_nsec_0 <token> 0x1106, <answer> = 
.vend1_ltc_wr_nsec_1 = <token> <answer> 0x1107, 
.vend1_ltc_wr_sec_0 <token> 0x1108, <answer> = 
<token> = 0x1109, <answer> .vend1_ltc_wr_sec_1 
.vend1_ltc_rd_nsec_0 <token> 0x110A, <answer> = 
<token> = 0x110B, <answer> .vend1_ltc_rd_nsec_1 
<token> = 0x110C, <answer> .vend1_ltc_rd_sec_0 
.vend1_ltc_rd_sec_1 <token> 0x110D, <answer> = 
<token> = 0x110F, <answer> .vend1_rate_adj_subns_0 
.vend1_rate_adj_subns_1 <token> 0x1110, <answer> = 
<token> = <answer> .irq_egr_ts_en 
NXP_C45_REG_FIELD(0x1131, MDIO_MMD_VEND1, 0, <token> <answer> 1), 
.irq_egr_ts_status <token> <answer> = 
NXP_C45_REG_FIELD(0x1132, MDIO_MMD_VEND1, 0, <token> <answer> 1), 
.domain_number <token> <answer> = 
NXP_C45_REG_FIELD(0x114E, MDIO_MMD_VEND1, <token> 8), <answer> 0, 
<token> = <answer> .msg_type 
NXP_C45_REG_FIELD(0x114E, <token> 8, 4), <answer> MDIO_MMD_VEND1, 
<token> = <answer> .sequence_id 
NXP_C45_REG_FIELD(0x114F, <token> 0, 16), <answer> MDIO_MMD_VEND1, 
<token> = <answer> .sec_1_0 
NXP_C45_REG_FIELD(0x1151, MDIO_MMD_VEND1, <token> 2), <answer> 14, 
.sec_4_2 <token> <answer> = 
NXP_C45_REG_FIELD(0x114E, MDIO_MMD_VEND1, <token> 3), <answer> 12, 
<token> = <answer> .nsec_15_0 
NXP_C45_REG_FIELD(0x1150, MDIO_MMD_VEND1, 0, <token> <answer> 16), 
<token> = <answer> .nsec_29_16 
NXP_C45_REG_FIELD(0x1151, <token> 0, 14), <answer> MDIO_MMD_VEND1, 
.vend1_ext_trg_data_0 = <token> <answer> 0x1121, 
.vend1_ext_trg_data_1 <token> 0x1122, <answer> = 
.vend1_ext_trg_data_2 = <token> <answer> 0x1123, 
.vend1_ext_trg_data_3 <token> 0x1124, <answer> = 
.vend1_ext_trg_ctrl <token> 0x1126, <answer> = 
.cable_test = <token> <answer> 0x8330, 
.cable_test_valid <token> <answer> = 
<token> MDIO_MMD_VEND1, 13, 1), <answer> NXP_C45_REG_FIELD(0x8330, 
<token> = <answer> .cable_test_result 
NXP_C45_REG_FIELD(0x8330, MDIO_MMD_VEND1, 0, <token> <answer> 3), 
static const <token> nxp_c45_phy_data tja1103_phy_data = { <answer> struct 
.regmap <token> &tja1103_regmap, <answer> = 
.stats <token> tja1103_hw_stats, <answer> = 
.n_stats = <token> <answer> ARRAY_SIZE(tja1103_hw_stats), 
.ptp_clk_period <token> PTP_CLK_PERIOD_100BT1, <answer> = 
.ext_ts_both_edges <token> false, <answer> = 
.ack_ptp_irq = <token> <answer> false, 
.counters_enable <token> tja1103_counters_enable, <answer> = 
.get_egressts <token> nxp_c45_get_hwtxts, <answer> = 
<token> = nxp_c45_get_extts, <answer> .get_extts 
<token> = tja1103_ptp_init, <answer> .ptp_init 
<token> = tja1103_ptp_enable, <answer> .ptp_enable 
<token> = tja1103_nmi_handler, <answer> .nmi_handler 
static void tja1120_counters_enable(struct <token> *phydev) <answer> phy_device 
phy_set_bits_mmd(phydev, <token> VEND1_SYMBOL_ERROR_CNT_XTD, <answer> MDIO_MMD_VEND1, 
<token> MDIO_MMD_VEND1, VEND1_MONITOR_STATUS, <answer> phy_set_bits_mmd(phydev, 
phy_set_bits_mmd(phydev, <token> VEND1_MONITOR_CONFIG, <answer> MDIO_MMD_VEND1, 
ALL_FRAMES_CNT_EN <token> LOST_FRAMES_CNT_EN); <answer> | 
static void tja1120_ptp_init(struct phy_device <token> <answer> *phydev) 
phy_write_mmd(phydev, <token> TJA1120_RX_TS_INSRT_CTRL, <answer> MDIO_MMD_VEND1, 
TJA1120_RX_TS_INSRT_EN <token> TJA1120_TS_INSRT_MODE); <answer> | 
<token> MDIO_MMD_VEND1, TJA1120_VEND1_EXT_TS_MODE, <answer> phy_write_mmd(phydev, 
phy_set_bits_mmd(phydev, MDIO_MMD_VEND1, <token> <answer> VEND1_DEVICE_CONFIG, 
static <token> tja1120_ptp_enable(struct phy_device *phydev, bool enable) <answer> void 
<token> (enable) <answer> if 
<token> MDIO_MMD_VEND1, <answer> phy_set_bits_mmd(phydev, 
<token> MDIO_MMD_VEND1, <answer> phy_clear_bits_mmd(phydev, 
static void tja1120_nmi_handler(struct phy_device <token> <answer> *phydev, 
irqreturn_t <token> <answer> *irq_status) 
int <token> <answer> ret; 
ret <token> phy_read_mmd(phydev, MDIO_MMD_VEND1, <answer> = 
if (ret <token> TJA1120_DEV_BOOT_DONE) { <answer> & 
<token> MDIO_MMD_VEND1, <answer> phy_write_mmd(phydev, 
*irq_status = <token> <answer> IRQ_HANDLED; 
static const <token> nxp_c45_regmap tja1120_regmap = { <answer> struct 
.vend1_ptp_clk_period <token> 0x1020, <answer> = 
<token> = 0x9010, <answer> .vend1_event_msg_filt 
.pps_enable <token> <answer> = 
NXP_C45_REG_FIELD(0x1006, MDIO_MMD_VEND1, 4, <token> <answer> 1), 
.pps_polarity <token> <answer> = 
NXP_C45_REG_FIELD(0x1006, <token> 5, 1), <answer> MDIO_MMD_VEND1, 
<token> = <answer> .ltc_lock_ctrl 
NXP_C45_REG_FIELD(0x1006, MDIO_MMD_VEND1, <token> 1), <answer> 2, 
<token> = <answer> .ltc_read 
NXP_C45_REG_FIELD(0x1000, <token> 1, 1), <answer> MDIO_MMD_VEND1, 
<token> = <answer> .ltc_write 
NXP_C45_REG_FIELD(0x1000, <token> 2, 1), <answer> MDIO_MMD_VEND1, 
.vend1_ltc_wr_nsec_0 = <token> <answer> 0x1040, 
.vend1_ltc_wr_nsec_1 = <token> <answer> 0x1041, 
.vend1_ltc_wr_sec_0 = <token> <answer> 0x1042, 
<token> = 0x1043, <answer> .vend1_ltc_wr_sec_1 
<token> = 0x1048, <answer> .vend1_ltc_rd_nsec_0 
.vend1_ltc_rd_nsec_1 = <token> <answer> 0x1049, 
.vend1_ltc_rd_sec_0 = <token> <answer> 0x104A, 
.vend1_ltc_rd_sec_1 = <token> <answer> 0x104B, 
.vend1_rate_adj_subns_0 <token> 0x1030, <answer> = 
.vend1_rate_adj_subns_1 <token> 0x1031, <answer> = 
<token> = <answer> .irq_egr_ts_en 
NXP_C45_REG_FIELD(0x900A, MDIO_MMD_VEND1, <token> 1), <answer> 1, 
.irq_egr_ts_status <token> <answer> = 
<token> MDIO_MMD_VEND1, 1, 1), <answer> NXP_C45_REG_FIELD(0x900C, 
.domain_number <token> <answer> = 
<token> MDIO_MMD_VEND1, 8, 8), <answer> NXP_C45_REG_FIELD(0x9061, 
.msg_type <token> <answer> = 
NXP_C45_REG_FIELD(0x9061, <token> 4, 4), <answer> MDIO_MMD_VEND1, 
.sequence_id <token> <answer> = 
NXP_C45_REG_FIELD(0x9062, MDIO_MMD_VEND1, <token> 16), <answer> 0, 
.sec_1_0 <token> <answer> = 
<token> MDIO_MMD_VEND1, 0, 2), <answer> NXP_C45_REG_FIELD(0x9065, 
<token> = <answer> .sec_4_2 
NXP_C45_REG_FIELD(0x9065, <token> 2, 3), <answer> MDIO_MMD_VEND1, 
.nsec_15_0 <token> <answer> = 
NXP_C45_REG_FIELD(0x9063, MDIO_MMD_VEND1, 0, <token> <answer> 16), 
.nsec_29_16 <token> <answer> = 
NXP_C45_REG_FIELD(0x9064, MDIO_MMD_VEND1, 0, <token> <answer> 14), 
<token> = 0x1071, <answer> .vend1_ext_trg_data_0 
.vend1_ext_trg_data_1 = <token> <answer> 0x1072, 
.vend1_ext_trg_data_2 = <token> <answer> 0x1073, 
<token> = 0x1074, <answer> .vend1_ext_trg_data_3 
<token> = 0x1075, <answer> .vend1_ext_trg_ctrl 
<token> = 0x8360, <answer> .cable_test 
<token> = <answer> .cable_test_valid 
NXP_C45_REG_FIELD(0x8361, <token> 15, 1), <answer> MDIO_MMD_VEND1, 
<token> = <answer> .cable_test_result 
NXP_C45_REG_FIELD(0x8361, MDIO_MMD_VEND1, 0, <token> <answer> 3), 
static const struct nxp_c45_phy_data tja1120_phy_data <token> { <answer> = 
.regmap = <token> <answer> &tja1120_regmap, 
.stats = <token> <answer> tja1120_hw_stats, 
<token> = ARRAY_SIZE(tja1120_hw_stats), <answer> .n_stats 
<token> = PTP_CLK_PERIOD_1000BT1, <answer> .ptp_clk_period 
.ext_ts_both_edges <token> true, <answer> = 
<token> = true, <answer> .ack_ptp_irq 
.counters_enable = <token> <answer> tja1120_counters_enable, 
.get_egressts = <token> <answer> tja1120_get_hwtxts, 
<token> = tja1120_get_extts, <answer> .get_extts 
<token> = tja1120_ptp_init, <answer> .ptp_init 
<token> = tja1120_ptp_enable, <answer> .ptp_enable 
<token> = tja1120_nmi_handler, <answer> .nmi_handler 
<token> struct phy_driver nxp_c45_driver[] = { <answer> static 
.name <token> "NXP C45 TJA1103", <answer> = 
<token> = nxp_c45_get_features, <answer> .get_features 
.driver_data = <token> <answer> &tja1103_phy_data, 
.probe <token> nxp_c45_probe, <answer> = 
.soft_reset = <token> <answer> nxp_c45_soft_reset, 
.config_aneg <token> genphy_c45_config_aneg, <answer> = 
<token> = nxp_c45_config_init, <answer> .config_init 
.config_intr = <token> <answer> tja1103_config_intr, 
.handle_interrupt = <token> <answer> nxp_c45_handle_interrupt, 
<token> = genphy_c45_read_status, <answer> .read_status 
.suspend = <token> <answer> genphy_c45_pma_suspend, 
.resume <token> genphy_c45_pma_resume, <answer> = 
<token> = nxp_c45_get_sset_count, <answer> .get_sset_count 
.get_strings <token> nxp_c45_get_strings, <answer> = 
.get_stats = <token> <answer> nxp_c45_get_stats, 
<token> = nxp_c45_cable_test_start, <answer> .cable_test_start 
.cable_test_get_status = <token> <answer> nxp_c45_cable_test_get_status, 
<token> = genphy_c45_loopback, <answer> .set_loopback 
.get_sqi = <token> <answer> nxp_c45_get_sqi, 
.get_sqi_max <token> nxp_c45_get_sqi_max, <answer> = 
.remove = <token> <answer> nxp_c45_remove, 
.name = <token> C45 TJA1120", <answer> "NXP 
.get_features = <token> <answer> nxp_c45_get_features, 
.driver_data <token> &tja1120_phy_data, <answer> = 
<token> = nxp_c45_probe, <answer> .probe 
.soft_reset = <token> <answer> nxp_c45_soft_reset, 
.config_aneg <token> genphy_c45_config_aneg, <answer> = 
.config_init <token> nxp_c45_config_init, <answer> = 
.config_intr = <token> <answer> tja1120_config_intr, 
.handle_interrupt = <token> <answer> nxp_c45_handle_interrupt, 
.read_status = <token> <answer> genphy_c45_read_status, 
.link_change_notify = <token> <answer> tja1120_link_change_notify, 
.suspend <token> genphy_c45_pma_suspend, <answer> = 
.resume = <token> <answer> genphy_c45_pma_resume, 
.get_sset_count <token> nxp_c45_get_sset_count, <answer> = 
.get_strings = <token> <answer> nxp_c45_get_strings, 
<token> = nxp_c45_get_stats, <answer> .get_stats 
<token> = nxp_c45_cable_test_start, <answer> .cable_test_start 
.cable_test_get_status = <token> <answer> nxp_c45_cable_test_get_status, 
.set_loopback = <token> <answer> genphy_c45_loopback, 
.get_sqi = <token> <answer> nxp_c45_get_sqi, 
.get_sqi_max <token> nxp_c45_get_sqi_max, <answer> = 
.remove = <token> <answer> nxp_c45_remove, 
static struct <token> __maybe_unused nxp_c45_tbl[] = { <answer> mdio_device_id 
{ PHY_ID_MATCH_MODEL(PHY_ID_TJA_1103) <token> <answer> }, 
<token> PHY_ID_MATCH_MODEL(PHY_ID_TJA_1120) }, <answer> { 
<token> "cxgb4.h" <answer> #include 
<token> CXGB4_NUM_TRIPS 1 <answer> #define 
static int cxgb4_thermal_get_temp(struct thermal_zone_device <token> <answer> *tzdev, 
<token> *temp) <answer> int 
struct adapter <token> = thermal_zone_device_priv(tzdev); <answer> *adap 
u32 <token> val; <answer> param, 
int <token> <answer> ret; 
<token> = (FW_PARAMS_MNEM_V(FW_PARAMS_MNEM_DEV) | <answer> param 
<token> | <answer> FW_PARAMS_PARAM_X_V(FW_PARAMS_PARAM_DEV_DIAG) 
ret = t4_query_params(adap, adap->mbox, adap->pf, 0, <token> <answer> 1, 
<token> &val); <answer> &param, 
if <token> < 0 || val == 0) <answer> (ret 
<token> -1; <answer> return 
*temp <token> val * 1000; <answer> = 
<token> 0; <answer> return 
static struct thermal_zone_device_ops cxgb4_thermal_ops = <token> <answer> { 
.get_temp = <token> <answer> cxgb4_thermal_get_temp, 
static struct thermal_trip trip = { .type <token> THERMAL_TRIP_CRITICAL } ; <answer> = 
int cxgb4_thermal_init(struct adapter <token> <answer> *adap) 
<token> ch_thermal *ch_thermal = &adap->ch_thermal; <answer> struct 
char <token> <answer> ch_tz_name[THERMAL_NAME_LENGTH]; 
int <token> = CXGB4_NUM_TRIPS; <answer> num_trip 
u32 param, <token> <answer> val; 
<token> ret; <answer> int 
param = <token> | <answer> (FW_PARAMS_MNEM_V(FW_PARAMS_MNEM_DEV) 
<token> | <answer> FW_PARAMS_PARAM_X_V(FW_PARAMS_PARAM_DEV_DIAG) 
ret = t4_query_params(adap, adap->mbox, adap->pf, 0, <token> <answer> 1, 
<token> &val); <answer> &param, 
if <token> < 0) { <answer> (ret 
<token> KMSG_COMPONENT "IPVS" <answer> #define 
#define <token> KMSG_COMPONENT ": " fmt <answer> pr_fmt(fmt) 
<token> <linux/in.h> <answer> #include 
#include <token> <answer> <linux/ip.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/netfilter.h> 
#include <token> <answer> <linux/netfilter_ipv4.h> 
<token> <net/ip_vs.h> <answer> #include 
<token> PORT_ISAKMP 500 <answer> #define 
<token> void <answer> static 
ah_esp_conn_fill_param_proto(struct netns_ipvs <token> int af, <answer> *ipvs, 
const <token> ip_vs_iphdr *iph, <answer> struct 
struct ip_vs_conn_param <token> <answer> *p) 
<token> (likely(!ip_vs_iph_inverse(iph))) <answer> if 
ip_vs_conn_fill_param(ipvs, <token> IPPROTO_UDP, <answer> af, 
<token> htons(PORT_ISAKMP), <answer> &iph->saddr, 
&iph->daddr, <token> p); <answer> htons(PORT_ISAKMP), 
<token> af, IPPROTO_UDP, <answer> ip_vs_conn_fill_param(ipvs, 
&iph->daddr, <token> <answer> htons(PORT_ISAKMP), 
<token> htons(PORT_ISAKMP), p); <answer> &iph->saddr, 
static struct <token> * <answer> ip_vs_conn 
ah_esp_conn_in_get(struct netns_ipvs *ipvs, int af, const <token> sk_buff *skb, <answer> struct 
const struct <token> *iph) <answer> ip_vs_iphdr 
<token> ip_vs_conn *cp; <answer> struct 
struct ip_vs_conn_param <token> <answer> p; 
ah_esp_conn_fill_param_proto(ipvs, af, iph, <token> <answer> &p); 
cp = <token> <answer> ip_vs_conn_in_get(&p); 
if (!cp) <token> <answer> { 
IP_VS_DBG_BUF(12, "Unknown <token> entry for outin packet " <answer> ISAKMP 
<token> %s->%s\n", <answer> "%s%s 
ip_vs_iph_icmp(iph) ? "ICMP+" <token> "", <answer> : 
<token> &iph->saddr), <answer> IP_VS_DBG_ADDR(af, 
IP_VS_DBG_ADDR(af, <token> <answer> &iph->daddr)); 
<token> cp; <answer> return 
<token> struct ip_vs_conn * <answer> static 
ah_esp_conn_out_get(struct netns_ipvs *ipvs, int af, const struct sk_buff <token> <answer> *skb, 
const <token> ip_vs_iphdr *iph) <answer> struct 
<token> ip_vs_conn *cp; <answer> struct 
struct <token> p; <answer> ip_vs_conn_param 
ah_esp_conn_fill_param_proto(ipvs, af, <token> &p); <answer> iph, 
<token> = ip_vs_conn_out_get(&p); <answer> cp 
if (!cp) <token> <answer> { 
IP_VS_DBG_BUF(12, "Unknown ISAKMP <token> for inout packet " <answer> entry 
<token> %s->%s\n", <answer> "%s%s 
ip_vs_iph_icmp(iph) ? "ICMP+" <token> "", <answer> : 
<token> &iph->saddr), <answer> IP_VS_DBG_ADDR(af, 
<token> &iph->daddr)); <answer> IP_VS_DBG_ADDR(af, 
return <token> <answer> cp; 
<token> int <answer> static 
ah_esp_conn_schedule(struct netns_ipvs *ipvs, <token> af, struct sk_buff *skb, <answer> int 
<token> ip_vs_proto_data *pd, <answer> struct 
int <token> struct ip_vs_conn **cpp, <answer> *verdict, 
struct <token> *iph) <answer> ip_vs_iphdr 
*verdict <token> NF_ACCEPT; <answer> = 
return <token> <answer> 0; 
#ifdef <token> <answer> CONFIG_IP_VS_PROTO_AH 
struct ip_vs_protocol ip_vs_protocol_ah = <token> <answer> { 
.name <token> "AH", <answer> = 
<token> = IPPROTO_AH, <answer> .protocol 
.num_states = <token> <answer> 1, 
<token> = 1, <answer> .dont_defrag 
.init = <token> <answer> NULL, 
<token> = NULL, <answer> .exit 
.conn_schedule = <token> <answer> ah_esp_conn_schedule, 
.conn_in_get <token> ah_esp_conn_in_get, <answer> = 
.conn_out_get <token> ah_esp_conn_out_get, <answer> = 
.snat_handler <token> NULL, <answer> = 
.dnat_handler <token> NULL, <answer> = 
.state_transition <token> NULL, <answer> = 
.register_app <token> NULL, <answer> = 
<token> = NULL, <answer> .unregister_app 
<token> = NULL, <answer> .app_conn_bind 
.debug_packet = <token> <answer> ip_vs_tcpudp_debug_packet, 
#include <token> <answer> <asm/page.h> 
#include <token> <answer> <linux/crc8.h> 
<token> <linux/debugfs.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/hwmon.h> 
#include <token> <answer> <linux/hwmon-sysfs.h> 
#include <token> <answer> <linux/i2c.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/slab.h> <answer> #include 
<token> <linux/jiffies.h> <answer> #include 
<token> temperature; <answer> int 
int <token> <answer> temperature_limits[SHT3X_NUM_LIMIT_CMD]; 
<token> humidity; <answer> u32 
u32 <token> <answer> humidity_limits[SHT3X_NUM_LIMIT_CMD]; 
static u8 <token> value) <answer> get_mode_from_update_interval(u16 
<token> index; <answer> size_t 
u8 number_of_modes <token> ARRAY_SIZE(mode_to_update_interval); <answer> = 
if <token> == 0) <answer> (value 
return <token> <answer> 0; 
return ((21875 * (int)raw) >> 13) <token> 45000; <answer> - 
static u32 sht3x_extract_humidity(u16 <token> <answer> raw) 
return (12500 * <token> >> 13; <answer> (u32)raw) 
static <token> sht3x_data *sht3x_update_client(struct device *dev) <answer> struct 
struct <token> *data = dev_get_drvdata(dev); <answer> sht3x_data 
<token> i2c_client *client = data->client; <answer> struct 
<token> interval_ms = mode_to_update_interval[data->mode]; <answer> u16 
unsigned long <token> = msecs_to_jiffies(interval_ms); <answer> interval_jiffies 
unsigned char <token> <answer> buf[SHT3X_RESPONSE_LENGTH]; 
<token> val; <answer> u16 
int ret <token> 0; <answer> = 
if (time_after(jiffies, data->last_update <token> interval_jiffies)) { <answer> + 
ret = sht3x_read_from_command(client, data, <token> buf, <answer> data->command, 
<token> data->wait_time); <answer> sizeof(buf), 
<token> (ret) <answer> if 
goto <token> <answer> out; 
<token> = be16_to_cpup((__be16 *)buf); <answer> val 
data->temperature <token> sht3x_extract_temperature(val); <answer> = 
val = be16_to_cpup((__be16 *)(buf <token> 3)); <answer> + 
data->humidity <token> sht3x_extract_humidity(val); <answer> = 
data->last_update <token> jiffies; <answer> = 
<token> (ret) <answer> if 
return <token> <answer> ERR_PTR(ret); 
return <token> <answer> data; 
static <token> temp1_input_read(struct device *dev) <answer> int 
struct sht3x_data *data <token> sht3x_update_client(dev); <answer> = 
<token> (IS_ERR(data)) <answer> if 
<token> PTR_ERR(data); <answer> return 
return <token> <answer> data->temperature; 
static <token> humidity1_input_read(struct device *dev) <answer> int 
struct sht3x_data *data = <token> <answer> sht3x_update_client(dev); 
<token> (IS_ERR(data)) <answer> if 
<token> PTR_ERR(data); <answer> return 
<token> data->humidity; <answer> return 
static int limits_update(struct sht3x_data <token> <answer> *data) 
<token> ret; <answer> int 
u8 <token> <answer> index; 
int <token> <answer> temperature; 
<token> humidity; <answer> u32 
u16 <token> <answer> raw; 
<token> buffer[SHT3X_RESPONSE_LENGTH]; <answer> char 
const struct sht3x_limit_commands <token> <answer> *commands; 
struct i2c_client <token> = data->client; <answer> *client 
<token> (index = 0; index < SHT3X_NUM_LIMIT_CMD; index++) { <answer> for 
commands = <token> <answer> &limit_commands[index]; 
ret = <token> data, <answer> sht3x_read_from_command(client, 
commands->read_command, <token> <answer> buffer, 
<token> 0); <answer> SHT3X_RESPONSE_LENGTH, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
raw = <token> *)buffer); <answer> be16_to_cpup((__be16 
<token> = sht3x_extract_temperature((raw & 0x01ff) << 7); <answer> temperature 
humidity = <token> & 0xfe00); <answer> sht3x_extract_humidity(raw 
data->temperature_limits[index] = <token> <answer> temperature; 
<token> = humidity; <answer> data->humidity_limits[index] 
<token> ret; <answer> return 
static int temp1_limit_read(struct device *dev, <token> index) <answer> int 
struct <token> *data = dev_get_drvdata(dev); <answer> sht3x_data 
return <token> <answer> data->temperature_limits[index]; 
static int humidity1_limit_read(struct device *dev, <token> index) <answer> int 
struct sht3x_data <token> = dev_get_drvdata(dev); <answer> *data 
<token> data->humidity_limits[index]; <answer> return 
static size_t <token> device *dev, <answer> limit_write(struct 
<token> index, <answer> u8 
<token> temperature, <answer> int 
u32 <token> <answer> humidity) 
char buffer[SHT3X_CMD_LENGTH <token> SHT3X_WORD_LEN + SHT3X_CRC8_LEN]; <answer> + 
<token> *position = buffer; <answer> char 
<token> ret; <answer> int 
<token> raw; <answer> u16 
struct sht3x_data *data <token> dev_get_drvdata(dev); <answer> = 
struct <token> *client = data->client; <answer> i2c_client 
const <token> sht3x_limit_commands *commands; <answer> struct 
<token> = &limit_commands[index]; <answer> commands 
memcpy(position, <token> SHT3X_CMD_LENGTH); <answer> commands->write_command, 
<token> += SHT3X_CMD_LENGTH; <answer> position 
raw = ((u32)(temperature + 45000) * 24543) >> (16 + <token> <answer> 7); 
raw |= ((humidity * 42950) >> 16) <token> 0xfe00; <answer> & 
*((__be16 <token> = cpu_to_be16(raw); <answer> *)position) 
<token> += SHT3X_WORD_LEN; <answer> position 
*position = <token> <answer> crc8(sht3x_crc8_table, 
<token> - SHT3X_WORD_LEN, <answer> position 
ret <token> i2c_master_send(client, buffer, sizeof(buffer)); <answer> = 
if <token> != sizeof(buffer)) <answer> (ret 
<token> ret < 0 ? ret : -EIO; <answer> return 
data->temperature_limits[index] <token> temperature; <answer> = 
data->humidity_limits[index] <token> humidity; <answer> = 
<token> 0; <answer> return 
static int temp1_limit_write(struct device *dev, int index, int <token> <answer> val) 
<token> temperature; <answer> int 
int <token> <answer> ret; 
struct <token> *data = dev_get_drvdata(dev); <answer> sht3x_data 
temperature = clamp_val(val, <token> <answer> SHT3X_MIN_TEMPERATURE, 
ret = limit_write(dev, <token> temperature, <answer> index, 
return <token> <answer> ret; 
static int humidity1_limit_write(struct device *dev, <token> index, int val) <answer> int 
u32 <token> <answer> humidity; 
int <token> <answer> ret; 
struct <token> *data = dev_get_drvdata(dev); <answer> sht3x_data 
humidity = clamp_val(val, SHT3X_MIN_HUMIDITY, <token> <answer> SHT3X_MAX_HUMIDITY); 
<token> = limit_write(dev, index, data->temperature_limits[index], <answer> ret 
return <token> <answer> ret; 
static void sht3x_select_command(struct <token> *data) <answer> sht3x_data 
if (data->mode <token> 0) { <answer> > 
data->command <token> sht3x_cmd_measure_periodic_mode; <answer> = 
data->wait_time <token> 0; <answer> = 
} else <token> <answer> { 
if <token> == high_repeatability) { <answer> (data->repeatability 
data->command = <token> <answer> sht3x_cmd_measure_single_hpm; 
data->wait_time = <token> <answer> SHT3X_SINGLE_WAIT_TIME_HPM; 
} <token> if (data->repeatability == medium_repeatability) { <answer> else 
data->command <token> sht3x_cmd_measure_single_mpm; <answer> = 
data->wait_time <token> SHT3X_SINGLE_WAIT_TIME_MPM; <answer> = 
<token> else { <answer> } 
data->command <token> sht3x_cmd_measure_single_lpm; <answer> = 
data->wait_time <token> SHT3X_SINGLE_WAIT_TIME_LPM; <answer> = 
<token> int status_register_read(struct device *dev, <answer> static 
char <token> int length) <answer> *buffer, 
int <token> <answer> ret; 
struct sht3x_data *data <token> dev_get_drvdata(dev); <answer> = 
<token> i2c_client *client = data->client; <answer> struct 
ret = sht3x_read_from_command(client, <token> sht3x_cmd_read_status_reg, <answer> data, 
<token> length, 0); <answer> buffer, 
<token> ret; <answer> return 
static <token> temp1_alarm_read(struct device *dev) <answer> int 
char buffer[SHT3X_WORD_LEN + <token> <answer> SHT3X_CRC8_LEN]; 
<token> ret; <answer> int 
ret = <token> buffer, <answer> status_register_read(dev, 
SHT3X_WORD_LEN + <token> <answer> SHT3X_CRC8_LEN); 
<token> (ret) <answer> if 
return <token> <answer> ret; 
return !!(buffer[0] <token> 0x04); <answer> & 
<token> int humidity1_alarm_read(struct device *dev) <answer> static 
<token> buffer[SHT3X_WORD_LEN + SHT3X_CRC8_LEN]; <answer> char 
int <token> <answer> ret; 
ret = status_register_read(dev, <token> <answer> buffer, 
<token> + SHT3X_CRC8_LEN); <answer> SHT3X_WORD_LEN 
<token> (ret) <answer> if 
<token> ret; <answer> return 
return !!(buffer[0] <token> 0x08); <answer> & 
<token> ssize_t heater_enable_show(struct device *dev, <answer> static 
struct device_attribute <token> <answer> *attr, 
char <token> <answer> *buf) 
char buffer[SHT3X_WORD_LEN <token> SHT3X_CRC8_LEN]; <answer> + 
int <token> <answer> ret; 
ret = <token> buffer, <answer> status_register_read(dev, 
SHT3X_WORD_LEN + <token> <answer> SHT3X_CRC8_LEN); 
<token> (ret) <answer> if 
return <token> <answer> ret; 
return sysfs_emit(buf, "%d\n", <token> & 0x20)); <answer> !!(buffer[0] 
static ssize_t heater_enable_store(struct device <token> <answer> *dev, 
struct <token> *attr, <answer> device_attribute 
<token> char *buf, <answer> const 
size_t <token> <answer> count) 
<token> sht3x_data *data = dev_get_drvdata(dev); <answer> struct 
<token> i2c_client *client = data->client; <answer> struct 
int <token> <answer> ret; 
<token> status; <answer> bool 
ret = <token> &status); <answer> kstrtobool(buf, 
if <token> <answer> (ret) 
return <token> <answer> ret; 
if <token> <answer> (status) 
ret = <token> (char *)&sht3x_cmd_heater_on, <answer> i2c_master_send(client, 
ret = i2c_master_send(client, (char <token> <answer> *)&sht3x_cmd_heater_off, 
return <token> <answer> ret; 
<token> int update_interval_read(struct device *dev) <answer> static 
struct sht3x_data *data <token> dev_get_drvdata(dev); <answer> = 
<token> mode_to_update_interval[data->mode]; <answer> return 
static <token> update_interval_write(struct device *dev, int val) <answer> int 
u8 <token> <answer> mode; 
<token> ret; <answer> int 
const char <token> <answer> *command; 
struct sht3x_data *data <token> dev_get_drvdata(dev); <answer> = 
struct i2c_client <token> = data->client; <answer> *client 
<token> = get_mode_from_update_interval(val); <answer> mode 
if (data->mode > <token> { <answer> 0) 
ret = i2c_master_send(client, <token> <answer> sht3x_cmd_break, 
if (ret <token> SHT3X_CMD_LENGTH) <answer> != 
goto <token> <answer> out; 
data->mode = <token> <answer> 0; 
if <token> > 0) { <answer> (mode 
if <token> == high_repeatability) <answer> (data->repeatability 
command <token> periodic_measure_commands_hpm[mode - 1]; <answer> = 
<token> if (data->repeatability == medium_repeatability) <answer> else 
command = periodic_measure_commands_mpm[mode - <token> <answer> 1]; 
command = periodic_measure_commands_lpm[mode <token> 1]; <answer> - 
if <token> I2C_FUNC_I2C)) <answer> (!i2c_check_functionality(adap, 
<token> -ENODEV; <answer> return 
ret = <token> sht3x_cmd_clear_status_reg, <answer> i2c_master_send(client, 
if (ret != <token> <answer> SHT3X_CMD_LENGTH) 
return ret < 0 ? <token> : -ENODEV; <answer> ret 
<token> = devm_kzalloc(dev, sizeof(*data), GFP_KERNEL); <answer> data 
if <token> <answer> (!data) 
return <token> <answer> -ENOMEM; 
data->repeatability = <token> <answer> high_repeatability; 
<token> = 0; <answer> data->mode 
<token> = jiffies - msecs_to_jiffies(3000); <answer> data->last_update 
<token> = client; <answer> data->client 
data->chip_id <token> i2c_match_id(sht3x_ids, client)->driver_data; <answer> = 
crc8_populate_msb(sht3x_crc8_table, <token> <answer> SHT3X_CRC8_POLYNOMIAL); 
<token> 600); <answer> usleep_range(500, 
<token> = limits_update(data); <answer> ret 
<token> (ret) <answer> if 
return <token> <answer> ret; 
<token> = sht3x_serial_number_read(data); <answer> ret 
if (ret) <token> <answer> { 
dev_dbg(dev, <token> to read serial number\n"); <answer> "unable 
} else <token> <answer> { 
ret <token> devm_add_action_or_reset(dev, <answer> = 
<token> (ret) <answer> if 
return <token> <answer> ret; 
hwmon_dev <token> devm_hwmon_device_register_with_info(dev, <answer> = 
if <token> <answer> (IS_ERR(hwmon_dev)) 
dev_dbg(dev, "unable to register <token> device\n"); <answer> hwmon 
<token> PTR_ERR_OR_ZERO(hwmon_dev); <answer> return 
static struct i2c_driver sht3x_i2c_driver = <token> <answer> { 
<token> = "sht3x", <answer> .driver.name 
<token> = sht3x_probe, <answer> .probe 
.id_table = <token> <answer> sht3x_ids, 
static int <token> sht3x_init(void) <answer> __init 
debugfs = debugfs_create_dir("sht3x", <token> <answer> NULL); 
return <token> <answer> i2c_add_driver(&sht3x_i2c_driver); 
<token> void __exit sht3x_cleanup(void) <answer> static 
MODULE_AUTHOR("David Frey <token> <answer> <david.frey@sensirion.com>"); 
MODULE_AUTHOR("Pascal Sachs <token> <answer> <pascal.sachs@sensirion.com>"); 
MODULE_DESCRIPTION("Sensirion SHT3x humidity and temperature <token> driver"); <answer> sensor 
#include <token> <answer> <kunit/test.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/time64.h> <answer> #include 
#include <token> <answer> "ext4.h" 
<token> LOWER_MSB_0 0L <answer> #define 
<token> UPPER_MSB_0 0x7fffffffL <answer> #define 
#define UPPER_MSB_1 <token> <answer> (-1L) 
#define MAX_NANOSECONDS ((1L << 30) - <token> <answer> 1) 
#define CASE_NAME_FORMAT "%s: <token> lower_bound:%x extra_bits: %x" <answer> msb:%x 
<token> LOWER_BOUND_NEG_NO_EXTRA_BITS_CASE\ <answer> #define 
"1901-12-13 Lower <token> of 32bit < 0 timestamp, no extra bits" <answer> bound 
<token> UPPER_BOUND_NEG_NO_EXTRA_BITS_CASE\ <answer> #define 
"1969-12-31 Upper bound of 32bit < <token> timestamp, no extra bits" <answer> 0 
#define <token> <answer> LOWER_BOUND_NONNEG_NO_EXTRA_BITS_CASE\ 
"1970-01-01 <token> bound of 32bit >=0 timestamp, no extra bits" <answer> Lower 
<token> UPPER_BOUND_NONNEG_NO_EXTRA_BITS_CASE\ <answer> #define 
"2038-01-19 Upper <token> of 32bit >=0 timestamp, no extra bits" <answer> bound 
<token> LOWER_BOUND_NEG_LO_1_CASE\ <answer> #define 
"2038-01-19 Lower bound of 32bit <0 timestamp, lo extra sec <token> on" <answer> bit 
<token> UPPER_BOUND_NEG_LO_1_CASE\ <answer> #define 
"2106-02-07 Upper <token> of 32bit <0 timestamp, lo extra sec bit on" <answer> bound 
#define <token> <answer> LOWER_BOUND_NONNEG_LO_1_CASE\ 
"2106-02-07 Lower bound of 32bit >=0 <token> lo extra sec bit on" <answer> timestamp, 
<token> UPPER_BOUND_NONNEG_LO_1_CASE\ <answer> #define 
"2174-02-25 Upper bound of 32bit >=0 <token> lo extra sec bit on" <answer> timestamp, 
<token> LOWER_BOUND_NEG_HI_1_CASE\ <answer> #define 
"2174-02-25 Lower bound of 32bit <token> timestamp, hi extra sec bit on" <answer> <0 
<token> UPPER_BOUND_NEG_HI_1_CASE\ <answer> #define 
"2242-03-16 Upper bound of 32bit <0 timestamp, hi <token> sec bit on" <answer> extra 
<token> LOWER_BOUND_NONNEG_HI_1_CASE\ <answer> #define 
"2242-03-16 Lower bound of 32bit <token> timestamp, hi extra sec bit on" <answer> >=0 
<token> UPPER_BOUND_NONNEG_HI_1_CASE\ <answer> #define 
"2310-04-04 Upper bound of 32bit >=0 timestamp, <token> extra sec bit on" <answer> hi 
<token> UPPER_BOUND_NONNEG_HI_1_NS_1_CASE\ <answer> #define 
"2310-04-04 Upper bound of 32bit>=0 timestamp, hi extra sec bit 1. 1 <token> <answer> ns" 
<token> LOWER_BOUND_NONNEG_HI_1_NS_MAX_CASE\ <answer> #define 
<token> Lower bound of 32bit>= timestamp. Extra sec bits 1. Max ns" <answer> "2378-04-22 
#define <token> <answer> LOWER_BOUND_NONNEG_EXTRA_BITS_1_CASE\ 
"2378-04-22 Lower bound of 32bit >=0 <token> All extra sec bits on" <answer> timestamp. 
<token> UPPER_BOUND_NONNEG_EXTRA_BITS_1_CASE\ <answer> #define 
"2446-05-10 <token> bound of 32bit >=0 timestamp. All extra sec bits on" <answer> Upper 
struct <token> { <answer> timestamp_expectation 
const <token> *test_case_name; <answer> char 
struct timespec64 <token> <answer> expected; 
u32 <token> <answer> extra_bits; 
<token> msb_set; <answer> bool 
bool <token> <answer> lower_bound; 
static const struct <token> test_data[] = { <answer> timestamp_expectation 
.test_case_name <token> LOWER_BOUND_NEG_NO_EXTRA_BITS_CASE, <answer> = 
.msb_set <token> true, <answer> = 
<token> = true, <answer> .lower_bound 
.extra_bits = <token> <answer> 0, 
.expected = {.tv_sec <token> -0x80000000LL, .tv_nsec = 0L}, <answer> = 
.test_case_name = <token> <answer> UPPER_BOUND_NEG_NO_EXTRA_BITS_CASE, 
.msb_set <token> true, <answer> = 
.lower_bound = <token> <answer> false, 
<token> = 0, <answer> .extra_bits 
.expected = <token> = -1LL, .tv_nsec = 0L}, <answer> {.tv_sec 
<token> = LOWER_BOUND_NONNEG_NO_EXTRA_BITS_CASE, <answer> .test_case_name 
<token> = false, <answer> .msb_set 
<token> = true, <answer> .lower_bound 
.extra_bits = <token> <answer> 0, 
<token> = {0LL, 0L}, <answer> .expected 
.test_case_name = <token> <answer> UPPER_BOUND_NONNEG_NO_EXTRA_BITS_CASE, 
<token> = false, <answer> .msb_set 
<token> = false, <answer> .lower_bound 
<token> = 0, <answer> .extra_bits 
.expected = {.tv_sec = 0x7fffffffLL, <token> = 0L}, <answer> .tv_nsec 
.test_case_name = <token> <answer> LOWER_BOUND_NEG_LO_1_CASE, 
.msb_set <token> true, <answer> = 
.lower_bound <token> true, <answer> = 
<token> = 1, <answer> .extra_bits 
.expected = {.tv_sec = 0x80000000LL, <token> = 0L}, <answer> .tv_nsec 
.test_case_name <token> UPPER_BOUND_NEG_LO_1_CASE, <answer> = 
.msb_set <token> true, <answer> = 
.lower_bound = <token> <answer> false, 
.extra_bits = <token> <answer> 1, 
.expected = {.tv_sec = 0xffffffffLL, .tv_nsec <token> 0L}, <answer> = 
.test_case_name <token> LOWER_BOUND_NONNEG_LO_1_CASE, <answer> = 
.msb_set <token> false, <answer> = 
.lower_bound = <token> <answer> true, 
.extra_bits <token> 1, <answer> = 
.expected = {.tv_sec = 0x100000000LL, <token> = 0L}, <answer> .tv_nsec 
<token> = UPPER_BOUND_NONNEG_LO_1_CASE, <answer> .test_case_name 
.msb_set <token> false, <answer> = 
<token> = false, <answer> .lower_bound 
<token> = 1, <answer> .extra_bits 
.expected = {.tv_sec = 0x17fffffffLL, <token> = 0L}, <answer> .tv_nsec 
<token> = LOWER_BOUND_NEG_HI_1_CASE, <answer> .test_case_name 
<token> = true, <answer> .msb_set 
.lower_bound = <token> <answer> true, 
<token> = 2, <answer> .extra_bits 
<token> = {.tv_sec = 0x180000000LL, .tv_nsec = 0L}, <answer> .expected 
.test_case_name <token> UPPER_BOUND_NEG_HI_1_CASE, <answer> = 
.msb_set <token> true, <answer> = 
.lower_bound <token> false, <answer> = 
<token> = 2, <answer> .extra_bits 
.expected <token> {.tv_sec = 0x1ffffffffLL, .tv_nsec = 0L}, <answer> = 
<token> = LOWER_BOUND_NONNEG_HI_1_CASE, <answer> .test_case_name 
.msb_set = <token> <answer> false, 
.lower_bound <token> true, <answer> = 
<token> = 2, <answer> .extra_bits 
.expected = {.tv_sec = 0x200000000LL, <token> = 0L}, <answer> .tv_nsec 
.test_case_name <token> UPPER_BOUND_NONNEG_HI_1_CASE, <answer> = 
.msb_set = <token> <answer> false, 
<token> = false, <answer> .lower_bound 
.extra_bits = <token> <answer> 2, 
.expected = {.tv_sec <token> 0x27fffffffLL, .tv_nsec = 0L}, <answer> = 
.test_case_name = <token> <answer> UPPER_BOUND_NONNEG_HI_1_NS_1_CASE, 
.msb_set <token> false, <answer> = 
<token> = false, <answer> .lower_bound 
.extra_bits <token> 6, <answer> = 
.expected = {.tv_sec <token> 0x27fffffffLL, .tv_nsec = 1L}, <answer> = 
.test_case_name = <token> <answer> LOWER_BOUND_NONNEG_HI_1_NS_MAX_CASE, 
<token> = false, <answer> .msb_set 
<token> = true, <answer> .lower_bound 
.extra_bits = <token> <answer> 0xFFFFFFFF, 
.expected = <token> = 0x300000000LL, <answer> {.tv_sec 
<token> = MAX_NANOSECONDS}, <answer> .tv_nsec 
<token> = LOWER_BOUND_NONNEG_EXTRA_BITS_1_CASE, <answer> .test_case_name 
.msb_set <token> false, <answer> = 
.lower_bound <token> true, <answer> = 
<token> = 3, <answer> .extra_bits 
.expected = {.tv_sec = <token> .tv_nsec = 0L}, <answer> 0x300000000LL, 
.test_case_name <token> UPPER_BOUND_NONNEG_EXTRA_BITS_1_CASE, <answer> = 
.msb_set <token> false, <answer> = 
<token> = false, <answer> .lower_bound 
.extra_bits = <token> <answer> 3, 
.expected = {.tv_sec = <token> .tv_nsec = 0L}, <answer> 0x37fffffffLL, 
static void <token> struct timestamp_expectation *t, <answer> timestamp_expectation_to_desc(const 
char <token> <answer> *desc) 
<token> t->test_case_name, KUNIT_PARAM_DESC_SIZE); <answer> strscpy(desc, 
<token> test_data, timestamp_expectation_to_desc); <answer> KUNIT_ARRAY_PARAM(ext4_inode, 
static time64_t get_32bit_time(const <token> timestamp_expectation * const test) <answer> struct 
if (test->msb_set) <token> <answer> { 
if <token> <answer> (test->lower_bound) 
return <token> <answer> LOWER_MSB_1; 
<token> UPPER_MSB_1; <answer> return 
if <token> <answer> (test->lower_bound) 
return <token> <answer> LOWER_MSB_0; 
return <token> <answer> UPPER_MSB_0; 
static void <token> kunit *test) <answer> inode_test_xtimestamp_decoding(struct 
struct timespec64 <token> <answer> timestamp; 
struct timestamp_expectation *test_param <token> <answer> = 
<token> timestamp_expectation *)(test->param_value); <answer> (struct 
timestamp = <token> <answer> ext4_decode_extra_time( 
<token> struct kunit_case ext4_inode_test_cases[] = { <answer> static 
<token> ext4_inode_gen_params), <answer> KUNIT_CASE_PARAM(inode_test_xtimestamp_decoding, 
static struct <token> ext4_inode_test_suite = { <answer> kunit_suite 
.name = <token> <answer> "ext4_inode_test", 
.test_cases = <token> <answer> ext4_inode_test_cases, 
MODULE_LICENSE("GPL <token> <answer> v2"); 
#define <token> "QCOM80B1:" fmt <answer> pr_fmt(fmt) 
#include <token> <answer> <linux/acpi.h> 
<token> <linux/irqchip/chained_irq.h> <answer> #include 
<token> <linux/irqdomain.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#define <token> 32 <answer> REG_SIZE 
struct combiner_reg <token> <answer> { 
void __iomem <token> <answer> *addr; 
unsigned long <token> <answer> enabled; 
struct <token> { <answer> combiner 
<token> irq_domain *domain; <answer> struct 
int <token> <answer> parent_irq; 
u32 <token> <answer> nirqs; 
u32 <token> <answer> nregs; 
struct combiner_reg <token> <answer> regs[]; 
<token> inline int irq_nr(u32 reg, u32 bit) <answer> static 
return reg <token> REG_SIZE + bit; <answer> * 
static void <token> irq_desc *desc) <answer> combiner_handle_irq(struct 
struct combiner <token> = irq_desc_get_handler_data(desc); <answer> *combiner 
struct <token> *chip = irq_desc_get_chip(desc); <answer> irq_chip 
u32 <token> <answer> reg; 
chained_irq_enter(chip, <token> <answer> desc); 
for (reg = <token> reg < combiner->nregs; reg++) { <answer> 0; 
int <token> <answer> hwirq; 
<token> bit; <answer> u32 
<token> status; <answer> u32 
bit = <token> <answer> readl_relaxed(combiner->regs[reg].addr); 
status = bit & <token> <answer> combiner->regs[reg].enabled; 
if (bit && <token> <answer> !status) 
pr_warn_ratelimited("Unexpected IRQ on CPU%d: (%08x %08lx <token> <answer> %p)\n", 
smp_processor_id(), <token> <answer> bit, 
while <token> { <answer> (status) 
bit <token> __ffs(status); <answer> = 
status &= <token> << bit); <answer> ~(1 
<token> = irq_nr(reg, bit); <answer> hwirq 
<token> hwirq); <answer> generic_handle_domain_irq(combiner->domain, 
chained_irq_exit(chip, <token> <answer> desc); 
<token> void combiner_irq_chip_mask_irq(struct irq_data *data) <answer> static 
struct combiner *combiner = <token> <answer> irq_data_get_irq_chip_data(data); 
struct combiner_reg <token> = combiner->regs + data->hwirq / REG_SIZE; <answer> *reg 
clear_bit(data->hwirq <token> REG_SIZE, &reg->enabled); <answer> % 
<token> void combiner_irq_chip_unmask_irq(struct irq_data *data) <answer> static 
<token> combiner *combiner = irq_data_get_irq_chip_data(data); <answer> struct 
<token> combiner_reg *reg = combiner->regs + data->hwirq / REG_SIZE; <answer> struct 
set_bit(data->hwirq % <token> &reg->enabled); <answer> REG_SIZE, 
static <token> irq_chip irq_chip = { <answer> struct 
<token> = combiner_irq_chip_mask_irq, <answer> .irq_mask 
.irq_unmask <token> combiner_irq_chip_unmask_irq, <answer> = 
<token> = "qcom-irq-combiner" <answer> .name 
static int combiner_irq_map(struct <token> *domain, unsigned int irq, <answer> irq_domain 
<token> hwirq) <answer> irq_hw_number_t 
irq_set_chip_and_handler(irq, &irq_chip, <token> <answer> handle_level_irq); 
irq_set_chip_data(irq, <token> <answer> domain->host_data); 
<token> 0; <answer> return 
<token> void combiner_irq_unmap(struct irq_domain *domain, unsigned int irq) <answer> static 
static int combiner_irq_translate(struct irq_domain <token> struct irq_fwspec *fws, <answer> *d, 
unsigned <token> *hwirq, unsigned int *type) <answer> long 
struct combiner *combiner <token> d->host_data; <answer> = 
if <token> { <answer> (is_acpi_node(fws->fwnode)) 
if (WARN_ON((fws->param_count <token> 2) || <answer> != 
(fws->param[0] >= <token> || <answer> combiner->nirqs) 
(fws->param[1] & IORESOURCE_IRQ_LOWEDGE) <token> <answer> || 
(fws->param[1] & <token> <answer> IORESOURCE_IRQ_HIGHEDGE))) 
<token> -EINVAL; <answer> return 
<token> = fws->param[0]; <answer> *hwirq 
*type <token> fws->param[1]; <answer> = 
return <token> <answer> 0; 
return <token> <answer> -EINVAL; 
<token> const struct irq_domain_ops domain_ops = { <answer> static 
<token> = combiner_irq_map, <answer> .map 
.unmap = <token> <answer> combiner_irq_unmap, 
.translate <token> combiner_irq_translate <answer> = 
static acpi_status count_registers_cb(struct acpi_resource *ares, void <token> <answer> *context) 
<token> *count = context; <answer> int 
if (ares->type == <token> <answer> ACPI_RESOURCE_TYPE_GENERIC_REGISTER) 
<token> AE_OK; <answer> return 
static int count_registers(struct platform_device <token> <answer> *pdev) 
acpi_handle ahandle = <token> <answer> ACPI_HANDLE(&pdev->dev); 
<token> status; <answer> acpi_status 
<token> count = 0; <answer> int 
if <token> METHOD_NAME__CRS)) <answer> (!acpi_has_method(ahandle, 
return <token> <answer> -EINVAL; 
status <token> acpi_walk_resources(ahandle, METHOD_NAME__CRS, <answer> = 
<token> &count); <answer> count_registers_cb, 
if <token> <answer> (ACPI_FAILURE(status)) 
return <token> <answer> -EINVAL; 
return <token> <answer> count; 
struct <token> { <answer> get_registers_context 
<token> device *dev; <answer> struct 
<token> combiner *combiner; <answer> struct 
<token> err; <answer> int 
static acpi_status get_registers_cb(struct acpi_resource <token> void *context) <answer> *ares, 
struct <token> *ctx = context; <answer> get_registers_context 
<token> acpi_resource_generic_register *reg; <answer> struct 
phys_addr_t <token> <answer> paddr; 
void __iomem <token> <answer> *vaddr; 
if <token> != ACPI_RESOURCE_TYPE_GENERIC_REGISTER) <answer> (ares->type 
return <token> <answer> AE_OK; 
reg = <token> <answer> &ares->data.generic_reg; 
paddr = <token> <answer> reg->address; 
if ((reg->space_id != <token> || <answer> ACPI_SPACE_MEM) 
(reg->bit_offset != 0) <token> <answer> || 
(reg->bit_width > REG_SIZE)) <token> <answer> { 
dev_err(ctx->dev, "Bad register resource <token> &paddr); <answer> @%pa\n", 
ctx->err <token> -EINVAL; <answer> = 
return <token> <answer> AE_ERROR; 
vaddr = devm_ioremap(ctx->dev, <token> REG_SIZE); <answer> reg->address, 
<token> (!vaddr) { <answer> if 
dev_err(ctx->dev, "Can't <token> register @%pa\n", &paddr); <answer> map 
<token> = -ENOMEM; <answer> ctx->err 
<token> AE_ERROR; <answer> return 
ctx->combiner->regs[ctx->combiner->nregs].addr <token> vaddr; <answer> = 
<token> += reg->bit_width; <answer> ctx->combiner->nirqs 
return <token> <answer> AE_OK; 
static int get_registers(struct platform_device <token> struct combiner *comb) <answer> *pdev, 
acpi_handle ahandle <token> ACPI_HANDLE(&pdev->dev); <answer> = 
<token> status; <answer> acpi_status 
struct get_registers_context <token> <answer> ctx; 
<token> (!acpi_has_method(ahandle, METHOD_NAME__CRS)) <answer> if 
return <token> <answer> -EINVAL; 
ctx.dev <token> &pdev->dev; <answer> = 
ctx.combiner <token> comb; <answer> = 
ctx.err <token> 0; <answer> = 
status = <token> METHOD_NAME__CRS, <answer> acpi_walk_resources(ahandle, 
get_registers_cb, <token> <answer> &ctx); 
<token> (ACPI_FAILURE(status)) <answer> if 
return <token> <answer> ctx.err; 
return <token> <answer> 0; 
static <token> __init combiner_probe(struct platform_device *pdev) <answer> int 
<token> combiner *combiner; <answer> struct 
<token> nregs; <answer> int 
int <token> <answer> err; 
nregs = <token> <answer> count_registers(pdev); 
if <token> <= 0) { <answer> (nregs 
dev_err(&pdev->dev, "Error reading <token> resources\n"); <answer> register 
<token> -EINVAL; <answer> return 
combiner = devm_kzalloc(&pdev->dev, <token> regs, nregs), <answer> struct_size(combiner, 
if <token> <answer> (!combiner) 
<token> -ENOMEM; <answer> return 
err = get_registers(pdev, <token> <answer> combiner); 
<token> (err < 0) <answer> if 
return <token> <answer> err; 
combiner->parent_irq = <token> 0); <answer> platform_get_irq(pdev, 
<token> (combiner->parent_irq <= 0) <answer> if 
return <token> <answer> -EPROBE_DEFER; 
combiner->domain <token> irq_domain_create_linear(pdev->dev.fwnode, combiner->nirqs, <answer> = 
&domain_ops, <token> <answer> combiner); 
<token> (!combiner->domain) <answer> if 
#include <token> <answer> <linux/bitfield.h> 
<token> <linux/clk.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
<token> <linux/mfd/syscon.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/of_platform.h> 
<token> <linux/phy/phy.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/rational.h> 
<token> <linux/regmap.h> <answer> #include 
#include <token> <answer> <linux/reset.h> 
#define <token> 0x00 <answer> GRF_HDPTX_CON0 
#define <token> BIT(7) <answer> HDPTX_I_PLL_EN 
#define <token> BIT(6) <answer> HDPTX_I_BIAS_EN 
#define HDPTX_I_BGR_EN <token> <answer> BIT(5) 
<token> GRF_HDPTX_STATUS 0x80 <answer> #define 
#define HDPTX_O_PLL_LOCK_DONE <token> <answer> BIT(3) 
#define HDPTX_O_PHY_CLK_RDY <token> <answer> BIT(2) 
<token> HDPTX_O_PHY_RDY BIT(1) <answer> #define 
<token> HDPTX_O_SB_RDY BIT(0) <answer> #define 
<token> HDTPX_REG(_n, _min, _max) \ <answer> #define 
<token> \ <answer> ( 
BUILD_BUG_ON_ZERO((0x##_n) < (0x##_min)) + <token> <answer> \ 
<token> > (0x##_max)) + \ <answer> BUILD_BUG_ON_ZERO((0x##_n) 
((0x##_n) * <token> \ <answer> 4) 
#define CMN_REG(n) <token> 0000, 00a7) <answer> HDTPX_REG(n, 
#define <token> HDTPX_REG(n, 0100, 0129) <answer> SB_REG(n) 
#define LNTOP_REG(n) HDTPX_REG(n, <token> 0229) <answer> 0200, 
#define LANE_REG(n) HDTPX_REG(n, 0300, <token> <answer> 062d) 
unsigned int <token> = bus_width & 0xfffffff; <answer> rate 
<token> "%s bus_width=%x rate=%u\n", <answer> dev_dbg(hdptx->dev, 
<token> bus_width, rate); <answer> __func__, 
ret = <token> <answer> pm_runtime_resume_and_get(hdptx->dev); 
if <token> { <answer> (ret) 
dev_err(hdptx->dev, "Failed <token> resume phy: %d\n", ret); <answer> to 
<token> ret; <answer> return 
ret = <token> rate); <answer> rk_hdptx_ropll_tmds_mode_config(hdptx, 
if <token> <answer> (ret) 
return <token> <answer> ret; 
static <token> rk_hdptx_phy_power_off(struct phy *phy) <answer> int 
<token> rk_hdptx_phy *hdptx = phy_get_drvdata(phy); <answer> struct 
u32 <token> <answer> val; 
int <token> <answer> ret; 
<token> = regmap_read(hdptx->grf, GRF_HDPTX_STATUS, &val); <answer> ret 
if <token> == 0 && (val & HDPTX_O_PLL_LOCK_DONE)) <answer> (ret 
<token> ret; <answer> return 
static const struct phy_ops rk_hdptx_phy_ops = <token> <answer> { 
.power_on = <token> <answer> rk_hdptx_phy_power_on, 
.power_off <token> rk_hdptx_phy_power_off, <answer> = 
.owner <token> THIS_MODULE, <answer> = 
<token> int rk_hdptx_phy_runtime_suspend(struct device *dev) <answer> static 
<token> rk_hdptx_phy *hdptx = dev_get_drvdata(dev); <answer> struct 
<token> hdptx->clks); <answer> clk_bulk_disable_unprepare(hdptx->nr_clks, 
return <token> <answer> 0; 
static int <token> device *dev) <answer> rk_hdptx_phy_runtime_resume(struct 
struct rk_hdptx_phy <token> = dev_get_drvdata(dev); <answer> *hdptx 
int <token> <answer> ret; 
ret <token> clk_bulk_prepare_enable(hdptx->nr_clks, hdptx->clks); <answer> = 
<token> (ret) <answer> if 
dev_err(hdptx->dev, "Failed to enable <token> %d\n", ret); <answer> clocks: 
return <token> <answer> ret; 
static <token> rk_hdptx_phy_probe(struct platform_device *pdev) <answer> int 
struct <token> *phy_provider; <answer> phy_provider 
struct <token> *dev = &pdev->dev; <answer> device 
<token> rk_hdptx_phy *hdptx; <answer> struct 
void __iomem <token> <answer> *regs; 
int <token> <answer> ret; 
<token> = devm_kzalloc(dev, sizeof(*hdptx), GFP_KERNEL); <answer> hdptx 
<token> (!hdptx) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = dev; <answer> hdptx->dev 
<token> = devm_platform_ioremap_resource(pdev, 0); <answer> regs 
if <token> <answer> (IS_ERR(regs)) 
return <token> PTR_ERR(regs), <answer> dev_err_probe(dev, 
"Failed to <token> resource\n"); <answer> ioremap 
ret = <token> &hdptx->clks); <answer> devm_clk_bulk_get_all(dev, 
<token> (ret < 0) <answer> if 
return dev_err_probe(dev, <token> "Failed to get clocks\n"); <answer> ret, 
if (ret <token> 0) <answer> == 
return <token> -EINVAL, "Missing clocks\n"); <answer> dev_err_probe(dev, 
hdptx->nr_clks = <token> <answer> ret; 
hdptx->regmap = <token> regs, <answer> devm_regmap_init_mmio(dev, 
<token> (IS_ERR(hdptx->regmap)) <answer> if 
return <token> PTR_ERR(hdptx->regmap), <answer> dev_err_probe(dev, 
"Failed to <token> regmap\n"); <answer> init 
hdptx->rsts[RST_PHY].id <token> "phy"; <answer> = 
<token> = "apb"; <answer> hdptx->rsts[RST_APB].id 
hdptx->rsts[RST_INIT].id <token> "init"; <answer> = 
<token> = "cmn"; <answer> hdptx->rsts[RST_CMN].id 
hdptx->rsts[RST_LANE].id = <token> <answer> "lane"; 
hdptx->rsts[RST_ROPLL].id = <token> <answer> "ropll"; 
hdptx->rsts[RST_LCPLL].id = <token> <answer> "lcpll"; 
ret <token> devm_reset_control_bulk_get_exclusive(dev, RST_MAX, hdptx->rsts); <answer> = 
<token> (ret) <answer> if 
return dev_err_probe(dev, ret, "Failed to get <token> <answer> resets\n"); 
hdptx->grf <token> syscon_regmap_lookup_by_phandle(dev->of_node, <answer> = 
if <token> <answer> (IS_ERR(hdptx->grf)) 
return dev_err_probe(dev, <token> <answer> PTR_ERR(hdptx->grf), 
<token> not get GRF syscon\n"); <answer> "Could 
<token> = devm_phy_create(dev, NULL, &rk_hdptx_phy_ops); <answer> hdptx->phy 
<token> (IS_ERR(hdptx->phy)) <answer> if 
<token> dev_err_probe(dev, PTR_ERR(hdptx->phy), <answer> return 
<token> to create HDMI PHY\n"); <answer> "Failed 
platform_set_drvdata(pdev, <token> <answer> hdptx); 
phy_set_drvdata(hdptx->phy, <token> <answer> hdptx); 
<token> 8); <answer> phy_set_bus_width(hdptx->phy, 
ret = <token> <answer> devm_pm_runtime_enable(dev); 
<token> (ret) <answer> if 
return dev_err_probe(dev, <token> "Failed to enable runtime PM\n"); <answer> ret, 
phy_provider = <token> of_phy_simple_xlate); <answer> devm_of_phy_provider_register(dev, 
<token> (IS_ERR(phy_provider)) <answer> if 
return <token> PTR_ERR(phy_provider), <answer> dev_err_probe(dev, 
<token> to register PHY provider\n"); <answer> "Failed 
return <token> <answer> 0; 
static <token> struct dev_pm_ops rk_hdptx_phy_pm_ops = { <answer> const 
<token> NULL) <answer> rk_hdptx_phy_runtime_resume, 
static const struct of_device_id rk_hdptx_phy_of_match[] <token> { <answer> = 
{ .compatible = <token> }, <answer> "rockchip,rk3588-hdptx-phy", 
MODULE_DEVICE_TABLE(of, <token> <answer> rk_hdptx_phy_of_match); 
static <token> platform_driver rk_hdptx_phy_driver = { <answer> struct 
.probe = <token> <answer> rk_hdptx_phy_probe, 
.driver <token> { <answer> = 
.name <token> "rockchip-hdptx-phy", <answer> = 
<token> = &rk_hdptx_phy_pm_ops, <answer> .pm 
.of_match_table = <token> <answer> rk_hdptx_phy_of_match, 
MODULE_AUTHOR("Algea <token> <algea.cao@rock-chips.com>"); <answer> Cao 
MODULE_AUTHOR("Cristian Ciocaltea <token> <answer> <cristian.ciocaltea@collabora.com>"); 
<token> HDMI/eDP Transmitter Combo PHY Driver"); <answer> MODULE_DESCRIPTION("Samsung 
#define <token> KBUILD_MODNAME ": " fmt <answer> pr_fmt(fmt) 
<token> <linux/module.h> <answer> #include 
<token> <linux/firmware.h> <answer> #include 
<token> <net/rsi_91x.h> <answer> #include 
<token> "rsi_mgmt.h" <answer> #include 
<token> "rsi_common.h" <answer> #include 
#include <token> <answer> "rsi_coex.h" 
<token> "rsi_hal.h" <answer> #include 
#include <token> <answer> "rsi_usb.h" 
<token> | <answer> ERR_ZONE 
<token> CONFIG_RSI_COEX <answer> #ifdef 
static struct rsi_proto_ops g_proto_ops <token> { <answer> = 
.coex_send_pkt <token> rsi_coex_send_pkt, <answer> = 
<token> = rsi_get_host_intf, <answer> .get_host_intf 
.set_bt_context = <token> <answer> rsi_set_bt_context, 
void rsi_dbg(u32 zone, const char <token> ...) <answer> *fmt, 
<token> va_format vaf; <answer> struct 
va_list <token> <answer> args; 
<token> fmt); <answer> va_start(args, 
vaf.fmt = <token> <answer> fmt; 
vaf.va = <token> <answer> &args; 
if (zone & <token> <answer> rsi_zone_enabled) 
<token> &vaf); <answer> pr_info("%pV", 
static char *opmode_str(int <token> <answer> oper_mode) 
switch (oper_mode) <token> <answer> { 
<token> DEV_OPMODE_WIFI_ALONE: <answer> case 
return <token> alone"; <answer> "Wi-Fi 
<token> DEV_OPMODE_BT_ALONE: <answer> case 
return <token> EDR alone"; <answer> "BT 
<token> DEV_OPMODE_BT_LE_ALONE: <answer> case 
return "BT <token> alone"; <answer> LE 
<token> DEV_OPMODE_BT_DUAL: <answer> case 
<token> "BT Dual"; <answer> return 
case <token> <answer> DEV_OPMODE_STA_BT: 
<token> "Wi-Fi STA + BT EDR"; <answer> return 
<token> DEV_OPMODE_STA_BT_LE: <answer> case 
return <token> STA + BT LE"; <answer> "Wi-Fi 
<token> DEV_OPMODE_STA_BT_DUAL: <answer> case 
return "Wi-Fi <token> + BT DUAL"; <answer> STA 
case <token> <answer> DEV_OPMODE_AP_BT: 
<token> "Wi-Fi AP + BT EDR"; <answer> return 
case <token> <answer> DEV_OPMODE_AP_BT_DUAL: 
return <token> AP + BT DUAL"; <answer> "Wi-Fi 
return <token> <answer> "Unknown"; 
void rsi_print_version(struct rsi_common <token> <answer> *common) 
<token> "================================================\n"); <answer> rsi_dbg(ERR_ZONE, 
<token> "================ RSI Version Info ==============\n"); <answer> rsi_dbg(ERR_ZONE, 
rsi_dbg(ERR_ZONE, <token> <answer> "================================================\n"); 
rsi_dbg(ERR_ZONE, "FW <token> %d.%d.%d\n", <answer> Version\t: 
common->lmac_ver.major, <token> <answer> common->lmac_ver.minor, 
rsi_dbg(ERR_ZONE, <token> mode\t: %d [%s]", <answer> "Operating 
common->oper_mode, <token> <answer> opmode_str(common->oper_mode)); 
<token> "Firmware file\t: %s", common->priv->fw_file_name); <answer> rsi_dbg(ERR_ZONE, 
rsi_dbg(ERR_ZONE, <token> <answer> "================================================\n"); 
static struct sk_buff <token> rsi_common *common, <answer> *rsi_prepare_skb(struct 
<token> *buffer, <answer> u8 
<token> pkt_len, <answer> u32 
<token> extended_desc) <answer> u8 
struct <token> *skb = NULL; <answer> sk_buff 
<token> payload_offset; <answer> u8 
if (WARN(!pkt_len, "%s: <token> pkt received", __func__)) <answer> Dummy 
<token> NULL; <answer> return 
if (pkt_len > (RSI_RCV_BUFFER_LEN * 4)) <token> <answer> { 
<token> "%s: Pkt size > max rx buf size %d\n", <answer> rsi_dbg(ERR_ZONE, 
__func__, <token> <answer> pkt_len); 
<token> = RSI_RCV_BUFFER_LEN * 4; <answer> pkt_len 
pkt_len -= <token> <answer> extended_desc; 
skb = <token> + FRAME_DESC_SZ); <answer> dev_alloc_skb(pkt_len 
<token> (skb == NULL) <answer> if 
<token> NULL; <answer> return 
payload_offset = (extended_desc <token> FRAME_DESC_SZ); <answer> + 
skb_put(skb, <token> <answer> pkt_len); 
<token> (buffer + payload_offset), skb->len); <answer> memcpy((skb->data), 
return <token> <answer> skb; 
int rsi_read_pkt(struct rsi_common *common, <token> *rx_pkt, s32 rcv_pkt_len) <answer> u8 
u8 *frame_desc = <token> extended_desc = 0; <answer> NULL, 
u32 index, length <token> 0, queueno = 0; <answer> = 
<token> actual_length = 0, offset; <answer> u16 
struct <token> *skb = NULL; <answer> sk_buff 
<token> CONFIG_RSI_COEX <answer> #ifdef 
<token> bt_pkt_type; <answer> u8 
<token> = 0; <answer> index 
do <token> <answer> { 
frame_desc = <token> <answer> &rx_pkt[index]; 
actual_length = *(u16 <token> <answer> *)&frame_desc[0]; 
offset = <token> *)&frame_desc[2]; <answer> *(u16 
if (!rcv_pkt_len && offset <token> <answer> > 
RSI_MAX_RX_USB_PKT_SIZE - <token> <answer> FRAME_DESC_SZ) 
goto <token> <answer> fail; 
<token> = rsi_get_queueno(frame_desc, offset); <answer> queueno 
<token> = rsi_get_length(frame_desc, offset); <answer> length 
static <token> rsi_tx_scheduler_thread(struct rsi_common *common) <answer> void 
struct rsi_hw <token> = common->priv; <answer> *adapter 
u32 timeout <token> EVENT_WAIT_FOREVER; <answer> = 
<token> { <answer> do 
if <token> <answer> (adapter->determine_event_timeout) 
timeout = <token> <answer> adapter->determine_event_timeout(adapter); 
rsi_wait_event(&common->tx_thread.event, <token> <answer> timeout); 
if <token> <answer> (common->init_done) 
} while (atomic_read(&common->tx_thread.thread_done) == <token> <answer> 0); 
<token> 0); <answer> kthread_complete_and_exit(&common->tx_thread.completion, 
#ifdef <token> <answer> CONFIG_RSI_COEX 
enum rsi_host_intf <token> *priv) <answer> rsi_get_host_intf(void 
struct <token> *common = priv; <answer> rsi_common 
return <token> <answer> common->priv->rsi_host_intf; 
void <token> *priv, void *bt_context) <answer> rsi_set_bt_context(void 
<token> rsi_common *common = priv; <answer> struct 
<token> = bt_context; <answer> common->bt_adapter 
void rsi_attach_bt(struct rsi_common <token> <answer> *common) 
<token> CONFIG_RSI_COEX <answer> #ifdef 
<token> (rsi_bt_ops.attach(common, &g_proto_ops)) <answer> if 
"Failed to attach <token> module\n"); <answer> BT 
struct <token> *rsi_91x_init(u16 oper_mode) <answer> rsi_hw 
struct rsi_hw *adapter <token> NULL; <answer> = 
struct rsi_common *common <token> NULL; <answer> = 
u8 ii <token> 0; <answer> = 
<token> = kzalloc(sizeof(*adapter), GFP_KERNEL); <answer> adapter 
if <token> <answer> (!adapter) 
return <token> <answer> NULL; 
adapter->priv <token> kzalloc(sizeof(*common), GFP_KERNEL); <answer> = 
if (adapter->priv <token> NULL) { <answer> == 
rsi_dbg(ERR_ZONE, "%s: Failed in allocation of <token> <answer> memory\n", 
<token> NULL; <answer> return 
} else <token> <answer> { 
common = <token> <answer> adapter->priv; 
common->priv = <token> <answer> adapter; 
for (ii = 0; ii <token> NUM_SOFT_QUEUES; ii++) <answer> < 
<token> (rsi_create_kthread(common, <answer> if 
<token> { <answer> "Tx-Thread")) 
rsi_dbg(ERR_ZONE, "%s: Unable <token> init tx thrd\n", __func__); <answer> to 
<token> err; <answer> goto 
timer_setup(&common->roc_timer, rsi_roc_timeout, <token> <answer> 0); 
<token> = RSI_DEV_9113; <answer> adapter->device_model 
common->oper_mode = <token> <answer> oper_mode; 
void <token> rsi_hw *adapter) <answer> rsi_91x_deinit(struct 
<token> rsi_common *common = adapter->priv; <answer> struct 
<token> ii; <answer> u8 
<token> "%s: Performing deinit os ops\n", __func__); <answer> rsi_dbg(INFO_ZONE, 
for <token> = 0; ii < NUM_SOFT_QUEUES; ii++) <answer> (ii 
#ifdef <token> <answer> CONFIG_RSI_COEX 
if (common->coex_mode <token> 1) { <answer> > 
if <token> { <answer> (common->bt_adapter) 
common->bt_adapter = <token> <answer> NULL; 
<token> = false; <answer> common->init_done 
<token> int rsi_91x_hal_module_init(void) <answer> static 
rsi_dbg(INIT_ZONE, "%s: Module <token> called\n", __func__); <answer> init 
return <token> <answer> 0; 
static <token> rsi_91x_hal_module_exit(void) <answer> void 
rsi_dbg(INIT_ZONE, "%s: Module <token> called\n", __func__); <answer> exit 
<token> Signals Inc"); <answer> MODULE_AUTHOR("Redpine 
<token> driver for RSI 91x devices"); <answer> MODULE_DESCRIPTION("Station 
<token> BSD/GPL"); <answer> MODULE_LICENSE("Dual 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/videodev2.h> <answer> #include 
<token> <media/v4l2-common.h> <answer> #include 
#include <token> <answer> "vivid-core.h" 
#include <token> <answer> "vivid-kthread-out.h" 
#include <token> <answer> "vivid-vbi-out.h" 
#include <token> <answer> "vivid-vbi-cap.h" 
static <token> vbi_out_queue_setup(struct vb2_queue *vq, <answer> int 
unsigned *nbuffers, <token> *nplanes, <answer> unsigned 
<token> sizes[], struct device *alloc_devs[]) <answer> unsigned 
struct vivid_dev *dev = <token> <answer> vb2_get_drv_priv(vq); 
bool is_60hz <token> dev->std_out & V4L2_STD_525_60; <answer> = 
<token> size = vq->type == V4L2_BUF_TYPE_SLICED_VBI_OUTPUT ? <answer> unsigned 
36 * sizeof(struct v4l2_sliced_vbi_data) <token> <answer> : 
1440 * <token> * (is_60hz ? 12 : 18); <answer> 2 
if <token> <answer> (!vivid_is_svid_out(dev)) 
<token> -EINVAL; <answer> return 
<token> = size; <answer> sizes[0] 
*nplanes = <token> <answer> 1; 
return <token> <answer> 0; 
static <token> vbi_out_buf_prepare(struct vb2_buffer *vb) <answer> int 
struct vivid_dev *dev <token> vb2_get_drv_priv(vb->vb2_queue); <answer> = 
bool is_60hz <token> dev->std_out & V4L2_STD_525_60; <answer> = 
unsigned size = vb->vb2_queue->type == V4L2_BUF_TYPE_SLICED_VBI_OUTPUT <token> <answer> ? 
36 <token> sizeof(struct v4l2_sliced_vbi_data) : <answer> * 
1440 * 2 * (is_60hz <token> 12 : 18); <answer> ? 
dprintk(dev, 1, "%s\n", <token> <answer> __func__); 
<token> (dev->buf_prepare_error) { <answer> if 
dev->buf_prepare_error <token> false; <answer> = 
<token> -EINVAL; <answer> return 
if (vb2_plane_size(vb, 0) < <token> { <answer> size) 
dprintk(dev, 1, "%s data will not <token> into plane (%lu < %u)\n", <answer> fit 
__func__, <token> 0), size); <answer> vb2_plane_size(vb, 
<token> -EINVAL; <answer> return 
<token> 0, size); <answer> vb2_set_plane_payload(vb, 
<token> 0; <answer> return 
static void vbi_out_buf_queue(struct <token> *vb) <answer> vb2_buffer 
struct <token> *vbuf = to_vb2_v4l2_buffer(vb); <answer> vb2_v4l2_buffer 
struct vivid_dev <token> = vb2_get_drv_priv(vb->vb2_queue); <answer> *dev 
struct <token> *buf = container_of(vbuf, struct vivid_buffer, vb); <answer> vivid_buffer 
dprintk(dev, 1, "%s\n", <token> <answer> __func__); 
list_add_tail(&buf->list, <token> <answer> &dev->vbi_out_active); 
static int vbi_out_start_streaming(struct <token> *vq, unsigned count) <answer> vb2_queue 
struct vivid_dev *dev <token> vb2_get_drv_priv(vq); <answer> = 
<token> err; <answer> int 
<token> 1, "%s\n", __func__); <answer> dprintk(dev, 
<token> = 0; <answer> dev->vbi_out_seq_count 
if (dev->start_streaming_error) <token> <answer> { 
<token> = false; <answer> dev->start_streaming_error 
err <token> -EINVAL; <answer> = 
} else <token> <answer> { 
err = vivid_start_generating_vid_out(dev, <token> <answer> &dev->vbi_out_streaming); 
if <token> { <answer> (err) 
struct <token> *buf, *tmp; <answer> vivid_buffer 
list_for_each_entry_safe(buf, tmp, &dev->vbi_out_active, list) <token> <answer> { 
<token> err; <answer> return 
#include <token> <answer> <linux/version.h> 
<token> <linux/ptrace.h> <answer> #include 
#include <token> <answer> <uapi/linux/bpf.h> 
<token> <bpf/bpf_helpers.h> <answer> #include 
int bpf_prog1(struct pt_regs <token> <answer> *ctx) 
<token> 0; <answer> return 
<token> bpf_prog2(struct pt_regs *ctx) <answer> int 
return <token> <answer> 0; 
char _license[] SEC("license") = <token> <answer> "GPL"; 
u32 _version <token> = LINUX_VERSION_CODE; <answer> SEC("version") 
<token> <linux/types.h> <answer> #include 
<token> <linux/socket.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/skbuff.h> 
#include <token> <answer> <linux/mm.h> 
#include <token> <answer> <net/sock.h> 
<token> <net/genetlink.h> <answer> #include 
#include <token> <answer> <net/netns/generic.h> 
#include <token> <answer> <kunit/visibility.h> 
#include <token> <answer> <uapi/linux/handshake.h> 
<token> "handshake.h" <answer> #include 
<token> "genl.h" <answer> #include 
<token> <trace/events/handshake.h> <answer> #include 
int handshake_genl_notify(struct net *net, const struct handshake_proto <token> <answer> *proto, 
<token> flags) <answer> gfp_t 
<token> sk_buff *msg; <answer> struct 
<token> *hdr; <answer> void 
struct <token> *handshake_genl_put(struct sk_buff *msg, <answer> nlmsghdr 
struct <token> *info) <answer> genl_info 
<token> genlmsg_put(msg, info->snd_portid, info->snd_seq, <answer> return 
<token> 0, info->genlhdr->cmd); <answer> &handshake_nl_family, 
int handshake_nl_accept_doit(struct sk_buff <token> struct genl_info *info) <answer> *skb, 
struct net <token> = sock_net(skb->sk); <answer> *net 
<token> handshake_net *hn = handshake_pernet(net); <answer> struct 
struct handshake_req *req = <token> <answer> NULL; 
struct <token> *sock; <answer> socket 
int <token> fd, err; <answer> class, 
<token> = -EOPNOTSUPP; <answer> err 
if <token> <answer> (!hn) 
<token> out_status; <answer> goto 
err = <token> <answer> -EINVAL; 
if <token> HANDSHAKE_A_ACCEPT_HANDLER_CLASS)) <answer> (GENL_REQ_ATTR_CHECK(info, 
goto <token> <answer> out_status; 
<token> = nla_get_u32(info->attrs[HANDSHAKE_A_ACCEPT_HANDLER_CLASS]); <answer> class 
<token> = -EAGAIN; <answer> err 
req <token> handshake_req_next(hn, class); <answer> = 
if <token> <answer> (!req) 
<token> out_status; <answer> goto 
sock <token> req->hr_sk->sk_socket; <answer> = 
fd = <token> <answer> get_unused_fd_flags(O_CLOEXEC); 
if (fd < 0) <token> <answer> { 
err <token> fd; <answer> = 
goto <token> <answer> out_complete; 
<token> = req->hr_proto->hp_accept(req, info, fd); <answer> err 
<token> (err) { <answer> if 
<token> out_complete; <answer> goto 
fd_install(fd, <token> <answer> get_file(sock->file)); 
trace_handshake_cmd_accept(net, req, req->hr_sk, <token> <answer> fd); 
<token> 0; <answer> return 
<token> -EIO, NULL); <answer> handshake_complete(req, 
trace_handshake_cmd_accept_err(net, req, NULL, <token> <answer> err); 
return <token> <answer> err; 
<token> handshake_nl_done_doit(struct sk_buff *skb, struct genl_info *info) <answer> int 
<token> net *net = sock_net(skb->sk); <answer> struct 
struct handshake_req <token> <answer> *req; 
struct socket <token> <answer> *sock; 
<token> fd, status, err; <answer> int 
<token> (GENL_REQ_ATTR_CHECK(info, HANDSHAKE_A_DONE_SOCKFD)) <answer> if 
return <token> <answer> -EINVAL; 
<token> = nla_get_s32(info->attrs[HANDSHAKE_A_DONE_SOCKFD]); <answer> fd 
sock = <token> &err); <answer> sockfd_lookup(fd, 
<token> (!sock) <answer> if 
return <token> <answer> err; 
req <token> handshake_req_hash_lookup(sock->sk); <answer> = 
<token> (!req) { <answer> if 
<token> = -EBUSY; <answer> err 
trace_handshake_cmd_done_err(net, req, sock->sk, <token> <answer> err); 
return <token> <answer> err; 
trace_handshake_cmd_done(net, <token> sock->sk, fd); <answer> req, 
status = <token> <answer> -EIO; 
<token> (info->attrs[HANDSHAKE_A_DONE_STATUS]) <answer> if 
status = <token> <answer> nla_get_u32(info->attrs[HANDSHAKE_A_DONE_STATUS]); 
handshake_complete(req, status, <token> <answer> info); 
<token> 0; <answer> return 
<token> unsigned int handshake_net_id; <answer> static 
static int __net_init handshake_net_init(struct net <token> <answer> *net) 
struct handshake_net *hn = net_generic(net, <token> <answer> handshake_net_id); 
unsigned <token> tmp; <answer> long 
<token> sysinfo si; <answer> struct 
tmp <token> si.totalram / (25 * si.mem_unit); <answer> = 
hn->hn_pending_max <token> clamp(tmp, 3UL, 50UL); <answer> = 
<token> = 0; <answer> hn->hn_pending 
<token> = 0; <answer> hn->hn_flags 
return <token> <answer> 0; 
static void <token> handshake_net_exit(struct net *net) <answer> __net_exit 
<token> handshake_net *hn = net_generic(net, handshake_net_id); <answer> struct 
struct handshake_req <token> <answer> *req; 
set_bit(HANDSHAKE_F_NET_DRAINING, <token> <answer> &hn->hn_flags); 
<token> &hn->hn_requests); <answer> list_splice_init(&requests, 
<token> (!list_empty(&requests)) { <answer> while 
<token> = list_first_entry(&requests, struct handshake_req, hr_list); <answer> req 
<token> -ETIMEDOUT, NULL); <answer> handshake_complete(req, 
<token> struct pernet_operations handshake_genl_net_ops = { <answer> static 
<token> = handshake_net_init, <answer> .init 
.exit <token> handshake_net_exit, <answer> = 
.id <token> &handshake_net_id, <answer> = 
.size <token> sizeof(struct handshake_net), <answer> = 
struct handshake_net *handshake_pernet(struct <token> *net) <answer> net 
return handshake_net_id <token> <answer> ? 
net_generic(net, handshake_net_id) : <token> <answer> NULL; 
static int __init <token> <answer> handshake_init(void) 
int <token> <answer> ret; 
ret = <token> <answer> handshake_req_hash_init(); 
<token> (ret) { <answer> if 
pr_warn("handshake: hash initialization failed (%d)\n", <token> <answer> ret); 
<token> ret; <answer> return 
ret <token> genl_register_family(&handshake_nl_family); <answer> = 
if (ret) <token> <answer> { 
pr_warn("handshake: netlink registration failed <token> ret); <answer> (%d)\n", 
<token> ret; <answer> return 
ret <token> register_pernet_subsys(&handshake_genl_net_ops); <answer> = 
if <token> { <answer> (ret) 
pr_warn("handshake: pernet registration failed (%d)\n", <token> <answer> ret); 
return <token> <answer> ret; 
static void <token> handshake_exit(void) <answer> __exit 
handshake_net_id = <token> <answer> 0; 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/errno.h> 
#include <token> <answer> <linux/fs.h> 
<token> <linux/file.h> <answer> #include 
#include <token> <answer> <linux/stat.h> 
#include <token> <answer> <linux/string.h> 
<token> <linux/pagemap.h> <answer> #include 
#include <token> <answer> <linux/mount.h> 
#include <token> <answer> <linux/sched.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/statfs.h> 
<token> <linux/magic.h> <answer> #include 
<token> <linux/fscache.h> <answer> #include 
#include <token> <answer> <net/9p/9p.h> 
<token> <net/9p/client.h> <answer> #include 
<token> "v9fs.h" <answer> #include 
<token> "v9fs_vfs.h" <answer> #include 
<token> "fid.h" <answer> #include 
#include <token> <answer> "xattr.h" 
#include <token> <answer> "acl.h" 
<token> const struct super_operations v9fs_super_ops, v9fs_super_ops_dotl; <answer> static 
static int v9fs_set_super(struct super_block <token> void *data) <answer> *s, 
s->s_fs_info <token> data; <answer> = 
return set_anon_super(s, <token> <answer> data); 
static <token> <answer> int 
v9fs_fill_super(struct super_block <token> struct v9fs_session_info *v9ses, <answer> *sb, 
<token> flags) <answer> int 
int <token> <answer> ret; 
sb->s_maxbytes <token> MAX_LFS_FILESIZE; <answer> = 
sb->s_blocksize_bits = fls(v9ses->maxdata <token> 1); <answer> - 
sb->s_blocksize = <token> << sb->s_blocksize_bits; <answer> 1 
<token> = V9FS_MAGIC; <answer> sb->s_magic 
if <token> { <answer> (v9fs_proto_dotl(v9ses)) 
sb->s_op = <token> <answer> &v9fs_super_ops_dotl; 
if <token> & V9FS_NO_XATTR)) <answer> (!(v9ses->flags 
sb->s_xattr <token> v9fs_xattr_handlers; <answer> = 
} else <token> <answer> { 
<token> = &v9fs_super_ops; <answer> sb->s_op 
<token> = U32_MAX; <answer> sb->s_time_max 
<token> = 0; <answer> sb->s_time_min 
<token> = super_setup_bdi(sb); <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ret; 
<token> (!v9ses->cache) { <answer> if 
sb->s_bdi->ra_pages = <token> <answer> 0; 
sb->s_bdi->io_pages = <token> <answer> 0; 
} <token> { <answer> else 
sb->s_bdi->ra_pages = <token> >> PAGE_SHIFT; <answer> v9ses->maxdata 
sb->s_bdi->io_pages = v9ses->maxdata >> <token> <answer> PAGE_SHIFT; 
<token> |= SB_ACTIVE; <answer> sb->s_flags 
<token> CONFIG_9P_FS_POSIX_ACL <answer> #ifdef 
if ((v9ses->flags & V9FS_ACL_MASK) == <token> <answer> V9FS_POSIX_ACL) 
<token> |= SB_POSIXACL; <answer> sb->s_flags 
return <token> <answer> 0; 
static struct <token> *v9fs_mount(struct file_system_type *fs_type, int flags, <answer> dentry 
const char *dev_name, <token> *data) <answer> void 
struct super_block *sb <token> NULL; <answer> = 
struct <token> *inode = NULL; <answer> inode 
struct dentry <token> = NULL; <answer> *root 
<token> v9fs_session_info *v9ses = NULL; <answer> struct 
struct <token> *fid; <answer> p9_fid 
int <token> = 0; <answer> retval 
p9_debug(P9_DEBUG_VFS, <token> <answer> "\n"); 
<token> = kzalloc(sizeof(struct v9fs_session_info), GFP_KERNEL); <answer> v9ses 
<token> (!v9ses) <answer> if 
<token> ERR_PTR(-ENOMEM); <answer> return 
fid = <token> dev_name, data); <answer> v9fs_session_init(v9ses, 
if (IS_ERR(fid)) <token> <answer> { 
retval <token> PTR_ERR(fid); <answer> = 
<token> free_session; <answer> goto 
sb = sget(fs_type, NULL, v9fs_set_super, <token> v9ses); <answer> flags, 
<token> (IS_ERR(sb)) { <answer> if 
<token> = PTR_ERR(sb); <answer> retval 
goto <token> <answer> clunk_fid; 
retval <token> v9fs_fill_super(sb, v9ses, flags); <answer> = 
if <token> <answer> (retval) 
<token> release_sb; <answer> goto 
if <token> & (CACHE_META|CACHE_LOOSE)) <answer> (v9ses->cache 
<token> = &v9fs_cached_dentry_operations; <answer> sb->s_d_op 
sb->s_d_op <token> &v9fs_dentry_operations; <answer> = 
inode <token> v9fs_get_inode_from_fid(v9ses, fid, sb, true); <answer> = 
if (IS_ERR(inode)) <token> <answer> { 
retval <token> PTR_ERR(inode); <answer> = 
<token> release_sb; <answer> goto 
root = <token> <answer> d_make_root(inode); 
if <token> { <answer> (!root) 
retval <token> -ENOMEM; <answer> = 
<token> release_sb; <answer> goto 
sb->s_root <token> root; <answer> = 
retval = v9fs_get_acl(inode, <token> <answer> fid); 
if <token> <answer> (retval) 
<token> release_sb; <answer> goto 
v9fs_fid_add(root, <token> <answer> &fid); 
p9_debug(P9_DEBUG_VFS, " <token> set mount, return 0\n"); <answer> simple 
return <token> <answer> dget(sb->s_root); 
return <token> <answer> ERR_PTR(retval); 
return <token> <answer> ERR_PTR(retval); 
static void v9fs_kill_super(struct <token> *s) <answer> super_block 
<token> v9fs_session_info *v9ses = s->s_fs_info; <answer> struct 
p9_debug(P9_DEBUG_VFS, " <token> s); <answer> %p\n", 
s->s_fs_info = <token> <answer> NULL; 
p9_debug(P9_DEBUG_VFS, <token> kill_super\n"); <answer> "exiting 
static <token> <answer> void 
v9fs_umount_begin(struct <token> *sb) <answer> super_block 
struct <token> *v9ses; <answer> v9fs_session_info 
v9ses = <token> <answer> sb->s_fs_info; 
static int v9fs_statfs(struct dentry *dentry, struct kstatfs <token> <answer> *buf) 
struct <token> *v9ses; <answer> v9fs_session_info 
struct <token> *fid; <answer> p9_fid 
<token> p9_rstatfs rs; <answer> struct 
<token> res; <answer> int 
fid <token> v9fs_fid_lookup(dentry); <answer> = 
<token> (IS_ERR(fid)) { <answer> if 
<token> = PTR_ERR(fid); <answer> res 
<token> done; <answer> goto 
v9ses <token> v9fs_dentry2v9ses(dentry); <answer> = 
if (v9fs_proto_dotl(v9ses)) <token> <answer> { 
res <token> p9_client_statfs(fid, &rs); <answer> = 
if <token> == 0) { <answer> (res 
buf->f_type = <token> <answer> rs.type; 
buf->f_bsize <token> rs.bsize; <answer> = 
<token> = rs.blocks; <answer> buf->f_blocks 
<token> = rs.bfree; <answer> buf->f_bfree 
buf->f_bavail = <token> <answer> rs.bavail; 
<token> = rs.files; <answer> buf->f_files 
<token> = rs.ffree; <answer> buf->f_ffree 
<token> = u64_to_fsid(rs.fsid); <answer> buf->f_fsid 
buf->f_namelen <token> rs.namelen; <answer> = 
<token> (res != -ENOSYS) <answer> if 
<token> done; <answer> goto 
res = simple_statfs(dentry, <token> <answer> buf); 
return <token> <answer> res; 
static int v9fs_drop_inode(struct inode <token> <answer> *inode) 
<token> v9fs_session_info *v9ses; <answer> struct 
<token> = v9fs_inode2v9ses(inode); <answer> v9ses 
if (v9ses->cache <token> (CACHE_META|CACHE_LOOSE)) <answer> & 
<token> generic_drop_inode(inode); <answer> return 
return <token> <answer> 1; 
static int <token> inode *inode, <answer> v9fs_write_inode(struct 
<token> writeback_control *wbc) <answer> struct 
p9_debug(P9_DEBUG_VFS, "%s: inode %p\n", __func__, <token> <answer> inode); 
<token> netfs_unpin_writeback(inode, wbc); <answer> return 
static int v9fs_write_inode_dotl(struct inode <token> <answer> *inode, 
struct <token> *wbc) <answer> writeback_control 
p9_debug(P9_DEBUG_VFS, "%s: <token> %p\n", __func__, inode); <answer> inode 
return <token> wbc); <answer> netfs_unpin_writeback(inode, 
static const struct super_operations <token> = { <answer> v9fs_super_ops 
.alloc_inode <token> v9fs_alloc_inode, <answer> = 
.free_inode <token> v9fs_free_inode, <answer> = 
<token> = simple_statfs, <answer> .statfs 
.drop_inode = <token> <answer> v9fs_drop_inode, 
.evict_inode = <token> <answer> v9fs_evict_inode, 
.show_options <token> v9fs_show_options, <answer> = 
.umount_begin = <token> <answer> v9fs_umount_begin, 
.write_inode <token> v9fs_write_inode, <answer> = 
<token> const struct super_operations v9fs_super_ops_dotl = { <answer> static 
.alloc_inode <token> v9fs_alloc_inode, <answer> = 
<token> = v9fs_free_inode, <answer> .free_inode 
<token> = v9fs_statfs, <answer> .statfs 
<token> = v9fs_drop_inode, <answer> .drop_inode 
<token> = v9fs_evict_inode, <answer> .evict_inode 
.show_options <token> v9fs_show_options, <answer> = 
.umount_begin = <token> <answer> v9fs_umount_begin, 
<token> = v9fs_write_inode_dotl, <answer> .write_inode 
struct file_system_type v9fs_fs_type = <token> <answer> { 
.name = <token> <answer> "9p", 
.mount <token> v9fs_mount, <answer> = 
.kill_sb = <token> <answer> v9fs_kill_super, 
<token> = THIS_MODULE, <answer> .owner 
.fs_flags <token> FS_RENAME_DOES_D_MOVE, <answer> = 
<token> <linux/cdev.h> <answer> #include 
<token> <linux/compat.h> <answer> #include 
#include <token> <answer> <linux/device.h> 
#include <token> <answer> <linux/fs.h> 
#include <token> <answer> <linux/idr.h> 
#include <token> <answer> <linux/iommu.h> 
<token> IS_ENABLED(CONFIG_KVM) <answer> #if 
#include <token> <answer> <linux/kvm_host.h> 
<token> <linux/list.h> <answer> #include 
#include <token> <answer> <linux/miscdevice.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/mutex.h> 
#include <token> <answer> <linux/pci.h> 
#include <token> <answer> <linux/rwsem.h> 
#include <token> <answer> <linux/sched.h> 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/stat.h> 
<token> <linux/string.h> <answer> #include 
<token> <linux/uaccess.h> <answer> #include 
#include <token> <answer> <linux/vfio.h> 
<token> <linux/wait.h> <answer> #include 
<token> <linux/sched/signal.h> <answer> #include 
<token> <linux/pm_runtime.h> <answer> #include 
<token> <linux/interval_tree.h> <answer> #include 
#include <token> <answer> <linux/iova_bitmap.h> 
<token> <linux/iommufd.h> <answer> #include 
#include <token> <answer> "vfio.h" 
<token> DRIVER_VERSION "0.3" <answer> #define 
#define <token> "Alex Williamson <alex.williamson@redhat.com>" <answer> DRIVER_AUTHOR 
#define DRIVER_DESC <token> - User Level meta-driver" <answer> "VFIO 
<token> struct vfio { <answer> static 
<token> class *device_class; <answer> struct 
struct <token> device_ida; <answer> ida 
<token> vfio; <answer> } 
<token> CONFIG_VFIO_NOIOMMU <answer> #ifdef 
bool vfio_noiommu <token> <answer> __read_mostly; 
vfio_noiommu, <token> S_IRUGO | S_IWUSR); <answer> bool, 
MODULE_PARM_DESC(enable_unsafe_noiommu_mode, "Enable UNSAFE, no-IOMMU mode. This mode provides no device isolation, no DMA translation, no host kernel protection, cannot be used for <token> assignment to virtual machines, requires RAWIO permissions, and will taint the kernel. If you do not know what this is for, step away. (default: false)"); <answer> device 
static <token> <answer> DEFINE_XARRAY(vfio_device_set_xa); 
int vfio_assign_device_set(struct vfio_device <token> void *set_id) <answer> *device, 
unsigned long <token> = (unsigned long)set_id; <answer> idx 
struct <token> *new_dev_set; <answer> vfio_device_set 
<token> vfio_device_set *dev_set; <answer> struct 
<token> (WARN_ON(!set_id)) <answer> if 
<token> -EINVAL; <answer> return 
dev_set <token> xa_load(&vfio_device_set_xa, idx); <answer> = 
<token> (dev_set) <answer> if 
goto <token> <answer> found_get_ref; 
new_dev_set <token> kzalloc(sizeof(*new_dev_set), GFP_KERNEL); <answer> = 
<token> (!new_dev_set) <answer> if 
return <token> <answer> -ENOMEM; 
new_dev_set->set_id <token> set_id; <answer> = 
dev_set = __xa_cmpxchg(&vfio_device_set_xa, idx, NULL, <token> <answer> new_dev_set, 
<token> (!dev_set) { <answer> if 
<token> = new_dev_set; <answer> dev_set 
<token> found_get_ref; <answer> goto 
if (xa_is_err(dev_set)) <token> <answer> { 
return <token> <answer> xa_err(dev_set); 
device->dev_set <token> dev_set; <answer> = 
<token> &dev_set->device_list); <answer> list_add_tail(&device->dev_set_list, 
<token> 0; <answer> return 
static void vfio_release_device_set(struct <token> *device) <answer> vfio_device 
struct vfio_device_set <token> = device->dev_set; <answer> *dev_set 
<token> (!dev_set) <answer> if 
if <token> { <answer> (!--dev_set->device_count) 
<token> long)dev_set->set_id); <answer> (unsigned 
unsigned int vfio_device_set_open_count(struct <token> *dev_set) <answer> vfio_device_set 
struct vfio_device <token> <answer> *cur; 
unsigned <token> open_count = 0; <answer> int 
list_for_each_entry(cur, &dev_set->device_list, <token> <answer> dev_set_list) 
open_count <token> cur->open_count; <answer> += 
return <token> <answer> open_count; 
<token> vfio_device * <answer> struct 
vfio_find_device_in_devset(struct vfio_device_set <token> <answer> *dev_set, 
struct device <token> <answer> *dev) 
<token> vfio_device *cur; <answer> struct 
<token> &dev_set->device_list, dev_set_list) <answer> list_for_each_entry(cur, 
if <token> == dev) <answer> (cur->dev 
return <token> <answer> cur; 
<token> NULL; <answer> return 
struct vfio_device <token> size, struct device *dev, <answer> *_vfio_alloc_device(size_t 
const struct <token> *ops) <answer> vfio_device_ops 
struct <token> *device; <answer> vfio_device 
<token> ret; <answer> int 
<token> (WARN_ON(size < sizeof(struct vfio_device))) <answer> if 
<token> ERR_PTR(-EINVAL); <answer> return 
device <token> kvzalloc(size, GFP_KERNEL); <answer> = 
<token> (!device) <answer> if 
<token> ERR_PTR(-ENOMEM); <answer> return 
ret <token> vfio_init_device(device, dev, ops); <answer> = 
if <token> <answer> (ret) 
<token> out_free; <answer> goto 
<token> device; <answer> return 
<token> ERR_PTR(ret); <answer> return 
static int vfio_init_device(struct <token> *device, struct device *dev, <answer> vfio_device 
<token> struct vfio_device_ops *ops) <answer> const 
<token> ret; <answer> int 
ret <token> ida_alloc_max(&vfio.device_ida, MINORMASK, GFP_KERNEL); <answer> = 
if <token> < 0) { <answer> (ret 
<token> "Error to alloc index\n"); <answer> dev_dbg(dev, 
<token> ret; <answer> return 
device->index <token> ret; <answer> = 
device->dev <token> dev; <answer> = 
<token> = ops; <answer> device->ops 
<token> (ops->init) { <answer> if 
ret = <token> <answer> ops->init(device); 
<token> (ret) <answer> if 
<token> out_uninit; <answer> goto 
<token> = vfio_device_release; <answer> device->device.release 
device->device.class <token> vfio.device_class; <answer> = 
<token> = device->dev; <answer> device->device.parent 
<token> 0; <answer> return 
<token> device->index); <answer> ida_free(&vfio.device_ida, 
return <token> <answer> ret; 
static int __vfio_register_dev(struct vfio_device <token> <answer> *device, 
enum vfio_group_type <token> <answer> type) 
int <token> <answer> ret; 
<token> (WARN_ON(IS_ENABLED(CONFIG_IOMMUFD) && <answer> if 
<token> || <answer> (!device->ops->bind_iommufd 
!device->ops->unbind_iommufd <token> <answer> || 
<token> || <answer> !device->ops->attach_ioas 
return <token> <answer> -EINVAL; 
if <token> <answer> (!device->dev_set) 
vfio_assign_device_set(device, <token> <answer> device); 
ret = <token> "vfio%d", device->index); <answer> dev_set_name(&device->device, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
ret = <token> type); <answer> vfio_device_set_group(device, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if (type == VFIO_IOMMU <token> !vfio_device_is_noiommu(device) && <answer> && 
!device_iommu_capable(device->dev, IOMMU_CAP_CACHE_COHERENCY)) <token> <answer> { 
<token> = -EINVAL; <answer> ret 
<token> err_out; <answer> goto 
<token> = vfio_device_add(device); <answer> ret 
<token> (ret) <answer> if 
<token> err_out; <answer> goto 
int vfio_register_emulated_iommu_dev(struct vfio_device <token> <answer> *device) 
<token> __vfio_register_dev(device, VFIO_EMULATED_IOMMU); <answer> return 
<token> vfio_unregister_group_dev(struct vfio_device *device) <answer> void 
unsigned int i = <token> <answer> 0; 
bool <token> = false; <answer> interrupted 
long <token> <answer> rc; 
rc <token> try_wait_for_completion(&device->comp); <answer> = 
while (rc <token> 0) { <answer> <= 
<token> (device->ops->request) <answer> if 
<token> i++); <answer> device->ops->request(device, 
if <token> { <answer> (interrupted) 
rc = <token> <answer> wait_for_completion_timeout(&device->comp, 
HZ * <token> <answer> 10); 
} <token> { <answer> else 
<token> = wait_for_completion_interruptible_timeout( <answer> rc 
&device->comp, HZ <token> 10); <answer> * 
if (rc < 0) <token> <answer> { 
<token> = true; <answer> interrupted 
"Device is <token> in use, task" <answer> currently 
" <token> (%d) " <answer> \"%s\" 
<token> until device is released", <answer> "blocked 
current->comm, <token> <answer> task_pid_nr(current)); 
if (device->open_count != 0 && <token> <answer> !df->group) 
<token> -EINVAL; <answer> return 
if (device->open_count <token> 1) { <answer> == 
<token> = vfio_df_device_first_open(df); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> vfio_df_close(struct vfio_device_file *df) <answer> void 
struct vfio_device <token> = df->device; <answer> *device 
if <token> == 1) <answer> (device->open_count 
static inline int vfio_device_pm_runtime_get(struct vfio_device <token> <answer> *device) 
struct device <token> = device->dev; <answer> *dev 
if (dev->driver <token> dev->driver->pm) { <answer> && 
int <token> <answer> ret; 
ret <token> pm_runtime_resume_and_get(dev); <answer> = 
if <token> { <answer> (ret) 
"vfio: runtime resume <token> %d\n", ret); <answer> failed 
return <token> <answer> -EIO; 
<token> 0; <answer> return 
<token> inline void vfio_device_pm_runtime_put(struct vfio_device *device) <answer> static 
struct device *dev <token> device->dev; <answer> = 
<token> (dev->driver && dev->driver->pm) <answer> if 
static <token> vfio_device_fops_release(struct inode *inode, struct file *filep) <answer> int 
<token> vfio_device_file *df = filep->private_data; <answer> struct 
struct vfio_device *device <token> df->device; <answer> = 
<token> (df->group) <answer> if 
return <token> <answer> 0; 
int <token> vfio_device *device, <answer> vfio_mig_get_next_state(struct 
enum <token> cur_fsm, <answer> vfio_device_mig_state 
enum vfio_device_mig_state <token> <answer> new_fsm, 
<token> vfio_device_mig_state *next_fsm) <answer> enum 
enum { VFIO_DEVICE_NUM_STATES = <token> + 1 }; <answer> VFIO_DEVICE_STATE_PRE_COPY_P2P 
static const u8 vfio_from_fsm_table[VFIO_DEVICE_NUM_STATES][VFIO_DEVICE_NUM_STATES] = <token> <answer> { 
<token> = { <answer> [VFIO_DEVICE_STATE_STOP] 
[VFIO_DEVICE_STATE_STOP] = <token> <answer> VFIO_DEVICE_STATE_STOP, 
[VFIO_DEVICE_STATE_RUNNING] = <token> <answer> VFIO_DEVICE_STATE_RUNNING_P2P, 
[VFIO_DEVICE_STATE_PRE_COPY] = <token> <answer> VFIO_DEVICE_STATE_RUNNING_P2P, 
<token> = VFIO_DEVICE_STATE_RUNNING_P2P, <answer> [VFIO_DEVICE_STATE_PRE_COPY_P2P] 
<token> = VFIO_DEVICE_STATE_STOP_COPY, <answer> [VFIO_DEVICE_STATE_STOP_COPY] 
[VFIO_DEVICE_STATE_RESUMING] = <token> <answer> VFIO_DEVICE_STATE_RESUMING, 
[VFIO_DEVICE_STATE_RUNNING_P2P] = <token> <answer> VFIO_DEVICE_STATE_RUNNING_P2P, 
<token> = VFIO_DEVICE_STATE_ERROR, <answer> [VFIO_DEVICE_STATE_ERROR] 
[VFIO_DEVICE_STATE_RUNNING] = <token> <answer> { 
[VFIO_DEVICE_STATE_STOP] <token> VFIO_DEVICE_STATE_RUNNING_P2P, <answer> = 
[VFIO_DEVICE_STATE_RUNNING] = <token> <answer> VFIO_DEVICE_STATE_RUNNING, 
[VFIO_DEVICE_STATE_PRE_COPY] = <token> <answer> VFIO_DEVICE_STATE_PRE_COPY, 
<token> = VFIO_DEVICE_STATE_RUNNING_P2P, <answer> [VFIO_DEVICE_STATE_PRE_COPY_P2P] 
<token> = VFIO_DEVICE_STATE_RUNNING_P2P, <answer> [VFIO_DEVICE_STATE_STOP_COPY] 
[VFIO_DEVICE_STATE_RESUMING] = <token> <answer> VFIO_DEVICE_STATE_RUNNING_P2P, 
[VFIO_DEVICE_STATE_RUNNING_P2P] = <token> <answer> VFIO_DEVICE_STATE_RUNNING_P2P, 
[VFIO_DEVICE_STATE_ERROR] = <token> <answer> VFIO_DEVICE_STATE_ERROR, 
[VFIO_DEVICE_STATE_PRE_COPY] = <token> <answer> { 
<token> = VFIO_DEVICE_STATE_RUNNING, <answer> [VFIO_DEVICE_STATE_STOP] 
<token> = VFIO_DEVICE_STATE_RUNNING, <answer> [VFIO_DEVICE_STATE_RUNNING] 
<token> = VFIO_DEVICE_STATE_PRE_COPY, <answer> [VFIO_DEVICE_STATE_PRE_COPY] 
[VFIO_DEVICE_STATE_PRE_COPY_P2P] = <token> <answer> VFIO_DEVICE_STATE_PRE_COPY_P2P, 
<token> = VFIO_DEVICE_STATE_PRE_COPY_P2P, <answer> [VFIO_DEVICE_STATE_STOP_COPY] 
[VFIO_DEVICE_STATE_RESUMING] = <token> <answer> VFIO_DEVICE_STATE_RUNNING, 
<token> = VFIO_DEVICE_STATE_RUNNING, <answer> [VFIO_DEVICE_STATE_RUNNING_P2P] 
[VFIO_DEVICE_STATE_ERROR] = <token> <answer> VFIO_DEVICE_STATE_ERROR, 
[VFIO_DEVICE_STATE_PRE_COPY_P2P] = <token> <answer> { 
[VFIO_DEVICE_STATE_STOP] = <token> <answer> VFIO_DEVICE_STATE_RUNNING_P2P, 
[VFIO_DEVICE_STATE_RUNNING] <token> VFIO_DEVICE_STATE_RUNNING_P2P, <answer> = 
<token> = VFIO_DEVICE_STATE_PRE_COPY, <answer> [VFIO_DEVICE_STATE_PRE_COPY] 
[VFIO_DEVICE_STATE_PRE_COPY_P2P] = <token> <answer> VFIO_DEVICE_STATE_PRE_COPY_P2P, 
[VFIO_DEVICE_STATE_STOP_COPY] <token> VFIO_DEVICE_STATE_STOP_COPY, <answer> = 
[VFIO_DEVICE_STATE_RESUMING] <token> VFIO_DEVICE_STATE_RUNNING_P2P, <answer> = 
<token> = VFIO_DEVICE_STATE_RUNNING_P2P, <answer> [VFIO_DEVICE_STATE_RUNNING_P2P] 
[VFIO_DEVICE_STATE_ERROR] <token> VFIO_DEVICE_STATE_ERROR, <answer> = 
[VFIO_DEVICE_STATE_STOP_COPY] <token> { <answer> = 
[VFIO_DEVICE_STATE_STOP] <token> VFIO_DEVICE_STATE_STOP, <answer> = 
<token> = VFIO_DEVICE_STATE_STOP, <answer> [VFIO_DEVICE_STATE_RUNNING] 
[VFIO_DEVICE_STATE_PRE_COPY] = <token> <answer> VFIO_DEVICE_STATE_ERROR, 
[VFIO_DEVICE_STATE_PRE_COPY_P2P] = <token> <answer> VFIO_DEVICE_STATE_ERROR, 
<token> = VFIO_DEVICE_STATE_STOP_COPY, <answer> [VFIO_DEVICE_STATE_STOP_COPY] 
<token> = VFIO_DEVICE_STATE_STOP, <answer> [VFIO_DEVICE_STATE_RESUMING] 
[VFIO_DEVICE_STATE_RUNNING_P2P] = <token> <answer> VFIO_DEVICE_STATE_STOP, 
[VFIO_DEVICE_STATE_ERROR] <token> VFIO_DEVICE_STATE_ERROR, <answer> = 
[VFIO_DEVICE_STATE_RESUMING] <token> { <answer> = 
<token> = VFIO_DEVICE_STATE_STOP, <answer> [VFIO_DEVICE_STATE_STOP] 
[VFIO_DEVICE_STATE_RUNNING] = <token> <answer> VFIO_DEVICE_STATE_STOP, 
<token> = VFIO_DEVICE_STATE_STOP, <answer> [VFIO_DEVICE_STATE_PRE_COPY] 
[VFIO_DEVICE_STATE_PRE_COPY_P2P] = <token> <answer> VFIO_DEVICE_STATE_STOP, 
[VFIO_DEVICE_STATE_STOP_COPY] <token> VFIO_DEVICE_STATE_STOP, <answer> = 
[VFIO_DEVICE_STATE_RESUMING] = <token> <answer> VFIO_DEVICE_STATE_RESUMING, 
[VFIO_DEVICE_STATE_RUNNING_P2P] <token> VFIO_DEVICE_STATE_STOP, <answer> = 
<token> = VFIO_DEVICE_STATE_ERROR, <answer> [VFIO_DEVICE_STATE_ERROR] 
[VFIO_DEVICE_STATE_RUNNING_P2P] = <token> <answer> { 
<token> = VFIO_DEVICE_STATE_STOP, <answer> [VFIO_DEVICE_STATE_STOP] 
[VFIO_DEVICE_STATE_RUNNING] <token> VFIO_DEVICE_STATE_RUNNING, <answer> = 
<token> = VFIO_DEVICE_STATE_RUNNING, <answer> [VFIO_DEVICE_STATE_PRE_COPY] 
[VFIO_DEVICE_STATE_PRE_COPY_P2P] = <token> <answer> VFIO_DEVICE_STATE_PRE_COPY_P2P, 
<token> = VFIO_DEVICE_STATE_STOP, <answer> [VFIO_DEVICE_STATE_STOP_COPY] 
[VFIO_DEVICE_STATE_RESUMING] = <token> <answer> VFIO_DEVICE_STATE_STOP, 
[VFIO_DEVICE_STATE_RUNNING_P2P] = <token> <answer> VFIO_DEVICE_STATE_RUNNING_P2P, 
<token> = VFIO_DEVICE_STATE_ERROR, <answer> [VFIO_DEVICE_STATE_ERROR] 
<token> = { <answer> [VFIO_DEVICE_STATE_ERROR] 
[VFIO_DEVICE_STATE_STOP] <token> VFIO_DEVICE_STATE_ERROR, <answer> = 
[VFIO_DEVICE_STATE_RUNNING] <token> VFIO_DEVICE_STATE_ERROR, <answer> = 
<token> = VFIO_DEVICE_STATE_ERROR, <answer> [VFIO_DEVICE_STATE_PRE_COPY] 
[VFIO_DEVICE_STATE_PRE_COPY_P2P] <token> VFIO_DEVICE_STATE_ERROR, <answer> = 
[VFIO_DEVICE_STATE_STOP_COPY] <token> VFIO_DEVICE_STATE_ERROR, <answer> = 
[VFIO_DEVICE_STATE_RESUMING] = <token> <answer> VFIO_DEVICE_STATE_ERROR, 
<token> = VFIO_DEVICE_STATE_ERROR, <answer> [VFIO_DEVICE_STATE_RUNNING_P2P] 
[VFIO_DEVICE_STATE_ERROR] <token> VFIO_DEVICE_STATE_ERROR, <answer> = 
static const <token> int state_flags_table[VFIO_DEVICE_NUM_STATES] = { <answer> unsigned 
[VFIO_DEVICE_STATE_STOP] <token> VFIO_MIGRATION_STOP_COPY, <answer> = 
[VFIO_DEVICE_STATE_RUNNING] <token> VFIO_MIGRATION_STOP_COPY, <answer> = 
<token> = <answer> [VFIO_DEVICE_STATE_PRE_COPY] 
<token> | VFIO_MIGRATION_PRE_COPY, <answer> VFIO_MIGRATION_STOP_COPY 
[VFIO_DEVICE_STATE_PRE_COPY_P2P] = VFIO_MIGRATION_STOP_COPY <token> <answer> | 
VFIO_MIGRATION_P2P <token> <answer> | 
<token> = VFIO_MIGRATION_STOP_COPY, <answer> [VFIO_DEVICE_STATE_STOP_COPY] 
[VFIO_DEVICE_STATE_RESUMING] = <token> <answer> VFIO_MIGRATION_STOP_COPY, 
<token> = <answer> [VFIO_DEVICE_STATE_RUNNING_P2P] 
VFIO_MIGRATION_STOP_COPY | <token> <answer> VFIO_MIGRATION_P2P, 
<token> = ~0U, <answer> [VFIO_DEVICE_STATE_ERROR] 
if (WARN_ON(cur_fsm <token> ARRAY_SIZE(vfio_from_fsm_table) || <answer> >= 
(state_flags_table[cur_fsm] & <token> != <answer> device->migration_flags) 
return <token> <answer> -EINVAL; 
if (new_fsm <token> ARRAY_SIZE(vfio_from_fsm_table) || <answer> >= 
(state_flags_table[new_fsm] & device->migration_flags) <token> <answer> != 
return <token> <answer> -EINVAL; 
*next_fsm <token> vfio_from_fsm_table[cur_fsm][new_fsm]; <answer> = 
while ((state_flags_table[*next_fsm] <token> device->migration_flags) != <answer> & 
*next_fsm = <token> <answer> vfio_from_fsm_table[*next_fsm][new_fsm]; 
<token> (*next_fsm != VFIO_DEVICE_STATE_ERROR) ? 0 : -EINVAL; <answer> return 
static int vfio_ioct_mig_return_fd(struct file *filp, <token> __user *arg, <answer> void 
struct <token> *mig) <answer> vfio_device_feature_mig_state 
<token> ret; <answer> int 
int <token> <answer> fd; 
<token> = get_unused_fd_flags(O_CLOEXEC); <answer> fd 
<token> (fd < 0) { <answer> if 
<token> = fd; <answer> ret 
<token> out_fput; <answer> goto 
mig->data_fd = <token> <answer> fd; 
if (copy_to_user(arg, mig, <token> { <answer> sizeof(*mig))) 
ret = <token> <answer> -EFAULT; 
<token> out_put_unused; <answer> goto 
fd_install(fd, <token> <answer> filp); 
<token> 0; <answer> return 
return <token> <answer> ret; 
static <token> <answer> int 
vfio_ioctl_device_feature_mig_device_state(struct vfio_device <token> <answer> *device, 
u32 flags, <token> __user *arg, <answer> void 
size_t <token> <answer> argsz) 
size_t <token> = <answer> minsz 
offsetofend(struct <token> data_fd); <answer> vfio_device_feature_mig_state, 
struct <token> mig; <answer> vfio_device_feature_mig_state 
struct <token> *filp = NULL; <answer> file 
int <token> <answer> ret; 
if <token> <answer> (!device->mig_ops) 
<token> -ENOTTY; <answer> return 
ret = vfio_check_feature(flags, <token> <answer> argsz, 
VFIO_DEVICE_FEATURE_SET <token> <answer> | 
if <token> != 1) <answer> (ret 
<token> ret; <answer> return 
if (copy_from_user(&mig, <token> minsz)) <answer> arg, 
<token> -EFAULT; <answer> return 
if <token> & VFIO_DEVICE_FEATURE_GET) { <answer> (flags 
enum <token> curr_state; <answer> vfio_device_mig_state 
ret = <token> <answer> device->mig_ops->migration_get_state(device, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
mig.device_state = <token> <answer> curr_state; 
goto <token> <answer> out_copy; 
bool <token> file *file) <answer> vfio_file_is_valid(struct 
<token> vfio_group_from_file(file) || <answer> return 
<token> vfio_file_enforced_coherent(struct file *file) <answer> bool 
struct vfio_device <token> <answer> *device; 
struct vfio_group <token> <answer> *group; 
<token> = vfio_group_from_file(file); <answer> group 
if <token> <answer> (group) 
<token> vfio_group_enforced_coherent(group); <answer> return 
device <token> vfio_device_from_file(file); <answer> = 
if <token> <answer> (device) 
<token> device_iommu_capable(device->dev, <answer> return 
<token> true; <answer> return 
static void vfio_device_file_set_kvm(struct <token> *file, struct kvm *kvm) <answer> file 
struct vfio_device_file *df <token> file->private_data; <answer> = 
df->kvm <token> kvm; <answer> = 
void <token> file *file, struct kvm *kvm) <answer> vfio_file_set_kvm(struct 
struct vfio_group <token> <answer> *group; 
group = <token> <answer> vfio_group_from_file(file); 
<token> (group) <answer> if 
vfio_group_set_kvm(group, <token> <answer> kvm); 
if <token> <answer> (vfio_device_from_file(file)) 
vfio_device_file_set_kvm(file, <token> <answer> kvm); 
struct vfio_info_cap_header *vfio_info_cap_add(struct vfio_info_cap <token> <answer> *caps, 
<token> size, u16 id, u16 version) <answer> size_t 
void <token> <answer> *buf; 
struct vfio_info_cap_header <token> *tmp; <answer> *header, 
<token> vfio_pin_pages(struct vfio_device *device, dma_addr_t iova, <answer> int 
int npage, int prot, <token> page **pages) <answer> struct 
<token> = iommufd_access_pin_pages( <answer> ret 
device->iommufd_access, <token> PAGE_SIZE), <answer> ALIGN_DOWN(iova, 
npage * <token> pages, <answer> PAGE_SIZE, 
<token> & IOMMU_WRITE) ? IOMMUFD_ACCESS_RW_WRITE : 0); <answer> (prot 
if <token> <answer> (ret) 
return <token> <answer> ret; 
<token> npage; <answer> return 
return <token> <answer> -EINVAL; 
void vfio_unpin_pages(struct <token> *device, dma_addr_t iova, int npage) <answer> vfio_device 
<token> (WARN_ON(!vfio_assert_device_open(device))) <answer> if 
<token> (WARN_ON(!device->ops->dma_unmap)) <answer> if 
if <token> { <answer> (vfio_device_has_container(device)) 
vfio_device_container_unpin_pages(device, iova, <token> <answer> npage); 
<token> (device->iommufd_access) { <answer> if 
<token> (WARN_ON(iova > ULONG_MAX)) <answer> if 
<token> PAGE_SIZE), <answer> ALIGN_DOWN(iova, 
npage * <token> <answer> PAGE_SIZE); 
int vfio_dma_rw(struct vfio_device *device, <token> iova, void *data, <answer> dma_addr_t 
<token> len, bool write) <answer> size_t 
if (!data || len <= 0 <token> !vfio_assert_device_open(device)) <answer> || 
<token> -EINVAL; <answer> return 
<token> (vfio_device_has_container(device)) <answer> if 
return vfio_device_container_dma_rw(device, <token> <answer> iova, 
data, len, <token> <answer> write); 
<token> (device->iommufd_access) { <answer> if 
unsigned <token> flags = 0; <answer> int 
if (iova > <token> <answer> ULONG_MAX) 
return <token> <answer> -EINVAL; 
<token> int __init vfio_init(void) <answer> static 
<token> ret; <answer> int 
ret <token> vfio_group_init(); <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> = vfio_virqfd_init(); <answer> ret 
if <token> <answer> (ret) 
goto <token> <answer> err_virqfd; 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/clk.h> 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/of_address.h> 
<token> <linux/of.h> <answer> #include 
<token> <linux/of_platform.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/property.h> <answer> #include 
#include <token> <answer> <linux/mfd/syscon.h> 
#include <token> <answer> <linux/mfd/syscon/imx6q-iomuxc-gpr.h> 
#include <token> <answer> <linux/regmap.h> 
struct imx_weim_devtype <token> <answer> { 
unsigned <token> cs_count; <answer> int 
unsigned <token> cs_regs_count; <answer> int 
unsigned <token> cs_stride; <answer> int 
unsigned <token> wcr_offset; <answer> int 
unsigned int <token> <answer> wcr_bcm; 
unsigned <token> wcr_cont_bclk; <answer> int 
static const <token> imx_weim_devtype imx1_weim_devtype = { <answer> struct 
.cs_count = <token> <answer> 6, 
<token> = 2, <answer> .cs_regs_count 
.cs_stride = <token> <answer> 0x08, 
static const struct imx_weim_devtype imx27_weim_devtype <token> { <answer> = 
.cs_count = <token> <answer> 6, 
.cs_regs_count = <token> <answer> 3, 
.cs_stride = <token> <answer> 0x10, 
static <token> struct imx_weim_devtype imx50_weim_devtype = { <answer> const 
.cs_count = <token> <answer> 4, 
.cs_regs_count <token> 6, <answer> = 
<token> = 0x18, <answer> .cs_stride 
<token> = 0x90, <answer> .wcr_offset 
.wcr_bcm = <token> <answer> BIT(0), 
.wcr_cont_bclk = <token> <answer> BIT(3), 
static <token> struct imx_weim_devtype imx51_weim_devtype = { <answer> const 
<token> = 6, <answer> .cs_count 
<token> = 6, <answer> .cs_regs_count 
.cs_stride = <token> <answer> 0x18, 
<token> MAX_CS_REGS_COUNT 6 <answer> #define 
#define <token> 6 <answer> MAX_CS_COUNT 
<token> OF_REG_SIZE 3 <answer> #define 
struct cs_timing <token> <answer> { 
bool <token> <answer> is_applied; 
u32 <token> <answer> regs[MAX_CS_REGS_COUNT]; 
struct cs_timing_state <token> <answer> { 
<token> cs_timing cs[MAX_CS_COUNT]; <answer> struct 
struct <token> { <answer> weim_priv 
void __iomem <token> <answer> *base; 
struct cs_timing_state <token> <answer> timing_state; 
static <token> struct of_device_id weim_id_table[] = { <answer> const 
num_regs <token> of_property_count_elems_of_size(np, "reg", OF_REG_SIZE); <answer> = 
if <token> < 0) <answer> (num_regs 
return <token> <answer> num_regs; 
if <token> <answer> (!num_regs) 
<token> -EINVAL; <answer> return 
for (reg_idx <token> 0; reg_idx < num_regs; reg_idx++) { <answer> = 
<token> &= ~FWNODE_FLAG_NOT_DEVICE; <answer> rd->dn->fwnode.flags 
if (!of_platform_device_create(rd->dn, <token> &pdev->dev)) { <answer> NULL, 
"Failed to create child <token> '%pOF'\n", <answer> device 
ret <token> notifier_from_errno(-EINVAL); <answer> = 
case <token> <answer> OF_RECONFIG_CHANGE_REMOVE: 
<token> (!of_node_check_flag(rd->dn, OF_POPULATED)) <answer> if 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/err.h> 
<token> <linux/isa.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/pnp.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/io.h> 
<token> <asm/dma.h> <answer> #include 
#include <token> <answer> <sound/core.h> 
#include <token> <answer> <sound/tlv.h> 
<token> <sound/wss.h> <answer> #include 
<token> <sound/mpu401.h> <answer> #include 
#include <token> <answer> <sound/opl3.h> 
#ifndef <token> <answer> OPTi93X 
<token> <sound/opl4.h> <answer> #include 
#define <token> <answer> SNDRV_LEGACY_FIND_FREE_IOPORT 
#define <token> <answer> SNDRV_LEGACY_FIND_FREE_IRQ 
#define <token> <answer> SNDRV_LEGACY_FIND_FREE_DMA 
<token> <sound/initval.h> <answer> #include 
MODULE_AUTHOR("Massimo <token> <dafastidio@libero.it>"); <answer> Piccioni 
<token> OPTi93X <answer> #ifdef 
snd_opti9xx_write_mask(chip, <token> 0x00, 0x0c); <answer> OPTi9XX_MC_REG(4), 
#ifdef <token> <answer> CS4231 
<token> OPTi9XX_MC_REG(5), 0x02, 0x02); <answer> snd_opti9xx_write_mask(chip, 
<token> OPTi9XX_MC_REG(5), 0x00, 0x02); <answer> snd_opti9xx_write_mask(chip, 
<token> OPTi9XX_MC_REG(21), 0x82, 0xff); <answer> snd_opti9xx_write_mask(chip, 
snd_opti9xx_write_mask(chip, OPTi9XX_MC_REG(26), <token> 0x01); <answer> 0x01, 
<token> OPTi9XX_HW_82C930: <answer> case 
snd_opti9xx_write_mask(chip, OPTi9XX_MC_REG(6), 0x02, <token> <answer> 0x03); 
snd_opti9xx_write_mask(chip, <token> 0x00, 0xff); <answer> OPTi9XX_MC_REG(3), 
<token> OPTi9XX_MC_REG(4), 0x10 | <answer> snd_opti9xx_write_mask(chip, 
(chip->hardware == OPTi9XX_HW_82C930 ? <token> : 0x04), <answer> 0x00 
snd_opti9xx_write_mask(chip, <token> 0x20, 0xbf); <answer> OPTi9XX_MC_REG(5), 
chip->mc_indir_index = (pnp_port_start(pdev, <token> & ~0xf) | 0xe; <answer> 3) 
<token> = pnp_request_card_device(card, pid->devs[2].id, NULL); <answer> devmc 
if (devmc <token> NULL) <answer> == 
<token> -EBUSY; <answer> return 
err = <token> <answer> pnp_activate_dev(devmc); 
if (err < 0) <token> <answer> { 
snd_printk(KERN_ERR "MC pnp configure <token> %d\n", err); <answer> failure: 
return <token> <answer> err; 
port <token> pnp_port_start(pdev, 1); <answer> = 
fm_port <token> pnp_port_start(pdev, 2) + 8; <answer> = 
chip->mc_base = pnp_port_start(devmc, 0) <token> 1; <answer> - 
<token> = pnp_port_len(devmc, 0) + 1; <answer> chip->mc_base_size 
<token> _GNU_SOURCE <answer> #undef 
#include <token> <answer> <string.h> 
<token> <stdio.h> <answer> #include 
<token> <linux/string.h> <answer> #include 
char <token> errnum, char *buf, size_t buflen) <answer> *str_error_r(int 
int err = strerror_r(errnum, <token> buflen); <answer> buf, 
if <token> <answer> (err) 
snprintf(buf, buflen, "INTERNAL <token> strerror_r(%d, [buf], %zd)=%d", errnum, buflen, err); <answer> ERROR: 
return <token> <answer> buf; 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/mod_devicetable.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/pm_runtime.h> 
#include <token> <answer> <linux/slab.h> 
<token> <media/v4l2-ioctl.h> <answer> #include 
#include <token> <answer> <media/v4l2-event.h> 
#include <token> <answer> <media/v4l2-ctrls.h> 
#include <token> <answer> <media/v4l2-mem2mem.h> 
#include <token> <answer> <media/videobuf2-dma-contig.h> 
<token> "hfi_venus_io.h" <answer> #include 
<token> "hfi_parser.h" <answer> #include 
<token> "core.h" <answer> #include 
<token> "helpers.h" <answer> #include 
<token> "vdec.h" <answer> #include 
#include <token> <answer> "pm_helpers.h" 
static const struct venus_format vdec_formats[] <token> { <answer> = 
<token> = { <answer> [VENUS_FMT_NV12] 
.pixfmt = <token> <answer> V4L2_PIX_FMT_NV12, 
.num_planes = <token> <answer> 1, 
.type = <token> <answer> V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE, 
[VENUS_FMT_QC08C] <token> { <answer> = 
.pixfmt <token> V4L2_PIX_FMT_QC08C, <answer> = 
.num_planes = <token> <answer> 1, 
.type = <token> <answer> V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE, 
[VENUS_FMT_QC10C] = <token> <answer> { 
.pixfmt = <token> <answer> V4L2_PIX_FMT_QC10C, 
<token> = 1, <answer> .num_planes 
<token> = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE, <answer> .type 
[VENUS_FMT_P010] = <token> <answer> { 
<token> = V4L2_PIX_FMT_P010, <answer> .pixfmt 
<token> = 1, <answer> .num_planes 
.type <token> V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE, <answer> = 
<token> = { <answer> [VENUS_FMT_H264] 
.pixfmt = <token> <answer> V4L2_PIX_FMT_H264, 
<token> = 1, <answer> .num_planes 
.type <token> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, <answer> = 
.flags = <token> <answer> V4L2_FMT_FLAG_DYN_RESOLUTION, 
[VENUS_FMT_VP8] = <token> <answer> { 
<token> = V4L2_PIX_FMT_VP8, <answer> .pixfmt 
.num_planes = <token> <answer> 1, 
.type = <token> <answer> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, 
.flags = <token> <answer> V4L2_FMT_FLAG_DYN_RESOLUTION, 
<token> = { <answer> [VENUS_FMT_VP9] 
<token> = V4L2_PIX_FMT_VP9, <answer> .pixfmt 
.num_planes = <token> <answer> 1, 
.type <token> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, <answer> = 
<token> = V4L2_FMT_FLAG_DYN_RESOLUTION, <answer> .flags 
[VENUS_FMT_HEVC] <token> { <answer> = 
<token> = V4L2_PIX_FMT_HEVC, <answer> .pixfmt 
.num_planes <token> 1, <answer> = 
.type <token> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, <answer> = 
.flags = <token> <answer> V4L2_FMT_FLAG_DYN_RESOLUTION, 
[VENUS_FMT_VC1_ANNEX_G] = <token> <answer> { 
<token> = V4L2_PIX_FMT_VC1_ANNEX_G, <answer> .pixfmt 
.num_planes = <token> <answer> 1, 
.type = <token> <answer> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, 
<token> = V4L2_FMT_FLAG_DYN_RESOLUTION, <answer> .flags 
<token> = { <answer> [VENUS_FMT_VC1_ANNEX_L] 
<token> = V4L2_PIX_FMT_VC1_ANNEX_L, <answer> .pixfmt 
.num_planes <token> 1, <answer> = 
.type = <token> <answer> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, 
.flags <token> V4L2_FMT_FLAG_DYN_RESOLUTION, <answer> = 
<token> = { <answer> [VENUS_FMT_MPEG4] 
.pixfmt <token> V4L2_PIX_FMT_MPEG4, <answer> = 
.num_planes = <token> <answer> 1, 
.type = <token> <answer> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, 
<token> = V4L2_FMT_FLAG_DYN_RESOLUTION, <answer> .flags 
[VENUS_FMT_MPEG2] = <token> <answer> { 
.pixfmt = <token> <answer> V4L2_PIX_FMT_MPEG2, 
.num_planes = <token> <answer> 1, 
<token> = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, <answer> .type 
.flags = <token> <answer> V4L2_FMT_FLAG_DYN_RESOLUTION, 
[VENUS_FMT_H263] <token> { <answer> = 
.pixfmt = <token> <answer> V4L2_PIX_FMT_H263, 
.num_planes <token> 1, <answer> = 
.type <token> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, <answer> = 
<token> = V4L2_FMT_FLAG_DYN_RESOLUTION, <answer> .flags 
[VENUS_FMT_XVID] = <token> <answer> { 
<token> = V4L2_PIX_FMT_XVID, <answer> .pixfmt 
.num_planes = <token> <answer> 1, 
<token> = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE, <answer> .type 
.flags = <token> <answer> V4L2_FMT_FLAG_DYN_RESOLUTION, 
static <token> struct venus_format * <answer> const 
find_format(struct venus_inst *inst, <token> pixfmt, u32 type) <answer> u32 
const struct venus_format *fmt <token> vdec_formats; <answer> = 
unsigned int size = <token> <answer> ARRAY_SIZE(vdec_formats); 
unsigned <token> i; <answer> int 
for (i = 0; i <token> size; i++) { <answer> < 
if <token> == pixfmt) <answer> (fmt[i].pixfmt 
if (i == <token> || fmt[i].type != type) <answer> size 
<token> NULL; <answer> return 
<token> (type == V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE && <answer> if 
<token> fmt[i].pixfmt)) <answer> !venus_helper_check_codec(inst, 
return <token> <answer> NULL; 
if <token> && <answer> (V4L2_TYPE_IS_CAPTURE(type) 
<token> fmt[i].pixfmt)) <answer> !venus_helper_check_format(inst, 
<token> NULL; <answer> return 
if (V4L2_TYPE_IS_CAPTURE(type) <token> fmt[i].pixfmt == V4L2_PIX_FMT_QC10C && <answer> && 
<token> == VIDC_BITDEPTH_10)) <answer> !(inst->bit_depth 
return <token> <answer> NULL; 
<token> &fmt[i]; <answer> return 
static const struct <token> * <answer> venus_format 
<token> venus_inst *inst, unsigned int index, u32 type) <answer> find_format_by_index(struct 
const struct venus_format *fmt <token> vdec_formats; <answer> = 
unsigned int size = <token> <answer> ARRAY_SIZE(vdec_formats); 
<token> int i, k = 0; <answer> unsigned 
if (index <token> size) <answer> > 
return <token> <answer> NULL; 
for (i = 0; i < size; <token> { <answer> i++) 
bool <token> <answer> valid; 
if (fmt[i].type != <token> <answer> type) 
if (V4L2_TYPE_IS_OUTPUT(type)) <token> <answer> { 
valid = venus_helper_check_codec(inst, <token> <answer> fmt[i].pixfmt); 
} else if (V4L2_TYPE_IS_CAPTURE(type)) <token> <answer> { 
valid = <token> fmt[i].pixfmt); <answer> venus_helper_check_format(inst, 
if (fmt[i].pixfmt <token> V4L2_PIX_FMT_QC10C && <answer> == 
!(inst->bit_depth == <token> <answer> VIDC_BITDEPTH_10)) 
valid = <token> <answer> false; 
if (k == <token> && valid) <answer> index 
<token> (valid) <answer> if 
<token> (i == size) <answer> if 
<token> NULL; <answer> return 
return <token> <answer> &fmt[i]; 
static const struct venus_format <token> <answer> * 
vdec_try_fmt_common(struct venus_inst *inst, struct <token> *f) <answer> v4l2_format 
struct <token> *pixmp = &f->fmt.pix_mp; <answer> v4l2_pix_format_mplane 
struct v4l2_plane_pix_format *pfmt = <token> <answer> pixmp->plane_fmt; 
const struct venus_format <token> <answer> *fmt; 
<token> szimage; <answer> u32 
<token> 0, sizeof(pfmt[0].reserved)); <answer> memset(pfmt[0].reserved, 
memset(pixmp->reserved, <token> sizeof(pixmp->reserved)); <answer> 0, 
<token> = find_format(inst, pixmp->pixelformat, f->type); <answer> fmt 
if <token> { <answer> (!fmt) 
if <token> == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) <answer> (f->type 
<token> = V4L2_PIX_FMT_NV12; <answer> pixmp->pixelformat 
<token> if (f->type == V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE) <answer> else 
pixmp->pixelformat <token> V4L2_PIX_FMT_H264; <answer> = 
return <token> <answer> NULL; 
<token> = find_format(inst, pixmp->pixelformat, f->type); <answer> fmt 
if <token> <answer> (!fmt) 
return <token> <answer> NULL; 
pixmp->width = clamp(pixmp->width, <token> <answer> frame_width_min(inst), 
pixmp->height = clamp(pixmp->height, <token> <answer> frame_height_min(inst), 
if (f->type == <token> <answer> V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) 
pixmp->height <token> ALIGN(pixmp->height, 32); <answer> = 
if (pixmp->field == <token> <answer> V4L2_FIELD_ANY) 
pixmp->field = <token> <answer> V4L2_FIELD_NONE; 
<token> = fmt->num_planes; <answer> pixmp->num_planes 
pixmp->flags <token> 0; <answer> = 
<token> = venus_helper_get_framesz(pixmp->pixelformat, pixmp->width, <answer> szimage 
if (f->type <token> V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) { <answer> == 
unsigned int <token> = pixmp->width; <answer> stride 
<token> (pixmp->pixelformat == V4L2_PIX_FMT_P010) <answer> if 
<token> *= 2; <answer> stride 
pfmt[0].sizeimage = <token> <answer> szimage; 
<token> = ALIGN(stride, 128); <answer> pfmt[0].bytesperline 
} else <token> <answer> { 
<token> = clamp_t(u32, pfmt[0].sizeimage, 0, SZ_8M); <answer> pfmt[0].sizeimage 
<token> = max(pfmt[0].sizeimage, szimage); <answer> pfmt[0].sizeimage 
pfmt[0].bytesperline = <token> <answer> 0; 
return <token> <answer> fmt; 
static int vdec_try_fmt(struct file *file, void *fh, struct v4l2_format <token> <answer> *f) 
struct venus_inst *inst = <token> <answer> to_inst(file); 
<token> f); <answer> vdec_try_fmt_common(inst, 
<token> 0; <answer> return 
<token> int vdec_check_src_change(struct venus_inst *inst) <answer> static 
<token> ret; <answer> int 
<token> (inst->subscriptions & V4L2_EVENT_SOURCE_CHANGE && <answer> if 
<token> == VENUS_DEC_STATE_INIT && <answer> inst->codec_state 
return <token> <answer> -EINVAL; 
if (inst->subscriptions & <token> <answer> V4L2_EVENT_SOURCE_CHANGE) 
<token> 0; <answer> return 
if (inst->codec_state <token> VENUS_DEC_STATE_INIT) <answer> != 
goto <token> <answer> done; 
ret = wait_event_timeout(inst->reconf_wait, <token> <answer> inst->reconfig, 
if <token> <answer> (!ret) 
return <token> <answer> -EINVAL; 
<token> (!(inst->codec_state == VENUS_DEC_STATE_CAPTURE_SETUP) || <answer> if 
dev_dbg(inst->core->dev, VDBGH "wrong <token> <answer> state\n"); 
<token> 0; <answer> return 
static int vdec_g_fmt(struct file *file, void *fh, <token> v4l2_format *f) <answer> struct 
struct venus_inst *inst = <token> <answer> to_inst(file); 
<token> struct venus_format *fmt = NULL; <answer> const 
<token> v4l2_pix_format_mplane *pixmp = &f->fmt.pix_mp; <answer> struct 
int <token> <answer> ret; 
if (f->type == <token> <answer> V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) 
fmt <token> inst->fmt_cap; <answer> = 
else <token> (f->type == V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE) <answer> if 
<token> = inst->fmt_out; <answer> fmt 
if (f->type <token> V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) { <answer> == 
<token> = vdec_check_src_change(inst); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
pixmp->pixelformat = <token> <answer> fmt->pixfmt; 
if (f->type <token> V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) { <answer> == 
<token> = inst->width; <answer> pixmp->width 
pixmp->height <token> inst->height; <answer> = 
<token> = inst->colorspace; <answer> pixmp->colorspace 
pixmp->ycbcr_enc = <token> <answer> inst->ycbcr_enc; 
pixmp->quantization <token> inst->quantization; <answer> = 
<token> = inst->xfer_func; <answer> pixmp->xfer_func 
} else if (f->type == <token> { <answer> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE) 
pixmp->width <token> inst->out_width; <answer> = 
<token> = inst->out_height; <answer> pixmp->height 
<token> f); <answer> vdec_try_fmt_common(inst, 
return <token> <answer> 0; 
static int vdec_s_fmt(struct file <token> void *fh, struct v4l2_format *f) <answer> *file, 
struct <token> *inst = to_inst(file); <answer> venus_inst 
<token> v4l2_pix_format_mplane *pixmp = &f->fmt.pix_mp; <answer> struct 
<token> v4l2_pix_format_mplane orig_pixmp; <answer> struct 
const <token> venus_format *fmt; <answer> struct 
<token> v4l2_format format; <answer> struct 
<token> pixfmt_out = 0, pixfmt_cap = 0; <answer> u32 
struct vb2_queue <token> <answer> *q; 
q = v4l2_m2m_get_vq(inst->m2m_ctx, <token> <answer> f->type); 
<token> (!q) <answer> if 
<token> -EINVAL; <answer> return 
if <token> <answer> (vb2_is_busy(q)) 
return <token> <answer> -EBUSY; 
<token> = *pixmp; <answer> orig_pixmp 
fmt = <token> f); <answer> vdec_try_fmt_common(inst, 
if (f->type == <token> { <answer> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE) 
<token> = pixmp->pixelformat; <answer> pixfmt_out 
pixfmt_cap <token> inst->fmt_cap->pixfmt; <answer> = 
} else <token> (f->type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) { <answer> if 
<token> = pixmp->pixelformat; <answer> pixfmt_cap 
pixfmt_out <token> inst->fmt_out->pixfmt; <answer> = 
<token> 0, sizeof(format)); <answer> memset(&format, 
<token> = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE; <answer> format.type 
format.fmt.pix_mp.pixelformat = <token> <answer> pixfmt_out; 
<token> = orig_pixmp.width; <answer> format.fmt.pix_mp.width 
format.fmt.pix_mp.height <token> orig_pixmp.height; <answer> = 
<token> &format); <answer> vdec_try_fmt_common(inst, 
if (f->type == <token> { <answer> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE) 
inst->out_width <token> format.fmt.pix_mp.width; <answer> = 
<token> = format.fmt.pix_mp.height; <answer> inst->out_height 
inst->colorspace = <token> <answer> pixmp->colorspace; 
<token> = pixmp->ycbcr_enc; <answer> inst->ycbcr_enc 
inst->quantization = <token> <answer> pixmp->quantization; 
inst->xfer_func <token> pixmp->xfer_func; <answer> = 
inst->input_buf_size = <token> <answer> pixmp->plane_fmt[0].sizeimage; 
<token> 0, sizeof(format)); <answer> memset(&format, 
format.type <token> V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE; <answer> = 
<token> = pixfmt_cap; <answer> format.fmt.pix_mp.pixelformat 
<token> = orig_pixmp.width; <answer> format.fmt.pix_mp.width 
<token> = orig_pixmp.height; <answer> format.fmt.pix_mp.height 
vdec_try_fmt_common(inst, <token> <answer> &format); 
<token> = format.fmt.pix_mp.width; <answer> inst->width 
inst->height <token> format.fmt.pix_mp.height; <answer> = 
inst->crop.top <token> 0; <answer> = 
inst->crop.left <token> 0; <answer> = 
<token> = inst->width; <answer> inst->crop.width 
<token> = inst->height; <answer> inst->crop.height 
if <token> == V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE) <answer> (f->type 
<token> = fmt; <answer> inst->fmt_out 
<token> if (f->type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) { <answer> else 
inst->fmt_cap = <token> <answer> fmt; 
<token> = <answer> inst->output2_buf_size 
<token> orig_pixmp.width, orig_pixmp.height); <answer> venus_helper_get_framesz(pixfmt_cap, 
return <token> <answer> 0; 
static <token> <answer> int 
vdec_g_selection(struct <token> *file, void *fh, struct v4l2_selection *s) <answer> file 
struct venus_inst *inst <token> to_inst(file); <answer> = 
if (s->type <token> V4L2_BUF_TYPE_VIDEO_CAPTURE && <answer> != 
<token> != V4L2_BUF_TYPE_VIDEO_OUTPUT) <answer> s->type 
<token> -EINVAL; <answer> return 
<token> = 0; <answer> s->r.top 
<token> = 0; <answer> s->r.left 
<token> (s->target) { <answer> switch 
<token> V4L2_SEL_TGT_CROP_BOUNDS: <answer> case 
<token> V4L2_SEL_TGT_CROP_DEFAULT: <answer> case 
<token> V4L2_SEL_TGT_CROP: <answer> case 
if (s->type <token> V4L2_BUF_TYPE_VIDEO_OUTPUT) <answer> != 
return <token> <answer> -EINVAL; 
<token> = inst->out_width; <answer> s->r.width 
s->r.height = <token> <answer> inst->out_height; 
case <token> <answer> V4L2_SEL_TGT_COMPOSE_BOUNDS: 
case <token> <answer> V4L2_SEL_TGT_COMPOSE_PADDED: 
if (s->type <token> V4L2_BUF_TYPE_VIDEO_CAPTURE) <answer> != 
<token> -EINVAL; <answer> return 
<token> = inst->width; <answer> s->r.width 
s->r.height <token> inst->height; <answer> = 
case <token> <answer> V4L2_SEL_TGT_COMPOSE_DEFAULT: 
case <token> <answer> V4L2_SEL_TGT_COMPOSE: 
if (s->type <token> V4L2_BUF_TYPE_VIDEO_CAPTURE) <answer> != 
<token> -EINVAL; <answer> return 
<token> = inst->crop; <answer> s->r 
return <token> <answer> -EINVAL; 
<token> 0; <answer> return 
<token> int <answer> static 
vdec_querycap(struct file <token> void *fh, struct v4l2_capability *cap) <answer> *file, 
strscpy(cap->driver, "qcom-venus", <token> <answer> sizeof(cap->driver)); 
strscpy(cap->card, "Qualcomm <token> video decoder", sizeof(cap->card)); <answer> Venus 
strscpy(cap->bus_info, "platform:qcom-venus", <token> <answer> sizeof(cap->bus_info)); 
return <token> <answer> 0; 
static int vdec_enum_fmt(struct <token> *file, void *fh, struct v4l2_fmtdesc *f) <answer> file 
struct <token> *inst = to_inst(file); <answer> venus_inst 
const <token> venus_format *fmt; <answer> struct 
<token> 0, sizeof(f->reserved)); <answer> memset(f->reserved, 
fmt = find_format_by_index(inst, <token> f->type); <answer> f->index, 
<token> (!fmt) <answer> if 
<token> -EINVAL; <answer> return 
f->pixelformat <token> fmt->pixfmt; <answer> = 
f->flags <token> fmt->flags; <answer> = 
return <token> <answer> 0; 
static int <token> file *file, void *fh, struct v4l2_streamparm *a) <answer> vdec_s_parm(struct 
<token> venus_inst *inst = to_inst(file); <answer> struct 
struct v4l2_captureparm *cap = <token> <answer> &a->parm.capture; 
<token> v4l2_fract *timeperframe = &cap->timeperframe; <answer> struct 
<token> us_per_frame, fps; <answer> u64 
if (a->type <token> V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE && <answer> != 
a->type <token> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE) <answer> != 
return <token> <answer> -EINVAL; 
memset(cap->reserved, 0, <token> <answer> sizeof(cap->reserved)); 
if <token> <answer> (!timeperframe->denominator) 
timeperframe->denominator <token> inst->timeperframe.denominator; <answer> = 
<token> (!timeperframe->numerator) <answer> if 
<token> = inst->timeperframe.numerator; <answer> timeperframe->numerator 
<token> = 0; <answer> cap->readbuffers 
cap->extendedmode <token> 0; <answer> = 
cap->capability = <token> <answer> V4L2_CAP_TIMEPERFRAME; 
us_per_frame = <token> * (u64)USEC_PER_SEC; <answer> timeperframe->numerator 
<token> timeperframe->denominator); <answer> do_div(us_per_frame, 
if <token> <answer> (!us_per_frame) 
<token> -EINVAL; <answer> return 
fps <token> (u64)USEC_PER_SEC; <answer> = 
<token> us_per_frame); <answer> do_div(fps, 
inst->fps = <token> <answer> fps; 
<token> = *timeperframe; <answer> inst->timeperframe 
return <token> <answer> 0; 
static <token> vdec_enum_framesizes(struct file *file, void *fh, <answer> int 
struct <token> *fsize) <answer> v4l2_frmsizeenum 
struct <token> *inst = to_inst(file); <answer> venus_inst 
const struct venus_format <token> <answer> *fmt; 
fmt = <token> fsize->pixel_format, <answer> find_format(inst, 
<token> (!fmt) { <answer> if 
fmt <token> find_format(inst, fsize->pixel_format, <answer> = 
if <token> <answer> (!fmt) 
<token> -EINVAL; <answer> return 
if <token> <answer> (fsize->index) 
return <token> <answer> -EINVAL; 
fsize->type = <token> <answer> V4L2_FRMSIZE_TYPE_STEPWISE; 
fsize->stepwise.min_width = <token> <answer> frame_width_min(inst); 
fsize->stepwise.max_width = <token> <answer> frame_width_max(inst); 
fsize->stepwise.step_width <token> frame_width_step(inst); <answer> = 
fsize->stepwise.min_height <token> frame_height_min(inst); <answer> = 
fsize->stepwise.max_height = <token> <answer> frame_height_max(inst); 
fsize->stepwise.step_height <token> frame_height_step(inst); <answer> = 
<token> 0; <answer> return 
static <token> vdec_subscribe_event(struct v4l2_fh *fh, <answer> int 
const struct v4l2_event_subscription <token> <answer> *sub) 
struct venus_inst *inst = <token> struct venus_inst, fh); <answer> container_of(fh, 
int <token> <answer> ret; 
<token> (sub->type) { <answer> switch 
case <token> <answer> V4L2_EVENT_EOS: 
return v4l2_event_subscribe(fh, sub, 2, <token> <answer> NULL); 
<token> V4L2_EVENT_SOURCE_CHANGE: <answer> case 
ret = v4l2_src_change_event_subscribe(fh, <token> <answer> sub); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
inst->subscriptions |= <token> <answer> V4L2_EVENT_SOURCE_CHANGE; 
<token> 0; <answer> return 
<token> V4L2_EVENT_CTRL: <answer> case 
return <token> sub); <answer> v4l2_ctrl_subscribe_event(fh, 
return <token> <answer> -EINVAL; 
<token> int <answer> static 
vdec_decoder_cmd(struct file *file, void *fh, struct <token> *cmd) <answer> v4l2_decoder_cmd 
<token> venus_inst *inst = to_inst(file); <answer> struct 
<token> vb2_queue *dst_vq; <answer> struct 
struct hfi_frame_data <token> = {0}; <answer> fdata 
<token> ret; <answer> int 
ret = <token> fh, cmd); <answer> v4l2_m2m_ioctl_try_decoder_cmd(file, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if (cmd->cmd == V4L2_DEC_CMD_STOP) <token> <answer> { 
if <token> && inst->streamon_cap)) <answer> (!(inst->streamon_out 
goto <token> <answer> unlock; 
<token> = HFI_BUFFER_INPUT; <answer> fdata.buffer_type 
<token> |= HFI_BUFFERFLAG_EOS; <answer> fdata.flags 
if (IS_V6(inst->core) && is_fw_rev_or_older(inst->core, <token> 0, 87)) <answer> 1, 
fdata.device_addr = <token> <answer> 0; 
<token> = 0xdeadb000; <answer> fdata.device_addr 
ret = <token> &fdata); <answer> hfi_session_process_buf(inst, 
if (!ret && inst->codec_state <token> VENUS_DEC_STATE_DECODING) { <answer> == 
<token> = VENUS_DEC_STATE_DRAIN; <answer> inst->codec_state 
inst->drain_active <token> true; <answer> = 
} else if (cmd->cmd == V4L2_DEC_CMD_START <token> <answer> && 
inst->codec_state <token> VENUS_DEC_STATE_STOPPED) { <answer> == 
<token> = v4l2_m2m_get_vq(inst->fh.m2m_ctx, <answer> dst_vq 
inst->codec_state <token> VENUS_DEC_STATE_DECODING; <answer> = 
<token> ret; <answer> return 
static const struct v4l2_ioctl_ops vdec_ioctl_ops = <token> <answer> { 
.vidioc_querycap <token> vdec_querycap, <answer> = 
<token> = vdec_enum_fmt, <answer> .vidioc_enum_fmt_vid_cap 
.vidioc_enum_fmt_vid_out = <token> <answer> vdec_enum_fmt, 
.vidioc_s_fmt_vid_cap_mplane = <token> <answer> vdec_s_fmt, 
<token> = vdec_s_fmt, <answer> .vidioc_s_fmt_vid_out_mplane 
.vidioc_g_fmt_vid_cap_mplane = <token> <answer> vdec_g_fmt, 
<token> = vdec_g_fmt, <answer> .vidioc_g_fmt_vid_out_mplane 
<token> = vdec_try_fmt, <answer> .vidioc_try_fmt_vid_cap_mplane 
<token> = vdec_try_fmt, <answer> .vidioc_try_fmt_vid_out_mplane 
.vidioc_g_selection <token> vdec_g_selection, <answer> = 
.vidioc_reqbufs = <token> <answer> v4l2_m2m_ioctl_reqbufs, 
<token> = v4l2_m2m_ioctl_querybuf, <answer> .vidioc_querybuf 
.vidioc_create_bufs = <token> <answer> v4l2_m2m_ioctl_create_bufs, 
.vidioc_prepare_buf <token> v4l2_m2m_ioctl_prepare_buf, <answer> = 
.vidioc_qbuf <token> v4l2_m2m_ioctl_qbuf, <answer> = 
.vidioc_expbuf = <token> <answer> v4l2_m2m_ioctl_expbuf, 
.vidioc_dqbuf <token> v4l2_m2m_ioctl_dqbuf, <answer> = 
.vidioc_streamon <token> v4l2_m2m_ioctl_streamon, <answer> = 
.vidioc_streamoff = <token> <answer> v4l2_m2m_ioctl_streamoff, 
<token> = vdec_s_parm, <answer> .vidioc_s_parm 
.vidioc_enum_framesizes <token> vdec_enum_framesizes, <answer> = 
.vidioc_subscribe_event <token> vdec_subscribe_event, <answer> = 
.vidioc_unsubscribe_event = <token> <answer> v4l2_event_unsubscribe, 
.vidioc_try_decoder_cmd <token> v4l2_m2m_ioctl_try_decoder_cmd, <answer> = 
.vidioc_decoder_cmd <token> vdec_decoder_cmd, <answer> = 
static int vdec_pm_get(struct venus_inst <token> <answer> *inst) 
struct venus_core <token> = inst->core; <answer> *core 
struct device *dev = <token> <answer> core->dev_dec; 
<token> ret; <answer> int 
ret <token> pm_runtime_resume_and_get(dev); <answer> = 
return <token> <answer> ret; 
static int vdec_pm_put(struct venus_inst *inst, bool <token> <answer> autosuspend) 
struct venus_core *core = <token> <answer> inst->core; 
<token> device *dev = core->dev_dec; <answer> struct 
int <token> <answer> ret; 
if <token> <answer> (autosuspend) 
ret <token> pm_runtime_put_autosuspend(dev); <answer> = 
ret <token> pm_runtime_put_sync(dev); <answer> = 
return ret < 0 <token> ret : 0; <answer> ? 
static int vdec_pm_get_put(struct <token> *inst) <answer> venus_inst 
struct venus_core *core <token> inst->core; <answer> = 
struct device <token> = core->dev_dec; <answer> *dev 
<token> ret = 0; <answer> int 
<token> (pm_runtime_suspended(dev)) { <answer> if 
ret = <token> <answer> pm_runtime_resume_and_get(dev); 
if (ret < <token> <answer> 0) 
<token> error; <answer> goto 
ret = <token> <answer> pm_runtime_put_autosuspend(dev); 
<token> ret < 0 ? ret : 0; <answer> return 
static void vdec_pm_touch(struct venus_inst <token> <answer> *inst) 
static int <token> venus_inst *inst) <answer> vdec_set_properties(struct 
struct vdec_controls <token> = &inst->controls.dec; <answer> *ctr 
struct hfi_enable en = { .enable = 1 <token> <answer> }; 
<token> ptype, decode_order, conceal; <answer> u32 
int <token> <answer> ret; 
if (ctr->post_loop_deb_mode) <token> <answer> { 
ptype = <token> <answer> HFI_PROPERTY_CONFIG_VDEC_POST_LOOP_DEBLOCKER; 
ret = hfi_session_set_property(inst, <token> &en); <answer> ptype, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
<token> (ctr->display_delay_enable && ctr->display_delay == 0) { <answer> if 
<token> = HFI_PROPERTY_PARAM_VDEC_OUTPUT_ORDER; <answer> ptype 
decode_order <token> HFI_OUTPUT_ORDER_DECODE; <answer> = 
ret <token> hfi_session_set_property(inst, ptype, &decode_order); <answer> = 
if <token> <answer> (ret) 
<token> ret; <answer> return 
if (ev_data->input_crop.width > 0 && ev_data->input_crop.height > <token> { <answer> 0) 
inst->crop.left <token> ev_data->input_crop.left; <answer> = 
<token> = ev_data->input_crop.top; <answer> inst->crop.top 
inst->crop.width = <token> <answer> ev_data->input_crop.width; 
inst->crop.height = <token> <answer> ev_data->input_crop.height; 
<token> else { <answer> } 
<token> = 0; <answer> inst->crop.left 
inst->crop.top <token> 0; <answer> = 
<token> = ev_data->width; <answer> inst->crop.width 
inst->crop.height <token> ev_data->height; <answer> = 
inst->fw_min_cnt = <token> <answer> ev_data->buf_count; 
if (inst->codec_state == VENUS_DEC_STATE_DRC) <token> <answer> { 
<token> ret; <answer> int 
inst->next_buf_last <token> true; <answer> = 
ret = hfi_session_flush(inst, <token> false); <answer> HFI_FLUSH_OUTPUT, 
<token> (ret) <answer> if 
dev_dbg(dev, VDBGH "flush output error %d\n", <token> <answer> ret); 
inst->next_buf_last = <token> <answer> true; 
inst->reconfig = <token> <answer> true; 
v4l2_event_queue_fh(&inst->fh, <token> <answer> &ev); 
static void vdec_event_notify(struct <token> *inst, u32 event, <answer> venus_inst 
struct hfi_event_data <token> <answer> *data) 
struct venus_core *core = <token> <answer> inst->core; 
struct device *dev <token> core->dev_dec; <answer> = 
switch (event) <token> <answer> { 
case <token> <answer> EVT_SESSION_ERROR: 
inst->session_error = <token> <answer> true; 
dev_err(dev, <token> event session error %x\n", inst->error); <answer> "dec: 
case <token> <answer> EVT_SYS_EVENT_CHANGE: 
<token> (data->event_type) { <answer> switch 
<token> HFI_EVENT_DATA_SEQUENCE_CHANGED_SUFFICIENT_BUF_RESOURCES: <answer> case 
<token> data, true); <answer> vdec_event_change(inst, 
case <token> <answer> HFI_EVENT_DATA_SEQUENCE_CHANGED_INSUFFICIENT_BUF_RESOURCES: 
vdec_event_change(inst, data, <token> <answer> false); 
case <token> <answer> HFI_EVENT_RELEASE_BUFFER_REFERENCE: 
venus_helper_release_buf_ref(inst, <token> <answer> data->tag); 
static void vdec_flush_done(struct venus_inst <token> <answer> *inst) 
<token> VDBGH "flush done\n"); <answer> dev_dbg(inst->core->dev_dec, 
static <token> struct hfi_inst_ops vdec_hfi_ops = { <answer> const 
.buf_done <token> vdec_buf_done, <answer> = 
.event_notify <token> vdec_event_notify, <answer> = 
.flush_done = <token> <answer> vdec_flush_done, 
static void vdec_inst_init(struct venus_inst <token> <answer> *inst) 
<token> = HFI_VIDEO_CODEC_H264; <answer> inst->hfi_codec 
<token> = &vdec_formats[VENUS_FMT_H264]; <answer> inst->fmt_out 
inst->fmt_cap <token> &vdec_formats[VENUS_FMT_NV12]; <answer> = 
inst->width <token> frame_width_min(inst); <answer> = 
<token> = ALIGN(frame_height_min(inst), 32); <answer> inst->height 
inst->crop.left = <token> <answer> 0; 
inst->crop.top <token> 0; <answer> = 
<token> = inst->width; <answer> inst->crop.width 
inst->crop.height = <token> <answer> inst->height; 
<token> = 8; <answer> inst->fw_min_cnt 
inst->out_width <token> frame_width_min(inst); <answer> = 
<token> = frame_height_min(inst); <answer> inst->out_height 
<token> = 30; <answer> inst->fps 
<token> = 1; <answer> inst->timeperframe.numerator 
inst->timeperframe.denominator <token> 30; <answer> = 
inst->opb_buftype <token> HFI_BUFFER_OUTPUT; <answer> = 
<token> void vdec_m2m_device_run(void *priv) <answer> static 
static const struct v4l2_m2m_ops vdec_m2m_ops <token> { <answer> = 
<token> = vdec_m2m_device_run, <answer> .device_run 
.job_abort = <token> <answer> venus_helper_m2m_job_abort, 
static int m2m_queue_init(void <token> struct vb2_queue *src_vq, <answer> *priv, 
<token> vb2_queue *dst_vq) <answer> struct 
struct venus_inst *inst <token> priv; <answer> = 
<token> ret; <answer> int 
src_vq->type <token> V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE; <answer> = 
src_vq->io_modes = VB2_MMAP <token> VB2_DMABUF; <answer> | 
src_vq->timestamp_flags = <token> <answer> V4L2_BUF_FLAG_TIMESTAMP_COPY; 
src_vq->ops = <token> <answer> &vdec_vb2_ops; 
src_vq->mem_ops = <token> <answer> &vb2_dma_contig_memops; 
src_vq->drv_priv <token> inst; <answer> = 
src_vq->buf_struct_size = sizeof(struct <token> <answer> venus_buffer); 
src_vq->allow_zero_bytesused = <token> <answer> 1; 
src_vq->min_queued_buffers <token> 0; <answer> = 
src_vq->dev = <token> <answer> inst->core->dev; 
src_vq->lock <token> &inst->ctx_q_lock; <answer> = 
ret <token> vb2_queue_init(src_vq); <answer> = 
if <token> <answer> (ret) 
return <token> <answer> ret; 
dst_vq->type = <token> <answer> V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE; 
dst_vq->io_modes = VB2_MMAP <token> VB2_DMABUF; <answer> | 
dst_vq->timestamp_flags = <token> <answer> V4L2_BUF_FLAG_TIMESTAMP_COPY; 
<token> = &vdec_vb2_ops; <answer> dst_vq->ops 
dst_vq->mem_ops = <token> <answer> &vb2_dma_contig_memops; 
dst_vq->drv_priv <token> inst; <answer> = 
dst_vq->buf_struct_size <token> sizeof(struct venus_buffer); <answer> = 
<token> = 1; <answer> dst_vq->allow_zero_bytesused 
<token> = 0; <answer> dst_vq->min_queued_buffers 
dst_vq->dev = <token> <answer> inst->core->dev; 
dst_vq->lock = <token> <answer> &inst->ctx_q_lock; 
return <token> <answer> vb2_queue_init(dst_vq); 
static int vdec_open(struct file <token> <answer> *file) 
struct venus_core *core <token> video_drvdata(file); <answer> = 
struct venus_inst <token> <answer> *inst; 
int <token> <answer> ret; 
<token> = kzalloc(sizeof(*inst), GFP_KERNEL); <answer> inst 
<token> (!inst) <answer> if 
<token> -ENOMEM; <answer> return 
<token> = core; <answer> inst->core 
<token> = VIDC_SESSION_TYPE_DEC; <answer> inst->session_type 
<token> = 1; <answer> inst->num_output_bufs 
inst->codec_state = <token> <answer> VENUS_DEC_STATE_DEINIT; 
inst->buf_count = <token> <answer> 0; 
inst->clk_data.core_id = <token> <answer> VIDC_CORE_ID_DEFAULT; 
inst->core_acquired <token> false; <answer> = 
inst->bit_depth = <token> <answer> VIDC_BITDEPTH_8; 
inst->pic_struct = <token> <answer> HFI_INTERLACE_FRAME_PROGRESSIVE; 
inst->nonblock = file->f_flags <token> O_NONBLOCK; <answer> & 
<token> = vdec_ctrl_init(inst); <answer> ret 
<token> (ret) <answer> if 
<token> err_free; <answer> goto 
ret = hfi_session_create(inst, <token> <answer> &vdec_hfi_ops); 
if <token> <answer> (ret) 
<token> err_ctrl_deinit; <answer> goto 
inst->m2m_dev <token> v4l2_m2m_init(&vdec_m2m_ops); <answer> = 
<token> (IS_ERR(inst->m2m_dev)) { <answer> if 
ret <token> PTR_ERR(inst->m2m_dev); <answer> = 
<token> err_session_destroy; <answer> goto 
inst->m2m_ctx <token> v4l2_m2m_ctx_init(inst->m2m_dev, inst, m2m_queue_init); <answer> = 
if (IS_ERR(inst->m2m_ctx)) <token> <answer> { 
<token> = PTR_ERR(inst->m2m_ctx); <answer> ret 
goto <token> <answer> err_m2m_release; 
<token> core->vdev_dec); <answer> v4l2_fh_init(&inst->fh, 
inst->fh.ctrl_handler = <token> <answer> &inst->ctrl_handler; 
inst->fh.m2m_ctx <token> inst->m2m_ctx; <answer> = 
file->private_data = <token> <answer> &inst->fh; 
return <token> <answer> 0; 
<token> ret; <answer> return 
static int <token> file *file) <answer> vdec_close(struct 
struct venus_inst <token> = to_inst(file); <answer> *inst 
vdec_pm_put(inst, <token> <answer> false); 
return <token> <answer> 0; 
static const struct v4l2_file_operations vdec_fops = <token> <answer> { 
<token> = THIS_MODULE, <answer> .owner 
.open = <token> <answer> vdec_open, 
.release <token> vdec_close, <answer> = 
.unlocked_ioctl = <token> <answer> video_ioctl2, 
.poll <token> v4l2_m2m_fop_poll, <answer> = 
<token> = v4l2_m2m_fop_mmap, <answer> .mmap 
static int <token> platform_device *pdev) <answer> vdec_probe(struct 
struct device *dev = <token> <answer> &pdev->dev; 
struct <token> *vdev; <answer> video_device 
struct <token> *core; <answer> venus_core 
<token> ret; <answer> int 
if <token> <answer> (!dev->parent) 
return <token> <answer> -EPROBE_DEFER; 
core <token> dev_get_drvdata(dev->parent); <answer> = 
if <token> <answer> (!core) 
return <token> <answer> -EPROBE_DEFER; 
platform_set_drvdata(pdev, <token> <answer> core); 
<token> (core->pm_ops->vdec_get) { <answer> if 
ret = <token> <answer> core->pm_ops->vdec_get(dev); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
<token> = video_device_alloc(); <answer> vdev 
if <token> <answer> (!vdev) 
<token> -ENOMEM; <answer> return 
strscpy(vdev->name, "qcom-venus-decoder", <token> <answer> sizeof(vdev->name)); 
<token> = video_device_release; <answer> vdev->release 
vdev->fops <token> &vdec_fops; <answer> = 
<token> = &vdec_ioctl_ops; <answer> vdev->ioctl_ops 
vdev->vfl_dir = <token> <answer> VFL_DIR_M2M; 
vdev->v4l2_dev <token> &core->v4l2_dev; <answer> = 
<token> = V4L2_CAP_VIDEO_M2M_MPLANE | V4L2_CAP_STREAMING; <answer> vdev->device_caps 
ret = video_register_device(vdev, <token> -1); <answer> VFL_TYPE_VIDEO, 
if <token> <answer> (ret) 
<token> err_vdev_release; <answer> goto 
<token> = vdev; <answer> core->vdev_dec 
core->dev_dec <token> dev; <answer> = 
video_set_drvdata(vdev, <token> <answer> core); 
<token> 2000); <answer> pm_runtime_set_autosuspend_delay(dev, 
<token> 0; <answer> return 
return <token> <answer> ret; 
static void vdec_remove(struct platform_device <token> <answer> *pdev) 
<token> venus_core *core = dev_get_drvdata(pdev->dev.parent); <answer> struct 
<token> (core->pm_ops->vdec_put) <answer> if 
static __maybe_unused int <token> device *dev) <answer> vdec_runtime_suspend(struct 
struct venus_core *core <token> dev_get_drvdata(dev); <answer> = 
const <token> venus_pm_ops *pm_ops = core->pm_ops; <answer> struct 
int ret <token> 0; <answer> = 
if <token> <answer> (pm_ops->vdec_power) 
ret = <token> POWER_OFF); <answer> pm_ops->vdec_power(dev, 
<token> ret; <answer> return 
static __maybe_unused <token> vdec_runtime_resume(struct device *dev) <answer> int 
struct venus_core *core <token> dev_get_drvdata(dev); <answer> = 
<token> struct venus_pm_ops *pm_ops = core->pm_ops; <answer> const 
<token> ret = 0; <answer> int 
if <token> <answer> (pm_ops->vdec_power) 
<token> = pm_ops->vdec_power(dev, POWER_ON); <answer> ret 
return <token> <answer> ret; 
<token> const struct dev_pm_ops vdec_pm_ops = { <answer> static 
SET_RUNTIME_PM_OPS(vdec_runtime_suspend, <token> NULL) <answer> vdec_runtime_resume, 
static const struct of_device_id vdec_dt_match[] <token> { <answer> = 
{ <token> = "venus-decoder" }, <answer> .compatible 
<token> } <answer> { 
<token> vdec_dt_match); <answer> MODULE_DEVICE_TABLE(of, 
<token> struct platform_driver qcom_venus_dec_driver = { <answer> static 
.probe <token> vdec_probe, <answer> = 
.remove_new <token> vdec_remove, <answer> = 
<token> = { <answer> .driver 
.name = <token> <answer> "qcom-venus-decoder", 
<token> = vdec_dt_match, <answer> .of_match_table 
.pm = <token> <answer> &vdec_pm_ops, 
MODULE_DESCRIPTION("Qualcomm Venus <token> decoder driver"); <answer> video 
<token> v2"); <answer> MODULE_LICENSE("GPL 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/ref_tracker.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/timer.h> 
static struct ref_tracker_dir <token> <answer> ref_dir; 
<token> struct ref_tracker *tracker[20]; <answer> static 
#define TRT_ALLOC(X) static noinline void <token> <answer> \ 
alloctest_ref_tracker_alloc##X(struct ref_tracker_dir *dir, <token> <answer> \ 
struct <token> **trackerp) \ <answer> ref_tracker 
{ <token> <answer> \ 
<token> trackerp, GFP_KERNEL); \ <answer> ref_tracker_alloc(dir, 
<token> TRT_ALLOC <answer> #undef 
<token> noinline void <answer> static 
<token> ref_tracker_dir *dir, <answer> alloctest_ref_tracker_free(struct 
struct <token> **trackerp) <answer> ref_tracker 
ref_tracker_free(dir, <token> <answer> trackerp); 
<token> struct timer_list test_ref_tracker_timer; <answer> static 
static atomic_t test_ref_timer_done = <token> <answer> ATOMIC_INIT(0); 
static void test_ref_tracker_timer_func(struct <token> *t) <answer> timer_list 
ref_tracker_alloc(&ref_dir, &tracker[0], <token> <answer> GFP_ATOMIC); 
atomic_set(&test_ref_timer_done, <token> <answer> 1); 
<token> int __init test_ref_tracker_init(void) <answer> static 
<token> i; <answer> int 
ref_tracker_dir_init(&ref_dir, 100, <token> <answer> "selftest"); 
timer_setup(&test_ref_tracker_timer, <token> 0); <answer> test_ref_tracker_timer_func, 
mod_timer(&test_ref_tracker_timer, jiffies <token> 1); <answer> + 
<token> &tracker[1]); <answer> alloctest_ref_tracker_alloc1(&ref_dir, 
<token> &tracker[2]); <answer> alloctest_ref_tracker_alloc2(&ref_dir, 
<token> &tracker[3]); <answer> alloctest_ref_tracker_alloc3(&ref_dir, 
alloctest_ref_tracker_alloc4(&ref_dir, <token> <answer> &tracker[4]); 
alloctest_ref_tracker_alloc5(&ref_dir, <token> <answer> &tracker[5]); 
<token> &tracker[6]); <answer> alloctest_ref_tracker_alloc6(&ref_dir, 
<token> &tracker[7]); <answer> alloctest_ref_tracker_alloc7(&ref_dir, 
<token> &tracker[8]); <answer> alloctest_ref_tracker_alloc8(&ref_dir, 
<token> &tracker[9]); <answer> alloctest_ref_tracker_alloc9(&ref_dir, 
alloctest_ref_tracker_alloc10(&ref_dir, <token> <answer> &tracker[10]); 
<token> &tracker[11]); <answer> alloctest_ref_tracker_alloc11(&ref_dir, 
<token> &tracker[12]); <answer> alloctest_ref_tracker_alloc12(&ref_dir, 
<token> &tracker[13]); <answer> alloctest_ref_tracker_alloc13(&ref_dir, 
<token> &tracker[14]); <answer> alloctest_ref_tracker_alloc14(&ref_dir, 
<token> &tracker[15]); <answer> alloctest_ref_tracker_alloc15(&ref_dir, 
<token> &tracker[16]); <answer> alloctest_ref_tracker_alloc16(&ref_dir, 
alloctest_ref_tracker_alloc17(&ref_dir, <token> <answer> &tracker[17]); 
<token> &tracker[18]); <answer> alloctest_ref_tracker_alloc18(&ref_dir, 
<token> &tracker[19]); <answer> alloctest_ref_tracker_alloc19(&ref_dir, 
#include <token> <answer> "ubifs.h" 
static int scan_padding_bytes(void <token> int len) <answer> *buf, 
int pad_len = 0, max_pad_len <token> min_t(int, UBIFS_PAD_NODE_SZ, len); <answer> = 
<token> *p = buf; <answer> uint8_t 
dbg_scan("not <token> node"); <answer> a 
while (pad_len <token> max_pad_len && *p++ == UBIFS_PADDING_BYTE) <answer> < 
pad_len <token> 1; <answer> += 
<token> (!pad_len || (pad_len & 7)) <answer> if 
<token> SCANNED_GARBAGE; <answer> return 
dbg_scan("%d padding bytes", <token> <answer> pad_len); 
return <token> <answer> pad_len; 
int ubifs_scan_a_node(const struct ubifs_info <token> void *buf, int len, int lnum, <answer> *c, 
int <token> int quiet) <answer> offs, 
struct ubifs_ch *ch <token> buf; <answer> = 
<token> magic; <answer> uint32_t 
<token> = le32_to_cpu(ch->magic); <answer> magic 
if (magic == <token> { <answer> 0xFFFFFFFF) 
dbg_scan("hit empty space at LEB %d:%d", <token> offs); <answer> lnum, 
<token> SCANNED_EMPTY_SPACE; <answer> return 
if (magic != <token> <answer> UBIFS_NODE_MAGIC) 
<token> scan_padding_bytes(buf, len); <answer> return 
if (len <token> UBIFS_CH_SZ) <answer> < 
<token> SCANNED_GARBAGE; <answer> return 
dbg_scan("scanning <token> at LEB %d:%d", <answer> %s 
dbg_ntype(ch->node_type), <token> offs); <answer> lnum, 
if (ubifs_check_node(c, buf, <token> lnum, offs, quiet, 1)) <answer> len, 
<token> SCANNED_A_CORRUPT_NODE; <answer> return 
if <token> == UBIFS_PAD_NODE) { <answer> (ch->node_type 
struct ubifs_pad_node *pad <token> buf; <answer> = 
int pad_len = <token> <answer> le32_to_cpu(pad->pad_len); 
int <token> = le32_to_cpu(ch->len); <answer> node_len 
struct ubifs_scan_leb <token> struct ubifs_info *c, int lnum, <answer> *ubifs_start_scan(const 
int <token> void *sbuf) <answer> offs, 
<token> ubifs_scan_leb *sleb; <answer> struct 
int <token> <answer> err; 
dbg_scan("scan <token> %d:%d", lnum, offs); <answer> LEB 
sleb = kzalloc(sizeof(struct <token> GFP_NOFS); <answer> ubifs_scan_leb), 
if <token> <answer> (!sleb) 
return <token> <answer> ERR_PTR(-ENOMEM); 
sleb->lnum <token> lnum; <answer> = 
<token> = sbuf; <answer> sleb->buf 
err = ubifs_leb_read(c, lnum, sbuf + offs, offs, c->leb_size - <token> 0); <answer> offs, 
if (err && err != -EBADMSG) <token> <answer> { 
ubifs_err(c, "cannot read %d bytes from LEB <token> error %d", <answer> %d:%d, 
c->leb_size - <token> lnum, offs, err); <answer> offs, 
<token> ERR_PTR(err); <answer> return 
<token> sleb; <answer> return 
void ubifs_end_scan(const <token> ubifs_info *c, struct ubifs_scan_leb *sleb, <answer> struct 
<token> lnum, int offs) <answer> int 
dbg_scan("stop scanning <token> %d at offset %d", lnum, offs); <answer> LEB 
ubifs_assert(c, offs <token> c->min_io_size == 0); <answer> % 
<token> = ALIGN(offs, c->min_io_size); <answer> sleb->endpt 
int ubifs_add_snod(const struct ubifs_info *c, struct ubifs_scan_leb <token> <answer> *sleb, 
void *buf, <token> offs) <answer> int 
<token> ubifs_ch *ch = buf; <answer> struct 
struct ubifs_ino_node *ino <token> buf; <answer> = 
struct ubifs_scan_node <token> <answer> *snod; 
<token> = kmalloc(sizeof(struct ubifs_scan_node), GFP_NOFS); <answer> snod 
<token> (!snod) <answer> if 
<token> -ENOMEM; <answer> return 
snod->sqnum <token> le64_to_cpu(ch->sqnum); <answer> = 
snod->type = <token> <answer> ch->node_type; 
snod->offs <token> offs; <answer> = 
<token> = le32_to_cpu(ch->len); <answer> snod->len 
<token> = buf; <answer> snod->node 
switch <token> { <answer> (ch->node_type) 
case <token> <answer> UBIFS_INO_NODE: 
case <token> <answer> UBIFS_DENT_NODE: 
<token> UBIFS_XENT_NODE: <answer> case 
case <token> <answer> UBIFS_DATA_NODE: 
key_read(c, <token> &snod->key); <answer> &ino->key, 
<token> &snod->key); <answer> invalid_key_init(c, 
<token> &sleb->nodes); <answer> list_add_tail(&snod->list, 
sleb->nodes_cnt += <token> <answer> 1; 
return <token> <answer> 0; 
void ubifs_scanned_corruption(const struct ubifs_info *c, int lnum, <token> offs, <answer> int 
void <token> <answer> *buf) 
<token> len; <answer> int 
ubifs_err(c, "corruption at <token> %d:%d", lnum, offs); <answer> LEB 
len <token> c->leb_size - offs; <answer> = 
<token> (len > 8192) <answer> if 
<token> = 8192; <answer> len 
ubifs_err(c, "first %d bytes from LEB %d:%d", len, <token> offs); <answer> lnum, 
print_hex_dump(KERN_DEBUG, "", DUMP_PREFIX_OFFSET, 32, 4, buf, <token> 1); <answer> len, 
struct <token> *ubifs_scan(const struct ubifs_info *c, int lnum, <answer> ubifs_scan_leb 
int offs, <token> *sbuf, int quiet) <answer> void 
<token> *buf = sbuf + offs; <answer> void 
int err, len = <token> - offs; <answer> c->leb_size 
struct ubifs_scan_leb <token> <answer> *sleb; 
sleb = ubifs_start_scan(c, lnum, <token> sbuf); <answer> offs, 
<token> (IS_ERR(sleb)) <answer> if 
<token> sleb; <answer> return 
while (len >= <token> { <answer> 8) 
struct <token> *ch = buf; <answer> ubifs_ch 
int node_len, <token> <answer> ret; 
dbg_scan("look at LEB %d:%d (%d bytes <token> <answer> left)", 
lnum, <token> len); <answer> offs, 
ret = ubifs_scan_a_node(c, <token> len, lnum, offs, quiet); <answer> buf, 
if <token> > 0) { <answer> (ret 
void ubifs_scan_destroy(struct <token> *sleb) <answer> ubifs_scan_leb 
<token> ubifs_scan_node *node; <answer> struct 
<token> list_head *head; <answer> struct 
<token> = &sleb->nodes; <answer> head 
while (!list_empty(head)) <token> <answer> { 
node = list_entry(head->next, struct ubifs_scan_node, <token> <answer> list); 
<token> <stddef.h> <answer> #include 
<token> <string.h> <answer> #include 
<token> <linux/bpf.h> <answer> #include 
<token> <linux/if_ether.h> <answer> #include 
#include <token> <answer> <linux/if_packet.h> 
<token> <linux/ip.h> <answer> #include 
<token> <linux/ipv6.h> <answer> #include 
#include <token> <answer> <linux/in.h> 
<token> <linux/udp.h> <answer> #include 
<token> <linux/tcp.h> <answer> #include 
#include <token> <answer> <linux/pkt_cls.h> 
#include <token> <answer> <sys/socket.h> 
#include <token> <answer> <bpf/bpf_helpers.h> 
#include <token> <answer> <bpf/bpf_endian.h> 
#include <token> <answer> "test_iptunnel_common.h" 
<token> "bpf_compiler.h" <answer> #include 
struct <token> <answer> { 
__uint(type, <token> <answer> BPF_MAP_TYPE_PERCPU_ARRAY); 
__uint(max_entries, <token> <answer> 256); 
<token> __u32); <answer> __type(key, 
__type(value, <token> <answer> __u64); 
} rxcnt <token> <answer> SEC(".maps"); 
<token> { <answer> struct 
<token> BPF_MAP_TYPE_HASH); <answer> __uint(type, 
<token> MAX_IPTNL_ENTRIES); <answer> __uint(max_entries, 
<token> struct vip); <answer> __type(key, 
__type(value, <token> iptnl_info); <answer> struct 
} vip2tnl <token> <answer> SEC(".maps"); 
static <token> void count_tx(__u32 protocol) <answer> __always_inline 
__u64 <token> <answer> *rxcnt_count; 
<token> = bpf_map_lookup_elem(&rxcnt, &protocol); <answer> rxcnt_count 
if <token> <answer> (rxcnt_count) 
*rxcnt_count <token> 1; <answer> += 
static __always_inline int get_dport(void *trans_data, <token> *data_end, <answer> void 
<token> protocol) <answer> __u8 
struct tcphdr <token> <answer> *th; 
struct udphdr <token> <answer> *uh; 
<token> (protocol) { <answer> switch 
<token> IPPROTO_TCP: <answer> case 
th = <token> tcphdr *)trans_data; <answer> (struct 
<token> (th + 1 > data_end) <answer> if 
<token> -1; <answer> return 
<token> th->dest; <answer> return 
<token> IPPROTO_UDP: <answer> case 
uh = <token> udphdr *)trans_data; <answer> (struct 
if (uh + <token> > data_end) <answer> 1 
return <token> <answer> -1; 
<token> uh->dest; <answer> return 
<token> 0; <answer> return 
static __always_inline void <token> ethhdr *new_eth, <answer> set_ethhdr(struct 
const struct ethhdr <token> <answer> *old_eth, 
<token> struct iptnl_info *tnl, <answer> const 
__be16 <token> <answer> h_proto) 
memcpy(new_eth->h_source, old_eth->h_dest, <token> <answer> sizeof(new_eth->h_source)); 
memcpy(new_eth->h_dest, tnl->dmac, <token> <answer> sizeof(new_eth->h_dest)); 
<token> = h_proto; <answer> new_eth->h_proto 
static __always_inline int handle_ipv4(struct <token> *xdp) <answer> xdp_md 
void *data_end = (void <token> <answer> *)(long)xdp->data_end; 
void *data = (void <token> <answer> *)(long)xdp->data; 
struct <token> *tnl; <answer> iptnl_info 
<token> ethhdr *new_eth; <answer> struct 
struct ethhdr <token> <answer> *old_eth; 
struct iphdr *iph = data + <token> ethhdr); <answer> sizeof(struct 
<token> *next_iph; <answer> __u16 
<token> payload_len; <answer> __u16 
struct vip <token> = {}; <answer> vip 
int <token> <answer> dport; 
__u32 csum = <token> <answer> 0; 
<token> i; <answer> int 
if (iph <token> 1 > data_end) <answer> + 
return <token> <answer> XDP_DROP; 
dport = get_dport(iph + 1, data_end, <token> <answer> iph->protocol); 
<token> (dport == -1) <answer> if 
return <token> <answer> XDP_DROP; 
<token> = iph->protocol; <answer> vip.protocol 
vip.family = <token> <answer> AF_INET; 
vip.daddr.v4 = <token> <answer> iph->daddr; 
vip.dport = <token> <answer> dport; 
<token> = bpf_ntohs(iph->tot_len); <answer> payload_len 
<token> = bpf_map_lookup_elem(&vip2tnl, &vip); <answer> tnl 
<token> <linux/delay.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
<token> <linux/mailbox_client.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_platform.h> 
#include <token> <answer> <linux/phy/phy.h> 
<token> <linux/phy/tegra/xusb.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/regulator/consumer.h> <answer> #include 
#include <token> <answer> <linux/reset.h> 
<token> <linux/slab.h> <answer> #include 
<token> <linux/workqueue.h> <answer> #include 
#include <token> <answer> <soc/tegra/fuse.h> 
<token> "xusb.h" <answer> #include 
static struct phy *tegra_xusb_pad_of_xlate(struct <token> *dev, <answer> device 
const <token> of_phandle_args *args) <answer> struct 
struct tegra_xusb_pad <token> = dev_get_drvdata(dev); <answer> *pad 
struct phy *phy = <token> <answer> NULL; 
<token> int i; <answer> unsigned 
if (args->args_count <token> 0) <answer> != 
<token> ERR_PTR(-EINVAL); <answer> return 
for (i = 0; i <token> pad->soc->num_lanes; i++) { <answer> < 
<token> (!pad->lanes[i]) <answer> if 
<token> (pad->lanes[i]->dev.of_node == args->np) { <answer> if 
<token> = pad->lanes[i]; <answer> phy 
if <token> == NULL) <answer> (phy 
phy <token> ERR_PTR(-ENODEV); <answer> = 
return <token> <answer> phy; 
static <token> struct of_device_id tegra_xusb_padctl_of_match[] = { <answer> const 
#if defined(CONFIG_ARCH_TEGRA_124_SOC) <token> defined(CONFIG_ARCH_TEGRA_132_SOC) <answer> || 
.compatible = <token> <answer> "nvidia,tegra124-xusb-padctl", 
.data <token> &tegra124_xusb_padctl_soc, <answer> = 
#if <token> <answer> defined(CONFIG_ARCH_TEGRA_210_SOC) 
<token> = "nvidia,tegra210-xusb-padctl", <answer> .compatible 
<token> = &tegra210_xusb_padctl_soc, <answer> .data 
<token> defined(CONFIG_ARCH_TEGRA_186_SOC) <answer> #if 
.compatible <token> "nvidia,tegra186-xusb-padctl", <answer> = 
.data = <token> <answer> &tegra186_xusb_padctl_soc, 
#if <token> <answer> defined(CONFIG_ARCH_TEGRA_194_SOC) 
<token> = "nvidia,tegra194-xusb-padctl", <answer> .compatible 
.data <token> &tegra194_xusb_padctl_soc, <answer> = 
<token> defined(CONFIG_ARCH_TEGRA_234_SOC) <answer> #if 
.compatible <token> "nvidia,tegra234-xusb-padctl", <answer> = 
.data <token> &tegra234_xusb_padctl_soc, <answer> = 
<token> } <answer> { 
<token> tegra_xusb_padctl_of_match); <answer> MODULE_DEVICE_TABLE(of, 
static <token> device_node * <answer> struct 
tegra_xusb_find_pad_node(struct tegra_xusb_padctl *padctl, const <token> *name) <answer> char 
<token> device_node *pads, *np; <answer> struct 
pads <token> of_get_child_by_name(padctl->dev->of_node, "pads"); <answer> = 
<token> (!pads) <answer> if 
return <token> <answer> NULL; 
np = of_get_child_by_name(pads, <token> <answer> name); 
<token> np; <answer> return 
static <token> device_node * <answer> struct 
<token> tegra_xusb_pad *pad, unsigned int index) <answer> tegra_xusb_pad_find_phy_node(struct 
struct <token> *np, *lanes; <answer> device_node 
lanes = of_get_child_by_name(pad->dev.of_node, <token> <answer> "lanes"); 
if <token> <answer> (!lanes) 
return <token> <answer> NULL; 
np <token> of_get_child_by_name(lanes, pad->soc->lanes[index].name); <answer> = 
return <token> <answer> np; 
int tegra_xusb_lane_parse_dt(struct <token> *lane, <answer> tegra_xusb_lane 
<token> device_node *np) <answer> struct 
struct device *dev = <token> <answer> &lane->pad->dev; 
const <token> *function; <answer> char 
<token> err; <answer> int 
err <token> of_property_read_string(np, "nvidia,function", &function); <answer> = 
if (err < <token> <answer> 0) 
<token> err; <answer> return 
err = <token> lane->soc->num_funcs, function); <answer> match_string(lane->soc->funcs, 
if <token> < 0) { <answer> (err 
dev_err(dev, <token> function \"%s\" for lane \"%pOFn\"\n", <answer> "invalid 
<token> np); <answer> function, 
return <token> <answer> err; 
<token> = err; <answer> lane->function 
<token> 0; <answer> return 
<token> void tegra_xusb_lane_destroy(struct phy *phy) <answer> static 
<token> (phy) { <answer> if 
struct tegra_xusb_lane *lane = <token> <answer> phy_get_drvdata(phy); 
static void <token> device *dev) <answer> tegra_xusb_pad_release(struct 
<token> tegra_xusb_pad *pad = to_tegra_xusb_pad(dev); <answer> struct 
static const struct device_type tegra_xusb_pad_type <token> { <answer> = 
.release <token> tegra_xusb_pad_release, <answer> = 
int tegra_xusb_pad_init(struct tegra_xusb_pad <token> <answer> *pad, 
struct <token> *padctl, <answer> tegra_xusb_padctl 
struct <token> *np) <answer> device_node 
<token> err; <answer> int 
<token> = padctl->dev; <answer> pad->dev.parent 
pad->dev.type <token> &tegra_xusb_pad_type; <answer> = 
<token> = np; <answer> pad->dev.of_node 
pad->padctl <token> padctl; <answer> = 
err = dev_set_name(&pad->dev, "%s", <token> <answer> pad->soc->name); 
if <token> < 0) <answer> (err 
goto <token> <answer> unregister; 
err = <token> <answer> device_add(&pad->dev); 
if (err < <token> <answer> 0) 
<token> unregister; <answer> goto 
return <token> <answer> 0; 
<token> err; <answer> return 
<token> tegra_xusb_pad_register(struct tegra_xusb_pad *pad, <answer> int 
const struct phy_ops <token> <answer> *ops) 
struct <token> *children; <answer> device_node 
struct phy <token> <answer> *lane; 
unsigned int <token> <answer> i; 
<token> err; <answer> int 
children <token> of_get_child_by_name(pad->dev.of_node, "lanes"); <answer> = 
<token> (!children) <answer> if 
<token> -ENODEV; <answer> return 
pad->lanes = devm_kcalloc(&pad->dev, pad->soc->num_lanes, <token> <answer> sizeof(lane), 
<token> (!pad->lanes) { <answer> if 
<token> -ENOMEM; <answer> return 
for (i = 0; i < pad->soc->num_lanes; i++) <token> <answer> { 
struct <token> *np = tegra_xusb_pad_find_phy_node(pad, i); <answer> device_node 
struct tegra_xusb_lane <token> <answer> *lane; 
port->dev.driver = <token> <answer> devm_kzalloc(&port->dev, 
sizeof(struct <token> <answer> device_driver), 
<token> (!port->dev.driver) <answer> if 
return <token> <answer> -ENOMEM; 
port->dev.driver->owner = <token> <answer> THIS_MODULE; 
<token> = usb_role_switch_register(&port->dev, <answer> port->usb_role_sw 
<token> (IS_ERR(port->usb_role_sw)) { <answer> if 
err = <token> <answer> PTR_ERR(port->usb_role_sw); 
<token> "failed to register USB role switch: %d", <answer> dev_err(&port->dev, 
return <token> <answer> err; 
<token> tegra_xusb_usb_phy_work); <answer> INIT_WORK(&port->usb_phy_work, 
usb_role_switch_set_drvdata(port->usb_role_sw, <token> <answer> port); 
port->usb_phy.otg <token> devm_kzalloc(&port->dev, sizeof(struct usb_otg), <answer> = 
if <token> <answer> (!port->usb_phy.otg) 
<token> -ENOMEM; <answer> return 
lane <token> tegra_xusb_find_lane(port->padctl, "usb2", port->index); <answer> = 
port->usb_phy.dev = <token> <answer> &lane->pad->lanes[port->index]->dev; 
port->usb_phy.dev->driver <token> port->dev.driver; <answer> = 
<token> = &port->usb_phy; <answer> port->usb_phy.otg->usb_phy 
port->usb_phy.otg->set_peripheral = <token> <answer> tegra_xusb_set_peripheral; 
port->usb_phy.otg->set_host = <token> <answer> tegra_xusb_set_host; 
<token> = usb_add_phy_dev(&port->usb_phy); <answer> err 
<token> (err < 0) { <answer> if 
dev_err(&port->dev, "Failed to add USB <token> %d\n", err); <answer> PHY: 
return <token> <answer> err; 
np = <token> "usb2", index); <answer> tegra_xusb_find_port_node(padctl, 
if <token> || !of_device_is_available(np)) <answer> (!np 
<token> out; <answer> goto 
<token> = kzalloc(sizeof(*usb2), GFP_KERNEL); <answer> usb2 
<token> (!usb2) { <answer> if 
err = <token> <answer> -ENOMEM; 
<token> out; <answer> goto 
<token> = tegra_xusb_port_init(&usb2->base, padctl, np, "usb2", index); <answer> err 
if <token> < 0) <answer> (err 
<token> out; <answer> goto 
usb2->base.ops = <token> <answer> padctl->soc->ports.usb2.ops; 
usb2->base.lane <token> usb2->base.ops->map(&usb2->base); <answer> = 
if (IS_ERR(usb2->base.lane)) <token> <answer> { 
err = <token> <answer> PTR_ERR(usb2->base.lane); 
goto <token> <answer> out; 
err = <token> <answer> tegra_xusb_usb2_port_parse_dt(usb2); 
if (err < 0) <token> <answer> { 
goto <token> <answer> out; 
<token> &padctl->ports); <answer> list_add_tail(&usb2->base.list, 
<token> err; <answer> return 
void tegra_xusb_usb2_port_release(struct <token> *port) <answer> tegra_xusb_port 
struct tegra_xusb_usb2_port *usb2 <token> to_usb2_port(port); <answer> = 
void tegra_xusb_usb2_port_remove(struct tegra_xusb_port <token> <answer> *port) 
struct <token> *usb2 = to_usb2_port(port); <answer> tegra_xusb_usb2_port 
static int tegra_xusb_ulpi_port_parse_dt(struct tegra_xusb_ulpi_port <token> <answer> *ulpi) 
struct tegra_xusb_port *port <token> &ulpi->base; <answer> = 
struct <token> *np = port->dev.of_node; <answer> device_node 
ulpi->internal <token> of_property_read_bool(np, "nvidia,internal"); <answer> = 
<token> 0; <answer> return 
static int tegra_xusb_add_ulpi_port(struct tegra_xusb_padctl <token> <answer> *padctl, 
<token> int index) <answer> unsigned 
struct tegra_xusb_ulpi_port <token> <answer> *ulpi; 
struct device_node <token> <answer> *np; 
<token> err = 0; <answer> int 
np = tegra_xusb_find_port_node(padctl, "ulpi", <token> <answer> index); 
if (!np <token> !of_device_is_available(np)) <answer> || 
<token> out; <answer> goto 
ulpi <token> kzalloc(sizeof(*ulpi), GFP_KERNEL); <answer> = 
if (!ulpi) <token> <answer> { 
err = <token> <answer> -ENOMEM; 
goto <token> <answer> out; 
err = <token> padctl, np, "ulpi", index); <answer> tegra_xusb_port_init(&ulpi->base, 
if <token> < 0) <answer> (err 
goto <token> <answer> out; 
<token> = padctl->soc->ports.ulpi.ops; <answer> ulpi->base.ops 
ulpi->base.lane <token> ulpi->base.ops->map(&ulpi->base); <answer> = 
<token> (IS_ERR(ulpi->base.lane)) { <answer> if 
<token> = PTR_ERR(ulpi->base.lane); <answer> err 
goto <token> <answer> out; 
err = <token> <answer> tegra_xusb_ulpi_port_parse_dt(ulpi); 
<token> (err < 0) { <answer> if 
<token> out; <answer> goto 
list_add_tail(&ulpi->base.list, <token> <answer> &padctl->ports); 
<token> err; <answer> return 
void tegra_xusb_ulpi_port_release(struct tegra_xusb_port <token> <answer> *port) 
struct <token> *ulpi = to_ulpi_port(port); <answer> tegra_xusb_ulpi_port 
<token> int tegra_xusb_hsic_port_parse_dt(struct tegra_xusb_hsic_port *hsic) <answer> static 
np = <token> "usb3", index); <answer> tegra_xusb_find_port_node(padctl, 
if (!np || <token> <answer> !of_device_is_available(np)) 
<token> out; <answer> goto 
<token> = kzalloc(sizeof(*usb3), GFP_KERNEL); <answer> usb3 
if <token> { <answer> (!usb3) 
err <token> -ENOMEM; <answer> = 
goto <token> <answer> out; 
err = tegra_xusb_port_init(&usb3->base, padctl, np, <token> index); <answer> "usb3", 
if (err < <token> <answer> 0) 
<token> out; <answer> goto 
<token> = padctl->soc->ports.usb3.ops; <answer> usb3->base.ops 
<token> = usb3->base.ops->map(&usb3->base); <answer> usb3->base.lane 
if (IS_ERR(usb3->base.lane)) <token> <answer> { 
err = <token> <answer> PTR_ERR(usb3->base.lane); 
goto <token> <answer> out; 
<token> = tegra_xusb_usb3_port_parse_dt(usb3); <answer> err 
if (err <token> 0) { <answer> < 
goto <token> <answer> out; 
<token> &padctl->ports); <answer> list_add_tail(&usb3->base.list, 
return <token> <answer> err; 
<token> tegra_xusb_usb3_port_release(struct tegra_xusb_port *port) <answer> void 
struct <token> *usb3 = to_usb3_port(port); <answer> tegra_xusb_usb3_port 
static void __tegra_xusb_remove_ports(struct <token> *padctl) <answer> tegra_xusb_padctl 
struct tegra_xusb_port *port, <token> <answer> *tmp; 
<token> tmp, &padctl->ports, list) { <answer> list_for_each_entry_safe_reverse(port, 
static int tegra_xusb_find_unused_usb3_port(struct <token> *padctl) <answer> tegra_xusb_padctl 
struct device_node <token> <answer> *np; 
<token> int i; <answer> unsigned 
for (i = 0; <token> < padctl->soc->ports.usb3.count; i++) { <answer> i 
<token> = tegra_xusb_find_port_node(padctl, "usb3", i); <answer> np 
if (!np <token> !of_device_is_available(np)) <answer> || 
<token> i; <answer> return 
<token> -ENODEV; <answer> return 
static bool <token> tegra_xusb_usb2_port *usb2) <answer> tegra_xusb_port_is_companion(struct 
unsigned <token> i; <answer> int 
<token> tegra_xusb_usb3_port *usb3; <answer> struct 
struct tegra_xusb_padctl <token> = usb2->base.padctl; <answer> *padctl 
for (i = 0; i <token> padctl->soc->ports.usb3.count; i++) { <answer> < 
usb3 <token> tegra_xusb_find_usb3_port(padctl, i); <answer> = 
if (usb3 && usb3->port == <token> <answer> usb2->base.index) 
<token> true; <answer> return 
<token> false; <answer> return 
<token> int tegra_xusb_update_usb3_fake_port(struct tegra_xusb_usb2_port *usb2) <answer> static 
<token> fake; <answer> int 
<token> = of_find_device_by_node(np); <answer> pdev 
<token> (!pdev) { <answer> if 
<token> ERR_PTR(-ENODEV); <answer> return 
<token> = platform_get_drvdata(pdev); <answer> padctl 
<token> (!padctl) { <answer> if 
<token> ERR_PTR(-EPROBE_DEFER); <answer> return 
<token> padctl; <answer> return 
void tegra_xusb_padctl_put(struct tegra_xusb_padctl <token> <answer> *padctl) 
<token> (padctl) <answer> if 
int tegra_xusb_padctl_usb3_save_context(struct <token> *padctl, <answer> tegra_xusb_padctl 
<token> int port) <answer> unsigned 
if <token> <answer> (padctl->soc->ops->usb3_save_context) 
return <token> port); <answer> padctl->soc->ops->usb3_save_context(padctl, 
return <token> <answer> -ENOSYS; 
int tegra_xusb_padctl_hsic_set_idle(struct tegra_xusb_padctl <token> <answer> *padctl, 
unsigned int port, <token> idle) <answer> bool 
if <token> <answer> (padctl->soc->ops->hsic_set_idle) 
return <token> port, idle); <answer> padctl->soc->ops->hsic_set_idle(padctl, 
return <token> <answer> -ENOSYS; 
int tegra_xusb_padctl_enable_phy_sleepwalk(struct tegra_xusb_padctl *padctl, struct <token> *phy, <answer> phy 
enum usb_device_speed <token> <answer> speed) 
struct tegra_xusb_lane *lane <token> phy_get_drvdata(phy); <answer> = 
if <token> <answer> (lane->pad->ops->enable_phy_sleepwalk) 
return lane->pad->ops->enable_phy_sleepwalk(lane, <token> <answer> speed); 
<token> -EOPNOTSUPP; <answer> return 
int tegra_xusb_padctl_disable_phy_sleepwalk(struct tegra_xusb_padctl *padctl, <token> phy *phy) <answer> struct 
struct <token> *lane = phy_get_drvdata(phy); <answer> tegra_xusb_lane 
if <token> <answer> (lane->pad->ops->disable_phy_sleepwalk) 
<token> lane->pad->ops->disable_phy_sleepwalk(lane); <answer> return 
<token> -EOPNOTSUPP; <answer> return 
int tegra_xusb_padctl_enable_phy_wake(struct tegra_xusb_padctl <token> struct phy *phy) <answer> *padctl, 
struct <token> *lane = phy_get_drvdata(phy); <answer> tegra_xusb_lane 
<token> (lane->pad->ops->enable_phy_wake) <answer> if 
<token> lane->pad->ops->enable_phy_wake(lane); <answer> return 
<token> -EOPNOTSUPP; <answer> return 
int tegra_xusb_padctl_disable_phy_wake(struct tegra_xusb_padctl *padctl, struct <token> *phy) <answer> phy 
struct tegra_xusb_lane <token> = phy_get_drvdata(phy); <answer> *lane 
<token> (lane->pad->ops->disable_phy_wake) <answer> if 
return <token> <answer> lane->pad->ops->disable_phy_wake(lane); 
return <token> <answer> -EOPNOTSUPP; 
<token> tegra_xusb_padctl_remote_wake_detected(struct tegra_xusb_padctl *padctl, struct phy *phy) <answer> bool 
struct tegra_xusb_lane <token> = phy_get_drvdata(phy); <answer> *lane 
<token> (lane->pad->ops->remote_wake_detected) <answer> if 
<token> lane->pad->ops->remote_wake_detected(lane); <answer> return 
<token> false; <answer> return 
<token> tegra_xusb_padctl_usb3_set_lfps_detect(struct tegra_xusb_padctl *padctl, <answer> int 
<token> int port, bool enable) <answer> unsigned 
<token> (padctl->soc->ops->usb3_set_lfps_detect) <answer> if 
return <token> port, <answer> padctl->soc->ops->usb3_set_lfps_detect(padctl, 
return <token> <answer> -ENOSYS; 
int <token> tegra_xusb_padctl *padctl, <answer> tegra_xusb_padctl_set_vbus_override(struct 
<token> val) <answer> bool 
<token> (padctl->soc->ops->vbus_override) <answer> if 
return <token> val); <answer> padctl->soc->ops->vbus_override(padctl, 
<token> -ENOTSUPP; <answer> return 
int <token> phy *phy) <answer> tegra_phy_xusb_utmi_port_reset(struct 
struct <token> *lane = phy_get_drvdata(phy); <answer> tegra_xusb_lane 
struct tegra_xusb_padctl *padctl = <token> <answer> lane->pad->padctl; 
if <token> <answer> (padctl->soc->ops->utmi_port_reset) 
<token> padctl->soc->ops->utmi_port_reset(phy); <answer> return 
return <token> <answer> -ENOTSUPP; 
void <token> phy *phy) <answer> tegra_phy_xusb_utmi_pad_power_on(struct 
<token> tegra_xusb_lane *lane; <answer> struct 
struct tegra_xusb_padctl <token> <answer> *padctl; 
if <token> <answer> (!phy) 
lane = <token> <answer> phy_get_drvdata(phy); 
padctl <token> lane->pad->padctl; <answer> = 
if <token> <answer> (padctl->soc->ops->utmi_pad_power_on) 
<token> tegra_phy_xusb_utmi_pad_power_down(struct phy *phy) <answer> void 
struct <token> *lane; <answer> tegra_xusb_lane 
struct <token> *padctl; <answer> tegra_xusb_padctl 
if <token> <answer> (!phy) 
lane = <token> <answer> phy_get_drvdata(phy); 
padctl <token> lane->pad->padctl; <answer> = 
<token> (padctl->soc->ops->utmi_pad_power_down) <answer> if 
int <token> tegra_xusb_padctl *padctl, <answer> tegra_xusb_padctl_get_usb3_companion(struct 
unsigned int <token> <answer> port) 
struct <token> *usb2; <answer> tegra_xusb_usb2_port 
<token> tegra_xusb_usb3_port *usb3; <answer> struct 
<token> i; <answer> int 
usb2 = tegra_xusb_find_usb2_port(padctl, <token> <answer> port); 
if <token> <answer> (!usb2) 
return <token> <answer> -EINVAL; 
for (i = 0; i < padctl->soc->ports.usb3.count; <token> { <answer> i++) 
<token> = tegra_xusb_find_usb3_port(padctl, i); <answer> usb3 
if <token> && usb3->port == usb2->base.index) <answer> (usb3 
return <token> <answer> usb3->base.index; 
<token> -ENODEV; <answer> return 
int tegra_xusb_padctl_get_port_number(struct <token> *phy) <answer> phy 
struct tegra_xusb_lane <token> <answer> *lane; 
<token> (!phy) <answer> if 
<token> -ENODEV; <answer> return 
<token> = phy_get_drvdata(phy); <answer> lane 
return <token> <answer> lane->index; 
<token> Reding <treding@nvidia.com>"); <answer> MODULE_AUTHOR("Thierry 
MODULE_DESCRIPTION("Tegra XUSB Pad Controller <token> <answer> driver"); 
MODULE_LICENSE("GPL <token> <answer> v2"); 
<token> "hw_translate_dce120.h" <answer> #include 
<token> "dm_services.h" <answer> #include 
#include <token> <answer> "include/gpio_types.h" 
<token> "../hw_translate.h" <answer> #include 
<token> "dce/dce_12_0_offset.h" <answer> #include 
<token> "dce/dce_12_0_sh_mask.h" <answer> #include 
<token> "soc15_hw_ip.h" <answer> #include 
<token> "vega10_ip_offset.h" <answer> #include 
#define BASE_INNER(seg) <token> <answer> \ 
DCE_BASE__INST0_SEG ## <token> <answer> seg 
<token> bool offset_to_id( <answer> static 
<token> offset, <answer> uint32_t 
uint32_t <token> <answer> mask, 
<token> gpio_id *id, <answer> enum 
<token> *en) <answer> uint32_t 
switch (offset) <token> <answer> { 
<token> REG(DC_GPIO_DDC1_A): <answer> case 
<token> = GPIO_DDC_LINE_DDC1; <answer> *en 
<token> true; <answer> return 
case <token> <answer> REG(DC_GPIO_DDC2_A): 
<token> = GPIO_DDC_LINE_DDC2; <answer> *en 
<token> true; <answer> return 
case <token> <answer> REG(DC_GPIO_DDC3_A): 
*en <token> GPIO_DDC_LINE_DDC3; <answer> = 
return <token> <answer> true; 
<token> REG(DC_GPIO_DDC4_A): <answer> case 
*en = <token> <answer> GPIO_DDC_LINE_DDC4; 
return <token> <answer> true; 
case <token> <answer> REG(DC_GPIO_DDC5_A): 
*en = <token> <answer> GPIO_DDC_LINE_DDC5; 
<token> true; <answer> return 
case <token> <answer> REG(DC_GPIO_DDC6_A): 
*en = <token> <answer> GPIO_DDC_LINE_DDC6; 
return <token> <answer> true; 
case <token> <answer> REG(DC_GPIO_DDCVGA_A): 
<token> = GPIO_DDC_LINE_DDC_VGA; <answer> *en 
return <token> <answer> true; 
void <token> hw_translate *tr) <answer> dal_hw_translate_dce120_init(struct 
<token> = &funcs; <answer> tr->funcs 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/if_ether.h> 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/dma-mapping.h> 
<token> <asm/paccess.h> <answer> #include 
#include <token> <answer> <asm/sgi/ip22.h> 
#include <token> <answer> <asm/sgi/hpc3.h> 
#include <token> <answer> <asm/sgi/mc.h> 
#include <token> <answer> <asm/sgi/seeq.h> 
#include <token> <answer> <asm/sgi/wd.h> 
static <token> resource sgiwd93_0_resources[] = { <answer> struct 
<token> = "eth0 irq", <answer> .name 
.start = <token> <answer> SGI_WD93_0_IRQ, 
<token> = SGI_WD93_0_IRQ, <answer> .end 
<token> = IORESOURCE_IRQ <answer> .flags 
<token> struct sgiwd93_platform_data sgiwd93_0_pd = { <answer> static 
.unit = <token> <answer> 0, 
<token> = SGI_WD93_0_IRQ, <answer> .irq 
static <token> sgiwd93_0_dma_mask = DMA_BIT_MASK(32); <answer> u64 
static struct platform_device sgiwd93_0_device = <token> <answer> { 
.name = <token> <answer> "sgiwd93", 
.id <token> 0, <answer> = 
<token> = ARRAY_SIZE(sgiwd93_0_resources), <answer> .num_resources 
.resource <token> sgiwd93_0_resources, <answer> = 
.dev <token> { <answer> = 
.platform_data = <token> <answer> &sgiwd93_0_pd, 
.dma_mask = <token> <answer> &sgiwd93_0_dma_mask, 
<token> = DMA_BIT_MASK(32), <answer> .coherent_dma_mask 
static struct resource sgiwd93_1_resources[] = <token> <answer> { 
.name = <token> irq", <answer> "eth0 
.start = <token> <answer> SGI_WD93_1_IRQ, 
.end <token> SGI_WD93_1_IRQ, <answer> = 
<token> = IORESOURCE_IRQ <answer> .flags 
static struct sgiwd93_platform_data sgiwd93_1_pd = <token> <answer> { 
<token> = 1, <answer> .unit 
.irq <token> SGI_WD93_1_IRQ, <answer> = 
<token> u64 sgiwd93_1_dma_mask = DMA_BIT_MASK(32); <answer> static 
static <token> platform_device sgiwd93_1_device = { <answer> struct 
.name <token> "sgiwd93", <answer> = 
.id <token> 1, <answer> = 
<token> = ARRAY_SIZE(sgiwd93_1_resources), <answer> .num_resources 
<token> = sgiwd93_1_resources, <answer> .resource 
.dev = <token> <answer> { 
<token> = &sgiwd93_1_pd, <answer> .platform_data 
<token> = &sgiwd93_1_dma_mask, <answer> .dma_mask 
<token> = DMA_BIT_MASK(32), <answer> .coherent_dma_mask 
<token> int __init sgiwd93_devinit(void) <answer> static 
int <token> <answer> res; 
<token> = &hpc3c0->scsi_chan0; <answer> sgiwd93_0_pd.hregs 
<token> = (unsigned char *) hpc3c0->scsi0_ext; <answer> sgiwd93_0_pd.wdregs 
res = <token> <answer> platform_device_register(&sgiwd93_0_device); 
if <token> <answer> (res) 
<token> res; <answer> return 
<token> (!ip22_is_fullhouse()) <answer> if 
<token> 0; <answer> return 
sgiwd93_1_pd.hregs = <token> <answer> &hpc3c0->scsi_chan1; 
sgiwd93_1_pd.wdregs <token> (unsigned char *) hpc3c0->scsi1_ext; <answer> = 
return <token> <answer> platform_device_register(&sgiwd93_1_device); 
static struct resource <token> = { <answer> sgiseeq_0_resources[] 
.name <token> "eth0 irq", <answer> = 
<token> = SGI_ENET_IRQ, <answer> .start 
.end = <token> <answer> SGI_ENET_IRQ, 
<token> = IORESOURCE_IRQ <answer> .flags 
static <token> sgiseeq_platform_data eth0_pd; <answer> struct 
static u64 sgiseeq_dma_mask = <token> <answer> DMA_BIT_MASK(32); 
static struct <token> eth0_device = { <answer> platform_device 
<token> = "sgiseeq", <answer> .name 
<token> = 0, <answer> .id 
.num_resources <token> ARRAY_SIZE(sgiseeq_0_resources), <answer> = 
.resource <token> sgiseeq_0_resources, <answer> = 
.dev = <token> <answer> { 
.platform_data = <token> <answer> &eth0_pd, 
<token> = &sgiseeq_dma_mask, <answer> .dma_mask 
.coherent_dma_mask = <token> <answer> DMA_BIT_MASK(32), 
static struct resource sgiseeq_1_resources[] = <token> <answer> { 
<token> = "eth1 irq", <answer> .name 
.start <token> SGI_GIO_0_IRQ, <answer> = 
<token> = SGI_GIO_0_IRQ, <answer> .end 
.flags <token> IORESOURCE_IRQ <answer> = 
static <token> sgiseeq_platform_data eth1_pd; <answer> struct 
static struct platform_device eth1_device = <token> <answer> { 
.name <token> "sgiseeq", <answer> = 
<token> = 1, <answer> .id 
<token> = ARRAY_SIZE(sgiseeq_1_resources), <answer> .num_resources 
.resource = <token> <answer> sgiseeq_1_resources, 
.dev = <token> <answer> { 
<token> = &eth1_pd, <answer> .platform_data 
<token> int __init sgiseeq_devinit(void) <answer> static 
unsigned int pbdma <token> <answer> __maybe_unused; 
int res, <token> <answer> i; 
eth0_pd.hpc = <token> <answer> hpc3c0; 
eth0_pd.irq <token> SGI_ENET_IRQ; <answer> = 
<token> EADDR_NVOFS 250 <answer> #define 
for (i = 0; i < 3; <token> { <answer> i++) 
unsigned short tmp = ip22_nvram_read(EADDR_NVOFS / 2 <token> i); <answer> + 
eth0_pd.mac[2 * <token> = tmp >> 8; <answer> i] 
eth0_pd.mac[2 * i + 1] = <token> & 0xff; <answer> tmp 
res = <token> <answer> platform_device_register(&eth0_device); 
<token> (res) <answer> if 
<token> res; <answer> return 
#include <token> <answer> <asm/unaligned.h> 
<token> <linux/delay.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/spi/spi.h> 
<token> <linux/platform_data/b53.h> <answer> #include 
#include <token> <answer> "b53_priv.h" 
#define <token> 0xf0 <answer> B53_SPI_DATA 
<token> B53_SPI_STATUS 0xfe <answer> #define 
#define <token> BIT(7) <answer> B53_SPI_CMD_SPIF 
#define B53_SPI_CMD_RACK <token> <answer> BIT(5) 
<token> B53_SPI_CMD_READ 0x00 <answer> #define 
#define <token> 0x01 <answer> B53_SPI_CMD_WRITE 
<token> B53_SPI_CMD_NORMAL 0x60 <answer> #define 
<token> B53_SPI_CMD_FAST 0x10 <answer> #define 
#define B53_SPI_PAGE_SELECT <token> <answer> 0xff 
static inline int b53_spi_read_reg(struct <token> *spi, u8 reg, u8 *val, <answer> spi_device 
unsigned <token> len) <answer> int 
<token> txbuf[2]; <answer> u8 
txbuf[0] = B53_SPI_CMD_NORMAL <token> B53_SPI_CMD_READ; <answer> | 
txbuf[1] <token> reg; <answer> = 
return spi_write_then_read(spi, <token> 2, val, len); <answer> txbuf, 
static inline int b53_spi_clear_status(struct spi_device <token> <answer> *spi) 
unsigned <token> i; <answer> int 
<token> rxbuf; <answer> u8 
<token> ret; <answer> int 
for (i <token> 0; i < 10; i++) { <answer> = 
ret = b53_spi_read_reg(spi, B53_SPI_STATUS, &rxbuf, <token> <answer> 1); 
if <token> <answer> (ret) 
return <token> <answer> ret; 
if <token> & B53_SPI_CMD_SPIF)) <answer> (!(rxbuf 
if (i <token> 10) <answer> == 
return <token> <answer> -EIO; 
<token> 0; <answer> return 
static inline int <token> spi_device *spi, u8 page) <answer> b53_spi_set_page(struct 
u8 <token> <answer> txbuf[3]; 
<token> = B53_SPI_CMD_NORMAL | B53_SPI_CMD_WRITE; <answer> txbuf[0] 
<token> = B53_SPI_PAGE_SELECT; <answer> txbuf[1] 
<token> = page; <answer> txbuf[2] 
return <token> txbuf, sizeof(txbuf)); <answer> spi_write(spi, 
static inline int b53_prepare_reg_access(struct spi_device *spi, u8 <token> <answer> page) 
int ret = <token> <answer> b53_spi_clear_status(spi); 
if <token> <answer> (ret) 
<token> ret; <answer> return 
return <token> page); <answer> b53_spi_set_page(spi, 
static int b53_spi_prepare_reg_read(struct spi_device *spi, u8 <token> <answer> reg) 
<token> rxbuf; <answer> u8 
int <token> <answer> retry_count; 
int <token> <answer> ret; 
ret = <token> reg, &rxbuf, 1); <answer> b53_spi_read_reg(spi, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
for (retry_count = 0; retry_count < 10; retry_count++) <token> <answer> { 
ret = <token> B53_SPI_STATUS, &rxbuf, 1); <answer> b53_spi_read_reg(spi, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> (rxbuf & B53_SPI_CMD_RACK) <answer> if 
if (retry_count <token> 10) <answer> == 
return <token> <answer> -EIO; 
<token> 0; <answer> return 
static int b53_spi_read(struct <token> *dev, u8 page, u8 reg, u8 *data, <answer> b53_device 
<token> int len) <answer> unsigned 
struct spi_device <token> = dev->priv; <answer> *spi 
<token> ret; <answer> int 
ret = <token> page); <answer> b53_prepare_reg_access(spi, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
ret <token> b53_spi_prepare_reg_read(spi, reg); <answer> = 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> b53_spi_read_reg(spi, B53_SPI_DATA, data, len); <answer> return 
static int b53_spi_read8(struct b53_device *dev, <token> page, u8 reg, u8 *val) <answer> u8 
return b53_spi_read(dev, page, reg, <token> 1); <answer> val, 
static int b53_spi_read16(struct b53_device *dev, u8 page, u8 reg, <token> *val) <answer> u16 
__le16 <token> <answer> value; 
<token> ret; <answer> int 
ret <token> b53_spi_read(dev, page, reg, (u8 *)&value, 2); <answer> = 
if <token> <answer> (!ret) 
<token> = le16_to_cpu(value); <answer> *val 
return <token> <answer> ret; 
static int b53_spi_read32(struct b53_device *dev, u8 page, u8 reg, <token> *val) <answer> u32 
<token> value; <answer> __le32 
<token> ret; <answer> int 
ret = b53_spi_read(dev, page, <token> (u8 *)&value, 4); <answer> reg, 
if <token> <answer> (!ret) 
*val <token> le32_to_cpu(value); <answer> = 
<token> ret; <answer> return 
static <token> b53_spi_read48(struct b53_device *dev, u8 page, u8 reg, u64 *val) <answer> int 
__le64 <token> <answer> value; 
int <token> <answer> ret; 
*val <token> 0; <answer> = 
ret <token> b53_spi_read(dev, page, reg, (u8 *)&value, 6); <answer> = 
<token> (!ret) <answer> if 
*val = <token> <answer> le64_to_cpu(value); 
return <token> <answer> ret; 
static int b53_spi_read64(struct b53_device *dev, u8 <token> u8 reg, u64 *val) <answer> page, 
__le64 <token> <answer> value; 
<token> ret; <answer> int 
ret = b53_spi_read(dev, page, reg, (u8 <token> 8); <answer> *)&value, 
if <token> <answer> (!ret) 
*val = <token> <answer> le64_to_cpu(value); 
<token> ret; <answer> return 
static int b53_spi_write8(struct b53_device <token> u8 page, u8 reg, u8 value) <answer> *dev, 
<token> spi_device *spi = dev->priv; <answer> struct 
int <token> <answer> ret; 
u8 <token> <answer> txbuf[3]; 
ret <token> b53_prepare_reg_access(spi, page); <answer> = 
<token> (ret) <answer> if 
return <token> <answer> ret; 
txbuf[0] <token> B53_SPI_CMD_NORMAL | B53_SPI_CMD_WRITE; <answer> = 
txbuf[1] <token> reg; <answer> = 
txbuf[2] <token> value; <answer> = 
return spi_write(spi, <token> sizeof(txbuf)); <answer> txbuf, 
static int <token> b53_device *dev, u8 page, u8 reg, u16 value) <answer> b53_spi_write16(struct 
<token> spi_device *spi = dev->priv; <answer> struct 
<token> ret; <answer> int 
<token> txbuf[4]; <answer> u8 
ret = <token> page); <answer> b53_prepare_reg_access(spi, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
<token> = B53_SPI_CMD_NORMAL | B53_SPI_CMD_WRITE; <answer> txbuf[0] 
<token> = reg; <answer> txbuf[1] 
put_unaligned_le16(value, <token> <answer> &txbuf[2]); 
return <token> txbuf, sizeof(txbuf)); <answer> spi_write(spi, 
static int b53_spi_write32(struct b53_device *dev, <token> page, u8 reg, u32 value) <answer> u8 
struct <token> *spi = dev->priv; <answer> spi_device 
int <token> <answer> ret; 
<token> txbuf[6]; <answer> u8 
<token> = b53_prepare_reg_access(spi, page); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
txbuf[0] = B53_SPI_CMD_NORMAL | <token> <answer> B53_SPI_CMD_WRITE; 
txbuf[1] <token> reg; <answer> = 
<token> &txbuf[2]); <answer> put_unaligned_le32(value, 
return spi_write(spi, txbuf, <token> <answer> sizeof(txbuf)); 
static int b53_spi_write48(struct <token> *dev, u8 page, u8 reg, u64 value) <answer> b53_device 
struct <token> *spi = dev->priv; <answer> spi_device 
<token> ret; <answer> int 
<token> txbuf[10]; <answer> u8 
ret = <token> page); <answer> b53_prepare_reg_access(spi, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
txbuf[0] <token> B53_SPI_CMD_NORMAL | B53_SPI_CMD_WRITE; <answer> = 
txbuf[1] <token> reg; <answer> = 
put_unaligned_le64(value, <token> <answer> &txbuf[2]); 
return spi_write(spi, txbuf, sizeof(txbuf) <token> 2); <answer> - 
<token> int b53_spi_write64(struct b53_device *dev, u8 page, u8 reg, u64 value) <answer> static 
struct spi_device *spi = <token> <answer> dev->priv; 
<token> ret; <answer> int 
u8 <token> <answer> txbuf[10]; 
ret <token> b53_prepare_reg_access(spi, page); <answer> = 
if <token> <answer> (ret) 
<token> ret; <answer> return 
txbuf[0] = B53_SPI_CMD_NORMAL <token> B53_SPI_CMD_WRITE; <answer> | 
txbuf[1] <token> reg; <answer> = 
<token> &txbuf[2]); <answer> put_unaligned_le64(value, 
return <token> txbuf, sizeof(txbuf)); <answer> spi_write(spi, 
static const struct b53_io_ops <token> = { <answer> b53_spi_ops 
.read8 = <token> <answer> b53_spi_read8, 
.read16 = <token> <answer> b53_spi_read16, 
.read32 <token> b53_spi_read32, <answer> = 
.read48 = <token> <answer> b53_spi_read48, 
<token> = b53_spi_read64, <answer> .read64 
.write8 <token> b53_spi_write8, <answer> = 
<token> = b53_spi_write16, <answer> .write16 
.write32 = <token> <answer> b53_spi_write32, 
<token> = b53_spi_write48, <answer> .write48 
.write64 = <token> <answer> b53_spi_write64, 
static <token> b53_spi_probe(struct spi_device *spi) <answer> int 
struct <token> *dev; <answer> b53_device 
int <token> <answer> ret; 
dev = b53_switch_alloc(&spi->dev, <token> spi); <answer> &b53_spi_ops, 
if <token> <answer> (!dev) 
<token> -ENOMEM; <answer> return 
<token> (spi->dev.platform_data) <answer> if 
<token> = spi->dev.platform_data; <answer> dev->pdata 
ret = <token> <answer> b53_switch_register(dev); 
<token> (ret) <answer> if 
return <token> <answer> ret; 
<token> dev); <answer> spi_set_drvdata(spi, 
return <token> <answer> 0; 
static void b53_spi_remove(struct spi_device <token> <answer> *spi) 
struct <token> *dev = spi_get_drvdata(spi); <answer> b53_device 
<token> (dev) <answer> if 
static void <token> spi_device *spi) <answer> b53_spi_shutdown(struct 
struct b53_device *dev <token> spi_get_drvdata(spi); <answer> = 
<token> (dev) <answer> if 
<token> NULL); <answer> spi_set_drvdata(spi, 
static const struct of_device_id b53_spi_of_match[] <token> { <answer> = 
{ .compatible = "brcm,bcm5325" <token> <answer> }, 
{ .compatible = <token> }, <answer> "brcm,bcm5365" 
{ .compatible <token> "brcm,bcm5395" }, <answer> = 
{ <token> = "brcm,bcm5397" }, <answer> .compatible 
{ .compatible = "brcm,bcm5398" <token> <answer> }, 
{ .compatible <token> "brcm,bcm53115" }, <answer> = 
<token> .compatible = "brcm,bcm53125" }, <answer> { 
{ <token> = "brcm,bcm53128" }, <answer> .compatible 
<token> <linux/device.h> <answer> #include 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/io.h> 
<token> <linux/ioport.h> <answer> #include 
#include <token> <answer> <linux/kexec.h> 
#include <token> <answer> <linux/mod_devicetable.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/types.h> 
<token> "pvpanic.h" <answer> #include 
<token> Tao <hutao@cn.fujitsu.com>"); <answer> MODULE_AUTHOR("Hu 
MODULE_DESCRIPTION("pvpanic-mmio <token> driver"); <answer> device 
static int pvpanic_mmio_probe(struct <token> *pdev) <answer> platform_device 
struct <token> *dev = &pdev->dev; <answer> device 
struct <token> *res; <answer> resource 
void __iomem <token> <answer> *base; 
res = platform_get_mem_or_io(pdev, <token> <answer> 0); 
<token> (!res) <answer> if 
<token> -EINVAL; <answer> return 
<token> (resource_type(res)) { <answer> switch 
case <token> <answer> IORESOURCE_IO: 
base <token> devm_ioport_map(dev, res->start, resource_size(res)); <answer> = 
<token> (!base) <answer> if 
<token> -ENOMEM; <answer> return 
<token> IORESOURCE_MEM: <answer> case 
<token> = devm_ioremap_resource(dev, res); <answer> base 
if <token> <answer> (IS_ERR(base)) 
return <token> <answer> PTR_ERR(base); 
return <token> <answer> -EINVAL; 
<token> devm_pvpanic_probe(dev, base); <answer> return 
<token> const struct of_device_id pvpanic_mmio_match[] = { <answer> static 
{ .compatible = "qemu,pvpanic-mmio", <token> <answer> }, 
<token> pvpanic_mmio_match); <answer> MODULE_DEVICE_TABLE(of, 
static const struct acpi_device_id <token> = { <answer> pvpanic_device_ids[] 
{ "QEMU0001", <token> }, <answer> 0 
{ "", <token> } <answer> 0 
MODULE_DEVICE_TABLE(acpi, <token> <answer> pvpanic_device_ids); 
static struct platform_driver pvpanic_mmio_driver = <token> <answer> { 
.driver = <token> <answer> { 
.name <token> "pvpanic-mmio", <answer> = 
.of_match_table <token> pvpanic_mmio_match, <answer> = 
.acpi_match_table <token> pvpanic_device_ids, <answer> = 
.dev_groups <token> pvpanic_dev_groups, <answer> = 
.probe <token> pvpanic_mmio_probe, <answer> = 
err = pds_vfio_client_adminq_cmd(pds_vfio, &cmd, <token> true); <answer> &comp, 
<token> (err) { <answer> if 
dev_err(dev, "vf%u: <token> failed: %pe\n", pds_vfio->vf_id, <answer> Suspend 
return <token> <answer> err; 
return pds_vfio_suspend_wait_device_cmd(pds_vfio, <token> <answer> type); 
int pds_vfio_resume_device_cmd(struct pds_vfio_pci_device <token> u8 type) <answer> *pds_vfio, 
union <token> cmd = { <answer> pds_core_adminq_cmd 
<token> = { <answer> .lm_resume 
.opcode = <token> <answer> PDS_LM_CMD_RESUME, 
.vf_id = <token> <answer> cpu_to_le16(pds_vfio->vf_id), 
.type <token> type, <answer> = 
struct <token> *dev = pds_vfio_to_dev(pds_vfio); <answer> device 
union <token> comp = {}; <answer> pds_core_adminq_comp 
dev_dbg(dev, <token> Resume device\n", pds_vfio->vf_id); <answer> "vf%u: 
return pds_vfio_client_adminq_cmd(pds_vfio, &cmd, &comp, <token> <answer> true); 
int pds_vfio_get_lm_state_size_cmd(struct <token> *pds_vfio, u64 *size) <answer> pds_vfio_pci_device 
<token> pds_core_adminq_cmd cmd = { <answer> union 
.lm_state_size <token> { <answer> = 
.opcode <token> PDS_LM_CMD_STATE_SIZE, <answer> = 
.vf_id = <token> <answer> cpu_to_le16(pds_vfio->vf_id), 
struct device *dev = <token> <answer> pds_vfio_to_dev(pds_vfio); 
union pds_core_adminq_comp comp = <token> <answer> {}; 
<token> err; <answer> int 
<token> "vf%u: Get migration status\n", pds_vfio->vf_id); <answer> dev_dbg(dev, 
err <token> pds_vfio_client_adminq_cmd(pds_vfio, &cmd, &comp, false); <answer> = 
if <token> <answer> (err) 
return <token> <answer> err; 
<token> = le64_to_cpu(comp.lm_state_size.size); <answer> *size 
return <token> <answer> 0; 
<token> int pds_vfio_dma_map_lm_file(struct device *dev, <answer> static 
enum <token> dir, <answer> dma_data_direction 
struct pds_vfio_lm_file <token> <answer> *lm_file) 
struct pds_lm_sg_elem *sgl, <token> <answer> *sge; 
struct <token> *sg; <answer> scatterlist 
<token> sgl_addr; <answer> dma_addr_t 
<token> sgl_size; <answer> size_t 
<token> err; <answer> int 
int <token> <answer> i; 
<token> (!lm_file) <answer> if 
return <token> <answer> -EINVAL; 
#include <token> <answer> <test_progs.h> 
<token> <network_helpers.h> <answer> #include 
<token> test_skb_helpers(void) <answer> void 
struct __sk_buff <token> = { <answer> skb 
.wire_len = <token> <answer> 100, 
.gso_segs = <token> <answer> 8, 
.gso_size <token> 10, <answer> = 
LIBBPF_OPTS(bpf_test_run_opts, <token> <answer> topts, 
.data_in <token> &pkt_v4, <answer> = 
.data_size_in = <token> <answer> sizeof(pkt_v4), 
.ctx_in = <token> <answer> &skb, 
.ctx_size_in = <token> <answer> sizeof(skb), 
<token> = &skb, <answer> .ctx_out 
.ctx_size_out = <token> <answer> sizeof(skb), 
struct <token> *obj; <answer> bpf_object 
<token> err, prog_fd; <answer> int 
<token> = bpf_prog_test_load("./test_skb_helpers.bpf.o", <answer> err 
BPF_PROG_TYPE_SCHED_CLS, &obj, <token> <answer> &prog_fd); 
if (!ASSERT_OK(err, <token> <answer> "load")) 
err <token> bpf_prog_test_run_opts(prog_fd, &topts); <answer> = 
ASSERT_OK(err, <token> <answer> "test_run"); 
<token> <linux/export.h> <answer> #include 
<token> <linux/lockref.h> <answer> #include 
<token> USE_CMPXCHG_LOCKREF <answer> #if 
#define CMPXCHG_LOOP(CODE, <token> do { \ <answer> SUCCESS) 
int retry = <token> \ <answer> 100; 
struct <token> old; \ <answer> lockref 
BUILD_BUG_ON(sizeof(old) <token> 8); \ <answer> != 
old.lock_count = READ_ONCE(lockref->lock_count); <token> <answer> \ 
while (likely(arch_spin_value_unlocked(old.lock.rlock.raw_lock))) <token> \ <answer> { 
struct <token> new = old; \ <answer> lockref 
CODE <token> <answer> \ 
<token> (likely(try_cmpxchg64_relaxed(&lockref->lock_count, \ <answer> if 
&old.lock_count, <token> <answer> \ 
new.lock_count))) { <token> <answer> \ 
<token> \ <answer> SUCCESS; 
} <token> <answer> \ 
if <token> \ <answer> (!--retry) 
<token> \ <answer> break; 
<token> \ <answer> } 
<token> while (0) <answer> } 
#define CMPXCHG_LOOP(CODE, SUCCESS) do { } while <token> <answer> (0) 
<token> lockref_get(struct lockref *lockref) <answer> void 
int <token> lockref *lockref) <answer> lockref_get_not_zero(struct 
<token> retval; <answer> int 
<token> (old.count <= 0) <answer> if 
<token> 0; <answer> return 
return <token> <answer> 1; 
retval = <token> <answer> 0; 
if (lockref->count > <token> { <answer> 0) 
retval = <token> <answer> 1; 
<token> retval; <answer> return 
int lockref_put_not_zero(struct lockref <token> <answer> *lockref) 
<token> retval; <answer> int 
if (old.count <token> 1) <answer> <= 
<token> 0; <answer> return 
return <token> <answer> 1; 
retval = <token> <answer> 0; 
if <token> > 1) { <answer> (lockref->count 
retval <token> 1; <answer> = 
<token> retval; <answer> return 
<token> lockref_put_return(struct lockref *lockref) <answer> int 
<token> (old.count <= 0) <answer> if 
<token> -1; <answer> return 
return <token> <answer> new.count; 
<token> -1; <answer> return 
int <token> lockref *lockref) <answer> lockref_put_or_lock(struct 
if (old.count <= <token> <answer> 1) 
return <token> <answer> 1; 
if (lockref->count <token> 1) <answer> <= 
return <token> <answer> 0; 
<token> 1; <answer> return 
void lockref_mark_dead(struct <token> *lockref) <answer> lockref 
<token> = -128; <answer> lockref->count 
int lockref_get_not_dead(struct <token> *lockref) <answer> lockref 
int <token> <answer> retval; 
if <token> < 0) <answer> (old.count 
return <token> <answer> 0; 
<token> 1; <answer> return 
retval <token> 0; <answer> = 
<token> (lockref->count >= 0) { <answer> if 
retval = <token> <answer> 1; 
return <token> <answer> retval; 
void qed_chain_free(struct qed_dev *cdev, struct <token> *chain) <answer> qed_chain 
switch (chain->mode) <token> <answer> { 
case <token> <answer> QED_CHAIN_MODE_NEXT_PTR: 
qed_chain_free_next_ptr(cdev, <token> <answer> chain); 
<token> QED_CHAIN_MODE_SINGLE: <answer> case 
qed_chain_free_single(cdev, <token> <answer> chain); 
<token> QED_CHAIN_MODE_PBL: <answer> case 
qed_chain_free_pbl(cdev, <token> <answer> chain); 
qed_chain_init_mem(chain, <token> 0); <answer> NULL, 
<token> int <answer> static 
qed_chain_alloc_sanity_check(struct qed_dev <token> <answer> *cdev, 
<token> struct qed_chain_init_params *params, <answer> const 
<token> page_cnt) <answer> u32 
<token> chain_size; <answer> u64 
chain_size = ELEMS_PER_PAGE(params->elem_size, <token> <answer> params->page_size); 
chain_size <token> page_cnt; <answer> *= 
<token> (!chain_size) <answer> if 
return <token> <answer> -EINVAL; 
switch (params->cnt_type) <token> <answer> { 
<token> QED_CHAIN_CNT_TYPE_U16: <answer> case 
if (chain_size > U16_MAX <token> 1) <answer> + 
<token> 0; <answer> return 
case <token> <answer> QED_CHAIN_CNT_TYPE_U32: 
<token> (chain_size > U32_MAX) <answer> if 
<token> 0; <answer> return 
return <token> <answer> -EINVAL; 
"The actual chain size (0x%llx) <token> larger than the maximal possible value\n", <answer> is 
<token> -EINVAL; <answer> return 
static int qed_chain_alloc_next_ptr(struct <token> *cdev, <answer> qed_dev 
struct <token> *chain) <answer> qed_chain 
struct device *dev <token> &cdev->pdev->dev; <answer> = 
void *virt, <token> = NULL; <answer> *virt_prev 
<token> phys; <answer> dma_addr_t 
u32 <token> <answer> i; 
for (i = 0; i <token> chain->page_cnt; i++) { <answer> < 
virt = dma_alloc_coherent(dev, chain->page_size, <token> <answer> &phys, 
<token> (!virt) <answer> if 
<token> -ENOMEM; <answer> return 
<token> (i == 0) { <answer> if 
qed_chain_init_mem(chain, virt, <token> <answer> phys); 
<token> else { <answer> } 
qed_chain_init_next_ptr_elem(chain, virt_prev, <token> <answer> virt, 
virt_prev <token> virt; <answer> = 
qed_chain_init_next_ptr_elem(chain, virt_prev, <token> <answer> chain->p_virt_addr, 
<token> 0; <answer> return 
static int qed_chain_alloc_single(struct qed_dev <token> <answer> *cdev, 
struct qed_chain <token> <answer> *chain) 
<token> phys; <answer> dma_addr_t 
void <token> <answer> *virt; 
<token> = dma_alloc_coherent(&cdev->pdev->dev, chain->page_size, <answer> virt 
<token> GFP_KERNEL); <answer> &phys, 
if <token> <answer> (!virt) 
return <token> <answer> -ENOMEM; 
<token> virt, phys); <answer> qed_chain_init_mem(chain, 
return <token> <answer> 0; 
<token> int qed_chain_alloc_pbl(struct qed_dev *cdev, struct qed_chain *chain) <answer> static 
struct device *dev = <token> <answer> &cdev->pdev->dev; 
<token> addr_tbl_entry *addr_tbl; <answer> struct 
<token> phys, pbl_phys; <answer> dma_addr_t 
__le64 <token> <answer> *pbl_virt; 
u32 page_cnt, <token> <answer> i; 
<token> size; <answer> size_t 
<token> *virt; <answer> void 
page_cnt <token> chain->page_cnt; <answer> = 
size <token> array_size(page_cnt, sizeof(*addr_tbl)); <answer> = 
if (unlikely(size == <token> <answer> SIZE_MAX)) 
return <token> <answer> -EOVERFLOW; 
addr_tbl = <token> <answer> vzalloc(size); 
<token> (!addr_tbl) <answer> if 
<token> -ENOMEM; <answer> return 
chain->pbl.pp_addr_tbl = <token> <answer> addr_tbl; 
if <token> { <answer> (chain->b_external_pbl) 
pbl_virt <token> chain->pbl_sp.table_virt; <answer> = 
<token> alloc_pages; <answer> goto 
<token> = array_size(page_cnt, sizeof(*pbl_virt)); <answer> size 
<token> (unlikely(size == SIZE_MAX)) <answer> if 
return <token> <answer> -EOVERFLOW; 
pbl_virt = dma_alloc_coherent(dev, <token> &pbl_phys, GFP_KERNEL); <answer> size, 
<token> (!pbl_virt) <answer> if 
return <token> <answer> -ENOMEM; 
chain->pbl_sp.table_virt <token> pbl_virt; <answer> = 
chain->pbl_sp.table_phys <token> pbl_phys; <answer> = 
chain->pbl_sp.table_size <token> size; <answer> = 
for (i = 0; <token> < page_cnt; i++) { <answer> i 
virt = dma_alloc_coherent(dev, chain->page_size, <token> <answer> &phys, 
if <token> <answer> (!virt) 
<token> -ENOMEM; <answer> return 
if (i == 0) <token> <answer> { 
<token> virt, phys); <answer> qed_chain_init_mem(chain, 
int <token> qed_dev *cdev, struct qed_chain *chain, <answer> qed_chain_alloc(struct 
<token> qed_chain_init_params *params) <answer> struct 
u32 <token> <answer> page_cnt; 
int <token> <answer> rc; 
if <token> <answer> (!params->page_size) 
<token> = QED_CHAIN_PAGE_SIZE; <answer> params->page_size 
<token> (params->mode == QED_CHAIN_MODE_SINGLE) <answer> if 
<token> = 1; <answer> page_cnt 
page_cnt = <token> <answer> QED_CHAIN_PAGE_CNT(params->num_elems, 
rc <token> qed_chain_alloc_sanity_check(cdev, params, page_cnt); <answer> = 
<token> (rc) { <answer> if 
"Cannot allocate <token> chain with the given arguments:\n"); <answer> a 
"[use_mode %d, mode %d, cnt_type %d, num_elems %d, elem_size %zu, <token> %u]\n", <answer> page_size 
params->intended_use, params->mode, <token> <answer> params->cnt_type, 
params->num_elems, <token> <answer> params->elem_size, 
<token> rc; <answer> return 
qed_chain_init(chain, params, <token> <answer> page_cnt); 
switch (params->mode) <token> <answer> { 
<token> QED_CHAIN_MODE_NEXT_PTR: <answer> case 
rc = <token> chain); <answer> qed_chain_alloc_next_ptr(cdev, 
<token> QED_CHAIN_MODE_SINGLE: <answer> case 
<token> = qed_chain_alloc_single(cdev, chain); <answer> rc 
case <token> <answer> QED_CHAIN_MODE_PBL: 
rc = qed_chain_alloc_pbl(cdev, <token> <answer> chain); 
return <token> <answer> -EINVAL; 
if <token> <answer> (!rc) 
<token> 0; <answer> return 
<token> chain); <answer> qed_chain_free(cdev, 
return <token> <answer> rc; 
#include <token> <answer> <linux/export.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/sched.h> 
<token> <linux/cred.h> <answer> #include 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> "../integrity.h" 
void __init add_to_platform_keyring(const char *source, <token> void *data, <answer> const 
<token> len) <answer> size_t 
<token> perm; <answer> key_perm_t 
int <token> <answer> rc; 
perm = (KEY_POS_ALL & ~KEY_POS_SETATTR) | <token> <answer> KEY_USR_VIEW; 
rc <token> integrity_load_cert(INTEGRITY_KEYRING_PLATFORM, source, data, len, <answer> = 
<token> (rc) <answer> if 
pr_info("Error <token> keys to platform keyring %s\n", source); <answer> adding 
static __init <token> platform_keyring_init(void) <answer> int 
int <token> <answer> rc; 
<token> = integrity_init_keyring(INTEGRITY_KEYRING_PLATFORM); <answer> rc 
<token> (rc) <answer> if 
<token> rc; <answer> return 
<token> Keyring initialized\n"); <answer> pr_notice("Platform 
<token> 0; <answer> return 
<token> <linux/stddef.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/errno.h> 
<token> <linux/reboot.h> <answer> #include 
#include <token> <answer> <linux/pci.h> 
#include <token> <answer> <linux/kdev_t.h> 
#include <token> <answer> <linux/major.h> 
<token> <linux/console.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
<token> <linux/seq_file.h> <answer> #include 
#include <token> <answer> <linux/initrd.h> 
<token> <linux/fsl_devices.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_address.h> <answer> #include 
#include <token> <answer> <linux/phy.h> 
<token> <linux/memblock.h> <answer> #include 
#include <token> <answer> <linux/fsl/guts.h> 
<token> <linux/atomic.h> <answer> #include 
<token> <asm/time.h> <answer> #include 
<token> <asm/io.h> <answer> #include 
<token> <asm/machdep.h> <answer> #include 
#include <token> <answer> <asm/pci-bridge.h> 
#include <token> <answer> <asm/irq.h> 
<token> <mm/mmu_decl.h> <answer> #include 
#include <token> <answer> <asm/udbg.h> 
#include <token> <answer> <sysdev/fsl_soc.h> 
#include <token> <answer> <sysdev/fsl_pci.h> 
<token> <soc/fsl/qe/qe.h> <answer> #include 
#include <token> <answer> <asm/mpic.h> 
#include <token> <answer> <asm/swiotlb.h> 
#include <token> <answer> "smp.h" 
<token> "mpc85xx.h" <answer> #include 
<token> IS_BUILTIN(CONFIG_PHYLIB) <answer> #if 
<token> MV88E1111_SCR 0x10 <answer> #define 
<token> MV88E1111_SCR_125CLK 0x0010 <answer> #define 
static int mpc8568_fixup_125_clock(struct <token> *phydev) <answer> phy_device 
int <token> <answer> scr; 
<token> err; <answer> int 
<token> CONFIG_QUICC_ENGINE <answer> #ifdef 
static void <token> mpc85xx_mds_reset_ucc_phys(void) <answer> __init 
struct <token> *np; <answer> device_node 
static u8 __iomem <token> <answer> *bcsr_regs; 
<token> BCSR7_UCC12_GETHnRST); <answer> clrbits8(&bcsr_regs[7], 
setbits8(&bcsr_regs[8], <token> <answer> BCSR8_UEM_MARVELL_RST); 
setbits8(&bcsr_regs[7], <token> <answer> BCSR7_UCC12_GETHnRST); 
<token> BCSR8_UEM_MARVELL_RST); <answer> clrbits8(&bcsr_regs[8], 
<token> "network", "ucc_geth") { <answer> for_each_compatible_node(np, 
<token> unsigned int *prop; <answer> const 
int <token> <answer> ucc_num; 
prop = of_get_property(np, <token> NULL); <answer> "cell-index", 
if <token> == NULL) <answer> (prop 
ucc_num = *prop - <token> <answer> 1; 
prop = of_get_property(np, "phy-connection-type", <token> <answer> NULL); 
<token> (prop == NULL) <answer> if 
<token> (strcmp("rtbi", (const char *)prop) == 0) <answer> if 
<token> + ucc_num], <answer> clrsetbits_8(&bcsr_regs[7 
BCSR_UCC_RGMII, <token> <answer> BCSR_UCC_RTBI); 
} <token> if (machine_is(p1021_mds)) { <answer> else 
#define BCSR11_ENET_MICRST (0x1 <token> 5) <answer> << 
setbits32(&guts->pmuxcr, MPC85xx_PMUXCR_QE(0) <token> <answer> | 
MPC85xx_PMUXCR_QE(3) <token> <answer> | 
<token> | <answer> MPC85xx_PMUXCR_QE(9) 
static void __init mpc85xx_mds_qe_init(void) { <token> <answer> } 
<token> <test_progs.h> <answer> #include 
<token> "cgroup_helpers.h" <answer> #include 
#include <token> <answer> "sockopt_inherit.skel.h" 
#define <token> 0xdeadbeef <answer> SOL_CUSTOM 
#define <token> 0 <answer> CUSTOM_INHERIT1 
<token> CUSTOM_INHERIT2 1 <answer> #define 
#define <token> 2 <answer> CUSTOM_LISTENER 
static int connect_to_server(int <token> <answer> server_fd) 
<token> sockaddr_storage addr; <answer> struct 
socklen_t len = <token> <answer> sizeof(addr); 
<token> fd; <answer> int 
fd = <token> SOCK_STREAM, 0); <answer> socket(AF_INET, 
if <token> < 0) { <answer> (fd 
log_err("Failed <token> create client socket"); <answer> to 
return <token> <answer> -1; 
<token> (getsockname(server_fd, (struct sockaddr *)&addr, &len)) { <answer> if 
log_err("Failed <token> get server addr"); <answer> to 
goto <token> <answer> out; 
if (connect(fd, <token> struct sockaddr *)&addr, len) < 0) { <answer> (const 
log_err("Fail <token> connect to server"); <answer> to 
goto <token> <answer> out; 
return <token> <answer> fd; 
return <token> <answer> -1; 
static int verify_sockopt(int fd, <token> optname, const char *msg, char expected) <answer> int 
<token> optlen = 1; <answer> socklen_t 
char <token> = 0; <answer> buf 
<token> err; <answer> int 
<token> = getsockopt(fd, SOL_CUSTOM, optname, &buf, &optlen); <answer> err 
<token> (err) { <answer> if 
<token> failed to call getsockopt", msg); <answer> log_err("%s: 
<token> 1; <answer> return 
printf("%s <token> got=0x%x ? expected=0x%x\n", msg, optname, buf, expected); <answer> %d: 
<token> (buf != expected) { <answer> if 
log_err("%s: unexpected getsockopt value %d != <token> msg, <answer> %d", 
<token> expected); <answer> buf, 
<token> 1; <answer> return 
<token> 0; <answer> return 
static <token> server_started_mtx = PTHREAD_MUTEX_INITIALIZER; <answer> pthread_mutex_t 
static pthread_cond_t server_started = <token> <answer> PTHREAD_COND_INITIALIZER; 
<token> void *server_thread(void *arg) <answer> static 
struct sockaddr_storage <token> <answer> addr; 
socklen_t len <token> sizeof(addr); <answer> = 
int fd <token> *(int *)arg; <answer> = 
int <token> <answer> client_fd; 
int err <token> 0; <answer> = 
err <token> listen(fd, 1); <answer> = 
if (!ASSERT_GE(err, 0, "listed <token> socket")) <answer> on 
<token> NULL; <answer> return 
err += verify_sockopt(fd, CUSTOM_INHERIT1, "listen", <token> <answer> 1); 
<token> += verify_sockopt(fd, CUSTOM_INHERIT2, "listen", 1); <answer> err 
err += verify_sockopt(fd, <token> "listen", 1); <answer> CUSTOM_LISTENER, 
client_fd = accept(fd, <token> sockaddr *)&addr, &len); <answer> (struct 
if (!ASSERT_GE(client_fd, <token> "accept client")) <answer> 0, 
<token> NULL; <answer> return 
err += verify_sockopt(client_fd, <token> "accept", 1); <answer> CUSTOM_INHERIT1, 
err += verify_sockopt(client_fd, <token> "accept", 1); <answer> CUSTOM_INHERIT2, 
err <token> verify_sockopt(client_fd, CUSTOM_LISTENER, "accept", 0); <answer> += 
return <token> *)(long)err; <answer> (void 
static int <token> <answer> start_server(void) 
struct sockaddr_in <token> = { <answer> addr 
.sin_family <token> AF_INET, <answer> = 
<token> = htonl(INADDR_LOOPBACK), <answer> .sin_addr.s_addr 
char <token> <answer> buf; 
<token> err; <answer> int 
int <token> <answer> fd; 
int <token> <answer> i; 
fd <token> socket(AF_INET, SOCK_STREAM, 0); <answer> = 
<token> (fd < 0) { <answer> if 
<token> to create server socket"); <answer> log_err("Failed 
<token> -1; <answer> return 
for (i <token> CUSTOM_INHERIT1; i <= CUSTOM_LISTENER; i++) { <answer> = 
<token> = 0x01; <answer> buf 
err = <token> SOL_CUSTOM, i, &buf, 1); <answer> setsockopt(fd, 
<token> (err) { <answer> if 
log_err("Failed to call setsockopt(%d)", <token> <answer> i); 
return <token> <answer> -1; 
if (bind(fd, (const struct sockaddr *)&addr, sizeof(addr)) < <token> { <answer> 0) 
log_err("Failed to <token> socket"); <answer> bind 
return <token> <answer> -1; 
<token> fd; <answer> return 
static void <token> cgroup_fd) <answer> run_test(int 
struct bpf_link *link_getsockopt <token> NULL; <answer> = 
struct bpf_link <token> = NULL; <answer> *link_setsockopt 
int server_fd = <token> client_fd; <answer> -1, 
<token> sockopt_inherit *obj; <answer> struct 
<token> *server_err; <answer> void 
<token> tid; <answer> pthread_t 
int <token> <answer> err; 
obj = <token> <answer> sockopt_inherit__open_and_load(); 
<token> (!ASSERT_OK_PTR(obj, "skel-load")) <answer> if 
obj->bss->page_size <token> sysconf(_SC_PAGESIZE); <answer> = 
<token> = bpf_program__attach_cgroup(obj->progs._getsockopt, <answer> link_getsockopt 
if (!ASSERT_OK_PTR(link_getsockopt, <token> <answer> "cg-attach-getsockopt")) 
<token> close_bpf_object; <answer> goto 
<token> = bpf_program__attach_cgroup(obj->progs._setsockopt, <answer> link_setsockopt 
if (!ASSERT_OK_PTR(link_setsockopt, <token> <answer> "cg-attach-setsockopt")) 
goto <token> <answer> close_bpf_object; 
server_fd = <token> <answer> start_server(); 
if (!ASSERT_GE(server_fd, <token> "start_server")) <answer> 0, 
<token> close_bpf_object; <answer> goto 
if <token> NULL, server_thread, <answer> (!ASSERT_OK(pthread_create(&tid, 
(void *)&server_fd), "pthread_create")) <token> <answer> { 
goto <token> <answer> close_server_fd; 
pthread_cond_wait(&server_started, <token> <answer> &server_started_mtx); 
client_fd <token> connect_to_server(server_fd); <answer> = 
if <token> 0, "connect_to_server")) <answer> (!ASSERT_GE(client_fd, 
<token> close_server_fd; <answer> goto 
ASSERT_OK(verify_sockopt(client_fd, CUSTOM_INHERIT1, <token> 0), "verify_sockopt1"); <answer> "connect", 
ASSERT_OK(verify_sockopt(client_fd, <token> "connect", 0), "verify_sockopt2"); <answer> CUSTOM_INHERIT2, 
ASSERT_OK(verify_sockopt(client_fd, CUSTOM_LISTENER, <token> 0), "verify_sockopt ener"); <answer> "connect", 
<token> &server_err); <answer> pthread_join(tid, 
err = <token> <answer> (int)(long)server_err; 
<token> "pthread_join retval"); <answer> ASSERT_OK(err, 
void <token> <answer> test_sockopt_inherit(void) 
<token> cgroup_fd; <answer> int 
cgroup_fd = <token> <answer> test__join_cgroup("/sockopt_inherit"); 
if (!ASSERT_GE(cgroup_fd, <token> "join_cgroup")) <answer> 0, 
<token> <linux/time.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/errno.h> 
<token> <linux/fcntl.h> <answer> #include 
<token> <linux/stat.h> <answer> #include 
#include <token> <answer> <linux/mm.h> 
<token> <linux/slab.h> <answer> #include 
<token> <linux/task_io_accounting_ops.h> <answer> #include 
#include <token> <answer> <linux/pagemap.h> 
<token> <linux/sunrpc/clnt.h> <answer> #include 
#include <token> <answer> <linux/nfs_fs.h> 
#include <token> <answer> <linux/nfs_page.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> "nfs4_fs.h" 
<token> "internal.h" <answer> #include 
<token> "iostat.h" <answer> #include 
<token> "fscache.h" <answer> #include 
#include <token> <answer> "pnfs.h" 
#include <token> <answer> "nfstrace.h" 
#define <token> NFSDBG_PAGECACHE <answer> NFSDBG_FACILITY 
<token> struct nfs_pgio_completion_ops nfs_async_read_completion_ops; <answer> const 
static const struct <token> nfs_rw_read_ops; <answer> nfs_rw_ops 
static struct kmem_cache <token> <answer> *nfs_rdata_cachep; 
static <token> nfs_pgio_header *nfs_readhdr_alloc(void) <answer> struct 
struct <token> *p = kmem_cache_zalloc(nfs_rdata_cachep, GFP_KERNEL); <answer> nfs_pgio_header 
<token> (p) <answer> if 
p->rw_mode = <token> <answer> FMODE_READ; 
return <token> <answer> p; 
<token> void nfs_readhdr_free(struct nfs_pgio_header *rhdr) <answer> static 
if <token> != NULL) <answer> (rhdr->res.scratch 
kmem_cache_free(nfs_rdata_cachep, <token> <answer> rhdr); 
static int nfs_return_empty_folio(struct <token> *folio) <answer> folio 
<token> 0, folio_size(folio)); <answer> folio_zero_segment(folio, 
<token> 0; <answer> return 
void nfs_pageio_init_read(struct <token> *pgio, <answer> nfs_pageio_descriptor 
struct <token> *inode, bool force_mds, <answer> inode 
const struct nfs_pgio_completion_ops <token> <answer> *compl_ops) 
<token> nfs_server *server = NFS_SERVER(inode); <answer> struct 
const struct <token> *pg_ops = &nfs_pgio_rw_ops; <answer> nfs_pageio_ops 
#ifdef <token> <answer> CONFIG_NFS_V4_1 
if (server->pnfs_curr_ld <token> !force_mds) <answer> && 
<token> = server->pnfs_curr_ld->pg_read_ops; <answer> pg_ops 
nfs_pageio_init(pgio, inode, pg_ops, compl_ops, <token> <answer> &nfs_rw_read_ops, 
server->rsize, <token> <answer> 0); 
<token> nfs_pageio_complete_read(struct nfs_pageio_descriptor *pgio) <answer> void 
struct nfs_pgio_mirror <token> <answer> *pgm; 
unsigned <token> npages; <answer> long 
