#include <token> <answer> <dt-bindings/clock/mt8167-clk.h> 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <linux/of.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> "clk-pll.h" <answer> #include 
<token> "clk-mtk.h" <answer> #include 
<token> DEFINE_SPINLOCK(mt8167_apmixed_clk_lock); <answer> static 
#define MT8167_PLL_FMAX (2500UL <token> MHZ) <answer> * 
#define <token> BIT(27) <answer> CON0_MT8167_RST_BAR 
#define <token> _name, _reg, _pwr_reg, _en_mask, _flags, _pcwbits, \ <answer> PLL_B(_id, 
_pd_reg, _pd_shift, <token> _pcw_reg, \ <answer> _tuner_reg, 
_pcw_shift, <token> { \ <answer> _div_table) 
.id = _id, <token> <answer> \ 
.name = _name, <token> <answer> \ 
.reg = <token> \ <answer> _reg, 
<token> = _pwr_reg, \ <answer> .pwr_reg 
.en_mask = <token> \ <answer> _en_mask, 
.flags <token> _flags, \ <answer> = 
.rst_bar_mask = CON0_MT8167_RST_BAR, <token> <answer> \ 
.fmax = MT8167_PLL_FMAX, <token> <answer> \ 
.pcwbits = _pcwbits, <token> <answer> \ 
<token> = _pd_reg, \ <answer> .pd_reg 
.pd_shift = <token> \ <answer> _pd_shift, 
.tuner_reg <token> _tuner_reg, \ <answer> = 
.pcw_reg <token> _pcw_reg, \ <answer> = 
.pcw_shift = _pcw_shift, <token> <answer> \ 
.div_table <token> _div_table, \ <answer> = 
<token> PLL(_id, _name, _reg, _pwr_reg, _en_mask, _flags, _pcwbits, \ <answer> #define 
_pd_reg, _pd_shift, <token> _pcw_reg, \ <answer> _tuner_reg, 
_pcw_shift) <token> <answer> \ 
PLL_B(_id, _name, _reg, _pwr_reg, _en_mask, _flags, <token> \ <answer> _pcwbits, 
<token> _pd_shift, _tuner_reg, _pcw_reg, _pcw_shift, \ <answer> _pd_reg, 
static const struct mtk_pll_div_table mmpll_div_table[] = <token> <answer> { 
{ .div = 0, .freq <token> MT8167_PLL_FMAX }, <answer> = 
<token> .div = 1, .freq = 1000000000 }, <answer> { 
{ .div = 2, .freq = 604500000 <token> <answer> }, 
{ .div = <token> .freq = 253500000 }, <answer> 3, 
{ .div = 4, .freq = 126750000 <token> <answer> }, 
<token> <linux/attribute_container.h> <answer> #include 
<token> <linux/device.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/slab.h> <answer> #include 
<token> <linux/list.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/mutex.h> 
#include <token> <answer> "base.h" 
struct <token> { <answer> internal_container 
<token> klist_node node; <answer> struct 
struct <token> *cont; <answer> attribute_container 
struct device <token> <answer> classdev; 
static void internal_container_klist_get(struct klist_node <token> <answer> *n) 
struct internal_container <token> = <answer> *ic 
container_of(n, struct internal_container, <token> <answer> node); 
static void <token> klist_node *n) <answer> internal_container_klist_put(struct 
struct internal_container *ic <token> <answer> = 
container_of(n, struct <token> node); <answer> internal_container, 
<token> attribute_container * <answer> struct 
<token> device *classdev) <answer> attribute_container_classdev_to_container(struct 
struct <token> *ic = <answer> internal_container 
container_of(classdev, <token> internal_container, classdev); <answer> struct 
<token> ic->cont; <answer> return 
static <token> <answer> LIST_HEAD(attribute_container_list); 
<token> DEFINE_MUTEX(attribute_container_mutex); <answer> static 
attribute_container_register(struct attribute_container <token> <answer> *cont) 
<token> internal_container_klist_get, <answer> klist_init(&cont->containers, 
list_add_tail(&cont->node, <token> <answer> &attribute_container_list); 
return <token> <answer> 0; 
attribute_container_unregister(struct attribute_container <token> <answer> *cont) 
int <token> = -EBUSY; <answer> retval 
if <token> <answer> (!list_empty(&cont->containers.k_list)) 
goto <token> <answer> out; 
retval = <token> <answer> 0; 
<token> retval; <answer> return 
attribute_container_add_device(struct <token> *dev, <answer> device 
int <token> attribute_container *, <answer> (*fn)(struct 
struct device <token> <answer> *, 
struct device <token> <answer> *)) 
struct <token> *cont; <answer> attribute_container 
list_for_each_entry(cont, &attribute_container_list, <token> { <answer> node) 
<token> internal_container *ic; <answer> struct 
if <token> <answer> (attribute_container_no_classdevs(cont)) 
if (!cont->match(cont, <token> <answer> dev)) 
ic = kzalloc(sizeof(*ic), <token> <answer> GFP_KERNEL); 
<token> (!ic) { <answer> if 
dev_err(dev, <token> to allocate class container\n"); <answer> "failed 
ic->cont <token> cont; <answer> = 
ic->classdev.parent <token> get_device(dev); <answer> = 
<token> = cont->class; <answer> ic->classdev.class 
cont->class->dev_release <token> attribute_container_release; <answer> = 
<token> "%s", dev_name(dev)); <answer> dev_set_name(&ic->classdev, 
if <token> <answer> (fn) 
fn(cont, <token> &ic->classdev); <answer> dev, 
klist_add_tail(&ic->node, <token> <answer> &cont->containers); 
#define klist_for_each_entry(pos, <token> member, iter) \ <answer> head, 
<token> (klist_iter_init(head, iter); (pos = ({ \ <answer> for 
struct klist_node *n = <token> \ <answer> klist_next(iter); 
n ? container_of(n, typeof(*pos), member) : <token> <answer> \ 
({ klist_iter_exit(iter) ; NULL; <token> \ <answer> }); 
})) <token> NULL;) <answer> != 
attribute_container_remove_device(struct <token> *dev, <answer> device 
void <token> attribute_container *, <answer> (*fn)(struct 
<token> device *, <answer> struct 
struct <token> *)) <answer> device 
struct <token> *cont; <answer> attribute_container 
list_for_each_entry(cont, &attribute_container_list, <token> { <answer> node) 
<token> internal_container *ic; <answer> struct 
struct klist_iter <token> <answer> iter; 
if <token> <answer> (attribute_container_no_classdevs(cont)) 
if <token> dev)) <answer> (!cont->match(cont, 
klist_for_each_entry(ic, &cont->containers, node, &iter) <token> <answer> { 
if (dev != <token> <answer> ic->classdev.parent) 
<token> (fn) <answer> if 
fn(cont, dev, <token> <answer> &ic->classdev); 
<token> { <answer> else 
<token> int <answer> static 
<token> device *dev, <answer> do_attribute_container_device_trigger_safe(struct 
struct <token> *cont, <answer> attribute_container 
int (*fn)(struct <token> *, <answer> attribute_container 
struct device <token> struct device *), <answer> *, 
int (*undo)(struct attribute_container <token> <answer> *, 
struct device *, struct <token> *)) <answer> device 
<token> ret; <answer> int 
struct internal_container <token> *failed; <answer> *ic, 
struct klist_iter <token> <answer> iter; 
if <token> <answer> (attribute_container_no_classdevs(cont)) 
return fn(cont, dev, <token> <answer> NULL); 
<token> &cont->containers, node, &iter) { <answer> klist_for_each_entry(ic, 
if (dev == <token> { <answer> ic->classdev.parent) 
ret = fn(cont, <token> &ic->classdev); <answer> dev, 
if (ret) <token> <answer> { 
<token> = ic; <answer> failed 
<token> fail; <answer> goto 
return <token> <answer> 0; 
if <token> <answer> (!undo) 
return <token> <answer> ret; 
attribute_container_device_trigger_safe(struct device <token> <answer> *dev, 
int (*fn)(struct <token> *, <answer> attribute_container 
struct <token> *, <answer> device 
<token> device *), <answer> struct 
int (*undo)(struct attribute_container <token> <answer> *, 
struct device <token> <answer> *, 
<token> device *)) <answer> struct 
struct attribute_container *cont, <token> = NULL; <answer> *failed 
int ret <token> 0; <answer> = 
<token> &attribute_container_list, node) { <answer> list_for_each_entry(cont, 
if (!cont->match(cont, <token> <answer> dev)) 
ret = <token> cont, <answer> do_attribute_container_device_trigger_safe(dev, 
fn, <token> <answer> undo); 
if (ret) <token> <answer> { 
failed = <token> <answer> cont; 
if <token> && !WARN_ON(!undo)) { <answer> (ret 
list_for_each_entry(cont, &attribute_container_list, node) <token> <answer> { 
<token> (failed == cont) <answer> if 
<token> (!cont->match(cont, dev)) <answer> if 
do_attribute_container_device_trigger_safe(dev, <token> <answer> cont, 
undo, <token> <answer> NULL); 
<token> ret; <answer> return 
attribute_container_device_trigger(struct <token> *dev, <answer> device 
int (*fn)(struct <token> *, <answer> attribute_container 
<token> device *, <answer> struct 
<token> device *)) <answer> struct 
<token> attribute_container *cont; <answer> struct 
list_for_each_entry(cont, &attribute_container_list, node) <token> <answer> { 
struct <token> *ic; <answer> internal_container 
struct klist_iter <token> <answer> iter; 
if <token> dev)) <answer> (!cont->match(cont, 
<token> (attribute_container_no_classdevs(cont)) { <answer> if 
<token> dev, NULL); <answer> fn(cont, 
<token> &cont->containers, node, &iter) { <answer> klist_for_each_entry(ic, 
if (dev == <token> <answer> ic->classdev.parent) 
fn(cont, dev, <token> <answer> &ic->classdev); 
<token> device *dev, <answer> attribute_container_trigger(struct 
int (*fn)(struct <token> *, <answer> attribute_container 
struct device <token> <answer> *)) 
<token> attribute_container *cont; <answer> struct 
list_for_each_entry(cont, &attribute_container_list, node) <token> <answer> { 
if <token> dev)) <answer> (cont->match(cont, 
fn(cont, <token> <answer> dev); 
attribute_container_add_attrs(struct <token> *classdev) <answer> device 
struct attribute_container *cont <token> <answer> = 
struct device_attribute **attrs = <token> <answer> cont->attrs; 
int <token> error; <answer> i, 
BUG_ON(attrs && <token> <answer> cont->grp); 
<token> (!attrs && !cont->grp) <answer> if 
return <token> <answer> 0; 
if <token> <answer> (cont->grp) 
return sysfs_create_group(&classdev->kobj, <token> <answer> cont->grp); 
for (i = 0; <token> i++) { <answer> attrs[i]; 
error = <token> attrs[i]); <answer> device_create_file(classdev, 
if <token> <answer> (error) 
<token> error; <answer> return 
<token> 0; <answer> return 
<token> device *classdev) <answer> attribute_container_add_class_device(struct 
int <token> = device_add(classdev); <answer> error 
<token> (error) <answer> if 
return <token> <answer> error; 
return <token> <answer> attribute_container_add_attrs(classdev); 
<token> attribute_container *cont, <answer> attribute_container_add_class_device_adapter(struct 
<token> device *dev, <answer> struct 
struct <token> *classdev) <answer> device 
<token> attribute_container_add_class_device(classdev); <answer> return 
<token> device *classdev) <answer> attribute_container_remove_attrs(struct 
<token> attribute_container *cont = <answer> struct 
struct device_attribute **attrs = <token> <answer> cont->attrs; 
<token> i; <answer> int 
if (!attrs && <token> <answer> !cont->grp) 
<token> (cont->grp) { <answer> if 
sysfs_remove_group(&classdev->kobj, <token> <answer> cont->grp); 
<token> ; <answer> return 
for (i = 0; attrs[i]; <token> <answer> i++) 
device_remove_file(classdev, <token> <answer> attrs[i]); 
<token> device *classdev) <answer> attribute_container_class_device_del(struct 
<token> device * <answer> struct 
attribute_container_find_class_device(struct <token> *cont, <answer> attribute_container 
struct <token> *dev) <answer> device 
struct device *cdev <token> NULL; <answer> = 
<token> internal_container *ic; <answer> struct 
<token> klist_iter iter; <answer> struct 
klist_for_each_entry(ic, &cont->containers, node, &iter) <token> <answer> { 
if (ic->classdev.parent == dev) <token> <answer> { 
cdev = <token> <answer> &ic->classdev; 
#include <token> <answer> "vmlinux.h" 
<token> <bpf/bpf_helpers.h> <answer> #include 
<token> <bpf/bpf_tracing.h> <answer> #include 
char _license[] SEC("license") <token> "GPL"; <answer> = 
int ca1_cnt <token> 0; <answer> = 
int ca2_cnt <token> 0; <answer> = 
static inline struct tcp_sock *tcp_sk(const <token> sock *sk) <answer> struct 
return <token> tcp_sock *)sk; <answer> (struct 
<token> BPF_PROG(ca_update_1_init, struct sock *sk) <answer> void 
void BPF_PROG(ca_update_2_init, struct sock <token> <answer> *sk) 
<token> BPF_PROG(ca_update_cong_control, struct sock *sk, <answer> void 
<token> struct rate_sample *rs) <answer> const 
__u32 BPF_PROG(ca_update_ssthresh, <token> sock *sk) <answer> struct 
<token> tcp_sk(sk)->snd_ssthresh; <answer> return 
__u32 <token> struct sock *sk) <answer> BPF_PROG(ca_update_undo_cwnd, 
return <token> <answer> tcp_sk(sk)->snd_cwnd; 
struct tcp_congestion_ops <token> = { <answer> ca_update_1 
.init = (void <token> <answer> *)ca_update_1_init, 
<token> = (void *)ca_update_cong_control, <answer> .cong_control 
.ssthresh = <token> *)ca_update_ssthresh, <answer> (void 
.undo_cwnd <token> (void *)ca_update_undo_cwnd, <answer> = 
.name = <token> <answer> "tcp_ca_update", 
<token> tcp_congestion_ops ca_update_2 = { <answer> struct 
.init = (void <token> <answer> *)ca_update_2_init, 
.cong_control = (void <token> <answer> *)ca_update_cong_control, 
.ssthresh = (void <token> <answer> *)ca_update_ssthresh, 
.undo_cwnd <token> (void *)ca_update_undo_cwnd, <answer> = 
.name = <token> <answer> "tcp_ca_update", 
struct tcp_congestion_ops ca_wrong <token> { <answer> = 
.cong_control = (void <token> <answer> *)ca_update_cong_control, 
.ssthresh <token> (void *)ca_update_ssthresh, <answer> = 
.undo_cwnd <token> (void *)ca_update_undo_cwnd, <answer> = 
<token> = "tcp_ca_wrong", <answer> .name 
<token> tcp_congestion_ops ca_no_link = { <answer> struct 
.cong_control = (void <token> <answer> *)ca_update_cong_control, 
.ssthresh = (void <token> <answer> *)ca_update_ssthresh, 
.undo_cwnd <token> (void *)ca_update_undo_cwnd, <answer> = 
.name = <token> <answer> "tcp_ca_no_link", 
#include <token> <answer> <linux/completion.h> 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/sched.h> <answer> #include 
#include <token> <answer> <linux/stacktrace.h> 
static <token> backtrace_test_normal(void) <answer> void 
pr_info("Testing a backtrace <token> process context.\n"); <answer> from 
<token> following trace is a kernel self test and not a bug!\n"); <answer> pr_info("The 
static void backtrace_test_bh_workfn(struct work_struct <token> <answer> *work) 
static <token> &backtrace_test_bh_workfn); <answer> DECLARE_WORK(backtrace_bh_work, 
static <token> backtrace_test_bh(void) <answer> void 
pr_info("Testing a <token> from BH context.\n"); <answer> backtrace 
pr_info("The following trace is a kernel self test and not <token> bug!\n"); <answer> a 
<token> &backtrace_bh_work); <answer> queue_work(system_bh_wq, 
#ifdef <token> <answer> CONFIG_STACKTRACE 
static void <token> <answer> backtrace_test_saved(void) 
unsigned long <token> <answer> entries[8]; 
unsigned int <token> <answer> nr_entries; 
pr_info("Testing a <token> backtrace.\n"); <answer> saved 
pr_info("The following trace is <token> kernel self test and not a bug!\n"); <answer> a 
nr_entries = stack_trace_save(entries, ARRAY_SIZE(entries), <token> <answer> 0); 
stack_trace_print(entries, <token> 0); <answer> nr_entries, 
<token> void backtrace_test_saved(void) <answer> static 
pr_info("Saved <token> test skipped.\n"); <answer> backtrace 
<token> int backtrace_regression_test(void) <answer> static 
pr_info("====[ backtrace testing <token> <answer> ]===========\n"); 
<token> end of backtrace testing ]====\n"); <answer> pr_info("====[ 
return <token> <answer> 0; 
static <token> exitf(void) <answer> void 
MODULE_AUTHOR("Arjan <token> de Ven <arjan@linux.intel.com>"); <answer> van 
<token> <linux/bits.h> <answer> #include 
#include <token> <answer> <linux/gpio/driver.h> 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/pinctrl/pinmux.h> 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/regmap.h> <answer> #include 
<token> "../pinctrl-utils.h" <answer> #include 
#include <token> <answer> "pinctrl-bcm63xx.h" 
#define BCM6362_BANK_GPIOS <token> <answer> 32 
#define BCM6362_NUM_GPIOS <token> <answer> 48 
#define <token> 24 <answer> BCM6362_NUM_LEDS 
#define BCM6362_LED_REG <token> <answer> 0x10 
#define <token> 0x18 <answer> BCM6362_MODE_REG 
#define <token> 0x1c <answer> BCM6362_CTRL_REG 
#define BCM6362_BASEMODE_REG <token> <answer> 0x38 
#define BASEMODE_NAND <token> <answer> BIT(2) 
enum <token> { <answer> bcm6362_pinctrl_reg 
struct bcm6362_function <token> <answer> { 
const char <token> <answer> *name; 
<token> char * const *groups; <answer> const 
const unsigned <token> <answer> num_groups; 
<token> bcm6362_pinctrl_reg reg; <answer> enum 
<token> basemode_mask; <answer> uint32_t 
#define BCM6362_PIN(a, <token> mask) \ <answer> b, 
<token> \ <answer> { 
.number <token> a, \ <answer> = 
.name <token> b, \ <answer> = 
<token> = (void *)(mask), \ <answer> .drv_data 
static const struct pinctrl_pin_desc <token> = { <answer> bcm6362_pins[] 
PINCTRL_PIN(0, <token> <answer> "gpio0"), 
<token> "gpio1"), <answer> PINCTRL_PIN(1, 
<token> "gpio2"), <answer> PINCTRL_PIN(2, 
<token> "gpio3"), <answer> PINCTRL_PIN(3, 
<token> "gpio4"), <answer> PINCTRL_PIN(4, 
<token> "gpio5"), <answer> PINCTRL_PIN(5, 
PINCTRL_PIN(6, <token> <answer> "gpio6"), 
PINCTRL_PIN(7, <token> <answer> "gpio7"), 
<token> "gpio8", BASEMODE_NAND), <answer> BCM6362_PIN(8, 
<token> "gpio9"), <answer> PINCTRL_PIN(9, 
<token> "gpio10"), <answer> PINCTRL_PIN(10, 
<token> "gpio11"), <answer> PINCTRL_PIN(11, 
BCM6362_PIN(12, <token> BASEMODE_NAND), <answer> "gpio12", 
BCM6362_PIN(13, "gpio13", <token> <answer> BASEMODE_NAND), 
<token> "gpio14", BASEMODE_NAND), <answer> BCM6362_PIN(14, 
<token> "gpio15", BASEMODE_NAND), <answer> BCM6362_PIN(15, 
BCM6362_PIN(16, <token> BASEMODE_NAND), <answer> "gpio16", 
BCM6362_PIN(17, "gpio17", <token> <answer> BASEMODE_NAND), 
<token> "gpio18", BASEMODE_NAND), <answer> BCM6362_PIN(18, 
BCM6362_PIN(19, <token> BASEMODE_NAND), <answer> "gpio19", 
<token> "gpio20", BASEMODE_NAND), <answer> BCM6362_PIN(20, 
<token> "gpio21", BASEMODE_NAND), <answer> BCM6362_PIN(21, 
<token> "gpio22", BASEMODE_NAND), <answer> BCM6362_PIN(22, 
BCM6362_PIN(23, <token> BASEMODE_NAND), <answer> "gpio23", 
<token> "gpio24"), <answer> PINCTRL_PIN(24, 
<token> "gpio25"), <answer> PINCTRL_PIN(25, 
<token> "gpio26"), <answer> PINCTRL_PIN(26, 
BCM6362_PIN(27, "gpio27", <token> <answer> BASEMODE_NAND), 
<token> "gpio28"), <answer> PINCTRL_PIN(28, 
<token> "gpio29"), <answer> PINCTRL_PIN(29, 
PINCTRL_PIN(30, <token> <answer> "gpio30"), 
PINCTRL_PIN(31, <token> <answer> "gpio31"), 
PINCTRL_PIN(32, <token> <answer> "gpio32"), 
<token> "gpio33"), <answer> PINCTRL_PIN(33, 
<token> "gpio34"), <answer> PINCTRL_PIN(34, 
PINCTRL_PIN(35, <token> <answer> "gpio35"), 
<token> "gpio36"), <answer> PINCTRL_PIN(36, 
<token> "gpio37"), <answer> PINCTRL_PIN(37, 
PINCTRL_PIN(38, <token> <answer> "gpio38"), 
<token> "gpio39"), <answer> PINCTRL_PIN(39, 
<token> "gpio40"), <answer> PINCTRL_PIN(40, 
PINCTRL_PIN(41, <token> <answer> "gpio41"), 
<token> "gpio42"), <answer> PINCTRL_PIN(42, 
<token> "gpio43"), <answer> PINCTRL_PIN(43, 
<token> "gpio44"), <answer> PINCTRL_PIN(44, 
<token> "gpio45"), <answer> PINCTRL_PIN(45, 
PINCTRL_PIN(46, <token> <answer> "gpio46"), 
PINCTRL_PIN(47, <token> <answer> "gpio47"), 
static unsigned gpio0_pins[] = <token> 0 }; <answer> { 
static unsigned gpio1_pins[] = <token> 1 }; <answer> { 
static unsigned gpio2_pins[] <token> { 2 }; <answer> = 
<token> unsigned gpio3_pins[] = { 3 }; <answer> static 
static <token> gpio4_pins[] = { 4 }; <answer> unsigned 
static unsigned gpio5_pins[] = { <token> }; <answer> 5 
<token> unsigned gpio6_pins[] = { 6 }; <answer> static 
static <token> gpio7_pins[] = { 7 }; <answer> unsigned 
static <token> gpio8_pins[] = { 8 }; <answer> unsigned 
static unsigned gpio9_pins[] <token> { 9 }; <answer> = 
static unsigned gpio10_pins[] = <token> 10 }; <answer> { 
static unsigned gpio11_pins[] = <token> 11 }; <answer> { 
static unsigned gpio12_pins[] <token> { 12 }; <answer> = 
static unsigned gpio13_pins[] = { 13 <token> <answer> }; 
static unsigned gpio14_pins[] = { <token> }; <answer> 14 
<token> unsigned gpio15_pins[] = { 15 }; <answer> static 
static unsigned gpio16_pins[] = <token> 16 }; <answer> { 
<token> unsigned gpio17_pins[] = { 17 }; <answer> static 
static unsigned gpio18_pins[] = <token> 18 }; <answer> { 
<token> unsigned gpio19_pins[] = { 19 }; <answer> static 
static unsigned gpio20_pins[] = { 20 <token> <answer> }; 
<token> unsigned gpio21_pins[] = { 21 }; <answer> static 
static unsigned <token> = { 22 }; <answer> gpio22_pins[] 
static unsigned gpio23_pins[] = { 23 <token> <answer> }; 
<token> unsigned gpio24_pins[] = { 24 }; <answer> static 
static unsigned gpio25_pins[] <token> { 25 }; <answer> = 
static unsigned gpio26_pins[] <token> { 26 }; <answer> = 
static unsigned <token> = { 27 }; <answer> gpio27_pins[] 
static unsigned gpio28_pins[] <token> { 28 }; <answer> = 
static unsigned <token> = { 29 }; <answer> gpio29_pins[] 
<token> unsigned gpio30_pins[] = { 30 }; <answer> static 
static unsigned gpio31_pins[] = { 31 <token> <answer> }; 
static unsigned <token> = { 32 }; <answer> gpio32_pins[] 
static unsigned gpio33_pins[] = { <token> }; <answer> 33 
static unsigned gpio34_pins[] <token> { 34 }; <answer> = 
static unsigned gpio35_pins[] = { 35 <token> <answer> }; 
static unsigned <token> = { 36 }; <answer> gpio36_pins[] 
<token> unsigned gpio37_pins[] = { 37 }; <answer> static 
static unsigned gpio38_pins[] = <token> 38 }; <answer> { 
<token> unsigned gpio39_pins[] = { 39 }; <answer> static 
static <token> gpio40_pins[] = { 40 }; <answer> unsigned 
static unsigned gpio41_pins[] = <token> 41 }; <answer> { 
static unsigned gpio42_pins[] = { <token> }; <answer> 42 
static unsigned gpio43_pins[] <token> { 43 }; <answer> = 
static unsigned gpio44_pins[] = { 44 <token> <answer> }; 
static unsigned gpio45_pins[] = <token> 45 }; <answer> { 
static unsigned gpio46_pins[] = { <token> }; <answer> 46 
static unsigned <token> = { 47 }; <answer> gpio47_pins[] 
static unsigned nand_grp_pins[] <token> { <answer> = 
8, 12, <token> 14, 15, 16, 17, <answer> 13, 
18, <token> 20, 21, 22, 23, 27, <answer> 19, 
static struct <token> bcm6362_groups[] = { <answer> pingroup 
static const char * const led_groups[] = <token> <answer> { 
static const char * const <token> = { <answer> usb_device_led_groups[] 
static const char * const sys_irq_groups[] = <token> <answer> { 
static const char * <token> serial_led_clk_groups[] = { <answer> const 
static const char * const serial_led_data_groups[] <token> { <answer> = 
static const char * <token> robosw_led_data_groups[] = { <answer> const 
static const char * const <token> = { <answer> robosw_led_clk_groups[] 
static const char * <token> robosw_led0_groups[] = { <answer> const 
static const char * const robosw_led1_groups[] = <token> <answer> { 
static const char * <token> inet_led_groups[] = { <answer> const 
static const char * const <token> = { <answer> spi_cs2_groups[] 
static const char <token> const spi_cs3_groups[] = { <answer> * 
static const char * const ntr_pulse_groups[] = <token> <answer> { 
static const char * <token> uart1_scts_groups[] = { <answer> const 
static const char <token> const uart1_srts_groups[] = { <answer> * 
static const char * const uart1_sdin_groups[] = <token> <answer> { 
static const char <token> const uart1_sdout_groups[] = { <answer> * 
static const <token> * const adsl_spi_miso_groups[] = { <answer> char 
static const char * <token> adsl_spi_mosi_groups[] = { <answer> const 
static const char * const adsl_spi_clk_groups[] = <token> <answer> { 
static const char * <token> adsl_spi_cs_groups[] = { <answer> const 
static const char * <token> ephy0_led_groups[] = { <answer> const 
static const char * const <token> = { <answer> ephy1_led_groups[] 
static const <token> * const ephy2_led_groups[] = { <answer> char 
static const <token> * const ephy3_led_groups[] = { <answer> char 
static const char * const ext_irq0_groups[] = <token> <answer> { 
static const char * const ext_irq1_groups[] <token> { <answer> = 
static const char * const ext_irq2_groups[] <token> { <answer> = 
static const char * const ext_irq3_groups[] = <token> <answer> { 
static const char * <token> wifi_groups[] = { <answer> const 
static const char * <token> nand_groups[] = { <answer> const 
<token> BCM6362_LED_FUN(n) \ <answer> #define 
<token> \ <answer> { 
<token> = #n, \ <answer> .name 
<token> = n##_groups, \ <answer> .groups 
.num_groups = ARRAY_SIZE(n##_groups), <token> <answer> \ 
.reg = BCM6362_LEDCTRL, <token> <answer> \ 
#define <token> \ <answer> BCM6362_MODE_FUN(n) 
<token> \ <answer> { 
.name = <token> \ <answer> #n, 
<token> = n##_groups, \ <answer> .groups 
.num_groups = <token> \ <answer> ARRAY_SIZE(n##_groups), 
.reg = <token> \ <answer> BCM6362_MODE, 
#define <token> \ <answer> BCM6362_CTRL_FUN(n) 
<token> \ <answer> { 
.name <token> #n, \ <answer> = 
.groups <token> n##_groups, \ <answer> = 
.num_groups <token> ARRAY_SIZE(n##_groups), \ <answer> = 
<token> = BCM6362_CTRL, \ <answer> .reg 
<token> BCM6362_BASEMODE_FUN(n, mask) \ <answer> #define 
{ <token> <answer> \ 
.name = #n, <token> <answer> \ 
.groups = <token> \ <answer> n##_groups, 
.num_groups <token> ARRAY_SIZE(n##_groups), \ <answer> = 
.reg = <token> \ <answer> BCM6362_BASEMODE, 
.basemode_mask = (mask), <token> <answer> \ 
static <token> struct bcm6362_function bcm6362_funcs[] = { <answer> const 
BCM6362_BASEMODE_FUN(nand, <token> <answer> BASEMODE_NAND), 
static int bcm6362_pinctrl_get_group_count(struct pinctrl_dev <token> <answer> *pctldev) 
<token> ARRAY_SIZE(bcm6362_groups); <answer> return 
static const char *bcm6362_pinctrl_get_group_name(struct <token> *pctldev, <answer> pinctrl_dev 
<token> group) <answer> unsigned 
<token> bcm6362_groups[group].name; <answer> return 
<token> int bcm6362_pinctrl_get_group_pins(struct pinctrl_dev *pctldev, <answer> static 
unsigned group, <token> unsigned **pins, <answer> const 
unsigned <token> <answer> *npins) 
*pins <token> bcm6362_groups[group].pins; <answer> = 
*npins = <token> <answer> bcm6362_groups[group].npins; 
return <token> <answer> 0; 
static int bcm6362_pinctrl_get_func_count(struct pinctrl_dev <token> <answer> *pctldev) 
<token> ARRAY_SIZE(bcm6362_funcs); <answer> return 
static <token> char *bcm6362_pinctrl_get_func_name(struct pinctrl_dev *pctldev, <answer> const 
unsigned <token> <answer> selector) 
return <token> <answer> bcm6362_funcs[selector].name; 
<token> int bcm6362_pinctrl_get_groups(struct pinctrl_dev *pctldev, <answer> static 
<token> selector, <answer> unsigned 
const char * <token> **groups, <answer> const 
<token> * const num_groups) <answer> unsigned 
*groups <token> bcm6362_funcs[selector].groups; <answer> = 
*num_groups <token> bcm6362_funcs[selector].num_groups; <answer> = 
return <token> <answer> 0; 
static void bcm6362_set_gpio(struct bcm63xx_pinctrl *pc, <token> pin) <answer> unsigned 
const <token> pinctrl_pin_desc *desc = &bcm6362_pins[pin]; <answer> struct 
unsigned int basemode = <token> <answer> (uintptr_t)desc->drv_data; 
unsigned int mask = <token> <answer> bcm63xx_bank_pin(pin); 
<token> (basemode) <answer> if 
regmap_update_bits(pc->regs, <token> basemode, 0); <answer> BCM6362_BASEMODE_REG, 
if (pin <token> BCM63XX_BANK_GPIOS) { <answer> < 
<token> <linux/bsg.h> <answer> #include 
#include <token> <answer> <scsi/scsi.h> 
#include <token> <answer> <scsi/scsi_ioctl.h> 
<token> <scsi/scsi_cmnd.h> <answer> #include 
#include <token> <answer> <scsi/scsi_device.h> 
#include <token> <answer> <scsi/sg.h> 
<token> "scsi_priv.h" <answer> #include 
#define uptr64(val) ((void <token> *)(uintptr_t)(val)) <answer> __user 
<token> int scsi_bsg_sg_io_fn(struct request_queue *q, struct sg_io_v4 *hdr, <answer> static 
bool <token> unsigned int timeout) <answer> open_for_write, 
struct scsi_cmnd <token> <answer> *scmd; 
<token> request *rq; <answer> struct 
struct <token> *bio; <answer> bio 
<token> ret; <answer> int 
if (hdr->protocol <token> BSG_PROTOCOL_SCSI || <answer> != 
hdr->subprotocol != <token> <answer> BSG_SUB_PROTOCOL_SCSI_CMD) 
return <token> <answer> -EINVAL; 
<token> (hdr->dout_xfer_len && hdr->din_xfer_len) { <answer> if 
pr_warn_once("BIDI <token> in bsg has been removed.\n"); <answer> support 
<token> -EOPNOTSUPP; <answer> return 
rq = scsi_alloc_request(q, hdr->dout_xfer_len <token> <answer> ? 
<token> : REQ_OP_DRV_IN, 0); <answer> REQ_OP_DRV_OUT 
<token> (IS_ERR(rq)) <answer> if 
return <token> <answer> PTR_ERR(rq); 
rq->timeout = <token> <answer> timeout; 
scmd = <token> <answer> blk_mq_rq_to_pdu(rq); 
scmd->cmd_len = <token> <answer> hdr->request_len; 
if (scmd->cmd_len <token> sizeof(scmd->cmnd)) { <answer> > 
ret = <token> <answer> -EINVAL; 
<token> out_put_request; <answer> goto 
ret <token> -EFAULT; <answer> = 
if (copy_from_user(scmd->cmnd, <token> scmd->cmd_len)) <answer> uptr64(hdr->request), 
goto <token> <answer> out_put_request; 
<token> = -EPERM; <answer> ret 
if (!scsi_cmd_allowed(scmd->cmnd, <token> <answer> open_for_write)) 
<token> out_put_request; <answer> goto 
ret = <token> <answer> 0; 
if <token> { <answer> (hdr->dout_xfer_len) 
ret <token> blk_rq_map_user(rq->q, rq, NULL, uptr64(hdr->dout_xferp), <answer> = 
<token> GFP_KERNEL); <answer> hdr->dout_xfer_len, 
} else if (hdr->din_xfer_len) <token> <answer> { 
ret = <token> rq, NULL, uptr64(hdr->din_xferp), <answer> blk_rq_map_user(rq->q, 
hdr->din_xfer_len, <token> <answer> GFP_KERNEL); 
if <token> <answer> (ret) 
goto <token> <answer> out_put_request; 
<token> = rq->bio; <answer> bio 
blk_execute_rq(rq, !(hdr->flags <token> BSG_FLAG_Q_AT_TAIL)); <answer> & 
<token> = scmd->result & 0xff; <answer> hdr->device_status 
<token> = host_byte(scmd->result); <answer> hdr->transport_status 
<token> = 0; <answer> hdr->driver_status 
if <token> <answer> (scsi_status_is_check_condition(scmd->result)) 
<token> = DRIVER_SENSE; <answer> hdr->driver_status 
<token> = 0; <answer> hdr->info 
if (hdr->device_status || hdr->transport_status || <token> <answer> hdr->driver_status) 
<token> |= SG_INFO_CHECK; <answer> hdr->info 
<token> = 0; <answer> hdr->response_len 
if <token> && hdr->response) { <answer> (scmd->sense_len 
<token> len = min_t(unsigned int, hdr->max_response_len, <answer> int 
if (copy_to_user(uptr64(hdr->response), <token> <answer> scmd->sense_buffer, 
ret = <token> <answer> -EFAULT; 
<token> = len; <answer> hdr->response_len 
if (rq_data_dir(rq) <token> READ) <answer> == 
hdr->din_resid = <token> <answer> scmd->resid_len; 
hdr->dout_resid <token> scmd->resid_len; <answer> = 
return <token> <answer> ret; 
struct bsg_device <token> scsi_device *sdev) <answer> *scsi_bsg_register_queue(struct 
return bsg_register_queue(sdev->request_queue, <token> <answer> &sdev->sdev_gendev, 
<token> scsi_bsg_sg_io_fn); <answer> dev_name(&sdev->sdev_gendev), 
#define <token> BPF_MAP_TYPE_QUEUE <answer> MAP_TYPE 
#include <token> <answer> "test_queue_stack_map.h" 
<token> <linux/export.h> <answer> #include 
#include <token> <answer> <linux/mii.h> 
#include <token> <answer> <linux/phy.h> 
#include <token> <answer> <linux/phy_fixed.h> 
<token> "swphy.h" <answer> #include 
#define <token> 29 <answer> MII_REGS_NUM 
struct <token> { <answer> swmii_regs 
u16 <token> <answer> bmsr; 
u16 <token> <answer> lpa; 
u16 <token> <answer> lpagb; 
u16 <token> <answer> estat; 
enum <token> <answer> { 
SWMII_SPEED_10 = <token> <answer> 0, 
SWMII_DUPLEX_HALF = <token> <answer> 0, 
static const struct swmii_regs speed[] <token> { <answer> = 
[SWMII_SPEED_10] <token> { <answer> = 
.lpa = LPA_10FULL <token> LPA_10HALF, <answer> | 
<token> = { <answer> [SWMII_SPEED_100] 
.bmsr = BMSR_100FULL | <token> <answer> BMSR_100HALF, 
<token> = LPA_100FULL | LPA_100HALF, <answer> .lpa 
<token> = { <answer> [SWMII_SPEED_1000] 
.bmsr <token> BMSR_ESTATEN, <answer> = 
<token> = LPA_1000FULL | LPA_1000HALF, <answer> .lpagb 
.estat = ESTATUS_1000_TFULL <token> ESTATUS_1000_THALF, <answer> | 
static const struct <token> duplex[] = { <answer> swmii_regs 
[SWMII_DUPLEX_HALF] <token> { <answer> = 
<token> = BMSR_ESTATEN | BMSR_100HALF, <answer> .bmsr 
.lpa <token> LPA_10HALF | LPA_100HALF, <answer> = 
.lpagb <token> LPA_1000HALF, <answer> = 
.estat = <token> <answer> ESTATUS_1000_THALF, 
<token> = { <answer> [SWMII_DUPLEX_FULL] 
.bmsr = BMSR_ESTATEN <token> BMSR_100FULL, <answer> | 
.lpa = <token> | LPA_100FULL, <answer> LPA_10FULL 
.lpagb <token> LPA_1000FULL, <answer> = 
.estat = <token> <answer> ESTATUS_1000_TFULL, 
static int swphy_decode_speed(int <token> <answer> speed) 
<token> (speed) { <answer> switch 
<token> 1000: <answer> case 
<token> SWMII_SPEED_1000; <answer> return 
case <token> <answer> 100: 
<token> SWMII_SPEED_100; <answer> return 
case <token> <answer> 10: 
<token> SWMII_SPEED_10; <answer> return 
<token> -EINVAL; <answer> return 
int swphy_validate_state(const struct <token> *state) <answer> fixed_phy_status 
int <token> <answer> err; 
if <token> { <answer> (state->link) 
err = <token> <answer> swphy_decode_speed(state->speed); 
if (err < <token> { <answer> 0) 
pr_warn("swphy: unknown <token> <answer> speed\n"); 
return <token> <answer> -EINVAL; 
return <token> <answer> 0; 
int <token> reg, const struct fixed_phy_status *state) <answer> swphy_read_reg(int 
<token> speed_index, duplex_index; <answer> int 
u16 bmsr = <token> <answer> BMSR_ANEGCAPABLE; 
u16 estat <token> 0; <answer> = 
u16 <token> = 0; <answer> lpagb 
u16 lpa <token> 0; <answer> = 
if (reg > <token> <answer> MII_REGS_NUM) 
return <token> <answer> -1; 
speed_index = <token> <answer> swphy_decode_speed(state->speed); 
if <token> < 0)) <answer> (WARN_ON(speed_index 
<token> 0; <answer> return 
duplex_index <token> state->duplex ? SWMII_DUPLEX_FULL : SWMII_DUPLEX_HALF; <answer> = 
bmsr |= speed[speed_index].bmsr & <token> <answer> duplex[duplex_index].bmsr; 
estat <token> speed[speed_index].estat & duplex[duplex_index].estat; <answer> |= 
if <token> { <answer> (state->link) 
bmsr |= BMSR_LSTATUS | <token> <answer> BMSR_ANEGCOMPLETE; 
lpa |= speed[speed_index].lpa & <token> <answer> duplex[duplex_index].lpa; 
lpagb |= speed[speed_index].lpagb <token> duplex[duplex_index].lpagb; <answer> & 
if <token> <answer> (state->pause) 
<token> |= LPA_PAUSE_CAP; <answer> lpa 
if <token> <answer> (state->asym_pause) 
<token> |= LPA_PAUSE_ASYM; <answer> lpa 
switch (reg) <token> <answer> { 
<token> MII_BMCR: <answer> case 
<token> BMCR_ANENABLE; <answer> return 
case <token> <answer> MII_BMSR: 
return <token> <answer> bmsr; 
<token> MII_PHYSID1: <answer> case 
<token> MII_PHYSID2: <answer> case 
return <token> <answer> 0; 
case <token> <answer> MII_LPA: 
<token> lpa; <answer> return 
<token> MII_STAT1000: <answer> case 
return <token> <answer> lpagb; 
case <token> <answer> MII_ESTATUS: 
return <token> <answer> estat; 
case <token> <answer> MII_MMD_CTRL: 
<token> MII_MMD_DATA: <answer> case 
return <token> <answer> -1; 
return <token> <answer> 0xffff; 
<token> <linux/types.h> <answer> #include 
<token> <linux/device.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/bitfield.h> <answer> #include 
#include <token> <answer> <linux/dma-direction.h> 
#include <token> <answer> "gsi.h" 
<token> "gsi_trans.h" <answer> #include 
#include <token> <answer> "ipa.h" 
<token> "ipa_endpoint.h" <answer> #include 
#include <token> <answer> "ipa_table.h" 
#include <token> <answer> "ipa_cmd.h" 
#include <token> <answer> "ipa_mem.h" 
BUILD_BUG_ON(IPA_ENDPOINT_MAX - 1 > <token> <answer> U8_MAX); 
<token> = field_max(HDR_INIT_LOCAL_FLAGS_HDR_ADDR_FMASK); <answer> offset_max 
<token> = field_max(HDR_INIT_LOCAL_FLAGS_TABLE_SIZE_FMASK); <answer> size_max 
mem = ipa_mem_find(ipa, <token> <answer> IPA_MEM_MODEM_HEADER); 
<token> = mem->offset; <answer> offset 
size <token> mem->size; <answer> = 
bit_count = BITS_PER_BYTE <token> sizeof(payload->offset); <answer> * 
<token> (ipa->version >= IPA_VERSION_4_0) <answer> if 
bit_count += <token> <answer> hweight32(REGISTER_WRITE_FLAGS_OFFSET_HIGH_FMASK); 
BUILD_BUG_ON(bit_count > <token> <answer> 32); 
offset_max = ~0U >> (32 <token> bit_count); <answer> - 
if (offset <token> offset_max || ipa->mem_offset > offset_max - offset) { <answer> > 
dev_err(dev, "%s <token> too large 0x%04x + 0x%04x > 0x%04x)\n", <answer> offset 
name, ipa->mem_offset, offset, <token> <answer> offset_max); 
return <token> <answer> false; 
return <token> <answer> true; 
if (ipa_table_hash_support(ipa)) <token> <answer> { 
if (ipa->version <token> IPA_VERSION_5_0) <answer> < 
reg = ipa_reg(ipa, <token> <answer> FILT_ROUT_HASH_FLUSH); 
reg <token> ipa_reg(ipa, FILT_ROUT_CACHE_FLUSH); <answer> = 
<token> = reg_offset(reg); <answer> offset 
name = "filter/route <token> flush"; <answer> hash 
if (!ipa_cmd_register_write_offset_valid(ipa, <token> offset)) <answer> name, 
<token> false; <answer> return 
reg <token> ipa_reg(ipa, ENDP_STATUS); <answer> = 
offset <token> reg_n_offset(reg, IPA_ENDPOINT_COUNT - 1); <answer> = 
name <token> "maximal endpoint status"; <answer> = 
if (!ipa_cmd_register_write_offset_valid(ipa, name, <token> <answer> offset)) 
<token> false; <answer> return 
return <token> <answer> true; 
int <token> gsi_channel *channel, u32 tre_max) <answer> ipa_cmd_pool_init(struct 
struct <token> *trans_info = &channel->trans_info; <answer> gsi_trans_info 
struct device <token> = channel->gsi->dev; <answer> *dev 
<token> gsi_trans_pool_init_dma(dev, &trans_info->cmd_pool, <answer> return 
sizeof(union <token> <answer> ipa_cmd_payload), 
<token> channel->trans_tre_max); <answer> tre_max, 
void ipa_cmd_pool_exit(struct gsi_channel <token> <answer> *channel) 
<token> gsi_trans_info *trans_info = &channel->trans_info; <answer> struct 
struct device *dev = <token> <answer> channel->gsi->dev; 
gsi_trans_pool_exit_dma(dev, <token> <answer> &trans_info->cmd_pool); 
<token> union ipa_cmd_payload * <answer> static 
ipa_cmd_payload_alloc(struct <token> *ipa, dma_addr_t *addr) <answer> ipa 
struct <token> *trans_info; <answer> gsi_trans_info 
<token> ipa_endpoint *endpoint; <answer> struct 
endpoint <token> ipa->name_map[IPA_ENDPOINT_AP_COMMAND_TX]; <answer> = 
trans_info <token> &ipa->gsi.channel[endpoint->channel_id].trans_info; <answer> = 
<token> gsi_trans_pool_alloc_dma(&trans_info->cmd_pool, addr); <answer> return 
<token> = ipa_cmd_payload_alloc(ipa, &payload_addr); <answer> cmd_payload 
<token> = &cmd_payload->hdr_init_local; <answer> payload 
payload->hdr_table_addr <token> cpu_to_le64(addr); <answer> = 
flags = <token> HDR_INIT_LOCAL_FLAGS_TABLE_SIZE_FMASK); <answer> u32_encode_bits(size, 
<token> |= u32_encode_bits(offset, HDR_INIT_LOCAL_FLAGS_HDR_ADDR_FMASK); <answer> flags 
payload->flags <token> cpu_to_le32(flags); <answer> = 
gsi_trans_cmd_add(trans, <token> sizeof(*payload), payload_addr, <answer> payload, 
void ipa_cmd_register_write_add(struct gsi_trans *trans, u32 offset, u32 <token> <answer> value, 
u32 mask, bool <token> <answer> clear_full) 
struct ipa *ipa = container_of(trans->gsi, struct <token> gsi); <answer> ipa, 
<token> ipa_cmd_register_write *payload; <answer> struct 
<token> ipa_cmd_payload *cmd_payload; <answer> union 
u32 opcode <token> IPA_CMD_REGISTER_WRITE; <answer> = 
<token> payload_addr; <answer> dma_addr_t 
u32 <token> <answer> clear_option; 
u32 <token> <answer> options; 
<token> flags; <answer> u16 
if (ipa->version >= IPA_VERSION_4_0) <token> <answer> { 
<token> offset_high; <answer> u16 
<token> val; <answer> u32 
payload->size = <token> <answer> cpu_to_le16(size); 
payload->local_addr = <token> <answer> cpu_to_le16(offset); 
flags = toward_ipa <token> 0 : DMA_SHARED_MEM_FLAGS_DIRECTION_FMASK; <answer> ? 
payload->flags = <token> <answer> cpu_to_le16(flags); 
<token> = cpu_to_le64(addr); <answer> payload->system_addr 
gsi_trans_cmd_add(trans, payload, sizeof(*payload), <token> <answer> payload_addr, 
static <token> ipa_cmd_ip_tag_status_add(struct gsi_trans *trans) <answer> void 
struct ipa *ipa = container_of(trans->gsi, struct ipa, <token> <answer> gsi); 
<token> ipa_cmd_opcode opcode = IPA_CMD_IP_PACKET_TAG_STATUS; <answer> enum 
struct ipa_cmd_ip_packet_tag_status <token> <answer> *payload; 
union <token> *cmd_payload; <answer> ipa_cmd_payload 
dma_addr_t <token> <answer> payload_addr; 
cmd_payload = <token> &payload_addr); <answer> ipa_cmd_payload_alloc(ipa, 
payload <token> &cmd_payload->ip_packet_tag_status; <answer> = 
payload->tag = <token> IP_PACKET_TAG_STATUS_TAG_FMASK); <answer> le64_encode_bits(0, 
gsi_trans_cmd_add(trans, payload, <token> payload_addr, <answer> sizeof(*payload), 
endpoint <token> ipa->name_map[IPA_ENDPOINT_AP_LAN_RX]; <answer> = 
<token> endpoint->endpoint_id); <answer> ipa_cmd_ip_packet_init_add(trans, 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/device.h> 
#include <token> <answer> <linux/err.h> 
<token> <linux/fs.h> <answer> #include 
<token> <linux/poll.h> <answer> #include 
#include <token> <answer> <linux/sched.h> 
<token> <linux/file.h> <answer> #include 
#include <token> <answer> <linux/cdev.h> 
#include <token> <answer> <linux/anon_inodes.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/sched/mm.h> 
#include <token> <answer> <linux/uaccess.h> 
<token> <rdma/ib.h> <answer> #include 
#include <token> <answer> <rdma/uverbs_std_types.h> 
<token> <rdma/rdma_netlink.h> <answer> #include 
<token> "uverbs.h" <answer> #include 
#include <token> <answer> "core_priv.h" 
<token> "rdma_core.h" <answer> #include 
<token> Dreier"); <answer> MODULE_AUTHOR("Roland 
<token> userspace verbs access"); <answer> MODULE_DESCRIPTION("InfiniBand 
<token> BSD/GPL"); <answer> MODULE_LICENSE("Dual 
<token> { <answer> enum 
IB_UVERBS_MAJOR = <token> <answer> 231, 
IB_UVERBS_BASE_MINOR = <token> <answer> 192, 
IB_UVERBS_MAX_DEVICES <token> RDMA_MAX_PORTS, <answer> = 
IB_UVERBS_NUM_FIXED_MINOR = <token> <answer> 32, 
IB_UVERBS_NUM_DYNAMIC_MINOR = IB_UVERBS_MAX_DEVICES - <token> <answer> IB_UVERBS_NUM_FIXED_MINOR, 
#define IB_UVERBS_BASE_DEV <token> IB_UVERBS_BASE_MINOR) <answer> MKDEV(IB_UVERBS_MAJOR, 
static <token> dynamic_uverbs_dev; <answer> dev_t 
static <token> <answer> DEFINE_IDA(uverbs_ida); 
static <token> ib_uverbs_add_one(struct ib_device *device); <answer> int 
static void ib_uverbs_remove_one(struct ib_device *device, void <token> <answer> *client_data); 
static char <token> struct device *dev, umode_t *mode) <answer> *uverbs_devnode(const 
<token> (mode) <answer> if 
*mode = <token> <answer> 0666; 
return kasprintf(GFP_KERNEL, "infiniband/%s", <token> <answer> dev_name(dev)); 
static const struct <token> uverbs_class = { <answer> class 
.name = <token> <answer> "infiniband_verbs", 
.devnode <token> uverbs_devnode, <answer> = 
struct ib_ucontext *ib_uverbs_get_ucontext_file(struct ib_uverbs_file <token> <answer> *ufile) 
struct ib_ucontext <token> = smp_load_acquire(&ufile->ucontext); <answer> *ucontext 
<token> (!srcu_dereference(ufile->device->ib_dev, <answer> if 
return <token> <answer> ERR_PTR(-EIO); 
if <token> <answer> (!ucontext) 
return <token> <answer> ERR_PTR(-EINVAL); 
<token> ucontext; <answer> return 
int <token> ib_mw *mw) <answer> uverbs_dealloc_mw(struct 
struct ib_pd *pd = <token> <answer> mw->pd; 
int <token> <answer> ret; 
<token> = mw->device->ops.dealloc_mw(mw); <answer> ret 
<token> (ret) <answer> if 
<token> ret; <answer> return 
return <token> <answer> ret; 
static void ib_uverbs_release_dev(struct <token> *device) <answer> device 
<token> ib_uverbs_device *dev = <answer> struct 
<token> struct ib_uverbs_device, dev); <answer> container_of(device, 
void <token> ib_uverbs_completion_event_file *ev_file, <answer> ib_uverbs_release_ucq(struct 
struct <token> *uobj) <answer> ib_ucq_object 
struct ib_uverbs_event *evt, <token> <answer> *tmp; 
if <token> { <answer> (ev_file) 
list_for_each_entry_safe(evt, tmp, <token> obj_list) { <answer> &uobj->comp_list, 
<token> ib_uverbs_release_uevent(struct ib_uevent_object *uobj) <answer> void 
struct ib_uverbs_async_event_file *async_file <token> uobj->event_file; <answer> = 
<token> ib_uverbs_event *evt, *tmp; <answer> struct 
<token> (!async_file) <answer> if 
<token> tmp, &uobj->event_list, obj_list) { <answer> list_for_each_entry_safe(evt, 
void ib_uverbs_detach_umcast(struct <token> *qp, <answer> ib_qp 
<token> ib_uqp_object *uobj) <answer> struct 
struct ib_uverbs_mcast_entry <token> *tmp; <answer> *mcast, 
list_for_each_entry_safe(mcast, <token> &uobj->mcast_list, list) { <answer> tmp, 
ib_detach_mcast(qp, <token> mcast->lid); <answer> &mcast->gid, 
<token> void ib_uverbs_comp_dev(struct ib_uverbs_device *dev) <answer> static 
void ib_uverbs_release_file(struct kref <token> <answer> *ref) 
struct ib_uverbs_file *file <token> <answer> = 
container_of(ref, struct ib_uverbs_file, <token> <answer> ref); 
struct ib_device <token> <answer> *ib_dev; 
int <token> <answer> srcu_key; 
srcu_key = <token> <answer> srcu_read_lock(&file->device->disassociate_srcu); 
<token> = srcu_dereference(file->device->ib_dev, <answer> ib_dev 
<token> (ib_dev && !ib_dev->ops.disassociate_ucontext) <answer> if 
srcu_read_unlock(&file->device->disassociate_srcu, <token> <answer> srcu_key); 
<token> (refcount_dec_and_test(&file->device->refcount)) <answer> if 
<token> (file->default_async_file) <answer> if 
if <token> <answer> (file->disassociate_page) 
<token> 0); <answer> __free_pages(file->disassociate_page, 
<token> ssize_t ib_uverbs_event_read(struct ib_uverbs_event_queue *ev_queue, <answer> static 
struct file <token> char __user *buf, <answer> *filp, 
size_t <token> loff_t *pos, <answer> count, 
<token> eventsz) <answer> size_t 
struct <token> *event; <answer> ib_uverbs_event 
int ret <token> 0; <answer> = 
while <token> { <answer> (list_empty(&ev_queue->event_list)) 
<token> (ev_queue->is_closed) { <answer> if 
<token> -EIO; <answer> return 
<token> (filp->f_flags & O_NONBLOCK) <answer> if 
<token> -EAGAIN; <answer> return 
if <token> <answer> (wait_event_interruptible(ev_queue->poll_wait, 
<token> || <answer> (!list_empty(&ev_queue->event_list) 
<token> -ERESTARTSYS; <answer> return 
event = list_entry(ev_queue->event_list.next, struct ib_uverbs_event, <token> <answer> list); 
if (eventsz > <token> { <answer> count) 
ret <token> -EINVAL; <answer> = 
<token> = NULL; <answer> event 
} <token> { <answer> else 
if (event->counter) <token> <answer> { 
if (event) <token> <answer> { 
<token> (copy_to_user(buf, event, eventsz)) <answer> if 
ret = <token> <answer> -EFAULT; 
<token> = eventsz; <answer> ret 
return <token> <answer> ret; 
static ssize_t ib_uverbs_async_event_read(struct <token> *filp, char __user *buf, <answer> file 
size_t count, <token> *pos) <answer> loff_t 
struct ib_uverbs_async_event_file <token> = filp->private_data; <answer> *file 
return ib_uverbs_event_read(&file->ev_queue, filp, buf, <token> pos, <answer> count, 
sizeof(struct <token> <answer> ib_uverbs_async_event_desc)); 
static ssize_t ib_uverbs_comp_event_read(struct file <token> char __user *buf, <answer> *filp, 
size_t count, loff_t <token> <answer> *pos) 
struct ib_uverbs_completion_event_file *comp_ev_file <token> <answer> = 
<token> ib_uverbs_event_read(&comp_ev_file->ev_queue, filp, buf, count, <answer> return 
<token> ib_uverbs_comp_event_desc)); <answer> sizeof(struct 
static __poll_t ib_uverbs_event_poll(struct ib_uverbs_event_queue <token> <answer> *ev_queue, 
struct <token> *filp, <answer> file 
struct <token> *wait) <answer> poll_table_struct 
__poll_t pollflags = <token> <answer> 0; 
<token> &ev_queue->poll_wait, wait); <answer> poll_wait(filp, 
<token> (!list_empty(&ev_queue->event_list)) <answer> if 
pollflags = EPOLLIN <token> EPOLLRDNORM; <answer> | 
else <token> (ev_queue->is_closed) <answer> if 
pollflags = <token> <answer> EPOLLERR; 
return <token> <answer> pollflags; 
static __poll_t ib_uverbs_async_event_poll(struct <token> *filp, <answer> file 
<token> poll_table_struct *wait) <answer> struct 
struct ib_uverbs_async_event_file *file = <token> <answer> filp->private_data; 
return ib_uverbs_event_poll(&file->ev_queue, filp, <token> <answer> wait); 
<token> __poll_t ib_uverbs_comp_event_poll(struct file *filp, <answer> static 
struct <token> *wait) <answer> poll_table_struct 
struct <token> *comp_ev_file = <answer> ib_uverbs_completion_event_file 
<token> ib_uverbs_event_poll(&comp_ev_file->ev_queue, filp, wait); <answer> return 
static int <token> fd, struct file *filp, int on) <answer> ib_uverbs_async_event_fasync(int 
struct ib_uverbs_async_event_file <token> = filp->private_data; <answer> *file 
return <token> filp, on, &file->ev_queue.async_queue); <answer> fasync_helper(fd, 
static int ib_uverbs_comp_event_fasync(int fd, struct file <token> int on) <answer> *filp, 
<token> ib_uverbs_completion_event_file *comp_ev_file = <answer> struct 
return fasync_helper(fd, filp, <token> &comp_ev_file->ev_queue.async_queue); <answer> on, 
const struct file_operations <token> = { <answer> uverbs_event_fops 
<token> = THIS_MODULE, <answer> .owner 
.read <token> ib_uverbs_comp_event_read, <answer> = 
<token> = ib_uverbs_comp_event_poll, <answer> .poll 
.release = <token> <answer> uverbs_uobject_fd_release, 
.fasync <token> ib_uverbs_comp_event_fasync, <answer> = 
<token> = no_llseek, <answer> .llseek 
const struct file_operations uverbs_async_event_fops = <token> <answer> { 
.owner = <token> <answer> THIS_MODULE, 
.read <token> ib_uverbs_async_event_read, <answer> = 
<token> = ib_uverbs_async_event_poll, <answer> .poll 
.release = <token> <answer> uverbs_async_event_release, 
.fasync <token> ib_uverbs_async_event_fasync, <answer> = 
.llseek <token> no_llseek, <answer> = 
void ib_uverbs_comp_handler(struct <token> *cq, void *cq_context) <answer> ib_cq 
struct <token> *ev_queue = cq_context; <answer> ib_uverbs_event_queue 
struct <token> *uobj; <answer> ib_ucq_object 
struct <token> *entry; <answer> ib_uverbs_event 
unsigned long <token> <answer> flags; 
if <token> <answer> (!ev_queue) 
<token> flags); <answer> spin_lock_irqsave(&ev_queue->lock, 
if <token> { <answer> (ev_queue->is_closed) 
<token> flags); <answer> spin_unlock_irqrestore(&ev_queue->lock, 
<token> = kmalloc(sizeof(*entry), GFP_ATOMIC); <answer> entry 
if <token> { <answer> (!entry) 
spin_unlock_irqrestore(&ev_queue->lock, <token> <answer> flags); 
<token> = cq->uobject; <answer> uobj 
<token> = cq->uobject->uevent.uobject.user_handle; <answer> entry->desc.comp.cq_handle 
<token> = &uobj->comp_events_reported; <answer> entry->counter 
<token> &ev_queue->event_list); <answer> list_add_tail(&entry->list, 
<token> &uobj->comp_list); <answer> list_add_tail(&entry->obj_list, 
<token> flags); <answer> spin_unlock_irqrestore(&ev_queue->lock, 
kill_fasync(&ev_queue->async_queue, SIGIO, <token> <answer> POLL_IN); 
<token> ib_uverbs_async_handler(struct ib_uverbs_async_event_file *async_file, <answer> void 
__u64 element, __u64 <token> <answer> event, 
struct list_head <token> u32 *counter) <answer> *obj_list, 
struct ib_uverbs_event <token> <answer> *entry; 
unsigned long <token> <answer> flags; 
if <token> <answer> (!async_file) 
spin_lock_irqsave(&async_file->ev_queue.lock, <token> <answer> flags); 
if (async_file->ev_queue.is_closed) <token> <answer> { 
<token> flags); <answer> spin_unlock_irqrestore(&async_file->ev_queue.lock, 
entry <token> kmalloc(sizeof(*entry), GFP_ATOMIC); <answer> = 
if <token> { <answer> (!entry) 
<token> flags); <answer> spin_unlock_irqrestore(&async_file->ev_queue.lock, 
entry->desc.async.element <token> element; <answer> = 
entry->desc.async.event_type = <token> <answer> event; 
entry->desc.async.reserved <token> 0; <answer> = 
entry->counter <token> counter; <answer> = 
list_add_tail(&entry->list, <token> <answer> &async_file->ev_queue.event_list); 
if <token> <answer> (obj_list) 
<token> obj_list); <answer> list_add_tail(&entry->obj_list, 
<token> flags); <answer> spin_unlock_irqrestore(&async_file->ev_queue.lock, 
kill_fasync(&async_file->ev_queue.async_queue, <token> POLL_IN); <answer> SIGIO, 
static void <token> ib_uevent_object *eobj, <answer> uverbs_uobj_event(struct 
<token> ib_event *event) <answer> struct 
<token> event->event, <answer> eobj->uobject.user_handle, 
&eobj->event_list, <token> <answer> &eobj->events_reported); 
void ib_uverbs_cq_event_handler(struct ib_event <token> void *context_ptr) <answer> *event, 
uverbs_uobj_event(&event->element.cq->uobject->uevent, <token> <answer> event); 
void <token> ib_event *event, void *context_ptr) <answer> ib_uverbs_qp_event_handler(struct 
if (hdr->command <token> IB_USER_VERBS_CMD_DESTROY_CQ && <answer> == 
count == 16) <token> <answer> { 
<token> = 6; <answer> hdr->in_words 
<token> 0; <answer> return 
return <token> <answer> -ENOSPC; 
if <token> * 4 < method_elm->resp_size) <answer> (hdr->out_words 
<token> -ENOSPC; <answer> return 
<token> 0; <answer> return 
static <token> ib_uverbs_write(struct file *filp, const char __user *buf, <answer> ssize_t 
size_t count, <token> *pos) <answer> loff_t 
struct ib_uverbs_file *file = <token> <answer> filp->private_data; 
const struct <token> *method_elm; <answer> uverbs_api_write_method 
struct uverbs_api <token> = file->device->uapi; <answer> *uapi 
struct ib_uverbs_ex_cmd_hdr <token> <answer> ex_hdr; 
<token> ib_uverbs_cmd_hdr hdr; <answer> struct 
struct <token> bundle; <answer> uverbs_attr_bundle 
<token> srcu_key; <answer> int 
<token> ret; <answer> ssize_t 
if (!ib_safe_file_access(filp)) <token> <answer> { 
pr_err_once("uverbs_write: process %d (%s) changed security contexts after opening file descriptor, this is <token> allowed.\n", <answer> not 
<token> current->comm); <answer> task_tgid_vnr(current), 
<token> -EACCES; <answer> return 
<token> (count < sizeof(hdr)) <answer> if 
<token> -EINVAL; <answer> return 
if <token> buf, sizeof(hdr))) <answer> (copy_from_user(&hdr, 
return <token> <answer> -EFAULT; 
method_elm <token> uapi_get_method(uapi, hdr.command); <answer> = 
<token> (IS_ERR(method_elm)) <answer> if 
return <token> <answer> PTR_ERR(method_elm); 
if <token> { <answer> (method_elm->is_ex) 
if (count < (sizeof(hdr) <token> sizeof(ex_hdr))) <answer> + 
<token> -EINVAL; <answer> return 
if (copy_from_user(&ex_hdr, <token> + sizeof(hdr), sizeof(ex_hdr))) <answer> buf 
return <token> <answer> -EFAULT; 
ret <token> verify_hdr(&hdr, &ex_hdr, count, method_elm); <answer> = 
if <token> <answer> (ret) 
<token> ret; <answer> return 
srcu_key <token> srcu_read_lock(&file->device->disassociate_srcu); <answer> = 
buf <token> sizeof(hdr); <answer> += 
<token> 0, sizeof(bundle.attr_present)); <answer> memset(bundle.attr_present, 
bundle.ufile = <token> <answer> file; 
ret = get_user(response, (const u64 <token> *)buf); <answer> __user 
<token> (ret) <answer> if 
<token> out_unlock; <answer> goto 
<token> (method_elm->has_udata) { <answer> if 
bundle.driver_udata.outlen <token> <answer> = 
out_len <token> method_elm->resp_size; <answer> - 
out_len = <token> <answer> method_elm->resp_size; 
<token> (bundle.driver_udata.outlen) <answer> if 
bundle.driver_udata.outbuf <token> <answer> = 
<token> + <answer> u64_to_user_ptr(response 
bundle.driver_udata.outbuf <token> NULL; <answer> = 
<token> else { <answer> } 
bundle.driver_udata.outlen = <token> <answer> 0; 
bundle.driver_udata.outbuf = <token> <answer> NULL; 
<token> buf, u64_to_user_ptr(response), <answer> &bundle.ucore, 
<token> out_len); <answer> in_len, 
} <token> { <answer> else 
buf <token> sizeof(ex_hdr); <answer> += 
<token> buf, <answer> ib_uverbs_init_udata_buf_or_null(&bundle.ucore, 
hdr.in_words <token> 8, hdr.out_words * 8); <answer> * 
&bundle.driver_udata, buf <token> bundle.ucore.inlen, <answer> + 
u64_to_user_ptr(ex_hdr.response) + <token> <answer> bundle.ucore.outlen, 
ex_hdr.provider_in_words * <token> <answer> 8, 
ex_hdr.provider_out_words * <token> <answer> 8); 
ret <token> method_elm->handler(&bundle); <answer> = 
<token> (bundle.uobject) <answer> if 
uverbs_finalize_object(bundle.uobject, <token> true, <answer> UVERBS_ACCESS_NEW, 
!ret, <token> <answer> &bundle); 
srcu_read_unlock(&file->device->disassociate_srcu, <token> <answer> srcu_key); 
return (ret) ? : <token> <answer> count; 
<token> const struct vm_operations_struct rdma_umap_ops; <answer> static 
static int ib_uverbs_mmap(struct file *filp, <token> vm_area_struct *vma) <answer> struct 
struct <token> *file = filp->private_data; <answer> ib_uverbs_file 
struct <token> *ucontext; <answer> ib_ucontext 
int ret <token> 0; <answer> = 
int <token> <answer> srcu_key; 
srcu_key <token> srcu_read_lock(&file->device->disassociate_srcu); <answer> = 
ucontext = <token> <answer> ib_uverbs_get_ucontext_file(file); 
if (IS_ERR(ucontext)) <token> <answer> { 
ret <token> PTR_ERR(ucontext); <answer> = 
goto <token> <answer> out; 
<token> = &rdma_umap_ops; <answer> vma->vm_ops 
ret = ucontext->device->ops.mmap(ucontext, <token> <answer> vma); 
<token> srcu_key); <answer> srcu_read_unlock(&file->device->disassociate_srcu, 
<token> ret; <answer> return 
<token> void rdma_umap_open(struct vm_area_struct *vma) <answer> static 
struct ib_uverbs_file <token> = vma->vm_file->private_data; <answer> *ufile 
struct rdma_umap_priv <token> = vma->vm_private_data; <answer> *opriv 
struct rdma_umap_priv <token> <answer> *priv; 
<token> (!opriv) <answer> if 
<token> (!ufile->ucontext) <answer> if 
<token> out_unlock; <answer> goto 
priv <token> kzalloc(sizeof(*priv), GFP_KERNEL); <answer> = 
if <token> <answer> (!priv) 
goto <token> <answer> out_unlock; 
<token> vma, opriv->entry); <answer> rdma_umap_priv_init(priv, 
vma->vm_private_data <token> NULL; <answer> = 
zap_vma_ptes(vma, <token> vma->vm_end - vma->vm_start); <answer> vma->vm_start, 
static <token> rdma_umap_close(struct vm_area_struct *vma) <answer> void 
struct ib_uverbs_file *ufile <token> vma->vm_file->private_data; <answer> = 
<token> rdma_umap_priv *priv = vma->vm_private_data; <answer> struct 
if <token> <answer> (!priv) 
if <token> <answer> (priv->entry) 
static <token> rdma_umap_fault(struct vm_fault *vmf) <answer> vm_fault_t 
struct ib_uverbs_file *ufile = <token> <answer> vmf->vma->vm_file->private_data; 
<token> rdma_umap_priv *priv = vmf->vma->vm_private_data; <answer> struct 
vm_fault_t ret <token> 0; <answer> = 
<token> (!priv) <answer> if 
return <token> <answer> VM_FAULT_SIGBUS; 
vmf->page = <token> <answer> ufile->disassociate_page; 
<token> else { <answer> } 
ret = <token> <answer> VM_FAULT_SIGBUS; 
<token> ret; <answer> return 
static const struct vm_operations_struct rdma_umap_ops <token> { <answer> = 
.open = <token> <answer> rdma_umap_open, 
.close = <token> <answer> rdma_umap_close, 
.fault = <token> <answer> rdma_umap_fault, 
void uverbs_user_mmap_disassociate(struct <token> *ufile) <answer> ib_uverbs_file 
struct rdma_umap_priv <token> *next_priv; <answer> *priv, 
while (1) <token> <answer> { 
<token> mm_struct *mm = NULL; <answer> struct 
list_for_each_entry_safe (priv, <token> &ufile->umaps, <answer> next_priv, 
<token> { <answer> list) 
struct <token> *vma = priv->vma; <answer> vm_area_struct 
<token> (vma->vm_mm != mm) <answer> if 
<token> vma->vm_start, <answer> zap_vma_ptes(vma, 
<token> - vma->vm_start); <answer> vma->vm_end 
if <token> { <answer> (priv->entry) 
priv->entry <token> NULL; <answer> = 
static int ib_uverbs_open(struct inode *inode, struct file <token> <answer> *filp) 
struct <token> *dev; <answer> ib_uverbs_device 
struct ib_uverbs_file <token> <answer> *file; 
struct <token> *ib_dev; <answer> ib_device 
<token> ret; <answer> int 
<token> module_dependent; <answer> int 
int <token> <answer> srcu_key; 
<token> = container_of(inode->i_cdev, struct ib_uverbs_device, cdev); <answer> dev 
<token> (!refcount_inc_not_zero(&dev->refcount)) <answer> if 
<token> -ENXIO; <answer> return 
<token> = srcu_read_lock(&dev->disassociate_srcu); <answer> srcu_key 
ib_dev <token> srcu_dereference(dev->ib_dev, <answer> = 
if (!ib_dev) <token> <answer> { 
<token> = -EIO; <answer> ret 
<token> err; <answer> goto 
<token> (!rdma_dev_access_netns(ib_dev, current->nsproxy->net_ns)) { <answer> if 
ret = <token> <answer> -EPERM; 
<token> err; <answer> goto 
<token> = !(ib_dev->ops.disassociate_ucontext); <answer> module_dependent 
if <token> { <answer> (module_dependent) 
if <token> { <answer> (!try_module_get(ib_dev->ops.owner)) 
ret = <token> <answer> -ENODEV; 
goto <token> <answer> err; 
file <token> kzalloc(sizeof(*file), GFP_KERNEL); <answer> = 
if <token> { <answer> (!file) 
ret = <token> <answer> -ENOMEM; 
<token> (module_dependent) <answer> if 
goto <token> <answer> err_module; 
goto <token> <answer> err; 
file->device <token> dev; <answer> = 
filp->private_data <token> file; <answer> = 
list_add_tail(&file->list, <token> <answer> &dev->uverbs_file_list); 
srcu_read_unlock(&dev->disassociate_srcu, <token> <answer> srcu_key); 
return stream_open(inode, <token> <answer> filp); 
<token> srcu_key); <answer> srcu_read_unlock(&dev->disassociate_srcu, 
<token> (refcount_dec_and_test(&dev->refcount)) <answer> if 
return <token> <answer> ret; 
<token> int ib_uverbs_close(struct inode *inode, struct file *filp) <answer> static 
struct ib_uverbs_file *file = <token> <answer> filp->private_data; 
<token> RDMA_REMOVE_CLOSE); <answer> uverbs_destroy_ufile_hw(file, 
kref_put(&file->ref, <token> <answer> ib_uverbs_release_file); 
<token> 0; <answer> return 
static const struct file_operations uverbs_fops = <token> <answer> { 
.owner <token> THIS_MODULE, <answer> = 
<token> = ib_uverbs_write, <answer> .write 
.open <token> ib_uverbs_open, <answer> = 
.release = <token> <answer> ib_uverbs_close, 
.llseek = <token> <answer> no_llseek, 
.unlocked_ioctl = <token> <answer> ib_uverbs_ioctl, 
.compat_ioctl = <token> <answer> compat_ptr_ioctl, 
static const struct file_operations <token> = { <answer> uverbs_mmap_fops 
.owner = <token> <answer> THIS_MODULE, 
.write <token> ib_uverbs_write, <answer> = 
.mmap = <token> <answer> ib_uverbs_mmap, 
<token> = ib_uverbs_open, <answer> .open 
.release = <token> <answer> ib_uverbs_close, 
.llseek <token> no_llseek, <answer> = 
.unlocked_ioctl <token> ib_uverbs_ioctl, <answer> = 
.compat_ioctl <token> compat_ptr_ioctl, <answer> = 
static int ib_uverbs_get_nl_info(struct ib_device *ibdev, <token> *client_data, <answer> void 
<token> ib_client_nl_info *res) <answer> struct 
struct <token> *uverbs_dev = client_data; <answer> ib_uverbs_device 
<token> ret; <answer> int 
if <token> != -1) <answer> (res->port 
<token> -EINVAL; <answer> return 
<token> = ibdev->ops.uverbs_abi_ver; <answer> res->abi 
res->cdev <token> &uverbs_dev->dev; <answer> = 
if <token> { <answer> (!ibdev->ops.uverbs_no_driver_id_binding) 
ret = <token> RDMA_NLDEV_ATTR_UVERBS_DRIVER_ID, <answer> nla_put_u32(res->nl_msg, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
<token> 0; <answer> return 
static <token> ib_client uverbs_client = { <answer> struct 
<token> = "uverbs", <answer> .name 
<token> = true, <answer> .no_kverbs_req 
.add <token> ib_uverbs_add_one, <answer> = 
.remove = <token> <answer> ib_uverbs_remove_one, 
<token> = ib_uverbs_get_nl_info, <answer> .get_nl_info 
static ssize_t ibdev_show(struct device *device, struct <token> *attr, <answer> device_attribute 
<token> *buf) <answer> char 
struct ib_uverbs_device <token> = <answer> *dev 
<token> struct ib_uverbs_device, dev); <answer> container_of(device, 
<token> ret = -ENODEV; <answer> int 
int <token> <answer> srcu_key; 
<token> ib_device *ib_dev; <answer> struct 
srcu_key = <token> <answer> srcu_read_lock(&dev->disassociate_srcu); 
<token> = srcu_dereference(dev->ib_dev, &dev->disassociate_srcu); <answer> ib_dev 
<token> (ib_dev) <answer> if 
ret = sysfs_emit(buf, <token> dev_name(&ib_dev->dev)); <answer> "%s\n", 
<token> srcu_key); <answer> srcu_read_unlock(&dev->disassociate_srcu, 
return <token> <answer> ret; 
<token> DEVICE_ATTR_RO(ibdev); <answer> static 
static <token> abi_version_show(struct device *device, <answer> ssize_t 
<token> device_attribute *attr, char *buf) <answer> struct 
<token> ib_uverbs_device *dev = <answer> struct 
container_of(device, struct <token> dev); <answer> ib_uverbs_device, 
int ret <token> -ENODEV; <answer> = 
<token> srcu_key; <answer> int 
struct ib_device <token> <answer> *ib_dev; 
<token> = srcu_read_lock(&dev->disassociate_srcu); <answer> srcu_key 
ib_dev = srcu_dereference(dev->ib_dev, <token> <answer> &dev->disassociate_srcu); 
<token> (ib_dev) <answer> if 
ret = sysfs_emit(buf, "%u\n", <token> <answer> ib_dev->ops.uverbs_abi_ver); 
srcu_read_unlock(&dev->disassociate_srcu, <token> <answer> srcu_key); 
<token> ret; <answer> return 
<token> DEVICE_ATTR_RO(abi_version); <answer> static 
static struct attribute *ib_dev_attrs[] <token> { <answer> = 
static const struct attribute_group dev_attr_group = <token> <answer> { 
<token> = ib_dev_attrs, <answer> .attrs 
static CLASS_ATTR_STRING(abi_version, <token> <answer> S_IRUGO, 
static <token> ib_uverbs_create_uapi(struct ib_device *device, <answer> int 
struct ib_uverbs_device <token> <answer> *uverbs_dev) 
<token> uverbs_api *uapi; <answer> struct 
uapi <token> uverbs_alloc_api(device); <answer> = 
if <token> <answer> (IS_ERR(uapi)) 
return <token> <answer> PTR_ERR(uapi); 
uverbs_dev->uapi = <token> <answer> uapi; 
return <token> <answer> 0; 
static <token> ib_uverbs_add_one(struct ib_device *device) <answer> int 
<token> devnum; <answer> int 
<token> base; <answer> dev_t 
struct <token> *uverbs_dev; <answer> ib_uverbs_device 
int <token> <answer> ret; 
if <token> <answer> (!device->ops.alloc_ucontext) 
return <token> <answer> -EOPNOTSUPP; 
uverbs_dev = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*uverbs_dev), 
if <token> <answer> (!uverbs_dev) 
<token> -ENOMEM; <answer> return 
<token> = init_srcu_struct(&uverbs_dev->disassociate_srcu); <answer> ret 
if <token> { <answer> (ret) 
<token> -ENOMEM; <answer> return 
uverbs_dev->dev.class <token> &uverbs_class; <answer> = 
uverbs_dev->dev.parent <token> device->dev.parent; <answer> = 
uverbs_dev->dev.release = <token> <answer> ib_uverbs_release_dev; 
uverbs_dev->groups[0] <token> &dev_attr_group; <answer> = 
uverbs_dev->dev.groups = <token> <answer> uverbs_dev->groups; 
<token> 1); <answer> refcount_set(&uverbs_dev->refcount, 
<token> = RB_ROOT; <answer> uverbs_dev->xrcd_tree 
<token> device); <answer> rcu_assign_pointer(uverbs_dev->ib_dev, 
uverbs_dev->num_comp_vectors <token> device->num_comp_vectors; <answer> = 
devnum = ida_alloc_max(&uverbs_ida, <token> - 1, <answer> IB_UVERBS_MAX_DEVICES 
if (devnum < 0) <token> <answer> { 
<token> = -ENOMEM; <answer> ret 
<token> err; <answer> goto 
uverbs_dev->devnum <token> devnum; <answer> = 
if (devnum <token> IB_UVERBS_NUM_FIXED_MINOR) <answer> >= 
base = dynamic_uverbs_dev + devnum - <token> <answer> IB_UVERBS_NUM_FIXED_MINOR; 
base = IB_UVERBS_BASE_DEV + <token> <answer> devnum; 
<token> = ib_uverbs_create_uapi(device, uverbs_dev); <answer> ret 
if <token> <answer> (ret) 
goto <token> <answer> err_uapi; 
<token> = base; <answer> uverbs_dev->dev.devt 
dev_set_name(&uverbs_dev->dev, "uverbs%d", <token> <answer> uverbs_dev->devnum); 
device->ops.mmap ? &uverbs_mmap_fops <token> &uverbs_fops); <answer> : 
<token> = THIS_MODULE; <answer> uverbs_dev->cdev.owner 
ret <token> cdev_device_add(&uverbs_dev->cdev, &uverbs_dev->dev); <answer> = 
if <token> <answer> (ret) 
<token> err_uapi; <answer> goto 
ib_set_client_data(device, <token> uverbs_dev); <answer> &uverbs_client, 
return <token> <answer> 0; 
ida_free(&uverbs_ida, <token> <answer> devnum); 
<token> (refcount_dec_and_test(&uverbs_dev->refcount)) <answer> if 
return <token> <answer> ret; 
static void ib_uverbs_free_hw_resources(struct <token> *uverbs_dev, <answer> ib_uverbs_device 
struct <token> *ib_dev) <answer> ib_device 
struct <token> *file; <answer> ib_uverbs_file 
<token> RDMA_REMOVE_DRIVER_REMOVE); <answer> uverbs_destroy_ufile_hw(file, 
<token> ib_uverbs_release_file); <answer> kref_put(&file->ref, 
static void ib_uverbs_remove_one(struct <token> *device, void *client_data) <answer> ib_device 
<token> ib_uverbs_device *uverbs_dev = client_data; <answer> struct 
int wait_clients <token> 1; <answer> = 
<token> &uverbs_dev->dev); <answer> cdev_device_del(&uverbs_dev->cdev, 
ida_free(&uverbs_ida, <token> <answer> uverbs_dev->devnum); 
if (device->ops.disassociate_ucontext) <token> <answer> { 
ib_uverbs_free_hw_resources(uverbs_dev, <token> <answer> device); 
wait_clients = <token> <answer> 0; 
<token> (refcount_dec_and_test(&uverbs_dev->refcount)) <answer> if 
<token> (wait_clients) <answer> if 
<token> int __init ib_uverbs_init(void) <answer> static 
int <token> <answer> ret; 
ret <token> register_chrdev_region(IB_UVERBS_BASE_DEV, <answer> = 
if <token> { <answer> (ret) 
pr_err("user_verbs: couldn't <token> device number\n"); <answer> register 
goto <token> <answer> out; 
ret <token> alloc_chrdev_region(&dynamic_uverbs_dev, 0, <answer> = 
if (ret) <token> <answer> { 
pr_err("couldn't register dynamic device <token> <answer> number\n"); 
<token> out_alloc; <answer> goto 
ret = <token> <answer> class_register(&uverbs_class); 
if <token> { <answer> (ret) 
pr_err("user_verbs: couldn't create class <token> <answer> infiniband_verbs\n"); 
goto <token> <answer> out_chrdev; 
ret = class_create_file(&uverbs_class, <token> <answer> &class_attr_abi_version.attr); 
if (ret) <token> <answer> { 
<token> couldn't create abi_version attribute\n"); <answer> pr_err("user_verbs: 
<token> out_class; <answer> goto 
<token> = ib_register_client(&uverbs_client); <answer> ret 
if <token> { <answer> (ret) 
pr_err("user_verbs: couldn't register <token> <answer> client\n"); 
<token> out_class; <answer> goto 
return <token> <answer> 0; 
return <token> <answer> ret; 
<token> void __exit ib_uverbs_cleanup(void) <answer> static 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/math.h> 
#include <token> <answer> "ia_css_pipe_binarydesc.h" 
#include <token> <answer> "ia_css_frame_format.h" 
<token> "ia_css_pipe.h" <answer> #include 
#include <token> <answer> "ia_css_pipe_util.h" 
#include <token> <answer> "ia_css_util.h" 
<token> "ia_css_debug.h" <answer> #include 
#include <token> <answer> "sh_css_params.h" 
#include <token> <answer> <assert_support.h> 
bool cond = (out_w <token> num / den + delta > in_w) && <answer> * 
(out_w * num / den <= <token> && <answer> in_w) 
(out_h * num / den + <token> > in_h) && <answer> delta 
(out_h <token> num / den <= in_h); <answer> * 
<token> (cond) { <answer> if 
*bds_factor = <token> <answer> i; 
<token> 0; <answer> return 
<token> = pipe->config.input_effective_res; <answer> in_info->res 
in_info->padded_width <token> in_info->res.width; <answer> = 
in_info->raw_bit_depth = <token> <answer> ia_css_pipe_util_pipe_input_format_bpp(pipe); 
<token> (ia_css_util_is_input_format_yuv(pipe->stream->config.input_config.format)) <answer> if 
mode <token> IA_CSS_BINARY_MODE_COPY; <answer> = 
in_info->format = <token> <answer> IA_CSS_FRAME_FORMAT_RAW; 
<token> = out_info; <answer> out_infos[0] 
for (i = 1; i < <token> i++) <answer> IA_CSS_BINARY_MAX_OUTPUT_PORTS; 
out_infos[i] = <token> <answer> NULL; 
<token> mode, <answer> pipe_binarydesc_get_offline(pipe, 
preview_descr, in_info, <token> vf_info); <answer> out_infos, 
if <token> { <answer> (pipe->stream->config.online) 
preview_descr->online <token> pipe->stream->config.online; <answer> = 
<token> = <answer> preview_descr->two_ppc 
(pipe->stream->config.pixels_per_clock == <token> <answer> 2); 
preview_descr->stream_format <token> pipe->stream->config.input_config.format; <answer> = 
<token> (!pipe->extra_config.enable_fractional_ds) <answer> if 
preview_descr->bds_out_info = <token> <answer> bds_out_info; 
preview_descr->bds_out_info = <token> <answer> NULL; 
*out_info <token> *vf_info; <answer> = 
if (!pipe->extra_config.enable_fractional_ds) <token> <answer> { 
if <token> <answer> (ia_css_util_is_input_format_yuv(pipe->stream->config.input_config.format)) 
<token> = IA_CSS_BINARY_MODE_COPY; <answer> mode 
in_info->res <token> pipe->config.input_effective_res; <answer> = 
in_info->padded_width = <token> <answer> in_info->res.width; 
<token> = IA_CSS_FRAME_FORMAT_RAW; <answer> in_info->format 
in_info->raw_bit_depth = <token> <answer> ia_css_pipe_util_pipe_input_format_bpp(pipe); 
out_infos[0] = <token> <answer> out_info; 
for (i = 1; <token> < IA_CSS_BINARY_MAX_OUTPUT_PORTS; i++) <answer> i 
out_infos[i] = <token> <answer> NULL; 
<token> mode, <answer> pipe_binarydesc_get_offline(pipe, 
video_descr, in_info, <token> vf_info); <answer> out_infos, 
if (pipe->stream->config.online) <token> <answer> { 
video_descr->online <token> pipe->stream->config.online; <answer> = 
video_descr->two_ppc <token> <answer> = 
(pipe->stream->config.pixels_per_clock == <token> <answer> 2); 
<token> (mode == IA_CSS_BINARY_MODE_VIDEO) { <answer> if 
stream_dz_config <token> <answer> = 
((pipe->stream->isp_params_configs->dz_config.dx <token> <answer> != 
|| <token> != <answer> (pipe->stream->isp_params_configs->dz_config.dy 
video_descr->enable_dz = <token> <answer> pipe->config.enable_dz 
<token> stream_dz_config; <answer> || 
video_descr->dvs_env = <token> <answer> pipe->config.dvs_envelope; 
video_descr->enable_yuv_ds = <token> <answer> pipe->extra_config.enable_yuv_ds; 
video_descr->enable_high_speed <token> <answer> = 
video_descr->enable_dvs_6axis <token> <answer> = 
video_descr->enable_reduced_pipe <token> <answer> = 
video_descr->isp_pipe_version <token> pipe->config.isp_pipe_version; <answer> = 
video_descr->enable_fractional_ds <token> <answer> = 
video_descr->enable_dpc <token> <answer> = 
<token> = <answer> video_descr->enable_tnr 
<token> (pipe->extra_config.enable_raw_binning) { <answer> if 
if (pipe->config.bayer_ds_out_res.width != <token> && <answer> 0 
pipe->config.bayer_ds_out_res.height <token> 0) { <answer> != 
<token> = <answer> bds_out_info->res.width 
bds_out_info->res.height <token> <answer> = 
bds_out_info->padded_width <token> <answer> = 
err <token> <answer> = 
<token> bds_out_info->res, <answer> in_info->res, 
<token> (err) <answer> if 
<token> err; <answer> return 
} else <token> <answer> { 
bds_out_info->res.width <token> <answer> = 
in_info->res.width / <token> <answer> 2; 
<token> = <answer> bds_out_info->res.height 
in_info->res.height / <token> <answer> 2; 
<token> = <answer> bds_out_info->padded_width 
in_info->padded_width / <token> <answer> 2; 
video_descr->required_bds_factor <token> <answer> = 
<token> else { <answer> } 
<token> = in_info->res.width; <answer> bds_out_info->res.width 
bds_out_info->res.height <token> in_info->res.height; <answer> = 
<token> = in_info->padded_width; <answer> bds_out_info->padded_width 
<token> = <answer> video_descr->required_bds_factor 
<token> = video_descr->required_bds_factor; <answer> pipe->required_bds_factor 
if <token> <answer> (!pipe->extra_config.enable_fractional_ds) 
video_descr->bds_out_info = <token> <answer> bds_out_info; 
video_descr->bds_out_info <token> NULL; <answer> = 
video_descr->enable_fractional_ds <token> <answer> = 
video_descr->stream_config_left_padding = <token> <answer> stream_config_left_padding; 
return <token> <answer> err; 
void <token> <answer> ia_css_pipe_get_yuvscaler_binarydesc( 
struct ia_css_pipe <token> *const pipe, <answer> const 
struct ia_css_binary_descr <token> <answer> *yuv_scaler_descr, 
struct ia_css_frame_info <token> <answer> *in_info, 
struct <token> *out_info, <answer> ia_css_frame_info 
<token> ia_css_frame_info *internal_out_info, <answer> struct 
struct ia_css_frame_info <token> <answer> *vf_info) 
<token> ia_css_frame_info *out_infos[IA_CSS_BINARY_MAX_OUTPUT_PORTS]; <answer> struct 
<token> ia_css_frame_info *this_vf_info = NULL; <answer> struct 
assert(IA_CSS_BINARY_MAX_OUTPUT_PORTS <token> 2); <answer> == 
in_info->padded_width = <token> <answer> in_info->res.width; 
in_info->raw_bit_depth = <token> <answer> 0; 
ia_css_frame_info_set_width(in_info, in_info->res.width, <token> <answer> 0); 
out_infos[0] <token> out_info; <answer> = 
out_infos[1] <token> internal_out_info; <answer> = 
if (vf_info) <token> <answer> { 
this_vf_info = (vf_info->res.width == <token> && <answer> 0 
vf_info->res.height == <token> ? NULL : vf_info; <answer> 0) 
in_info, <token> this_vf_info); <answer> out_infos, 
yuv_scaler_descr->enable_fractional_ds <token> true; <answer> = 
void <token> <answer> ia_css_pipe_get_capturepp_binarydesc( 
struct <token> *const pipe, <answer> ia_css_pipe 
struct ia_css_binary_descr <token> <answer> *capture_pp_descr, 
struct <token> *in_info, <answer> ia_css_frame_info 
struct <token> *out_info, <answer> ia_css_frame_info 
<token> ia_css_frame_info *vf_info) <answer> struct 
<token> int i; <answer> unsigned 
<token> ia_css_frame_info *out_infos[IA_CSS_BINARY_MAX_OUTPUT_PORTS]; <answer> struct 
<token> (pipe->out_yuv_ds_input_info.res.width) <answer> if 
*in_info <token> pipe->out_yuv_ds_input_info; <answer> = 
<token> = *out_info; <answer> *in_info 
in_info->format = <token> <answer> IA_CSS_FRAME_FORMAT_YUV420; 
in_info->raw_bit_depth = <token> <answer> 0; 
<token> in_info->res.width, 0); <answer> ia_css_frame_info_set_width(in_info, 
out_infos[0] <token> out_info; <answer> = 
for <token> = 1; i < IA_CSS_BINARY_MAX_OUTPUT_PORTS; i++) <answer> (i 
out_infos[i] <token> NULL; <answer> = 
<token> out_infos, vf_info); <answer> in_info, 
capture_pp_descr->enable_capture_pp_bli <token> <answer> = 
capture_pp_descr->enable_fractional_ds <token> true; <answer> = 
capture_pp_descr->enable_xnr <token> <answer> = 
pipe->config.default_capture_config.enable_xnr <token> 0; <answer> != 
if <token> == IA_CSS_PIPE_VERSION_2_6_1) <answer> (pipe_version 
prim_descr->striped <token> false; <answer> = 
<token> = prim_descr->continuous && <answer> prim_descr->striped 
<token> || !pipe->stream->disable_cont_vf); <answer> (!pipe->stream->stop_copy_preview 
<token> ia_css_pipe_get_pre_gdc_binarydesc( <answer> void 
struct ia_css_pipe const *const <token> <answer> pipe, 
struct ia_css_binary_descr <token> <answer> *pre_gdc_descr, 
struct ia_css_frame_info <token> <answer> *in_info, 
struct <token> *out_info) <answer> ia_css_frame_info 
<token> int i; <answer> unsigned 
struct ia_css_frame_info <token> <answer> *out_infos[IA_CSS_BINARY_MAX_OUTPUT_PORTS]; 
*in_info = <token> <answer> *out_info; 
<token> = IA_CSS_FRAME_FORMAT_RAW; <answer> in_info->format 
in_info->raw_bit_depth = <token> <answer> ia_css_pipe_util_pipe_input_format_bpp(pipe); 
out_infos[0] <token> out_info; <answer> = 
for (i = 1; <token> < IA_CSS_BINARY_MAX_OUTPUT_PORTS; i++) <answer> i 
out_infos[i] <token> NULL; <answer> = 
pipe_binarydesc_get_offline(pipe, <token> <answer> IA_CSS_BINARY_MODE_PRE_ISP, 
<token> in_info, out_infos, NULL); <answer> pre_gdc_descr, 
pre_gdc_descr->isp_pipe_version = <token> <answer> pipe->config.isp_pipe_version; 
void <token> <answer> ia_css_pipe_get_gdc_binarydesc( 
struct ia_css_pipe <token> *const pipe, <answer> const 
<token> ia_css_binary_descr *gdc_descr, <answer> struct 
<token> ia_css_frame_info *in_info, <answer> struct 
struct <token> *out_info) <answer> ia_css_frame_info 
unsigned <token> i; <answer> int 
<token> ia_css_frame_info *out_infos[IA_CSS_BINARY_MAX_OUTPUT_PORTS]; <answer> struct 
*in_info <token> *out_info; <answer> = 
<token> = IA_CSS_FRAME_FORMAT_QPLANE6; <answer> in_info->format 
out_infos[0] = <token> <answer> out_info; 
for <token> = 1; i < IA_CSS_BINARY_MAX_OUTPUT_PORTS; i++) <answer> (i 
<token> = NULL; <answer> out_infos[i] 
pipe_binarydesc_get_offline(pipe, <token> <answer> IA_CSS_BINARY_MODE_GDC, 
gdc_descr, <token> out_infos, NULL); <answer> in_info, 
<token> ia_css_pipe_get_post_gdc_binarydesc( <answer> void 
struct ia_css_pipe <token> *const pipe, <answer> const 
<token> ia_css_binary_descr *post_gdc_descr, <answer> struct 
struct <token> *in_info, <answer> ia_css_frame_info 
struct ia_css_frame_info <token> <answer> *out_info, 
struct ia_css_frame_info <token> <answer> *vf_info) 
unsigned int <token> <answer> i; 
struct ia_css_frame_info <token> <answer> *out_infos[IA_CSS_BINARY_MAX_OUTPUT_PORTS]; 
*in_info = <token> <answer> *out_info; 
<token> = IA_CSS_FRAME_FORMAT_YUV420_16; <answer> in_info->format 
in_info->raw_bit_depth <token> 16; <answer> = 
out_infos[0] <token> out_info; <answer> = 
for (i = 1; <token> < IA_CSS_BINARY_MAX_OUTPUT_PORTS; i++) <answer> i 
out_infos[i] = <token> <answer> NULL; 
pipe_binarydesc_get_offline(pipe, <token> <answer> IA_CSS_BINARY_MODE_POST_ISP, 
post_gdc_descr, <token> out_infos, vf_info); <answer> in_info, 
post_gdc_descr->isp_pipe_version = <token> <answer> pipe->config.isp_pipe_version; 
void <token> <answer> ia_css_pipe_get_pre_de_binarydesc( 
struct ia_css_pipe const *const <token> <answer> pipe, 
struct ia_css_binary_descr <token> <answer> *pre_de_descr, 
struct <token> *in_info, <answer> ia_css_frame_info 
<token> ia_css_frame_info *out_info) <answer> struct 
<token> int i; <answer> unsigned 
<token> ia_css_frame_info *out_infos[IA_CSS_BINARY_MAX_OUTPUT_PORTS]; <answer> struct 
*in_info <token> *out_info; <answer> = 
in_info->format <token> IA_CSS_FRAME_FORMAT_RAW; <answer> = 
in_info->raw_bit_depth <token> ia_css_pipe_util_pipe_input_format_bpp(pipe); <answer> = 
out_infos[0] <token> out_info; <answer> = 
for (i = 1; i < <token> i++) <answer> IA_CSS_BINARY_MAX_OUTPUT_PORTS; 
out_infos[i] <token> NULL; <answer> = 
<token> (pipe->config.isp_pipe_version == IA_CSS_PIPE_VERSION_1) <answer> if 
<token> IA_CSS_BINARY_MODE_PRE_ISP, <answer> pipe_binarydesc_get_offline(pipe, 
pre_de_descr, <token> out_infos, NULL); <answer> in_info, 
else if (pipe->config.isp_pipe_version <token> IA_CSS_PIPE_VERSION_2_2) { <answer> == 
pipe_binarydesc_get_offline(pipe, <token> <answer> IA_CSS_BINARY_MODE_PRE_DE, 
<token> in_info, out_infos, NULL); <answer> pre_de_descr, 
<token> (pipe->stream->config.online) { <answer> if 
pre_de_descr->online = <token> <answer> true; 
<token> = <answer> pre_de_descr->two_ppc 
(pipe->stream->config.pixels_per_clock <token> 2); <answer> == 
pre_de_descr->stream_format <token> pipe->stream->config.input_config.format; <answer> = 
<token> = pipe->config.isp_pipe_version; <answer> pre_de_descr->isp_pipe_version 
void <token> <answer> ia_css_pipe_get_pre_anr_binarydesc( 
<token> ia_css_pipe const *const pipe, <answer> struct 
struct ia_css_binary_descr <token> <answer> *pre_anr_descr, 
struct ia_css_frame_info <token> <answer> *in_info, 
struct <token> *out_info) <answer> ia_css_frame_info 
unsigned <token> i; <answer> int 
<token> ia_css_frame_info *out_infos[IA_CSS_BINARY_MAX_OUTPUT_PORTS]; <answer> struct 
*in_info = <token> <answer> *out_info; 
in_info->format = <token> <answer> IA_CSS_FRAME_FORMAT_RAW; 
in_info->raw_bit_depth <token> ia_css_pipe_util_pipe_input_format_bpp(pipe); <answer> = 
out_infos[0] = <token> <answer> out_info; 
<token> (i = 1; i < IA_CSS_BINARY_MAX_OUTPUT_PORTS; i++) <answer> for 
out_infos[i] = <token> <answer> NULL; 
<token> IA_CSS_BINARY_MODE_PRE_ISP, <answer> pipe_binarydesc_get_offline(pipe, 
pre_anr_descr, in_info, <token> NULL); <answer> out_infos, 
if <token> { <answer> (pipe->stream->config.online) 
pre_anr_descr->online = <token> <answer> true; 
<token> = <answer> pre_anr_descr->two_ppc 
<token> == 2); <answer> (pipe->stream->config.pixels_per_clock 
<token> = pipe->stream->config.input_config.format; <answer> pre_anr_descr->stream_format 
<token> = pipe->config.isp_pipe_version; <answer> pre_anr_descr->isp_pipe_version 
<token> ia_css_pipe_get_anr_binarydesc( <answer> void 
<token> ia_css_pipe const *const pipe, <answer> struct 
struct ia_css_binary_descr <token> <answer> *anr_descr, 
struct <token> *in_info, <answer> ia_css_frame_info 
struct ia_css_frame_info <token> <answer> *out_info) 
unsigned <token> i; <answer> int 
struct ia_css_frame_info <token> <answer> *out_infos[IA_CSS_BINARY_MAX_OUTPUT_PORTS]; 
*in_info = <token> <answer> *out_info; 
in_info->format = <token> <answer> IA_CSS_FRAME_FORMAT_RAW; 
in_info->raw_bit_depth <token> ANR_ELEMENT_BITS; <answer> = 
out_infos[0] <token> out_info; <answer> = 
for <token> = 1; i < IA_CSS_BINARY_MAX_OUTPUT_PORTS; i++) <answer> (i 
out_infos[i] <token> NULL; <answer> = 
pipe_binarydesc_get_offline(pipe, <token> <answer> IA_CSS_BINARY_MODE_ANR, 
anr_descr, in_info, out_infos, <token> <answer> NULL); 
anr_descr->isp_pipe_version = <token> <answer> pipe->config.isp_pipe_version; 
void <token> <answer> ia_css_pipe_get_post_anr_binarydesc( 
struct <token> const *const pipe, <answer> ia_css_pipe 
<token> ia_css_binary_descr *post_anr_descr, <answer> struct 
struct <token> *in_info, <answer> ia_css_frame_info 
struct ia_css_frame_info <token> <answer> *out_info, 
struct <token> *vf_info) <answer> ia_css_frame_info 
unsigned int <token> <answer> i; 
struct ia_css_frame_info <token> <answer> *out_infos[IA_CSS_BINARY_MAX_OUTPUT_PORTS]; 
*in_info <token> *out_info; <answer> = 
in_info->format = <token> <answer> IA_CSS_FRAME_FORMAT_RAW; 
in_info->raw_bit_depth = <token> <answer> ANR_ELEMENT_BITS; 
<token> = out_info; <answer> out_infos[0] 
for (i <token> 1; i < IA_CSS_BINARY_MAX_OUTPUT_PORTS; i++) <answer> = 
out_infos[i] <token> NULL; <answer> = 
<token> IA_CSS_BINARY_MODE_POST_ISP, <answer> pipe_binarydesc_get_offline(pipe, 
post_anr_descr, <token> out_infos, vf_info); <answer> in_info, 
post_anr_descr->isp_pipe_version <token> pipe->config.isp_pipe_version; <answer> = 
void <token> <answer> ia_css_pipe_get_ldc_binarydesc( 
struct ia_css_pipe const *const <token> <answer> pipe, 
struct ia_css_binary_descr <token> <answer> *ldc_descr, 
<token> ia_css_frame_info *in_info, <answer> struct 
<token> ia_css_frame_info *out_info) <answer> struct 
unsigned <token> i; <answer> int 
<token> ia_css_frame_info *out_infos[IA_CSS_BINARY_MAX_OUTPUT_PORTS]; <answer> struct 
*in_info = <token> <answer> *out_info; 
in_info->format = <token> <answer> IA_CSS_FRAME_FORMAT_YUV420; 
<token> = 0; <answer> in_info->raw_bit_depth 
ia_css_frame_info_set_width(in_info, in_info->res.width, <token> <answer> 0); 
out_infos[0] = <token> <answer> out_info; 
for (i = 1; <token> < IA_CSS_BINARY_MAX_OUTPUT_PORTS; i++) <answer> i 
out_infos[i] <token> NULL; <answer> = 
<token> IA_CSS_BINARY_MODE_CAPTURE_PP, <answer> pipe_binarydesc_get_offline(pipe, 
ldc_descr, in_info, out_infos, <token> <answer> NULL); 
ldc_descr->enable_dvs_6axis <token> <answer> = 
<token> <media/v4l2-ctrls.h> <answer> #include 
#include <token> <answer> <media/v4l2-event.h> 
<token> <media/v4l2-subdev.h> <answer> #include 
<token> "vimc-common.h" <answer> #include 
<token> VIMC_LENS_MAX_FOCUS_POS 1023 <answer> #define 
<token> VIMC_LENS_MAX_FOCUS_STEP 1 <answer> #define 
struct vimc_lens_device <token> <answer> { 
struct vimc_ent_device <token> <answer> ved; 
<token> v4l2_subdev sd; <answer> struct 
struct <token> hdl; <answer> v4l2_ctrl_handler 
<token> focus_absolute; <answer> u32 
static const struct v4l2_subdev_core_ops vimc_lens_core_ops = <token> <answer> { 
.log_status <token> v4l2_ctrl_subdev_log_status, <answer> = 
.subscribe_event <token> v4l2_ctrl_subdev_subscribe_event, <answer> = 
.unsubscribe_event <token> v4l2_event_subdev_unsubscribe, <answer> = 
static const struct v4l2_subdev_ops vimc_lens_ops = <token> <answer> { 
.core <token> &vimc_lens_core_ops <answer> = 
<token> int vimc_lens_s_ctrl(struct v4l2_ctrl *ctrl) <answer> static 
struct vimc_lens_device <token> = <answer> *vlens 
container_of(ctrl->handler, struct <token> hdl); <answer> vimc_lens_device, 
if (ctrl->id == <token> { <answer> V4L2_CID_FOCUS_ABSOLUTE) 
vlens->focus_absolute = <token> <answer> ctrl->val; 
<token> 0; <answer> return 
return <token> <answer> -EINVAL; 
static const struct v4l2_ctrl_ops vimc_lens_ctrl_ops <token> { <answer> = 
.s_ctrl = <token> <answer> vimc_lens_s_ctrl, 
static struct vimc_ent_device *vimc_lens_add(struct <token> *vimc, <answer> vimc_device 
const char <token> <answer> *vcfg_name) 
struct v4l2_device *v4l2_dev <token> &vimc->v4l2_dev; <answer> = 
<token> vimc_lens_device *vlens; <answer> struct 
int <token> <answer> ret; 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/types.h> 
<token> <linux/mm.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
<token> <linux/string.h> <answer> #include 
#include <token> <answer> <linux/pci.h> 
#include <token> <answer> <linux/dma-mapping.h> 
<token> <linux/vmalloc.h> <answer> #include 
<token> <linux/suspend.h> <answer> #include 
#include <token> <answer> <linux/memblock.h> 
#include <token> <answer> <linux/gfp.h> 
#include <token> <answer> <linux/kmemleak.h> 
<token> <linux/of_address.h> <answer> #include 
#include <token> <answer> <asm/io.h> 
#include <token> <answer> <asm/iommu.h> 
<token> <asm/pci-bridge.h> <answer> #include 
#include <token> <answer> <asm/machdep.h> 
<token> <asm/cacheflush.h> <answer> #include 
<token> <asm/ppc-pci.h> <answer> #include 
#include <token> <answer> "dart.h" 
<token> = 0; <answer> limit 
inv_bit = dart_is_u4 <token> DART_CNTL_U4_FLUSHTLB : DART_CNTL_U3_FLUSHTLB; <answer> ? 
l = <token> <answer> 0; 
reg <token> DART_IN(DART_CNTL); <answer> = 
<token> |= inv_bit; <answer> reg 
<token> reg); <answer> DART_OUT(DART_CNTL, 
while ((DART_IN(DART_CNTL) & inv_bit) && l < (1L << <token> <answer> limit)) 
if <token> == (1L << limit)) { <answer> (l 
if (limit < 4) <token> <answer> { 
reg <token> DART_IN(DART_CNTL); <answer> = 
reg &= <token> <answer> ~inv_bit; 
DART_OUT(DART_CNTL, <token> <answer> reg); 
goto <token> <answer> retry; 
} <token> <answer> else 
panic("DART: TLB did not flush after waiting a long <token> <answer> " 
"time. Buggy U3 <token> <answer> ?"); 
<token> flags); <answer> spin_unlock_irqrestore(&invalidate_lock, 
static inline <token> dart_tlb_invalidate_one(unsigned long bus_rpn) <answer> void 
unsigned <token> reg; <answer> int 
unsigned <token> l, limit; <answer> int 
unsigned long <token> <answer> flags; 
<token> flags); <answer> spin_lock_irqsave(&invalidate_lock, 
reg = DART_CNTL_U4_ENABLE | <token> | <answer> DART_CNTL_U4_IONE 
<token> & DART_CNTL_U4_IONE_MASK); <answer> (bus_rpn 
DART_OUT(DART_CNTL, <token> <answer> reg); 
limit = <token> <answer> 0; 
<token> = 0; <answer> l 
while ((DART_IN(DART_CNTL) & DART_CNTL_U4_IONE) && l <token> (1L << limit)) { <answer> < 
if (l == <token> << limit)) { <answer> (1L 
<token> (limit < 4) { <answer> if 
goto <token> <answer> wait_more; 
<token> else <answer> } 
panic("DART: TLB did not flush after waiting <token> long " <answer> a 
"time. Buggy U4 <token> <answer> ?"); 
<token> flags); <answer> spin_unlock_irqrestore(&invalidate_lock, 
static void <token> int *base, unsigned int count) <answer> dart_cache_sync(unsigned 
unsigned long start <token> (unsigned long)base; <answer> = 
unsigned long end = start + (count + 1) * sizeof(unsigned <token> <answer> int); 
unsigned <token> tmp; <answer> int 
asm volatile(" <token> <answer> sync;" 
<token> isync;" <answer> " 
" <token> 0,%1;" <answer> dcbf 
<token> sync;" <answer> " 
" <token> <answer> isync;" 
" lwz <token> <answer> %0,0(%1);" 
" isync" : "=r" (tmp) <token> "r" (end) : "memory"); <answer> : 
static void dart_flush(struct iommu_table <token> <answer> *tbl) 
<token> (dart_dirty) { <answer> if 
<token> = 0; <answer> dart_dirty 
static int dart_build(struct iommu_table *tbl, <token> index, <answer> long 
<token> npages, unsigned long uaddr, <answer> long 
enum dma_data_direction <token> <answer> direction, 
<token> long attrs) <answer> unsigned 
unsigned int *dp, <token> <answer> *orig_dp; 
<token> int rpn; <answer> unsigned 
long <token> <answer> l; 
DBG("dart: build at: %lx, <token> addr: %x\n", index, npages, uaddr); <answer> %lx, 
orig_dp <token> dp = ((unsigned int*)tbl->it_base) + index; <answer> = 
l <token> npages; <answer> = 
<token> (l--) { <answer> while 
rpn = __pa(uaddr) <token> DART_PAGE_SHIFT; <answer> >> 
*(dp++) = <token> | (rpn & DARTMAP_RPNMASK); <answer> DARTMAP_VALID 
uaddr <token> DART_PAGE_SIZE; <answer> += 
<token> npages); <answer> dart_cache_sync(orig_dp, 
<token> (dart_is_u4) { <answer> if 
rpn <token> index; <answer> = 
<token> (npages--) <answer> while 
} <token> { <answer> else 
dart_dirty = <token> <answer> 1; 
<token> 0; <answer> return 
static void dart_free(struct iommu_table *tbl, <token> index, long npages) <answer> long 
unsigned int *dp, <token> <answer> *orig_dp; 
long <token> = npages; <answer> orig_npages 
DBG("dart: free at: <token> %lx\n", index, npages); <answer> %lx, 
orig_dp = <token> = ((unsigned int *)tbl->it_base) + index; <answer> dp 
<token> (npages--) <answer> while 
*(dp++) = <token> <answer> dart_emptyval; 
dart_cache_sync(orig_dp, <token> <answer> orig_npages); 
static void __init <token> <answer> allocate_dart(void) 
<token> long tmp; <answer> unsigned 
dart_tablebase = <token> SZ_16M, <answer> memblock_alloc_try_nid_raw(SZ_16M, 
<token> SZ_2G, <answer> MEMBLOCK_LOW_LIMIT, 
if <token> <answer> (!dart_tablebase) 
panic("Failed to allocate 16MB <token> 2GB for DART table\n"); <answer> below 
tmp = <token> DART_PAGE_SIZE); <answer> memblock_phys_alloc(DART_PAGE_SIZE, 
if <token> <answer> (!tmp) 
panic("DART: table <token> failed\n"); <answer> allocation 
<token> = DARTMAP_VALID | ((tmp >> DART_PAGE_SHIFT) & <answer> dart_emptyval 
printk(KERN_INFO "DART table allocated at: <token> dart_tablebase); <answer> %p\n", 
static int <token> dart_init(struct device_node *dart_node) <answer> __init 
unsigned int <token> <answer> i; 
unsigned long <token> size; <answer> base, 
struct resource <token> <answer> r; 
if (!iommu_force_on <token> memblock_end_of_DRAM() <= 0x40000000ull) <answer> && 
<token> -ENODEV; <answer> return 
set_bit(iommu_table_dart.it_size - 1, <token> <answer> iommu_table_dart.it_map); 
static void pci_dma_bus_setup_dart(struct <token> *bus) <answer> pci_bus 
<token> (!iommu_table_dart_inited) { <answer> if 
<token> = 1; <answer> iommu_table_dart_inited 
static bool dart_device_on_pcie(struct device <token> <answer> *dev) 
struct <token> *np = of_node_get(dev->of_node); <answer> device_node 
<token> { <answer> while(np) 
if <token> "U4-pcie") || <answer> (of_device_is_compatible(np, 
of_device_is_compatible(np, "u4-pcie")) <token> <answer> { 
<token> true; <answer> return 
np = <token> <answer> of_get_next_parent(np); 
return <token> <answer> false; 
static void pci_dma_dev_setup_dart(struct <token> *dev) <answer> pci_dev 
<token> (dart_is_u4 && dart_device_on_pcie(&dev->dev)) <answer> if 
<token> = DART_U4_BYPASS_BASE; <answer> dev->dev.archdata.dma_offset 
<token> &iommu_table_dart); <answer> set_iommu_table_base(&dev->dev, 
static bool iommu_bypass_supported_dart(struct pci_dev *dev, <token> mask) <answer> u64 
return dart_is_u4 <token> <answer> && 
dart_device_on_pcie(&dev->dev) <token> <answer> && 
mask <token> DMA_BIT_MASK(40); <answer> >= 
void __init iommu_init_early_dart(struct <token> *controller_ops) <answer> pci_controller_ops 
struct <token> *dn; <answer> device_node 
controller_ops->dma_dev_setup = <token> <answer> pci_dma_dev_setup_dart; 
controller_ops->dma_bus_setup <token> pci_dma_bus_setup_dart; <answer> = 
<token> = iommu_bypass_supported_dart; <answer> controller_ops->iommu_bypass_supported 
<token> <linux/io.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/pm_domain.h> 
<token> <linux/pm_runtime.h> <answer> #include 
<token> "clk.h" <answer> #include 
<token> "clk-exynos5-subcmu.h" <answer> #include 
static struct samsung_clk_provider <token> <answer> *ctx; 
<token> const struct exynos5_subcmu_info **cmu; <answer> static 
static <token> nr_cmus; <answer> int 
static <token> exynos5_subcmu_clk_save(void __iomem *base, <answer> void 
struct exynos5_subcmu_reg_dump <token> <answer> *rd, 
<token> int num_regs) <answer> unsigned 
for (; num_regs <token> 0; --num_regs, ++rd) { <answer> > 
<token> = readl(base + rd->offset); <answer> rd->save 
writel((rd->save & ~rd->mask) | rd->value, base <token> rd->offset); <answer> + 
rd->save &= <token> <answer> rd->mask; 
<token> void exynos5_subcmu_clk_restore(void __iomem *base, <answer> static 
struct exynos5_subcmu_reg_dump <token> <answer> *rd, 
unsigned int <token> <answer> num_regs) 
for (; num_regs <token> 0; --num_regs, ++rd) <answer> > 
writel((readl(base + <token> & ~rd->mask) | rd->save, <answer> rd->offset) 
base + <token> <answer> rd->offset); 
static void exynos5_subcmu_defer_gate(struct samsung_clk_provider <token> <answer> *ctx, 
const <token> samsung_gate_clock *list, int nr_clk) <answer> struct 
<token> (nr_clk--) <answer> while 
samsung_clk_add_lookup(ctx, ERR_PTR(-EPROBE_DEFER), <token> <answer> list++->id); 
void exynos5_subcmus_init(struct samsung_clk_provider <token> int _nr_cmus, <answer> *_ctx, 
<token> struct exynos5_subcmu_info **_cmu) <answer> const 
<token> = _ctx; <answer> ctx 
cmu <token> _cmu; <answer> = 
nr_cmus = <token> <answer> _nr_cmus; 
<token> (; _nr_cmus--; _cmu++) { <answer> for 
<token> (*_cmu)->gate_clks, <answer> exynos5_subcmu_defer_gate(ctx, 
exynos5_subcmu_clk_save(ctx->reg_base, <token> <answer> (*_cmu)->suspend_regs, 
static int __maybe_unused exynos5_subcmu_suspend(struct <token> *dev) <answer> device 
struct exynos5_subcmu_info *info = <token> <answer> dev_get_drvdata(dev); 
<token> long flags; <answer> unsigned 
spin_lock_irqsave(&ctx->lock, <token> <answer> flags); 
<token> info->suspend_regs, <answer> exynos5_subcmu_clk_save(ctx->reg_base, 
spin_unlock_irqrestore(&ctx->lock, <token> <answer> flags); 
<token> 0; <answer> return 
static int __maybe_unused exynos5_subcmu_resume(struct device <token> <answer> *dev) 
struct exynos5_subcmu_info <token> = dev_get_drvdata(dev); <answer> *info 
unsigned <token> flags; <answer> long 
spin_lock_irqsave(&ctx->lock, <token> <answer> flags); 
<token> info->suspend_regs, <answer> exynos5_subcmu_clk_restore(ctx->reg_base, 
<token> flags); <answer> spin_unlock_irqrestore(&ctx->lock, 
return <token> <answer> 0; 
static <token> __init exynos5_subcmu_probe(struct platform_device *pdev) <answer> int 
struct device *dev <token> &pdev->dev; <answer> = 
<token> exynos5_subcmu_info *info = dev_get_drvdata(dev); <answer> struct 
ctx->dev <token> dev; <answer> = 
<token> info->div_clks, info->nr_div_clks); <answer> samsung_clk_register_div(ctx, 
samsung_clk_register_gate(ctx, info->gate_clks, <token> <answer> info->nr_gate_clks); 
<token> = NULL; <answer> ctx->dev 
<token> 0; <answer> return 
<token> const struct dev_pm_ops exynos5_subcmu_pm_ops = { <answer> static 
<token> NULL) <answer> exynos5_subcmu_resume, 
static <token> platform_driver exynos5_subcmu_driver __refdata = { <answer> struct 
<token> = { <answer> .driver 
<token> = "exynos5-subcmu", <answer> .name 
.suppress_bind_attrs <token> true, <answer> = 
.pm <token> &exynos5_subcmu_pm_ops, <answer> = 
<token> = exynos5_subcmu_probe, <answer> .probe 
static <token> __init exynos5_clk_register_subcmu(struct device *parent, <answer> int 
const <token> exynos5_subcmu_info *info, <answer> struct 
<token> device_node *pd_node) <answer> struct 
struct of_phandle_args genpdspec <token> { .np = pd_node }; <answer> = 
struct <token> *pdev; <answer> platform_device 
<token> ret; <answer> int 
pdev <token> platform_device_alloc("exynos5-subcmu", PLATFORM_DEVID_AUTO); <answer> = 
if <token> <answer> (!pdev) 
<token> -ENOMEM; <answer> return 
pdev->dev.parent <token> parent; <answer> = 
<token> (void *)info); <answer> platform_set_drvdata(pdev, 
<token> &pdev->dev); <answer> of_genpd_add_device(&genpdspec, 
<token> = platform_device_add(pdev); <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ret; 
static int __init exynos5_clk_probe(struct <token> *pdev) <answer> platform_device 
struct device_node <token> <answer> *np; 
<token> char *name; <answer> const 
<token> i; <answer> int 
<token> NULL, "samsung,exynos4210-pd") { <answer> for_each_compatible_node(np, 
if (of_property_read_string(np, "label", <token> < 0) <answer> &name) 
for (i = <token> i < nr_cmus; i++) <answer> 0; 
if (strcmp(cmu[i]->pd_name, name) <token> 0) <answer> == 
cmu[i], <token> <answer> np); 
<token> 0; <answer> return 
static const struct of_device_id <token> = { <answer> exynos5_clk_of_match[] 
<token> .compatible = "samsung,exynos5250-clock", }, <answer> { 
{ <token> = "samsung,exynos5420-clock", }, <answer> .compatible 
<token> .compatible = "samsung,exynos5800-clock", }, <answer> { 
<token> }, <answer> { 
static struct <token> exynos5_clk_driver __refdata = { <answer> platform_driver 
.driver = <token> <answer> { 
.name <token> "exynos5-clock", <answer> = 
.of_match_table = <token> <answer> exynos5_clk_of_match, 
.suppress_bind_attrs = <token> <answer> true, 
.probe <token> exynos5_clk_probe, <answer> = 
<token> int __init exynos5_clk_drv_init(void) <answer> static 
<token> 0; <answer> return 
#include <token> <answer> <linux/fs.h> 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/proc_fs.h> 
<token> <linux/seq_file.h> <answer> #include 
#include <token> <answer> <linux/utsname.h> 
<token> "internal.h" <answer> #include 
<token> int version_proc_show(struct seq_file *m, void *v) <answer> static 
<token> linux_proc_banner, <answer> seq_printf(m, 
<token> 0; <answer> return 
<token> int __init proc_version_init(void) <answer> static 
struct proc_dir_entry <token> <answer> *pde; 
pde <token> proc_create_single("version", 0, NULL, version_proc_show); <answer> = 
<token> 0; <answer> return 
<token> "ieee754sp.h" <answer> #include 
union ieee754sp ieee754sp_neg(union <token> x) <answer> ieee754sp 
<token> ieee754sp y; <answer> union 
if <token> { <answer> (ieee754_csr.abs2008) 
y <token> x; <answer> = 
SPSIGN(y) <token> !SPSIGN(x); <answer> = 
<token> else { <answer> } 
<token> int oldrm; <answer> unsigned 
oldrm <token> ieee754_csr.rm; <answer> = 
<token> = FPU_CSR_RD; <answer> ieee754_csr.rm 
y <token> ieee754sp_sub(ieee754sp_zero(0), x); <answer> = 
<token> = oldrm; <answer> ieee754_csr.rm 
<token> y; <answer> return 
union ieee754sp ieee754sp_abs(union ieee754sp <token> <answer> x) 
union <token> y; <answer> ieee754sp 
if <token> { <answer> (ieee754_csr.abs2008) 
y = <token> <answer> x; 
SPSIGN(y) = <token> <answer> 0; 
} else <token> <answer> { 
unsigned <token> oldrm; <answer> int 
oldrm = <token> <answer> ieee754_csr.rm; 
ieee754_csr.rm <token> FPU_CSR_RD; <answer> = 
if <token> <answer> (SPSIGN(x)) 
y = <token> x); <answer> ieee754sp_sub(ieee754sp_zero(0), 
y = <token> x); <answer> ieee754sp_add(ieee754sp_zero(0), 
ieee754_csr.rm <token> oldrm; <answer> = 
<token> y; <answer> return 
#include <token> <answer> "cx88.h" 
<token> <linux/init.h> <answer> #include 
<token> <linux/list.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/kmod.h> 
<token> <linux/sound.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/pci.h> 
#include <token> <answer> <linux/delay.h> 
<token> <linux/videodev2.h> <answer> #include 
#include <token> <answer> <linux/mutex.h> 
#include <token> <answer> <media/v4l2-common.h> 
#include <token> <answer> <media/v4l2-ioctl.h> 
MODULE_DESCRIPTION("v4l2 <token> module for cx2388x based TV cards"); <answer> driver 
MODULE_AUTHOR("Gerd Knorr <kraxel@bytesex.org> [SuSE <token> <answer> Labs]"); 
MODULE_LICENSE("GPL <token> <answer> v2"); 
static __le32 <token> *rp, struct scatterlist *sglist, <answer> *cx88_risc_field(__le32 
unsigned int offset, u32 <token> <answer> sync_line, 
unsigned int bpl, unsigned <token> padding, <answer> int 
unsigned int lines, <token> int lpi, bool jump) <answer> unsigned 
struct <token> *sg; <answer> scatterlist 
unsigned int line, <token> sol; <answer> todo, 
if <token> { <answer> (jump) 
(*rp++) <token> cpu_to_le32(RISC_JUMP); <answer> = 
(*rp++) = <token> <answer> 0; 
instructions = fields * <token> + ((bpl + padding) * lines) / <answer> (1 
PAGE_SIZE <token> lines); <answer> + 
instructions <token> 4; <answer> += 
<token> = instructions * 8; <answer> risc->size 
<token> = 0; <answer> risc->dma 
risc->cpu <token> dma_alloc_coherent(&pci->dev, risc->size, &risc->dma, <answer> = 
<token> (!risc->cpu) <answer> if 
return <token> <answer> -ENOMEM; 
instructions = 1 + (bpl * lines) / <token> + lines; <answer> PAGE_SIZE 
instructions += <token> <answer> 3; 
risc->size <token> instructions * 8; <answer> = 
risc->dma = <token> <answer> 0; 
<token> = dma_alloc_coherent(&pci->dev, risc->size, &risc->dma, <answer> risc->cpu 
if <token> <answer> (!risc->cpu) 
return <token> <answer> -ENOMEM; 
<token> struct sram_channel cx88_sram_channels[] = { <answer> const 
[SRAM_CH21] <token> { <answer> = 
<token> = "video y / packed", <answer> .name 
.cmds_start = <token> <answer> 0x180040, 
<token> = 0x180400, <answer> .ctrl_start 
.cdt = <token> + 64, <answer> 0x180400 
<token> = 0x180c00, <answer> .fifo_start 
.fifo_size = <token> <answer> 0x002800, 
.ptr1_reg <token> MO_DMA21_PTR1, <answer> = 
<token> = MO_DMA21_PTR2, <answer> .ptr2_reg 
<token> = MO_DMA21_CNT1, <answer> .cnt1_reg 
<token> = MO_DMA21_CNT2, <answer> .cnt2_reg 
[SRAM_CH22] <token> { <answer> = 
.name = "video <token> <answer> u", 
.cmds_start = <token> <answer> 0x180080, 
.ctrl_start = <token> <answer> 0x1804a0, 
<token> = 0x1804a0 + 64, <answer> .cdt 
.fifo_start = <token> <answer> 0x183400, 
<token> = 0x000800, <answer> .fifo_size 
.ptr1_reg <token> MO_DMA22_PTR1, <answer> = 
.ptr2_reg <token> MO_DMA22_PTR2, <answer> = 
.cnt1_reg = <token> <answer> MO_DMA22_CNT1, 
.cnt2_reg = <token> <answer> MO_DMA22_CNT2, 
[SRAM_CH23] <token> { <answer> = 
<token> = "video v", <answer> .name 
<token> = 0x1800c0, <answer> .cmds_start 
.ctrl_start <token> 0x180540, <answer> = 
.cdt = 0x180540 + <token> <answer> 64, 
.fifo_start <token> 0x183c00, <answer> = 
.fifo_size = <token> <answer> 0x000800, 
.ptr1_reg <token> MO_DMA23_PTR1, <answer> = 
<token> = MO_DMA23_PTR2, <answer> .ptr2_reg 
<token> = MO_DMA23_CNT1, <answer> .cnt1_reg 
<token> = MO_DMA23_CNT2, <answer> .cnt2_reg 
<token> = { <answer> [SRAM_CH24] 
<token> = "vbi", <answer> .name 
<token> = 0x180100, <answer> .cmds_start 
.ctrl_start = <token> <answer> 0x1805e0, 
.cdt = 0x1805e0 + <token> <answer> 64, 
<token> = 0x184400, <answer> .fifo_start 
.fifo_size <token> 0x001000, <answer> = 
.ptr1_reg = <token> <answer> MO_DMA24_PTR1, 
.ptr2_reg = <token> <answer> MO_DMA24_PTR2, 
<token> = MO_DMA24_CNT1, <answer> .cnt1_reg 
<token> = MO_DMA24_CNT2, <answer> .cnt2_reg 
[SRAM_CH25] = <token> <answer> { 
<token> = "audio from", <answer> .name 
.cmds_start = <token> <answer> 0x180140, 
.ctrl_start <token> 0x180680, <answer> = 
<token> = 0x180680 + 64, <answer> .cdt 
.fifo_start = <token> <answer> 0x185400, 
<token> = 0x001000, <answer> .fifo_size 
.ptr1_reg = <token> <answer> MO_DMA25_PTR1, 
.ptr2_reg <token> MO_DMA25_PTR2, <answer> = 
<token> = MO_DMA25_CNT1, <answer> .cnt1_reg 
<token> = MO_DMA25_CNT2, <answer> .cnt2_reg 
[SRAM_CH26] <token> { <answer> = 
.name = "audio <token> <answer> to", 
<token> = 0x180180, <answer> .cmds_start 
.ctrl_start <token> 0x180720, <answer> = 
<token> 35468950; <answer> return 
static inline unsigned int <token> norm) <answer> norm_htotal(v4l2_std_id 
unsigned int fsc4 = <token> / 2; <answer> norm_fsc8(norm) 
return <token> <answer> 0; 
int cx88_set_tvnorm(struct cx88_core <token> v4l2_std_id norm) <answer> *core, 
<token> fsc8; <answer> u32 
<token> adc_clock; <answer> u32 
u32 <token> <answer> vdec_clock; 
u32 step_db, <token> <answer> step_dr; 
u64 <token> <answer> tmp64; 
<token> bdelay, agcdelay, htotal; <answer> u32 
<token> cxiformat, cxoformat; <answer> u32 
<token> (norm == core->tvnorm) <answer> if 
return <token> <answer> 0; 
if <token> && (vb2_is_busy(&core->v4ldev->vb2_vidq) || <answer> (core->v4ldev 
<token> -EBUSY; <answer> return 
if (core->dvbdev <token> vb2_is_busy(&core->dvbdev->vb2_mpegq)) <answer> && 
return <token> <answer> -EBUSY; 
<token> = norm; <answer> core->tvnorm 
<token> = norm_fsc8(norm); <answer> fsc8 
<token> = xtal; <answer> adc_clock 
vdec_clock <token> fsc8; <answer> = 
step_db = <token> <answer> fsc8; 
<token> = fsc8; <answer> step_dr 
if <token> & V4L2_STD_NTSC_M_JP) { <answer> (norm 
<token> = VideoFormatNTSCJapan; <answer> cxiformat 
cxoformat = <token> <answer> 0x181f0008; 
} <token> if (norm & V4L2_STD_NTSC_443) { <answer> else 
<token> = VideoFormatNTSC443; <answer> cxiformat 
cxoformat = <token> <answer> 0x181f0008; 
<token> else if (norm & V4L2_STD_PAL_M) { <answer> } 
cxiformat <token> VideoFormatPALM; <answer> = 
cxoformat = <token> <answer> 0x1c1f0008; 
} else if (norm <token> V4L2_STD_PAL_N) { <answer> & 
cxiformat <token> VideoFormatPALN; <answer> = 
cxoformat <token> 0x1c1f0008; <answer> = 
} else if (norm & <token> { <answer> V4L2_STD_PAL_Nc) 
cxiformat <token> VideoFormatPALNC; <answer> = 
cxoformat = <token> <answer> 0x1c1f0008; 
<token> else if (norm & V4L2_STD_PAL_60) { <answer> } 
<token> = VideoFormatPAL60; <answer> cxiformat 
cxoformat = <token> <answer> 0x181f0008; 
} else if <token> & V4L2_STD_NTSC) { <answer> (norm 
<token> = VideoFormatNTSC; <answer> cxiformat 
cxoformat = <token> <answer> 0x181f0008; 
} else if (norm & <token> { <answer> V4L2_STD_SECAM) 
step_db <token> 4250000 * 8; <answer> = 
step_dr <token> 4406250 * 8; <answer> = 
cxiformat <token> VideoFormatSECAM; <answer> = 
cxoformat <token> 0x181f0008; <answer> = 
cx_andor(MO_INPUT_FORMAT, <token> <answer> 0x40f, 
norm & V4L2_STD_SECAM ? cxiformat : cxiformat <token> 0x400); <answer> | 
dprintk(1, "set_tvnorm: <token> 0x%08x [old=0x%08x]\n", <answer> MO_OUTPUT_FORMAT 
cxoformat, <token> <answer> cx_read(MO_OUTPUT_FORMAT)); 
cx_write(MO_OUTPUT_FORMAT, <token> <answer> cxoformat); 
<token> = adc_clock * (u64)(1 << 17); <answer> tmp64 
<token> vdec_clock); <answer> do_div(tmp64, 
dprintk(1, "set_tvnorm: <token> 0x%08x [old=0x%08x]\n", <answer> MO_SCONV_REG 
<token> cx_read(MO_SCONV_REG)); <answer> (u32)tmp64, 
cx_write(MO_SCONV_REG, <token> <answer> (u32)tmp64); 
<token> = step_db * (u64)(1 << 22); <answer> tmp64 
<token> vdec_clock); <answer> do_div(tmp64, 
dprintk(1, "set_tvnorm: MO_SUB_STEP 0x%08x <token> <answer> [old=0x%08x]\n", 
(u32)tmp64, <token> <answer> cx_read(MO_SUB_STEP)); 
<token> (u32)tmp64); <answer> cx_write(MO_SUB_STEP, 
<token> = step_dr * (u64)(1 << 22); <answer> tmp64 
do_div(tmp64, <token> <answer> vdec_clock); 
dprintk(1, <token> MO_SUB_STEP_DR 0x%08x [old=0x%08x]\n", <answer> "set_tvnorm: 
<token> cx_read(MO_SUB_STEP_DR)); <answer> (u32)tmp64, 
<token> (u32)tmp64); <answer> cx_write(MO_SUB_STEP_DR, 
bdelay = vdec_clock * 65 / 20000000 <token> 21; <answer> + 
agcdelay = vdec_clock * 68 / <token> + 15; <answer> 20000000 
"set_tvnorm: <token> 0x%08x [old=0x%08x,bdelay=%d,agcdelay=%d]\n", <answer> MO_AGC_BURST 
<token> << 8) | agcdelay, cx_read(MO_AGC_BURST), <answer> (bdelay 
<token> agcdelay); <answer> bdelay, 
<token> (bdelay << 8) | agcdelay); <answer> cx_write(MO_AGC_BURST, 
tmp64 = norm_htotal(norm) * <token> <answer> (u64)vdec_clock; 
do_div(tmp64, <token> <answer> fsc8); 
htotal <token> (u32)tmp64; <answer> = 
"set_tvnorm: MO_HTOTAL <token> [old=0x%08x,htotal=%d]\n", <answer> 0x%08x 
<token> cx_read(MO_HTOTAL), (u32)tmp64); <answer> htotal, 
cx_andor(MO_HTOTAL, <token> htotal); <answer> 0x07ff, 
cx_write(MO_VBI_PACKET, (10 << 11) <token> norm_vbipack(norm)); <answer> | 
cx88_set_scale(core, <token> 240, V4L2_FIELD_INTERLACED); <answer> 320, 
call_all(core, <token> s_std, norm); <answer> video, 
v4l2_ctrl_grab(core->chroma_agc, cxiformat == <token> <answer> VideoFormatSECAM); 
<token> 0; <answer> return 
vfd->v4l2_dev = <token> <answer> &core->v4l2_dev; 
vfd->dev_parent <token> &pci->dev; <answer> = 
<token> = video_device_release_empty; <answer> vfd->release 
vfd->lock <token> &core->lock; <answer> = 
<token> sizeof(vfd->name), "%s %s (%s)", <answer> snprintf(vfd->name, 
core->name, type, <token> <answer> core->board.name); 
struct cx88_core *cx88_core_get(struct pci_dev <token> <answer> *pci) 
struct <token> *core; <answer> cx88_core 
list_for_each_entry(core, &cx88_devlist, devlist) <token> <answer> { 
if (pci->bus->number <token> core->pci_bus) <answer> != 
<token> (PCI_SLOT(pci->devfn) != core->pci_slot) <answer> if 
if (cx88_get_resources(core, <token> != 0) { <answer> pci) 
<token> NULL; <answer> return 
<token> core; <answer> return 
core = <token> cx88_devcount); <answer> cx88_core_create(pci, 
if (core) <token> <answer> { 
list_add_tail(&core->devlist, <token> <answer> &cx88_devlist); 
<token> core; <answer> return 
void <token> cx88_core *core, struct pci_dev *pci) <answer> cx88_core_put(struct 
<token> 0), <answer> release_mem_region(pci_resource_start(pci, 
<token> 0)); <answer> pci_resource_len(pci, 
if <token> <answer> (!refcount_dec_and_test(&core->refcount)) 
<token> (core->i2c_rc == 0) { <answer> if 
<token> <linux/iopoll.h> <answer> #include 
<token> "main.h" <answer> #include 
#include <token> <answer> "efuse.h" 
<token> "reg.h" <answer> #include 
#include <token> <answer> "debug.h" 
#define RTW_EFUSE_BANK_WIFI <token> <answer> 0x0 
static void <token> rtw_dev *rtwdev) <answer> switch_efuse_bank(struct 
rtw_write32_mask(rtwdev, <token> BIT_MASK_EFUSE_BANK_SEL, <answer> REG_LDO_EFUSE_CTRL, 
#define invalid_efuse_header(hdr1, <token> \ <answer> hdr2) 
((hdr1) == 0xff || (((hdr1) & 0x1f) <token> 0xf && (hdr2) == 0xff)) <answer> == 
#define <token> i) \ <answer> invalid_efuse_content(word_en, 
(((word_en) & BIT(i)) <token> 0x0) <answer> != 
#define get_efuse_blk_idx_2_byte(hdr1, <token> \ <answer> hdr2) 
((((hdr2) & 0xf0) >> 1) <token> (((hdr1) >> 5) & 0x07)) <answer> | 
#define get_efuse_blk_idx_1_byte(hdr1) <token> <answer> \ 
(((hdr1) <token> 0xf0) >> 4) <answer> & 
<token> block_idx_to_logical_idx(blk_idx, i) \ <answer> #define 
(((blk_idx) << 3) + ((i) << <token> <answer> 1)) 
static <token> rtw_dump_logical_efuse_map(struct rtw_dev *rtwdev, u8 *phy_map, <answer> int 
u8 <token> <answer> *log_map) 
<token> physical_size = rtwdev->efuse.physical_size; <answer> u32 
<token> protect_size = rtwdev->efuse.protect_size; <answer> u32 
<token> logical_size = rtwdev->efuse.logical_size; <answer> u32 
u32 <token> log_idx; <answer> phy_idx, 
<token> hdr1, hdr2; <answer> u8 
<token> blk_idx; <answer> u8 
u8 <token> <answer> word_en; 
<token> i; <answer> int 
for <token> = 0; phy_idx < physical_size - protect_size;) { <answer> (phy_idx 
hdr1 = <token> <answer> phy_map[phy_idx]; 
hdr2 = phy_map[phy_idx <token> 1]; <answer> + 
if (invalid_efuse_header(hdr1, <token> <answer> hdr2)) 
if ((hdr1 & 0x1f) <token> 0xf) { <answer> == 
#include <token> <answer> <linux/bitmap.h> 
#include <token> <answer> <linux/workqueue.h> 
#include <token> <answer> "nitrox_csr.h" 
#include <token> <answer> "nitrox_hal.h" 
<token> "nitrox_dev.h" <answer> #include 
<token> "nitrox_mbx.h" <answer> #include 
#define RING_TO_VFNO(_x, _y) ((_x) <token> (_y)) <answer> / 
enum mbx_msg_type <token> <answer> { 
enum mbx_msg_opcode <token> <answer> { 
<token> = 1, <answer> MSG_OP_VF_MODE 
MSG_OP_MCODE_INFO <token> 11, <answer> = 
struct <token> { <answer> pf2vf_work 
struct nitrox_vfdev <token> <answer> *vfdev; 
struct <token> *ndev; <answer> nitrox_device 
<token> work_struct pf2vf_resp; <answer> struct 
static inline <token> pf2vf_read_mbox(struct nitrox_device *ndev, int ring) <answer> u64 
<token> reg_addr; <answer> u64 
<token> = NPS_PKT_MBOX_VF_PF_PFDATAX(ring); <answer> reg_addr 
return <token> reg_addr); <answer> nitrox_read_csr(ndev, 
static <token> void pf2vf_write_mbox(struct nitrox_device *ndev, u64 value, <answer> inline 
int <token> <answer> ring) 
<token> reg_addr; <answer> u64 
reg_addr <token> NPS_PKT_MBOX_PF_VF_PFDATAX(ring); <answer> = 
<token> reg_addr, value); <answer> nitrox_write_csr(ndev, 
static <token> pf2vf_send_response(struct nitrox_device *ndev, <answer> void 
<token> nitrox_vfdev *vfdev) <answer> struct 
union mbox_msg <token> <answer> msg; 
msg.value = <token> <answer> vfdev->msg.value; 
switch (vfdev->msg.opcode) <token> <answer> { 
case <token> <answer> MSG_OP_VF_MODE: 
<token> = ndev->mode; <answer> msg.data 
case <token> <answer> MSG_OP_VF_UP: 
<token> = vfdev->msg.data; <answer> vfdev->nr_queues 
atomic_set(&vfdev->state, <token> <answer> __NDEV_READY); 
<token> MSG_OP_CHIPID_VFID: <answer> case 
msg.id.chipid = <token> <answer> ndev->idx; 
msg.id.vfid <token> vfdev->vfno; <answer> = 
<token> MSG_OP_VF_DOWN: <answer> case 
vfdev->nr_queues = <token> <answer> 0; 
atomic_set(&vfdev->state, <token> <answer> __NDEV_NOT_READY); 
case <token> <answer> MSG_OP_MCODE_INFO: 
<token> = 0; <answer> msg.data 
msg.mcode_info.count <token> 2; <answer> = 
msg.mcode_info.info <token> MCODE_TYPE_SE_SSL | (MCODE_TYPE_AE << 5); <answer> = 
msg.mcode_info.next_se_grp = <token> <answer> 1; 
msg.mcode_info.next_ae_grp = <token> <answer> 1; 
msg.type <token> MBX_MSG_TYPE_NOP; <answer> = 
<token> (msg.type == MBX_MSG_TYPE_NOP) <answer> if 
<token> <linux/vmalloc.h> <answer> #include 
#include <token> <answer> "core.h" 
#include <token> <answer> "debug.h" 
void ath12k_info(struct ath12k_base *ab, const char *fmt, <token> <answer> ...) 
struct va_format vaf = <token> <answer> { 
.fmt <token> fmt, <answer> = 
<token> args; <answer> va_list 
va_start(args, <token> <answer> fmt); 
<token> = &args; <answer> vaf.va 
dev_info(ab->dev, <token> &vaf); <answer> "%pV", 
<token> "core.h" <answer> #include 
#include <token> <answer> <nvif/class.h> 
<token> nv50_core **pcore) <answer> nv50_core_del(struct 
struct nv50_core *core = <token> <answer> *pcore; 
if (core) <token> <answer> { 
*pcore <token> NULL; <answer> = 
nv50_core_new(struct nouveau_drm <token> struct nv50_core **pcore) <answer> *drm, 
<token> { <answer> struct 
s32 <token> <answer> oclass; 
<token> version; <answer> int 
int (*new)(struct <token> *, s32, struct nv50_core **); <answer> nouveau_drm 
} cores[] <token> { <answer> = 
{ AD102_DISP_CORE_CHANNEL_DMA, <token> corec57d_new }, <answer> 0, 
{ <token> 0, corec57d_new }, <answer> GA102_DISP_CORE_CHANNEL_DMA, 
{ TU102_DISP_CORE_CHANNEL_DMA, 0, corec57d_new <token> <answer> }, 
{ GV100_DISP_CORE_CHANNEL_DMA, 0, corec37d_new <token> <answer> }, 
{ GP102_DISP_CORE_CHANNEL_DMA, <token> core917d_new }, <answer> 0, 
<token> GP100_DISP_CORE_CHANNEL_DMA, 0, core917d_new }, <answer> { 
{ GM200_DISP_CORE_CHANNEL_DMA, 0, <token> }, <answer> core917d_new 
{ GM107_DISP_CORE_CHANNEL_DMA, 0, core917d_new <token> <answer> }, 
{ GK110_DISP_CORE_CHANNEL_DMA, <token> core917d_new }, <answer> 0, 
{ GK104_DISP_CORE_CHANNEL_DMA, 0, <token> }, <answer> core917d_new 
{ GF110_DISP_CORE_CHANNEL_DMA, 0, <token> }, <answer> core907d_new 
{ GT214_DISP_CORE_CHANNEL_DMA, 0, core827d_new <token> <answer> }, 
{ GT206_DISP_CORE_CHANNEL_DMA, 0, core827d_new <token> <answer> }, 
{ GT200_DISP_CORE_CHANNEL_DMA, 0, core827d_new <token> <answer> }, 
{ G82_DISP_CORE_CHANNEL_DMA, 0, core827d_new <token> <answer> }, 
{ NV50_DISP_CORE_CHANNEL_DMA, 0, core507d_new <token> <answer> }, 
<token> nv50_disp *disp = nv50_disp(drm->dev); <answer> struct 
<token> cid; <answer> int 
cid = nvif_mclass(&disp->disp->object, <token> <answer> cores); 
if <token> < 0) { <answer> (cid 
NV_ERROR(drm, "No <token> core channel class\n"); <answer> supported 
return <token> <answer> cid; 
<token> cores[cid].new(drm, cores[cid].oclass, pcore); <answer> return 
#include <token> <answer> <string.h> 
<token> <linux/bpf.h> <answer> #include 
#include <token> <answer> <linux/pkt_cls.h> 
<token> <linux/if_ether.h> <answer> #include 
#include <token> <answer> <linux/in.h> 
<token> <linux/ip.h> <answer> #include 
#include <token> <answer> <linux/ipv6.h> 
<token> <sys/socket.h> <answer> #include 
#include <token> <answer> <linux/tcp.h> 
<token> <bpf/bpf_helpers.h> <answer> #include 
<token> <bpf/bpf_endian.h> <answer> #include 
struct <token> <answer> { 
<token> BPF_MAP_TYPE_ARRAY); <answer> __uint(type, 
<token> __u32); <answer> __type(key, 
<token> __u32); <answer> __type(value, 
__uint(max_entries, <token> <answer> 3); 
} results <token> <answer> SEC(".maps"); 
static __always_inline __s64 gen_syncookie(void *data_end, struct bpf_sock <token> <answer> *sk, 
void *iph, __u32 <token> <answer> ip_size, 
struct <token> *tcph) <answer> tcphdr 
<token> thlen = tcph->doff * 4; <answer> __u32 
if (tcph->syn && !tcph->ack) <token> <answer> { 
if (thlen <token> 24) <answer> != 
<token> 0; <answer> return 
if ((void <token> + thlen > data_end) <answer> *)tcph 
<token> 0; <answer> return 
return bpf_tcp_gen_syncookie(sk, iph, ip_size, <token> thlen); <answer> tcph, 
<token> 0; <answer> return 
static __always_inline void check_syncookie(void <token> void *data, <answer> *ctx, 
void <token> <answer> *data_end) 
struct bpf_sock_tuple <token> <answer> tup; 
struct <token> *sk; <answer> bpf_sock 
<token> ethhdr *ethh; <answer> struct 
<token> iphdr *ipv4h; <answer> struct 
struct ipv6hdr <token> <answer> *ipv6h; 
<token> tcphdr *tcph; <answer> struct 
<token> ret; <answer> int 
<token> key_mss = 2; <answer> __u32 
__u32 key_gen <token> 1; <answer> = 
__u32 <token> = 0; <answer> key 
__s64 <token> <answer> seq_mss; 
ethh <token> data; <answer> = 
if (ethh + 1 > <token> <answer> data_end) 
switch (bpf_ntohs(ethh->h_proto)) <token> <answer> { 
case <token> <answer> ETH_P_IP: 
<token> = data + sizeof(struct ethhdr); <answer> ipv4h 
if (ipv4h + 1 <token> data_end) <answer> > 
if (ipv4h->ihl != <token> <answer> 5) 
tcph = data + sizeof(struct <token> + sizeof(struct iphdr); <answer> ethhdr) 
if (tcph + 1 <token> data_end) <answer> > 
<token> = ipv4h->saddr; <answer> tup.ipv4.saddr 
tup.ipv4.daddr <token> ipv4h->daddr; <answer> = 
tup.ipv4.sport = <token> <answer> tcph->source; 
tup.ipv4.dport <token> tcph->dest; <answer> = 
sk = bpf_skc_lookup_tcp(ctx, &tup, <token> <answer> sizeof(tup.ipv4), 
<token> 0); <answer> BPF_F_CURRENT_NETNS, 
<token> (!sk) <answer> if 
if <token> != BPF_TCP_LISTEN) <answer> (sk->state 
<token> release; <answer> goto 
seq_mss = gen_syncookie(data_end, sk, <token> sizeof(*ipv4h), <answer> ipv4h, 
<token> = bpf_tcp_check_syncookie(sk, ipv4h, sizeof(*ipv4h), <answer> ret 
tcph, <token> <answer> sizeof(*tcph)); 
<token> ETH_P_IPV6: <answer> case 
<token> = data + sizeof(struct ethhdr); <answer> ipv6h 
if (ipv6h + 1 > <token> <answer> data_end) 
if <token> != IPPROTO_TCP) <answer> (ipv6h->nexthdr 
<token> = data + sizeof(struct ethhdr) + sizeof(struct ipv6hdr); <answer> tcph 
if (tcph <token> 1 > data_end) <answer> + 
<token> &ipv6h->saddr, sizeof(tup.ipv6.saddr)); <answer> memcpy(tup.ipv6.saddr, 
<token> &ipv6h->daddr, sizeof(tup.ipv6.daddr)); <answer> memcpy(tup.ipv6.daddr, 
tup.ipv6.sport <token> tcph->source; <answer> = 
tup.ipv6.dport <token> tcph->dest; <answer> = 
sk = <token> &tup, sizeof(tup.ipv6), <answer> bpf_skc_lookup_tcp(ctx, 
<token> 0); <answer> BPF_F_CURRENT_NETNS, 
if <token> <answer> (!sk) 
if (sk->state <token> BPF_TCP_LISTEN) <answer> != 
<token> release; <answer> goto 
seq_mss = <token> sk, ipv6h, sizeof(*ipv6h), <answer> gen_syncookie(data_end, 
<token> = bpf_tcp_check_syncookie(sk, ipv6h, sizeof(*ipv6h), <answer> ret 
<token> sizeof(*tcph)); <answer> tcph, 
if <token> > 0) { <answer> (seq_mss 
__u32 <token> = (__u32)seq_mss; <answer> cookie 
<token> mss = seq_mss >> 32; <answer> __u32 
bpf_map_update_elem(&results, <token> &cookie, 0); <answer> &key_gen, 
bpf_map_update_elem(&results, <token> &mss, 0); <answer> &key_mss, 
if <token> == 0) { <answer> (ret 
__u32 <token> = bpf_ntohl(tcph->ack_seq) - 1; <answer> cookie 
bpf_map_update_elem(&results, &key, <token> 0); <answer> &cookie, 
int <token> __sk_buff *skb) <answer> check_syncookie_clsact(struct 
<token> (void *)(long)skb->data, <answer> check_syncookie(skb, 
<token> *)(long)skb->data_end); <answer> (void 
<token> TC_ACT_OK; <answer> return 
int <token> xdp_md *ctx) <answer> check_syncookie_xdp(struct 
check_syncookie(ctx, <token> *)(long)ctx->data, <answer> (void 
<token> *)(long)ctx->data_end); <answer> (void 
<token> XDP_PASS; <answer> return 
char _license[] SEC("license") = <token> <answer> "GPL"; 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/of_platform.h> 
<token> <linux/cpu.h> <answer> #include 
<token> <linux/mbus.h> <answer> #include 
<token> <linux/clocksource.h> <answer> #include 
#include <token> <answer> <asm/system_misc.h> 
<token> <asm/mach/arch.h> <answer> #include 
#include <token> <answer> <asm/mach/map.h> 
#include <token> <answer> <plat/irq.h> 
<token> <plat/time.h> <answer> #include 
<token> "orion5x.h" <answer> #include 
#include <token> <answer> "bridge-regs.h" 
<token> "common.h" <answer> #include 
static struct of_dev_auxdata orion5x_auxdata_lookup[] __initdata = <token> <answer> { 
OF_DEV_AUXDATA("marvell,orion-spi", 0xf1010600, "orion_spi.0", <token> <answer> NULL), 
<token> 0xf1011000, "mv64xxx_i2c.0", <answer> OF_DEV_AUXDATA("marvell,mv64xxx-i2c", 
<token> 0xf1020300, "orion_wdt", NULL), <answer> OF_DEV_AUXDATA("marvell,orion-wdt", 
OF_DEV_AUXDATA("marvell,orion-sata", <token> "sata_mv.0", NULL), <answer> 0xf1080000, 
<token> 0xf1090000, "mv_crypto", NULL), <answer> OF_DEV_AUXDATA("marvell,orion-crypto", 
<token> void __init orion5x_dt_init(void) <answer> static 
char <token> <answer> *dev_name; 
<token> dev, rev; <answer> u32 
<token> &rev, &dev_name); <answer> orion5x_id(&dev, 
<token> "Orion ID: %s. TCLK=%d.\n", dev_name, orion5x_tclk); <answer> printk(KERN_INFO 
if (dev == MV88F5281_DEV_ID && rev <token> MV88F5281_REV_D0) { <answer> == 
printk(KERN_INFO <token> Applying 5281 D0 WFI workaround.\n"); <answer> "Orion: 
if <token> <answer> (of_machine_is_compatible("maxtor,shared-storage-2")) 
if <token> <answer> (of_machine_is_compatible("lacie,d2-network")) 
of_platform_default_populate(NULL, orion5x_auxdata_lookup, <token> <answer> NULL); 
static const char *orion5x_dt_compat[] = <token> <answer> { 
<token> "Marvell Orion5x (Flattened Device Tree)") <answer> DT_MACHINE_START(ORION5X_DT, 
<token> <linux/types.h> <answer> #include 
#include <token> <answer> <linux/string.h> 
void *memset(void *s, int c, <token> count) <answer> size_t 
int destptr, <token> dwordcnt, fill8reg, wrkrega; <answer> charcnt, 
<token> (!count) <answer> if 
return <token> <answer> s; 
c <token> 0xFF; <answer> &= 
if (count <= 8) <token> <answer> { 
char *xs = (char *) <token> <answer> s; 
while <token> <answer> (count--) 
<token> = c; <answer> *xs++ 
<token> s; <answer> return 
<token> __volatile__ ( <answer> __asm__ 
<token> <linux/delay.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/pci.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <sound/core.h> 
<token> <sound/sb.h> <answer> #include 
#include <token> <answer> <sound/initval.h> 
<token> Willis"); <answer> MODULE_AUTHOR("Ash 
<token> Audio"); <answer> MODULE_DESCRIPTION("CS5530 
<token> int index[SNDRV_CARDS] = SNDRV_DEFAULT_IDX; <answer> static 
static <token> *id[SNDRV_CARDS] = SNDRV_DEFAULT_STR; <answer> char 
<token> bool enable[SNDRV_CARDS] = SNDRV_DEFAULT_ENABLE_PNP; <answer> static 
module_param_array(index, int, <token> 0444); <answer> NULL, 
MODULE_PARM_DESC(index, "Index value <token> CS5530 Audio driver."); <answer> for 
module_param_array(id, charp, NULL, <token> <answer> 0444); 
MODULE_PARM_DESC(id, "ID string <token> CS5530 Audio driver."); <answer> for 
module_param_array(enable, bool, NULL, <token> <answer> 0444); 
MODULE_PARM_DESC(enable, "Enable <token> Audio driver."); <answer> CS5530 
<token> snd_cs5530 { <answer> struct 
struct <token> *card; <answer> snd_card 
struct <token> *pci; <answer> pci_dev 
struct snd_sb <token> <answer> *sb; 
unsigned long <token> <answer> pci_base; 
static <token> struct pci_device_id snd_cs5530_ids[] = { <answer> const 
{PCI_VENDOR_ID_CYRIX, PCI_DEVICE_ID_CYRIX_5530_AUDIO, <token> <answer> PCI_ANY_ID, 
PCI_ANY_ID, <token> 0}, <answer> 0, 
MODULE_DEVICE_TABLE(pci, <token> <answer> snd_cs5530_ids); 
static u8 snd_cs5530_mixer_read(unsigned long io, u8 <token> <answer> reg) 
outb(reg, io <token> 4); <answer> + 
reg = <token> + 5); <answer> inb(io 
<token> reg; <answer> return 
<token> int snd_cs5530_create(struct snd_card *card, <answer> static 
struct pci_dev <token> <answer> *pci) 
struct snd_cs5530 *chip <token> card->private_data; <answer> = 
unsigned <token> sb_base; <answer> long 
<token> irq, dma8, dma16 = 0; <answer> u8 
<token> map; <answer> u16 
void <token> *mem; <answer> __iomem 
<token> err; <answer> int 
<token> = pcim_enable_device(pci); <answer> err 
<token> (err < 0) <answer> if 
return <token> <answer> err; 
<token> = card; <answer> chip->card 
chip->pci = <token> <answer> pci; 
err <token> pcim_iomap_regions(pci, 1 << 0, "CS5530"); <answer> = 
if (err <token> 0) <answer> < 
return <token> <answer> err; 
<token> = pci_resource_start(pci, 0); <answer> chip->pci_base 
mem <token> pcim_iomap_table(pci)[0]; <answer> = 
<token> = readw(mem + 0x18); <answer> map 
sb_base = 0x220 + <token> * (map & 3); <answer> 0x20 
if (map <token> (1<<2)) <answer> & 
dev_info(card->dev, "XpressAudio at <token> sb_base); <answer> 0x%lx\n", 
<token> { <answer> else 
<token> "Could not find XpressAudio!\n"); <answer> dev_err(card->dev, 
<token> -ENODEV; <answer> return 
if <token> & (1<<5)) <answer> (map 
<token> "MPU at 0x300\n"); <answer> dev_info(card->dev, 
else <token> (map & (1<<6)) <answer> if 
dev_info(card->dev, <token> at 0x330\n"); <answer> "MPU 
irq = snd_cs5530_mixer_read(sb_base, 0x80) <token> 0x0F; <answer> & 
<token> = snd_cs5530_mixer_read(sb_base, 0x81); <answer> dma8 
if <token> & 0x20) <answer> (dma8 
dma16 = <token> <answer> 5; 
<token> if (dma8 & 0x40) <answer> else 
dma16 <token> 6; <answer> = 
else if (dma8 <token> 0x80) <answer> & 
dma16 <token> 7; <answer> = 
else <token> <answer> { 
dev_err(card->dev, "No 16bit <token> enabled\n"); <answer> DMA 
<token> -ENODEV; <answer> return 
if (dma8 <token> 0x01) <answer> & 
<token> = 0; <answer> dma8 
else <token> (dma8 & 02) <answer> if 
dma8 = <token> <answer> 1; 
else if (dma8 & <token> <answer> 0x08) 
<token> = 3; <answer> dma8 
else <token> <answer> { 
dev_err(card->dev, "No 8bit <token> enabled\n"); <answer> DMA 
<token> -ENODEV; <answer> return 
if (irq & <token> <answer> 1) 
<token> = 9; <answer> irq 
else if (irq & <token> <answer> 2) 
irq = <token> <answer> 5; 
else if (irq <token> 4) <answer> & 
irq <token> 7; <answer> = 
else if (irq & <token> <answer> 8) 
irq = <token> <answer> 10; 
<token> { <answer> else 
dev_err(card->dev, <token> IRQ not set\n"); <answer> "SoundBlaster 
<token> -ENODEV; <answer> return 
dev_info(card->dev, "IRQ: <token> DMA8: %d DMA16: %d\n", irq, dma8, dma16); <answer> %d 
err <token> snd_sbdsp_create(card, sb_base, irq, snd_sb16dsp_interrupt, dma8, <answer> = 
dma16, <token> &chip->sb); <answer> SB_HW_CS5530, 
if (err <token> 0) { <answer> < 
<token> "Could not create SoundBlaster\n"); <answer> dev_err(card->dev, 
return <token> <answer> err; 
err = snd_sb16dsp_pcm(chip->sb, <token> <answer> 0); 
if (err <token> 0) { <answer> < 
dev_err(card->dev, "Could <token> create PCM\n"); <answer> not 
return <token> <answer> err; 
err = <token> <answer> snd_sbmixer_new(chip->sb); 
if (err < <token> { <answer> 0) 
dev_err(card->dev, <token> not create Mixer\n"); <answer> "Could 
<token> err; <answer> return 
<token> 0; <answer> return 
<token> int snd_cs5530_probe(struct pci_dev *pci, <answer> static 
const struct pci_device_id <token> <answer> *pci_id) 
static <token> dev; <answer> int 
struct snd_card <token> <answer> *card; 
<token> snd_cs5530 *chip; <answer> struct 
int <token> <answer> err; 
if (dev <token> SNDRV_CARDS) <answer> >= 
return <token> <answer> -ENODEV; 
if <token> { <answer> (!enable[dev]) 
<token> -ENOENT; <answer> return 
err <token> snd_devm_card_new(&pci->dev, index[dev], id[dev], THIS_MODULE, <answer> = 
sizeof(*chip), <token> <answer> &card); 
<token> (err < 0) <answer> if 
<token> err; <answer> return 
chip = <token> <answer> card->private_data; 
err = snd_cs5530_create(card, <token> <answer> pci); 
if (err <token> 0) <answer> < 
<token> err; <answer> return 
strcpy(card->driver, <token> <answer> "CS5530"); 
strcpy(card->shortname, "CS5530 <token> <answer> Audio"); 
sprintf(card->longname, <token> at 0x%lx", card->shortname, chip->pci_base); <answer> "%s 
<token> = snd_card_register(card); <answer> err 
<token> (err < 0) <answer> if 
<token> err; <answer> return 
<token> card); <answer> pci_set_drvdata(pci, 
<token> 0; <answer> return 
<token> struct pci_driver cs5530_driver = { <answer> static 
.name <token> KBUILD_MODNAME, <answer> = 
<token> = snd_cs5530_ids, <answer> .id_table 
.probe <token> snd_cs5530_probe, <answer> = 
<token> <linux/pagemap.h> <answer> #include 
#include <token> <answer> "hfsplus_fs.h" 
<token> "hfsplus_raw.h" <answer> #include 
#define PAGE_CACHE_BITS (PAGE_SIZE <token> 8) <answer> * 
int <token> super_block *sb, u32 size, <answer> hfsplus_block_allocate(struct 
u32 offset, <token> *max) <answer> u32 
struct hfsplus_sb_info *sbi <token> HFSPLUS_SB(sb); <answer> = 
struct page <token> <answer> *page; 
struct address_space <token> <answer> *mapping; 
__be32 <token> *curr, *end; <answer> *pptr, 
u32 <token> start, len, n; <answer> mask, 
__be32 <token> <answer> val; 
<token> i; <answer> int 
<token> = *max; <answer> len 
if <token> <answer> (!len) 
return <token> <answer> size; 
<token> "block_allocate: %u,%u,%u\n", size, offset, len); <answer> hfs_dbg(BITMAP, 
<token> = sbi->alloc_file->i_mapping; <answer> mapping 
<token> = read_mapping_page(mapping, offset / PAGE_CACHE_BITS, NULL); <answer> page 
<token> (IS_ERR(page)) { <answer> if 
start = <token> <answer> size; 
goto <token> <answer> out; 
pptr = <token> <answer> kmap_local_page(page); 
curr = pptr + (offset <token> (PAGE_CACHE_BITS - 1)) / 32; <answer> & 
<token> = offset % 32; <answer> i 
offset <token> ~(PAGE_CACHE_BITS - 1); <answer> &= 
<token> ((size ^ offset) / PAGE_CACHE_BITS) <answer> if 
end = pptr + <token> / 32; <answer> PAGE_CACHE_BITS 
end = pptr + ((size + 31) & (PAGE_CACHE_BITS - 1)) / <token> <answer> 32; 
<token> <linux/device.h> <answer> #include 
#include <token> <answer> <linux/sizes.h> 
<token> <linux/badblocks.h> <answer> #include 
<token> "nd-core.h" <answer> #include 
<token> "pmem.h" <answer> #include 
<token> "pfn.h" <answer> #include 
#include <token> <answer> "btt.h" 
<token> "nd.h" <answer> #include 
void __nd_detach_ndns(struct <token> *dev, struct nd_namespace_common **_ndns) <answer> device 
struct nd_namespace_common *ndns <token> *_ndns; <answer> = 
struct <token> *nvdimm_bus; <answer> nvdimm_bus 
<token> (!ndns) <answer> if 
nvdimm_bus <token> walk_to_nvdimm_bus(&ndns->dev); <answer> = 
dev_WARN_ONCE(dev, <token> != dev, "%s: invalid claim\n", __func__); <answer> ndns->claim 
ndns->claim <token> NULL; <answer> = 
*_ndns <token> NULL; <answer> = 
void <token> device *dev, <answer> nd_detach_ndns(struct 
struct nd_namespace_common <token> <answer> **_ndns) 
struct nd_namespace_common *ndns <token> *_ndns; <answer> = 
<token> (!ndns) <answer> if 
<token> _ndns); <answer> __nd_detach_ndns(dev, 
bool __nd_attach_ndns(struct device *dev, struct nd_namespace_common <token> <answer> *attach, 
struct nd_namespace_common <token> <answer> **_ndns) 
struct <token> *nvdimm_bus = walk_to_nvdimm_bus(&attach->dev); <answer> nvdimm_bus 
if <token> <answer> (attach->claim) 
return <token> <answer> false; 
dev_WARN_ONCE(dev, *_ndns, <token> invalid claim\n", __func__); <answer> "%s: 
<token> = dev; <answer> attach->claim 
<token> = attach; <answer> *_ndns 
<token> true; <answer> return 
bool nd_attach_ndns(struct device *dev, struct <token> *attach, <answer> nd_namespace_common 
struct <token> **_ndns) <answer> nd_namespace_common 
bool <token> <answer> claimed; 
claimed = __nd_attach_ndns(dev, attach, <token> <answer> _ndns); 
return <token> <answer> claimed; 
static int namespace_match(struct <token> *dev, void *data) <answer> device 
<token> *name = data; <answer> char 
return strcmp(name, <token> == 0; <answer> dev_name(dev)) 
static bool <token> device *dev, struct nd_namespace_common *ndns) <answer> is_idle(struct 
struct nd_region <token> = to_nd_region(dev->parent); <answer> *nd_region 
struct device <token> = NULL; <answer> *seed 
<token> (is_nd_btt(dev)) <answer> if 
seed <token> nd_region->btt_seed; <answer> = 
else <token> (is_nd_pfn(dev)) <answer> if 
seed = <token> <answer> nd_region->pfn_seed; 
else if <token> <answer> (is_nd_dax(dev)) 
<token> = nd_region->dax_seed; <answer> seed 
if (seed == <token> || ndns || dev->driver) <answer> dev 
<token> false; <answer> return 
return <token> <answer> true; 
struct nd_pfn *to_nd_pfn_safe(struct <token> *dev) <answer> device 
if <token> <answer> (is_nd_pfn(dev)) 
<token> to_nd_pfn(dev); <answer> return 
if (is_nd_dax(dev)) <token> <answer> { 
<token> nd_dax *nd_dax = to_nd_dax(dev); <answer> struct 
<token> &nd_dax->nd_pfn; <answer> return 
return <token> <answer> NULL; 
static void <token> device *dev, <answer> nd_detach_and_reset(struct 
struct <token> **_ndns) <answer> nd_namespace_common 
u64 <token> nd_gen_sb *nd_gen_sb) <answer> nd_sb_checksum(struct 
<token> sum; <answer> u64 
__le64 <token> <answer> sum_save; 
BUILD_BUG_ON(sizeof(struct btt_sb) <token> SZ_4K); <answer> != 
<token> nd_pfn_sb) != SZ_4K); <answer> BUILD_BUG_ON(sizeof(struct 
BUILD_BUG_ON(sizeof(struct nd_gen_sb) != <token> <answer> SZ_4K); 
sum_save = <token> <answer> nd_gen_sb->checksum; 
nd_gen_sb->checksum <token> 0; <answer> = 
sum = nd_fletcher64(nd_gen_sb, sizeof(*nd_gen_sb), <token> <answer> 1); 
nd_gen_sb->checksum <token> sum_save; <answer> = 
<token> sum; <answer> return 
<token> int nsio_rw_bytes(struct nd_namespace_common *ndns, <answer> static 
resource_size_t offset, void *buf, size_t size, int <token> <answer> rw, 
unsigned long <token> <answer> flags) 
struct nd_namespace_io *nsio <token> to_nd_namespace_io(&ndns->dev); <answer> = 
unsigned int sz_align = ALIGN(size + <token> & (512 - 1)), 512); <answer> (offset 
sector_t sector <token> offset >> 9; <answer> = 
int rc <token> 0, ret = 0; <answer> = 
<token> (unlikely(!size)) <answer> if 
<token> 0; <answer> return 
if (unlikely(offset + size > <token> { <answer> nsio->size)) 
dev_WARN_ONCE(&ndns->dev, 1, "request <token> of range\n"); <answer> out 
<token> -EFAULT; <answer> return 
if (rw == READ) <token> <answer> { 
<token> (unlikely(is_bad_pmem(&nsio->bb, sector, sz_align))) <answer> if 
return <token> <answer> -EIO; 
if (copy_mc_to_kernel(buf, nsio->addr + offset, <token> != 0) <answer> size) 
<token> -EIO; <answer> return 
return <token> <answer> 0; 
if (unlikely(is_bad_pmem(&nsio->bb, sector, <token> { <answer> sz_align))) 
<token> (IS_ALIGNED(offset, 512) && IS_ALIGNED(size, 512) <answer> if 
&& !(flags <token> NVDIMM_IO_ATOMIC)) { <answer> & 
<token> cleared; <answer> long 
cleared <token> nvdimm_clear_poison(&ndns->dev, <answer> = 
nsio->res.start <token> offset, size); <answer> + 
if (cleared <token> size) <answer> < 
<token> = -EIO; <answer> rc 
if (cleared > 0 && cleared <token> 512) { <answer> / 
cleared <token> 512; <answer> /= 
<token> sector, cleared); <answer> badblocks_clear(&nsio->bb, 
arch_invalidate_pmem(nsio->addr <token> offset, size); <answer> + 
<token> else <answer> } 
rc <token> -EIO; <answer> = 
memcpy_flushcache(nsio->addr + <token> buf, size); <answer> offset, 
ret = <token> NULL); <answer> nvdimm_flush(to_nd_region(ndns->dev.parent), 
<token> (ret) <answer> if 
rc <token> ret; <answer> = 
return <token> <answer> rc; 
int devm_nsio_enable(struct device *dev, <token> nd_namespace_io *nsio, <answer> struct 
resource_size_t <token> <answer> size) 
struct nd_namespace_common *ndns <token> &nsio->common; <answer> = 
<token> range range = { <answer> struct 
.start = <token> <answer> nsio->res.start, 
.end <token> nsio->res.end, <answer> = 
nsio->size = <token> <answer> size; 
if <token> range.start, size, <answer> (!devm_request_mem_region(dev, 
dev_name(&ndns->dev))) <token> <answer> { 
dev_warn(dev, "could not reserve region <token> &nsio->res); <answer> %pR\n", 
return <token> <answer> -EBUSY; 
ndns->rw_bytes = <token> <answer> nsio_rw_bytes; 
<token> (devm_init_badblocks(dev, &nsio->bb)) <answer> if 
return <token> <answer> -ENOMEM; 
<token> &nsio->bb, <answer> nvdimm_badblocks_populate(to_nd_region(ndns->dev.parent), 
nsio->addr <token> devm_memremap(dev, range.start, size, ARCH_MEMREMAP_PMEM); <answer> = 
<token> PTR_ERR_OR_ZERO(nsio->addr); <answer> return 
void devm_nsio_disable(struct device *dev, struct nd_namespace_io <token> <answer> *nsio) 
<token> resource *res = &nsio->res; <answer> struct 
<token> nsio->addr); <answer> devm_memunmap(dev, 
<token> &nsio->bb); <answer> devm_exit_badblocks(dev, 
devm_release_mem_region(dev, <token> nsio->size); <answer> res->start, 
#include <token> <answer> <linux/ioport.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/gpio/driver.h> 
<token> <linux/pci.h> <answer> #include 
<token> <linux/spinlock.h> <answer> #include 
<token> PMBASE_OFFSET 0xb0 <answer> #define 
#define PMBASE_SIZE <token> <answer> 0x30 
<token> AMD_REG_GPIO(i) (0x10 + (i)) <answer> #define 
static const struct pci_device_id pci_tbl[] = <token> <answer> { 
{ PCI_DEVICE(PCI_VENDOR_ID_AMD, <token> 0 }, <answer> PCI_DEVICE_ID_AMD_8111_SMBUS), 
for_each_pci_dev(pdev) <token> <answer> { 
<token> = pci_match_id(pci_tbl, pdev); <answer> ent 
if <token> <answer> (ent) 
<token> found; <answer> goto 
#include <token> <answer> <linux/module.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/pinctrl/pinctrl.h> 
<token> "pinctrl-sunxi.h" <answer> #include 
static const struct sunxi_desc_pin sun50i_h5_pins[] = <token> <answer> { 
<token> 0), <answer> SUNXI_PIN(SUNXI_PINCTRL_PIN(A, 
SUNXI_FUNCTION(0x0, <token> <answer> "gpio_in"), 
<token> "gpio_out"), <answer> SUNXI_FUNCTION(0x1, 
#define pr_fmt(fmt) "irq: " <token> <answer> fmt 
#include <token> <answer> <linux/acpi.h> 
#include <token> <answer> <linux/debugfs.h> 
<token> <linux/hardirq.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/irqdesc.h> 
<token> <linux/irqdomain.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/mutex.h> 
<token> <linux/of.h> <answer> #include 
<token> <linux/of_address.h> <answer> #include 
#include <token> <answer> <linux/of_irq.h> 
#include <token> <answer> <linux/topology.h> 
#include <token> <answer> <linux/seq_file.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/smp.h> <answer> #include 
<token> <linux/fs.h> <answer> #include 
<token> LIST_HEAD(irq_domain_list); <answer> static 
<token> DEFINE_MUTEX(irq_domain_mutex); <answer> static 
static struct <token> *irq_default_domain; <answer> irq_domain 
static int irq_domain_alloc_irqs_locked(struct <token> *domain, int irq_base, <answer> irq_domain 
unsigned int nr_irqs, int <token> void *arg, <answer> node, 
bool realloc, const struct irq_affinity_desc <token> <answer> *affinity); 
static void <token> irq_domain *domain); <answer> irq_domain_check_hierarchy(struct 
static void <token> irq_domain *domain, unsigned int virq); <answer> irq_domain_free_one_irq(struct 
<token> irqchip_fwid { <answer> struct 
struct <token> fwnode; <answer> fwnode_handle 
unsigned int <token> <answer> type; 
char <token> <answer> *name; 
<token> *pa; <answer> phys_addr_t 
<token> CONFIG_GENERIC_IRQ_DEBUGFS <answer> #ifdef 
static void debugfs_add_domain_dir(struct <token> *d); <answer> irq_domain 
static <token> debugfs_remove_domain_dir(struct irq_domain *d); <answer> void 
static inline void debugfs_add_domain_dir(struct irq_domain <token> { } <answer> *d) 
static <token> void debugfs_remove_domain_dir(struct irq_domain *d) { } <answer> inline 
static <token> char *irqchip_fwnode_get_name(const struct fwnode_handle *fwnode) <answer> const 
struct irqchip_fwid <token> = container_of(fwnode, struct irqchip_fwid, fwnode); <answer> *fwid 
<token> fwid->name; <answer> return 
const struct fwnode_operations irqchip_fwnode_ops <token> { <answer> = 
<token> = irqchip_fwnode_get_name, <answer> .get_name 
<token> fwnode_handle *__irq_domain_alloc_fwnode(unsigned int type, int id, <answer> struct 
const <token> *name, <answer> char 
phys_addr_t <token> <answer> *pa) 
struct <token> *fwid; <answer> irqchip_fwid 
<token> *n; <answer> char 
<token> = kzalloc(sizeof(*fwid), GFP_KERNEL); <answer> fwid 
<token> (type) { <answer> switch 
case <token> <answer> IRQCHIP_FWNODE_NAMED: 
n = <token> "%s", name); <answer> kasprintf(GFP_KERNEL, 
case <token> <answer> IRQCHIP_FWNODE_NAMED_ID: 
<token> = kasprintf(GFP_KERNEL, "%s-%d", name, id); <answer> n 
n = kasprintf(GFP_KERNEL, "irqchip@%pa", <token> <answer> pa); 
if (!fwid || <token> { <answer> !n) 
<token> NULL; <answer> return 
fwid->type <token> type; <answer> = 
fwid->name = <token> <answer> n; 
<token> = pa; <answer> fwid->pa 
fwnode_init(&fwid->fwnode, <token> <answer> &irqchip_fwnode_ops); 
return <token> <answer> &fwid->fwnode; 
void <token> fwnode_handle *fwnode) <answer> irq_domain_free_fwnode(struct 
<token> irqchip_fwid *fwid; <answer> struct 
if (!fwnode || <token> <answer> WARN_ON(!is_fwnode_irqchip(fwnode))) 
fwid = container_of(fwnode, struct <token> fwnode); <answer> irqchip_fwid, 
<token> struct irq_domain *__irq_domain_create(struct fwnode_handle *fwnode, <answer> static 
unsigned int <token> <answer> size, 
<token> hwirq_max, <answer> irq_hw_number_t 
<token> direct_max, <answer> int 
const struct irq_domain_ops <token> <answer> *ops, 
void <token> <answer> *host_data) 
struct <token> *fwid; <answer> irqchip_fwid 
<token> irq_domain *domain; <answer> struct 
static <token> unknown_domains; <answer> atomic_t 
if <token> && direct_max) || <answer> (WARN_ON((size 
(!IS_ENABLED(CONFIG_IRQ_DOMAIN_NOMAP) <token> direct_max) || <answer> && 
(direct_max <token> (direct_max != hwirq_max)))) <answer> && 
<token> NULL; <answer> return 
domain <token> kzalloc_node(struct_size(domain, revmap, size), <answer> = 
<token> of_node_to_nid(to_of_node(fwnode))); <answer> GFP_KERNEL, 
if <token> <answer> (!domain) 
<token> NULL; <answer> return 
<token> (is_fwnode_irqchip(fwnode)) { <answer> if 
fwid <token> container_of(fwnode, struct irqchip_fwid, fwnode); <answer> = 
switch (fwid->type) <token> <answer> { 
case <token> <answer> IRQCHIP_FWNODE_NAMED: 
<token> IRQCHIP_FWNODE_NAMED_ID: <answer> case 
<token> = fwnode; <answer> domain->fwnode 
<token> = kstrdup(fwid->name, GFP_KERNEL); <answer> domain->name 
if (!domain->name) <token> <answer> { 
<token> NULL; <answer> return 
domain->flags |= <token> <answer> IRQ_DOMAIN_NAME_ALLOCATED; 
<token> = fwnode; <answer> domain->fwnode 
domain->name = <token> <answer> fwid->name; 
} else if (is_of_node(fwnode) || <token> || <answer> is_acpi_device_node(fwnode) 
is_software_node(fwnode)) <token> <answer> { 
<token> *name; <answer> char 
name <token> kasprintf(GFP_KERNEL, "%pfw", fwnode); <answer> = 
<token> (!name) { <answer> if 
return <token> <answer> NULL; 
domain->name = strreplace(name, '/', <token> <answer> ':'); 
domain->fwnode = <token> <answer> fwnode; 
domain->flags |= <token> <answer> IRQ_DOMAIN_NAME_ALLOCATED; 
if (!domain->name) <token> <answer> { 
if <token> <answer> (fwnode) 
<token> fwnode type for irqdomain\n"); <answer> pr_err("Invalid 
domain->name <token> kasprintf(GFP_KERNEL, "unknown-%d", <answer> = 
if <token> { <answer> (!domain->name) 
<token> NULL; <answer> return 
domain->flags |= <token> <answer> IRQ_DOMAIN_NAME_ALLOCATED; 
fwnode_dev_initialized(fwnode, <token> <answer> true); 
domain->root = <token> <answer> domain; 
<token> domain; <answer> return 
static void <token> irq_domain *domain) <answer> __irq_domain_publish(struct 
list_add(&domain->link, <token> <answer> &irq_domain_list); 
pr_debug("Added domain <token> domain->name); <answer> %s\n", 
struct irq_domain *__irq_domain_add(struct fwnode_handle *fwnode, <token> int size, <answer> unsigned 
irq_hw_number_t <token> int direct_max, <answer> hwirq_max, 
const struct <token> *ops, <answer> irq_domain_ops 
<token> *host_data) <answer> void 
struct irq_domain <token> <answer> *domain; 
<token> = __irq_domain_create(fwnode, size, hwirq_max, direct_max, <answer> domain 
<token> host_data); <answer> ops, 
<token> (domain) <answer> if 
return <token> <answer> domain; 
void irq_domain_remove(struct <token> *domain) <answer> irq_domain 
<token> (unlikely(irq_default_domain == domain)) <answer> if 
pr_debug("Removed <token> %s\n", domain->name); <answer> domain 
fwnode_dev_initialized(domain->fwnode, <token> <answer> false); 
if (domain->flags & <token> <answer> IRQ_DOMAIN_NAME_ALLOCATED) 
void irq_domain_update_bus_token(struct irq_domain <token> <answer> *domain, 
<token> irq_domain_bus_token bus_token) <answer> enum 
char <token> <answer> *name; 
if (domain->bus_token == <token> <answer> bus_token) 
<token> = bus_token; <answer> domain->bus_token 
name = kasprintf(GFP_KERNEL, "%s-%d", <token> bus_token); <answer> domain->name, 
if <token> { <answer> (!name) 
if (domain->flags & <token> <answer> IRQ_DOMAIN_NAME_ALLOCATED) 
domain->flags |= <token> <answer> IRQ_DOMAIN_NAME_ALLOCATED; 
<token> = name; <answer> domain->name 
struct <token> *irq_domain_create_simple(struct fwnode_handle *fwnode, <answer> irq_domain 
<token> int size, <answer> unsigned 
unsigned int <token> <answer> first_irq, 
const <token> irq_domain_ops *ops, <answer> struct 
<token> *host_data) <answer> void 
struct <token> *domain; <answer> irq_domain 
domain = __irq_domain_add(fwnode, size, size, 0, <token> host_data); <answer> ops, 
if <token> <answer> (!domain) 
<token> NULL; <answer> return 
<token> (first_irq > 0) { <answer> if 
<token> (IS_ENABLED(CONFIG_SPARSE_IRQ)) { <answer> if 
struct <token> *irq_domain_add_legacy(struct device_node *of_node, <answer> irq_domain 
unsigned <token> size, <answer> int 
unsigned <token> first_irq, <answer> int 
irq_hw_number_t <token> <answer> first_hwirq, 
<token> struct irq_domain_ops *ops, <answer> const 
void <token> <answer> *host_data) 
return <token> size, <answer> irq_domain_create_legacy(of_node_to_fwnode(of_node), 
first_irq, first_hwirq, <token> host_data); <answer> ops, 
struct irq_domain *irq_domain_create_legacy(struct <token> *fwnode, <answer> fwnode_handle 
unsigned int <token> <answer> size, 
unsigned <token> first_irq, <answer> int 
irq_hw_number_t <token> <answer> first_hwirq, 
const <token> irq_domain_ops *ops, <answer> struct 
void <token> <answer> *host_data) 
struct irq_domain <token> <answer> *domain; 
domain = __irq_domain_add(fwnode, first_hwirq + size, first_hwirq + size, 0, <token> host_data); <answer> ops, 
<token> (domain) <answer> if 
irq_domain_associate_many(domain, <token> first_hwirq, size); <answer> first_irq, 
<token> domain; <answer> return 
struct irq_domain <token> irq_fwspec *fwspec, <answer> *irq_find_matching_fwspec(struct 
enum <token> bus_token) <answer> irq_domain_bus_token 
struct irq_domain *h, *found = <token> <answer> NULL; 
struct fwnode_handle *fwnode = <token> <answer> fwspec->fwnode; 
int <token> <answer> rc; 
list_for_each_entry(h, <token> link) { <answer> &irq_domain_list, 
if <token> && bus_token != DOMAIN_BUS_ANY) <answer> (h->ops->select 
rc = h->ops->select(h, fwspec, <token> <answer> bus_token); 
else if <token> <answer> (h->ops->match) 
rc <token> h->ops->match(h, to_of_node(fwnode), bus_token); <answer> = 
rc = ((fwnode != NULL) && (h->fwnode <token> fwnode) && <answer> == 
((bus_token <token> DOMAIN_BUS_ANY) || <answer> == 
(h->bus_token <token> bus_token))); <answer> == 
if (rc) <token> <answer> { 
<token> = h; <answer> found 
<token> found; <answer> return 
<token> irq_set_default_host(struct irq_domain *domain) <answer> void 
pr_debug("Default domain <token> to @0x%p\n", domain); <answer> set 
irq_default_domain <token> domain; <answer> = 
<token> irq_domain *irq_get_default_host(void) <answer> struct 
<token> irq_default_domain; <answer> return 
static <token> irq_domain_is_nomap(struct irq_domain *domain) <answer> bool 
<token> IS_ENABLED(CONFIG_IRQ_DOMAIN_NOMAP) && <answer> return 
<token> & IRQ_DOMAIN_FLAG_NO_MAP); <answer> (domain->flags 
static <token> irq_domain_clear_mapping(struct irq_domain *domain, <answer> void 
<token> hwirq) <answer> irq_hw_number_t 
if <token> <answer> (irq_domain_is_nomap(domain)) 
<token> (hwirq < domain->revmap_size) <answer> if 
<token> NULL); <answer> rcu_assign_pointer(domain->revmap[hwirq], 
<token> hwirq); <answer> radix_tree_delete(&domain->revmap_tree, 
static void <token> irq_domain *domain, <answer> irq_domain_set_mapping(struct 
<token> hwirq, <answer> irq_hw_number_t 
struct irq_data <token> <answer> *irq_data) 
if <token> <answer> (irq_domain_is_nomap(domain)) 
<token> (hwirq < domain->revmap_size) <answer> if 
<token> irq_data); <answer> rcu_assign_pointer(domain->revmap[hwirq], 
radix_tree_insert(&domain->revmap_tree, hwirq, <token> <answer> irq_data); 
static void irq_domain_disassociate(struct irq_domain *domain, unsigned <token> irq) <answer> int 
<token> irq_data *irq_data = irq_get_irq_data(irq); <answer> struct 
<token> hwirq; <answer> irq_hw_number_t 
if (WARN(!irq_data || irq_data->domain <token> domain, <answer> != 
"virq%i doesn't exist; <token> disassociate\n", irq)) <answer> cannot 
<token> = irq_data->hwirq; <answer> hwirq 
irq_set_status_flags(irq, <token> <answer> IRQ_NOREQUEST); 
if <token> != -EPERM) { <answer> (ret 
pr_info("%s didn't like <token> to VIRQ%i mapping (rc=%d)\n", <answer> hwirq-0x%lx 
domain->name, <token> virq, ret); <answer> hwirq, 
<token> = NULL; <answer> irq_data->domain 
<token> = 0; <answer> irq_data->hwirq 
return <token> <answer> ret; 
irq_domain_set_mapping(domain, <token> irq_data); <answer> hwirq, 
irq_clear_status_flags(virq, <token> <answer> IRQ_NOREQUEST); 
return <token> <answer> 0; 
int irq_domain_associate(struct irq_domain *domain, unsigned <token> virq, <answer> int 
irq_hw_number_t <token> <answer> hwirq) 
<token> ret; <answer> int 
ret <token> irq_domain_associate_locked(domain, virq, hwirq); <answer> = 
return <token> <answer> ret; 
void irq_domain_associate_many(struct irq_domain *domain, <token> int irq_base, <answer> unsigned 
irq_hw_number_t <token> int count) <answer> hwirq_base, 
struct <token> *of_node; <answer> device_node 
<token> i; <answer> int 
of_node = <token> <answer> irq_domain_get_of_node(domain); 
<token> irqbase=%i, hwbase=%i, count=%i)\n", __func__, <answer> pr_debug("%s(%s, 
of_node_full_name(of_node), <token> (int)hwirq_base, count); <answer> irq_base, 
for (i = 0; <token> < count; i++) <answer> i 
irq_domain_associate(domain, irq_base + i, hwirq_base <token> i); <answer> + 
<token> CONFIG_IRQ_DOMAIN_NOMAP <answer> #ifdef 
unsigned <token> irq_create_direct_mapping(struct irq_domain *domain) <answer> int 
struct device_node <token> <answer> *of_node; 
unsigned <token> virq; <answer> int 
if <token> == NULL) <answer> (domain 
<token> = irq_default_domain; <answer> domain 
of_node = <token> <answer> irq_domain_get_of_node(domain); 
virq = irq_alloc_desc_from(1, <token> <answer> of_node_to_nid(of_node)); 
if <token> { <answer> (!virq) 
pr_debug("create_direct <token> allocation failed\n"); <answer> virq 
return <token> <answer> 0; 
if (virq >= <token> { <answer> domain->hwirq_max) 
pr_err("ERROR: no free irqs <token> below %lu maximum\n", <answer> available 
<token> 0; <answer> return 
pr_debug("create_direct obtained virq <token> virq); <answer> %d\n", 
if (irq_domain_associate(domain, <token> virq)) { <answer> virq, 
<token> 0; <answer> return 
<token> virq; <answer> return 
static unsigned int irq_create_mapping_affinity_locked(struct <token> *domain, <answer> irq_domain 
<token> hwirq, <answer> irq_hw_number_t 
const struct <token> *affinity) <answer> irq_affinity_desc 
struct device_node *of_node <token> irq_domain_get_of_node(domain); <answer> = 
<token> virq; <answer> int 
<token> 0x%lx)\n", domain, hwirq); <answer> pr_debug("irq_create_mapping(0x%p, 
unsigned <token> irq_create_mapping_affinity(struct irq_domain *domain, <answer> int 
<token> hwirq, <answer> irq_hw_number_t 
const struct <token> *affinity) <answer> irq_affinity_desc 
int <token> <answer> virq; 
if <token> & ~IRQ_TYPE_SENSE_MASK)) <answer> (WARN_ON(type 
<token> &= IRQ_TYPE_SENSE_MASK; <answer> type 
virq <token> irq_find_mapping(domain, hwirq); <answer> = 
if <token> { <answer> (virq) 
<token> (type == IRQ_TYPE_NONE || type == irq_get_trigger_type(virq)) <answer> if 
<token> out; <answer> goto 
<token> (irq_get_trigger_type(virq) == IRQ_TYPE_NONE) { <answer> if 
irq_data = <token> <answer> irq_get_irq_data(virq); 
<token> (!irq_data) { <answer> if 
virq <token> 0; <answer> = 
<token> out; <answer> goto 
irqd_set_trigger_type(irq_data, <token> <answer> type); 
<token> out; <answer> goto 
pr_warn("type mismatch, failed <token> map hwirq-%lu for %s!\n", <answer> to 
<token> of_node_full_name(to_of_node(fwspec->fwnode))); <answer> hwirq, 
<token> = 0; <answer> virq 
<token> out; <answer> goto 
if <token> { <answer> (irq_domain_is_hierarchy(domain)) 
if (irq_domain_is_msi_device(domain)) <token> <answer> { 
virq = msi_device_domain_alloc_wired(domain, hwirq, <token> <answer> type); 
} <token> <answer> else 
virq <token> irq_domain_alloc_irqs_locked(domain, -1, 1, NUMA_NO_NODE, <answer> = 
<token> false, NULL); <answer> fwspec, 
if <token> <= 0) { <answer> (virq 
virq = <token> <answer> 0; 
<token> out; <answer> goto 
} else <token> <answer> { 
void irq_dispose_mapping(unsigned <token> virq) <answer> int 
struct <token> *irq_data = irq_get_irq_data(virq); <answer> irq_data 
<token> irq_domain *domain; <answer> struct 
if (!virq <token> !irq_data) <answer> || 
domain <token> irq_data->domain; <answer> = 
if <token> == NULL)) <answer> (WARN_ON(domain 
if <token> { <answer> (irq_domain_is_hierarchy(domain)) 
<token> virq); <answer> irq_domain_free_one_irq(domain, 
<token> else { <answer> } 
irq_domain_disassociate(domain, <token> <answer> virq); 
<token> irq_desc *__irq_resolve_mapping(struct irq_domain *domain, <answer> struct 
irq_hw_number_t <token> <answer> hwirq, 
unsigned <token> *irq) <answer> int 
struct irq_desc <token> = NULL; <answer> *desc 
<token> irq_data *data; <answer> struct 
int irq_domain_xlate_onecell(struct irq_domain *d, struct device_node <token> <answer> *ctrlr, 
const <token> *intspec, unsigned int intsize, <answer> u32 
<token> long *out_hwirq, unsigned int *out_type) <answer> unsigned 
if (WARN_ON(intsize <token> 1)) <answer> < 
return <token> <answer> -EINVAL; 
*out_hwirq <token> intspec[0]; <answer> = 
<token> = IRQ_TYPE_NONE; <answer> *out_type 
<token> 0; <answer> return 
int irq_domain_xlate_twocell(struct irq_domain <token> struct device_node *ctrlr, <answer> *d, 
const u32 *intspec, unsigned <token> intsize, <answer> int 
irq_hw_number_t *out_hwirq, unsigned <token> *out_type) <answer> int 
<token> irq_fwspec fwspec; <answer> struct 
<token> intspec, intsize, &fwspec); <answer> of_phandle_args_to_fwspec(ctrlr, 
return irq_domain_translate_twocell(d, &fwspec, <token> out_type); <answer> out_hwirq, 
int irq_domain_xlate_onetwocell(struct irq_domain <token> <answer> *d, 
struct device_node <token> <answer> *ctrlr, 
const u32 <token> unsigned int intsize, <answer> *intspec, 
unsigned long *out_hwirq, unsigned <token> *out_type) <answer> int 
if (WARN_ON(intsize <token> 1)) <answer> < 
return <token> <answer> -EINVAL; 
*out_hwirq <token> intspec[0]; <answer> = 
<token> (intsize > 1) <answer> if 
*out_type <token> intspec[1] & IRQ_TYPE_SENSE_MASK; <answer> = 
<token> = IRQ_TYPE_NONE; <answer> *out_type 
return <token> <answer> 0; 
const <token> irq_domain_ops irq_domain_simple_ops = { <answer> struct 
<token> = irq_domain_xlate_onetwocell, <answer> .xlate 
int <token> irq_domain *d, <answer> irq_domain_translate_onecell(struct 
struct <token> *fwspec, <answer> irq_fwspec 
<token> long *out_hwirq, <answer> unsigned 
<token> int *out_type) <answer> unsigned 
<token> (WARN_ON(fwspec->param_count < 1)) <answer> if 
<token> -EINVAL; <answer> return 
*out_hwirq <token> fwspec->param[0]; <answer> = 
*out_type = <token> <answer> IRQ_TYPE_NONE; 
return <token> <answer> 0; 
int <token> irq_domain *d, <answer> irq_domain_translate_twocell(struct 
<token> irq_fwspec *fwspec, <answer> struct 
<token> long *out_hwirq, <answer> unsigned 
<token> int *out_type) <answer> unsigned 
if (WARN_ON(fwspec->param_count < <token> <answer> 2)) 
<token> -EINVAL; <answer> return 
*out_hwirq <token> fwspec->param[0]; <answer> = 
*out_type <token> fwspec->param[1] & IRQ_TYPE_SENSE_MASK; <answer> = 
<token> 0; <answer> return 
int <token> virq, unsigned int cnt, irq_hw_number_t hwirq, <answer> irq_domain_alloc_descs(int 
int node, const struct <token> *affinity) <answer> irq_affinity_desc 
unsigned int <token> <answer> hint; 
if (virq >= 0) <token> <answer> { 
virq = <token> virq, cnt, node, THIS_MODULE, <answer> __irq_alloc_descs(virq, 
} <token> { <answer> else 
hint = hwirq <token> nr_irqs; <answer> % 
if <token> == 0) <answer> (hint 
virq = __irq_alloc_descs(-1, hint, <token> node, THIS_MODULE, <answer> cnt, 
<token> (virq <= 0 && hint > 1) { <answer> if 
virq = __irq_alloc_descs(-1, 1, cnt, <token> THIS_MODULE, <answer> node, 
<token> virq; <answer> return 
void irq_domain_reset_irq_data(struct irq_data <token> <answer> *irq_data) 
<token> = 0; <answer> irq_data->hwirq 
irq_data->chip = <token> <answer> &no_irq_chip; 
<token> = NULL; <answer> irq_data->chip_data 
<token> CONFIG_IRQ_DOMAIN_HIERARCHY <answer> #ifdef 
<token> irq_domain *irq_domain_create_hierarchy(struct irq_domain *parent, <answer> struct 
<token> int flags, <answer> unsigned 
unsigned int <token> <answer> size, 
struct fwnode_handle <token> <answer> *fwnode, 
<token> struct irq_domain_ops *ops, <answer> const 
void <token> <answer> *host_data) 
struct irq_domain <token> <answer> *domain; 
if <token> <answer> (size) 
domain <token> __irq_domain_create(fwnode, size, size, 0, ops, host_data); <answer> = 
domain = __irq_domain_create(fwnode, 0, ~0, 0, ops, <token> <answer> host_data); 
if <token> { <answer> (domain) 
<token> (parent) <answer> if 
domain->root = <token> <answer> parent->root; 
domain->parent <token> parent; <answer> = 
domain->flags |= <token> <answer> flags; 
return <token> <answer> domain; 
static <token> irq_domain_insert_irq(int virq) <answer> void 
<token> irq_data *data; <answer> struct 
for <token> = irq_get_irq_data(virq); data; data = data->parent_data) { <answer> (data 
struct irq_domain <token> = data->domain; <answer> *domain 
irq_domain_set_mapping(domain, <token> data); <answer> data->hwirq, 
irq_clear_status_flags(virq, <token> <answer> IRQ_NOREQUEST); 
static void irq_domain_remove_irq(int <token> <answer> virq) 
struct irq_data <token> <answer> *data; 
<token> IRQ_NOREQUEST); <answer> irq_set_status_flags(virq, 
irq_set_chip_and_handler(virq, <token> NULL); <answer> NULL, 
for (data = irq_get_irq_data(virq); <token> data = data->parent_data) { <answer> data; 
struct irq_domain *domain <token> data->domain; <answer> = 
irq_hw_number_t hwirq = <token> <answer> data->hwirq; 
irq_domain_clear_mapping(domain, <token> <answer> hwirq); 
static struct <token> *irq_domain_insert_irq_data(struct irq_domain *domain, <answer> irq_data 
struct <token> *child) <answer> irq_data 
struct irq_data <token> <answer> *irq_data; 
irq_data <token> kzalloc_node(sizeof(*irq_data), GFP_KERNEL, <answer> = 
if (irq_data) <token> <answer> { 
<token> = irq_data; <answer> child->parent_data 
irq_data->irq <token> child->irq; <answer> = 
irq_data->common = <token> <answer> child->common; 
irq_data->domain <token> domain; <answer> = 
<token> irq_data; <answer> return 
static void <token> irq_data *irq_data) <answer> __irq_domain_free_hierarchy(struct 
struct <token> *tmp; <answer> irq_data 
while (irq_data) <token> <answer> { 
<token> = irq_data; <answer> tmp 
irq_data <token> irq_data->parent_data; <answer> = 
static void irq_domain_free_irq_data(unsigned int virq, unsigned <token> nr_irqs) <answer> int 
struct <token> *irq_data, *tmp; <answer> irq_data 
<token> i; <answer> int 
for (i = 0; i < <token> i++) { <answer> nr_irqs; 
irq_data = irq_get_irq_data(virq <token> i); <answer> + 
tmp <token> irq_data->parent_data; <answer> = 
irq_data->parent_data = <token> <answer> NULL; 
irq_data->domain <token> NULL; <answer> = 
<token> irq_domain_disconnect_hierarchy(struct irq_domain *domain, <answer> int 
unsigned int <token> <answer> virq) 
struct irq_data <token> <answer> *irqd; 
irqd <token> irq_domain_get_irq_data(domain, virq); <answer> = 
<token> (!irqd) <answer> if 
<token> -EINVAL; <answer> return 
<token> = ERR_PTR(-ENOTCONN); <answer> irqd->chip 
<token> 0; <answer> return 
<token> int irq_domain_trim_hierarchy(unsigned int virq) <answer> static 
struct irq_data *tail, *irqd, <token> <answer> *irq_data; 
irq_data = <token> <answer> irq_get_irq_data(virq); 
tail = <token> <answer> NULL; 
for (irqd = irq_data->parent_data; irqd; irq_data = <token> irqd = irqd->parent_data) { <answer> irqd, 
<token> irq_data *irq_domain_get_irq_data(struct irq_domain *domain, <answer> struct 
unsigned <token> virq) <answer> int 
<token> irq_data *irq_data; <answer> struct 
for (irq_data <token> irq_get_irq_data(virq); irq_data; <answer> = 
<token> = irq_data->parent_data) <answer> irq_data 
if (irq_data->domain <token> domain) <answer> == 
<token> irq_data; <answer> return 
<token> NULL; <answer> return 
int irq_domain_set_hwirq_and_chip(struct irq_domain <token> unsigned int virq, <answer> *domain, 
irq_hw_number_t <token> <answer> hwirq, 
const struct irq_chip <token> <answer> *chip, 
void <token> <answer> *chip_data) 
struct irq_data *irq_data = <token> virq); <answer> irq_domain_get_irq_data(domain, 
<token> (!irq_data) <answer> if 
<token> -ENOENT; <answer> return 
irq_data->hwirq = <token> <answer> hwirq; 
irq_data->chip = (struct irq_chip *)(chip ? <token> : &no_irq_chip); <answer> chip 
<token> = chip_data; <answer> irq_data->chip_data 
return <token> <answer> 0; 
void irq_domain_set_info(struct irq_domain *domain, <token> int virq, <answer> unsigned 
<token> hwirq, const struct irq_chip *chip, <answer> irq_hw_number_t 
void <token> irq_flow_handler_t handler, <answer> *chip_data, 
void *handler_data, const char <token> <answer> *handler_name) 
irq_domain_set_hwirq_and_chip(domain, virq, hwirq, <token> chip_data); <answer> chip, 
<token> handler, 0, handler_name); <answer> __irq_set_handler(virq, 
<token> handler_data); <answer> irq_set_handler_data(virq, 
void irq_domain_free_irqs_common(struct irq_domain *domain, unsigned <token> virq, <answer> int 
unsigned <token> nr_irqs) <answer> int 
struct <token> *irq_data; <answer> irq_data 
<token> i; <answer> int 
for (i = <token> i < nr_irqs; i++) { <answer> 0; 
irq_data = irq_domain_get_irq_data(domain, <token> + i); <answer> virq 
if <token> <answer> (irq_data) 
irq_domain_free_irqs_parent(domain, virq, <token> <answer> nr_irqs); 
void irq_domain_free_irqs_top(struct irq_domain *domain, unsigned <token> virq, <answer> int 
unsigned <token> nr_irqs) <answer> int 
int <token> <answer> i; 
for (i = 0; i < nr_irqs; <token> { <answer> i++) 
irq_set_handler_data(virq + i, <token> <answer> NULL); 
irq_set_handler(virq <token> i, NULL); <answer> + 
irq_domain_free_irqs_common(domain, <token> nr_irqs); <answer> virq, 
static void irq_domain_free_irqs_hierarchy(struct <token> *domain, <answer> irq_domain 
<token> int irq_base, <answer> unsigned 
unsigned int <token> <answer> nr_irqs) 
<token> int i; <answer> unsigned 
if <token> <answer> (!domain->ops->free) 
for (i = 0; i < <token> i++) { <answer> nr_irqs; 
if <token> irq_base + i)) <answer> (irq_domain_get_irq_data(domain, 
domain->ops->free(domain, irq_base + <token> 1); <answer> i, 
int irq_domain_alloc_irqs_hierarchy(struct <token> *domain, <answer> irq_domain 
unsigned int <token> <answer> irq_base, 
unsigned int <token> void *arg) <answer> nr_irqs, 
<token> (!domain->ops->alloc) { <answer> if 
pr_debug("domain->ops->alloc() is <token> <answer> NULL\n"); 
return <token> <answer> -ENOSYS; 
return domain->ops->alloc(domain, <token> nr_irqs, arg); <answer> irq_base, 
static int <token> irq_domain *domain, int irq_base, <answer> irq_domain_alloc_irqs_locked(struct 
unsigned int <token> int node, void *arg, <answer> nr_irqs, 
bool realloc, const struct <token> *affinity) <answer> irq_affinity_desc 
int i, ret, <token> <answer> virq; 
if (realloc && irq_base >= 0) <token> <answer> { 
<token> = irq_base; <answer> virq 
<token> else { <answer> } 
virq = irq_domain_alloc_descs(irq_base, nr_irqs, 0, <token> <answer> node, 
if (virq < <token> { <answer> 0) 
pr_debug("cannot <token> IRQ(base %d, count %d)\n", <answer> allocate 
irq_base, <token> <answer> nr_irqs); 
<token> virq; <answer> return 
if <token> virq, nr_irqs)) { <answer> (irq_domain_alloc_irq_data(domain, 
pr_debug("cannot <token> memory for IRQ%d\n", virq); <answer> allocate 
ret <token> -ENOMEM; <answer> = 
<token> out_free_desc; <answer> goto 
ret = irq_domain_alloc_irqs_hierarchy(domain, virq, nr_irqs, <token> <answer> arg); 
if <token> < 0) <answer> (ret 
<token> out_free_irq_data; <answer> goto 
for (i = <token> i < nr_irqs; i++) { <answer> 0; 
<token> = irq_domain_trim_hierarchy(virq + i); <answer> ret 
if <token> <answer> (ret) 
<token> out_free_irq_data; <answer> goto 
for (i = 0; i < <token> i++) <answer> nr_irqs; 
irq_domain_insert_irq(virq + <token> <answer> i); 
return <token> <answer> virq; 
irq_domain_free_irq_data(virq, <token> <answer> nr_irqs); 
<token> nr_irqs); <answer> irq_free_descs(virq, 
return <token> <answer> ret; 
int __irq_domain_alloc_irqs(struct <token> *domain, int irq_base, <answer> irq_domain 
<token> int nr_irqs, int node, void *arg, <answer> unsigned 
<token> realloc, const struct irq_affinity_desc *affinity) <answer> bool 
<token> ret; <answer> int 
if <token> == NULL) { <answer> (domain 
domain = <token> <answer> irq_default_domain; 
if (WARN(!domain, "domain is NULL; cannot <token> IRQ\n")) <answer> allocate 
return <token> <answer> -EINVAL; 
ret = <token> irq_base, nr_irqs, node, arg, <answer> irq_domain_alloc_irqs_locked(domain, 
realloc, <token> <answer> affinity); 
<token> ret; <answer> return 
int irq_domain_push_irq(struct irq_domain *domain, int <token> void *arg) <answer> virq, 
struct <token> *irq_data = irq_get_irq_data(virq); <answer> irq_data 
struct irq_data <token> <answer> *parent_irq_data; 
<token> irq_desc *desc; <answer> struct 
<token> rv = 0; <answer> int 
desc = <token> <answer> irq_to_desc(virq); 
<token> (!desc) <answer> if 
return <token> <answer> -EINVAL; 
<token> (WARN_ON(desc->action)) <answer> if 
<token> -EBUSY; <answer> return 
if (domain == <token> <answer> NULL) 
return <token> <answer> -EINVAL; 
<token> (WARN_ON(!irq_domain_is_hierarchy(domain))) <answer> if 
return <token> <answer> -EINVAL; 
if <token> <answer> (!irq_data) 
<token> -EINVAL; <answer> return 
<token> (domain->parent != irq_data->domain) <answer> if 
<token> -EINVAL; <answer> return 
parent_irq_data = kzalloc_node(sizeof(*parent_irq_data), <token> <answer> GFP_KERNEL, 
if <token> <answer> (!parent_irq_data) 
<token> -ENOMEM; <answer> return 
irq_data->parent_data <token> parent_irq_data; <answer> = 
irq_data->domain <token> domain; <answer> = 
<token> = 0; <answer> irq_data->mask 
irq_data->hwirq = <token> <answer> 0; 
irq_data->chip = <token> <answer> NULL; 
irq_data->chip_data = <token> <answer> NULL; 
int irq_domain_pop_irq(struct irq_domain *domain, int <token> <answer> virq) 
<token> irq_data *irq_data = irq_get_irq_data(virq); <answer> struct 
struct <token> *parent_irq_data; <answer> irq_data 
struct <token> *tmp_irq_data; <answer> irq_data 
struct <token> *desc; <answer> irq_desc 
<token> = irq_to_desc(virq); <answer> desc 
<token> (!desc) <answer> if 
<token> -EINVAL; <answer> return 
<token> (WARN_ON(desc->action)) <answer> if 
<token> -EBUSY; <answer> return 
if <token> == NULL) <answer> (domain 
<token> -EINVAL; <answer> return 
if <token> <answer> (!irq_data) 
return <token> <answer> -EINVAL; 
tmp_irq_data = <token> virq); <answer> irq_domain_get_irq_data(domain, 
void irq_domain_free_irqs(unsigned int virq, unsigned int <token> <answer> nr_irqs) 
struct irq_data *data <token> irq_get_irq_data(virq); <answer> = 
struct <token> *domain; <answer> irq_domain 
<token> i; <answer> int 
if (WARN(!data || !data->domain || <token> <answer> !data->domain->ops->free, 
"NULL pointer, cannot <token> irq\n")) <answer> free 
<token> = data->domain; <answer> domain 
for <token> = 0; i < nr_irqs; i++) <answer> (i 
irq_domain_remove_irq(virq + <token> <answer> i); 
irq_domain_free_irqs_hierarchy(domain, virq, <token> <answer> nr_irqs); 
irq_domain_free_irq_data(virq, <token> <answer> nr_irqs); 
irq_free_descs(virq, <token> <answer> nr_irqs); 
static void irq_domain_free_one_irq(struct irq_domain *domain, unsigned <token> virq) <answer> int 
<token> (irq_domain_is_msi_device(domain)) <answer> if 
<token> virq); <answer> msi_device_domain_free_wired(domain, 
<token> 1); <answer> irq_domain_free_irqs(virq, 
<token> irq_domain_alloc_irqs_parent(struct irq_domain *domain, <answer> int 
unsigned int irq_base, <token> int nr_irqs, <answer> unsigned 
<token> *arg) <answer> void 
if <token> <answer> (!domain->parent) 
<token> -ENOSYS; <answer> return 
return <token> irq_base, <answer> irq_domain_alloc_irqs_hierarchy(domain->parent, 
<token> arg); <answer> nr_irqs, 
<token> irq_domain_free_irqs_parent(struct irq_domain *domain, <answer> void 
unsigned int <token> unsigned int nr_irqs) <answer> irq_base, 
if <token> <answer> (!domain->parent) 
<token> irq_base, nr_irqs); <answer> irq_domain_free_irqs_hierarchy(domain->parent, 
static void <token> irq_data *irq_data) <answer> __irq_domain_deactivate_irq(struct 
if (irq_data && irq_data->domain) <token> <answer> { 
struct irq_domain *domain <token> irq_data->domain; <answer> = 
if <token> <answer> (domain->ops->deactivate) 
domain->ops->deactivate(domain, <token> <answer> irq_data); 
<token> (irq_data->parent_data) <answer> if 
static int <token> irq_data *irqd, bool reserve) <answer> __irq_domain_activate_irq(struct 
int ret <token> 0; <answer> = 
if <token> && irqd->domain) { <answer> (irqd 
struct irq_domain <token> = irqd->domain; <answer> *domain 
if <token> <answer> (irqd->parent_data) 
ret = <token> <answer> __irq_domain_activate_irq(irqd->parent_data, 
if (!ret <token> domain->ops->activate) { <answer> && 
ret = domain->ops->activate(domain, <token> reserve); <answer> irqd, 
int irq_domain_activate_irq(struct <token> *irq_data, bool reserve) <answer> irq_data 
<token> ret = 0; <answer> int 
if <token> <answer> (!irqd_is_activated(irq_data)) 
ret <token> __irq_domain_activate_irq(irq_data, reserve); <answer> = 
<token> (!ret) <answer> if 
<token> ret; <answer> return 
void irq_domain_deactivate_irq(struct irq_data <token> <answer> *irq_data) 
if (irqd_is_activated(irq_data)) <token> <answer> { 
static void <token> irq_domain *domain) <answer> irq_domain_check_hierarchy(struct 
struct irq_data *irq_domain_get_irq_data(struct irq_domain <token> <answer> *domain, 
unsigned int <token> <answer> virq) 
struct irq_data *irq_data = <token> <answer> irq_get_irq_data(virq); 
return (irq_data && irq_data->domain == domain) <token> irq_data : NULL; <answer> ? 
void irq_domain_set_info(struct irq_domain *domain, <token> int virq, <answer> unsigned 
irq_hw_number_t hwirq, <token> struct irq_chip *chip, <answer> const 
void *chip_data, <token> handler, <answer> irq_flow_handler_t 
void *handler_data, const char <token> <answer> *handler_name) 
<token> chip, handler, handler_name); <answer> irq_set_chip_and_handler_name(virq, 
irq_set_chip_data(virq, <token> <answer> chip_data); 
<token> handler_data); <answer> irq_set_handler_data(virq, 
<token> int irq_domain_alloc_irqs_locked(struct irq_domain *domain, int irq_base, <answer> static 
unsigned <token> nr_irqs, int node, void *arg, <answer> int 
bool realloc, <token> struct irq_affinity_desc *affinity) <answer> const 
return <token> <answer> -EINVAL; 
static void <token> irq_domain *domain) { } <answer> irq_domain_check_hierarchy(struct 
static void irq_domain_free_one_irq(struct irq_domain *domain, <token> int virq) { } <answer> unsigned 
<token> <linux/device.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/clk.h> 
<token> <media/cec.h> <answer> #include 
<token> "adv7511.h" <answer> #include 
static const u8 <token> = { <answer> ADV7511_REG_CEC_RX_FRAME_HDR[] 
static const u8 <token> = { <answer> ADV7511_REG_CEC_RX_FRAME_LEN[] 
<token> ADV7511_INT1_CEC_MASK \ <answer> #define 
(ADV7511_INT1_CEC_TX_READY | ADV7511_INT1_CEC_TX_ARBIT_LOST | <token> <answer> \ 
ADV7511_INT1_CEC_TX_RETRY_TIMEOUT | ADV7511_INT1_CEC_RX_READY1 | <token> <answer> \ 
ADV7511_INT1_CEC_RX_READY2 <token> ADV7511_INT1_CEC_RX_READY3) <answer> | 
static void adv_cec_tx_raw_status(struct adv7511 *adv7511, <token> tx_raw_status) <answer> u8 
unsigned int offset = <token> <answer> adv7511->info->reg_cec_offset; 
unsigned <token> val; <answer> int 
<token> (regmap_read(adv7511->regmap_cec, <answer> if 
ADV7511_REG_CEC_TX_ENABLE + <token> &val)) <answer> offset, 
<token> ((val & 0x01) == 0) <answer> if 
<token> (tx_raw_status & ADV7511_INT1_CEC_TX_ARBIT_LOST) { <answer> if 
if <token> & ADV7511_INT1_CEC_TX_RETRY_TIMEOUT) { <answer> (tx_raw_status 
u8 <token> <answer> status; 
u8 err_cnt = <token> <answer> 0; 
u8 <token> = 0; <answer> nack_cnt 
u8 low_drive_cnt <token> 0; <answer> = 
unsigned <token> cnt; <answer> int 
status <token> CEC_TX_STATUS_MAX_RETRIES; <answer> = 
<token> (regmap_read(adv7511->regmap_cec, <answer> if 
ADV7511_REG_CEC_TX_LOW_DRV_CNT <token> offset, &cnt)) { <answer> + 
err_cnt = <token> <answer> 1; 
<token> |= CEC_TX_STATUS_ERROR; <answer> status 
<token> else { <answer> } 
<token> = cnt & 0xf; <answer> nack_cnt 
if <token> <answer> (nack_cnt) 
status <token> CEC_TX_STATUS_NACK; <answer> |= 
low_drive_cnt = cnt <token> 4; <answer> >> 
<token> (low_drive_cnt) <answer> if 
<token> |= CEC_TX_STATUS_LOW_DRIVE; <answer> status 
cec_transmit_done(adv7511->cec_adap, <token> <answer> status, 
0, <token> low_drive_cnt, err_cnt); <answer> nack_cnt, 
if (tx_raw_status & <token> { <answer> ADV7511_INT1_CEC_TX_READY) 
<token> CEC_TX_STATUS_OK); <answer> cec_transmit_attempt_done(adv7511->cec_adap, 
static void adv7511_cec_rx(struct <token> *adv7511, int rx_buf) <answer> adv7511 
<token> int offset = adv7511->info->reg_cec_offset; <answer> unsigned 
struct cec_msg msg <token> {}; <answer> = 
unsigned int <token> <answer> len; 
unsigned <token> val; <answer> int 
<token> i; <answer> u8 
<token> (regmap_read(adv7511->regmap_cec, <answer> if 
ADV7511_REG_CEC_RX_FRAME_LEN[rx_buf] <token> offset, &len)) <answer> + 
msg.len <token> len & 0x1f; <answer> = 
<token> (msg.len > 16) <answer> if 
<token> = 16; <answer> msg.len 
if <token> <answer> (!msg.len) 
<token> (i = 0; i < msg.len; i++) { <answer> for 
i + ADV7511_REG_CEC_RX_FRAME_HDR[rx_buf] + <token> <answer> offset, 
<token> = val; <answer> msg.msg[i] 
for (i <token> 0; i < 3; i++) { <answer> = 
unsigned int timestamp = (rx_status >> (2 <token> i)) & 0x3; <answer> * 
if <token> <answer> (timestamp) 
rx_order[timestamp - <token> = i; <answer> 1] 
<token> + offset, <answer> ADV7511_REG_CEC_TX_RETRY 
0x70, max(1, attempts - <token> << 4); <answer> 1) 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/of.h> 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/mfd/rk808.h> 
#include <token> <answer> <linux/regmap.h> 
<token> <linux/module.h> <answer> #include 
<token> <linux/reboot.h> <answer> #include 
#include <token> <answer> <linux/i2c.h> 
struct <token> { <answer> odroid_go_ultra_poweroff_data 
struct <token> *dev; <answer> device 
struct <token> *rk817; <answer> device 
<token> device *rk818; <answer> struct 
<token> int odroid_go_ultra_poweroff_prepare(struct sys_off_data *data) <answer> static 
<token> odroid_go_ultra_poweroff_data *poweroff_data = data->cb_data; <answer> struct 
struct regmap *rk817, <token> <answer> *rk818; 
<token> ret; <answer> int 
#include <token> <answer> <linux/sched.h> 
<token> <linux/sched/debug.h> <answer> #include 
#include <token> <answer> <linux/sched/task_stack.h> 
#include <token> <answer> <linux/stacktrace.h> 
#include <token> <answer> <linux/export.h> 
<token> <asm/stacktrace.h> <answer> #include 
static <token> save_raw_context_stack(struct stack_trace *trace, <answer> void 
unsigned long reg29, int <token> <answer> savesched) 
unsigned long *sp <token> (unsigned long *)reg29; <answer> = 
unsigned long <token> <answer> addr; 
<token> (!kstack_end(sp)) { <answer> while 
addr = <token> <answer> *sp++; 
if (__kernel_text_address(addr) <token> <answer> && 
<token> || !in_sched_functions(addr))) { <answer> (savesched 
if <token> > 0) <answer> (trace->skip 
trace->entries[trace->nr_entries++] <token> addr; <answer> = 
if (trace->nr_entries >= <token> <answer> trace->max_entries) 
static void save_context_stack(struct stack_trace <token> <answer> *trace, 
struct task_struct *tsk, struct pt_regs *regs, <token> savesched) <answer> int 
unsigned long sp = <token> <answer> regs->regs[29]; 
<token> CONFIG_KALLSYMS <answer> #ifdef 
unsigned <token> ra = regs->regs[31]; <answer> long 
unsigned long <token> = regs->cp0_epc; <answer> pc 
if (raw_show_trace || !__kernel_text_address(pc)) <token> <answer> { 
unsigned long stack_page <token> <answer> = 
<token> long)task_stack_page(tsk); <answer> (unsigned 
if (stack_page && <token> >= stack_page && <answer> sp 
sp <token> stack_page + THREAD_SIZE - 32) <answer> <= 
save_raw_context_stack(trace, sp, <token> <answer> savesched); 
<token> { <answer> do 
if (savesched || !in_sched_functions(pc)) <token> <answer> { 
if (trace->skip > <token> <answer> 0) 
<token> = pc; <answer> trace->entries[trace->nr_entries++] 
<token> (trace->nr_entries >= trace->max_entries) <answer> if 
pc = unwind_stack(tsk, &sp, pc, <token> <answer> &ra); 
} while <token> <answer> (pc); 
save_raw_context_stack(trace, <token> savesched); <answer> sp, 
<token> save_stack_trace(struct stack_trace *trace) <answer> void 
save_stack_trace_tsk(current, <token> <answer> trace); 
void save_stack_trace_tsk(struct task_struct <token> struct stack_trace *trace) <answer> *tsk, 
struct <token> dummyregs; <answer> pt_regs 
struct pt_regs *regs = <token> <answer> &dummyregs; 
<token> || !trace->max_entries); <answer> WARN_ON(trace->nr_entries 
<token> (tsk != current) { <answer> if 
regs->regs[29] <token> tsk->thread.reg29; <answer> = 
<token> = 0; <answer> regs->regs[31] 
regs->cp0_epc <token> tsk->thread.reg31; <answer> = 
} <token> <answer> else 
save_context_stack(trace, tsk, regs, tsk == <token> <answer> current); 
#include <token> <answer> <stdio.h> 
<token> <stdlib.h> <answer> #include 
#include <token> <answer> <sys/auxv.h> 
#include <token> <answer> "helper.h" 
<token> main(void) <answer> int 
<token> signatures signed_vals; <answer> struct 
unsigned long <token> <answer> hwcaps; 
size_t <token> <answer> val; 
<token> sizeof(size_t), 1, stdin); <answer> fread(&val, 
<token> = getauxval(AT_HWCAP); <answer> hwcaps 
if (hwcaps & HWCAP_PACA) <token> <answer> { 
<token> = keyia_sign(val); <answer> signed_vals.keyia 
signed_vals.keyib <token> keyib_sign(val); <answer> = 
signed_vals.keyda = <token> <answer> keyda_sign(val); 
signed_vals.keydb <token> keydb_sign(val); <answer> = 
signed_vals.keyg = (hwcaps & HWCAP_PACG) ? <token> : 0; <answer> keyg_sign(val) 
<token> sizeof(struct signatures), 1, stdout); <answer> fwrite(&signed_vals, 
return <token> <answer> 0; 
#include <token> <answer> <linux/clk.h> 
#include <token> <answer> <linux/debugfs.h> 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/hdmi.h> 
#include <token> <answer> <linux/math64.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/of.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
#include <token> <answer> <linux/pm_opp.h> 
<token> <linux/pm_runtime.h> <answer> #include 
<token> <linux/regulator/consumer.h> <answer> #include 
#include <token> <answer> <linux/reset.h> 
#include <token> <answer> <soc/tegra/common.h> 
#include <token> <answer> <sound/hdmi-codec.h> 
<token> <drm/drm_bridge_connector.h> <answer> #include 
#include <token> <answer> <drm/drm_atomic_helper.h> 
#include <token> <answer> <drm/drm_crtc.h> 
<token> <drm/drm_debugfs.h> <answer> #include 
<token> <drm/drm_edid.h> <answer> #include 
<token> <drm/drm_eld.h> <answer> #include 
<token> <drm/drm_file.h> <answer> #include 
#include <token> <answer> <drm/drm_fourcc.h> 
#include <token> <answer> <drm/drm_probe_helper.h> 
#include <token> <answer> <drm/drm_simple_kms_helper.h> 
#include <token> <answer> "hda.h" 
<token> "hdmi.h" <answer> #include 
<token> "drm.h" <answer> #include 
#include <token> <answer> "dc.h" 
#include <token> <answer> "trace.h" 
#define HDMI_ELD_BUFFER_SIZE <token> <answer> 96 
struct tmds_config <token> <answer> { 
unsigned int <token> <answer> pclk; 
<token> pll0; <answer> u32 
u32 <token> <answer> pll1; 
u32 <token> <answer> pe_current; 
<token> drive_current; <answer> u32 
u32 <token> <answer> peak_current; 
struct tegra_hdmi_config <token> <answer> { 
<token> struct tmds_config *tmds; <answer> const 
<token> int num_tmds; <answer> unsigned 
unsigned long <token> <answer> fuse_override_offset; 
u32 <token> <answer> fuse_override_value; 
<token> has_sor_io_peak_current; <answer> bool 
<token> has_hda; <answer> bool 
bool <token> <answer> has_hbr; 
<token> tegra_hdmi { <answer> struct 
struct <token> client; <answer> host1x_client 
struct tegra_output <token> <answer> output; 
struct <token> *dev; <answer> device 
struct regulator <token> <answer> *hdmi; 
struct <token> *pll; <answer> regulator 
<token> regulator *vdd; <answer> struct 
void __iomem <token> <answer> *regs; 
unsigned <token> irq; <answer> int 
<token> clk *clk_parent; <answer> struct 
struct <token> *clk; <answer> clk 
struct <token> *rst; <answer> reset_control 
<token> struct tegra_hdmi_config *config; <answer> const 
unsigned <token> audio_source; <answer> int 
struct <token> format; <answer> tegra_hda_format 
unsigned <token> pixel_clock; <answer> int 
bool <token> <answer> stereo; 
<token> dvi; <answer> bool 
struct drm_info_list <token> <answer> *debugfs_files; 
struct platform_device <token> <answer> *audio_pdev; 
struct <token> audio_lock; <answer> mutex 
<token> inline struct tegra_hdmi * <answer> static 
host1x_client_to_hdmi(struct <token> *client) <answer> host1x_client 
return container_of(client, struct <token> client); <answer> tegra_hdmi, 
static inline struct tegra_hdmi *to_hdmi(struct <token> *output) <answer> tegra_output 
return <token> struct tegra_hdmi, output); <answer> container_of(output, 
#define <token> 216000000 <answer> HDMI_AUDIOCLK_FREQ 
#define <token> 56 <answer> HDMI_REKEY_DEFAULT 
<token> { <answer> enum 
AUTO <token> 0, <answer> = 
static inline u32 tegra_hdmi_readl(struct <token> *hdmi, <answer> tegra_hdmi 
unsigned int <token> <answer> offset) 
u32 value = readl(hdmi->regs <token> (offset << 2)); <answer> + 
<token> offset, value); <answer> trace_hdmi_readl(hdmi->dev, 
return <token> <answer> value; 
<token> inline void tegra_hdmi_writel(struct tegra_hdmi *hdmi, u32 value, <answer> static 
<token> int offset) <answer> unsigned 
<token> offset, value); <answer> trace_hdmi_writel(hdmi->dev, 
writel(value, hdmi->regs <token> (offset << 2)); <answer> + 
<token> tegra_hdmi_audio_config { <answer> struct 
<token> int n; <answer> unsigned 
unsigned <token> cts; <answer> int 
unsigned int <token> <answer> aval; 
<token> const struct tmds_config tegra20_tmds_config[] = { <answer> static 
<token> (hdmi->config->has_hda) { <answer> if 
<token> (hdmi->format.channels == 2) <answer> if 
value = <token> <answer> SOR_AUDIO_CNTRL0_INJECT_NULLSMPL; 
value <token> 0; <answer> = 
value <token> source; <answer> |= 
tegra_hdmi_writel(hdmi, value, <token> <answer> HDMI_NV_PDISP_SOR_AUDIO_CNTRL0); 
value <token> AUDIO_CNTRL0_FRAMES_PER_BLOCK(0xc0) | <answer> = 
if <token> <answer> (!hdmi->config->has_hda) 
value |= <token> <answer> source; 
<token> value, HDMI_NV_PDISP_AUDIO_CNTRL0); <answer> tegra_hdmi_writel(hdmi, 
<token> (hdmi->config->has_hbr) { <answer> if 
value = tegra_hdmi_readl(hdmi, <token> <answer> HDMI_NV_PDISP_SOR_AUDIO_SPARE0); 
value <token> SOR_AUDIO_SPARE0_HBR_ENABLE; <answer> |= 
<token> value, HDMI_NV_PDISP_SOR_AUDIO_SPARE0); <answer> tegra_hdmi_writel(hdmi, 
err = <token> <answer> tegra_hdmi_get_audio_config(hdmi->format.sample_rate, 
hdmi->pixel_clock, <token> <answer> &config); 
if (err <token> 0) { <answer> < 
"cannot set <token> to %u Hz at %u Hz pixel clock\n", <answer> audio 
<token> hdmi->pixel_clock); <answer> hdmi->format.sample_rate, 
<token> err; <answer> return 
<token> "audio: pixclk=%u, n=%u, cts=%u, aval=%u\n", <answer> dev_dbg(hdmi->dev, 
hdmi->pixel_clock, <token> config.cts, config.aval); <answer> config.n, 
<token> 0, HDMI_NV_PDISP_HDMI_ACR_CTRL); <answer> tegra_hdmi_writel(hdmi, 
value = AUDIO_N_RESETF | <token> | <answer> AUDIO_N_GENERATE_ALTERNATE 
AUDIO_N_VALUE(config.n - <token> <answer> 1); 
tegra_hdmi_writel(hdmi, value, <token> <answer> HDMI_NV_PDISP_AUDIO_N); 
tegra_hdmi_writel(hdmi, ACR_SUBPACK_N(config.n) <token> ACR_ENABLE, <answer> | 
<token> ACR_SUBPACK_CTS(config.cts), <answer> tegra_hdmi_writel(hdmi, 
value = <token> | SPARE_FORCE_SW_CTS | SPARE_CTS_RESET_VAL(1); <answer> SPARE_HW_CTS 
tegra_hdmi_writel(hdmi, <token> HDMI_NV_PDISP_HDMI_SPARE); <answer> value, 
<token> = tegra_hdmi_readl(hdmi, HDMI_NV_PDISP_AUDIO_N); <answer> value 
value &= <token> <answer> ~AUDIO_N_RESETF; 
tegra_hdmi_writel(hdmi, <token> HDMI_NV_PDISP_AUDIO_N); <answer> value, 
<token> (hdmi->config->has_hda) <answer> if 
tegra_hdmi_write_aval(hdmi, <token> <answer> config.aval); 
return <token> <answer> 0; 
static <token> tegra_hdmi_disable_audio(struct tegra_hdmi *hdmi) <answer> void 
<token> value; <answer> u32 
value = <token> HDMI_NV_PDISP_HDMI_GENERIC_CTRL); <answer> tegra_hdmi_readl(hdmi, 
<token> &= ~GENERIC_CTRL_AUDIO; <answer> value 
tegra_hdmi_writel(hdmi, <token> HDMI_NV_PDISP_HDMI_GENERIC_CTRL); <answer> value, 
static <token> tegra_hdmi_enable_audio(struct tegra_hdmi *hdmi) <answer> void 
<token> value; <answer> u32 
<token> = tegra_hdmi_readl(hdmi, HDMI_NV_PDISP_HDMI_GENERIC_CTRL); <answer> value 
value |= <token> <answer> GENERIC_CTRL_AUDIO; 
tegra_hdmi_writel(hdmi, value, <token> <answer> HDMI_NV_PDISP_HDMI_GENERIC_CTRL); 
static void tegra_hdmi_write_eld(struct tegra_hdmi <token> <answer> *hdmi) 
size_t length = drm_eld_size(hdmi->output.connector.eld), <token> <answer> i; 
<token> value; <answer> u32 
for (i = 0; <token> < length; i++) <answer> i 
tegra_hdmi_writel(hdmi, i << 8 <token> hdmi->output.connector.eld[i], <answer> | 
for (i = length; <token> < HDMI_ELD_BUFFER_SIZE; i++) <answer> i 
tegra_hdmi_writel(hdmi, i <token> 8 | 0, <answer> << 
value = SOR_AUDIO_HDA_PRESENSE_VALID | <token> <answer> SOR_AUDIO_HDA_PRESENSE_PRESENT; 
<token> value, HDMI_NV_PDISP_SOR_AUDIO_HDA_PRESENSE); <answer> tegra_hdmi_writel(hdmi, 
static <token> u32 tegra_hdmi_subpack(const u8 *ptr, size_t size) <answer> inline 
u32 value <token> 0; <answer> = 
<token> i; <answer> size_t 
for (i = size; <token> > 0; i--) <answer> i 
value = (value << 8) | ptr[i - <token> <answer> 1]; 
<token> value; <answer> return 
static void tegra_hdmi_write_infopack(struct <token> *hdmi, const void *data, <answer> tegra_hdmi 
size_t <token> <answer> size) 
const <token> *ptr = data; <answer> u8 
<token> long offset; <answer> unsigned 
size_t <token> j; <answer> i, 
u32 <token> <answer> value; 
switch (ptr[0]) <token> <answer> { 
case <token> <answer> HDMI_INFOFRAME_TYPE_AVI: 
offset = <token> <answer> HDMI_NV_PDISP_HDMI_AVI_INFOFRAME_HEADER; 
<token> HDMI_INFOFRAME_TYPE_AUDIO: <answer> case 
offset <token> HDMI_NV_PDISP_HDMI_AUDIO_INFOFRAME_HEADER; <answer> = 
<token> HDMI_INFOFRAME_TYPE_VENDOR: <answer> case 
<token> = HDMI_NV_PDISP_HDMI_GENERIC_HEADER; <answer> offset 
<token> "unsupported infoframe type: %02x\n", <answer> dev_err(hdmi->dev, 
<token> = INFOFRAME_HEADER_TYPE(ptr[0]) | <answer> value 
<token> | <answer> INFOFRAME_HEADER_VERSION(ptr[1]) 
tegra_hdmi_writel(hdmi, <token> offset); <answer> value, 
for (i = 3, j = 0; i < size; i += 7, j <token> 8) { <answer> += 
<token> rem = size - i, num = min_t(size_t, rem, 4); <answer> size_t 
value <token> tegra_hdmi_subpack(&ptr[i], num); <answer> = 
tegra_hdmi_writel(hdmi, <token> offset++); <answer> value, 
num = min_t(size_t, rem <token> num, 3); <answer> - 
value = tegra_hdmi_subpack(&ptr[i + <token> num); <answer> 4], 
<token> value, offset++); <answer> tegra_hdmi_writel(hdmi, 
static void tegra_hdmi_setup_avi_infoframe(struct tegra_hdmi <token> <answer> *hdmi, 
struct <token> *mode) <answer> drm_display_mode 
struct hdmi_avi_infoframe <token> <answer> frame; 
u8 <token> <answer> buffer[17]; 
<token> err; <answer> ssize_t 
<token> = drm_hdmi_avi_infoframe_from_display_mode(&frame, <answer> err 
&hdmi->output.connector, <token> <answer> mode); 
if <token> < 0) { <answer> (err 
dev_err(hdmi->dev, <token> to setup AVI infoframe: %zd\n", err); <answer> "failed 
err = hdmi_avi_infoframe_pack(&frame, <token> sizeof(buffer)); <answer> buffer, 
<token> (err < 0) { <answer> if 
<token> "failed to pack AVI infoframe: %zd\n", err); <answer> dev_err(hdmi->dev, 
tegra_hdmi_write_infopack(hdmi, buffer, <token> <answer> err); 
static void tegra_hdmi_disable_avi_infoframe(struct tegra_hdmi <token> <answer> *hdmi) 
u32 <token> <answer> value; 
value <token> tegra_hdmi_readl(hdmi, HDMI_NV_PDISP_HDMI_AVI_INFOFRAME_CTRL); <answer> = 
value &= <token> <answer> ~INFOFRAME_CTRL_ENABLE; 
tegra_hdmi_writel(hdmi, <token> HDMI_NV_PDISP_HDMI_AVI_INFOFRAME_CTRL); <answer> value, 
<token> void tegra_hdmi_enable_avi_infoframe(struct tegra_hdmi *hdmi) <answer> static 
<token> value; <answer> u32 
value <token> tegra_hdmi_readl(hdmi, HDMI_NV_PDISP_HDMI_AVI_INFOFRAME_CTRL); <answer> = 
value <token> INFOFRAME_CTRL_ENABLE; <answer> |= 
<token> value, HDMI_NV_PDISP_HDMI_AVI_INFOFRAME_CTRL); <answer> tegra_hdmi_writel(hdmi, 
static void <token> tegra_hdmi *hdmi) <answer> tegra_hdmi_setup_audio_infoframe(struct 
struct hdmi_audio_infoframe <token> <answer> frame; 
<token> buffer[14]; <answer> u8 
ssize_t <token> <answer> err; 
<token> = hdmi_audio_infoframe_init(&frame); <answer> err 
if (err < 0) <token> <answer> { 
dev_err(hdmi->dev, "failed <token> setup audio infoframe: %zd\n", <answer> to 
frame.channels <token> hdmi->format.channels; <answer> = 
err = hdmi_audio_infoframe_pack(&frame, <token> sizeof(buffer)); <answer> buffer, 
if (err < <token> { <answer> 0) 
dev_err(hdmi->dev, "failed to pack audio <token> %zd\n", <answer> infoframe: 
tegra_hdmi_write_infopack(hdmi, buffer, min_t(size_t, <token> err)); <answer> 10, 
static void tegra_hdmi_disable_audio_infoframe(struct <token> *hdmi) <answer> tegra_hdmi 
<token> value; <answer> u32 
value <token> tegra_hdmi_readl(hdmi, HDMI_NV_PDISP_HDMI_AUDIO_INFOFRAME_CTRL); <answer> = 
value <token> ~INFOFRAME_CTRL_ENABLE; <answer> &= 
tegra_hdmi_writel(hdmi, <token> HDMI_NV_PDISP_HDMI_AUDIO_INFOFRAME_CTRL); <answer> value, 
static void tegra_hdmi_enable_audio_infoframe(struct <token> *hdmi) <answer> tegra_hdmi 
u32 <token> <answer> value; 
value = <token> HDMI_NV_PDISP_HDMI_AUDIO_INFOFRAME_CTRL); <answer> tegra_hdmi_readl(hdmi, 
value <token> INFOFRAME_CTRL_ENABLE; <answer> |= 
tegra_hdmi_writel(hdmi, <token> HDMI_NV_PDISP_HDMI_AUDIO_INFOFRAME_CTRL); <answer> value, 
<token> void tegra_hdmi_setup_stereo_infoframe(struct tegra_hdmi *hdmi) <answer> static 
<token> hdmi_vendor_infoframe frame; <answer> struct 
u8 <token> <answer> buffer[10]; 
ssize_t <token> <answer> err; 
<token> = HDMI_3D_STRUCTURE_FRAME_PACKING; <answer> frame.s3d_struct 
<token> = hdmi_vendor_infoframe_pack(&frame, buffer, sizeof(buffer)); <answer> err 
if (err <token> 0) { <answer> < 
dev_err(hdmi->dev, <token> to pack vendor infoframe: %zd\n", <answer> "failed 
<token> buffer, err); <answer> tegra_hdmi_write_infopack(hdmi, 
<token> void tegra_hdmi_disable_stereo_infoframe(struct tegra_hdmi *hdmi) <answer> static 
<token> value; <answer> u32 
value <token> tegra_hdmi_readl(hdmi, HDMI_NV_PDISP_HDMI_GENERIC_CTRL); <answer> = 
value <token> ~GENERIC_CTRL_ENABLE; <answer> &= 
tegra_hdmi_writel(hdmi, <token> HDMI_NV_PDISP_HDMI_GENERIC_CTRL); <answer> value, 
static <token> tegra_hdmi_enable_stereo_infoframe(struct tegra_hdmi *hdmi) <answer> void 
u32 <token> <answer> value; 
<token> = tegra_hdmi_readl(hdmi, HDMI_NV_PDISP_HDMI_GENERIC_CTRL); <answer> value 
value <token> GENERIC_CTRL_ENABLE; <answer> |= 
tegra_hdmi_writel(hdmi, <token> HDMI_NV_PDISP_HDMI_GENERIC_CTRL); <answer> value, 
static void <token> tegra_hdmi *hdmi, <answer> tegra_hdmi_setup_tmds(struct 
<token> struct tmds_config *tmds) <answer> const 
<token> value; <answer> u32 
tegra_hdmi_writel(hdmi, tmds->pll0, <token> <answer> HDMI_NV_PDISP_SOR_PLL0); 
<token> tmds->pll1, HDMI_NV_PDISP_SOR_PLL1); <answer> tegra_hdmi_writel(hdmi, 
tegra_hdmi_writel(hdmi, tmds->pe_current, <token> <answer> HDMI_NV_PDISP_PE_CURRENT); 
tegra_hdmi_writel(hdmi, <token> <answer> tmds->drive_current, 
value = <token> hdmi->config->fuse_override_offset); <answer> tegra_hdmi_readl(hdmi, 
value |= <token> <answer> hdmi->config->fuse_override_value; 
tegra_hdmi_writel(hdmi, <token> hdmi->config->fuse_override_offset); <answer> value, 
<token> (hdmi->config->has_sor_io_peak_current) <answer> if 
tegra_hdmi_writel(hdmi, <token> <answer> tmds->peak_current, 
static int tegra_hdmi_reconfigure_audio(struct tegra_hdmi <token> <answer> *hdmi) 
<token> err; <answer> int 
<token> = tegra_hdmi_setup_audio(hdmi); <answer> err 
if (err <token> 0) { <answer> < 
<token> else { <answer> } 
<token> err; <answer> return 
static bool <token> tegra_output *output) <answer> tegra_output_is_hdmi(struct 
return <token> <answer> output->connector.display_info.is_hdmi; 
static enum <token> <answer> drm_connector_status 
tegra_hdmi_connector_detect(struct drm_connector <token> bool force) <answer> *connector, 
struct <token> *output = connector_to_output(connector); <answer> tegra_output 
struct tegra_hdmi <token> = to_hdmi(output); <answer> *hdmi 
enum drm_connector_status <token> <answer> status; 
status = <token> force); <answer> tegra_output_connector_detect(connector, 
if (status == <token> <answer> connector_status_connected) 
<token> status; <answer> return 
tegra_hdmi_writel(hdmi, <token> HDMI_NV_PDISP_SOR_AUDIO_HDA_PRESENSE); <answer> 0, 
<token> status; <answer> return 
<token> DEBUGFS_REG32(_name) { .name = #_name, .offset = _name } <answer> #define 
static const struct debugfs_reg32 <token> = { <answer> tegra_hdmi_regs[] 
static int <token> seq_file *s, void *data) <answer> tegra_hdmi_show_regs(struct 
struct <token> *node = s->private; <answer> drm_info_node 
struct tegra_hdmi <token> = node->info_ent->data; <answer> *hdmi 
struct <token> *crtc = hdmi->output.encoder.crtc; <answer> drm_crtc 
<token> drm_device *drm = node->minor->dev; <answer> struct 
unsigned int <token> <answer> i; 
int err <token> 0; <answer> = 
if <token> || !crtc->state->active) { <answer> (!crtc 
err = <token> <answer> -EBUSY; 
<token> unlock; <answer> goto 
for (i = 0; i < ARRAY_SIZE(tegra_hdmi_regs); i++) <token> <answer> { 
unsigned int offset = <token> <answer> tegra_hdmi_regs[i].offset; 
seq_printf(s, "%-56s %#05x %08x\n", <token> <answer> tegra_hdmi_regs[i].name, 
offset, <token> offset)); <answer> tegra_hdmi_readl(hdmi, 
<token> err; <answer> return 
<token> struct drm_info_list debugfs_files[] = { <answer> static 
<token> "regs", tegra_hdmi_show_regs, 0, NULL }, <answer> { 
static int tegra_hdmi_late_register(struct drm_connector <token> <answer> *connector) 
<token> tegra_output *output = connector_to_output(connector); <answer> struct 
unsigned int i, count = <token> <answer> ARRAY_SIZE(debugfs_files); 
struct drm_minor *minor = <token> <answer> connector->dev->primary; 
struct dentry *root <token> connector->debugfs_entry; <answer> = 
struct tegra_hdmi *hdmi = <token> <answer> to_hdmi(output); 
<token> = kmemdup(debugfs_files, sizeof(debugfs_files), <answer> hdmi->debugfs_files 
if <token> <answer> (!hdmi->debugfs_files) 
return <token> <answer> -ENOMEM; 
for (i = 0; i < <token> i++) <answer> count; 
hdmi->debugfs_files[i].data <token> hdmi; <answer> = 
<token> count, root, minor); <answer> drm_debugfs_create_files(hdmi->debugfs_files, 
<token> 0; <answer> return 
static <token> tegra_hdmi_early_unregister(struct drm_connector *connector) <answer> void 
struct tegra_output <token> = connector_to_output(connector); <answer> *output 
<token> drm_minor *minor = connector->dev->primary; <answer> struct 
unsigned int <token> = ARRAY_SIZE(debugfs_files); <answer> count 
struct tegra_hdmi *hdmi <token> to_hdmi(output); <answer> = 
drm_debugfs_remove_files(hdmi->debugfs_files, <token> <answer> count, 
connector->debugfs_entry, <token> <answer> minor); 
<token> = NULL; <answer> hdmi->debugfs_files 
static const struct drm_connector_funcs tegra_hdmi_connector_funcs <token> { <answer> = 
.reset <token> drm_atomic_helper_connector_reset, <answer> = 
.detect <token> tegra_hdmi_connector_detect, <answer> = 
.fill_modes <token> drm_helper_probe_single_connector_modes, <answer> = 
.destroy = <token> <answer> tegra_output_connector_destroy, 
.atomic_duplicate_state <token> drm_atomic_helper_connector_duplicate_state, <answer> = 
.atomic_destroy_state = <token> <answer> drm_atomic_helper_connector_destroy_state, 
.late_register <token> tegra_hdmi_late_register, <answer> = 
.early_unregister <token> tegra_hdmi_early_unregister, <answer> = 
<token> enum drm_mode_status <answer> static 
tegra_hdmi_connector_mode_valid(struct <token> *connector, <answer> drm_connector 
struct drm_display_mode <token> <answer> *mode) 
struct tegra_output <token> = connector_to_output(connector); <answer> *output 
struct <token> *hdmi = to_hdmi(output); <answer> tegra_hdmi 
unsigned long pclk <token> mode->clock * 1000; <answer> = 
enum <token> status = MODE_OK; <answer> drm_mode_status 
struct <token> *parent; <answer> clk 
<token> err; <answer> long 
parent <token> clk_get_parent(hdmi->clk_parent); <answer> = 
err = clk_round_rate(parent, pclk * <token> <answer> 4); 
if <token> <= 0) <answer> (err 
status = <token> <answer> MODE_NOCLOCK; 
<token> status; <answer> return 
static const struct <token> <answer> drm_connector_helper_funcs 
tegra_hdmi_connector_helper_funcs <token> { <answer> = 
.get_modes = <token> <answer> tegra_output_connector_get_modes, 
.mode_valid = <token> <answer> tegra_hdmi_connector_mode_valid, 
static void <token> drm_encoder *encoder) <answer> tegra_hdmi_encoder_disable(struct 
struct tegra_output <token> = encoder_to_output(encoder); <answer> *output 
struct tegra_dc <token> = to_tegra_dc(encoder->crtc); <answer> *dc 
struct tegra_hdmi *hdmi = <token> <answer> to_hdmi(output); 
u32 <token> <answer> value; 
int <token> <answer> err; 
if (dc) <token> <answer> { 
value = <token> DC_DISP_DISP_WIN_OPTIONS); <answer> tegra_dc_readl(dc, 
value &= <token> <answer> ~HDMI_ENABLE; 
tegra_dc_writel(dc, value, <token> <answer> DC_DISP_DISP_WIN_OPTIONS); 
if (!hdmi->dvi) <token> <answer> { 
if <token> <answer> (hdmi->stereo) 
tegra_hdmi_writel(hdmi, <token> HDMI_NV_PDISP_INT_ENABLE); <answer> 0, 
<token> 0, HDMI_NV_PDISP_INT_MASK); <answer> tegra_hdmi_writel(hdmi, 
hdmi->pixel_clock = <token> <answer> 0; 
err <token> host1x_client_suspend(&hdmi->client); <answer> = 
<token> (err < 0) <answer> if 
dev_err(hdmi->dev, "failed to <token> %d\n", err); <answer> suspend: 
static void tegra_hdmi_encoder_enable(struct drm_encoder <token> <answer> *encoder) 
struct drm_display_mode *mode <token> &encoder->crtc->state->adjusted_mode; <answer> = 
unsigned int h_sync_width, <token> h_back_porch, i, rekey; <answer> h_front_porch, 
struct tegra_output *output = <token> <answer> encoder_to_output(encoder); 
struct tegra_dc <token> = to_tegra_dc(encoder->crtc); <answer> *dc 
struct tegra_hdmi *hdmi = <token> <answer> to_hdmi(output); 
unsigned int <token> div82; <answer> pulse_start, 
int retries <token> 1000; <answer> = 
u32 <token> <answer> value; 
int <token> <answer> err; 
err <token> host1x_client_resume(&hdmi->client); <answer> = 
if <token> < 0) { <answer> (err 
dev_err(hdmi->dev, <token> to resume: %d\n", err); <answer> "failed 
<token> INT_CODEC_SCRATCH0, HDMI_NV_PDISP_INT_ENABLE); <answer> tegra_hdmi_writel(hdmi, 
<token> INT_CODEC_SCRATCH0, HDMI_NV_PDISP_INT_MASK); <answer> tegra_hdmi_writel(hdmi, 
hdmi->pixel_clock <token> mode->clock * 1000; <answer> = 
<token> = mode->hsync_end - mode->hsync_start; <answer> h_sync_width 
h_back_porch = <token> - mode->hsync_end; <answer> mode->htotal 
<token> = mode->hsync_start - mode->hdisplay; <answer> h_front_porch 
err = dev_pm_opp_set_rate(hdmi->dev, <token> <answer> hdmi->pixel_clock); 
if <token> < 0) { <answer> (err 
dev_err(hdmi->dev, "failed to set HDMI clock <token> %d\n", <answer> frequency: 
<token> clock rate: %lu Hz\n", clk_get_rate(hdmi->clk)); <answer> DRM_DEBUG_KMS("HDMI 
if (hdmi->format.sample_rate > <token> { <answer> 0) 
err = <token> <answer> tegra_hdmi_setup_audio(hdmi); 
if (err < <token> <answer> 0) 
hdmi->dvi = <token> <answer> true; 
<token> (hdmi->config->has_hda) <answer> if 
rekey = <token> <answer> HDMI_REKEY_DEFAULT; 
value <token> HDMI_CTRL_REKEY(rekey); <answer> = 
<token> |= HDMI_CTRL_MAX_AC_PACKET((h_sync_width + h_back_porch + <answer> value 
<token> - rekey - 18) / 32); <answer> h_front_porch 
if <token> <answer> (!hdmi->dvi) 
<token> |= HDMI_CTRL_ENABLE; <answer> value 
<token> value, HDMI_NV_PDISP_HDMI_CTRL); <answer> tegra_hdmi_writel(hdmi, 
<token> (!hdmi->dvi) { <answer> if 
tegra_hdmi_setup_avi_infoframe(hdmi, <token> <answer> mode); 
if <token> <answer> (hdmi->stereo) 
#include <token> <answer> <linux/gpio/driver.h> 
#include <token> <answer> <linux/i2c.h> 
<token> <linux/mfd/max77650.h> <answer> #include 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/regmap.h> <answer> #include 
<token> MAX77650_GPIO_DIR_MASK BIT(0) <answer> #define 
#define MAX77650_GPIO_INVAL_MASK <token> <answer> BIT(1) 
#define <token> BIT(2) <answer> MAX77650_GPIO_DRV_MASK 
<token> MAX77650_GPIO_OUTVAL_MASK BIT(3) <answer> #define 
<token> MAX77650_GPIO_DEBOUNCE_MASK BIT(4) <answer> #define 
#define <token> 0x00 <answer> MAX77650_GPIO_DIR_OUT 
<token> MAX77650_GPIO_DIR_IN BIT(0) <answer> #define 
<token> MAX77650_GPIO_OUT_LOW 0x00 <answer> #define 
<token> MAX77650_GPIO_OUT_HIGH BIT(3) <answer> #define 
#define MAX77650_GPIO_DRV_OPEN_DRAIN <token> <answer> 0x00 
<token> MAX77650_GPIO_DRV_PUSH_PULL BIT(2) <answer> #define 
<token> MAX77650_GPIO_DEBOUNCE BIT(4) <answer> #define 
#define MAX77650_GPIO_DIR_BITS(_reg) <token> <answer> \ 
<token> & MAX77650_GPIO_DIR_MASK) <answer> ((_reg) 
#define <token> \ <answer> MAX77650_GPIO_INVAL_BITS(_reg) 
(((_reg) & <token> >> 1) <answer> MAX77650_GPIO_INVAL_MASK) 
<token> max77650_gpio_chip { <answer> struct 
<token> regmap *map; <answer> struct 
struct <token> gc; <answer> gpio_chip 
<token> irq; <answer> int 
static int <token> gpio_chip *gc, <answer> max77650_gpio_direction_input(struct 
<token> int offset) <answer> unsigned 
<token> max77650_gpio_chip *chip = gpiochip_get_data(gc); <answer> struct 
return <token> <answer> regmap_update_bits(chip->map, 
<token> int max77650_gpio_direction_output(struct gpio_chip *gc, <answer> static 
unsigned int offset, <token> value) <answer> int 
struct max77650_gpio_chip *chip <token> gpiochip_get_data(gc); <answer> = 
int mask, <token> <answer> regval; 
<token> = MAX77650_GPIO_DIR_MASK | MAX77650_GPIO_OUTVAL_MASK; <answer> mask 
regval = value ? <token> : MAX77650_GPIO_OUT_LOW; <answer> MAX77650_GPIO_OUT_HIGH 
regval <token> MAX77650_GPIO_DIR_OUT; <answer> |= 
<token> regmap_update_bits(chip->map, <answer> return 
<token> mask, regval); <answer> MAX77650_REG_CNFG_GPIO, 
<token> void max77650_gpio_set_value(struct gpio_chip *gc, <answer> static 
unsigned int <token> int value) <answer> offset, 
struct max77650_gpio_chip *chip <token> gpiochip_get_data(gc); <answer> = 
<token> rv, regval; <answer> int 
regval <token> value ? MAX77650_GPIO_OUT_HIGH : MAX77650_GPIO_OUT_LOW; <answer> = 
<token> = regmap_update_bits(chip->map, MAX77650_REG_CNFG_GPIO, <answer> rv 
MAX77650_GPIO_OUTVAL_MASK, <token> <answer> regval); 
if <token> <answer> (rv) 
<token> "cannot set GPIO value: %d\n", rv); <answer> dev_err(gc->parent, 
static int max77650_gpio_get_value(struct <token> *gc, <answer> gpio_chip 
unsigned <token> offset) <answer> int 
struct max77650_gpio_chip *chip = <token> <answer> gpiochip_get_data(gc); 
unsigned <token> val; <answer> int 
int <token> <answer> rv; 
<token> = regmap_read(chip->map, MAX77650_REG_CNFG_GPIO, &val); <answer> rv 
<token> (rv) <answer> if 
return <token> <answer> rv; 
<token> MAX77650_GPIO_INVAL_BITS(val); <answer> return 
static int <token> gpio_chip *gc, <answer> max77650_gpio_get_direction(struct 
unsigned <token> offset) <answer> int 
struct <token> *chip = gpiochip_get_data(gc); <answer> max77650_gpio_chip 
<token> int val; <answer> unsigned 
<token> rv; <answer> int 
<token> = regmap_read(chip->map, MAX77650_REG_CNFG_GPIO, &val); <answer> rv 
<token> (rv) <answer> if 
<token> rv; <answer> return 
return <token> <answer> MAX77650_GPIO_DIR_BITS(val); 
static int max77650_gpio_set_config(struct gpio_chip <token> <answer> *gc, 
unsigned <token> offset, unsigned long cfg) <answer> int 
struct max77650_gpio_chip *chip <token> gpiochip_get_data(gc); <answer> = 
switch (pinconf_to_config_param(cfg)) <token> <answer> { 
<token> PIN_CONFIG_DRIVE_OPEN_DRAIN: <answer> case 
return <token> <answer> regmap_update_bits(chip->map, 
<token> PIN_CONFIG_DRIVE_PUSH_PULL: <answer> case 
return <token> <answer> regmap_update_bits(chip->map, 
<token> PIN_CONFIG_INPUT_DEBOUNCE: <answer> case 
return <token> <answer> regmap_update_bits(chip->map, 
return <token> <answer> -ENOTSUPP; 
static int max77650_gpio_to_irq(struct gpio_chip *gc, unsigned <token> offset) <answer> int 
<token> max77650_gpio_chip *chip = gpiochip_get_data(gc); <answer> struct 
<token> chip->irq; <answer> return 
static int max77650_gpio_probe(struct <token> *pdev) <answer> platform_device 
struct max77650_gpio_chip <token> <answer> *chip; 
struct device *dev, <token> <answer> *parent; 
struct <token> *i2c; <answer> i2c_client 
dev <token> &pdev->dev; <answer> = 
<token> = dev->parent; <answer> parent 
i2c <token> to_i2c_client(parent); <answer> = 
chip = devm_kzalloc(dev, <token> GFP_KERNEL); <answer> sizeof(*chip), 
if <token> <answer> (!chip) 
return <token> <answer> -ENOMEM; 
chip->map = <token> NULL); <answer> dev_get_regmap(parent, 
<token> (!chip->map) <answer> if 
<token> -ENODEV; <answer> return 
chip->irq = <token> "GPI"); <answer> platform_get_irq_byname(pdev, 
if (chip->irq < <token> <answer> 0) 
return <token> <answer> chip->irq; 
<token> = -1; <answer> chip->gc.base 
chip->gc.ngpio = <token> <answer> 1; 
chip->gc.label <token> i2c->name; <answer> = 
<token> = dev; <answer> chip->gc.parent 
chip->gc.owner = <token> <answer> THIS_MODULE; 
<token> = true; <answer> chip->gc.can_sleep 
chip->gc.direction_input <token> max77650_gpio_direction_input; <answer> = 
chip->gc.direction_output <token> max77650_gpio_direction_output; <answer> = 
chip->gc.set = <token> <answer> max77650_gpio_set_value; 
chip->gc.get = <token> <answer> max77650_gpio_get_value; 
<token> = max77650_gpio_get_direction; <answer> chip->gc.get_direction 
<token> = max77650_gpio_set_config; <answer> chip->gc.set_config 
chip->gc.to_irq <token> max77650_gpio_to_irq; <answer> = 
<token> devm_gpiochip_add_data(dev, &chip->gc, chip); <answer> return 
static struct <token> max77650_gpio_driver = { <answer> platform_driver 
.driver = <token> <answer> { 
.name <token> "max77650-gpio", <answer> = 
.probe <token> max77650_gpio_probe, <answer> = 
MODULE_DESCRIPTION("MAXIM <token> GPIO driver"); <answer> 77650/77651 
MODULE_AUTHOR("Bartosz Golaszewski <token> <answer> <bgolaszewski@baylibre.com>"); 
<token> v2"); <answer> MODULE_LICENSE("GPL 
#include <token> <answer> <linux/slab.h> 
<token> <linux/spinlock.h> <answer> #include 
<token> <asm/unaligned.h> <answer> #include 
<token> <rdma/ib_verbs.h> <answer> #include 
#include <token> <answer> <rdma/rdma_cm.h> 
<token> <linux/sunrpc/xdr.h> <answer> #include 
<token> <linux/sunrpc/debug.h> <answer> #include 
<token> <linux/sunrpc/rpc_rdma.h> <answer> #include 
<token> <linux/sunrpc/svc_rdma.h> <answer> #include 
#include <token> <answer> "xprt_rdma.h" 
#include <token> <answer> <trace/events/rpcrdma.h> 
<token> void svc_rdma_wc_receive(struct ib_cq *cq, struct ib_wc *wc); <answer> static 
static inline <token> svc_rdma_recv_ctxt * <answer> struct 
svc_rdma_next_recv_ctxt(struct list_head <token> <answer> *list) 
<token> list_first_entry_or_null(list, struct svc_rdma_recv_ctxt, <answer> return 
static struct <token> * <answer> svc_rdma_recv_ctxt 
svc_rdma_recv_ctxt_alloc(struct <token> *rdma) <answer> svcxprt_rdma 
int node <token> ibdev_to_node(rdma->sc_cm_id->device); <answer> = 
struct svc_rdma_recv_ctxt <token> <answer> *ctxt; 
<token> addr; <answer> dma_addr_t 
void <token> <answer> *buffer; 
ctxt = kzalloc_node(sizeof(*ctxt), GFP_KERNEL, <token> <answer> node); 
if <token> <answer> (!ctxt) 
goto <token> <answer> fail0; 
<token> = kmalloc_node(rdma->sc_max_req_size, GFP_KERNEL, node); <answer> buffer 
if <token> <answer> (!buffer) 
<token> fail1; <answer> goto 
<token> = ib_dma_map_single(rdma->sc_pd->device, buffer, <answer> addr 
<token> DMA_FROM_DEVICE); <answer> rdma->sc_max_req_size, 
if <token> addr)) <answer> (ib_dma_mapping_error(rdma->sc_pd->device, 
<token> fail2; <answer> goto 
<token> &ctxt->rc_cid); <answer> svc_rdma_recv_cid_init(rdma, 
ctxt->rc_recv_wr.next = <token> <answer> NULL; 
ctxt->rc_recv_wr.wr_cqe <token> &ctxt->rc_cqe; <answer> = 
<token> = &ctxt->rc_recv_sge; <answer> ctxt->rc_recv_wr.sg_list 
ctxt->rc_recv_wr.num_sge <token> 1; <answer> = 
<token> = svc_rdma_wc_receive; <answer> ctxt->rc_cqe.done 
<token> = addr; <answer> ctxt->rc_recv_sge.addr 
ctxt->rc_recv_sge.length <token> rdma->sc_max_req_size; <answer> = 
ctxt->rc_recv_sge.lkey = <token> <answer> rdma->sc_pd->local_dma_lkey; 
ctxt->rc_recv_buf <token> buffer; <answer> = 
svc_rdma_cc_init(rdma, <token> <answer> &ctxt->rc_cc); 
return <token> <answer> ctxt; 
<token> NULL; <answer> return 
static void <token> svcxprt_rdma *rdma, <answer> svc_rdma_recv_ctxt_destroy(struct 
<token> svc_rdma_recv_ctxt *ctxt) <answer> struct 
<token> ctxt->rc_recv_sge.addr, <answer> ib_dma_unmap_single(rdma->sc_pd->device, 
ctxt->rc_recv_sge.length, <token> <answer> DMA_FROM_DEVICE); 
<token> svc_rdma_recv_ctxts_destroy(struct svcxprt_rdma *rdma) <answer> void 
struct svc_rdma_recv_ctxt <token> <answer> *ctxt; 
struct llist_node <token> <answer> *node; 
while ((node <token> llist_del_first(&rdma->sc_recv_ctxts))) { <answer> = 
ctxt <token> llist_entry(node, struct svc_rdma_recv_ctxt, rc_node); <answer> = 
svc_rdma_recv_ctxt_destroy(rdma, <token> <answer> ctxt); 
struct svc_rdma_recv_ctxt *svc_rdma_recv_ctxt_get(struct svcxprt_rdma <token> <answer> *rdma) 
struct svc_rdma_recv_ctxt <token> <answer> *ctxt; 
struct <token> *node; <answer> llist_node 
node = <token> <answer> llist_del_first(&rdma->sc_recv_ctxts); 
if <token> <answer> (!node) 
<token> NULL; <answer> return 
ctxt = <token> struct svc_rdma_recv_ctxt, rc_node); <answer> llist_entry(node, 
<token> = 0; <answer> ctxt->rc_page_count 
return <token> <answer> ctxt; 
void <token> svcxprt_rdma *rdma, <answer> svc_rdma_recv_ctxt_put(struct 
<token> svc_rdma_recv_ctxt *ctxt) <answer> struct 
svc_rdma_cc_release(rdma, &ctxt->rc_cc, <token> <answer> DMA_FROM_DEVICE); 
<token> ctxt->rc_page_count); <answer> release_pages(ctxt->rc_pages, 
llist_add(&ctxt->rc_node, <token> <answer> &rdma->sc_recv_ctxts); 
void svc_rdma_release_ctxt(struct <token> *xprt, void *vctxt) <answer> svc_xprt 
struct svc_rdma_recv_ctxt *ctxt = <token> <answer> vctxt; 
struct svcxprt_rdma <token> = <answer> *rdma 
container_of(xprt, struct <token> sc_xprt); <answer> svcxprt_rdma, 
<token> (ctxt) <answer> if 
svc_rdma_recv_ctxt_put(rdma, <token> <answer> ctxt); 
<token> bool svc_rdma_refresh_recvs(struct svcxprt_rdma *rdma, <answer> static 
unsigned int <token> <answer> wanted) 
const struct ib_recv_wr <token> = NULL; <answer> *bad_wr 
struct <token> *ctxt; <answer> svc_rdma_recv_ctxt 
<token> ib_recv_wr *recv_chain; <answer> struct 
<token> ret; <answer> int 
if (test_bit(XPT_CLOSE, <token> <answer> &rdma->sc_xprt.xpt_flags)) 
<token> false; <answer> return 
recv_chain <token> NULL; <answer> = 
while <token> { <answer> (wanted--) 
ctxt <token> svc_rdma_recv_ctxt_get(rdma); <answer> = 
if <token> <answer> (!ctxt) 
ctxt->rc_recv_wr.next <token> recv_chain; <answer> = 
<token> = &ctxt->rc_recv_wr; <answer> recv_chain 
if <token> <answer> (!recv_chain) 
return <token> <answer> true; 
<token> = ib_post_recv(rdma->sc_qp, recv_chain, &bad_wr); <answer> ret 
if <token> <answer> (ret) 
goto <token> <answer> err_free; 
<token> true; <answer> return 
trace_svcrdma_rq_post_err(rdma, <token> <answer> ret); 
<token> (bad_wr) { <answer> while 
ctxt <token> container_of(bad_wr, struct svc_rdma_recv_ctxt, <answer> = 
bad_wr = <token> <answer> bad_wr->next; 
svc_rdma_recv_ctxt_put(rdma, <token> <answer> ctxt); 
<token> false; <answer> return 
bool svc_rdma_post_recvs(struct <token> *rdma) <answer> svcxprt_rdma 
<token> int total; <answer> unsigned 
total = (rdma->sc_max_requests * 2) <token> rdma->sc_recv_batch; <answer> + 
<token> (total--) { <answer> while 
struct svc_rdma_recv_ctxt <token> <answer> *ctxt; 
<token> = svc_rdma_recv_ctxt_alloc(rdma); <answer> ctxt 
if <token> <answer> (!ctxt) 
<token> false; <answer> return 
<token> &rdma->sc_recv_ctxts); <answer> llist_add(&ctxt->rc_node, 
return <token> rdma->sc_max_requests); <answer> svc_rdma_refresh_recvs(rdma, 
static void <token> ib_cq *cq, struct ib_wc *wc) <answer> svc_rdma_wc_receive(struct 
struct <token> *rdma = cq->cq_context; <answer> svcxprt_rdma 
struct ib_cqe *cqe <token> wc->wr_cqe; <answer> = 
<token> svc_rdma_recv_ctxt *ctxt; <answer> struct 
if <token> < rdma->sc_max_requests) <answer> (rdma->sc_pending_recvs 
if (!svc_rdma_refresh_recvs(rdma, <token> <answer> rdma->sc_recv_batch)) 
<token> dropped; <answer> goto 
<token> svc_rdma_flush_recv_queues(struct svcxprt_rdma *rdma) <answer> void 
<token> svc_rdma_recv_ctxt *ctxt; <answer> struct 
<token> ((ctxt = svc_rdma_next_recv_ctxt(&rdma->sc_read_complete_q))) { <answer> while 
svc_rdma_recv_ctxt_put(rdma, <token> <answer> ctxt); 
while ((ctxt <token> svc_rdma_next_recv_ctxt(&rdma->sc_rq_dto_q))) { <answer> = 
<token> ctxt); <answer> svc_rdma_recv_ctxt_put(rdma, 
static <token> svc_rdma_build_arg_xdr(struct svc_rqst *rqstp, <answer> void 
struct <token> *ctxt) <answer> svc_rdma_recv_ctxt 
struct xdr_buf <token> = &rqstp->rq_arg; <answer> *arg 
arg->head[0].iov_base <token> ctxt->rc_recv_buf; <answer> = 
arg->head[0].iov_len = <token> <answer> ctxt->rc_byte_len; 
arg->tail[0].iov_base <token> NULL; <answer> = 
arg->tail[0].iov_len = <token> <answer> 0; 
<token> = 0; <answer> arg->page_len 
<token> = 0; <answer> arg->page_base 
arg->buflen <token> ctxt->rc_byte_len; <answer> = 
arg->len = <token> <answer> ctxt->rc_byte_len; 
<token> bool xdr_count_read_segments(struct svc_rdma_recv_ctxt *rctxt, __be32 *p) <answer> static 
<token> = 0; <answer> rctxt->rc_call_pcl.cl_count 
rctxt->rc_read_pcl.cl_count <token> 0; <answer> = 
while (xdr_item_is_present(p)) <token> <answer> { 
u32 <token> handle, length; <answer> position, 
u64 <token> <answer> offset; 
<token> = xdr_inline_decode(&rctxt->rc_stream, <answer> p 
rpcrdma_readseg_maxsz <token> sizeof(*p)); <answer> * 
if <token> <answer> (!p) 
return <token> <answer> false; 
xdr_decode_read_segment(p, <token> &handle, <answer> &position, 
&length, <token> <answer> &offset); 
if (position) <token> <answer> { 
<token> (position & 3) <answer> if 
<token> false; <answer> return 
<token> else { <answer> } 
<token> = xdr_inline_decode(&rctxt->rc_stream, sizeof(*p)); <answer> p 
<token> (!p) <answer> if 
return <token> <answer> false; 
return <token> <answer> true; 
static bool xdr_check_read_list(struct <token> *rctxt) <answer> svc_rdma_recv_ctxt 
<token> *p; <answer> __be32 
p = xdr_inline_decode(&rctxt->rc_stream, <token> <answer> sizeof(*p)); 
<token> (!p) <answer> if 
return <token> <answer> false; 
if (!xdr_count_read_segments(rctxt, <token> <answer> p)) 
<token> false; <answer> return 
if <token> p)) <answer> (!pcl_alloc_call(rctxt, 
<token> false; <answer> return 
<token> pcl_alloc_read(rctxt, p); <answer> return 
static bool <token> svc_rdma_recv_ctxt *rctxt) <answer> xdr_check_write_chunk(struct 
<token> segcount; <answer> u32 
__be32 <token> <answer> *p; 
if (xdr_stream_decode_u32(&rctxt->rc_stream, <token> <answer> &segcount)) 
return <token> <answer> false; 
static bool xdr_count_write_chunks(struct svc_rdma_recv_ctxt *rctxt, __be32 <token> <answer> *p) 
rctxt->rc_write_pcl.cl_count <token> 0; <answer> = 
while <token> { <answer> (xdr_item_is_present(p)) 
if <token> <answer> (!xdr_check_write_chunk(rctxt)) 
<token> false; <answer> return 
p = xdr_inline_decode(&rctxt->rc_stream, <token> <answer> sizeof(*p)); 
if <token> <answer> (!p) 
<token> false; <answer> return 
return <token> <answer> true; 
static <token> xdr_check_write_list(struct svc_rdma_recv_ctxt *rctxt) <answer> bool 
__be32 <token> <answer> *p; 
p = xdr_inline_decode(&rctxt->rc_stream, <token> <answer> sizeof(*p)); 
if <token> <answer> (!p) 
<token> false; <answer> return 
if (!xdr_count_write_chunks(rctxt, <token> <answer> p)) 
return <token> <answer> false; 
if (!pcl_alloc_write(rctxt, &rctxt->rc_write_pcl, <token> <answer> p)) 
return <token> <answer> false; 
<token> = pcl_first_chunk(&rctxt->rc_write_pcl); <answer> rctxt->rc_cur_result_payload 
return <token> <answer> true; 
<token> bool xdr_check_reply_chunk(struct svc_rdma_recv_ctxt *rctxt) <answer> static 
<token> *p; <answer> __be32 
p = xdr_inline_decode(&rctxt->rc_stream, <token> <answer> sizeof(*p)); 
if <token> <answer> (!p) 
<token> false; <answer> return 
<token> (!xdr_item_is_present(p)) <answer> if 
return <token> <answer> true; 
<token> (!xdr_check_write_chunk(rctxt)) <answer> if 
return <token> <answer> false; 
<token> = 1; <answer> rctxt->rc_reply_pcl.cl_count 
<token> pcl_alloc_write(rctxt, &rctxt->rc_reply_pcl, p); <answer> return 
static <token> svc_rdma_get_inv_rkey(struct svcxprt_rdma *rdma, <answer> void 
<token> svc_rdma_recv_ctxt *ctxt) <answer> struct 
<token> svc_rdma_segment *segment; <answer> struct 
struct <token> *chunk; <answer> svc_rdma_chunk 
u32 <token> <answer> inv_rkey; 
<token> = 0; <answer> ctxt->rc_inv_rkey 
if <token> <answer> (!rdma->sc_snd_w_inv) 
<token> = 0; <answer> inv_rkey 
<token> &ctxt->rc_call_pcl) { <answer> pcl_for_each_chunk(chunk, 
<token> chunk) { <answer> pcl_for_each_segment(segment, 
if (inv_rkey == <token> <answer> 0) 
<token> = segment->rs_handle; <answer> inv_rkey 
else if (inv_rkey <token> segment->rs_handle) <answer> != 
pcl_for_each_chunk(chunk, &ctxt->rc_read_pcl) <token> <answer> { 
pcl_for_each_segment(segment, chunk) <token> <answer> { 
if (inv_rkey <token> 0) <answer> == 
inv_rkey = <token> <answer> segment->rs_handle; 
else if <token> != segment->rs_handle) <answer> (inv_rkey 
pcl_for_each_chunk(chunk, <token> { <answer> &ctxt->rc_write_pcl) 
pcl_for_each_segment(segment, <token> { <answer> chunk) 
if (inv_rkey <token> 0) <answer> == 
inv_rkey <token> segment->rs_handle; <answer> = 
else <token> (inv_rkey != segment->rs_handle) <answer> if 
<token> &ctxt->rc_reply_pcl) { <answer> pcl_for_each_chunk(chunk, 
pcl_for_each_segment(segment, chunk) <token> <answer> { 
<token> (inv_rkey == 0) <answer> if 
<token> = segment->rs_handle; <answer> inv_rkey 
else if (inv_rkey != <token> <answer> segment->rs_handle) 
ctxt->rc_inv_rkey <token> inv_rkey; <answer> = 
static <token> svc_rdma_xdr_decode_req(struct xdr_buf *rq_arg, <answer> int 
struct <token> *rctxt) <answer> svc_rdma_recv_ctxt 
<token> *p, *rdma_argp; <answer> __be32 
unsigned <token> hdr_len; <answer> int 
rdma_argp <token> rq_arg->head[0].iov_base; <answer> = 
xdr_init_decode(&rctxt->rc_stream, rq_arg, <token> NULL); <answer> rdma_argp, 
<token> = xdr_inline_decode(&rctxt->rc_stream, <answer> p 
<token> * sizeof(*p)); <answer> rpcrdma_fixed_maxsz 
if <token> <answer> (unlikely(!p)) 
<token> out_short; <answer> goto 
<token> (*p != rpcrdma_version) <answer> if 
goto <token> <answer> out_version; 
p <token> 2; <answer> += 
rctxt->rc_msgtype = <token> <answer> *p; 
switch (rctxt->rc_msgtype) <token> <answer> { 
case <token> <answer> rdma_msg: 
<token> rdma_nomsg: <answer> case 
case <token> <answer> rdma_done: 
goto <token> <answer> out_drop; 
case <token> <answer> rdma_error: 
<token> out_drop; <answer> goto 
<token> out_proc; <answer> goto 
<token> (!xdr_check_read_list(rctxt)) <answer> if 
<token> out_inval; <answer> goto 
<token> (!xdr_check_write_list(rctxt)) <answer> if 
<token> out_inval; <answer> goto 
<token> (!xdr_check_reply_chunk(rctxt)) <answer> if 
goto <token> <answer> out_inval; 
rq_arg->head[0].iov_base <token> rctxt->rc_stream.p; <answer> = 
<token> = xdr_stream_pos(&rctxt->rc_stream); <answer> hdr_len 
rq_arg->head[0].iov_len <token> hdr_len; <answer> -= 
<token> -= hdr_len; <answer> rq_arg->len 
trace_svcrdma_decode_rqst(rctxt, <token> hdr_len); <answer> rdma_argp, 
<token> hdr_len; <answer> return 
<token> rq_arg->len); <answer> trace_svcrdma_decode_short_err(rctxt, 
<token> -EINVAL; <answer> return 
trace_svcrdma_decode_badvers_err(rctxt, <token> <answer> rdma_argp); 
<token> -EPROTONOSUPPORT; <answer> return 
trace_svcrdma_decode_drop_err(rctxt, <token> <answer> rdma_argp); 
return <token> <answer> 0; 
trace_svcrdma_decode_badproc_err(rctxt, <token> <answer> rdma_argp); 
<token> -EINVAL; <answer> return 
trace_svcrdma_decode_parse_err(rctxt, <token> <answer> rdma_argp); 
<token> -EINVAL; <answer> return 
static <token> svc_rdma_send_error(struct svcxprt_rdma *rdma, <answer> void 
struct <token> *rctxt, <answer> svc_rdma_recv_ctxt 
int <token> <answer> status) 
struct <token> *sctxt; <answer> svc_rdma_send_ctxt 
sctxt <token> svc_rdma_send_ctxt_get(rdma); <answer> = 
if <token> <answer> (!sctxt) 
svc_rdma_send_error_msg(rdma, sctxt, rctxt, <token> <answer> status); 
static bool svc_rdma_is_reverse_direction_reply(struct svc_xprt <token> <answer> *xprt, 
struct svc_rdma_recv_ctxt <token> <answer> *rctxt) 
__be32 <token> = rctxt->rc_recv_buf; <answer> *p 
if <token> <answer> (!xprt->xpt_bc_xprt) 
return <token> <answer> false; 
<token> (rctxt->rc_msgtype != rdma_msg) <answer> if 
<token> false; <answer> return 
if <token> <answer> (!pcl_is_empty(&rctxt->rc_call_pcl)) 
<token> false; <answer> return 
if <token> <answer> (!pcl_is_empty(&rctxt->rc_read_pcl)) 
return <token> <answer> false; 
if <token> <answer> (!pcl_is_empty(&rctxt->rc_write_pcl)) 
<token> false; <answer> return 
<token> (!pcl_is_empty(&rctxt->rc_reply_pcl)) <answer> if 
<token> false; <answer> return 
static <token> svc_rdma_read_complete_one(struct svc_rqst *rqstp, <answer> void 
<token> svc_rdma_recv_ctxt *ctxt) <answer> struct 
struct svc_rdma_chunk *chunk = <token> <answer> pcl_first_chunk(&ctxt->rc_read_pcl); 
struct xdr_buf *buf = <token> <answer> &rqstp->rq_arg; 
<token> int length; <answer> unsigned 
buf->tail[0].iov_base <token> buf->head[0].iov_base + chunk->ch_position; <answer> = 
buf->tail[0].iov_len = buf->head[0].iov_len - <token> <answer> chunk->ch_position; 
buf->head[0].iov_len = <token> <answer> chunk->ch_position; 
buf->pages <token> &rqstp->rq_pages[0]; <answer> = 
length = <token> <answer> xdr_align_size(chunk->ch_length); 
buf->page_len <token> length; <answer> = 
buf->len <token> length; <answer> += 
buf->buflen <token> length; <answer> += 
static void svc_rdma_read_complete_multiple(struct <token> *rqstp, <answer> svc_rqst 
struct <token> *ctxt) <answer> svc_rdma_recv_ctxt 
struct xdr_buf *buf = <token> <answer> &rqstp->rq_arg; 
buf->len <token> ctxt->rc_readbytes; <answer> += 
buf->buflen <token> ctxt->rc_readbytes; <answer> += 
<token> = page_address(rqstp->rq_pages[0]); <answer> buf->head[0].iov_base 
buf->head[0].iov_len = min_t(size_t, PAGE_SIZE, <token> <answer> ctxt->rc_readbytes); 
<token> = &rqstp->rq_pages[1]; <answer> buf->pages 
buf->page_len = ctxt->rc_readbytes <token> buf->head[0].iov_len; <answer> - 
static void <token> svc_rqst *rqstp, <answer> svc_rdma_read_complete_pzrc(struct 
<token> svc_rdma_recv_ctxt *ctxt) <answer> struct 
struct <token> *buf = &rqstp->rq_arg; <answer> xdr_buf 
<token> += ctxt->rc_readbytes; <answer> buf->len 
buf->buflen <token> ctxt->rc_readbytes; <answer> += 
<token> = page_address(rqstp->rq_pages[0]); <answer> buf->head[0].iov_base 
buf->head[0].iov_len <token> min_t(size_t, PAGE_SIZE, ctxt->rc_readbytes); <answer> = 
<token> = &rqstp->rq_pages[1]; <answer> buf->pages 
buf->page_len = ctxt->rc_readbytes - <token> <answer> buf->head[0].iov_len; 
static noinline void svc_rdma_read_complete(struct svc_rqst <token> <answer> *rqstp, 
<token> svc_rdma_recv_ctxt *ctxt) <answer> struct 
<token> int i; <answer> unsigned 
<token> ctxt->rc_page_count); <answer> release_pages(rqstp->rq_respages, 
for (i = 0; i < <token> i++) <answer> ctxt->rc_page_count; 
rqstp->rq_pages[i] <token> ctxt->rc_pages[i]; <answer> = 
rqstp->rq_respages <token> &rqstp->rq_pages[ctxt->rc_page_count]; <answer> = 
rqstp->rq_next_page = rqstp->rq_respages + <token> <answer> 1; 
ctxt->rc_page_count <token> 0; <answer> = 
rqstp->rq_arg <token> ctxt->rc_saved_arg; <answer> = 
if (pcl_is_empty(&ctxt->rc_call_pcl)) <token> <answer> { 
if (ctxt->rc_read_pcl.cl_count == <token> <answer> 1) 
<token> ctxt); <answer> svc_rdma_read_complete_one(rqstp, 
<token> ctxt); <answer> svc_rdma_read_complete_multiple(rqstp, 
} else <token> <answer> { 
<token> ctxt); <answer> svc_rdma_read_complete_pzrc(rqstp, 
int <token> svc_rqst *rqstp) <answer> svc_rdma_recvfrom(struct 
struct svc_xprt *xprt = <token> <answer> rqstp->rq_xprt; 
struct svcxprt_rdma <token> = <answer> *rdma_xprt 
container_of(xprt, <token> svcxprt_rdma, sc_xprt); <answer> struct 
struct <token> *ctxt; <answer> svc_rdma_recv_ctxt 
<token> ret; <answer> int 
rqstp->rq_respages <token> rqstp->rq_pages; <answer> = 
rqstp->rq_next_page <token> rqstp->rq_respages; <answer> = 
<token> = NULL; <answer> rqstp->rq_xprt_ctxt 
<token> = svc_rdma_next_recv_ctxt(&rdma_xprt->sc_read_complete_q); <answer> ctxt 
<token> (ctxt) { <answer> if 
<token> ctxt); <answer> svc_rdma_read_complete(rqstp, 
<token> complete; <answer> goto 
ctxt = <token> <answer> svc_rdma_next_recv_ctxt(&rdma_xprt->sc_rq_dto_q); 
<token> (ctxt) <answer> if 
<token> = rqstp->rq_arg; <answer> ctxt->rc_saved_arg 
ret = svc_rdma_process_read_list(rdma_xprt, <token> ctxt); <answer> rqstp, 
if <token> < 0) { <answer> (ret 
if (ret == <token> <answer> -EINVAL) 
svc_rdma_send_error(rdma_xprt, <token> ret); <answer> ctxt, 
<token> ctxt); <answer> svc_rdma_recv_ctxt_put(rdma_xprt, 
return <token> <answer> ret; 
return <token> <answer> 0; 
svc_rdma_handle_bc_reply(rqstp, <token> <answer> ctxt); 
svc_rdma_recv_ctxt_put(rdma_xprt, <token> <answer> ctxt); 
return <token> <answer> 0; 
<token> "dc_bios_types.h" <answer> #include 
#include <token> <answer> "dce_stream_encoder.h" 
<token> "reg_helper.h" <answer> #include 
#include <token> <answer> "hw_shared.h" 
#define <token> \ <answer> DC_LOGGER 
<token> REG(reg)\ <answer> #define 
<token> FN <answer> #undef 
<token> FN(reg_name, field_name) \ <answer> #define 
<token> enc110->se_mask->field_name <answer> enc110->se_shift->field_name, 
#define <token> 0 <answer> VBI_LINE_0 
#define DP_BLANK_MAX_RETRY <token> <answer> 20 
#define <token> 340000 <answer> HDMI_CLOCK_CHANNEL_RATE_MORE_340M 
#ifndef <token> <answer> TMDS_CNTL__TMDS_PIXEL_ENCODING_MASK 
<token> TMDS_CNTL__TMDS_PIXEL_ENCODING_MASK 0x00000010L <answer> #define 
#define TMDS_CNTL__TMDS_COLOR_FORMAT_MASK <token> <answer> 0x00000300L 
#define TMDS_CNTL__TMDS_PIXEL_ENCODING__SHIFT <token> <answer> 0x00000004 
#define <token> 0x00000008 <answer> TMDS_CNTL__TMDS_COLOR_FORMAT__SHIFT 
<token> { <answer> enum 
DP_MST_UPDATE_MAX_RETRY = <token> <answer> 50 
#define <token> <answer> DCE110_SE(audio)\ 
<token> struct dce110_stream_encoder, base) <answer> container_of(audio, 
#define <token> \ <answer> CTX 
static void <token> <answer> dce110_update_generic_info_packet( 
struct <token> *enc110, <answer> dce110_stream_encoder 
uint32_t <token> <answer> packet_index, 
const struct <token> *info_packet) <answer> dc_info_packet 
uint32_t <token> = 50; <answer> max_retries 
REG_UPDATE(AFMT_VBI_PACKET_CONTROL, AFMT_GENERIC_CONFLICT_CLR, <token> <answer> 1); 
<token> 0, <answer> REG_SET_4(AFMT_GENERIC_HDR, 
AFMT_GENERIC_HB0, <token> <answer> info_packet->hb0, 
AFMT_GENERIC_HB1, <token> <answer> info_packet->hb1, 
<token> info_packet->hb2, <answer> AFMT_GENERIC_HB2, 
AFMT_GENERIC_HB3, <token> <answer> info_packet->hb3); 
const <token> *content = <answer> uint32_t 
(const uint32_t <token> &info_packet->sb[0]; <answer> *) 
<token> *content++); <answer> REG_WRITE(AFMT_GENERIC_0, 
REG_WRITE(AFMT_GENERIC_1, <token> <answer> *content++); 
REG_WRITE(AFMT_GENERIC_2, <token> <answer> *content++); 
<token> *content++); <answer> REG_WRITE(AFMT_GENERIC_3, 
<token> *content++); <answer> REG_WRITE(AFMT_GENERIC_4, 
<token> *content++); <answer> REG_WRITE(AFMT_GENERIC_5, 
<token> *content++); <answer> REG_WRITE(AFMT_GENERIC_6, 
REG_WRITE(AFMT_GENERIC_7, <token> <answer> *content); 
if <token> { <answer> (!REG(AFMT_VBI_PACKET_CONTROL1)) 
cont = <token> <answer> 1; 
<token> DP_PIXEL_ENCODING, <answer> REG_UPDATE(DP_PIXEL_FORMAT, 
case <token> <answer> PIXEL_ENCODING_YCBCR420: 
REG_UPDATE(DP_PIXEL_FORMAT, <token> <answer> DP_PIXEL_ENCODING, 
<token> (enc110->se_mask->DP_VID_M_DOUBLE_VALUE_EN) <answer> if 
<token> DP_VID_M_DOUBLE_VALUE_EN, 1); <answer> REG_UPDATE(DP_VID_TIMING, 
if <token> <answer> (enc110->se_mask->DP_VID_N_MUL) 
REG_UPDATE(DP_VID_TIMING, <token> 1); <answer> DP_VID_N_MUL, 
REG_UPDATE(DP_PIXEL_FORMAT, <token> <answer> DP_PIXEL_ENCODING, 
<token> (REG(DP_MSA_MISC)) <answer> if 
misc1 <token> REG_READ(DP_MSA_MISC); <answer> = 
if <token> <answer> (REG(DP_MSA_TIMING_PARAM1)) 
<token> 0, <answer> REG_SET_2(DP_MSA_TIMING_PARAM1, 
DP_MSA_HTOTAL, <token> <answer> hw_crtc_timing.h_total, 
DP_MSA_VTOTAL, <token> <answer> hw_crtc_timing.v_total); 
h_blank = hw_crtc_timing.h_total - <token> - <answer> hw_crtc_timing.h_border_left 
hw_crtc_timing.h_addressable - <token> <answer> hw_crtc_timing.h_border_right; 
h_back_porch = h_blank - <token> - <answer> hw_crtc_timing.h_front_porch 
HDMI_DATA_SCRAMBLE_EN, <token> <answer> 1, 
HDMI_CLOCK_CHANNEL_RATE, <token> <answer> 1); 
} <token> if (crtc_timing->flags.LTE_340MCSC_SCRAMBLE) { <answer> else 
<token> 1, <answer> HDMI_DATA_SCRAMBLE_EN, 
<token> 0); <answer> HDMI_CLOCK_CHANNEL_RATE, 
<token> 1, <answer> HDMI_GC_CONT, 
HDMI_GC_SEND, <token> <answer> 1, 
<token> 1); <answer> HDMI_NULL_SEND, 
REG_UPDATE(HDMI_VBI_PACKET_CONTROL, <token> 0); <answer> HDMI_ACP_SEND, 
<token> DP_SEC_GSP0_ENABLE, info_frame->vsc.valid); <answer> REG_UPDATE(DP_SEC_CNTL, 
REG_UPDATE(DP_SEC_CNTL, DP_SEC_GSP2_ENABLE, <token> <answer> info_frame->spd.valid); 
<token> DP_SEC_GSP3_ENABLE, info_frame->hdrsmd.valid); <answer> REG_UPDATE(DP_SEC_CNTL, 
value = <token> <answer> REG_READ(DP_SEC_CNTL); 
<token> (value) <answer> if 
REG_UPDATE(DP_SEC_CNTL, <token> 1); <answer> DP_SEC_STREAM_ENABLE, 
<token> void dce110_stream_encoder_stop_dp_info_packets( <answer> static 
struct <token> *enc) <answer> stream_encoder 
<token> = REG_READ(DP_SEC_CNTL); <answer> value 
<token> (value) <answer> if 
REG_UPDATE(DP_SEC_CNTL, DP_SEC_STREAM_ENABLE, <token> <answer> 1); 
static void <token> <answer> dce110_stream_encoder_dp_blank( 
<token> dc_link *link, <answer> struct 
struct stream_encoder <token> <answer> *enc) 
<token> dce110_stream_encoder *enc110 = DCE110STRENC_FROM_STRENC(enc); <answer> struct 
<token> reg1 = 0; <answer> uint32_t 
uint32_t max_retries <token> DP_BLANK_MAX_RETRY * 10; <answer> = 
<token> DP_VID_STREAM_ENABLE, &reg1); <answer> REG_GET(DP_VID_STREAM_CNTL, 
<token> ((reg1 & 0x1) == 0) <answer> if 
<token> DP_VID_STREAM_DIS_DEFER, 2); <answer> REG_UPDATE(DP_VID_STREAM_CNTL, 
<token> = DP_BLANK_MAX_RETRY * 150; <answer> max_retries 
REG_WAIT(DP_VID_STREAM_CNTL, <token> <answer> DP_VID_STREAM_STATUS, 
10, <token> <answer> max_retries); 
<token> DP_STEER_FIFO_RESET, true); <answer> REG_UPDATE(DP_STEER_FIFO, 
uint64_t m_vid_l = <token> <answer> n_vid; 
<token> *= param->timing.pix_clk_100hz / 10; <answer> m_vid_l 
m_vid_l = <token> <answer> div_u64(m_vid_l, 
* <token> <answer> LINK_RATE_REF_FREQ_IN_KHZ); 
<token> = (uint32_t) m_vid_l; <answer> m_vid 
<token> DP_VID_N, n_vid); <answer> REG_UPDATE(DP_VID_N, 
<token> DP_VID_M, m_vid); <answer> REG_UPDATE(DP_VID_M, 
REG_UPDATE(DP_VID_TIMING, DP_VID_M_N_GEN_EN, <token> <answer> 1); 
REG_UPDATE(DP_VID_STREAM_CNTL, DP_VID_STREAM_ENABLE, <token> <answer> true); 
static void <token> <answer> dce110_stream_encoder_set_avmute( 
struct stream_encoder <token> <answer> *enc, 
bool <token> <answer> enable) 
struct <token> *enc110 = DCE110STRENC_FROM_STRENC(enc); <answer> dce110_stream_encoder 
unsigned int value <token> enable ? 1 : 0; <answer> = 
REG_UPDATE(HDMI_GC, <token> value); <answer> HDMI_GC_AVMUTE, 
static void <token> <answer> dce110_reset_hdmi_stream_attribute( 
<token> stream_encoder *enc) <answer> struct 
<token> dce110_stream_encoder *enc110 = DCE110STRENC_FROM_STRENC(enc); <answer> struct 
if <token> <answer> (enc110->se_mask->HDMI_DATA_SCRAMBLE_EN) 
HDMI_PACKET_GEN_VERSION, <token> <answer> 1, 
<token> 1, <answer> HDMI_KEEPOUT_MODE, 
HDMI_DEEP_COLOR_ENABLE, <token> <answer> 0, 
<token> 0, <answer> HDMI_DATA_SCRAMBLE_EN, 
HDMI_CLOCK_CHANNEL_RATE, <token> <answer> 0); 
HDMI_PACKET_GEN_VERSION, <token> <answer> 1, 
<token> 1, <answer> HDMI_KEEPOUT_MODE, 
<token> 0); <answer> HDMI_DEEP_COLOR_ENABLE, 
<token> DP_SEC_AUD_N__DP_SEC_AUD_N__DEFAULT 0x8000 <answer> #define 
#define <token> 1 <answer> DP_SEC_TIMESTAMP__DP_SEC_TIMESTAMP_MODE__AUTO_CALC 
<token> "include/audio_types.h" <answer> #include 
if <token> { <answer> (speaker_flags.RL_RR) 
cea_channels.channels.RL_RC = <token> <answer> speaker_flags.RL_RR; 
cea_channels.channels.RR <token> speaker_flags.RL_RR; <answer> = 
cea_channels.channels.RC_RLC_FLC = <token> <answer> speaker_flags.RC; 
} else <token> <answer> { 
<token> = speaker_flags.RC; <answer> cea_channels.channels.RL_RC 
audio_clock_info->pixel_clock_in_10khz <token> <answer> = 
actual_pixel_clock_100Hz <token> 100; <answer> / 
audio_clock_info->cts_32khz = <token> / 10; <answer> actual_pixel_clock_100Hz 
audio_clock_info->cts_44khz <token> actual_pixel_clock_100Hz / 10; <answer> = 
audio_clock_info->cts_48khz <token> actual_pixel_clock_100Hz / 10; <answer> = 
audio_clock_info->n_32khz = <token> <answer> 4096; 
audio_clock_info->n_44khz <token> 6272; <answer> = 
audio_clock_info->n_48khz <token> 6144; <answer> = 
static <token> dce110_se_audio_setup( <answer> void 
struct <token> *enc, <answer> stream_encoder 
unsigned int <token> <answer> az_inst, 
<token> audio_info *audio_info) <answer> struct 
struct dce110_stream_encoder <token> = DCE110STRENC_FROM_STRENC(enc); <answer> *enc110 
uint32_t channels <token> 0; <answer> = 
if (audio_info == <token> <answer> NULL) 
<token> = calc_max_audio_packets_per_line(crtc_info); <answer> max_packets_per_line 
<token> 1, <answer> AFMT_60958_CS_CHANNEL_NUMBER_L, 
AFMT_60958_CS_CLOCK_ACCURACY, <token> <answer> 0); 
AFMT_60958_CS_CHANNEL_NUMBER_2, <token> <answer> 3, 
AFMT_60958_CS_CHANNEL_NUMBER_3, <token> <answer> 4, 
<token> 5, <answer> AFMT_60958_CS_CHANNEL_NUMBER_4, 
<token> 6, <answer> AFMT_60958_CS_CHANNEL_NUMBER_5, 
<token> 7, <answer> AFMT_60958_CS_CHANNEL_NUMBER_6, 
<token> 8); <answer> AFMT_60958_CS_CHANNEL_NUMBER_7, 
static <token> dce110_se_setup_dp_audio( <answer> void 
<token> stream_encoder *enc) <answer> struct 
struct dce110_stream_encoder <token> = DCE110STRENC_FROM_STRENC(enc); <answer> *enc110 
static <token> dce110_se_enable_dp_audio( <answer> void 
struct <token> *enc) <answer> stream_encoder 
<token> dce110_stream_encoder *enc110 = DCE110STRENC_FROM_STRENC(enc); <answer> struct 
value <token> REG_READ(DP_SEC_CNTL); <answer> = 
if (value <token> 0) <answer> != 
REG_UPDATE(DP_SEC_CNTL, <token> 1); <answer> DP_SEC_STREAM_ENABLE, 
<token> dce110_se_audio_mute_control( <answer> void 
struct <token> *enc, <answer> stream_encoder 
bool <token> <answer> mute) 
struct dce110_stream_encoder *enc110 = <token> <answer> DCE110STRENC_FROM_STRENC(enc); 
REG_UPDATE(AFMT_AUDIO_PACKET_CONTROL, AFMT_AUDIO_SAMPLE_SEND, <token> <answer> !mute); 
void <token> <answer> dce110_se_dp_audio_setup( 
struct <token> *enc, <answer> stream_encoder 
unsigned int <token> <answer> az_inst, 
<token> audio_info *info) <answer> struct 
dce110_se_audio_setup(enc, <token> info); <answer> az_inst, 
void <token> <answer> dce110_se_dp_audio_enable( 
struct stream_encoder <token> <answer> *enc) 
dce110_se_enable_audio_clock(enc, <token> <answer> true); 
<token> dce110_se_dp_audio_disable( <answer> void 
<token> stream_encoder *enc) <answer> struct 
<token> false); <answer> dce110_se_enable_audio_clock(enc, 
void <token> <answer> dce110_se_hdmi_audio_setup( 
struct <token> *enc, <answer> stream_encoder 
unsigned <token> az_inst, <answer> int 
struct <token> *info, <answer> audio_info 
<token> audio_crtc_info *audio_crtc_info) <answer> struct 
<token> true); <answer> dce110_se_enable_audio_clock(enc, 
dce110_se_setup_hdmi_audio(enc, <token> <answer> audio_crtc_info); 
<token> az_inst, info); <answer> dce110_se_audio_setup(enc, 
<token> dce110_se_hdmi_audio_disable( <answer> void 
<token> stream_encoder *enc) <answer> struct 
<token> false); <answer> dce110_se_enable_audio_clock(enc, 
<token> void setup_stereo_sync( <answer> static 
<token> stream_encoder *enc, <answer> struct 
<token> tg_inst, bool enable) <answer> int 
<token> dce110_stream_encoder *enc110 = DCE110STRENC_FROM_STRENC(enc); <answer> struct 
REG_UPDATE(DIG_FE_CNTL, DIG_STEREOSYNC_SELECT, <token> <answer> tg_inst); 
REG_UPDATE(DIG_FE_CNTL, DIG_STEREOSYNC_GATE_EN, <token> <answer> !enable); 
<token> void dig_connect_to_otg( <answer> static 
<token> stream_encoder *enc, <answer> struct 
int <token> <answer> tg_inst) 
<token> dce110_stream_encoder *enc110 = DCE110STRENC_FROM_STRENC(enc); <answer> struct 
REG_UPDATE(DIG_FE_CNTL, DIG_SOURCE_SELECT, <token> <answer> tg_inst); 
static unsigned int <token> <answer> dig_source_otg( 
struct stream_encoder <token> <answer> *enc) 
uint32_t <token> = 0; <answer> tg_inst 
struct dce110_stream_encoder *enc110 = <token> <answer> DCE110STRENC_FROM_STRENC(enc); 
REG_GET(DIG_FE_CNTL, DIG_SOURCE_SELECT, <token> <answer> &tg_inst); 
return <token> <answer> tg_inst; 
static const struct stream_encoder_funcs <token> = { <answer> dce110_str_enc_funcs 
<token> = <answer> .dp_set_stream_attribute 
.hdmi_set_stream_attribute <token> <answer> = 
.dvi_set_stream_attribute <token> <answer> = 
<token> = <answer> .lvds_set_stream_attribute 
<token> = <answer> .set_throttled_vcp_size 
<token> = <answer> .update_hdmi_info_packets 
.stop_hdmi_info_packets <token> <answer> = 
.update_dp_info_packets <token> <answer> = 
.stop_dp_info_packets <token> <answer> = 
.dp_blank <token> <answer> = 
<token> = <answer> .dp_unblank 
.audio_mute_control <token> dce110_se_audio_mute_control, <answer> = 
<token> = dce110_se_dp_audio_setup, <answer> .dp_audio_setup 
.dp_audio_enable = <token> <answer> dce110_se_dp_audio_enable, 
.dp_audio_disable <token> dce110_se_dp_audio_disable, <answer> = 
.hdmi_audio_setup = <token> <answer> dce110_se_hdmi_audio_setup, 
.hdmi_audio_disable <token> dce110_se_hdmi_audio_disable, <answer> = 
.setup_stereo_sync <token> setup_stereo_sync, <answer> = 
.set_avmute = <token> <answer> dce110_stream_encoder_set_avmute, 
.dig_connect_to_otg = <token> <answer> dig_connect_to_otg, 
.hdmi_reset_stream_attribute <token> dce110_reset_hdmi_stream_attribute, <answer> = 
.dig_source_otg = <token> <answer> dig_source_otg, 
<token> dce110_stream_encoder_construct( <answer> void 
struct <token> *enc110, <answer> dce110_stream_encoder 
<token> dc_context *ctx, <answer> struct 
struct <token> *bp, <answer> dc_bios 
enum engine_id <token> <answer> eng_id, 
const <token> dce110_stream_enc_registers *regs, <answer> struct 
const <token> dce_stream_encoder_shift *se_shift, <answer> struct 
const struct <token> *se_mask) <answer> dce_stream_encoder_mask 
enc110->base.funcs = <token> <answer> &dce110_str_enc_funcs; 
enc110->base.ctx <token> ctx; <answer> = 
enc110->base.id <token> eng_id; <answer> = 
<token> = bp; <answer> enc110->base.bp 
<token> = regs; <answer> enc110->regs 
enc110->se_shift = <token> <answer> se_shift; 
enc110->se_mask <token> se_mask; <answer> = 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/mm.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/uaccess.h> 
#include <token> <answer> <linux/ktime.h> 
<token> <linux/debugfs.h> <answer> #include 
<token> <linux/highmem.h> <answer> #include 
<token> "gup_test.h" <answer> #include 
static void put_back_pages(unsigned int cmd, struct <token> **pages, <answer> page 
unsigned long <token> unsigned int gup_test_flags) <answer> nr_pages, 
unsigned <token> i; <answer> long 
<token> (cmd) { <answer> switch 
case <token> <answer> GUP_FAST_BENCHMARK: 
case <token> <answer> GUP_BASIC_TEST: 
for (i = 0; i < nr_pages; <token> <answer> i++) 
<token> PIN_FAST_BENCHMARK: <answer> case 
<token> PIN_BASIC_TEST: <answer> case 
case <token> <answer> PIN_LONGTERM_BENCHMARK: 
unpin_user_pages(pages, <token> <answer> nr_pages); 
<token> DUMP_USER_PAGES_TEST: <answer> case 
if <token> & GUP_TEST_FLAG_DUMP_PAGES_USE_PIN) { <answer> (gup_test_flags 
<token> nr_pages); <answer> unpin_user_pages(pages, 
<token> else { <answer> } 
for (i = 0; i < nr_pages; <token> <answer> i++) 
static void verify_dma_pinned(unsigned int cmd, struct <token> **pages, <answer> page 
<token> long nr_pages) <answer> unsigned 
unsigned <token> i; <answer> long 
struct folio <token> <answer> *folio; 
switch <token> { <answer> (cmd) 
<token> PIN_FAST_BENCHMARK: <answer> case 
<token> PIN_BASIC_TEST: <answer> case 
case <token> <answer> PIN_LONGTERM_BENCHMARK: 
for (i = 0; i <token> nr_pages; i++) { <answer> < 
folio = <token> <answer> page_folio(pages[i]); 
if <token> <answer> (WARN(!folio_maybe_dma_pinned(folio), 
<token> is NOT dma-pinned\n", i)) { <answer> "pages[%lu] 
<token> "gup_test failure"); <answer> dump_page(&folio->page, 
} <token> if (cmd == PIN_LONGTERM_BENCHMARK && <answer> else 
"pages[%lu] is NOT <token> but pinned\n", <answer> pinnable 
i)) <token> <answer> { 
dump_page(&folio->page, "gup_test <token> <answer> failure"); 
static void <token> gup_test *gup, struct page **pages, <answer> dump_pages_test(struct 
unsigned long <token> <answer> nr_pages) 
<token> int index_to_dump; <answer> unsigned 
unsigned <token> i; <answer> int 
for (i = 0; i < <token> i++) { <answer> GUP_TEST_MAX_PAGES_TO_DUMP; 
if <token> > nr_pages) { <answer> (gup->which_pages[i] 
<token> due to out of range: .which_pages[%u]: %u\n", <answer> pr_warn("ZEROING 
<token> gup->which_pages[i]); <answer> i, 
gup->which_pages[i] <token> 0; <answer> = 
for (i = 0; i < GUP_TEST_MAX_PAGES_TO_DUMP; i++) <token> <answer> { 
<token> = gup->which_pages[i]; <answer> index_to_dump 
if (index_to_dump) <token> <answer> { 
pr_info("---- page #%u, <token> from user virt addr: 0x%llx\n", <answer> starting 
index_to_dump, <token> <answer> gup->addr); 
<token> dump_pages() test"); <answer> "gup_test: 
static int __gup_test_ioctl(unsigned <token> cmd, <answer> int 
struct gup_test <token> <answer> *gup) 
ktime_t <token> end_time; <answer> start_time, 
unsigned long <token> nr_pages, addr, next; <answer> i, 
long <token> <answer> nr; 
struct <token> **pages; <answer> page 
int ret = <token> <answer> 0; 
bool needs_mmap_lock <token> <answer> = 
cmd <token> GUP_FAST_BENCHMARK && cmd != PIN_FAST_BENCHMARK; <answer> != 
if (gup->size <token> ULONG_MAX) <answer> > 
return <token> <answer> -EINVAL; 
nr_pages = <token> / PAGE_SIZE; <answer> gup->size 
pages = <token> sizeof(void *), GFP_KERNEL); <answer> kvcalloc(nr_pages, 
if <token> <answer> (!pages) 
return <token> <answer> -ENOMEM; 
<token> (needs_mmap_lock && mmap_read_lock_killable(current->mm)) { <answer> if 
ret = <token> <answer> -EINTR; 
goto <token> <answer> free_pages; 
<token> = 0; <answer> i 
<token> = gup->nr_pages_per_call; <answer> nr 
start_time = <token> <answer> ktime_get(); 
for (addr = gup->addr; <token> < gup->addr + gup->size; addr = next) { <answer> addr 
if (nr != <token> <answer> gup->nr_pages_per_call) 
<token> = addr + nr * PAGE_SIZE; <answer> next 
if <token> > gup->addr + gup->size) { <answer> (next 
next = gup->addr + <token> <answer> gup->size; 
nr = (next - addr) / <token> <answer> PAGE_SIZE; 
<token> (cmd) { <answer> switch 
case <token> <answer> GUP_FAST_BENCHMARK: 
<token> = get_user_pages_fast(addr, nr, gup->gup_flags, <answer> nr 
pages + <token> <answer> i); 
<token> GUP_BASIC_TEST: <answer> case 
nr = get_user_pages(addr, nr, gup->gup_flags, <token> + i); <answer> pages 
case <token> <answer> PIN_FAST_BENCHMARK: 
nr <token> pin_user_pages_fast(addr, nr, gup->gup_flags, <answer> = 
pages + <token> <answer> i); 
case <token> <answer> PIN_BASIC_TEST: 
<token> = pin_user_pages(addr, nr, gup->gup_flags, pages + i); <answer> nr 
case <token> <answer> PIN_LONGTERM_BENCHMARK: 
nr <token> pin_user_pages(addr, nr, <answer> = 
<token> | FOLL_LONGTERM, <answer> gup->gup_flags 
pages <token> i); <answer> + 
case <token> <answer> DUMP_USER_PAGES_TEST: 
if <token> & GUP_TEST_FLAG_DUMP_PAGES_USE_PIN) <answer> (gup->test_flags 
<token> = pin_user_pages(addr, nr, gup->gup_flags, <answer> nr 
pages + <token> <answer> i); 
nr = get_user_pages(addr, <token> gup->gup_flags, <answer> nr, 
<token> + i); <answer> pages 
ret <token> -EINVAL; <answer> = 
<token> unlock; <answer> goto 
if (nr <token> 0) <answer> <= 
i <token> nr; <answer> += 
<token> = ktime_get(); <answer> end_time 
<token> pages, nr_pages); <answer> verify_dma_pinned(cmd, 
<token> (cmd == DUMP_USER_PAGES_TEST) <answer> if 
<token> pages, nr_pages); <answer> dump_pages_test(gup, 
start_time = <token> <answer> ktime_get(); 
<token> pages, nr_pages, gup->test_flags); <answer> put_back_pages(cmd, 
end_time = <token> <answer> ktime_get(); 
gup->put_delta_usec <token> ktime_us_delta(end_time, start_time); <answer> = 
if <token> <answer> (needs_mmap_lock) 
<token> ret; <answer> return 
<token> DEFINE_MUTEX(pin_longterm_test_mutex); <answer> static 
<token> struct page **pin_longterm_test_pages; <answer> static 
static unsigned <token> pin_longterm_test_nr_pages; <answer> long 
static inline <token> pin_longterm_test_stop(void) <answer> void 
<token> (pin_longterm_test_pages) { <answer> if 
if <token> <answer> (pin_longterm_test_nr_pages) 
pin_longterm_test_pages <token> NULL; <answer> = 
pin_longterm_test_nr_pages = <token> <answer> 0; 
static inline int <token> long arg) <answer> pin_longterm_test_start(unsigned 
long nr_pages, cur_pages, addr, <token> <answer> remaining_pages; 
int <token> = FOLL_LONGTERM; <answer> gup_flags 
struct <token> args; <answer> pin_longterm_test 
struct page <token> <answer> **pages; 
int <token> = 0; <answer> ret 
bool <token> <answer> fast; 
if <token> <answer> (pin_longterm_test_pages) 
return <token> <answer> -EINVAL; 
if (copy_from_user(&args, <token> __user *)arg, sizeof(args))) <answer> (void 
<token> -EFAULT; <answer> return 
if (args.flags <token> <answer> & 
return <token> <answer> -EINVAL; 
if (!IS_ALIGNED(args.addr <token> args.size, PAGE_SIZE)) <answer> | 
<token> -EINVAL; <answer> return 
<token> (args.size > LONG_MAX) <answer> if 
<token> -EINVAL; <answer> return 
<token> = args.size / PAGE_SIZE; <answer> nr_pages 
<token> (!nr_pages) <answer> if 
<token> -EINVAL; <answer> return 
<token> = kvcalloc(nr_pages, sizeof(void *), GFP_KERNEL); <answer> pages 
<token> (!pages) <answer> if 
<token> -ENOMEM; <answer> return 
if <token> & PIN_LONGTERM_TEST_FLAG_USE_WRITE) <answer> (args.flags 
gup_flags <token> FOLL_WRITE; <answer> |= 
fast <token> !!(args.flags & PIN_LONGTERM_TEST_FLAG_USE_FAST); <answer> = 
if (!fast && mmap_read_lock_killable(current->mm)) <token> <answer> { 
<token> -EINTR; <answer> return 
pin_longterm_test_pages <token> pages; <answer> = 
pin_longterm_test_nr_pages = <token> <answer> 0; 
while (nr_pages - pin_longterm_test_nr_pages) <token> <answer> { 
remaining_pages = nr_pages <token> pin_longterm_test_nr_pages; <answer> - 
addr <token> args.addr + pin_longterm_test_nr_pages * PAGE_SIZE; <answer> = 
<token> (fast) <answer> if 
cur_pages = <token> remaining_pages, <answer> pin_user_pages_fast(addr, 
<token> pages); <answer> gup_flags, 
cur_pages <token> pin_user_pages(addr, remaining_pages, <answer> = 
<token> pages); <answer> gup_flags, 
if (cur_pages < <token> { <answer> 0) 
<token> = cur_pages; <answer> ret 
pin_longterm_test_nr_pages += <token> <answer> cur_pages; 
pages <token> cur_pages; <answer> += 
<token> (!fast) <answer> if 
return <token> <answer> ret; 
static inline int pin_longterm_test_read(unsigned <token> arg) <answer> long 
__u64 <token> <answer> user_addr; 
unsigned <token> i; <answer> long 
<token> (!pin_longterm_test_pages) <answer> if 
<token> -EINVAL; <answer> return 
<token> (copy_from_user(&user_addr, (void __user *)arg, sizeof(user_addr))) <answer> if 
return <token> <answer> -EFAULT; 
for <token> = 0; i < pin_longterm_test_nr_pages; i++) { <answer> (i 
void <token> = kmap_local_page(pin_longterm_test_pages[i]); <answer> *addr 
unsigned <token> ret; <answer> long 
ret = <token> __user *)(unsigned long)user_addr, addr, <answer> copy_to_user((void 
if <token> <answer> (ret) 
return <token> <answer> -EFAULT; 
user_addr += <token> <answer> PAGE_SIZE; 
return <token> <answer> 0; 
static <token> pin_longterm_test_ioctl(struct file *filep, unsigned int cmd, <answer> long 
unsigned <token> arg) <answer> long 
int ret <token> -EINVAL; <answer> = 
<token> (mutex_lock_killable(&pin_longterm_test_mutex)) <answer> if 
<token> -EINTR; <answer> return 
<token> (cmd) { <answer> switch 
<token> PIN_LONGTERM_TEST_START: <answer> case 
ret = <token> <answer> pin_longterm_test_start(arg); 
case <token> <answer> PIN_LONGTERM_TEST_STOP: 
ret <token> 0; <answer> = 
<token> PIN_LONGTERM_TEST_READ: <answer> case 
ret = <token> <answer> pin_longterm_test_read(arg); 
<token> ret; <answer> return 
static long gup_test_ioctl(struct <token> *filep, unsigned int cmd, <answer> file 
<token> long arg) <answer> unsigned 
struct <token> gup; <answer> gup_test 
int <token> <answer> ret; 
<token> (cmd) { <answer> switch 
case <token> <answer> GUP_FAST_BENCHMARK: 
case <token> <answer> PIN_FAST_BENCHMARK: 
case <token> <answer> PIN_LONGTERM_BENCHMARK: 
<token> GUP_BASIC_TEST: <answer> case 
<token> PIN_BASIC_TEST: <answer> case 
<token> DUMP_USER_PAGES_TEST: <answer> case 
<token> PIN_LONGTERM_TEST_START: <answer> case 
case <token> <answer> PIN_LONGTERM_TEST_STOP: 
case <token> <answer> PIN_LONGTERM_TEST_READ: 
return <token> cmd, arg); <answer> pin_longterm_test_ioctl(filep, 
return <token> <answer> -EINVAL; 
if (copy_from_user(&gup, (void __user <token> sizeof(gup))) <answer> *)arg, 
<token> -EFAULT; <answer> return 
<token> = __gup_test_ioctl(cmd, &gup); <answer> ret 
if <token> <answer> (ret) 
<token> ret; <answer> return 
if <token> __user *)arg, &gup, sizeof(gup))) <answer> (copy_to_user((void 
<token> -EFAULT; <answer> return 
return <token> <answer> 0; 
static int <token> inode *inode, struct file *file) <answer> gup_test_release(struct 
<token> 0; <answer> return 
static const struct file_operations gup_test_fops = <token> <answer> { 
.open <token> nonseekable_open, <answer> = 
.unlocked_ioctl <token> gup_test_ioctl, <answer> = 
.compat_ioctl <token> compat_ptr_ioctl, <answer> = 
.release <token> gup_test_release, <answer> = 
static <token> __init gup_test_init(void) <answer> int 
debugfs_create_file_unsafe("gup_test", 0600, <token> NULL, <answer> NULL, 
<token> 0; <answer> return 
<token> <linux/types.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
#include <token> <answer> "vcap_api.h" 
#include <token> <answer> "sparx5_vcap_ag_api.h" 
#include <token> <answer> <linux/mm.h> 
<token> <linux/gfp.h> <answer> #include 
#include <token> <answer> <linux/ras.h> 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/workqueue.h> <answer> #include 
#include <token> <answer> <asm/mce.h> 
<token> "debugfs.h" <answer> #include 
#undef <token> <answer> pr_fmt 
<token> pr_fmt(fmt) "RAS: " fmt <answer> #define 
#define DECAY_BITS <token> <answer> 2 
#define DECAY_MASK ((1ULL << DECAY_BITS) - <token> <answer> 1) 
#define <token> (PAGE_SIZE / sizeof(u64)) <answer> MAX_ELEMS 
#define CLEAN_ELEMS (MAX_ELEMS <token> DECAY_BITS) <answer> >> 
#define PFN(e) <token> >> PAGE_SHIFT) <answer> ((e) 
#define DECAY(e) (((e) >> COUNT_BITS) & <token> <answer> DECAY_MASK) 
#define COUNT(e) <token> int)(e) & COUNT_MASK) <answer> ((unsigned 
#define <token> ((e) & (PAGE_SIZE - 1)) <answer> FULL_COUNT(e) 
<token> struct ce_array { <answer> static 
union <token> <answer> { 
struct <token> <answer> { 
static <token> do_spring_cleaning(struct ce_array *ca) <answer> void 
int <token> <answer> i; 
for <token> = 0; i < ca->n; i++) { <answer> (i 
<token> decay = DECAY(ca->array[i]); <answer> u8 
<token> (!decay) <answer> if 
ca->array[i] <token> ~(DECAY_MASK << COUNT_BITS); <answer> &= 
<token> |= (decay << COUNT_BITS); <answer> ca->array[i] 
ca->decay_count <token> 0; <answer> = 
static void cec_mod_work(unsigned long <token> <answer> interval) 
unsigned long <token> <answer> iv; 
<token> = interval * HZ; <answer> iv 
mod_delayed_work(system_wq, &cec_work, <token> <answer> round_jiffies(iv)); 
static void cec_work_fn(struct <token> *work) <answer> work_struct 
static int __find_elem(struct ce_array *ca, <token> pfn, unsigned int *to) <answer> u64 
int min = 0, max = <token> - 1; <answer> ca->n 
u64 <token> <answer> this_pfn; 
<token> (min <= max) { <answer> while 
int i = (min + <token> >> 1; <answer> max) 
this_pfn <token> PFN(ca->array[i]); <answer> = 
if (this_pfn <token> pfn) <answer> < 
min <token> i + 1; <answer> = 
else if <token> > pfn) <answer> (this_pfn 
max = <token> - 1; <answer> i 
else if (this_pfn == <token> { <answer> pfn) 
if <token> <answer> (to) 
*to <token> i; <answer> = 
return <token> <answer> i; 
if <token> <answer> (to) 
*to = <token> <answer> min; 
<token> -ENOKEY; <answer> return 
static int find_elem(struct <token> *ca, u64 pfn, unsigned int *to) <answer> ce_array 
if <token> { <answer> (!ca->n) 
*to <token> 0; <answer> = 
return <token> <answer> -ENOKEY; 
return <token> pfn, to); <answer> __find_elem(ca, 
static <token> del_elem(struct ce_array *ca, int idx) <answer> void 
static u64 <token> del_lru_elem(void) <answer> __maybe_unused 
struct ce_array *ca = <token> <answer> &ce_arr; 
<token> pfn; <answer> u64 
<token> (!ca->n) <answer> if 
<token> 0; <answer> return 
pfn = <token> <answer> del_lru_elem_unlocked(ca); 
<token> pfn; <answer> return 
static bool sanity_check(struct ce_array <token> <answer> *ca) 
<token> ret = false; <answer> bool 
<token> prev = 0; <answer> u64 
<token> i; <answer> int 
for (i = 0; i < ca->n; i++) <token> <answer> { 
u64 <token> = PFN(ca->array[i]); <answer> this 
if (WARN(prev > this, <token> 0x%016llx <-> this: 0x%016llx\n", prev, this)) <answer> "prev: 
<token> = true; <answer> ret 
<token> = this; <answer> prev 
if <token> <answer> (!ret) 
<token> ret; <answer> return 
pr_info("Sanity check <token> n: %d\n", ca->n); <answer> dump:\n{ 
for <token> = 0; i < ca->n; i++) { <answer> (i 
u64 <token> = PFN(ca->array[i]); <answer> this 
pr_info(" %03d: [%016llx|%03llx]\n", i, this, <token> <answer> FULL_COUNT(ca->array[i])); 
<token> ret; <answer> return 
static int cec_add_elem(u64 <token> <answer> pfn) 
<token> ce_array *ca = &ce_arr; <answer> struct 
int count, err, ret <token> 0; <answer> = 
unsigned <token> to = 0; <answer> int 
if (!ce_arr.array <token> ce_arr.disabled) <answer> || 
<token> -ENODEV; <answer> return 
memmove((void *)&ca->array[to + <token> <answer> 1], 
<token> *)&ca->array[to], <answer> (void 
(ca->n <token> to) * sizeof(u64)); <answer> - 
ca->array[to] = <token> << PAGE_SHIFT; <answer> pfn 
ret = <token> <answer> 1; 
<token> unlock; <answer> goto 
<token> (ca->decay_count >= CLEAN_ELEMS) <answer> if 
return <token> <answer> ret; 
<token> int u64_get(void *data, u64 *val) <answer> static 
*val = <token> *)data; <answer> *(u64 
<token> 0; <answer> return 
static <token> pfn_set(void *data, u64 val) <answer> int 
*(u64 <token> = val; <answer> *)data 
return <token> <answer> 0; 
<token> u64_get, pfn_set, "0x%llx\n"); <answer> DEFINE_DEBUGFS_ATTRIBUTE(pfn_ops, 
static int decay_interval_set(void *data, <token> val) <answer> u64 
if (val <token> CEC_DECAY_MIN_INTERVAL) <answer> < 
return <token> <answer> -EINVAL; 
if (val <token> CEC_DECAY_MAX_INTERVAL) <answer> > 
return <token> <answer> -EINVAL; 
*(u64 *)data = <token> <answer> val; 
<token> = val; <answer> decay_interval 
return <token> <answer> 0; 
DEFINE_DEBUGFS_ATTRIBUTE(decay_interval_ops, u64_get, decay_interval_set, <token> <answer> "%lld\n"); 
static int action_threshold_set(void *data, u64 <token> <answer> val) 
*(u64 <token> = val; <answer> *)data 
if (val > <token> <answer> COUNT_MASK) 
<token> = COUNT_MASK; <answer> val 
action_threshold = <token> <answer> val; 
<token> 0; <answer> return 
DEFINE_DEBUGFS_ATTRIBUTE(action_threshold_ops, u64_get, action_threshold_set, <token> <answer> "%lld\n"); 
static <token> char * const bins[] = { "00", "01", "10", "11" }; <answer> const 
static int array_show(struct seq_file *m, void <token> <answer> *v) 
<token> ce_array *ca = &ce_arr; <answer> struct 
<token> i; <answer> int 
<token> "{ n: %d\n", ca->n); <answer> seq_printf(m, 
<token> (i = 0; i < ca->n; i++) { <answer> for 
u64 this <token> PFN(ca->array[i]); <answer> = 
<token> " %3d: [%016llx|%s|%03llx]\n", <answer> seq_printf(m, 
i, this, <token> COUNT(ca->array[i])); <answer> bins[DECAY(ca->array[i])], 
<token> "}\n"); <answer> seq_printf(m, 
<token> "Stats:\nCEs: %llu\nofflined pages: %llu\n", <answer> seq_printf(m, 
<token> ca->pfns_poisoned); <answer> ca->ces_entered, 
<token> "Flags: 0x%x\n", ca->flags); <answer> seq_printf(m, 
seq_printf(m, "Decay <token> %lld seconds\n", decay_interval); <answer> interval: 
seq_printf(m, <token> %lld\n", ca->decays_done); <answer> "Decays: 
seq_printf(m, "Action threshold: <token> action_threshold); <answer> %lld\n", 
<token> 0; <answer> return 
static <token> __init create_debugfs_nodes(void) <answer> int 
struct dentry *d, *pfn, *decay, <token> *array, *dfs; <answer> *count, 
<token> = ras_get_debugfs_root(); <answer> dfs 
if <token> { <answer> (!dfs) 
pr_warn("Error getting RAS <token> root!\n"); <answer> debugfs 
return <token> <answer> -1; 
<token> = debugfs_create_dir("cec", dfs); <answer> d 
if <token> { <answer> (!d) 
pr_warn("Error creating cec <token> node!\n"); <answer> debugfs 
return <token> <answer> -1; 
decay = <token> S_IRUSR | S_IWUSR, d, <answer> debugfs_create_file("decay_interval", 
<token> &decay_interval_ops); <answer> &decay_interval, 
<token> (!decay) { <answer> if 
<token> creating decay_interval debugfs node!\n"); <answer> pr_warn("Error 
<token> err; <answer> goto 
count = debugfs_create_file("action_threshold", S_IRUSR | S_IWUSR, <token> <answer> d, 
<token> &action_threshold_ops); <answer> &action_threshold, 
if <token> { <answer> (!count) 
pr_warn("Error creating <token> debugfs node!\n"); <answer> action_threshold 
<token> err; <answer> goto 
if <token> <answer> (!IS_ENABLED(CONFIG_RAS_CEC_DEBUG)) 
<token> 0; <answer> return 
pfn = debugfs_create_file("pfn", S_IRUSR | S_IWUSR, <token> &dfs_pfn, &pfn_ops); <answer> d, 
<token> (!pfn) { <answer> if 
pr_warn("Error creating pfn debugfs <token> <answer> node!\n"); 
<token> err; <answer> goto 
array = debugfs_create_file("array", <token> d, NULL, &array_fops); <answer> S_IRUSR, 
if <token> { <answer> (!array) 
pr_warn("Error creating <token> debugfs node!\n"); <answer> array 
<token> err; <answer> goto 
return <token> <answer> 0; 
return <token> <answer> 1; 
static int <token> notifier_block *nb, unsigned long val, <answer> cec_notifier(struct 
<token> *data) <answer> void 
struct mce *m = <token> mce *)data; <answer> (struct 
if <token> <answer> (!m) 
return <token> <answer> NOTIFY_DONE; 
<token> (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL) <answer> if 
<token> = 2; <answer> action_threshold 
ce_arr.array <token> (void *)get_zeroed_page(GFP_KERNEL); <answer> = 
<token> (!ce_arr.array) { <answer> if 
<token> allocating CE array page!\n"); <answer> pr_err("Error 
return <token> <answer> -ENOMEM; 
if (create_debugfs_nodes()) <token> <answer> { 
free_page((unsigned <token> <answer> long)ce_arr.array); 
<token> -ENOMEM; <answer> return 
INIT_DELAYED_WORK(&cec_work, <token> <answer> cec_work_fn); 
schedule_delayed_work(&cec_work, <token> <answer> CEC_DECAY_DEFAULT_INTERVAL); 
<token> Errors collector initialized.\n"); <answer> pr_info("Correctable 
<token> 0; <answer> return 
<token> __init parse_cec_param(char *str) <answer> int 
<token> (!str) <answer> if 
<token> 0; <answer> return 
if (*str <token> '=') <answer> == 
<token> (!strcmp(str, "cec_disable")) <answer> if 
<token> = 1; <answer> ce_arr.disabled 
return <token> <answer> 0; 
return <token> <answer> 1; 
<token> <linux/completion.h> <answer> #include 
#include <token> <answer> <linux/dma-mapping.h> 
#include <token> <answer> <linux/err.h> 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/export.h> 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/bitops.h> 
#include <token> <answer> <linux/random.h> 
<token> <rdma/ib_cache.h> <answer> #include 
#include <token> <answer> "sa.h" 
static <token> mcast_add_one(struct ib_device *device); <answer> int 
static void mcast_remove_one(struct ib_device *device, void <token> <answer> *client_data); 
static struct ib_client mcast_client <token> { <answer> = 
<token> = "ib_multicast", <answer> .name 
<token> = mcast_add_one, <answer> .add 
.remove <token> mcast_remove_one <answer> = 
<token> struct ib_sa_client sa_client; <answer> static 
static struct <token> *mcast_wq; <answer> workqueue_struct 
static <token> ib_gid mgid0; <answer> union 
<token> mcast_device; <answer> struct 
struct mcast_port <token> <answer> { 
struct mcast_device <token> <answer> *dev; 
spinlock_t <token> <answer> lock; 
struct rb_root <token> <answer> table; 
refcount_t <token> <answer> refcount; 
<token> completion comp; <answer> struct 
<token> port_num; <answer> u32 
struct <token> { <answer> mcast_device 
<token> ib_device *device; <answer> struct 
struct <token> event_handler; <answer> ib_event_handler 
<token> start_port; <answer> int 
int <token> <answer> end_port; 
<token> mcast_port port[]; <answer> struct 
<token> mcast_state { <answer> enum 
<token> mcast_group_state { <answer> enum 
enum <token> <answer> { 
<token> = 0xFFFF <answer> MCAST_INVALID_PKEY_INDEX 
struct <token> <answer> mcast_member; 
<token> mcast_group { <answer> struct 
<token> ib_sa_mcmember_rec rec; <answer> struct 
struct rb_node <token> <answer> node; 
struct mcast_port <token> <answer> *port; 
spinlock_t <token> <answer> lock; 
<token> work_struct work; <answer> struct 
struct <token> pending_list; <answer> list_head 
<token> list_head active_list; <answer> struct 
<token> mcast_member *last_join; <answer> struct 
<token> members[NUM_JOIN_MEMBERSHIP_TYPES]; <answer> int 
atomic_t <token> <answer> refcount; 
enum mcast_group_state <token> <answer> state; 
struct ib_sa_query <token> <answer> *query; 
u16 <token> <answer> pkey_index; 
u8 <token> <answer> leave_state; 
<token> retries; <answer> int 
<token> mcast_member { <answer> struct 
<token> ib_sa_multicast multicast; <answer> struct 
<token> ib_sa_client *client; <answer> struct 
struct mcast_group <token> <answer> *group; 
struct <token> list; <answer> list_head 
enum <token> state; <answer> mcast_state 
<token> refcount; <answer> refcount_t 
struct completion <token> <answer> comp; 
static void join_handler(int status, struct ib_sa_mcmember_rec <token> <answer> *rec, 
void <token> <answer> *context); 
<token> void leave_handler(int status, struct ib_sa_mcmember_rec *rec, <answer> static 
void <token> <answer> *context); 
static struct mcast_group <token> mcast_port *port, <answer> *mcast_find(struct 
union <token> *mgid) <answer> ib_gid 
struct rb_node *node = <token> <answer> port->table.rb_node; 
struct <token> *group; <answer> mcast_group 
int <token> <answer> ret; 
while (node) <token> <answer> { 
<token> = rb_entry(node, struct mcast_group, node); <answer> group 
<token> = memcmp(mgid->raw, group->rec.mgid.raw, sizeof *mgid); <answer> ret 
if <token> <answer> (!ret) 
return <token> <answer> group; 
<token> (ret < 0) <answer> if 
node = <token> <answer> node->rb_left; 
<token> = node->rb_right; <answer> node 
return <token> <answer> NULL; 
static struct mcast_group <token> mcast_port *port, <answer> *mcast_insert(struct 
<token> mcast_group *group, <answer> struct 
int <token> <answer> allow_duplicates) 
struct rb_node **link <token> &port->table.rb_node; <answer> = 
struct rb_node *parent <token> NULL; <answer> = 
struct <token> *cur_group; <answer> mcast_group 
int <token> <answer> ret; 
<token> (*link) { <answer> while 
parent <token> *link; <answer> = 
cur_group = <token> struct mcast_group, node); <answer> rb_entry(parent, 
ret = <token> cur_group->rec.mgid.raw, <answer> memcmp(group->rec.mgid.raw, 
<token> group->rec.mgid); <answer> sizeof 
if (ret < <token> <answer> 0) 
<token> = &(*link)->rb_left; <answer> link 
else if (ret > <token> <answer> 0) 
link <token> &(*link)->rb_right; <answer> = 
else <token> (allow_duplicates) <answer> if 
link = <token> <answer> &(*link)->rb_left; 
<token> cur_group; <answer> return 
<token> parent, link); <answer> rb_link_node(&group->node, 
rb_insert_color(&group->node, <token> <answer> &port->table); 
<token> NULL; <answer> return 
static void <token> mcast_port *port) <answer> deref_port(struct 
<token> (refcount_dec_and_test(&port->refcount)) <answer> if 
<token> void release_group(struct mcast_group *group) <answer> static 
struct <token> *port = group->port; <answer> mcast_port 
<token> long flags; <answer> unsigned 
<token> flags); <answer> spin_lock_irqsave(&port->lock, 
<token> (atomic_dec_and_test(&group->refcount)) { <answer> if 
<token> &port->table); <answer> rb_erase(&group->node, 
spin_unlock_irqrestore(&port->lock, <token> <answer> flags); 
} <token> <answer> else 
spin_unlock_irqrestore(&port->lock, <token> <answer> flags); 
static void deref_member(struct mcast_member <token> <answer> *member) 
<token> (refcount_dec_and_test(&member->refcount)) <answer> if 
<token> void queue_join(struct mcast_member *member) <answer> static 
struct <token> *group = member->group; <answer> mcast_group 
unsigned <token> flags; <answer> long 
spin_lock_irqsave(&group->lock, <token> <answer> flags); 
<token> &group->pending_list); <answer> list_add_tail(&member->list, 
if (group->state <token> MCAST_IDLE) { <answer> == 
group->state = <token> <answer> MCAST_BUSY; 
<token> &group->work); <answer> queue_work(mcast_wq, 
spin_unlock_irqrestore(&group->lock, <token> <answer> flags); 
static void adjust_membership(struct mcast_group *group, u8 join_state, <token> inc) <answer> int 
int <token> <answer> i; 
for (i = 0; i < NUM_JOIN_MEMBERSHIP_TYPES; <token> join_state >>= 1) <answer> i++, 
if (join_state & <token> <answer> 0x1) 
group->members[i] <token> inc; <answer> += 
static <token> get_leave_state(struct mcast_group *group) <answer> u8 
u8 leave_state = <token> <answer> 0; 
int <token> <answer> i; 
for (i = 0; i <token> NUM_JOIN_MEMBERSHIP_TYPES; i++) <answer> < 
if <token> <answer> (!group->members[i]) 
leave_state |= (0x1 << <token> <answer> i); 
return leave_state & <token> <answer> group->rec.join_state; 
static <token> check_selector(ib_sa_comp_mask comp_mask, <answer> int 
<token> selector_mask, <answer> ib_sa_comp_mask 
ib_sa_comp_mask <token> <answer> value_mask, 
<token> selector, u8 src_value, u8 dst_value) <answer> u8 
<token> err; <answer> int 
if (!(comp_mask & selector_mask) || !(comp_mask <token> value_mask)) <answer> & 
return <token> <answer> 0; 
switch (selector) <token> <answer> { 
case <token> <answer> IB_SA_GT: 
err = <token> <= dst_value); <answer> (src_value 
<token> IB_SA_LT: <answer> case 
err <token> (src_value >= dst_value); <answer> = 
case <token> <answer> IB_SA_EQ: 
err = (src_value <token> dst_value); <answer> != 
err = <token> <answer> 0; 
<token> err; <answer> return 
static <token> cmp_rec(struct ib_sa_mcmember_rec *src, <answer> int 
struct ib_sa_mcmember_rec *dst, ib_sa_comp_mask <token> <answer> comp_mask) 
static void process_join_error(struct mcast_group *group, <token> status) <answer> int 
<token> mcast_member *member; <answer> struct 
int <token> <answer> ret; 
member <token> list_entry(group->pending_list.next, <answer> = 
<token> mcast_member, list); <answer> struct 
if (group->last_join == <token> { <answer> member) 
ret = <token> &member->multicast); <answer> member->multicast.callback(status, 
<token> (ret) <answer> if 
<token> else <answer> } 
static <token> join_handler(int status, struct ib_sa_mcmember_rec *rec, <answer> void 
void <token> <answer> *context) 
struct <token> *group = context; <answer> mcast_group 
u16 <token> = MCAST_INVALID_PKEY_INDEX; <answer> pkey_index 
if <token> <answer> (status) 
<token> status); <answer> process_join_error(group, 
else <token> <answer> { 
int mgids_changed, <token> <answer> is_mgid0; 
<token> (ib_find_pkey(group->port->dev->device, <answer> if 
<token> be16_to_cpu(rec->pkey), <answer> group->port->port_num, 
pkey_index = <token> <answer> MCAST_INVALID_PKEY_INDEX; 
if <token> == MCAST_BUSY && <answer> (group->state 
group->pkey_index <token> MCAST_INVALID_PKEY_INDEX) <answer> == 
<token> = pkey_index; <answer> group->pkey_index 
mgids_changed <token> memcmp(&rec->mgid, &group->rec.mgid, <answer> = 
<token> = *rec; <answer> group->rec 
if <token> { <answer> (mgids_changed) 
rb_erase(&group->node, <token> <answer> &group->port->table); 
is_mgid0 = !memcmp(&mgid0, <token> <answer> &group->rec.mgid, 
<token> group, is_mgid0); <answer> mcast_insert(group->port, 
static void <token> status, struct ib_sa_mcmember_rec *rec, <answer> leave_handler(int 
<token> *context) <answer> void 
struct mcast_group <token> = context; <answer> *group 
if (status && <token> > 0 && <answer> group->retries 
!send_leave(group, <token> <answer> group->leave_state)) 
static struct mcast_group <token> mcast_port *port, <answer> *acquire_group(struct 
<token> ib_gid *mgid, gfp_t gfp_mask) <answer> union 
struct mcast_group <token> *cur_group; <answer> *group, 
unsigned <token> flags; <answer> long 
int <token> <answer> is_mgid0; 
is_mgid0 = !memcmp(&mgid0, <token> sizeof mgid0); <answer> mgid, 
<token> (!is_mgid0) { <answer> if 
<token> flags); <answer> spin_lock_irqsave(&port->lock, 
<token> = mcast_find(port, mgid); <answer> group 
<token> (group) <answer> if 
goto <token> <answer> found; 
spin_unlock_irqrestore(&port->lock, <token> <answer> flags); 
group = kzalloc(sizeof *group, <token> <answer> gfp_mask); 
<token> (!group) <answer> if 
<token> NULL; <answer> return 
<token> = 3; <answer> group->retries 
group->port = <token> <answer> port; 
group->rec.mgid <token> *mgid; <answer> = 
<token> = MCAST_INVALID_PKEY_INDEX; <answer> group->pkey_index 
<token> mcast_work_handler); <answer> INIT_WORK(&group->work, 
spin_lock_irqsave(&port->lock, <token> <answer> flags); 
cur_group = mcast_insert(port, group, <token> <answer> is_mgid0); 
if <token> { <answer> (cur_group) 
<token> = cur_group; <answer> group 
<token> else <answer> } 
<token> flags); <answer> spin_unlock_irqrestore(&port->lock, 
return <token> <answer> group; 
struct <token> * <answer> ib_sa_multicast 
<token> ib_sa_client *client, <answer> ib_sa_join_multicast(struct 
<token> ib_device *device, u32 port_num, <answer> struct 
struct ib_sa_mcmember_rec <token> <answer> *rec, 
ib_sa_comp_mask comp_mask, <token> gfp_mask, <answer> gfp_t 
int (*callback)(int <token> <answer> status, 
struct <token> *multicast), <answer> ib_sa_multicast 
<token> *context) <answer> void 
<token> mcast_device *dev; <answer> struct 
struct <token> *member; <answer> mcast_member 
struct <token> *multicast; <answer> ib_sa_multicast 
int <token> <answer> ret; 
<token> = ib_get_client_data(device, &mcast_client); <answer> dev 
if <token> <answer> (!dev) 
return <token> <answer> ERR_PTR(-ENODEV); 
member <token> kmalloc(sizeof *member, gfp_mask); <answer> = 
<token> (!member) <answer> if 
return <token> <answer> ERR_PTR(-ENOMEM); 
member->client = <token> <answer> client; 
member->multicast.rec <token> *rec; <answer> = 
member->multicast.comp_mask <token> comp_mask; <answer> = 
member->multicast.callback <token> callback; <answer> = 
<token> = context; <answer> member->multicast.context 
<token> 1); <answer> refcount_set(&member->refcount, 
member->state = <token> <answer> MCAST_JOINING; 
member->group <token> acquire_group(&dev->port[port_num - dev->start_port], <answer> = 
<token> gfp_mask); <answer> &rec->mgid, 
<token> (!member->group) { <answer> if 
<token> = -ENOMEM; <answer> ret 
goto <token> <answer> err; 
multicast <token> &member->multicast; <answer> = 
return <token> <answer> multicast; 
<token> ERR_PTR(ret); <answer> return 
void ib_sa_free_multicast(struct <token> *multicast) <answer> ib_sa_multicast 
struct mcast_member <token> <answer> *member; 
struct mcast_group <token> <answer> *group; 
member = container_of(multicast, <token> mcast_member, multicast); <answer> struct 
<token> = member->group; <answer> group 
if (member->state == <token> <answer> MCAST_MEMBER) 
adjust_membership(group, multicast->rec.join_state, <token> <answer> -1); 
if <token> == MCAST_IDLE) { <answer> (group->state 
group->state <token> MCAST_BUSY; <answer> = 
int <token> ib_device *device, u32 port_num, <answer> ib_init_ah_from_mcmember(struct 
struct ib_sa_mcmember_rec <token> <answer> *rec, 
<token> net_device *ndev, <answer> struct 
<token> ib_gid_type gid_type, <answer> enum 
struct <token> *ah_attr) <answer> rdma_ah_attr 
<token> struct ib_gid_attr *sgid_attr; <answer> const 
if <token> port_num)) <answer> (rdma_protocol_ib(device, 
ndev = <token> <answer> NULL; 
else if <token> port_num)) <answer> (!rdma_protocol_roce(device, 
return <token> <answer> -EINVAL; 
sgid_attr = <token> &rec->port_gid, <answer> rdma_find_gid_by_port(device, 
gid_type, port_num, <token> <answer> ndev); 
<token> (IS_ERR(sgid_attr)) <answer> if 
<token> PTR_ERR(sgid_attr); <answer> return 
memset(ah_attr, 0, <token> <answer> sizeof(*ah_attr)); 
ah_attr->type = rdma_ah_find_type(device, <token> <answer> port_num); 
rdma_ah_set_dlid(ah_attr, <token> <answer> be16_to_cpu(rec->mlid)); 
<token> rec->sl); <answer> rdma_ah_set_sl(ah_attr, 
<token> port_num); <answer> rdma_ah_set_port_num(ah_attr, 
rdma_ah_set_static_rate(ah_attr, <token> <answer> rec->rate); 
<token> &rec->mgid, <answer> rdma_move_grh_sgid_attr(ah_attr, 
<token> rec->traffic_class, <answer> rec->hop_limit, 
return <token> <answer> 0; 
static void mcast_groups_event(struct mcast_port <token> <answer> *port, 
<token> mcast_group_state state) <answer> enum 
struct mcast_group <token> <answer> *group; 
struct <token> *node; <answer> rb_node 
unsigned <token> flags; <answer> long 
spin_lock_irqsave(&port->lock, <token> <answer> flags); 
for (node <token> rb_first(&port->table); node; node = rb_next(node)) { <answer> = 
group <token> rb_entry(node, struct mcast_group, node); <answer> = 
if (group->state == MCAST_IDLE) <token> <answer> { 
<token> &group->work); <answer> queue_work(mcast_wq, 
if <token> != MCAST_GROUP_ERROR) <answer> (group->state 
group->state <token> state; <answer> = 
<token> flags); <answer> spin_unlock_irqrestore(&port->lock, 
<token> void mcast_event_handler(struct ib_event_handler *handler, <answer> static 
struct ib_event <token> <answer> *event) 
<token> mcast_device *dev; <answer> struct 
int <token> <answer> index; 
dev = container_of(handler, struct mcast_device, <token> <answer> event_handler); 
if (!rdma_cap_ib_mcast(dev->device, <token> <answer> event->element.port_num)) 
index = event->element.port_num - <token> <answer> dev->start_port; 
switch <token> { <answer> (event->event) 
case <token> <answer> IB_EVENT_PORT_ERR: 
<token> IB_EVENT_LID_CHANGE: <answer> case 
case <token> <answer> IB_EVENT_CLIENT_REREGISTER: 
mcast_groups_event(&dev->port[index], <token> <answer> MCAST_GROUP_ERROR); 
case <token> <answer> IB_EVENT_PKEY_CHANGE: 
mcast_groups_event(&dev->port[index], <token> <answer> MCAST_PKEY_EVENT); 
static int <token> ib_device *device) <answer> mcast_add_one(struct 
struct mcast_device <token> <answer> *dev; 
struct <token> *port; <answer> mcast_port 
<token> i; <answer> int 
int count = <token> <answer> 0; 
dev = <token> port, device->phys_port_cnt), <answer> kmalloc(struct_size(dev, 
<token> (!dev) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = rdma_start_port(device); <answer> dev->start_port 
<token> = rdma_end_port(device); <answer> dev->end_port 
for (i = 0; <token> <= dev->end_port - dev->start_port; i++) { <answer> i 
if <token> dev->start_port + i)) <answer> (!rdma_cap_ib_mcast(device, 
port <token> &dev->port[i]; <answer> = 
port->dev <token> dev; <answer> = 
<token> = dev->start_port + i; <answer> port->port_num 
<token> = RB_ROOT; <answer> port->table 
refcount_set(&port->refcount, <token> <answer> 1); 
if <token> { <answer> (!count) 
<token> -EOPNOTSUPP; <answer> return 
<token> = device; <answer> dev->device 
<token> &mcast_client, dev); <answer> ib_set_client_data(device, 
<token> device, mcast_event_handler); <answer> INIT_IB_EVENT_HANDLER(&dev->event_handler, 
<token> 0; <answer> return 
static void mcast_remove_one(struct ib_device <token> void *client_data) <answer> *device, 
struct mcast_device *dev <token> client_data; <answer> = 
struct <token> *port; <answer> mcast_port 
int <token> <answer> i; 
for (i = 0; <token> <= dev->end_port - dev->start_port; i++) { <answer> i 
if <token> dev->start_port + i)) { <answer> (rdma_cap_ib_mcast(device, 
port <token> &dev->port[i]; <answer> = 
<token> mcast_init(void) <answer> int 
int <token> <answer> ret; 
<token> = alloc_ordered_workqueue("ib_mcast", WQ_MEM_RECLAIM); <answer> mcast_wq 
<token> (!mcast_wq) <answer> if 
return <token> <answer> -ENOMEM; 
<token> = ib_register_client(&mcast_client); <answer> ret 
if <token> <answer> (ret) 
goto <token> <answer> err; 
<token> 0; <answer> return 
<token> ret; <answer> return 
<token> mcast_cleanup(void) <answer> void 
#include <token> <answer> <linux/bitfield.h> 
<token> <linux/bits.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/device.h> 
<token> <linux/gpio/consumer.h> <answer> #include 
<token> <linux/iio/iio.h> <answer> #include 
<token> <linux/mod_devicetable.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/regulator/consumer.h> 
#include <token> <answer> <linux/spi/spi.h> 
#include <token> <answer> <asm/unaligned.h> 
<token> AD7293_R1B BIT(16) <answer> #define 
<token> AD7293_R2B BIT(17) <answer> #define 
#define AD7293_PAGE_ADDR_MSK GENMASK(15, <token> <answer> 8) 
#define AD7293_PAGE(x) <token> x) <answer> FIELD_PREP(AD7293_PAGE_ADDR_MSK, 
<token> <linux/module.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
<token> <linux/err.h> <answer> #include 
#include <token> <answer> <linux/ctype.h> 
<token> <linux/kthread.h> <answer> #include 
<token> <linux/string.h> <answer> #include 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/atomic.h> 
#include <token> <answer> <linux/inet.h> 
<token> <rdma/ib_cache.h> <answer> #include 
<token> <scsi/scsi_proto.h> <answer> #include 
<token> <scsi/scsi_tcq.h> <answer> #include 
<token> <target/target_core_base.h> <answer> #include 
<token> <target/target_core_fabric.h> <answer> #include 
<token> "ib_srpt.h" <answer> #include 
static <token> srpt_service_guid; <answer> u64 
static bool srpt_set_ch_state(struct srpt_rdma_ch *ch, enum <token> new) <answer> rdma_ch_state 
unsigned long <token> <answer> flags; 
enum rdma_ch_state <token> <answer> prev; 
<token> changed = false; <answer> bool 
<token> flags); <answer> spin_lock_irqsave(&ch->spinlock, 
prev <token> ch->state; <answer> = 
if <token> > prev) { <answer> (new 
<token> = new; <answer> ch->state 
changed <token> true; <answer> = 
spin_unlock_irqrestore(&ch->spinlock, <token> <answer> flags); 
return <token> <answer> changed; 
static void srpt_event_handler(struct ib_event_handler <token> <answer> *handler, 
struct ib_event <token> <answer> *event) 
struct srpt_device <token> = <answer> *sdev 
container_of(handler, struct srpt_device, <token> <answer> event_handler); 
<token> srpt_port *sport; <answer> struct 
<token> port_num; <answer> u8 
pr_debug("ASYNC event= %d <token> device= %s\n", event->event, <answer> on 
switch (event->event) <token> <answer> { 
<token> IB_EVENT_PORT_ERR: <answer> case 
port_num = event->element.port_num - <token> <answer> 1; 
if (port_num < <token> { <answer> sdev->device->phys_port_cnt) 
sport <token> &sdev->port[port_num]; <answer> = 
sport->lid = <token> <answer> 0; 
<token> = 0; <answer> sport->sm_lid 
} <token> { <answer> else 
WARN(true, "event %d: port_num %d <token> of range 1..%d\n", <answer> out 
event->event, port_num + <token> <answer> 1, 
<token> IB_EVENT_PORT_ACTIVE: <answer> case 
case <token> <answer> IB_EVENT_LID_CHANGE: 
<token> IB_EVENT_PKEY_CHANGE: <answer> case 
case <token> <answer> IB_EVENT_SM_CHANGE: 
case <token> <answer> IB_EVENT_CLIENT_REREGISTER: 
case <token> <answer> IB_EVENT_GID_CHANGE: 
static void srpt_srq_event(struct <token> *event, void *ctx) <answer> ib_event 
<token> event %d\n", event->event); <answer> pr_debug("SRQ 
static const <token> *get_ch_state_name(enum rdma_ch_state s) <answer> char 
switch (s) <token> <answer> { 
<token> CH_CONNECTING: <answer> case 
<token> "connecting"; <answer> return 
case <token> <answer> CH_LIVE: 
return <token> <answer> "live"; 
case <token> <answer> CH_DISCONNECTING: 
<token> "disconnecting"; <answer> return 
<token> CH_DRAINING: <answer> case 
return <token> <answer> "draining"; 
case <token> <answer> CH_DISCONNECTED: 
return <token> <answer> "disconnected"; 
return <token> <answer> "???"; 
static void <token> ib_event *event, void *ptr) <answer> srpt_qp_event(struct 
struct srpt_rdma_ch *ch <token> ptr; <answer> = 
pr_debug("QP <token> %d on ch=%p sess_name=%s-%d state=%s\n", <answer> event 
event->event, <token> ch->sess_name, ch->qp->qp_num, <answer> ch, 
switch (event->event) <token> <answer> { 
case <token> <answer> IB_EVENT_COMM_EST: 
if <token> <answer> (ch->using_rdma_cm) 
rdma_notify(ch->rdma_cm.cm_id, <token> <answer> event->event); 
ib_cm_notify(ch->ib_cm.cm_id, <token> <answer> event->event); 
case <token> <answer> IB_EVENT_QP_LAST_WQE_REACHED: 
pr_debug("%s-%d, <token> %s: received Last WQE event.\n", <answer> state 
ch->sess_name, <token> <answer> ch->qp->qp_num, 
pr_err("received <token> IB QP event %d\n", event->event); <answer> unrecognized 
static <token> srpt_set_ioc(u8 *c_list, u32 slot, u8 value) <answer> void 
<token> id; <answer> u16 
u8 <token> <answer> tmp; 
id = (slot - <token> / 2; <answer> 1) 
if (slot <token> 0x1) { <answer> & 
<token> = c_list[id] & 0xf; <answer> tmp 
c_list[id] = (value <token> 4) | tmp; <answer> << 
} <token> { <answer> else 
tmp = c_list[id] & <token> <answer> 0xf0; 
c_list[id] = (value & <token> | tmp; <answer> 0xf) 
static void <token> ib_dm_mad *mad) <answer> srpt_get_class_port_info(struct 
struct <token> *cif; <answer> ib_class_port_info 
cif = (struct ib_class_port_info <token> <answer> *)mad->data; 
memset(cif, 0, <token> <answer> sizeof(*cif)); 
<token> = 1; <answer> cif->base_version 
<token> = 1; <answer> cif->class_version 
ib_set_cpi_resp_time(cif, <token> <answer> 20); 
<token> = 0; <answer> mad->mad_hdr.status 
<token> void srpt_get_iou(struct ib_dm_mad *mad) <answer> static 
struct <token> *ioui; <answer> ib_dm_iou_info 
u8 <token> <answer> slot; 
int <token> <answer> i; 
ioui = (struct <token> *)mad->data; <answer> ib_dm_iou_info 
ioui->change_id <token> cpu_to_be16(1); <answer> = 
<token> = 16; <answer> ioui->max_controllers 
static void <token> srpt_port *sport, u32 slot, <answer> srpt_get_ioc(struct 
struct ib_dm_mad <token> <answer> *mad) 
struct <token> *sdev = sport->sdev; <answer> srpt_device 
struct ib_dm_ioc_profile <token> <answer> *iocp; 
<token> send_queue_depth; <answer> int 
iocp = <token> ib_dm_ioc_profile *)mad->data; <answer> (struct 
if (!slot <token> slot > 16) { <answer> || 
= <token> <answer> cpu_to_be16(DM_MAD_STATUS_INVALID_FIELD); 
if (slot > <token> { <answer> 2) 
<token> cpu_to_be16(DM_MAD_STATUS_NO_IOC); <answer> = 
<token> (sdev->use_srq) <answer> if 
send_queue_depth <token> sdev->srq_size; <answer> = 
<token> = min(MAX_SRPT_RQ_SIZE, <answer> send_queue_depth 
<token> 0, sizeof(*iocp)); <answer> memset(iocp, 
strcpy(iocp->id_string, <token> <answer> SRPT_ID_STRING); 
iocp->guid <token> cpu_to_be64(srpt_service_guid); <answer> = 
iocp->vendor_id = <token> <answer> cpu_to_be32(sdev->device->attrs.vendor_id); 
iocp->device_id <token> cpu_to_be32(sdev->device->attrs.vendor_part_id); <answer> = 
<token> = cpu_to_be16(sdev->device->attrs.hw_ver); <answer> iocp->device_version 
iocp->subsys_vendor_id = <token> <answer> cpu_to_be32(sdev->device->attrs.vendor_id); 
<token> = 0x0; <answer> iocp->subsys_device_id 
<token> = cpu_to_be16(SRP_REV16A_IB_IO_CLASS); <answer> iocp->io_class 
iocp->io_subclass = <token> <answer> cpu_to_be16(SRP_IO_SUBCLASS); 
<token> = cpu_to_be16(SRP_PROTOCOL); <answer> iocp->protocol 
iocp->protocol_version <token> cpu_to_be16(SRP_PROTOCOL_VERSION); <answer> = 
iocp->send_queue_depth <token> cpu_to_be16(send_queue_depth); <answer> = 
<token> = 4; <answer> iocp->rdma_read_depth 
<token> = cpu_to_be32(srp_max_req_size); <answer> iocp->send_size 
<token> = cpu_to_be32(min(sport->port_attrib.srp_max_rdma_size, <answer> iocp->rdma_size 
1U << <token> <answer> 24)); 
iocp->num_svc_entries = <token> <answer> 1; 
iocp->op_cap_mask = SRP_SEND_TO_IOC | <token> | <answer> SRP_SEND_FROM_IOC 
SRP_RDMA_READ_FROM_IOC <token> SRP_RDMA_WRITE_FROM_IOC; <answer> | 
mad->mad_hdr.status <token> 0; <answer> = 
static void srpt_get_svc_entries(u64 <token> <answer> ioc_guid, 
u16 slot, u8 hi, u8 lo, struct ib_dm_mad <token> <answer> *mad) 
<token> ib_dm_svc_entries *svc_entries; <answer> struct 
if (!slot <token> slot > 16) { <answer> || 
<token> cpu_to_be16(DM_MAD_STATUS_INVALID_FIELD); <answer> = 
if (slot <token> 2 || lo > hi || hi > 1) { <answer> > 
= <token> <answer> cpu_to_be16(DM_MAD_STATUS_NO_IOC); 
svc_entries <token> (struct ib_dm_svc_entries *)mad->data; <answer> = 
memset(svc_entries, <token> sizeof(*svc_entries)); <answer> 0, 
<token> = cpu_to_be64(ioc_guid); <answer> svc_entries->service_entries[0].id 
mad->mad_hdr.status <token> 0; <answer> = 
static <token> srpt_mgmt_method_get(struct srpt_port *sp, struct ib_mad *rq_mad, <answer> void 
struct ib_dm_mad <token> <answer> *rsp_mad) 
u16 <token> <answer> attr_id; 
u32 <token> <answer> slot; 
<token> hi, lo; <answer> u8 
attr_id <token> be16_to_cpu(rq_mad->mad_hdr.attr_id); <answer> = 
<token> (attr_id) { <answer> switch 
case <token> <answer> DM_ATTR_CLASS_PORT_INFO: 
case <token> <answer> DM_ATTR_IOU_INFO: 
<token> DM_ATTR_IOC_PROFILE: <answer> case 
slot = <token> <answer> be32_to_cpu(rq_mad->mad_hdr.attr_mod); 
<token> slot, rsp_mad); <answer> srpt_get_ioc(sp, 
case <token> <answer> DM_ATTR_SVC_ENTRIES: 
slot <token> be32_to_cpu(rq_mad->mad_hdr.attr_mod); <answer> = 
hi = (u8) <token> >> 8) & 0xff); <answer> ((slot 
lo <token> (u8) (slot & 0xff); <answer> = 
slot = (u16) ((slot >> 16) <token> 0xffff); <answer> & 
slot, hi, lo, <token> <answer> rsp_mad); 
rsp_mad->mad_hdr.status <token> <answer> = 
static void <token> ib_mad_agent *mad_agent, <answer> srpt_mad_send_handler(struct 
<token> ib_mad_send_wc *mad_wc) <answer> struct 
<token> RDMA_DESTROY_AH_SLEEPABLE); <answer> rdma_destroy_ah(mad_wc->send_buf->ah, 
static void srpt_mad_recv_handler(struct ib_mad_agent <token> <answer> *mad_agent, 
struct <token> *send_buf, <answer> ib_mad_send_buf 
struct ib_mad_recv_wc <token> <answer> *mad_wc) 
<token> srpt_port *sport = (struct srpt_port *)mad_agent->context; <answer> struct 
struct ib_ah <token> <answer> *ah; 
struct ib_mad_send_buf <token> <answer> *rsp; 
struct <token> *dm_mad; <answer> ib_dm_mad 
if (!mad_wc <token> !mad_wc->recv_buf.mad) <answer> || 
<token> = ib_create_ah_from_wc(mad_agent->qp->pd, mad_wc->wc, <answer> ah 
mad_wc->recv_buf.grh, <token> <answer> mad_agent->port_num); 
if <token> <answer> (IS_ERR(ah)) 
<token> err; <answer> goto 
BUILD_BUG_ON(offsetof(struct ib_dm_mad, data) != <token> <answer> IB_MGMT_DEVICE_HDR); 
rsp = <token> mad_wc->wc->src_qp, <answer> ib_create_send_mad(mad_agent, 
mad_wc->wc->pkey_index, <token> <answer> 0, 
IB_MGMT_DEVICE_HDR, <token> <answer> IB_MGMT_DEVICE_DATA, 
if <token> <answer> (IS_ERR(rsp)) 
<token> err_rsp; <answer> goto 
<token> = ah; <answer> rsp->ah 
dm_mad = <token> <answer> rsp->mad; 
memcpy(dm_mad, mad_wc->recv_buf.mad, <token> <answer> sizeof(*dm_mad)); 
dm_mad->mad_hdr.method <token> IB_MGMT_METHOD_GET_RESP; <answer> = 
dm_mad->mad_hdr.status <token> 0; <answer> = 
switch <token> { <answer> (mad_wc->recv_buf.mad->mad_hdr.method) 
<token> IB_MGMT_METHOD_GET: <answer> case 
srpt_mgmt_method_get(sport, mad_wc->recv_buf.mad, <token> <answer> dm_mad); 
<token> IB_MGMT_METHOD_SET: <answer> case 
dm_mad->mad_hdr.status <token> <answer> = 
<token> = <answer> dm_mad->mad_hdr.status 
<token> (!ib_post_send_mad(rsp, NULL)) { <answer> if 
static <token> srpt_refresh_port(struct srpt_port *sport) <answer> int 
<token> ib_mad_agent *mad_agent; <answer> struct 
struct <token> reg_req; <answer> ib_mad_reg_req 
struct <token> port_modify; <answer> ib_port_modify 
struct <token> port_attr; <answer> ib_port_attr 
<token> ret; <answer> int 
ret = <token> sport->port, &port_attr); <answer> ib_query_port(sport->sdev->device, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
sport->sm_lid = <token> <answer> port_attr.sm_lid; 
sport->lid <token> port_attr.lid; <answer> = 
ret = <token> sport->port, 0, &sport->gid); <answer> rdma_query_gid(sport->sdev->device, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
srpt_format_guid(sport->guid_name, <token> <answer> ARRAY_SIZE(sport->guid_name), 
snprintf(sport->gid_name, <token> <answer> ARRAY_SIZE(sport->gid_name), 
<token> (rdma_protocol_iwarp(sport->sdev->device, sport->port)) <answer> if 
<token> 0; <answer> return 
memset(&port_modify, <token> sizeof(port_modify)); <answer> 0, 
<token> = IB_PORT_DEVICE_MGMT_SUP; <answer> port_modify.set_port_cap_mask 
port_modify.clr_port_cap_mask = <token> <answer> 0; 
ret = ib_modify_port(sport->sdev->device, sport->port, 0, <token> <answer> &port_modify); 
if <token> { <answer> (ret) 
pr_warn("%s-%d: <token> device management failed (%d). Note: this is expected if SR-IOV is enabled.\n", <answer> enabling 
dev_name(&sport->sdev->device->dev), <token> ret); <answer> sport->port, 
<token> 0; <answer> return 
if (!sport->mad_agent) <token> <answer> { 
<token> 0, sizeof(reg_req)); <answer> memset(&reg_req, 
reg_req.mgmt_class = <token> <answer> IB_MGMT_CLASS_DEVICE_MGMT; 
reg_req.mgmt_class_version = <token> <answer> IB_MGMT_BASE_VERSION; 
set_bit(IB_MGMT_METHOD_GET, <token> <answer> reg_req.method_mask); 
set_bit(IB_MGMT_METHOD_SET, <token> <answer> reg_req.method_mask); 
mad_agent <token> ib_register_mad_agent(sport->sdev->device, <answer> = 
<token> 0, <answer> &reg_req, 
<token> 0); <answer> sport, 
if (IS_ERR(mad_agent)) <token> <answer> { 
pr_err("%s-%d: MAD agent registration failed (%ld). Note: this is expected if SR-IOV is <token> <answer> enabled.\n", 
<token> sport->port, <answer> dev_name(&sport->sdev->device->dev), 
<token> = NULL; <answer> sport->mad_agent 
memset(&port_modify, <token> sizeof(port_modify)); <answer> 0, 
port_modify.clr_port_cap_mask = <token> <answer> IB_PORT_DEVICE_MGMT_SUP; 
ib_modify_port(sport->sdev->device, sport->port, <token> <answer> 0, 
<token> 0; <answer> return 
sport->mad_agent <token> mad_agent; <answer> = 
return <token> <answer> 0; 
static void <token> srpt_device *sdev, int port_cnt) <answer> srpt_unregister_mad_agent(struct 
struct <token> port_modify = { <answer> ib_port_modify 
<token> = IB_PORT_DEVICE_MGMT_SUP, <answer> .clr_port_cap_mask 
struct srpt_port <token> <answer> *sport; 
<token> i; <answer> int 
for (i = 1; i <token> port_cnt; i++) { <answer> <= 
sport = <token> - 1]; <answer> &sdev->port[i 
<token> != i); <answer> WARN_ON(sport->port 
if (sport->mad_agent) <token> <answer> { 
ib_modify_port(sdev->device, i, 0, <token> <answer> &port_modify); 
<token> = NULL; <answer> sport->mad_agent 
static struct <token> *srpt_alloc_ioctx(struct srpt_device *sdev, <answer> srpt_ioctx 
<token> ioctx_size, <answer> int 
struct kmem_cache <token> <answer> *buf_cache, 
<token> dma_data_direction dir) <answer> enum 
<token> srpt_ioctx *ioctx; <answer> struct 
ioctx <token> kzalloc(ioctx_size, GFP_KERNEL); <answer> = 
if <token> <answer> (!ioctx) 
<token> err; <answer> goto 
<token> = kmem_cache_alloc(buf_cache, GFP_KERNEL); <answer> ioctx->buf 
<token> (!ioctx->buf) <answer> if 
<token> err_free_ioctx; <answer> goto 
ioctx->dma = ib_dma_map_single(sdev->device, <token> <answer> ioctx->buf, 
kmem_cache_size(buf_cache), <token> <answer> dir); 
if <token> ioctx->dma)) <answer> (ib_dma_mapping_error(sdev->device, 
goto <token> <answer> err_free_buf; 
return <token> <answer> ioctx; 
<token> ioctx->buf); <answer> kmem_cache_free(buf_cache, 
<token> NULL; <answer> return 
<token> void srpt_free_ioctx(struct srpt_device *sdev, struct srpt_ioctx *ioctx, <answer> static 
struct <token> *buf_cache, <answer> kmem_cache 
enum <token> dir) <answer> dma_data_direction 
<token> (!ioctx) <answer> if 
<token> ioctx->dma, <answer> ib_dma_unmap_single(sdev->device, 
kmem_cache_size(buf_cache), <token> <answer> dir); 
kmem_cache_free(buf_cache, <token> <answer> ioctx->buf); 
static <token> srpt_ioctx **srpt_alloc_ioctx_ring(struct srpt_device *sdev, <answer> struct 
int ring_size, <token> ioctx_size, <answer> int 
struct kmem_cache <token> <answer> *buf_cache, 
<token> alignment_offset, <answer> int 
enum <token> dir) <answer> dma_data_direction 
struct <token> **ring; <answer> srpt_ioctx 
<token> i; <answer> int 
WARN_ON(ioctx_size != <token> srpt_recv_ioctx) && <answer> sizeof(struct 
<token> != sizeof(struct srpt_send_ioctx)); <answer> ioctx_size 
<token> = kvmalloc_array(ring_size, sizeof(ring[0]), GFP_KERNEL); <answer> ring 
<token> (!ring) <answer> if 
goto <token> <answer> out; 
for <token> = 0; i < ring_size; ++i) { <answer> (i 
<token> = srpt_alloc_ioctx(sdev, ioctx_size, buf_cache, dir); <answer> ring[i] 
<token> (!ring[i]) <answer> if 
<token> err; <answer> goto 
<token> = i; <answer> ring[i]->index 
ring[i]->offset = <token> <answer> alignment_offset; 
goto <token> <answer> out; 
while (--i >= <token> <answer> 0) 
srpt_free_ioctx(sdev, <token> buf_cache, dir); <answer> ring[i], 
ring <token> NULL; <answer> = 
<token> ring; <answer> return 
static void srpt_free_ioctx_ring(struct srpt_ioctx <token> <answer> **ioctx_ring, 
struct srpt_device <token> int ring_size, <answer> *sdev, 
struct <token> *buf_cache, <answer> kmem_cache 
enum dma_data_direction <token> <answer> dir) 
<token> i; <answer> int 
<token> (!ioctx_ring) <answer> if 
for (i = 0; i < ring_size; <token> <answer> ++i) 
srpt_free_ioctx(sdev, ioctx_ring[i], <token> dir); <answer> buf_cache, 
static enum srpt_command_state srpt_set_cmd_state(struct <token> *ioctx, <answer> srpt_send_ioctx 
enum <token> new) <answer> srpt_command_state 
enum <token> previous; <answer> srpt_command_state 
previous = <token> <answer> ioctx->state; 
if (previous <token> SRPT_STATE_DONE) <answer> != 
ioctx->state <token> new; <answer> = 
return <token> <answer> previous; 
static bool srpt_test_and_set_cmd_state(struct <token> *ioctx, <answer> srpt_send_ioctx 
enum <token> old, <answer> srpt_command_state 
<token> srpt_command_state new) <answer> enum 
<token> srpt_command_state previous; <answer> enum 
<token> == SRPT_STATE_DONE); <answer> WARN_ON(old 
<token> == SRPT_STATE_NEW); <answer> WARN_ON(new 
previous <token> ioctx->state; <answer> = 
<token> (previous == old) <answer> if 
ioctx->state <token> new; <answer> = 
<token> previous == old; <answer> return 
static int srpt_post_recv(struct srpt_device *sdev, struct srpt_rdma_ch <token> <answer> *ch, 
<token> srpt_recv_ioctx *ioctx) <answer> struct 
struct ib_sge <token> <answer> list; 
<token> ib_recv_wr wr; <answer> struct 
<token> = ioctx->ioctx.dma + ioctx->ioctx.offset; <answer> list.addr 
list.length <token> srp_max_req_size; <answer> = 
list.lkey <token> sdev->lkey; <answer> = 
ioctx->ioctx.cqe.done = <token> <answer> srpt_recv_done; 
wr.wr_cqe = <token> <answer> &ioctx->ioctx.cqe; 
<token> = NULL; <answer> wr.next 
wr.sg_list = <token> <answer> &list; 
wr.num_sge <token> 1; <answer> = 
<token> (sdev->use_srq) <answer> if 
return ib_post_srq_recv(sdev->srq, &wr, <token> <answer> NULL); 
return ib_post_recv(ch->qp, &wr, <token> <answer> NULL); 
static int srpt_zerolength_write(struct <token> *ch) <answer> srpt_rdma_ch 
struct ib_rdma_wr <token> = { <answer> wr 
<token> = { <answer> .wr 
.next <token> NULL, <answer> = 
{ .wr_cqe <token> &ch->zw_cqe, }, <answer> = 
<token> = IB_WR_RDMA_WRITE, <answer> .opcode 
.send_flags <token> IB_SEND_SIGNALED, <answer> = 
pr_debug("%s-%d: <token> zerolength write\n", ch->sess_name, <answer> queued 
return ib_post_send(ch->qp, <token> NULL); <answer> &wr.wr, 
static void srpt_zerolength_write_done(struct ib_cq *cq, struct <token> *wc) <answer> ib_wc 
struct <token> *ch = wc->qp->qp_context; <answer> srpt_rdma_ch 
pr_debug("%s-%d wc->status <token> ch->sess_name, ch->qp->qp_num, <answer> %d\n", 
if (wc->status == IB_WC_SUCCESS) <token> <answer> { 
} <token> { <answer> else 
if (srpt_set_ch_state(ch, <token> <answer> CH_DISCONNECTED)) 
pr_debug("%s-%d: <token> disconnected.\n", <answer> already 
ch->sess_name, <token> <answer> ch->qp->qp_num); 
static <token> srpt_alloc_rw_ctxs(struct srpt_send_ioctx *ioctx, <answer> int 
struct srp_direct_buf *db, int nbufs, <token> scatterlist **sg, <answer> struct 
unsigned <token> <answer> *sg_cnt) 
enum <token> dir = target_reverse_dma_direction(&ioctx->cmd); <answer> dma_data_direction 
struct srpt_rdma_ch <token> = ioctx->ch; <answer> *ch 
struct scatterlist <token> = NULL; <answer> *prev 
unsigned <token> <answer> prev_nents; 
<token> ret, i; <answer> int 
if (nbufs == 1) <token> <answer> { 
ioctx->rw_ctxs = <token> <answer> &ioctx->s_rw_ctx; 
} <token> { <answer> else 
ioctx->rw_ctxs = kmalloc_array(nbufs, <token> <answer> sizeof(*ioctx->rw_ctxs), 
<token> (!ioctx->rw_ctxs) <answer> if 
return <token> <answer> -ENOMEM; 
for (i = ioctx->n_rw_ctx; i < <token> i++, db++) { <answer> nbufs; 
struct srpt_rw_ctx <token> = &ioctx->rw_ctxs[i]; <answer> *ctx 
u64 remote_addr <token> be64_to_cpu(db->va); <answer> = 
u32 size <token> be32_to_cpu(db->len); <answer> = 
u32 rkey <token> be32_to_cpu(db->key); <answer> = 
ret = target_alloc_sgl(&ctx->sg, <token> size, false, <answer> &ctx->nents, 
i <token> nbufs - 1); <answer> < 
if <token> <answer> (ret) 
<token> unwind; <answer> goto 
ret <token> rdma_rw_ctx_init(&ctx->rw, ch->qp, ch->sport->port, <answer> = 
ctx->sg, ctx->nents, 0, <token> rkey, dir); <answer> remote_addr, 
if (ret <token> 0) { <answer> < 
<token> ctx->nents); <answer> target_free_sgl(ctx->sg, 
goto <token> <answer> unwind; 
<token> += ret; <answer> ioctx->n_rdma 
<token> (prev) { <answer> if 
sg_unmark_end(&prev[prev_nents - <token> <answer> 1]); 
sg_chain(prev, prev_nents <token> 1, ctx->sg); <answer> + 
<token> else { <answer> } 
*sg <token> ctx->sg; <answer> = 
prev = <token> <answer> ctx->sg; 
<token> = ctx->nents; <answer> prev_nents 
<token> += ctx->nents; <answer> *sg_cnt 
return <token> <answer> 0; 
while (--i >= 0) <token> <answer> { 
struct srpt_rw_ctx *ctx <token> &ioctx->rw_ctxs[i]; <answer> = 
rdma_rw_ctx_destroy(&ctx->rw, <token> ch->sport->port, <answer> ch->qp, 
<token> ctx->nents, dir); <answer> ctx->sg, 
<token> ctx->nents); <answer> target_free_sgl(ctx->sg, 
if (ioctx->rw_ctxs <token> &ioctx->s_rw_ctx) <answer> != 
<token> ret; <answer> return 
static <token> srpt_free_rw_ctxs(struct srpt_rdma_ch *ch, <answer> void 
struct srpt_send_ioctx <token> <answer> *ioctx) 
enum dma_data_direction dir <token> target_reverse_dma_direction(&ioctx->cmd); <answer> = 
<token> i; <answer> int 
for (i = 0; i <token> ioctx->n_rw_ctx; i++) { <answer> < 
struct srpt_rw_ctx *ctx = <token> <answer> &ioctx->rw_ctxs[i]; 
rdma_rw_ctx_destroy(&ctx->rw, ch->qp, <token> <answer> ch->sport->port, 
ctx->sg, <token> dir); <answer> ctx->nents, 
<token> ctx->nents); <answer> target_free_sgl(ctx->sg, 
if (ioctx->rw_ctxs != <token> <answer> &ioctx->s_rw_ctx) 
static inline void <token> srp_cmd *srp_cmd) <answer> *srpt_get_desc_buf(struct 
<token> (s8)0) && <answer> BUILD_BUG_ON(!__same_type(srp_cmd->add_data[0], 
!__same_type(srp_cmd->add_data[0], <token> <answer> (u8)0)); 
return srp_cmd->add_data + (srp_cmd->add_cdb_len <token> ~3); <answer> & 
static <token> srpt_get_desc_tbl(struct srpt_recv_ioctx *recv_ioctx, <answer> int 
<token> srpt_send_ioctx *ioctx, <answer> struct 
struct srp_cmd *srp_cmd, enum <token> *dir, <answer> dma_data_direction 
struct scatterlist **sg, unsigned int *sg_cnt, <token> *data_len, <answer> u64 
u16 <token> <answer> imm_data_offset) 
if (srp_cmd->buf_fmt <token> 0xf) <answer> & 
<token> ((void *)(imm_buf + 1) > (void *)data) { <answer> if 
pr_err("Received invalid <token> request\n"); <answer> write 
<token> -EINVAL; <answer> return 
*data_len <token> len; <answer> = 
<token> = recv_ioctx; <answer> ioctx->recv_ioctx 
if ((uintptr_t)data & 511) <token> <answer> { 
pr_warn_once("Internal error - the <token> buffers are not aligned properly.\n"); <answer> receive 
<token> -EINVAL; <answer> return 
sg_init_one(&ioctx->imm_sg, data, <token> <answer> len); 
*sg <token> &ioctx->imm_sg; <answer> = 
*sg_cnt = <token> <answer> 1; 
return <token> <answer> 0; 
<token> else { <answer> } 
*data_len = <token> <answer> 0; 
<token> 0; <answer> return 
static int srpt_init_ch_qp(struct <token> *ch, struct ib_qp *qp) <answer> srpt_rdma_ch 
struct <token> *attr; <answer> ib_qp_attr 
int <token> <answer> ret; 
attr <token> kzalloc(sizeof(*attr), GFP_KERNEL); <answer> = 
<token> (!attr) <answer> if 
<token> -ENOMEM; <answer> return 
<token> = IB_QPS_INIT; <answer> attr->qp_state 
<token> = IB_ACCESS_LOCAL_WRITE; <answer> attr->qp_access_flags 
<token> = ch->sport->port; <answer> attr->port_num 
ret = <token> ch->sport->port, <answer> ib_find_cached_pkey(ch->sport->sdev->device, 
ch->pkey, <token> <answer> &attr->pkey_index); 
if (ret < <token> <answer> 0) 
<token> pkey %#x failed (%d) - using index 0\n", <answer> pr_err("Translating 
ch->pkey, <token> <answer> ret); 
ret = ib_modify_qp(qp, <token> <answer> attr, 
IB_QP_STATE <token> IB_QP_ACCESS_FLAGS | IB_QP_PORT | <answer> | 
return <token> <answer> ret; 
static int srpt_ch_qp_rtr(struct srpt_rdma_ch *ch, struct <token> *qp) <answer> ib_qp 
struct <token> qp_attr; <answer> ib_qp_attr 
int <token> <answer> attr_mask; 
<token> ret; <answer> int 
qp_attr.qp_state = <token> <answer> IB_QPS_RTR; 
ret = <token> &qp_attr, &attr_mask); <answer> ib_cm_init_qp_attr(ch->ib_cm.cm_id, 
<token> (ret) <answer> if 
goto <token> <answer> out; 
qp_attr.max_dest_rd_atomic <token> 4; <answer> = 
ret <token> ib_modify_qp(qp, &qp_attr, attr_mask); <answer> = 
<token> ret; <answer> return 
static int srpt_ch_qp_rts(struct srpt_rdma_ch *ch, <token> ib_qp *qp) <answer> struct 
<token> ib_qp_attr qp_attr; <answer> struct 
int <token> <answer> attr_mask; 
<token> ret; <answer> int 
<token> = IB_QPS_RTS; <answer> qp_attr.qp_state 
ret = <token> &qp_attr, &attr_mask); <answer> ib_cm_init_qp_attr(ch->ib_cm.cm_id, 
<token> (ret) <answer> if 
goto <token> <answer> out; 
qp_attr.max_rd_atomic = <token> <answer> 4; 
ret <token> ib_modify_qp(qp, &qp_attr, attr_mask); <answer> = 
<token> ret; <answer> return 
static int srpt_ch_qp_err(struct srpt_rdma_ch <token> <answer> *ch) 
struct ib_qp_attr <token> <answer> qp_attr; 
qp_attr.qp_state = <token> <answer> IB_QPS_ERR; 
return <token> &qp_attr, IB_QP_STATE); <answer> ib_modify_qp(ch->qp, 
static struct srpt_send_ioctx *srpt_get_send_ioctx(struct srpt_rdma_ch <token> <answer> *ch) 
struct srpt_send_ioctx <token> <answer> *ioctx; 
int <token> cpu; <answer> tag, 
tag = <token> &cpu); <answer> sbitmap_queue_get(&ch->sess->sess_tag_pool, 
<token> (tag < 0) <answer> if 
return <token> <answer> NULL; 
ioctx <token> ch->ioctx_ring[tag]; <answer> = 
BUG_ON(ioctx->ch <token> ch); <answer> != 
ioctx->state <token> SRPT_STATE_NEW; <answer> = 
ioctx->n_rdma = <token> <answer> 0; 
ioctx->n_rw_ctx <token> 0; <answer> = 
ioctx->queue_status_only = <token> <answer> false; 
memset(&ioctx->cmd, <token> sizeof(ioctx->cmd)); <answer> 0, 
memset(&ioctx->sense_data, 0, <token> <answer> sizeof(ioctx->sense_data)); 
<token> = tag; <answer> ioctx->cmd.map_tag 
ioctx->cmd.map_cpu <token> cpu; <answer> = 
<token> ioctx; <answer> return 
static int srpt_abort_cmd(struct srpt_send_ioctx <token> <answer> *ioctx) 
enum srpt_command_state <token> <answer> state; 
state = <token> <answer> ioctx->state; 
switch <token> { <answer> (state) 
<token> SRPT_STATE_NEED_DATA: <answer> case 
ioctx->state = <token> <answer> SRPT_STATE_DATA_IN; 
<token> SRPT_STATE_CMD_RSP_SENT: <answer> case 
case <token> <answer> SRPT_STATE_MGMT_RSP_SENT: 
ioctx->state = <token> <answer> SRPT_STATE_DONE; 
WARN_ONCE(true, "%s: unexpected I/O context <token> %d\n", <answer> state 
__func__, <token> <answer> state); 
pr_debug("Aborting cmd with state <token> -> %d and tag %lld\n", state, <answer> %d 
ioctx->state, <token> <answer> ioctx->cmd.tag); 
switch <token> { <answer> (state) 
case <token> <answer> SRPT_STATE_NEW: 
case <token> <answer> SRPT_STATE_DATA_IN: 
case <token> <answer> SRPT_STATE_MGMT: 
<token> SRPT_STATE_DONE: <answer> case 
case <token> <answer> SRPT_STATE_NEED_DATA: 
pr_debug("tag <token> RDMA read error\n", ioctx->cmd.tag); <answer> %#llx: 
<token> SRPT_STATE_CMD_RSP_SENT: <answer> case 
transport_generic_free_cmd(&ioctx->cmd, <token> <answer> 0); 
case <token> <answer> SRPT_STATE_MGMT_RSP_SENT: 
transport_generic_free_cmd(&ioctx->cmd, <token> <answer> 0); 
WARN(1, "Unexpected command <token> (%d)", state); <answer> state 
<token> state; <answer> return 
static <token> srpt_rdma_read_done(struct ib_cq *cq, struct ib_wc *wc) <answer> void 
struct srpt_rdma_ch *ch <token> wc->qp->qp_context; <answer> = 
struct srpt_send_ioctx <token> = <answer> *ioctx 
<token> struct srpt_send_ioctx, rdma_cqe); <answer> container_of(wc->wr_cqe, 
<token> <= 0); <answer> WARN_ON(ioctx->n_rdma 
atomic_add(ioctx->n_rdma, <token> <answer> &ch->sq_wr_avail); 
<token> = 0; <answer> ioctx->n_rdma 
if (unlikely(wc->status != <token> { <answer> IB_WC_SUCCESS)) 
pr_info("RDMA_READ for ioctx 0x%p failed with status <token> <answer> %d\n", 
ioctx, <token> <answer> wc->status); 
if (srpt_test_and_set_cmd_state(ioctx, <token> <answer> SRPT_STATE_NEED_DATA, 
pr_err("%s[%d]: wrong <token> = %d\n", __func__, <answer> state 
__LINE__, <token> <answer> ioctx->state); 
<token> int srpt_build_cmd_rsp(struct srpt_rdma_ch *ch, <answer> static 
<token> srpt_send_ioctx *ioctx, u64 tag, <answer> struct 
<token> status) <answer> int 
<token> se_cmd *cmd = &ioctx->cmd; <answer> struct 
<token> srp_rsp *srp_rsp; <answer> struct 
const u8 <token> <answer> *sense_data; 
int sense_data_len, <token> <answer> max_sense_len; 
u32 <token> = cmd->residual_count; <answer> resid 
WARN_ON(status & <token> <answer> 1); 
<token> = ioctx->ioctx.buf; <answer> srp_rsp 
sense_data = <token> <answer> ioctx->sense_data; 
<token> = ioctx->cmd.scsi_sense_length; <answer> sense_data_len 
WARN_ON(sense_data_len > <token> <answer> sizeof(ioctx->sense_data)); 
<token> 0, sizeof(*srp_rsp)); <answer> memset(srp_rsp, 
srp_rsp->opcode = <token> <answer> SRP_RSP; 
<token> = <answer> srp_rsp->req_lim_delta 
cpu_to_be32(1 + <token> 0)); <answer> atomic_xchg(&ch->req_lim_delta, 
srp_rsp->tag = <token> <answer> tag; 
<token> = status; <answer> srp_rsp->status 
if <token> & SCF_UNDERFLOW_BIT) { <answer> (cmd->se_cmd_flags 
if <token> == DMA_TO_DEVICE) { <answer> (cmd->data_direction 
static <token> srpt_build_tskmgmt_rsp(struct srpt_rdma_ch *ch, <answer> int 
<token> srpt_send_ioctx *ioctx, <answer> struct 
u8 <token> u64 tag) <answer> rsp_code, 
<token> srp_rsp *srp_rsp; <answer> struct 
int <token> <answer> resp_data_len; 
int <token> <answer> resp_len; 
resp_data_len = <token> <answer> 4; 
resp_len = sizeof(*srp_rsp) + <token> <answer> resp_data_len; 
srp_rsp <token> ioctx->ioctx.buf; <answer> = 
memset(srp_rsp, 0, <token> <answer> sizeof(*srp_rsp)); 
<token> = SRP_RSP; <answer> srp_rsp->opcode 
srp_rsp->req_lim_delta <token> <answer> = 
cpu_to_be32(1 + atomic_xchg(&ch->req_lim_delta, <token> <answer> 0)); 
<token> = tag; <answer> srp_rsp->tag 
<token> |= SRP_RSP_FLAG_RSPVALID; <answer> srp_rsp->flags 
srp_rsp->resp_data_len <token> cpu_to_be32(resp_data_len); <answer> = 
srp_rsp->data[3] = <token> <answer> rsp_code; 
return <token> <answer> resp_len; 
static int srpt_check_stop_free(struct se_cmd <token> <answer> *cmd) 
struct srpt_send_ioctx *ioctx = <token> <answer> container_of(cmd, 
<token> srpt_send_ioctx, cmd); <answer> struct 
return <token> <answer> target_put_sess_cmd(&ioctx->cmd); 
static void srpt_handle_cmd(struct srpt_rdma_ch <token> <answer> *ch, 
struct <token> *recv_ioctx, <answer> srpt_recv_ioctx 
struct <token> *send_ioctx) <answer> srpt_send_ioctx 
struct se_cmd <token> <answer> *cmd; 
struct srp_cmd <token> <answer> *srp_cmd; 
struct scatterlist *sg = <token> <answer> NULL; 
<token> sg_cnt = 0; <answer> unsigned 
u64 <token> <answer> data_len; 
<token> dma_data_direction dir; <answer> enum 
int <token> <answer> rc; 
srp_cmd = recv_ioctx->ioctx.buf <token> recv_ioctx->ioctx.offset; <answer> + 
<token> = &send_ioctx->cmd; <answer> cmd 
cmd->tag = <token> <answer> srp_cmd->tag; 
switch (srp_cmd->task_attr) <token> <answer> { 
<token> SRP_CMD_SIMPLE_Q: <answer> case 
cmd->sam_task_attr <token> TCM_SIMPLE_TAG; <answer> = 
case <token> <answer> SRP_CMD_ORDERED_Q: 
cmd->sam_task_attr <token> TCM_ORDERED_TAG; <answer> = 
case <token> <answer> SRP_CMD_HEAD_OF_Q: 
cmd->sam_task_attr <token> TCM_HEAD_TAG; <answer> = 
<token> SRP_CMD_ACA: <answer> case 
cmd->sam_task_attr <token> TCM_ACA_TAG; <answer> = 
rc = srpt_get_desc_tbl(recv_ioctx, <token> srp_cmd, &dir, <answer> send_ioctx, 
&sg, &sg_cnt, <token> ch->imm_data_offset); <answer> &data_len, 
if (rc) <token> <answer> { 
if <token> != -EAGAIN) { <answer> (rc 
pr_err("0x%llx: parsing SRP <token> table failed.\n", <answer> descriptor 
<token> busy; <answer> goto 
<token> = target_init_cmd(cmd, ch->sess, &send_ioctx->sense_data[0], <answer> rc 
<token> data_len, <answer> scsilun_to_int(&srp_cmd->lun), 
TCM_SIMPLE_TAG, dir, <token> <answer> TARGET_SCF_ACK_KREF); 
if (rc <token> 0) { <answer> != 
pr_debug("target_submit_cmd() returned %d for tag <token> rc, <answer> %#llx\n", 
<token> busy; <answer> goto 
if (target_submit_prep(cmd, <token> sg, sg_cnt, NULL, 0, NULL, 0, <answer> srp_cmd->cdb, 
static int srp_tmr_to_tcm(int <token> <answer> fn) 
<token> (fn) { <answer> switch 
case <token> <answer> SRP_TSK_ABORT_TASK: 
return <token> <answer> TMR_ABORT_TASK; 
case <token> <answer> SRP_TSK_ABORT_TASK_SET: 
return <token> <answer> TMR_ABORT_TASK_SET; 
case <token> <answer> SRP_TSK_CLEAR_TASK_SET: 
return <token> <answer> TMR_CLEAR_TASK_SET; 
case <token> <answer> SRP_TSK_LUN_RESET: 
return <token> <answer> TMR_LUN_RESET; 
case <token> <answer> SRP_TSK_CLEAR_ACA: 
return <token> <answer> TMR_CLEAR_ACA; 
return <token> <answer> -1; 
static void srpt_handle_tsk_mgmt(struct srpt_rdma_ch <token> <answer> *ch, 
struct <token> *recv_ioctx, <answer> srpt_recv_ioctx 
struct srpt_send_ioctx <token> <answer> *send_ioctx) 
struct <token> *srp_tsk; <answer> srp_tsk_mgmt 
struct <token> *cmd; <answer> se_cmd 
struct se_session *sess = <token> <answer> ch->sess; 
<token> tcm_tmr; <answer> int 
<token> rc; <answer> int 
srp_tsk = recv_ioctx->ioctx.buf <token> recv_ioctx->ioctx.offset; <answer> + 
cmd <token> &send_ioctx->cmd; <answer> = 
pr_debug("recv <token> fn %d for task_tag %lld and cmd tag %lld ch %p sess %p\n", <answer> tsk_mgmt 
srp_tsk->tsk_mgmt_func, srp_tsk->task_tag, <token> ch, <answer> srp_tsk->tag, 
<token> SRPT_STATE_MGMT); <answer> srpt_set_cmd_state(send_ioctx, 
send_ioctx->cmd.tag = <token> <answer> srp_tsk->tag; 
<token> = srp_tmr_to_tcm(srp_tsk->tsk_mgmt_func); <answer> tcm_tmr 
rc = <token> sess, NULL, <answer> target_submit_tmr(&send_ioctx->cmd, 
scsilun_to_int(&srp_tsk->lun), srp_tsk, <token> <answer> tcm_tmr, 
<token> srp_tsk->task_tag, <answer> GFP_KERNEL, 
if (rc <token> 0) { <answer> != 
<token> = TMR_FUNCTION_REJECTED; <answer> send_ioctx->cmd.se_tmr_req->response 
<token> bool <answer> static 
srpt_handle_new_iu(struct srpt_rdma_ch *ch, struct <token> *recv_ioctx) <answer> srpt_recv_ioctx 
struct srpt_send_ioctx *send_ioctx <token> NULL; <answer> = 
struct <token> *srp_cmd; <answer> srp_cmd 
bool res = <token> <answer> false; 
<token> opcode; <answer> u8 
if (unlikely(ch->state <token> CH_CONNECTING)) <answer> == 
goto <token> <answer> push; 
<token> + srp_max_req_size, <answer> recv_ioctx->ioctx.offset 
<token> = recv_ioctx->ioctx.buf + recv_ioctx->ioctx.offset; <answer> srp_cmd 
opcode = <token> <answer> srp_cmd->opcode; 
if (opcode == SRP_CMD || opcode == <token> { <answer> SRP_TSK_MGMT) 
<token> = srpt_get_send_ioctx(ch); <answer> send_ioctx 
<token> (unlikely(!send_ioctx)) <answer> if 
goto <token> <answer> push; 
if <token> { <answer> (!list_empty(&recv_ioctx->wait_list)) 
<token> (opcode) { <answer> switch 
<token> SRP_CMD: <answer> case 
srpt_handle_cmd(ch, <token> send_ioctx); <answer> recv_ioctx, 
case <token> <answer> SRP_TSK_MGMT: 
srpt_handle_tsk_mgmt(ch, recv_ioctx, <token> <answer> send_ioctx); 
<token> SRP_I_LOGOUT: <answer> case 
<token> yet implemented: SRP_I_LOGOUT\n"); <answer> pr_err("Not 
<token> SRP_CRED_RSP: <answer> case 
<token> SRP_CRED_RSP\n"); <answer> pr_debug("received 
case <token> <answer> SRP_AER_RSP: 
pr_debug("received <token> <answer> SRP_AER_RSP\n"); 
<token> SRP_RSP: <answer> case 
pr_err("Received <token> <answer> SRP_RSP\n"); 
<token> IU with unknown opcode 0x%x\n", opcode); <answer> pr_err("received 
if <token> || !send_ioctx->recv_ioctx) <answer> (!send_ioctx 
srpt_post_recv(ch->sport->sdev, ch, <token> <answer> recv_ioctx); 
<token> = true; <answer> res 
return <token> <answer> res; 
if (list_empty(&recv_ioctx->wait_list)) <token> <answer> { 
list_add_tail(&recv_ioctx->wait_list, <token> <answer> &ch->cmd_wait_list); 
goto <token> <answer> out; 
static void srpt_recv_done(struct ib_cq *cq, struct ib_wc <token> <answer> *wc) 
struct srpt_rdma_ch *ch <token> wc->qp->qp_context; <answer> = 
struct srpt_recv_ioctx *ioctx <token> <answer> = 
container_of(wc->wr_cqe, struct srpt_recv_ioctx, <token> <answer> ioctx.cqe); 
if (wc->status <token> IB_WC_SUCCESS) { <answer> == 
<token> req_lim; <answer> int 
req_lim <token> atomic_dec_return(&ch->req_lim); <answer> = 
if (unlikely(req_lim <token> 0)) <answer> < 
pr_err("req_lim = %d < 0\n", <token> <answer> req_lim); 
<token> = wc->byte_len; <answer> ioctx->byte_len 
srpt_handle_new_iu(ch, <token> <answer> ioctx); 
} <token> { <answer> else 
pr_info_ratelimited("receiving failed for <token> %p with status %d\n", <answer> ioctx 
<token> wc->status); <answer> ioctx, 
static void srpt_process_wait_list(struct srpt_rdma_ch <token> <answer> *ch) 
struct srpt_recv_ioctx *recv_ioctx, <token> <answer> *tmp; 
WARN_ON_ONCE(ch->state <token> CH_CONNECTING); <answer> == 
if <token> <answer> (list_empty(&ch->cmd_wait_list)) 
<token> = true; <answer> ch->processing_wait_list 
list_for_each_entry_safe(recv_ioctx, <token> &ch->cmd_wait_list, <answer> tmp, 
wait_list) <token> <answer> { 
<token> (!srpt_handle_new_iu(ch, recv_ioctx)) <answer> if 
ch->processing_wait_list <token> false; <answer> = 
<token> void srpt_send_done(struct ib_cq *cq, struct ib_wc *wc) <answer> static 
struct srpt_rdma_ch <token> = wc->qp->qp_context; <answer> *ch 
struct srpt_send_ioctx *ioctx <token> <answer> = 
container_of(wc->wr_cqe, <token> srpt_send_ioctx, ioctx.cqe); <answer> struct 
enum srpt_command_state <token> <answer> state; 
state = srpt_set_cmd_state(ioctx, <token> <answer> SRPT_STATE_DONE); 
WARN_ON(state <token> SRPT_STATE_CMD_RSP_SENT && <answer> != 
state != <token> <answer> SRPT_STATE_MGMT_RSP_SENT); 
<token> + ioctx->n_rdma, &ch->sq_wr_avail); <answer> atomic_add(1 
if <token> != IB_WC_SUCCESS) <answer> (wc->status 
<token> response for ioctx 0x%p failed with status %d\n", <answer> pr_info("sending 
<token> wc->status); <answer> ioctx, 
<token> (state != SRPT_STATE_DONE) { <answer> if 
<token> 0); <answer> transport_generic_free_cmd(&ioctx->cmd, 
} else <token> <answer> { 
pr_err("IB completion has been <token> too late for wr_id = %u.\n", <answer> received 
static int srpt_create_ch_ib(struct srpt_rdma_ch <token> <answer> *ch) 
struct ib_qp_init_attr <token> <answer> *qp_init; 
struct srpt_port *sport <token> ch->sport; <answer> = 
struct srpt_device *sdev <token> sport->sdev; <answer> = 
const <token> ib_device_attr *attrs = &sdev->device->attrs; <answer> struct 
int sq_size <token> sport->port_attrib.srp_sq_size; <answer> = 
int i, <token> <answer> ret; 
WARN_ON(ch->rq_size <token> 1); <answer> < 
<token> = -ENOMEM; <answer> ret 
qp_init = kzalloc(sizeof(*qp_init), <token> <answer> GFP_KERNEL); 
if <token> <answer> (!qp_init) 
<token> out; <answer> goto 
<token> = ib_cq_pool_get(sdev->device, ch->rq_size + sq_size, -1, <answer> ch->cq 
<token> (IS_ERR(ch->cq)) { <answer> if 
<token> = PTR_ERR(ch->cq); <answer> ret 
pr_err("failed to create CQ cqe= <token> ret= %d\n", <answer> %d 
ch->rq_size + sq_size, <token> <answer> ret); 
<token> out; <answer> goto 
ch->cq_size = ch->rq_size <token> sq_size; <answer> + 
qp_init->qp_context = (void <token> <answer> *)ch; 
qp_init->event_handler = <token> <answer> srpt_qp_event; 
qp_init->send_cq = <token> <answer> ch->cq; 
qp_init->recv_cq <token> ch->cq; <answer> = 
qp_init->sq_sig_type = <token> <answer> IB_SIGNAL_REQ_WR; 
qp_init->qp_type = <token> <answer> IB_QPT_RC; 
qp_init->cap.max_send_wr = min(sq_size <token> 2, attrs->max_qp_wr); <answer> / 
qp_init->cap.max_rdma_ctxs <token> sq_size / 2; <answer> = 
qp_init->cap.max_send_sge <token> attrs->max_send_sge; <answer> = 
qp_init->cap.max_recv_sge = <token> <answer> 1; 
<token> = ch->sport->port; <answer> qp_init->port_num 
<token> (sdev->use_srq) <answer> if 
qp_init->srq = <token> <answer> sdev->srq; 
qp_init->cap.max_recv_wr = <token> <answer> ch->rq_size; 
<token> (ch->using_rdma_cm) { <answer> if 
ret = rdma_create_qp(ch->rdma_cm.cm_id, sdev->pd, <token> <answer> qp_init); 
<token> = ch->rdma_cm.cm_id->qp; <answer> ch->qp 
} <token> { <answer> else 
ch->qp <token> ib_create_qp(sdev->pd, qp_init); <answer> = 
<token> (!IS_ERR(ch->qp)) { <answer> if 
ret = <token> ch->qp); <answer> srpt_init_ch_qp(ch, 
if <token> <answer> (ret) 
<token> else { <answer> } 
<token> = PTR_ERR(ch->qp); <answer> ret 
<token> (ret) { <answer> if 
bool retry = <token> > MIN_SRPT_SQ_SIZE; <answer> sq_size 
if <token> { <answer> (retry) 
<token> to create queue pair with sq_size = %d (%d) - retrying\n", <answer> pr_debug("failed 
<token> ret); <answer> sq_size, 
ib_cq_pool_put(ch->cq, <token> <answer> ch->cq_size); 
<token> = max(sq_size / 2, MIN_SRPT_SQ_SIZE); <answer> sq_size 
<token> retry; <answer> goto 
<token> else { <answer> } 
pr_err("failed to <token> queue pair with sq_size = %d (%d)\n", <answer> create 
sq_size, <token> <answer> ret); 
<token> err_destroy_cq; <answer> goto 
atomic_set(&ch->sq_wr_avail, <token> <answer> qp_init->cap.max_send_wr); 
pr_debug("%s: max_cqe= <token> max_sge= %d sq_size = %d ch= %p\n", <answer> %d 
__func__, ch->cq->cqe, <token> <answer> qp_init->cap.max_send_sge, 
<token> ch); <answer> qp_init->cap.max_send_wr, 
<token> (!sdev->use_srq) <answer> if 
for (i = 0; i <token> ch->rq_size; i++) <answer> < 
<token> ch, ch->ioctx_recv_ring[i]); <answer> srpt_post_recv(sdev, 
<token> ret; <answer> return 
ch->qp = <token> <answer> NULL; 
<token> ch->cq_size); <answer> ib_cq_pool_put(ch->cq, 
<token> out; <answer> goto 
static <token> srpt_destroy_ch_ib(struct srpt_rdma_ch *ch) <answer> void 
<token> ch->cq_size); <answer> ib_cq_pool_put(ch->cq, 
<token> bool srpt_close_ch(struct srpt_rdma_ch *ch) <answer> static 
int <token> <answer> ret; 
if (!srpt_set_ch_state(ch, <token> { <answer> CH_DRAINING)) 
pr_debug("%s: already <token> ch->sess_name); <answer> closed\n", 
return <token> <answer> false; 
<token> = srpt_ch_qp_err(ch); <answer> ret 
if <token> < 0) <answer> (ret 
pr_err("%s-%d: changing <token> pair into error state failed: %d\n", <answer> queue 
<token> ch->qp->qp_num, ret); <answer> ch->sess_name, 
<token> = srpt_zerolength_write(ch); <answer> ret 
if (ret < 0) <token> <answer> { 
pr_err("%s-%d: <token> zero-length write failed: %d\n", <answer> queuing 
<token> ch->qp->qp_num, ret); <answer> ch->sess_name, 
if (srpt_set_ch_state(ch, <token> <answer> CH_DISCONNECTED)) 
<token> srpt_free_ch); <answer> kref_put(&ch->kref, 
return <token> <answer> true; 
<token> int srpt_disconnect_ch(struct srpt_rdma_ch *ch) <answer> static 
int <token> <answer> ret; 
if (!srpt_set_ch_state(ch, <token> <answer> CH_DISCONNECTING)) 
<token> -ENOTCONN; <answer> return 
<token> (ch->using_rdma_cm) { <answer> if 
ret <token> rdma_disconnect(ch->rdma_cm.cm_id); <answer> = 
} else <token> <answer> { 
ret = <token> NULL, 0); <answer> ib_send_cm_dreq(ch->ib_cm.cm_id, 
if (ret <token> 0) <answer> < 
ret = <token> NULL, 0); <answer> ib_send_cm_drep(ch->ib_cm.cm_id, 
if (ret <token> 0 && srpt_close_ch(ch)) <answer> < 
<token> = 0; <answer> ret 
<token> ret; <answer> return 
static struct srpt_nexus *srpt_get_nexus(struct srpt_port <token> <answer> *sport, 
const <token> i_port_id[16], <answer> u8 
<token> u8 t_port_id[16]) <answer> const 
struct <token> *nexus = NULL, *tmp_nexus = NULL, *n; <answer> srpt_nexus 
for (;;) <token> <answer> { 
list_for_each_entry(n, &sport->nexus_list, <token> { <answer> entry) 
if (memcmp(n->i_port_id, i_port_id, 16) <token> 0 && <answer> == 
memcmp(n->t_port_id, t_port_id, <token> == 0) { <answer> 16) 
nexus <token> n; <answer> = 
if <token> && tmp_nexus) { <answer> (!nexus 
swap(nexus, <token> <answer> tmp_nexus); 
<token> (nexus) <answer> if 
tmp_nexus = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*nexus), 
<token> (!tmp_nexus) { <answer> if 
nexus <token> ERR_PTR(-ENOMEM); <answer> = 
memcpy(tmp_nexus->i_port_id, i_port_id, <token> <answer> 16); 
memcpy(tmp_nexus->t_port_id, t_port_id, <token> <answer> 16); 
<token> nexus; <answer> return 
<token> void srpt_set_enabled(struct srpt_port *sport, bool enabled) <answer> static 
if (sport->enabled == <token> <answer> enabled) 
sport->enabled <token> enabled; <answer> = 
<token> (!enabled) <answer> if 
static void srpt_drop_sport_ref(struct <token> *sport) <answer> srpt_port 
if (atomic_dec_return(&sport->refcount) == 0 <token> sport->freed_channels) <answer> && 
static void srpt_free_ch(struct kref <token> <answer> *kref) 
struct srpt_rdma_ch *ch <token> container_of(kref, struct srpt_rdma_ch, kref); <answer> = 
<token> rcu); <answer> kfree_rcu(ch, 
static void srpt_release_channel_work(struct work_struct <token> <answer> *w) 
struct srpt_rdma_ch <token> <answer> *ch; 
<token> srpt_device *sdev; <answer> struct 
struct srpt_port <token> <answer> *sport; 
struct <token> *se_sess; <answer> se_session 
<token> = container_of(w, struct srpt_rdma_ch, release_work); <answer> ch 
pr_debug("%s-%d\n", ch->sess_name, <token> <answer> ch->qp->qp_num); 
sdev = <token> <answer> ch->sport->sdev; 
se_sess = <token> <answer> ch->sess; 
ch->sess <token> NULL; <answer> = 
if <token> <answer> (ch->using_rdma_cm) 
<token> = ch->sport; <answer> sport 
<token> (ch->closed) <answer> if 
srpt_free_ioctx_ring((struct <token> **)ch->ioctx_ring, <answer> srpt_ioctx 
ch->sport->sdev, <token> <answer> ch->rq_size, 
ch->rsp_buf_cache, <token> <answer> DMA_TO_DEVICE); 
<token> srpt_ioctx **)ch->ioctx_recv_ring, <answer> srpt_free_ioctx_ring((struct 
sdev, <token> <answer> ch->rq_size, 
ch->req_buf_cache, <token> <answer> DMA_FROM_DEVICE); 
<token> srpt_free_ch); <answer> kref_put(&ch->kref, 
<token> int srpt_cm_req_recv(struct srpt_device *const sdev, <answer> static 
<token> ib_cm_id *ib_cm_id, <answer> struct 
<token> rdma_cm_id *rdma_cm_id, <answer> struct 
<token> port_num, __be16 pkey, <answer> u8 
<token> struct srp_login_req *req, <answer> const 
const <token> *src_addr) <answer> char 
struct <token> *sport = &sdev->port[port_num - 1]; <answer> srpt_port 
struct srpt_nexus <token> <answer> *nexus; 
<token> srp_login_rsp *rsp = NULL; <answer> struct 
struct srp_login_rej <token> = NULL; <answer> *rej 
union <token> <answer> { 
struct rdma_conn_param <token> <answer> rdma_cm; 
<token> ib_cm_rep_param ib_cm; <answer> struct 
} <token> = NULL; <answer> *rep_param 
struct srpt_rdma_ch *ch = <token> <answer> NULL; 
<token> i_port_id[36]; <answer> char 
<token> it_iu_len; <answer> u32 
int <token> tag_num, tag_size, ret; <answer> i, 
<token> srpt_tpg *stpg; <answer> struct 
it_iu_len = <token> <answer> be32_to_cpu(req->req_it_iu_len); 
pr_info("Received SRP_LOGIN_REQ with <token> %pI6, t_port_id %pI6 and it_iu_len %d on port %d (guid=%pI6); pkey %#04x\n", <answer> i_port_id 
req->initiator_port_id, <token> it_iu_len, <answer> req->target_port_id, 
<token> &sport->gid, be16_to_cpu(pkey)); <answer> port_num, 
nexus = <token> req->initiator_port_id, <answer> srpt_get_nexus(sport, 
if <token> { <answer> (IS_ERR(nexus)) 
ret = <token> <answer> PTR_ERR(nexus); 
goto <token> <answer> out; 
ret = <token> <answer> -ENOMEM; 
rsp = kzalloc(sizeof(*rsp), <token> <answer> GFP_KERNEL); 
rej <token> kzalloc(sizeof(*rej), GFP_KERNEL); <answer> = 
rep_param <token> kzalloc(sizeof(*rep_param), GFP_KERNEL); <answer> = 
<token> (!rsp || !rej || !rep_param) <answer> if 
<token> out; <answer> goto 
<token> = -EINVAL; <answer> ret 
if (it_iu_len > srp_max_req_size || it_iu_len < 64) <token> <answer> { 
rej->reason <token> cpu_to_be32( <answer> = 
pr_err("rejected SRP_LOGIN_REQ because its length <token> bytes) is out of range (%d .. %d)\n", <answer> (%d 
it_iu_len, <token> srp_max_req_size); <answer> 64, 
goto <token> <answer> reject; 
if (!sport->enabled) <token> <answer> { 
<token> = cpu_to_be32(SRP_LOGIN_REJ_INSUFFICIENT_RESOURCES); <answer> rej->reason 
pr_info("rejected SRP_LOGIN_REQ because <token> port %s_%d has not yet been enabled\n", <answer> target 
dev_name(&sport->sdev->device->dev), <token> <answer> port_num); 
<token> reject; <answer> goto 
<token> (*(__be64 *)req->target_port_id != cpu_to_be64(srpt_service_guid) <answer> if 
|| <token> *)(req->target_port_id + 8) != <answer> *(__be64 
<token> { <answer> cpu_to_be64(srpt_service_guid)) 
rej->reason <token> cpu_to_be32( <answer> = 
pr_err("rejected SRP_LOGIN_REQ <token> it has an invalid target port identifier.\n"); <answer> because 
goto <token> <answer> reject; 
<token> = -ENOMEM; <answer> ret 
ch = kzalloc(sizeof(*ch), <token> <answer> GFP_KERNEL); 
<token> (!ch) { <answer> if 
rej->reason = <token> <answer> cpu_to_be32(SRP_LOGIN_REJ_INSUFFICIENT_RESOURCES); 
pr_err("rejected <token> because out of memory.\n"); <answer> SRP_LOGIN_REQ 
<token> reject; <answer> goto 
ch->pkey = <token> <answer> be16_to_cpu(pkey); 
ch->nexus <token> nexus; <answer> = 
ch->zw_cqe.done = <token> <answer> srpt_zerolength_write_done; 
INIT_WORK(&ch->release_work, <token> <answer> srpt_release_channel_work); 
ch->sport = <token> <answer> sport; 
if <token> { <answer> (rdma_cm_id) 
ch->using_rdma_cm <token> true; <answer> = 
ch->rdma_cm.cm_id = <token> <answer> rdma_cm_id; 
rdma_cm_id->context <token> ch; <answer> = 
<token> else { <answer> } 
ch->ib_cm.cm_id <token> ib_cm_id; <answer> = 
ib_cm_id->context = <token> <answer> ch; 
ch->rq_size = min(MAX_SRPT_RQ_SIZE, <token> <answer> sdev->device->attrs.max_qp_wr); 
ch->state <token> CH_CONNECTING; <answer> = 
ch->max_rsp_size <token> ch->sport->port_attrib.srp_max_rsp_size; <answer> = 
<token> = kmem_cache_create("srpt-rsp-buf", ch->max_rsp_size, <answer> ch->rsp_buf_cache 
512, <token> NULL); <answer> 0, 
<token> (!ch->rsp_buf_cache) <answer> if 
goto <token> <answer> free_ch; 
ch->ioctx_ring = (struct <token> **) <answer> srpt_send_ioctx 
<token> ch->rq_size, <answer> srpt_alloc_ioctx_ring(ch->sport->sdev, 
ch->rsp_buf_cache, <token> DMA_TO_DEVICE); <answer> 0, 
if <token> { <answer> (!ch->ioctx_ring) 
pr_err("rejected SRP_LOGIN_REQ because creating a <token> QP SQ ring failed.\n"); <answer> new 
rej->reason <token> cpu_to_be32(SRP_LOGIN_REJ_INSUFFICIENT_RESOURCES); <answer> = 
<token> free_rsp_cache; <answer> goto 
for (i = 0; <token> < ch->rq_size; i++) <answer> i 
ch->ioctx_ring[i]->ch = <token> <answer> ch; 
if <token> { <answer> (!sdev->use_srq) 
u16 <token> = req->req_flags & SRP_IMMED_REQUESTED ? <answer> imm_data_offset 
<token> : 0; <answer> be16_to_cpu(req->imm_data_offset) 
<token> alignment_offset; <answer> u16 
u32 <token> <answer> req_sz; 
if (req->req_flags <token> SRP_IMMED_REQUESTED) <answer> & 
<token> = %d\n", <answer> pr_debug("imm_data_offset 
if (imm_data_offset >= sizeof(struct srp_cmd)) <token> <answer> { 
ch->imm_data_offset <token> imm_data_offset; <answer> = 
<token> |= SRP_LOGIN_RSP_IMMED_SUPP; <answer> rsp->rsp_flags 
} else <token> <answer> { 
<token> = 0; <answer> ch->imm_data_offset 
<token> = round_up(imm_data_offset, 512) - <answer> alignment_offset 
req_sz <token> alignment_offset + imm_data_offset + srp_max_req_size; <answer> = 
<token> = kmem_cache_create("srpt-req-buf", req_sz, <answer> ch->req_buf_cache 
512, <token> NULL); <answer> 0, 
if <token> <answer> (!ch->req_buf_cache) 
<token> free_rsp_ring; <answer> goto 
ch->ioctx_recv_ring = <token> srpt_recv_ioctx **) <answer> (struct 
srpt_alloc_ioctx_ring(ch->sport->sdev, <token> <answer> ch->rq_size, 
if <token> { <answer> (!ch->ioctx_recv_ring) 
pr_err("rejected SRP_LOGIN_REQ because creating a new QP RQ <token> failed.\n"); <answer> ring 
<token> = <answer> rej->reason 
<token> free_recv_cache; <answer> goto 
for (i = 0; i <token> ch->rq_size; i++) <answer> < 
ret <token> srpt_create_ch_ib(ch); <answer> = 
if (ret) <token> <answer> { 
<token> = cpu_to_be32(SRP_LOGIN_REJ_INSUFFICIENT_RESOURCES); <answer> rej->reason 
pr_err("rejected SRP_LOGIN_REQ because creating a new <token> channel failed.\n"); <answer> RDMA 
goto <token> <answer> free_recv_ring; 
<token> src_addr, sizeof(ch->sess_name)); <answer> strscpy(ch->sess_name, 
snprintf(i_port_id, sizeof(i_port_id), <token> <answer> "0x%016llx%016llx", 
be64_to_cpu(*(__be64 <token> <answer> *)nexus->i_port_id), 
be64_to_cpu(*(__be64 <token> + 8))); <answer> *)(nexus->i_port_id 
pr_debug("registering src addr %s or <token> %s\n", ch->sess_name, <answer> i_port_id 
tag_num <token> ch->rq_size; <answer> = 
if ((req->req_flags <token> SRP_MTCH_ACTION) == SRP_MULTICHAN_SINGLE) { <answer> & 
<token> srpt_rdma_ch *ch2; <answer> struct 
list_for_each_entry(ch2, &nexus->ch_list, <token> { <answer> list) 
if <token> < 0) <answer> (srpt_disconnect_ch(ch2) 
pr_info("Relogin - closed existing channel <token> <answer> %s\n", 
rsp->rsp_flags |= <token> <answer> SRP_LOGIN_RSP_MULTICHAN_TERMINATED; 
} else <token> <answer> { 
<token> |= SRP_LOGIN_RSP_MULTICHAN_MAINTAINED; <answer> rsp->rsp_flags 
#define pr_fmt(fmt) "%s: " fmt, <token> <answer> __func__ 
#include <token> <answer> <crypto/engine.h> 
#include <token> <answer> <crypto/hmac.h> 
#include <token> <answer> <crypto/internal/hash.h> 
<token> <crypto/scatterwalk.h> <answer> #include 
#include <token> <answer> <crypto/sha1.h> 
<token> <crypto/sha2.h> <answer> #include 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/device.h> 
#include <token> <answer> <linux/dma-mapping.h> 
#include <token> <answer> <linux/dmaengine.h> 
#include <token> <answer> <linux/init.h> 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/io.h> <answer> #include 
#include <token> <answer> <linux/irq.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
<token> <linux/of_address.h> <answer> #include 
#include <token> <answer> <linux/of_irq.h> 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/pm_runtime.h> <answer> #include 
#include <token> <answer> <linux/scatterlist.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/string.h> <answer> #include 
#define MD5_DIGEST_SIZE <token> <answer> 16 
<token> SHA_REG_IDIGEST(dd, x) ((dd)->pdata->idigest_ofs + ((x)*0x04)) <answer> #define 
<token> SHA_REG_DIN(dd, x) ((dd)->pdata->din_ofs + ((x) * 0x04)) <answer> #define 
#define SHA_REG_DIGCNT(dd) <token> <answer> ((dd)->pdata->digcnt_ofs) 
<token> SHA_REG_ODIGEST(dd, x) ((dd)->pdata->odigest_ofs + (x * 0x04)) <answer> #define 
<token> SHA_REG_CTRL 0x18 <answer> #define 
#define SHA_REG_CTRL_LENGTH <token> << 5) <answer> (0xFFFFFFFF 
#define SHA_REG_CTRL_CLOSE_HASH (1 << <token> <answer> 4) 
<token> SHA_REG_CTRL_ALGO_CONST (1 << 3) <answer> #define 
#define SHA_REG_CTRL_ALGO <token> << 2) <answer> (1 
#define SHA_REG_CTRL_INPUT_READY (1 << <token> <answer> 1) 
<token> SHA_REG_CTRL_OUTPUT_READY (1 << 0) <answer> #define 
#define <token> ((dd)->pdata->rev_ofs) <answer> SHA_REG_REV(dd) 
<token> SHA_REG_MASK(dd) ((dd)->pdata->mask_ofs) <answer> #define 
#define SHA_REG_MASK_DMA_EN (1 << <token> <answer> 3) 
#define <token> (1 << 2) <answer> SHA_REG_MASK_IT_EN 
#define <token> (1 << 1) <answer> SHA_REG_MASK_SOFTRESET 
#define SHA_REG_AUTOIDLE <token> << 0) <answer> (1 
<token> SHA_REG_SYSSTATUS(dd) ((dd)->pdata->sysstatus_ofs) <answer> #define 
<token> SHA_REG_SYSSTATUS_RESETDONE (1 << 0) <answer> #define 
<token> SHA_REG_MODE(dd) ((dd)->pdata->mode_ofs) <answer> #define 
#define SHA_REG_MODE_HMAC_OUTER_HASH <token> << 7) <answer> (1 
#define SHA_REG_MODE_HMAC_KEY_PROC (1 <token> 5) <answer> << 
#define SHA_REG_MODE_CLOSE_HASH (1 <token> 4) <answer> << 
#define SHA_REG_MODE_ALGO_CONSTANT (1 <token> 3) <answer> << 
<token> SHA_REG_MODE_ALGO_MASK (7 << 0) <answer> #define 
#define SHA_REG_MODE_ALGO_MD5_128 <token> << 1) <answer> (0 
#define SHA_REG_MODE_ALGO_SHA1_160 (1 << <token> <answer> 1) 
#define SHA_REG_MODE_ALGO_SHA2_224 (2 << <token> <answer> 1) 
<token> SHA_REG_MODE_ALGO_SHA2_256 (3 << 1) <answer> #define 
#define <token> (1 << 0) <answer> SHA_REG_MODE_ALGO_SHA2_384 
#define <token> (3 << 0) <answer> SHA_REG_MODE_ALGO_SHA2_512 
#define SHA_REG_LENGTH(dd) <token> <answer> ((dd)->pdata->length_ofs) 
#define <token> 0x118 <answer> SHA_REG_IRQSTATUS 
#define SHA_REG_IRQSTATUS_CTX_RDY (1 <token> 3) <answer> << 
<token> SHA_REG_IRQSTATUS_PARTHASH_RDY (1 << 2) <answer> #define 
#define SHA_REG_IRQSTATUS_INPUT_RDY <token> << 1) <answer> (1 
<token> SHA_REG_IRQSTATUS_OUTPUT_RDY (1 << 0) <answer> #define 
#define SHA_REG_IRQENA <token> <answer> 0x11C 
#define SHA_REG_IRQENA_CTX_RDY (1 << <token> <answer> 3) 
<token> SHA_REG_IRQENA_PARTHASH_RDY (1 << 2) <answer> #define 
<token> SHA_REG_IRQENA_INPUT_RDY (1 << 1) <answer> #define 
#define SHA_REG_IRQENA_OUTPUT_RDY (1 << <token> <answer> 0) 
#define <token> HZ <answer> DEFAULT_TIMEOUT_INTERVAL 
#define DEFAULT_AUTOSUSPEND_DELAY <token> <answer> 1000 
<token> ((ctx->flags & FLAGS_MODE_MASK) == FLAGS_MODE_SHA1) <answer> if 
<token> |= SHA_REG_CTRL_ALGO; <answer> val 
if <token> <answer> (!ctx->digcnt) 
<token> |= SHA_REG_CTRL_ALGO_CONST; <answer> val 
if <token> <answer> (final) 
val <token> SHA_REG_CTRL_CLOSE_HASH; <answer> |= 
mask = SHA_REG_CTRL_ALGO_CONST | SHA_REG_CTRL_CLOSE_HASH <token> <answer> | 
<token> | SHA_REG_CTRL_LENGTH; <answer> SHA_REG_CTRL_ALGO 
<token> SHA_REG_CTRL, val, mask); <answer> omap_sham_write_mask(dd, 
<token> void omap_sham_trigger_omap2(struct omap_sham_dev *dd, size_t length) <answer> static 
<token> int omap_sham_poll_irq_omap2(struct omap_sham_dev *dd) <answer> static 
<token> omap_sham_wait(dd, SHA_REG_CTRL, SHA_REG_CTRL_INPUT_READY); <answer> return 
<token> int get_block_size(struct omap_sham_reqctx *ctx) <answer> static 
int <token> <answer> d; 
switch (ctx->flags & FLAGS_MODE_MASK) <token> <answer> { 
<token> FLAGS_MODE_MD5: <answer> case 
<token> FLAGS_MODE_SHA1: <answer> case 
d = <token> <answer> SHA1_BLOCK_SIZE; 
<token> FLAGS_MODE_SHA224: <answer> case 
<token> FLAGS_MODE_SHA256: <answer> case 
d <token> SHA256_BLOCK_SIZE; <answer> = 
case <token> <answer> FLAGS_MODE_SHA384: 
case <token> <answer> FLAGS_MODE_SHA512: 
d = <token> <answer> SHA512_BLOCK_SIZE; 
d <token> 0; <answer> = 
return <token> <answer> d; 
static void omap_sham_write_n(struct omap_sham_dev *dd, <token> offset, <answer> u32 
u32 <token> int count) <answer> *value, 
<token> (; count--; value++, offset += 4) <answer> for 
omap_sham_write(dd, <token> *value); <answer> offset, 
static void omap_sham_write_ctrl_omap4(struct <token> *dd, size_t length, <answer> omap_sham_dev 
<token> final, int dma) <answer> int 
<token> omap_sham_reqctx *ctx = ahash_request_ctx(dd->req); <answer> struct 
u32 <token> mask; <answer> val, 
if <token> <answer> (likely(ctx->digcnt)) 
omap_sham_write(dd, <token> ctx->digcnt); <answer> SHA_REG_DIGCNT(dd), 
val = (ctx->flags & FLAGS_MODE_MASK) <token> (FLAGS_MODE_SHIFT); <answer> >> 
if <token> { <answer> (!ctx->digcnt) 
<token> crypto_ahash *tfm = crypto_ahash_reqtfm(dd->req); <answer> struct 
struct omap_sham_ctx *tctx = <token> <answer> crypto_ahash_ctx(tfm); 
struct omap_sham_hmac_ctx *bctx = <token> <answer> tctx->base; 
<token> bs, nr_dr; <answer> int 
<token> |= SHA_REG_MODE_ALGO_CONSTANT; <answer> val 
if (ctx->flags & BIT(FLAGS_HMAC)) <token> <answer> { 
<token> = get_block_size(ctx); <answer> bs 
nr_dr = <token> / (2 * sizeof(u32)); <answer> bs 
val <token> SHA_REG_MODE_HMAC_KEY_PROC; <answer> |= 
omap_sham_write_n(dd, <token> 0), <answer> SHA_REG_ODIGEST(dd, 
(u32 <token> nr_dr); <answer> *)bctx->ipad, 
omap_sham_write_n(dd, <token> 0), <answer> SHA_REG_IDIGEST(dd, 
(u32 *)bctx->ipad + nr_dr, <token> <answer> nr_dr); 
ctx->digcnt <token> bs; <answer> += 
<token> (final) { <answer> if 
val |= <token> <answer> SHA_REG_MODE_CLOSE_HASH; 
if (ctx->flags <token> BIT(FLAGS_HMAC)) <answer> & 
val <token> SHA_REG_MODE_HMAC_OUTER_HASH; <answer> |= 
mask = <token> | SHA_REG_MODE_CLOSE_HASH | <answer> SHA_REG_MODE_ALGO_CONSTANT 
SHA_REG_MODE_ALGO_MASK | <token> | <answer> SHA_REG_MODE_HMAC_OUTER_HASH 
dev_dbg(dd->dev, "ctrl: %08x, <token> %08lx\n", val, ctx->flags); <answer> flags: 
omap_sham_write_mask(dd, SHA_REG_MODE(dd), val, <token> <answer> mask); 
omap_sham_write(dd, <token> SHA_REG_IRQENA_OUTPUT_RDY); <answer> SHA_REG_IRQENA, 
omap_sham_write_mask(dd, <token> <answer> SHA_REG_MASK(dd), 
SHA_REG_MASK_IT_EN <token> <answer> | 
(dma ? <token> : 0), <answer> SHA_REG_MASK_DMA_EN 
SHA_REG_MASK_IT_EN | <token> <answer> SHA_REG_MASK_DMA_EN); 
static void omap_sham_trigger_omap4(struct omap_sham_dev <token> size_t length) <answer> *dd, 
omap_sham_write(dd, SHA_REG_LENGTH(dd), <token> <answer> length); 
static <token> omap_sham_poll_irq_omap4(struct omap_sham_dev *dd) <answer> int 
return <token> SHA_REG_IRQSTATUS, <answer> omap_sham_wait(dd, 
static int omap_sham_xmit_cpu(struct omap_sham_dev *dd, <token> length, <answer> size_t 
<token> final) <answer> int 
<token> omap_sham_reqctx *ctx = ahash_request_ctx(dd->req); <answer> struct 
int <token> len32, bs32, offset = 0; <answer> count, 
const <token> *buffer; <answer> u32 
int <token> <answer> mlen; 
struct <token> mi; <answer> sg_mapping_iter 
dev_dbg(dd->dev, "xmit_cpu: <token> %zd, length: %zd, final: %d\n", <answer> digcnt: 
ctx->digcnt, <token> final); <answer> length, 
dd->pdata->write_ctrl(dd, <token> final, 0); <answer> length, 
dd->pdata->trigger(dd, <token> <answer> length); 
use_dma <token> 0; <answer> = 
<token> (use_dma) <answer> if 
err <token> omap_sham_xmit_dma(dd, ctx->total, 1); <answer> = 
<token> = omap_sham_xmit_cpu(dd, ctx->total, 1); <answer> err 
<token> = 0; <answer> ctx->bufcnt 
dev_dbg(dd->dev, <token> err: %d\n", err); <answer> "final_req: 
<token> err; <answer> return 
static int omap_sham_hash_one_req(struct crypto_engine *engine, void <token> <answer> *areq) 
struct ahash_request *req = container_of(areq, <token> ahash_request, <answer> struct 
struct omap_sham_reqctx *ctx <token> ahash_request_ctx(req); <answer> = 
<token> omap_sham_dev *dd = ctx->dd; <answer> struct 
int <token> <answer> err; 
bool final = <token> & BIT(FLAGS_FINUP)) && <answer> (ctx->flags 
!(dd->flags & <token> <answer> BIT(FLAGS_HUGE)); 
dev_dbg(dd->dev, "hash-one: op: %u, <token> %u, digcnt: %zd, final: %d", <answer> total: 
<token> ctx->total, ctx->digcnt, final); <answer> ctx->op, 
<token> = omap_sham_prepare_request(engine, areq); <answer> err 
<token> (err) <answer> if 
<token> err; <answer> return 
<token> = pm_runtime_resume_and_get(dd->dev); <answer> err 
<token> (err < 0) { <answer> if 
dev_err(dd->dev, "failed to <token> sync: %d\n", err); <answer> get 
<token> err; <answer> return 
<token> = 0; <answer> dd->err 
dd->req = <token> <answer> req; 
<token> (ctx->digcnt) <answer> if 
dd->pdata->copy_hash(req, <token> <answer> 0); 
<token> (ctx->op == OP_UPDATE) <answer> if 
err = <token> <answer> omap_sham_update_req(dd); 
else if (ctx->op == <token> <answer> OP_FINAL) 
err = <token> <answer> omap_sham_final_req(dd); 
if (err != <token> <answer> -EINPROGRESS) 
omap_sham_finish_req(req, <token> <answer> err); 
<token> 0; <answer> return 
static int omap_sham_finish_hmac(struct ahash_request <token> <answer> *req) 
struct <token> *tctx = crypto_tfm_ctx(req->base.tfm); <answer> omap_sham_ctx 
struct omap_sham_hmac_ctx *bctx = <token> <answer> tctx->base; 
<token> bs = crypto_shash_blocksize(bctx->shash); <answer> int 
int <token> = crypto_shash_digestsize(bctx->shash); <answer> ds 
SHASH_DESC_ON_STACK(shash, <token> <answer> bctx->shash); 
shash->tfm = <token> <answer> bctx->shash; 
return <token> ?: <answer> crypto_shash_init(shash) 
crypto_shash_update(shash, <token> bs) ?: <answer> bctx->opad, 
crypto_shash_finup(shash, req->result, ds, <token> <answer> req->result); 
static int omap_sham_finish(struct <token> *req) <answer> ahash_request 
<token> omap_sham_reqctx *ctx = ahash_request_ctx(req); <answer> struct 
struct omap_sham_dev <token> = ctx->dd; <answer> *dd 
int err <token> 0; <answer> = 
<token> (ctx->digcnt) { <answer> if 
if ((ctx->flags & <token> && <answer> BIT(FLAGS_HMAC)) 
!test_bit(FLAGS_AUTO_XOR, <token> <answer> &dd->flags)) 
err = <token> <answer> omap_sham_finish_hmac(req); 
dev_dbg(dd->dev, "digcnt: %zd, bufcnt: %zd\n", ctx->digcnt, <token> <answer> ctx->bufcnt); 
return <token> <answer> err; 
static void omap_sham_finish_req(struct ahash_request *req, int <token> <answer> err) 
struct omap_sham_reqctx *ctx = <token> <answer> ahash_request_ctx(req); 
struct omap_sham_dev <token> = ctx->dd; <answer> *dd 
<token> (test_bit(FLAGS_SGS_COPIED, &dd->flags)) <answer> if 
<token> long)sg_virt(ctx->sg), <answer> free_pages((unsigned 
if <token> &dd->flags)) <answer> (test_bit(FLAGS_SGS_ALLOCED, 
<token> = NULL; <answer> ctx->sg 
dd->flags &= ~(BIT(FLAGS_SGS_ALLOCED) | <token> | <answer> BIT(FLAGS_SGS_COPIED) 
BIT(FLAGS_CPU) <token> BIT(FLAGS_DMA_READY) | <answer> | 
<token> (!err) <answer> if 
dd->pdata->copy_hash(req, <token> <answer> 1); 
if (dd->flags <token> BIT(FLAGS_HUGE)) { <answer> & 
if (test_bit(FLAGS_HMAC, &ctx->flags) <token> <answer> && 
<token> &ctx->dd->flags)) <answer> !test_bit(FLAGS_AUTO_XOR, 
offset = <token> <answer> get_block_size(ctx); 
return crypto_shash_tfm_digest(tctx->fallback, ctx->buffer + <token> <answer> offset, 
ctx->bufcnt <token> offset, req->result); <answer> - 
static int <token> ahash_request *req) <answer> omap_sham_final(struct 
struct <token> *ctx = ahash_request_ctx(req); <answer> omap_sham_reqctx 
ctx->flags <token> BIT(FLAGS_FINUP); <answer> |= 
if (ctx->flags <token> BIT(FLAGS_ERROR)) <answer> & 
if (!ctx->digcnt && ctx->bufcnt <token> ctx->dd->fallback_sz) <answer> < 
<token> omap_sham_final_shash(req); <answer> return 
else if <token> <answer> (ctx->bufcnt) 
return <token> OP_FINAL); <answer> omap_sham_enqueue(req, 
<token> = omap_sham_final(req); <answer> err2 
return <token> ?: err2; <answer> err1 
static int omap_sham_digest(struct ahash_request <token> <answer> *req) 
return omap_sham_init(req) <token> omap_sham_finup(req); <answer> ?: 
static int omap_sham_setkey(struct crypto_ahash *tfm, <token> u8 *key, <answer> const 
unsigned int <token> <answer> keylen) 
struct omap_sham_ctx *tctx = <token> <answer> crypto_ahash_ctx(tfm); 
struct omap_sham_hmac_ctx *bctx = <token> <answer> tctx->base; 
int bs = <token> <answer> crypto_shash_blocksize(bctx->shash); 
int ds = <token> <answer> crypto_shash_digestsize(bctx->shash); 
<token> err, i; <answer> int 
err = crypto_shash_setkey(tctx->fallback, key, <token> <answer> keylen); 
if <token> <answer> (err) 
return <token> <answer> err; 
if (keylen <token> bs) { <answer> > 
err <token> crypto_shash_tfm_digest(bctx->shash, key, keylen, <answer> = 
if <token> <answer> (err) 
return <token> <answer> err; 
keylen <token> ds; <answer> = 
<token> else { <answer> } 
memcpy(bctx->ipad, <token> keylen); <answer> key, 
memset(bctx->ipad + keylen, 0, bs <token> keylen); <answer> - 
if (!test_bit(FLAGS_AUTO_XOR, &sham.flags)) <token> <answer> { 
<token> bctx->ipad, bs); <answer> memcpy(bctx->opad, 
for (i = 0; i <token> bs; i++) { <answer> < 
bctx->ipad[i] <token> HMAC_IPAD_VALUE; <answer> ^= 
bctx->opad[i] ^= <token> <answer> HMAC_OPAD_VALUE; 
<token> err; <answer> return 
static int omap_sham_cra_init_alg(struct crypto_tfm *tfm, const char <token> <answer> *alg_base) 
<token> omap_sham_ctx *tctx = crypto_tfm_ctx(tfm); <answer> struct 
const <token> *alg_name = crypto_tfm_alg_name(tfm); <answer> char 
<token> = value; <answer> dd->queue.max_qlen 
return <token> <answer> size; 
<token> DEVICE_ATTR_RW(queue_len); <answer> static 
<token> DEVICE_ATTR_RW(fallback); <answer> static 
static struct attribute *omap_sham_attrs[] <token> { <answer> = 
static <token> struct attribute_group omap_sham_attr_group = { <answer> const 
.attrs = <token> <answer> omap_sham_attrs, 
static int <token> platform_device *pdev) <answer> omap_sham_probe(struct 
struct <token> *dd; <answer> omap_sham_dev 
struct <token> *dev = &pdev->dev; <answer> device 
struct <token> res; <answer> resource 
dma_cap_mask_t <token> <answer> mask; 
int <token> i, j; <answer> err, 
<token> rev; <answer> u32 
dd <token> devm_kzalloc(dev, sizeof(struct omap_sham_dev), GFP_KERNEL); <answer> = 
if (dd == <token> { <answer> NULL) 
dev_err(dev, "unable to alloc <token> struct.\n"); <answer> data 
err <token> -ENOMEM; <answer> = 
goto <token> <answer> data_err; 
<token> = dev; <answer> dd->dev 
<token> dd); <answer> platform_set_drvdata(pdev, 
tasklet_init(&dd->done_task, omap_sham_done_task, (unsigned <token> <answer> long)dd); 
<token> OMAP_SHAM_QUEUE_LENGTH); <answer> crypto_init_queue(&dd->queue, 
<token> = (dev->of_node) ? omap_sham_get_res_of(dd, dev, &res) : <answer> err 
omap_sham_get_res_pdev(dd, <token> &res); <answer> pdev, 
if <token> <answer> (err) 
goto <token> <answer> data_err; 
dd->io_base <token> devm_ioremap_resource(dev, &res); <answer> = 
<token> (IS_ERR(dd->io_base)) { <answer> if 
err <token> PTR_ERR(dd->io_base); <answer> = 
<token> data_err; <answer> goto 
dd->phys_base = <token> <answer> res.start; 
<token> = devm_request_irq(dev, dd->irq, dd->pdata->intr_hdlr, <answer> err 
IRQF_TRIGGER_NONE, <token> dd); <answer> dev_name(dev), 
<token> (err) { <answer> if 
<token> "unable to request irq %d, err = %d\n", <answer> dev_err(dev, 
<token> err); <answer> dd->irq, 
goto <token> <answer> data_err; 
dma_cap_set(DMA_SLAVE, <token> <answer> mask); 
dd->dma_lch <token> dma_request_chan(dev, "rx"); <answer> = 
if (IS_ERR(dd->dma_lch)) <token> <answer> { 
err = <token> <answer> PTR_ERR(dd->dma_lch); 
if <token> == -EPROBE_DEFER) <answer> (err 
goto <token> <answer> data_err; 
dd->polling_mode <token> 1; <answer> = 
<token> "using polling mode instead of dma\n"); <answer> dev_dbg(dev, 
dd->flags |= <token> <answer> dd->pdata->flags; 
sham.flags |= <token> <answer> dd->pdata->flags; 
<token> DEFAULT_AUTOSUSPEND_DELAY); <answer> pm_runtime_set_autosuspend_delay(dev, 
dd->fallback_sz = <token> <answer> OMAP_SHA_DMA_THRESHOLD; 
<token> = pm_runtime_resume_and_get(dev); <answer> err 
<token> (err < 0) { <answer> if 
dev_err(dev, "failed <token> get sync: %d\n", err); <answer> to 
goto <token> <answer> err_pm; 
<token> = omap_sham_read(dd, SHA_REG_REV(dd)); <answer> rev 
dev_info(dev, <token> accel on OMAP rev %u.%u\n", <answer> "hw 
(rev & <token> >> dd->pdata->major_shift, <answer> dd->pdata->major_mask) 
(rev & dd->pdata->minor_mask) >> <token> <answer> dd->pdata->minor_shift); 
list_add_tail(&dd->list, <token> <answer> &sham.dev_list); 
dd->engine = <token> 1); <answer> crypto_engine_alloc_init(dev, 
if <token> { <answer> (!dd->engine) 
err = <token> <answer> -ENOMEM; 
<token> err_engine; <answer> goto 
<token> = crypto_engine_start(dd->engine); <answer> err 
<token> (err) <answer> if 
<token> err_engine_start; <answer> goto 
for <token> = 0; i < dd->pdata->algs_info_size; i++) { <answer> (i 
<token> (dd->pdata->algs_info[i].registered) <answer> if 
for (j = 0; <token> < dd->pdata->algs_info[i].size; j++) { <answer> j 
struct ahash_engine_alg <token> <answer> *ealg; 
struct <token> *alg; <answer> ahash_alg 
<token> = &dd->pdata->algs_info[i].algs_list[j]; <answer> ealg 
<token> = &ealg->base; <answer> alg 
<token> = omap_sham_export; <answer> alg->export 
<token> = omap_sham_import; <answer> alg->import 
alg->halg.statesize = <token> omap_sham_reqctx) + <answer> sizeof(struct 
err <token> crypto_engine_register_ahash(ealg); <answer> = 
if <token> <answer> (err) 
<token> err_algs; <answer> goto 
<token> = sysfs_create_group(&dev->kobj, &omap_sham_attr_group); <answer> err 
<token> (err) { <answer> if 
dev_err(dev, "could not <token> sysfs device attrs\n"); <answer> create 
goto <token> <answer> err_algs; 
return <token> <answer> 0; 
for (i = dd->pdata->algs_info_size <token> 1; i >= 0; i--) <answer> - 
for (j = dd->pdata->algs_info[i].registered - 1; j >= <token> j--) <answer> 0; 
if <token> <answer> (!dd->polling_mode) 
<token> "initialization failed.\n"); <answer> dev_err(dev, 
return <token> <answer> err; 
static void omap_sham_remove(struct <token> *pdev) <answer> platform_device 
struct omap_sham_dev <token> <answer> *dd; 
<token> i, j; <answer> int 
dd = <token> <answer> platform_get_drvdata(pdev); 
for (i = dd->pdata->algs_info_size - 1; i >= 0; <token> <answer> i--) 
for (j = <token> - 1; j >= 0; j--) { <answer> dd->pdata->algs_info[i].registered 
<token> (!dd->polling_mode) <answer> if 
sysfs_remove_group(&dd->dev->kobj, <token> <answer> &omap_sham_attr_group); 
<token> struct platform_driver omap_sham_driver = { <answer> static 
.probe = <token> <answer> omap_sham_probe, 
.remove_new <token> omap_sham_remove, <answer> = 
.driver = <token> <answer> { 
.name <token> "omap-sham", <answer> = 
.of_match_table = <token> <answer> omap_sham_of_match, 
MODULE_DESCRIPTION("OMAP <token> hw acceleration support."); <answer> SHA1/MD5 
<token> v2"); <answer> MODULE_LICENSE("GPL 
<token> Kasatkin"); <answer> MODULE_AUTHOR("Dmitry 
#define RTL819x_2GHZ_CH01_11 <token> <answer> \ 
REG_RULE(2412-10, 2462+10, 40, 0, <token> 0) <answer> 20, 
#define <token> \ <answer> RTL819x_2GHZ_CH12_13 
<token> 2472+10, 40, 0, 20,\ <answer> REG_RULE(2467-10, 
#define <token> \ <answer> RTL819x_2GHZ_CH14 
REG_RULE(2484-10, 2484+10, 40, 0, 20, <token> <answer> \ 
<token> | \ <answer> NL80211_RRF_PASSIVE_SCAN 
if (!(reg_rule->flags & <token> <answer> NL80211_RRF_NO_IBSS)) 
ch->flags <token> ~IEEE80211_CHAN_NO_IBSS; <answer> &= 
if (!(reg_rule->flags <token> <answer> & 
<token> &= <answer> ch->flags 
} else <token> <answer> { 
<token> (ch->beacon_found) <answer> if 
ch->flags <token> ~(IEEE80211_CHAN_NO_IBSS | <answer> &= 
if (initiator != NL80211_REGDOM_SET_BY_COUNTRY_IE) <token> <answer> { 
static void _rtl_reg_apply_radar_flags(struct <token> *wiphy) <answer> wiphy 
struct ieee80211_supported_band <token> <answer> *sband; 
<token> ieee80211_channel *ch; <answer> struct 
<token> int i; <answer> unsigned 
<token> (!wiphy->bands[NL80211_BAND_5GHZ]) <answer> if 
sband <token> wiphy->bands[NL80211_BAND_5GHZ]; <answer> = 
for (i <token> 0; i < sband->n_channels; i++) { <answer> = 
<token> = &sband->channels[i]; <answer> ch 
<token> (!_rtl_is_radar_freq(ch->center_freq)) <answer> if 
if (!(ch->flags <token> IEEE80211_CHAN_DISABLED)) <answer> & 
ch->flags |= <token> | <answer> IEEE80211_CHAN_RADAR 
<token> | <answer> IEEE80211_CHAN_NO_IBSS 
<token> void _rtl_reg_apply_world_flags(struct wiphy *wiphy, <answer> static 
enum <token> initiator, <answer> nl80211_reg_initiator 
struct rtl_regulatory <token> <answer> *reg) 
<token> initiator); <answer> _rtl_reg_apply_beaconing_flags(wiphy, 
<token> initiator); <answer> _rtl_reg_apply_active_scan_flags(wiphy, 
static int _rtl_reg_notifier_apply(struct wiphy <token> <answer> *wiphy, 
struct regulatory_request <token> <answer> *request, 
<token> rtl_regulatory *reg) <answer> struct 
#include <token> <answer> <trace/syscall.h> 
<token> <trace/events/syscalls.h> <answer> #include 
<token> <linux/syscalls.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
return !strcmp(sym + 3, name + <token> <answer> 3); 
<token> ARCH_TRACE_IGNORE_COMPAT_SYSCALLS <answer> #ifdef 
<token> int <answer> static 
trace_get_syscall_nr(struct task_struct *task, <token> pt_regs *regs) <answer> struct 
if <token> <answer> (unlikely(arch_trace_is_compat_syscall(regs))) 
<token> -1; <answer> return 
<token> syscall_get_nr(task, regs); <answer> return 
static <token> int <answer> inline 
trace_get_syscall_nr(struct task_struct <token> struct pt_regs *regs) <answer> *task, 
return syscall_get_nr(task, <token> <answer> regs); 
<token> <linux/io.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> <linux/types.h> <answer> #include 
#include <token> <answer> <asm/bootinfo.h> 
<token> <loongson.h> <answer> #include 
<token> <cs5536/cs5536.h> <answer> #include 
<token> "ec_kb3310b.h" <answer> #include 
static <token> reset_cpu(void) <answer> void 
writel(readl(LOONGSON_CHIPCFG) | 0x7, <token> <answer> LOONGSON_CHIPCFG); 
u32 hi, <token> <answer> lo; 
_rdmsr(DIVIL_MSR_REG(DIVIL_SOFT_RESET), &hi, <token> <answer> &lo); 
lo <token> 0x00000001; <answer> |= 
<token> hi, lo); <answer> _wrmsr(DIVIL_MSR_REG(DIVIL_SOFT_RESET), 
static void <token> <answer> fl2f_shutdown(void) 
u32 hi, <token> val; <answer> lo, 
int <token> <answer> gpio_base; 
#include <token> <answer> <linux/errno.h> 
<token> <linux/export.h> <answer> #include 
#include <token> <answer> <linux/sched.h> 
<token> <linux/sched/debug.h> <answer> #include 
#include <token> <answer> <linux/sched/task.h> 
#include <token> <answer> <linux/sched/task_stack.h> 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/mm.h> <answer> #include 
#include <token> <answer> <linux/fs.h> 
#include <token> <answer> <linux/smp.h> 
#include <token> <answer> <linux/stddef.h> 
<token> <linux/ptrace.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> <linux/user.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
#include <token> <answer> <linux/compat.h> 
#include <token> <answer> <linux/tick.h> 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/cpu.h> 
#include <token> <answer> <linux/perf_event.h> 
#include <token> <answer> <linux/elfcore.h> 
<token> <linux/sysrq.h> <answer> #include 
<token> <linux/nmi.h> <answer> #include 
<token> <linux/context_tracking.h> <answer> #include 
<token> <linux/signal.h> <answer> #include 
<token> <linux/uaccess.h> <answer> #include 
<token> <asm/page.h> <answer> #include 
#include <token> <answer> <asm/pgalloc.h> 
#include <token> <answer> <asm/processor.h> 
<token> <asm/pstate.h> <answer> #include 
<token> <asm/elf.h> <answer> #include 
<token> <asm/fpumacro.h> <answer> #include 
<token> <asm/head.h> <answer> #include 
#include <token> <answer> <asm/cpudata.h> 
<token> <asm/mmu_context.h> <answer> #include 
#include <token> <answer> <asm/unistd.h> 
#include <token> <answer> <asm/hypervisor.h> 
<token> <asm/syscalls.h> <answer> #include 
#include <token> <answer> <asm/irq_regs.h> 
#include <token> <answer> <asm/smp.h> 
<token> <asm/pcr.h> <answer> #include 
<token> "kstack.h" <answer> #include 
<token> __volatile__( <answer> __asm__ 
"rdpr %%pstate, <token> <answer> %0\n\t" 
"andn %0, %1, <token> <answer> %0\n\t" 
<token> %0, %%g0, %%pstate" <answer> "wrpr 
: <token> (pstate) <answer> "=&r" 
<token> "i" (PSTATE_IE)); <answer> : 
if (!need_resched() <token> !cpu_is_offline(smp_processor_id())) { <answer> && 
static <token> __global_reg_poll(struct global_reg_snapshot *gp) <answer> void 
<token> limit = 0; <answer> int 
while (!gp->thread && ++limit < 100) <token> <answer> { 
<token> arch_trigger_cpumask_backtrace(const cpumask_t *mask, int exclude_cpu) <answer> void 
struct thread_info <token> = current_thread_info(); <answer> *tp 
struct pt_regs *regs <token> get_irq_regs(); <answer> = 
unsigned long <token> <answer> flags; 
<token> this_cpu, cpu; <answer> int 
<token> (!regs) <answer> if 
regs <token> tp->kregs; <answer> = 
spin_lock_irqsave(&global_cpu_snapshot_lock, <token> <answer> flags); 
<token> = raw_smp_processor_id(); <answer> this_cpu 
memset(global_cpu_snapshot, <token> sizeof(global_cpu_snapshot)); <answer> 0, 
if (cpumask_test_cpu(this_cpu, <token> && this_cpu != exclude_cpu) <answer> mask) 
__global_reg_self(tp, regs, <token> <answer> this_cpu); 
for_each_cpu(cpu, <token> { <answer> mask) 
<token> global_reg_snapshot *gp; <answer> struct 
if <token> == exclude_cpu) <answer> (cpu 
gp <token> &global_cpu_snapshot[cpu].reg; <answer> = 
tp <token> gp->thread; <answer> = 
printk("%c <token> TSTATE[%016lx] TPC[%016lx] TNPC[%016lx] TASK[%s:%d]\n", <answer> CPU[%3d]: 
(cpu == this_cpu ? '*' : ' <token> cpu, <answer> '), 
gp->tstate, <token> gp->tnpc, <answer> gp->tpc, 
((tp && <token> ? tp->task->comm : "NULL"), <answer> tp->task) 
((tp && tp->task) <token> tp->task->pid : -1)); <answer> ? 
<token> (gp->tstate & TSTATE_PRIV) { <answer> if 
printk(" TPC[%pS] O7[%pS] I7[%pS] <token> <answer> RPC[%pS]\n", 
<token> *) gp->tpc, <answer> (void 
(void *) <token> <answer> gp->o7, 
(void *) <token> <answer> gp->i7, 
(void *) <token> <answer> gp->rpc); 
<token> else { <answer> } 
printk(" TPC[%lx] O7[%lx] <token> RPC[%lx]\n", <answer> I7[%lx] 
<token> gp->o7, gp->i7, gp->rpc); <answer> gp->tpc, 
memset(global_cpu_snapshot, <token> sizeof(global_cpu_snapshot)); <answer> 0, 
<token> flags); <answer> spin_unlock_irqrestore(&global_cpu_snapshot_lock, 
<token> CONFIG_MAGIC_SYSRQ <answer> #ifdef 
static void sysrq_handle_globreg(u8 <token> <answer> key) 
static <token> struct sysrq_key_op sparc_globalreg_op = { <answer> const 
.handler = <token> <answer> sysrq_handle_globreg, 
.help_msg = <token> <answer> "global-regs(y)", 
.action_msg = "Show Global CPU <token> <answer> Regs", 
static void <token> this_cpu) <answer> __global_pmu_self(int 
struct <token> *pp; <answer> global_pmu_snapshot 
<token> i, num; <answer> int 
<token> (!pcr_ops) <answer> if 
<token> = &global_cpu_snapshot[this_cpu].pmu; <answer> pp 
num <token> 1; <answer> = 
if (tlb_type <token> hypervisor && <answer> == 
sun4v_chip_type <token> SUN4V_CHIP_NIAGARA4) <answer> >= 
num <token> 4; <answer> = 
for (i = 0; i < <token> i++) { <answer> num; 
pp->pcr[i] = <token> <answer> pcr_ops->read_pcr(i); 
pp->pic[i] <token> pcr_ops->read_pic(i); <answer> = 
static <token> __global_pmu_poll(struct global_pmu_snapshot *pp) <answer> void 
int limit = <token> <answer> 0; 
<token> (!pp->pcr[0] && ++limit < 100) { <answer> while 
static <token> pmu_snapshot_all_cpus(void) <answer> void 
unsigned <token> flags; <answer> long 
<token> this_cpu, cpu; <answer> int 
<token> flags); <answer> spin_lock_irqsave(&global_cpu_snapshot_lock, 
memset(global_cpu_snapshot, <token> sizeof(global_cpu_snapshot)); <answer> 0, 
<token> = raw_smp_processor_id(); <answer> this_cpu 
for_each_online_cpu(cpu) <token> <answer> { 
struct global_pmu_snapshot <token> = &global_cpu_snapshot[cpu].pmu; <answer> *pp 
printk("%c <token> PCR[%08lx:%08lx:%08lx:%08lx] PIC[%08lx:%08lx:%08lx:%08lx]\n", <answer> CPU[%3d]: 
(cpu == this_cpu ? '*' : <token> '), cpu, <answer> ' 
pp->pcr[0], pp->pcr[1], pp->pcr[2], <token> <answer> pp->pcr[3], 
pp->pic[0], <token> pp->pic[2], pp->pic[3]); <answer> pp->pic[1], 
<token> 0, sizeof(global_cpu_snapshot)); <answer> memset(global_cpu_snapshot, 
spin_unlock_irqrestore(&global_cpu_snapshot_lock, <token> <answer> flags); 
<token> void sysrq_handle_globpmu(u8 key) <answer> static 
static const struct sysrq_key_op sparc_globalpmu_op <token> { <answer> = 
.handler = <token> <answer> sysrq_handle_globpmu, 
.help_msg = <token> <answer> "global-pmu(x)", 
<token> = "Show Global PMU Regs", <answer> .action_msg 
static <token> __init sparc_sysrq_init(void) <answer> int 
<token> ret = register_sysrq_key('y', &sparc_globalreg_op); <answer> int 
if <token> <answer> (!ret) 
ret = register_sysrq_key('x', <token> <answer> &sparc_globalpmu_op); 
return <token> <answer> ret; 
csp <token> ~15UL; <answer> &= 
distance = fp - <token> <answer> psp; 
rval = (csp - <token> <answer> distance); 
if (raw_copy_in_user((void <token> *)rval, (void __user *)psp, distance)) <answer> __user 
rval <token> 0; <answer> = 
<token> if (!stack_64bit) { <answer> else 
<token> (put_user(((u32)csp), <answer> if 
&(((struct reg_window32 <token> *)rval)->ins[6]))) <answer> __user 
rval <token> 0; <answer> = 
} <token> { <answer> else 
<token> (put_user(((u64)csp - STACK_BIAS), <answer> if 
&(((struct reg_window __user <token> <answer> *)rval)->ins[6]))) 
rval = <token> <answer> 0; 
rval = <token> - STACK_BIAS; <answer> rval 
<token> rval; <answer> return 
int copy_thread(struct task_struct <token> const struct kernel_clone_args *args) <answer> *p, 
<token> long clone_flags = args->flags; <answer> unsigned 
unsigned <token> sp = args->stack; <answer> long 
unsigned long tls = <token> <answer> args->tls; 
struct thread_info *t <token> task_thread_info(p); <answer> = 
<token> pt_regs *regs = current_pt_regs(); <answer> struct 
<token> sparc_stackf *parent_sf; <answer> struct 
unsigned long <token> <answer> child_stack_sz; 
<token> *child_trap_frame; <answer> char 
int arch_dup_task_struct(struct task_struct *dst, struct <token> *src) <answer> task_struct 
if (adi_capable()) <token> <answer> { 
register unsigned long <token> <answer> tmp_mcdper; 
__asm__ <token> <answer> __volatile__( 
#define pr_fmt(fmt) KBUILD_MODNAME ": " <token> <answer> fmt 
<token> "m5602_mt9m111.h" <answer> #include 
static int mt9m111_s_ctrl(struct v4l2_ctrl <token> <answer> *ctrl); 
<token> void mt9m111_dump_registers(struct sd *sd); <answer> static 
static const unsigned char preinit_mt9m111[][4] <token> { <answer> = 
{BRIDGE, <token> 0x02, 0x00}, <answer> M5602_XB_MCU_CLK_DIV, 
{BRIDGE, <token> 0xb0, 0x00}, <answer> M5602_XB_MCU_CLK_CTRL, 
{BRIDGE, M5602_XB_SEN_CLK_DIV, <token> 0x00}, <answer> 0x00, 
{BRIDGE, <token> 0xb0, 0x00}, <answer> M5602_XB_SEN_CLK_CTRL, 
{BRIDGE, M5602_XB_SENSOR_TYPE, 0x0d, <token> <answer> 0x00}, 
{BRIDGE, M5602_XB_SENSOR_CTRL, <token> 0x00}, <answer> 0x00, 
{BRIDGE, <token> 0xc0, 0x00}, <answer> M5602_XB_ADC_CTRL, 
{BRIDGE, M5602_XB_SENSOR_TYPE, <token> 0x00}, <answer> 0x09, 
{SENSOR, <token> 0x00, 0x00}, <answer> MT9M111_PAGE_MAP, 
<token> MT9M111_SC_RESET, <answer> {SENSOR, 
MT9M111_RESET <token> <answer> | 
MT9M111_RESTART <token> <answer> | 
<token> | <answer> MT9M111_ANALOG_STANDBY 
<token> | <answer> MT9M111_SHOW_BAD_FRAMES 
<token> | <answer> MT9M111_RESTART_BAD_FRAMES 
{BRIDGE, M5602_XB_GPIO_DIR, <token> 0x00}, <answer> 0x05, 
{BRIDGE, M5602_XB_GPIO_DAT, <token> 0x00}, <answer> 0x04, 
{BRIDGE, M5602_XB_GPIO_EN_H, <token> 0x00}, <answer> 0x3e, 
<token> M5602_XB_GPIO_DIR_H, 0x3e, 0x00}, <answer> {BRIDGE, 
<token> M5602_XB_GPIO_DAT_H, 0x02, 0x00}, <answer> {BRIDGE, 
{BRIDGE, <token> 0xff, 0x00}, <answer> M5602_XB_GPIO_EN_L, 
{BRIDGE, M5602_XB_GPIO_DIR_L, 0xff, <token> <answer> 0x00}, 
{BRIDGE, M5602_XB_GPIO_DAT_L, 0x00, <token> <answer> 0x00}, 
{BRIDGE, M5602_XB_SEN_CLK_DIV, <token> 0x00}, <answer> 0x00, 
{BRIDGE, M5602_XB_SEN_CLK_CTRL, <token> 0x00}, <answer> 0xb0, 
{BRIDGE, M5602_XB_GPIO_DIR, 0x07, <token> <answer> 0x00}, 
{BRIDGE, M5602_XB_GPIO_DAT, <token> 0x00}, <answer> 0x0b, 
{BRIDGE, M5602_XB_GPIO_EN_H, <token> 0x00}, <answer> 0x06, 
<token> M5602_XB_GPIO_EN_L, 0x00, 0x00}, <answer> {BRIDGE, 
{BRIDGE, M5602_XB_I2C_CLK_DIV, 0x0a, <token> <answer> 0x00} 
static <token> unsigned char init_mt9m111[][4] = { <answer> const 
<token> M5602_XB_MCU_CLK_DIV, 0x02, 0x00}, <answer> {BRIDGE, 
{BRIDGE, M5602_XB_MCU_CLK_CTRL, 0xb0, <token> <answer> 0x00}, 
{BRIDGE, <token> 0x00, 0x00}, <answer> M5602_XB_SEN_CLK_DIV, 
{BRIDGE, M5602_XB_SEN_CLK_CTRL, <token> 0x00}, <answer> 0xb0, 
{BRIDGE, <token> 0xc0, 0x00}, <answer> M5602_XB_ADC_CTRL, 
{BRIDGE, M5602_XB_SENSOR_TYPE, 0x09, <token> <answer> 0x00}, 
<token> M5602_XB_GPIO_EN_H, 0x06, 0x00}, <answer> {BRIDGE, 
{BRIDGE, M5602_XB_GPIO_EN_L, 0x00, <token> <answer> 0x00}, 
<token> M5602_XB_GPIO_DAT, 0x04, 0x00}, <answer> {BRIDGE, 
{BRIDGE, M5602_XB_GPIO_DIR_H, <token> 0x00}, <answer> 0x3e, 
{BRIDGE, M5602_XB_GPIO_DIR_L, 0xff, <token> <answer> 0x00}, 
{BRIDGE, M5602_XB_GPIO_DAT_H, 0x02, <token> <answer> 0x00}, 
{BRIDGE, M5602_XB_GPIO_DAT_L, 0x00, <token> <answer> 0x00}, 
{BRIDGE, M5602_XB_GPIO_DIR, <token> 0x00}, <answer> 0x07, 
{BRIDGE, <token> 0x0b, 0x00}, <answer> M5602_XB_GPIO_DAT, 
{BRIDGE, M5602_XB_I2C_CLK_DIV, 0x0a, <token> <answer> 0x00}, 
<token> MT9M111_SC_RESET, 0x00, 0x29}, <answer> {SENSOR, 
{SENSOR, <token> 0x00, 0x00}, <answer> MT9M111_PAGE_MAP, 
{SENSOR, <token> 0x00, 0x08}, <answer> MT9M111_SC_RESET, 
{SENSOR, <token> 0x00, 0x01}, <answer> MT9M111_PAGE_MAP, 
{SENSOR, <token> 0x00, <answer> MT9M111_CP_OPERATING_MODE_CTL, 
{SENSOR, MT9M111_CP_LENS_CORRECTION_1, <token> 0x2a}, <answer> 0x04, 
{SENSOR, MT9M111_CP_DEFECT_CORR_CONTEXT_A, <token> <answer> 0x00, 
<token> MT9M111_CP_DEFECT_CORR_CONTEXT_B, 0x00, <answer> {SENSOR, 
{SENSOR, <token> 0x00, 0x00}, <answer> MT9M111_CP_LUMA_OFFSET, 
<token> MT9M111_CP_LUMA_CLIP, 0xff, 0x00}, <answer> {SENSOR, 
<token> MT9M111_CP_OUTPUT_FORMAT_CTL2_CONTEXT_A, 0x14, 0x00}, <answer> {SENSOR, 
<token> MT9M111_CP_OUTPUT_FORMAT_CTL2_CONTEXT_B, 0x14, 0x00}, <answer> {SENSOR, 
<token> 0xcd, 0x00, 0x0e}, <answer> {SENSOR, 
{SENSOR, 0xd0, 0x00, <token> <answer> 0x40}, 
{SENSOR, MT9M111_PAGE_MAP, 0x00, <token> <answer> 0x02}, 
<token> MT9M111_CC_AUTO_EXPOSURE_PARAMETER_18, 0x00, 0x00}, <answer> {SENSOR, 
<token> MT9M111_CC_AWB_PARAMETER_7, 0xef, 0x03}, <answer> {SENSOR, 
<token> MT9M111_PAGE_MAP, 0x00, 0x00}, <answer> {SENSOR, 
<token> 0x33, 0x03, 0x49}, <answer> {SENSOR, 
<token> 0x34, 0xc0, 0x19}, <answer> {SENSOR, 
{SENSOR, 0x3f, 0x20, <token> <answer> 0x20}, 
{SENSOR, <token> 0x20, 0x20}, <answer> 0x40, 
{SENSOR, 0x5a, 0xc0, <token> <answer> 0x0a}, 
<token> 0x70, 0x7b, 0x0a}, <answer> {SENSOR, 
{SENSOR, 0x71, <token> 0x00}, <answer> 0xff, 
{SENSOR, 0x72, <token> 0x0e}, <answer> 0x19, 
{SENSOR, <token> 0x18, 0x0f}, <answer> 0x73, 
<token> 0x74, 0x57, 0x32}, <answer> {SENSOR, 
{SENSOR, 0x75, <token> 0x34}, <answer> 0x56, 
{SENSOR, <token> 0x73, 0x35}, <answer> 0x76, 
{SENSOR, 0x77, 0x30, <token> <answer> 0x12}, 
{SENSOR, 0x78, 0x79, <token> <answer> 0x02}, 
{SENSOR, 0x79, <token> 0x06}, <answer> 0x75, 
{SENSOR, 0x7a, 0x77, <token> <answer> 0x0a}, 
{SENSOR, 0x7b, 0x78, <token> <answer> 0x09}, 
{SENSOR, <token> 0x7d, 0x06}, <answer> 0x7c, 
{SENSOR, <token> 0x31, 0x10}, <answer> 0x7d, 
<token> 0x7e, 0x00, 0x7e}, <answer> {SENSOR, 
{SENSOR, 0x80, 0x59, <token> <answer> 0x04}, 
<token> 0x81, 0x59, 0x04}, <answer> {SENSOR, 
<token> 0x82, 0x57, 0x0a}, <answer> {SENSOR, 
{SENSOR, 0x83, 0x58, <token> <answer> 0x0b}, 
{SENSOR, 0x84, 0x47, <token> <answer> 0x0c}, 
<token> 0x85, 0x48, 0x0e}, <answer> {SENSOR, 
{SENSOR, 0x86, 0x5b, <token> <answer> 0x02}, 
{SENSOR, <token> 0x00, 0x5c}, <answer> 0x87, 
{SENSOR, <token> 0x00, MT9M111_SEL_CONTEXT_B}, <answer> MT9M111_CONTEXT_CONTROL, 
<token> 0x60, 0x00, 0x80}, <answer> {SENSOR, 
{SENSOR, 0x61, 0x00, <token> <answer> 0x00}, 
{SENSOR, <token> 0x00, 0x00}, <answer> 0x62, 
{SENSOR, <token> 0x00, 0x00}, <answer> 0x63, 
{SENSOR, 0x64, <token> 0x00}, <answer> 0x00, 
<token> -ENODEV; <answer> return 
<token> D_PROBE, "Probing for a mt9m111 sensor\n"); <answer> gspca_dbg(gspca_dev, 
<token> <linux/kvm_host.h> <answer> #include 
#include <token> <answer> <asm/kvm_emulate.h> 
<token> <trace/events/kvm.h> <answer> #include 
#include <token> <answer> "trace.h" 
void kvm_mmio_write_buf(void *buf, unsigned int len, <token> long data) <answer> unsigned 
<token> *datap = NULL; <answer> void 
union <token> <answer> { 
u8 <token> <answer> byte; 
<token> hword; <answer> u16 
u32 <token> <answer> word; 
u64 <token> <answer> dword; 
<token> tmp; <answer> } 
switch (len) <token> <answer> { 
case <token> <answer> 1: 
<token> = data; <answer> tmp.byte 
datap = <token> <answer> &tmp.byte; 
case <token> <answer> 2: 
<token> = data; <answer> tmp.hword 
datap <token> &tmp.hword; <answer> = 
<token> 4: <answer> case 
tmp.word = <token> <answer> data; 
datap = <token> <answer> &tmp.word; 
<token> 8: <answer> case 
<token> = data; <answer> tmp.dword 
datap = <token> <answer> &tmp.dword; 
memcpy(buf, datap, <token> <answer> len); 
unsigned long kvm_mmio_read_buf(const void *buf, <token> int len) <answer> unsigned 
unsigned long data = <token> <answer> 0; 
<token> { <answer> union 
<token> hword; <answer> u16 
<token> word; <answer> u32 
u64 <token> <answer> dword; 
} <token> <answer> tmp; 
switch <token> { <answer> (len) 
<token> 1: <answer> case 
data = *(u8 <token> <answer> *)buf; 
case <token> <answer> 2: 
memcpy(&tmp.hword, <token> len); <answer> buf, 
data <token> tmp.hword; <answer> = 
<token> 4: <answer> case 
memcpy(&tmp.word, <token> len); <answer> buf, 
<token> = tmp.word; <answer> data 
case <token> <answer> 8: 
<token> buf, len); <answer> memcpy(&tmp.dword, 
data <token> tmp.dword; <answer> = 
return <token> <answer> data; 
int kvm_handle_mmio_return(struct kvm_vcpu <token> <answer> *vcpu) 
unsigned long <token> <answer> data; 
<token> int len; <answer> unsigned 
<token> mask; <answer> int 
return <token> <answer> 0; 
int <token> kvm_vcpu *vcpu, phys_addr_t fault_ipa) <answer> io_mem_abort(struct 
struct kvm_run *run = <token> <answer> vcpu->run; 
<token> long data; <answer> unsigned 
unsigned long <token> <answer> rt; 
int <token> <answer> ret; 
bool <token> <answer> is_write; 
<token> len; <answer> int 
<token> data_buf[8]; <answer> u8 
if <token> { <answer> (!kvm_vcpu_dabt_isvalid(vcpu)) 
<token> kvm_vcpu_get_esr(vcpu), <answer> trace_kvm_mmio_nisv(*vcpu_pc(vcpu), 
kvm_vcpu_get_hfar(vcpu), <token> <answer> fault_ipa); 
if <token> <answer> (test_bit(KVM_ARCH_FLAG_RETURN_NISV_IO_ABORT_TO_USER, 
&vcpu->kvm->arch.flags)) <token> <answer> { 
<token> = KVM_EXIT_ARM_NISV; <answer> run->exit_reason 
run->arm_nisv.esr_iss = <token> <answer> kvm_vcpu_dabt_iss_nisv_sanitized(vcpu); 
run->arm_nisv.fault_ipa = <token> <answer> fault_ipa; 
<token> 0; <answer> return 
return <token> <answer> -ENOSYS; 
is_write <token> kvm_vcpu_dabt_iswrite(vcpu); <answer> = 
<token> = kvm_vcpu_dabt_get_as(vcpu); <answer> len 
<token> = kvm_vcpu_dabt_get_rd(vcpu); <answer> rt 
if <token> { <answer> (is_write) 
data = vcpu_data_guest_to_host(vcpu, <token> rt), <answer> vcpu_get_reg(vcpu, 
<token> len, fault_ipa, &data); <answer> trace_kvm_mmio(KVM_TRACE_MMIO_WRITE, 
<token> len, data); <answer> kvm_mmio_write_buf(data_buf, 
ret = kvm_io_bus_write(vcpu, KVM_MMIO_BUS, fault_ipa, <token> <answer> len, 
} else <token> <answer> { 
<token> len, <answer> trace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, 
fault_ipa, <token> <answer> NULL); 
ret = kvm_io_bus_read(vcpu, KVM_MMIO_BUS, fault_ipa, <token> <answer> len, 
#define dbg_port(hc,label,num,value) <token> <answer> \ 
ohci_dbg <token> \ <answer> (hc, 
"%s roothub.portstatus [%d] " <token> <answer> \ 
"= 0x%08x%s%s%s%s%s%s%s%s%s%s%s%s\n", <token> <answer> \ 
label, num, <token> \ <answer> value, 
<token> & RH_PS_PRSC) ? " PRSC" : "", \ <answer> (value 
<token> & RH_PS_OCIC) ? " OCIC" : "", \ <answer> (value 
(value & RH_PS_PSSC) ? " <token> : "", \ <answer> PSSC" 
(value & RH_PS_PESC) <token> " PESC" : "", \ <answer> ? 
<token> & RH_PS_CSC) ? " CSC" : "", \ <answer> (value 
(value & RH_PS_LSDA) ? " LSDA" <token> "", \ <answer> : 
(value & RH_PS_PPS) ? " <token> : "", \ <answer> PPS" 
(value & RH_PS_PRS) ? <token> PRS" : "", \ <answer> " 
(value & RH_PS_POCI) ? " <token> : "", \ <answer> POCI" 
(value & RH_PS_PSS) ? " PSS" : <token> \ <answer> "", 
(value & RH_PS_PES) ? " <token> : "", \ <answer> PES" 
(value & RH_PS_CCS) <token> " CCS" : "" \ <answer> ? 
<token> (ohci, "stopping schedules ...\n"); <answer> ohci_dbg 
ohci->autostop = <token> <answer> 0; 
<token> (&ohci->lock); <answer> spin_unlock_irq 
msleep <token> <answer> (8); 
spin_lock_irq <token> <answer> (&ohci->lock); 
if (ohci->flags & <token> { <answer> OHCI_QUIRK_GLOBAL_SUSPEND) 
__hc32 __iomem *portstat = <token> <answer> ohci->regs->roothub.portstatus; 
<token> i; <answer> int 
unsigned <token> <answer> temp; 
for (i = 0; i < ohci->num_ports; (++i, <token> { <answer> ++portstat)) 
<token> = ohci_readl(ohci, portstat); <answer> temp 
if ((temp & <token> | RH_PS_PSS)) == <answer> (RH_PS_PES 
ohci_writel(ohci, RH_PS_PSS, <token> <answer> portstat); 
ohci->hc_control &= <token> <answer> ~OHCI_CTRL_HCFS; 
ohci->hc_control |= <token> <answer> OHCI_USB_SUSPEND; 
ohci_writel (ohci, <token> &ohci->regs->control); <answer> ohci->hc_control, 
(void) ohci_readl <token> &ohci->regs->control); <answer> (ohci, 
rhsc_enable = <token> &ohci->regs->intrenable) & <answer> ohci_readl(ohci, 
switch <token> & OHCI_CTRL_HCFS) { <answer> (ohci->hc_control 
case <token> <answer> OHCI_USB_OPER: 
if (!ohci->autostop) <token> <answer> { 
if <token> || <answer> (any_connected 
<token> { <answer> ->self.root_hub->dev)) 
<token> (rhsc_enable) <answer> if 
poll_rh <token> 0; <answer> = 
<token> else { <answer> } 
ohci->autostop = <token> <answer> 1; 
ohci->next_statechange <token> jiffies + HZ; <answer> = 
if (!rhsc_enable <token> !rhsc_status) { <answer> && 
<token> = OHCI_INTR_RHSC; <answer> rhsc_enable 
<token> rhsc_enable, <answer> ohci_writel(ohci, 
static int ohci_root_hub_state_changes(struct <token> *ohci, int changed, <answer> ohci_hcd 
int any_connected, int <token> <answer> rhsc_status) 
if <token> || rhsc_status) <answer> (changed 
<token> 1; <answer> return 
#define <token> 50 <answer> PORT_RESET_MSEC 
<token> { <answer> do 
int <token> <answer> limit_2; 
if (limit_2 <token> 0) { <answer> < 
"port[%d] reset <token> stat %08x\n", <answer> timeout, 
<token> temp); <answer> port, 
if (!(temp & <token> <answer> RH_PS_CCS)) 
if (temp <token> RH_PS_PRSC) <answer> & 
ohci_writel <token> RH_PS_PRSC, portstat); <answer> (ohci, 
<token> 0; <answer> return 
<token> ohci_hub_control( <answer> int 
struct <token> *hcd, <answer> usb_hcd 
<token> typeReq, <answer> u16 
u16 <token> <answer> wValue, 
u16 <token> <answer> wIndex, 
char <token> <answer> *buf, 
<token> wLength <answer> u16 
) <token> <answer> { 
struct ohci_hcd *ohci = <token> (hcd); <answer> hcd_to_ohci 
int ports = <token> <answer> ohci->num_ports; 
u32 <token> <answer> temp; 
<token> retval = 0; <answer> int 
<token> (unlikely(!HCD_HW_ACCESSIBLE(hcd))) <answer> if 
<token> -ESHUTDOWN; <answer> return 
<token> (typeReq) { <answer> switch 
case <token> <answer> ClearHubFeature: 
<token> (wValue) { <answer> switch 
<token> C_HUB_OVER_CURRENT: <answer> case 
ohci_writel <token> RH_HS_OCIC, <answer> (ohci, 
case <token> <answer> C_HUB_LOCAL_POWER: 
goto <token> <answer> error; 
<token> ClearPortFeature: <answer> case 
if <token> || wIndex > ports) <answer> (!wIndex 
<token> error; <answer> goto 
switch <token> { <answer> (wValue) 
<token> USB_PORT_FEAT_ENABLE: <answer> case 
<token> = RH_PS_CCS; <answer> temp 
<token> USB_PORT_FEAT_C_ENABLE: <answer> case 
temp = <token> <answer> RH_PS_PESC; 
case <token> <answer> USB_PORT_FEAT_SUSPEND: 
temp = <token> <answer> RH_PS_POCI; 
case <token> <answer> USB_PORT_FEAT_C_SUSPEND: 
temp <token> RH_PS_PSSC; <answer> = 
case <token> <answer> USB_PORT_FEAT_POWER: 
<token> = RH_PS_LSDA; <answer> temp 
case <token> <answer> USB_PORT_FEAT_C_CONNECTION: 
temp = <token> <answer> RH_PS_CSC; 
<token> USB_PORT_FEAT_C_OVER_CURRENT: <answer> case 
temp <token> RH_PS_OCIC; <answer> = 
<token> USB_PORT_FEAT_C_RESET: <answer> case 
temp <token> RH_PS_PRSC; <answer> = 
goto <token> <answer> error; 
ohci_writel (ohci, <token> <answer> temp, 
&ohci->regs->roothub.portstatus <token> <answer> [wIndex]); 
case <token> <answer> GetHubDescriptor: 
ohci_hub_descriptor (ohci, (struct usb_hub_descriptor <token> buf); <answer> *) 
<token> GetHubStatus: <answer> case 
temp = roothub_status <token> & ~(RH_HS_CRWE | RH_HS_DRWE); <answer> (ohci) 
put_unaligned_le32(temp, <token> <answer> buf); 
case <token> <answer> GetPortStatus: 
if (!wIndex || <token> > ports) <answer> wIndex 
goto <token> <answer> error; 
<token> = roothub_portstatus (ohci, wIndex); <answer> temp 
put_unaligned_le32(temp, <token> <answer> buf); 
<token> <linux/io.h> <answer> #include 
<token> <linux/delay.h> <answer> #include 
<token> "gsc-core.h" <answer> #include 
void gsc_hw_set_sw_reset(struct gsc_dev <token> <answer> *dev) 
writel(GSC_SW_RESET_SRESET, dev->regs + <token> <answer> GSC_SW_RESET); 
int <token> gsc_dev *dev) <answer> gsc_wait_reset(struct 
unsigned long end <token> jiffies + msecs_to_jiffies(50); <answer> = 
<token> cfg; <answer> u32 
while (time_before(jiffies, end)) <token> <answer> { 
cfg = readl(dev->regs <token> GSC_SW_RESET); <answer> + 
<token> (!cfg) <answer> if 
<token> 0; <answer> return 
usleep_range(10, <token> <answer> 20); 
<token> -EBUSY; <answer> return 
void <token> gsc_dev *dev, bool mask) <answer> gsc_hw_set_frm_done_irq_mask(struct 
<token> cfg; <answer> u32 
cfg = readl(dev->regs <token> GSC_IRQ); <answer> + 
<token> (mask) <answer> if 
cfg |= <token> <answer> GSC_IRQ_FRMDONE_MASK; 
cfg <token> ~GSC_IRQ_FRMDONE_MASK; <answer> &= 
writel(cfg, dev->regs <token> GSC_IRQ); <answer> + 
void gsc_hw_set_gsc_irq_enable(struct <token> *dev, bool mask) <answer> gsc_dev 
u32 <token> <answer> cfg; 
cfg <token> readl(dev->regs + GSC_IRQ); <answer> = 
<token> (mask) <answer> if 
cfg |= <token> <answer> GSC_IRQ_ENABLE; 
<token> &= ~GSC_IRQ_ENABLE; <answer> cfg 
writel(cfg, dev->regs <token> GSC_IRQ); <answer> + 
void gsc_hw_set_input_buf_masking(struct gsc_dev *dev, u32 <token> <answer> shift, 
<token> enable) <answer> bool 
<token> cfg = readl(dev->regs + GSC_IN_BASE_ADDR_Y_MASK); <answer> u32 
u32 mask = <token> << shift; <answer> 1 
<token> &= ~mask; <answer> cfg 
cfg |= enable <token> shift; <answer> << 
writel(cfg, dev->regs <token> GSC_IN_BASE_ADDR_Y_MASK); <answer> + 
writel(cfg, dev->regs <token> GSC_IN_BASE_ADDR_CB_MASK); <answer> + 
writel(cfg, <token> + GSC_IN_BASE_ADDR_CR_MASK); <answer> dev->regs 
<token> gsc_hw_set_output_buf_masking(struct gsc_dev *dev, u32 shift, <answer> void 
bool <token> <answer> enable) 
u32 cfg = readl(dev->regs + <token> <answer> GSC_OUT_BASE_ADDR_Y_MASK); 
u32 mask = 1 << <token> <answer> shift; 
cfg &= <token> <answer> ~mask; 
cfg |= <token> << shift; <answer> enable 
writel(cfg, dev->regs + <token> <answer> GSC_OUT_BASE_ADDR_Y_MASK); 
writel(cfg, dev->regs <token> GSC_OUT_BASE_ADDR_CB_MASK); <answer> + 
writel(cfg, dev->regs <token> GSC_OUT_BASE_ADDR_CR_MASK); <answer> + 
void <token> gsc_dev *dev, struct gsc_addr *addr, <answer> gsc_hw_set_input_addr(struct 
<token> index) <answer> int 
pr_debug("src_buf[%d]: <token> cb: %pad, cr: %pad", index, <answer> %pad, 
<token> &addr->cb, &addr->cr); <answer> &addr->y, 
writel(addr->y, <token> + GSC_IN_BASE_ADDR_Y(index)); <answer> dev->regs 
writel(addr->cb, <token> + GSC_IN_BASE_ADDR_CB(index)); <answer> dev->regs 
writel(addr->cr, dev->regs <token> GSC_IN_BASE_ADDR_CR(index)); <answer> + 
void gsc_hw_set_output_addr(struct gsc_dev <token> <answer> *dev, 
struct <token> *addr, int index) <answer> gsc_addr 
pr_debug("dst_buf[%d]: %pad, cb: %pad, cr: <token> <answer> %pad", 
index, &addr->y, <token> &addr->cr); <answer> &addr->cb, 
writel(addr->y, dev->regs + <token> <answer> GSC_OUT_BASE_ADDR_Y(index)); 
<token> dev->regs + GSC_OUT_BASE_ADDR_CB(index)); <answer> writel(addr->cb, 
writel(addr->cr, dev->regs <token> GSC_OUT_BASE_ADDR_CR(index)); <answer> + 
void gsc_hw_set_input_path(struct <token> *ctx) <answer> gsc_ctx 
struct gsc_dev *dev <token> ctx->gsc_dev; <answer> = 
u32 cfg = <token> + GSC_IN_CON); <answer> readl(dev->regs 
cfg <token> ~(GSC_IN_PATH_MASK | GSC_IN_LOCAL_SEL_MASK); <answer> &= 
<token> (ctx->in_path == GSC_DMA) <answer> if 
cfg |= <token> <answer> GSC_IN_PATH_MEMORY; 
writel(cfg, dev->regs <token> GSC_IN_CON); <answer> + 
void <token> gsc_ctx *ctx) <answer> gsc_hw_set_in_size(struct 
struct gsc_dev *dev = <token> <answer> ctx->gsc_dev; 
struct <token> *frame = &ctx->s_frame; <answer> gsc_frame 
<token> cfg; <answer> u32 
<token> <linux/types.h> <answer> #include 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <linux/uaccess.h> 
<token> <asm/sfp-machine.h> <answer> #include 
#include <token> <answer> <math-emu/soft-fp.h> 
#include <token> <answer> <math-emu/double.h> 
#include <token> <answer> <math-emu/single.h> 
fnmsubs(void *frD, void *frA, void *frB, <token> *frC) <answer> void 
#ifdef <token> <answer> DEBUG 
printk("%s: %p <token> %p %p\n", __func__, frD, frA, frB, frC); <answer> %p 
FP_UNPACK_DP(A, <token> <answer> frA); 
FP_UNPACK_DP(B, <token> <answer> frB); 
FP_UNPACK_DP(C, <token> <answer> frC); 
#ifdef <token> <answer> DEBUG 
printk("A: <token> %lu %lu %ld (%ld)\n", A_s, A_f1, A_f0, A_e, A_c); <answer> %ld 
printk("B: <token> %lu %lu %ld (%ld)\n", B_s, B_f1, B_f0, B_e, B_c); <answer> %ld 
printk("C: %ld %lu %lu <token> (%ld)\n", C_s, C_f1, C_f0, C_e, C_c); <answer> %ld 
if ((A_c <token> FP_CLS_INF && C_c == FP_CLS_ZERO) || <answer> == 
(A_c <token> FP_CLS_ZERO && C_c == FP_CLS_INF)) <answer> == 
FP_MUL_D(T, A, <token> <answer> C); 
if (B_c != <token> <answer> FP_CLS_NAN) 
B_s <token> 1; <answer> ^= 
if (T_s != B_s && <token> == FP_CLS_INF && B_c == FP_CLS_INF) <answer> T_c 
FP_ADD_D(R, <token> B); <answer> T, 
if (R_c <token> FP_CLS_NAN) <answer> != 
R_s ^= <token> <answer> 1; 
<token> DEBUG <answer> #ifdef 
printk("D: %ld %lu %lu %ld (%ld)\n", R_s, R_f1, <token> R_e, R_c); <answer> R_f0, 
__FP_PACK_DS(frD, <token> <answer> R); 
<token> FP_CUR_EXCEPTIONS; <answer> return 
<token> <linux/interrupt.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/platform_device.h> <answer> #include 
<token> <linux/pm_runtime.h> <answer> #include 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> <linux/mfd/tps6594.h> 
#define <token> 0x08 <answer> TPS6594_DEV_REV_1 
static irqreturn_t tps6594_esm_isr(int irq, <token> *dev_id) <answer> void 
struct platform_device *pdev <token> dev_id; <answer> = 
<token> i; <answer> int 
for (i = 0 ; i < pdev->num_resources ; i++) <token> <answer> { 
<token> (irq == platform_get_irq_byname(pdev, pdev->resource[i].name)) { <answer> if 
dev_err(pdev->dev.parent, "%s error detected\n", <token> <answer> pdev->resource[i].name); 
return <token> <answer> IRQ_HANDLED; 
return <token> <answer> IRQ_NONE; 
static int tps6594_esm_probe(struct <token> *pdev) <answer> platform_device 
struct tps6594 <token> = dev_get_drvdata(pdev->dev.parent); <answer> *tps 
<token> device *dev = &pdev->dev; <answer> struct 
unsigned <token> rev; <answer> int 
<token> irq; <answer> int 
int <token> <answer> ret; 
int <token> <answer> i; 
<token> = regmap_read(tps->regmap, TPS6594_REG_DEV_REV, &rev); <answer> ret 
<token> (ret) <answer> if 
return <token> ret, <answer> dev_err_probe(dev, 
"Failed <token> read PMIC revision\n"); <answer> to 
<token> (rev == TPS6594_DEV_REV_1) <answer> if 
return <token> -ENODEV, <answer> dev_err_probe(dev, 
"ESM not supported for <token> 1 PMIC\n"); <answer> revision 
for (i <token> 0; i < pdev->num_resources; i++) { <answer> = 
<token> = platform_get_irq_byname(pdev, pdev->resource[i].name); <answer> irq 
<token> (irq < 0) <answer> if 
<token> irq; <answer> return 
ret = devm_request_threaded_irq(dev, <token> NULL, <answer> irq, 
<token> IRQF_ONESHOT, <answer> tps6594_esm_isr, 
<token> pdev); <answer> pdev->resource[i].name, 
if <token> <answer> (ret) 
return dev_err_probe(dev, ret, "Failed to <token> irq\n"); <answer> request 
ret <token> regmap_set_bits(tps->regmap, TPS6594_REG_ESM_SOC_MODE_CFG, <answer> = 
TPS6594_BIT_ESM_SOC_EN <token> TPS6594_BIT_ESM_SOC_ENDRV); <answer> | 
<token> (ret) <answer> if 
return dev_err_probe(dev, <token> "Failed to configure ESM\n"); <answer> ret, 
ret = <token> TPS6594_REG_ESM_SOC_START_REG, <answer> regmap_set_bits(tps->regmap, 
if <token> <answer> (ret) 
return dev_err_probe(dev, ret, "Failed to start <token> <answer> ESM\n"); 
return <token> <answer> 0; 
static void tps6594_esm_remove(struct platform_device <token> <answer> *pdev) 
struct tps6594 *tps <token> dev_get_drvdata(pdev->dev.parent); <answer> = 
struct <token> *dev = &pdev->dev; <answer> device 
int <token> <answer> ret; 
ret = regmap_clear_bits(tps->regmap, <token> <answer> TPS6594_REG_ESM_SOC_START_REG, 
if <token> { <answer> (ret) 
<token> "Failed to stop ESM\n"); <answer> dev_err(dev, 
goto <token> <answer> out; 
<token> = regmap_clear_bits(tps->regmap, TPS6594_REG_ESM_SOC_MODE_CFG, <answer> ret 
TPS6594_BIT_ESM_SOC_EN | <token> <answer> TPS6594_BIT_ESM_SOC_ENDRV); 
if <token> <answer> (ret) 
dev_err(dev, <token> to unconfigure ESM\n"); <answer> "Failed 
static int tps6594_esm_suspend(struct <token> *dev) <answer> device 
struct tps6594 *tps <token> dev_get_drvdata(dev->parent); <answer> = 
<token> ret; <answer> int 
ret = regmap_clear_bits(tps->regmap, <token> <answer> TPS6594_REG_ESM_SOC_START_REG, 
return <token> <answer> ret; 
static <token> tps6594_esm_resume(struct device *dev) <answer> int 
struct tps6594 *tps <token> dev_get_drvdata(dev->parent); <answer> = 
return regmap_set_bits(tps->regmap, <token> <answer> TPS6594_REG_ESM_SOC_START_REG, 
static DEFINE_SIMPLE_DEV_PM_OPS(tps6594_esm_pm_ops, <token> tps6594_esm_resume); <answer> tps6594_esm_suspend, 
static struct platform_driver tps6594_esm_driver = <token> <answer> { 
.driver <token> { <answer> = 
.name <token> "tps6594-esm", <answer> = 
.pm <token> pm_sleep_ptr(&tps6594_esm_pm_ops), <answer> = 
<token> = tps6594_esm_probe, <answer> .probe 
<token> = tps6594_esm_remove, <answer> .remove_new 
<token> Panis <jpanis@baylibre.com>"); <answer> MODULE_AUTHOR("Julien 
MODULE_DESCRIPTION("TPS6594 <token> Signal Monitor Driver"); <answer> Error 
#include <token> <answer> "priv.h" 
#include <token> <answer> <core/pci.h> 
#if <token> <answer> defined(__powerpc__) 
struct priv <token> <answer> { 
<token> void __iomem *data; <answer> const 
int <token> <answer> size; 
<token> u32 <answer> static 
of_read(void *data, u32 offset, u32 length, <token> nvkm_bios *bios) <answer> struct 
struct priv <token> = data; <answer> *priv 
if (offset < priv->size) <token> <answer> { 
length = min_t(u32, length, <token> - offset); <answer> priv->size 
<token> + offset, priv->data + offset, length); <answer> memcpy_fromio(bios->data 
return <token> <answer> length; 
return <token> <answer> 0; 
<token> u32 <answer> static 
<token> *data) <answer> of_size(void 
struct priv *priv = <token> <answer> data; 
return <token> <answer> priv->size; 
static <token> * <answer> void 
of_init(struct nvkm_bios <token> const char *name) <answer> *bios, 
<token> nvkm_device *device = bios->subdev.device; <answer> struct 
<token> pci_dev *pdev = device->func->pci(device)->pdev; <answer> struct 
struct <token> *dn; <answer> device_node 
struct priv <token> <answer> *priv; 
if (!(dn <token> pci_device_to_OF_node(pdev))) <answer> = 
<token> ERR_PTR(-ENODEV); <answer> return 
if (!(priv <token> kzalloc(sizeof(*priv), GFP_KERNEL))) <answer> = 
return <token> <answer> ERR_PTR(-ENOMEM); 
if ((priv->data = of_get_property(dn, <token> &priv->size))) <answer> "NVDA,BMP", 
<token> priv; <answer> return 
return <token> <answer> ERR_PTR(-EINVAL); 
static void of_fini(void <token> <answer> *p) 
<token> struct nvbios_source <answer> const 
nvbios_of = <token> <answer> { 
.name = <token> <answer> "OpenFirmware", 
.init <token> of_init, <answer> = 
.fini = <token> <answer> of_fini, 
.read = <token> <answer> of_read, 
<token> = of_size, <answer> .size 
.rw <token> false, <answer> = 
<token> = true, <answer> .ignore_checksum 
<token> = true, <answer> .no_pcir 
const <token> nvbios_source <answer> struct 
nvbios_of <token> { <answer> = 
#include <token> <answer> <linux/dma-direct.h> 
#include <token> <answer> <asm/ip32/crime.h> 
#define <token> 0x3fffffffUL <answer> RAM_OFFSET_MASK 
dma_addr_t <token> device *dev, phys_addr_t paddr) <answer> phys_to_dma(struct 
dma_addr_t dma_addr = paddr <token> RAM_OFFSET_MASK; <answer> & 
<token> (!dev) <answer> if 
dma_addr += <token> <answer> CRIME_HI_MEM_BASE; 
<token> dma_addr; <answer> return 
phys_addr_t <token> device *dev, dma_addr_t dma_addr) <answer> dma_to_phys(struct 
phys_addr_t paddr = dma_addr & <token> <answer> RAM_OFFSET_MASK; 
if <token> >= 256*1024*1024) <answer> (dma_addr 
paddr <token> CRIME_HI_MEM_BASE; <answer> += 
<token> paddr; <answer> return 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <rdma/uverbs_ioctl.h> 
<token> "mlx4_ib.h" <answer> #include 
struct <token> { <answer> mlx4_ib_user_db_page 
struct list_head <token> <answer> list; 
struct <token> *umem; <answer> ib_umem 
unsigned long <token> <answer> user_virt; 
<token> refcnt; <answer> int 
int mlx4_ib_db_map_user(struct ib_udata *udata, unsigned <token> virt, <answer> long 
struct mlx4_db <token> <answer> *db) 
<token> mlx4_ib_user_db_page *page; <answer> struct 
int <token> = 0; <answer> err 
struct mlx4_ib_ucontext *context = <token> <answer> rdma_udata_to_drv_context( 
<token> struct mlx4_ib_ucontext, ibucontext); <answer> udata, 
list_for_each_entry(page, <token> list) <answer> &context->db_page_list, 
if (page->user_virt == (virt & <token> <answer> PAGE_MASK)) 
<token> found; <answer> goto 
page = kmalloc(sizeof <token> GFP_KERNEL); <answer> *page, 
if <token> { <answer> (!page) 
err = <token> <answer> -ENOMEM; 
<token> out; <answer> goto 
<token> = (virt & PAGE_MASK); <answer> page->user_virt 
page->refcnt <token> 0; <answer> = 
page->umem = ib_umem_get(context->ibucontext.device, <token> & PAGE_MASK, <answer> virt 
<token> 0); <answer> PAGE_SIZE, 
if <token> { <answer> (IS_ERR(page->umem)) 
err <token> PTR_ERR(page->umem); <answer> = 
goto <token> <answer> out; 
list_add(&page->list, <token> <answer> &context->db_page_list); 
db->dma = sg_dma_address(page->umem->sgt_append.sgt.sgl) <token> <answer> + 
(virt & <token> <answer> ~PAGE_MASK); 
<token> = page; <answer> db->u.user_page 
return <token> <answer> err; 
void mlx4_ib_db_unmap_user(struct mlx4_ib_ucontext *context, struct <token> *db) <answer> mlx4_db 
<token> (!--db->u.user_page->refcnt) { <answer> if 
#include <token> <answer> <linux/bitfield.h> 
#include <token> <answer> <linux/clk.h> 
<token> <linux/mfd/syscon.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/of.h> <answer> #include 
#include <token> <answer> <linux/of_platform.h> 
<token> <linux/pinctrl/consumer.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/pm_runtime.h> 
<token> <linux/regmap.h> <answer> #include 
<token> <linux/reset.h> <answer> #include 
struct <token> { <answer> stm32_fmc2_prop 
<token> char *name; <answer> const 
bool <token> <answer> bprop; 
<token> mprop; <answer> bool 
int <token> <answer> reg_type; 
u32 <token> <answer> reg_mask; 
<token> reset_val; <answer> u32 
int (*check)(struct stm32_fmc2_ebi <token> <answer> *ebi, 
const struct stm32_fmc2_prop *prop, int <token> <answer> cs); 
u32 (*calculate)(struct stm32_fmc2_ebi *ebi, int cs, u32 <token> <answer> setup); 
int <token> stm32_fmc2_ebi *ebi, <answer> (*set)(struct 
const struct stm32_fmc2_prop <token> <answer> *prop, 
int cs, <token> setup); <answer> u32 
static <token> stm32_fmc2_ebi_check_mux(struct stm32_fmc2_ebi *ebi, <answer> int 
const struct stm32_fmc2_prop <token> <answer> *prop, 
int <token> <answer> cs) 
u32 <token> <answer> bcr; 
int <token> <answer> ret; 
ret <token> regmap_read(ebi->regmap, FMC2_BCR(cs), &bcr); <answer> = 
<token> (ret) <answer> if 
return <token> <answer> ret; 
if (bcr & <token> <answer> FMC2_BCR_MTYP) 
return <token> <answer> 0; 
return <token> <answer> -EINVAL; 
static int <token> stm32_fmc2_ebi *ebi, <answer> stm32_fmc2_ebi_check_waitcfg(struct 
const struct <token> *prop, <answer> stm32_fmc2_prop 
int <token> <answer> cs) 
u32 bcr, val = FIELD_PREP(FMC2_BCR_MTYP, <token> <answer> FMC2_BCR_MTYP_NOR); 
<token> ret; <answer> int 
ret <token> regmap_read(ebi->regmap, FMC2_BCR(cs), &bcr); <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if ((bcr & FMC2_BCR_MTYP) == val && bcr <token> FMC2_BCR_BURSTEN) <answer> & 
return <token> <answer> 0; 
<token> -EINVAL; <answer> return 
static int stm32_fmc2_ebi_check_sync_trans(struct stm32_fmc2_ebi <token> <answer> *ebi, 
const <token> stm32_fmc2_prop *prop, <answer> struct 
int <token> <answer> cs) 
u32 <token> <answer> bcr; 
<token> ret; <answer> int 
<token> = regmap_read(ebi->regmap, FMC2_BCR(cs), &bcr); <answer> ret 
if <token> <answer> (ret) 
return <token> <answer> ret; 
<token> (bcr & FMC2_BCR_BURSTEN) <answer> if 
<token> 0; <answer> return 
<token> -EINVAL; <answer> return 
static int <token> stm32_fmc2_ebi *ebi, <answer> stm32_fmc2_ebi_mp25_check_cclk(struct 
const <token> stm32_fmc2_prop *prop, <answer> struct 
int <token> <answer> cs) 
<token> (!ebi->access_granted) <answer> if 
<token> -EACCES; <answer> return 
<token> stm32_fmc2_ebi_check_sync_trans(ebi, prop, cs); <answer> return 
static <token> stm32_fmc2_ebi_mp25_check_clk_period(struct stm32_fmc2_ebi *ebi, <answer> int 
const <token> stm32_fmc2_prop *prop, <answer> struct 
<token> cs) <answer> int 
u32 <token> <answer> cfgr; 
<token> ret; <answer> int 
ret = <token> FMC2_CFGR, &cfgr); <answer> regmap_read(ebi->regmap, 
if <token> <answer> (ret) 
return <token> <answer> ret; 
if <token> & FMC2_CFGR_CCLKEN && !ebi->access_granted) <answer> (cfgr 
return <token> <answer> -EACCES; 
return stm32_fmc2_ebi_check_sync_trans(ebi, <token> cs); <answer> prop, 
static int stm32_fmc2_ebi_check_async_trans(struct stm32_fmc2_ebi <token> <answer> *ebi, 
<token> struct stm32_fmc2_prop *prop, <answer> const 
int <token> <answer> cs) 
u32 <token> <answer> bcr; 
<token> ret; <answer> int 
ret = regmap_read(ebi->regmap, FMC2_BCR(cs), <token> <answer> &bcr); 
if <token> <answer> (ret) 
<token> ret; <answer> return 
if (!(bcr & FMC2_BCR_BURSTEN) <token> !(bcr & FMC2_BCR_CBURSTRW)) <answer> || 
return <token> <answer> 0; 
<token> -EINVAL; <answer> return 
static int stm32_fmc2_ebi_check_cpsize(struct <token> *ebi, <answer> stm32_fmc2_ebi 
const struct stm32_fmc2_prop <token> <answer> *prop, 
int <token> <answer> cs) 
u32 bcr, val <token> FIELD_PREP(FMC2_BCR_MTYP, FMC2_BCR_MTYP_PSRAM); <answer> = 
int <token> <answer> ret; 
ret = regmap_read(ebi->regmap, <token> &bcr); <answer> FMC2_BCR(cs), 
if <token> <answer> (ret) 
<token> ret; <answer> return 
if ((bcr & FMC2_BCR_MTYP) == <token> && bcr & FMC2_BCR_BURSTEN) <answer> val 
return <token> <answer> 0; 
<token> -EINVAL; <answer> return 
static int stm32_fmc2_ebi_check_address_hold(struct <token> *ebi, <answer> stm32_fmc2_ebi 
const struct <token> *prop, <answer> stm32_fmc2_prop 
int <token> <answer> cs) 
u32 bcr, bxtr, val <token> FIELD_PREP(FMC2_BXTR_ACCMOD, FMC2_BXTR_EXTMOD_D); <answer> = 
int <token> <answer> ret; 
ret = <token> FMC2_BCR(cs), &bcr); <answer> regmap_read(ebi->regmap, 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if (prop->reg_type <token> FMC2_REG_BWTR) <answer> == 
ret = <token> FMC2_BWTR(cs), &bxtr); <answer> regmap_read(ebi->regmap, 
ret = <token> FMC2_BTR(cs), &bxtr); <answer> regmap_read(ebi->regmap, 
<token> (ret) <answer> if 
return <token> <answer> ret; 
if ((!(bcr & FMC2_BCR_BURSTEN) || !(bcr <token> FMC2_BCR_CBURSTRW)) && <answer> & 
((bxtr <token> FMC2_BXTR_ACCMOD) == val || bcr & FMC2_BCR_MUXEN)) <answer> & 
<token> 0; <answer> return 
return <token> <answer> -EINVAL; 
static int stm32_fmc2_ebi_check_clk_period(struct <token> *ebi, <answer> stm32_fmc2_ebi 
const struct stm32_fmc2_prop <token> <answer> *prop, 
int <token> <answer> cs) 
u32 bcr, <token> <answer> bcr1; 
int <token> <answer> ret; 
ret = regmap_read(ebi->regmap, FMC2_BCR(cs), <token> <answer> &bcr); 
<token> (ret) <answer> if 
return <token> <answer> ret; 
if <token> { <answer> (cs) 
ret <token> regmap_read(ebi->regmap, FMC2_BCR1, &bcr1); <answer> = 
<token> (ret) <answer> if 
<token> ret; <answer> return 
} else <token> <answer> { 
<token> = bcr; <answer> bcr1 
if (bcr & FMC2_BCR_BURSTEN && <token> || !(bcr1 & FMC2_BCR1_CCLKEN))) <answer> (!cs 
<token> 0; <answer> return 
return <token> <answer> -EINVAL; 
static int stm32_fmc2_ebi_check_cclk(struct stm32_fmc2_ebi <token> <answer> *ebi, 
const struct stm32_fmc2_prop <token> <answer> *prop, 
int <token> <answer> cs) 
<token> (cs) <answer> if 
return <token> <answer> -EINVAL; 
return stm32_fmc2_ebi_check_sync_trans(ebi, prop, <token> <answer> cs); 
static u32 <token> stm32_fmc2_ebi *ebi, <answer> stm32_fmc2_ebi_ns_to_clock_cycles(struct 
int cs, <token> setup) <answer> u32 
unsigned <token> hclk = clk_get_rate(ebi->clk); <answer> long 
unsigned <token> hclkp = NSEC_PER_SEC / (hclk / 1000); <answer> long 
return DIV_ROUND_UP(setup * <token> hclkp); <answer> 1000, 
static u32 stm32_fmc2_ebi_ns_to_clk_period(struct stm32_fmc2_ebi <token> <answer> *ebi, 
int cs, u32 <token> <answer> setup) 
u32 nb_clk_cycles = stm32_fmc2_ebi_ns_to_clock_cycles(ebi, cs, <token> <answer> setup); 
u32 bcr, <token> clk_period; <answer> btr, 
int <token> <answer> ret; 
ret = regmap_read(ebi->regmap, FMC2_BCR1, <token> <answer> &bcr); 
<token> (ret) <answer> if 
<token> ret; <answer> return 
if (bcr & FMC2_BCR1_CCLKEN || <token> <answer> !cs) 
ret <token> regmap_read(ebi->regmap, FMC2_BTR1, &btr); <answer> = 
ret = regmap_read(ebi->regmap, <token> &btr); <answer> FMC2_BTR(cs), 
if <token> <answer> (ret) 
return <token> <answer> ret; 
clk_period = FIELD_GET(FMC2_BTR_CLKDIV, <token> + 1; <answer> btr) 
<token> DIV_ROUND_UP(nb_clk_cycles, clk_period); <answer> return 
static u32 stm32_fmc2_ebi_mp25_ns_to_clk_period(struct stm32_fmc2_ebi <token> <answer> *ebi, 
<token> cs, u32 setup) <answer> int 
u32 nb_clk_cycles <token> stm32_fmc2_ebi_ns_to_clock_cycles(ebi, cs, setup); <answer> = 
u32 cfgr, <token> clk_period; <answer> btr, 
int <token> <answer> ret; 
ret = regmap_read(ebi->regmap, <token> &cfgr); <answer> FMC2_CFGR, 
if <token> <answer> (ret) 
<token> ret; <answer> return 
if <token> & FMC2_CFGR_CCLKEN) { <answer> (cfgr 
<token> = FIELD_GET(FMC2_CFGR_CLKDIV, cfgr) + 1; <answer> clk_period 
} else <token> <answer> { 
ret = regmap_read(ebi->regmap, FMC2_BTR(cs), <token> <answer> &btr); 
if <token> <answer> (ret) 
<token> ret; <answer> return 
clk_period = FIELD_GET(FMC2_BTR_CLKDIV, btr) <token> 1; <answer> + 
return <token> clk_period); <answer> DIV_ROUND_UP(nb_clk_cycles, 
static int stm32_fmc2_ebi_get_reg(int <token> int cs, u32 *reg) <answer> reg_type, 
switch (reg_type) <token> <answer> { 
<token> FMC2_REG_BCR: <answer> case 
<token> = FMC2_BCR(cs); <answer> *reg 
case <token> <answer> FMC2_REG_BTR: 
*reg = <token> <answer> FMC2_BTR(cs); 
case <token> <answer> FMC2_REG_BWTR: 
<token> = FMC2_BWTR(cs); <answer> *reg 
<token> FMC2_REG_PCSCNTR: <answer> case 
*reg = <token> <answer> FMC2_PCSCNTR; 
case <token> <answer> FMC2_REG_CFGR: 
*reg <token> FMC2_CFGR; <answer> = 
return <token> <answer> -EINVAL; 
<token> 0; <answer> return 
static int stm32_fmc2_ebi_set_bit_field(struct <token> *ebi, <answer> stm32_fmc2_ebi 
const struct <token> *prop, <answer> stm32_fmc2_prop 
int cs, u32 <token> <answer> setup) 
u32 <token> <answer> reg; 
<token> ret; <answer> int 
<token> = stm32_fmc2_ebi_get_reg(prop->reg_type, cs, &reg); <answer> ret 
if <token> <answer> (ret) 
<token> ret; <answer> return 
regmap_update_bits(ebi->regmap, <token> prop->reg_mask, <answer> reg, 
setup <token> prop->reg_mask : 0); <answer> ? 
<token> 0; <answer> return 
static <token> stm32_fmc2_ebi_set_trans_type(struct stm32_fmc2_ebi *ebi, <answer> int 
const struct stm32_fmc2_prop <token> <answer> *prop, 
int cs, u32 <token> <answer> setup) 
u32 <token> bcr = FMC2_BCR_WREN; <answer> bcr_mask, 
u32 btr_mask, btr = <token> <answer> 0; 
u32 <token> bwtr = 0; <answer> bwtr_mask, 
<token> = FMC2_BXTR_ACCMOD; <answer> bwtr_mask 
btr_mask <token> FMC2_BXTR_ACCMOD; <answer> = 
bcr_mask = FMC2_BCR_MUXEN | FMC2_BCR_MTYP | <token> | <answer> FMC2_BCR_FACCEN 
FMC2_BCR_WREN | FMC2_BCR_WAITEN <token> FMC2_BCR_BURSTEN | <answer> | 
FMC2_BCR_EXTMOD | <token> <answer> FMC2_BCR_CBURSTRW; 
switch (setup) <token> <answer> { 
<token> FMC2_ASYNC_MODE_1_SRAM: <answer> case 
bcr |= <token> FMC2_BCR_MTYP_SRAM); <answer> FIELD_PREP(FMC2_BCR_MTYP, 
case <token> <answer> FMC2_ASYNC_MODE_1_PSRAM: 
bcr |= FIELD_PREP(FMC2_BCR_MTYP, <token> <answer> FMC2_BCR_MTYP_PSRAM); 
case <token> <answer> FMC2_ASYNC_MODE_A_SRAM: 
bcr |= FIELD_PREP(FMC2_BCR_MTYP, <token> <answer> FMC2_BCR_MTYP_SRAM); 
<token> |= FMC2_BCR_EXTMOD; <answer> bcr 
btr |= <token> FMC2_BXTR_EXTMOD_A); <answer> FIELD_PREP(FMC2_BXTR_ACCMOD, 
bwtr <token> FIELD_PREP(FMC2_BXTR_ACCMOD, FMC2_BXTR_EXTMOD_A); <answer> |= 
case <token> <answer> FMC2_ASYNC_MODE_A_PSRAM: 
bcr <token> FIELD_PREP(FMC2_BCR_MTYP, FMC2_BCR_MTYP_PSRAM); <answer> |= 
bcr <token> FMC2_BCR_EXTMOD; <answer> |= 
btr |= FIELD_PREP(FMC2_BXTR_ACCMOD, <token> <answer> FMC2_BXTR_EXTMOD_A); 
bwtr |= FIELD_PREP(FMC2_BXTR_ACCMOD, <token> <answer> FMC2_BXTR_EXTMOD_A); 
<token> FMC2_ASYNC_MODE_2_NOR: <answer> case 
bcr |= FIELD_PREP(FMC2_BCR_MTYP, <token> <answer> FMC2_BCR_MTYP_NOR); 
bcr <token> FMC2_BCR_FACCEN; <answer> |= 
case <token> <answer> FMC2_ASYNC_MODE_B_NOR: 
bcr |= FIELD_PREP(FMC2_BCR_MTYP, <token> <answer> FMC2_BCR_MTYP_NOR); 
bcr <token> FMC2_BCR_FACCEN | FMC2_BCR_EXTMOD; <answer> |= 
btr <token> FIELD_PREP(FMC2_BXTR_ACCMOD, FMC2_BXTR_EXTMOD_B); <answer> |= 
bwtr |= <token> FMC2_BXTR_EXTMOD_B); <answer> FIELD_PREP(FMC2_BXTR_ACCMOD, 
<token> FMC2_ASYNC_MODE_C_NOR: <answer> case 
bcr |= FIELD_PREP(FMC2_BCR_MTYP, <token> <answer> FMC2_BCR_MTYP_NOR); 
bcr <token> FMC2_BCR_FACCEN | FMC2_BCR_EXTMOD; <answer> |= 
btr |= FIELD_PREP(FMC2_BXTR_ACCMOD, <token> <answer> FMC2_BXTR_EXTMOD_C); 
bwtr <token> FIELD_PREP(FMC2_BXTR_ACCMOD, FMC2_BXTR_EXTMOD_C); <answer> |= 
<token> FMC2_ASYNC_MODE_D_NOR: <answer> case 
bcr |= FIELD_PREP(FMC2_BCR_MTYP, <token> <answer> FMC2_BCR_MTYP_NOR); 
bcr <token> FMC2_BCR_FACCEN | FMC2_BCR_EXTMOD; <answer> |= 
<token> |= FIELD_PREP(FMC2_BXTR_ACCMOD, FMC2_BXTR_EXTMOD_D); <answer> btr 
bwtr <token> FIELD_PREP(FMC2_BXTR_ACCMOD, FMC2_BXTR_EXTMOD_D); <answer> |= 
case <token> <answer> FMC2_SYNC_READ_SYNC_WRITE_PSRAM: 
bcr |= FIELD_PREP(FMC2_BCR_MTYP, <token> <answer> FMC2_BCR_MTYP_PSRAM); 
bcr |= FMC2_BCR_BURSTEN | <token> <answer> FMC2_BCR_CBURSTRW; 
case <token> <answer> FMC2_SYNC_READ_ASYNC_WRITE_PSRAM: 
bcr |= FIELD_PREP(FMC2_BCR_MTYP, <token> <answer> FMC2_BCR_MTYP_PSRAM); 
<token> |= FMC2_BCR_BURSTEN; <answer> bcr 
case <token> <answer> FMC2_SYNC_READ_SYNC_WRITE_NOR: 
<token> |= FIELD_PREP(FMC2_BCR_MTYP, FMC2_BCR_MTYP_NOR); <answer> bcr 
<token> |= FMC2_BCR_FACCEN | FMC2_BCR_BURSTEN | FMC2_BCR_CBURSTRW; <answer> bcr 
<token> FMC2_SYNC_READ_ASYNC_WRITE_NOR: <answer> case 
<token> |= FIELD_PREP(FMC2_BCR_MTYP, FMC2_BCR_MTYP_NOR); <answer> bcr 
bcr |= FMC2_BCR_FACCEN | <token> <answer> FMC2_BCR_BURSTEN; 
<token> <linux/eventfd.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
<token> "acrn_drv.h" <answer> #include 
struct <token> { <answer> hsm_ioeventfd 
struct list_head <token> <answer> list; 
struct eventfd_ctx <token> <answer> *eventfd; 
u64 <token> <answer> addr; 
u64 <token> <answer> data; 
int <token> <answer> length; 
<token> type; <answer> int 
<token> wildcard; <answer> bool 
static <token> int ioreq_type_from_flags(int flags) <answer> inline 
<token> flags & ACRN_IOEVENTFD_FLAG_PIO ? <answer> return 
ACRN_IOREQ_TYPE_PORTIO : <token> <answer> ACRN_IOREQ_TYPE_MMIO; 
<token> void acrn_ioeventfd_shutdown(struct acrn_vm *vm, struct hsm_ioeventfd *p) <answer> static 
static <token> hsm_ioeventfd_is_conflict(struct acrn_vm *vm, <answer> bool 
struct <token> *ioeventfd) <answer> hsm_ioeventfd 
struct hsm_ioeventfd <token> <answer> *p; 
static <token> acrn_ioeventfd_assign(struct acrn_vm *vm, <answer> int 
struct acrn_ioeventfd <token> <answer> *args) 
<token> eventfd_ctx *eventfd; <answer> struct 
struct hsm_ioeventfd <token> <answer> *p; 
<token> ret; <answer> int 
if <token> == 1 || args->len == 2 || <answer> (!(args->len 
args->len == 4 <token> args->len == 8)) <answer> || 
return <token> <answer> -EINVAL; 
eventfd = <token> <answer> eventfd_ctx_fdget(args->fd); 
if <token> <answer> (IS_ERR(eventfd)) 
return <token> <answer> PTR_ERR(eventfd); 
p = <token> GFP_KERNEL); <answer> kzalloc(sizeof(*p), 
if (!p) <token> <answer> { 
ret = <token> <answer> -ENOMEM; 
<token> fail; <answer> goto 
p->addr = <token> <answer> args->addr; 
p->length = <token> <answer> args->len; 
p->eventfd <token> eventfd; <answer> = 
p->type = <token> <answer> ioreq_type_from_flags(args->flags); 
<token> (args->flags & ACRN_IOEVENTFD_FLAG_DATAMATCH) <answer> if 
<token> = args->data; <answer> p->data 
p->wildcard <token> true; <answer> = 
if (hsm_ioeventfd_is_conflict(vm, <token> { <answer> p)) 
<token> = -EEXIST; <answer> ret 
goto <token> <answer> unlock_fail; 
if <token> == ACRN_IOREQ_DIR_READ) { <answer> (req->reqs.mmio_request.direction 
<token> <linux/device-mapper.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/vmalloc.h> 
#define DM_MSG_PREFIX <token> <answer> "switch" 
typedef unsigned long <token> <answer> region_table_slot_t; 
struct switch_path <token> <answer> { 
struct <token> *dmdev; <answer> dm_dev 
sector_t <token> <answer> start; 
<token> switch_ctx { <answer> struct 
struct <token> *ti; <answer> dm_target 
<token> switch_path path_list[]; <answer> struct 
static struct switch_ctx <token> dm_target *ti, unsigned int nr_paths, <answer> *alloc_switch_ctx(struct 
unsigned int <token> <answer> region_size) 
struct <token> *sctx; <answer> switch_ctx 
sctx = <token> path_list, nr_paths), GFP_KERNEL); <answer> kzalloc(struct_size(sctx, 
if <token> <answer> (!sctx) 
<token> NULL; <answer> return 
sctx->ti <token> ti; <answer> = 
sctx->region_size = <token> <answer> region_size; 
ti->private = <token> <answer> sctx; 
<token> sctx; <answer> return 
static int alloc_region_table(struct <token> *ti, unsigned int nr_paths) <answer> dm_target 
<token> switch_ctx *sctx = ti->private; <answer> struct 
sector_t nr_regions <token> ti->len; <answer> = 
<token> nr_slots; <answer> sector_t 
if (!(sctx->region_size & (sctx->region_size <token> 1))) <answer> - 
sctx->region_size_bits = <token> <answer> __ffs(sctx->region_size); 
sctx->region_size_bits = <token> <answer> -1; 
sctx->region_table_entry_bits <token> 1; <answer> = 
while (sctx->region_table_entry_bits < sizeof(region_table_slot_t) <token> 8 && <answer> * 
(region_table_slot_t)1 << sctx->region_table_entry_bits <token> nr_paths) <answer> < 
sctx->region_entries_per_slot <token> (sizeof(region_table_slot_t) * 8) / sctx->region_table_entry_bits; <answer> = 
if <token> & (sctx->region_entries_per_slot - 1))) <answer> (!(sctx->region_entries_per_slot 
sctx->region_entries_per_slot_bits = <token> <answer> __ffs(sctx->region_entries_per_slot); 
<token> = -1; <answer> sctx->region_entries_per_slot_bits 
if <token> sctx->region_size)) <answer> (sector_div(nr_regions, 
if (nr_regions >= <token> { <answer> ULONG_MAX) 
ti->error <token> "Region table too large"; <answer> = 
return <token> <answer> -EINVAL; 
sctx->nr_regions <token> nr_regions; <answer> = 
nr_slots = <token> <answer> nr_regions; 
if <token> sctx->region_entries_per_slot)) <answer> (sector_div(nr_slots, 
if (nr_slots > <token> / sizeof(region_table_slot_t)) { <answer> ULONG_MAX 
ti->error = <token> table too large"; <answer> "Region 
return <token> <answer> -EINVAL; 
sctx->region_table = <token> <answer> vmalloc(array_size(nr_slots, 
<token> (!sctx->region_table) { <answer> if 
ti->error = "Cannot allocate <token> table"; <answer> region 
return <token> <answer> -ENOMEM; 
<token> 0; <answer> return 
<token> void switch_get_position(struct switch_ctx *sctx, unsigned long region_nr, <answer> static 
unsigned long <token> unsigned int *bit) <answer> *region_index, 
if (sctx->region_entries_per_slot_bits >= <token> { <answer> 0) 
*region_index = region_nr <token> sctx->region_entries_per_slot_bits; <answer> >> 
*bit <token> region_nr & (sctx->region_entries_per_slot - 1); <answer> = 
} else <token> <answer> { 
<token> = region_nr / sctx->region_entries_per_slot; <answer> *region_index 
*bit = <token> % sctx->region_entries_per_slot; <answer> region_nr 
*bit <token> sctx->region_table_entry_bits; <answer> *= 
<token> unsigned int switch_region_table_read(struct switch_ctx *sctx, unsigned long region_nr) <answer> static 
unsigned long <token> <answer> region_index; 
unsigned <token> bit; <answer> int 
switch_get_position(sctx, region_nr, <token> &bit); <answer> &region_index, 
return (READ_ONCE(sctx->region_table[region_index]) >> bit) <token> <answer> & 
((1 <token> sctx->region_table_entry_bits) - 1); <answer> << 
<token> unsigned int switch_get_path_nr(struct switch_ctx *sctx, sector_t offset) <answer> static 
unsigned <token> path_nr; <answer> int 
<token> p; <answer> sector_t 
p <token> offset; <answer> = 
<token> (sctx->region_size_bits >= 0) <answer> if 
p <token> sctx->region_size_bits; <answer> >>= 
sector_div(p, <token> <answer> sctx->region_size); 
path_nr = <token> p); <answer> switch_region_table_read(sctx, 
static void <token> switch_ctx *sctx) <answer> initialise_region_table(struct 
unsigned int path_nr = <token> <answer> 0; 
unsigned long <token> <answer> region_nr; 
for (region_nr = 0; region_nr < sctx->nr_regions; region_nr++) <token> <answer> { 
switch_region_table_write(sctx, <token> path_nr); <answer> region_nr, 
if (++path_nr <token> sctx->nr_paths) <answer> >= 
<token> = 0; <answer> path_nr 
static int parse_path(struct dm_arg_set *as, struct dm_target <token> <answer> *ti) 
struct switch_ctx <token> = ti->private; <answer> *sctx 
unsigned long <token> start; <answer> long 
<token> r; <answer> int 
<token> = dm_get_device(ti, dm_shift_arg(as), dm_table_get_mode(ti->table), <answer> r 
if (r) <token> <answer> { 
ti->error <token> "Device lookup failed"; <answer> = 
<token> r; <answer> return 
if (kstrtoull(dm_shift_arg(as), 10, &start) <token> start != (sector_t)start) { <answer> || 
ti->error = "Invalid device starting <token> <answer> offset"; 
dm_put_device(ti, <token> <answer> sctx->path_list[sctx->nr_paths].dmdev); 
<token> -EINVAL; <answer> return 
<token> = start; <answer> sctx->path_list[sctx->nr_paths].start 
<token> 0; <answer> return 
static void switch_dtr(struct dm_target <token> <answer> *ti) 
struct <token> *sctx = ti->private; <answer> switch_ctx 
while <token> <answer> (sctx->nr_paths--) 
<token> sctx->path_list[sctx->nr_paths].dmdev); <answer> dm_put_device(ti, 
static int switch_ctr(struct dm_target *ti, unsigned int <token> char **argv) <answer> argc, 
static const struct dm_arg _args[] <token> { <answer> = 
{1, (KMALLOC_MAX_SIZE - sizeof(struct switch_ctx)) / sizeof(struct <token> "Invalid number of paths"}, <answer> switch_path), 
{1, <token> "Invalid region size"}, <answer> UINT_MAX, 
{0, 0, "Invalid number <token> optional args"}, <answer> of 
struct <token> *sctx; <answer> switch_ctx 
struct <token> as; <answer> dm_arg_set 
<token> int nr_paths, region_size, nr_optional_args; <answer> unsigned 
int <token> <answer> r; 
<token> = argc; <answer> as.argc 
as.argv <token> argv; <answer> = 
r = dm_read_arg(_args, <token> &nr_paths, &ti->error); <answer> &as, 
<token> (r) <answer> if 
return <token> <answer> -EINVAL; 
r = dm_read_arg(_args + 1, <token> &region_size, &ti->error); <answer> &as, 
if <token> <answer> (r) 
return <token> <answer> r; 
r = dm_read_arg_group(_args + 2, <token> &nr_optional_args, &ti->error); <answer> &as, 
<token> (r) <answer> if 
<token> r; <answer> return 
static const <token> char hex_table[256] = { <answer> unsigned 
<token> 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, <answer> 255, 
255, 255, 255, 255, <token> 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, <answer> 255, 
255, 255, 255, 255, <token> 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, <answer> 255, 
0, 1, 2, <token> 4, 5, 6, 7, 8, 9, 255, 255, 255, 255, 255, 255, <answer> 3, 
255, 10, 11, 12, 13, 14, 15, 255, 255, 255, <token> 255, 255, 255, 255, 255, <answer> 255, 
255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, <token> <answer> 255, 
<token> 10, 11, 12, 13, 14, 15, 255, 255, 255, 255, 255, 255, 255, 255, 255, <answer> 255, 
255, 255, 255, <token> 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, <answer> 255, 
255, 255, 255, 255, 255, 255, 255, <token> 255, 255, 255, 255, 255, 255, 255, 255, <answer> 255, 
255, 255, 255, 255, 255, <token> 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, <answer> 255, 
255, 255, 255, 255, 255, 255, <token> 255, 255, 255, 255, 255, 255, 255, 255, 255, <answer> 255, 
255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, <token> 255, 255, <answer> 255, 
255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, <token> 255, 255, 255, <answer> 255, 
255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, <token> <answer> 255, 
255, 255, 255, 255, 255, 255, 255, <token> 255, 255, 255, 255, 255, 255, 255, 255, <answer> 255, 
255, 255, 255, 255, 255, 255, 255, 255, 255, <token> 255, 255, 255, 255, 255, 255 <answer> 255, 
<token> __always_inline unsigned long parse_hex(const char **string) <answer> static 
unsigned char <token> <answer> d; 
<token> long r = 0; <answer> unsigned 
while <token> = hex_table[(unsigned char)**string]) < 16) { <answer> ((d 
r = (r <token> 4) | d; <answer> << 
<token> r; <answer> return 
static int process_set_region_mappings(struct switch_ctx <token> <answer> *sctx, 
unsigned int <token> char **argv) <answer> argc, 
<token> int i; <answer> unsigned 
unsigned long region_index = <token> <answer> 0; 
for (i = 1; <token> < argc; i++) { <answer> i 
unsigned long <token> <answer> path_nr; 
const char <token> = argv[i]; <answer> *string 
if ((*string & 0xdf) == <token> { <answer> 'R') 
unsigned long <token> num_write; <answer> cycle_length, 
if <token> == ',')) { <answer> (unlikely(*string 
DMWARN("invalid set_region_mappings argument: '%s'", <token> <answer> argv[i]); 
return <token> <answer> -EINVAL; 
<token> = parse_hex(&string); <answer> cycle_length 
if (unlikely(*string <token> ',')) { <answer> != 
DMWARN("invalid <token> argument: '%s'", argv[i]); <answer> set_region_mappings 
<token> -EINVAL; <answer> return 
if <token> { <answer> (unlikely(!*string)) 
DMWARN("invalid set_region_mappings argument: <token> argv[i]); <answer> '%s'", 
return <token> <answer> -EINVAL; 
<token> = parse_hex(&string); <answer> num_write 
<token> (unlikely(*string)) { <answer> if 
DMWARN("invalid set_region_mappings argument: '%s'", <token> <answer> argv[i]); 
return <token> <answer> -EINVAL; 
if (unlikely(!cycle_length) || <token> - 1 > region_index)) { <answer> unlikely(cycle_length 
DMWARN("invalid <token> cycle length: %lu > %lu", <answer> set_region_mappings 
cycle_length - <token> region_index); <answer> 1, 
<token> -EINVAL; <answer> return 
if (unlikely(region_index + num_write < region_index) <token> <answer> || 
unlikely(region_index <token> num_write >= sctx->nr_regions)) { <answer> + 
DMWARN("invalid <token> region number: %lu + %lu >= %lu", <answer> set_region_mappings 
region_index, <token> sctx->nr_regions); <answer> num_write, 
<token> -EINVAL; <answer> return 
while (num_write--) <token> <answer> { 
path_nr = switch_region_table_read(sctx, region_index <token> cycle_length); <answer> - 
switch_region_table_write(sctx, region_index, <token> <answer> path_nr); 
if (*string == <token> <answer> ':') 
else <token> <answer> { 
region_index <token> parse_hex(&string); <answer> = 
if (unlikely(*string <token> ':')) { <answer> != 
DMWARN("invalid set_region_mappings <token> '%s'", argv[i]); <answer> argument: 
<token> -EINVAL; <answer> return 
if <token> { <answer> (unlikely(!*string)) 
DMWARN("invalid set_region_mappings argument: <token> argv[i]); <answer> '%s'", 
<token> -EINVAL; <answer> return 
<token> = parse_hex(&string); <answer> path_nr 
<token> (unlikely(*string)) { <answer> if 
DMWARN("invalid set_region_mappings argument: '%s'", <token> <answer> argv[i]); 
<token> -EINVAL; <answer> return 
<token> (unlikely(region_index >= sctx->nr_regions)) { <answer> if 
DMWARN("invalid set_region_mappings region number: %lu >= %lu", region_index, <token> <answer> sctx->nr_regions); 
<token> -EINVAL; <answer> return 
if <token> >= sctx->nr_paths)) { <answer> (unlikely(path_nr 
DMWARN("invalid set_region_mappings device: %lu >= %u", <token> sctx->nr_paths); <answer> path_nr, 
<token> -EINVAL; <answer> return 
switch_region_table_write(sctx, <token> path_nr); <answer> region_index, 
<token> 0; <answer> return 
static int switch_message(struct dm_target *ti, unsigned int <token> char **argv, <answer> argc, 
char *result, unsigned <token> maxlen) <answer> int 
static <token> <answer> DEFINE_MUTEX(message_mutex); 
struct switch_ctx *sctx = <token> <answer> ti->private; 
int r = <token> <answer> -EINVAL; 
<token> (!strcasecmp(argv[0], "set_region_mappings")) <answer> if 
r = <token> argc, argv); <answer> process_set_region_mappings(sctx, 
DMWARN("Unrecognised message <token> <answer> received."); 
<token> r; <answer> return 
static void switch_status(struct dm_target *ti, <token> type, <answer> status_type_t 
unsigned int status_flags, char *result, unsigned int <token> <answer> maxlen) 
struct <token> *sctx = ti->private; <answer> switch_ctx 
unsigned int sz <token> 0; <answer> = 
<token> path_nr; <answer> int 
switch <token> { <answer> (type) 
<token> STATUSTYPE_INFO: <answer> case 
result[0] <token> '\0'; <answer> = 
case <token> <answer> STATUSTYPE_TABLE: 
DMEMIT("%u <token> 0", sctx->nr_paths, sctx->region_size); <answer> %u 
for (path_nr = 0; <token> < sctx->nr_paths; path_nr++) <answer> path_nr 
DMEMIT(" <token> %llu", sctx->path_list[path_nr].dmdev->name, <answer> %s 
(unsigned long <token> <answer> long)sctx->path_list[path_nr].start); 
<token> STATUSTYPE_IMA: <answer> case 
result[0] = <token> <answer> '\0'; 
static int switch_prepare_ioctl(struct dm_target <token> struct block_device **bdev) <answer> *ti, 
struct switch_ctx *sctx = <token> <answer> ti->private; 
<token> int path_nr; <answer> unsigned 
path_nr <token> switch_get_path_nr(sctx, 0); <answer> = 
<token> = sctx->path_list[path_nr].dmdev->bdev; <answer> *bdev 
<token> (ti->len + sctx->path_list[path_nr].start != <answer> if 
<token> 1; <answer> return 
return <token> <answer> 0; 
static int switch_iterate_devices(struct dm_target <token> <answer> *ti, 
iterate_devices_callout_fn <token> void *data) <answer> fn, 
struct <token> *sctx = ti->private; <answer> switch_ctx 
<token> path_nr; <answer> int 
int <token> <answer> r; 
for (path_nr = <token> path_nr < sctx->nr_paths; path_nr++) { <answer> 0; 
r = <token> sctx->path_list[path_nr].dmdev, <answer> fn(ti, 
sctx->path_list[path_nr].start, ti->len, <token> <answer> data); 
if <token> <answer> (r) 
return <token> <answer> r; 
return <token> <answer> 0; 
static struct target_type <token> = { <answer> switch_target 
.name = <token> <answer> "switch", 
.version = {1, <token> 0}, <answer> 1, 
.features = <token> <answer> DM_TARGET_NOWAIT, 
.module <token> THIS_MODULE, <answer> = 
<token> = switch_ctr, <answer> .ctr 
.dtr = <token> <answer> switch_dtr, 
.map = <token> <answer> switch_map, 
<token> = switch_message, <answer> .message 
<token> = switch_status, <answer> .status 
<token> = switch_prepare_ioctl, <answer> .prepare_ioctl 
.iterate_devices <token> switch_iterate_devices, <answer> = 
MODULE_DESCRIPTION(DM_NAME <token> dynamic path switching target"); <answer> " 
<token> D. O'Kelley <Kevin_OKelley@dell.com>"); <answer> MODULE_AUTHOR("Kevin 
<token> Ganapathy <Narendran_Ganapathy@dell.com>"); <answer> MODULE_AUTHOR("Narendran 
MODULE_AUTHOR("Jim Ramsay <token> <answer> <Jim_Ramsay@dell.com>"); 
MODULE_AUTHOR("Mikulas <token> <mpatocka@redhat.com>"); <answer> Patocka 
<token> <linux/bits.h> <answer> #include 
<token> <linux/device.h> <answer> #include 
#include <token> <answer> <linux/gpio/driver.h> 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <linux/mfd/syscon.h> 
<token> <linux/module.h> <answer> #include 
#include <token> <answer> <linux/debugfs.h> 
<token> <linux/seq_file.h> <answer> #include 
#include <token> <answer> <linux/mod_devicetable.h> 
#include <token> <answer> <linux/pinctrl/machine.h> 
#include <token> <answer> <linux/pinctrl/pinconf.h> 
#include <token> <answer> <linux/pinctrl/pinconf-generic.h> 
<token> <linux/pinctrl/pinctrl.h> <answer> #include 
<token> <linux/pinctrl/pinmux.h> <answer> #include 
<token> <linux/pinctrl/consumer.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
<token> <linux/property.h> <answer> #include 
#include <token> <answer> <linux/regmap.h> 
<token> npcm8xx_pingroup { <answer> struct 
const <token> *name; <answer> char 
const <token> int *pins; <answer> unsigned 
<token> npins; <answer> int 
<token> NPCM8XX_GRPS \ <answer> #define 
<token> \ <answer> NPCM8XX_GRP(gpi36), 
NPCM8XX_GRP(gpi35), <token> <answer> \ 
NPCM8XX_GRP(tp_jtag3), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(tp_uart), 
<token> \ <answer> NPCM8XX_GRP(tp_smb2), 
NPCM8XX_GRP(tp_smb1), <token> <answer> \ 
NPCM8XX_GRP(tp_gpio7), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(tp_gpio6), 
NPCM8XX_GRP(tp_gpio5), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(tp_gpio4), 
<token> \ <answer> NPCM8XX_GRP(tp_gpio3), 
<token> \ <answer> NPCM8XX_GRP(tp_gpio2), 
<token> \ <answer> NPCM8XX_GRP(tp_gpio1), 
<token> \ <answer> NPCM8XX_GRP(tp_gpio0), 
NPCM8XX_GRP(tp_gpio2b), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(tp_gpio1b), 
NPCM8XX_GRP(tp_gpio0b), <token> <answer> \ 
NPCM8XX_GRP(vgadig), <token> <answer> \ 
NPCM8XX_GRP(nbu1crts), <token> <answer> \ 
NPCM8XX_GRP(fm2), <token> <answer> \ 
NPCM8XX_GRP(fm1), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(fm0), 
NPCM8XX_GRP(gpio1836), <token> <answer> \ 
NPCM8XX_GRP(gpio1889), <token> <answer> \ 
NPCM8XX_GRP(gpo187), <token> <answer> \ 
NPCM8XX_GRP(cp1urxd), <token> <answer> \ 
NPCM8XX_GRP(r3rxer), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(cp1gpio2c), 
NPCM8XX_GRP(cp1gpio3c), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(cp1gpio0b), 
<token> \ <answer> NPCM8XX_GRP(cp1gpio1b), 
NPCM8XX_GRP(cp1gpio2b), <token> <answer> \ 
NPCM8XX_GRP(cp1gpio3b), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(cp1gpio4b), 
NPCM8XX_GRP(cp1gpio5b), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(cp1gpio6b), 
<token> \ <answer> NPCM8XX_GRP(cp1gpio7b), 
NPCM8XX_GRP(cp1gpio0), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(cp1gpio1), 
<token> \ <answer> NPCM8XX_GRP(cp1gpio2), 
<token> \ <answer> NPCM8XX_GRP(cp1gpio3), 
NPCM8XX_GRP(cp1gpio4), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(cp1gpio5), 
<token> \ <answer> NPCM8XX_GRP(cp1gpio6), 
NPCM8XX_GRP(cp1gpio7), <token> <answer> \ 
NPCM8XX_GRP(cp1utxd), <token> <answer> \ 
NPCM8XX_GRP(spi1cs3), <token> <answer> \ 
NPCM8XX_GRP(spi1cs2), <token> <answer> \ 
NPCM8XX_GRP(spi1cs1), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(spi1cs0), 
NPCM8XX_GRP(spi1d23), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(j2j3), 
NPCM8XX_GRP(r3oen), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(r2oen), 
<token> \ <answer> NPCM8XX_GRP(r1oen), 
NPCM8XX_GRP(bu4b), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(bu4), 
<token> \ <answer> NPCM8XX_GRP(bu5b), 
<token> \ <answer> NPCM8XX_GRP(bu5), 
<token> \ <answer> NPCM8XX_GRP(bu6), 
NPCM8XX_GRP(rmii3), <token> <answer> \ 
NPCM8XX_GRP(jm1), <token> <answer> \ 
NPCM8XX_GRP(jm2), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(tpgpio5b), 
NPCM8XX_GRP(tpgpio4b), <token> <answer> \ 
NPCM8XX_GRP(clkrun), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(i3c5), 
NPCM8XX_GRP(i3c4), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(i3c3), 
<token> \ <answer> NPCM8XX_GRP(i3c2), 
NPCM8XX_GRP(i3c1), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(i3c0), 
NPCM8XX_GRP(hsi1a), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(hsi2a), 
<token> \ <answer> NPCM8XX_GRP(hsi1b), 
<token> \ <answer> NPCM8XX_GRP(hsi2b), 
<token> \ <answer> NPCM8XX_GRP(hsi1c), 
<token> \ <answer> NPCM8XX_GRP(hsi2c), 
<token> \ <answer> NPCM8XX_GRP(smb0), 
<token> \ <answer> NPCM8XX_GRP(smb0b), 
NPCM8XX_GRP(smb0c), <token> <answer> \ 
NPCM8XX_GRP(smb0d), <token> <answer> \ 
NPCM8XX_GRP(smb0den), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb1), 
NPCM8XX_GRP(smb1b), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb1c), 
NPCM8XX_GRP(smb1d), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb2), 
NPCM8XX_GRP(smb2b), <token> <answer> \ 
NPCM8XX_GRP(smb2c), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb2d), 
<token> \ <answer> NPCM8XX_GRP(smb3), 
NPCM8XX_GRP(smb3b), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb3c), 
<token> \ <answer> NPCM8XX_GRP(smb3d), 
NPCM8XX_GRP(smb4), <token> <answer> \ 
NPCM8XX_GRP(smb4b), <token> <answer> \ 
NPCM8XX_GRP(smb4c), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb4d), 
<token> \ <answer> NPCM8XX_GRP(smb4den), 
<token> \ <answer> NPCM8XX_GRP(smb5), 
<token> \ <answer> NPCM8XX_GRP(smb5b), 
NPCM8XX_GRP(smb5c), <token> <answer> \ 
NPCM8XX_GRP(smb5d), <token> <answer> \ 
NPCM8XX_GRP(ga20kbc), <token> <answer> \ 
NPCM8XX_GRP(smb6), <token> <answer> \ 
NPCM8XX_GRP(smb6b), <token> <answer> \ 
NPCM8XX_GRP(smb6c), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb6d), 
<token> \ <answer> NPCM8XX_GRP(smb7), 
NPCM8XX_GRP(smb7b), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb7c), 
NPCM8XX_GRP(smb7d), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb8), 
NPCM8XX_GRP(smb9), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb10), 
NPCM8XX_GRP(smb11), <token> <answer> \ 
NPCM8XX_GRP(smb12), <token> <answer> \ 
NPCM8XX_GRP(smb13), <token> <answer> \ 
NPCM8XX_GRP(smb14), <token> <answer> \ 
NPCM8XX_GRP(smb14b), <token> <answer> \ 
NPCM8XX_GRP(smb15), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb15b), 
<token> \ <answer> NPCM8XX_GRP(smb16), 
NPCM8XX_GRP(smb16b), <token> <answer> \ 
NPCM8XX_GRP(smb17), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb18), 
<token> \ <answer> NPCM8XX_GRP(smb19), 
<token> \ <answer> NPCM8XX_GRP(smb20), 
NPCM8XX_GRP(smb21), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(smb22), 
<token> \ <answer> NPCM8XX_GRP(smb23), 
NPCM8XX_GRP(smb23b), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(fanin0), 
NPCM8XX_GRP(fanin1), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(fanin2), 
NPCM8XX_GRP(fanin3), <token> <answer> \ 
NPCM8XX_GRP(fanin4), <token> <answer> \ 
NPCM8XX_GRP(fanin5), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(fanin6), 
<token> \ <answer> NPCM8XX_GRP(fanin7), 
<token> \ <answer> NPCM8XX_GRP(fanin8), 
NPCM8XX_GRP(fanin9), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(fanin10), 
<token> \ <answer> NPCM8XX_GRP(fanin11), 
<token> \ <answer> NPCM8XX_GRP(fanin12), 
<token> \ <answer> NPCM8XX_GRP(fanin13), 
NPCM8XX_GRP(fanin14), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(fanin15), 
<token> \ <answer> NPCM8XX_GRP(faninx), 
NPCM8XX_GRP(pwm0), <token> <answer> \ 
NPCM8XX_GRP(pwm1), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(pwm2), 
<token> \ <answer> NPCM8XX_GRP(pwm3), 
<token> \ <answer> NPCM8XX_GRP(pwm4), 
<token> \ <answer> NPCM8XX_GRP(pwm5), 
NPCM8XX_GRP(pwm6), <token> <answer> \ 
NPCM8XX_GRP(pwm7), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(pwm8), 
<token> \ <answer> NPCM8XX_GRP(pwm9), 
NPCM8XX_GRP(pwm10), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(pwm11), 
NPCM8XX_GRP(sg1mdio), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(rg2), 
NPCM8XX_GRP(rg2mdio), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(ddr), 
<token> \ <answer> NPCM8XX_GRP(uart1), 
NPCM8XX_GRP(uart2), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(bmcuart0a), 
NPCM8XX_GRP(bmcuart0b), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(bmcuart1), 
<token> \ <answer> NPCM8XX_GRP(iox1), 
<token> \ <answer> NPCM8XX_GRP(iox2), 
<token> \ <answer> NPCM8XX_GRP(ioxh), 
NPCM8XX_GRP(gspi), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(mmc), 
NPCM8XX_GRP(mmcwp), <token> <answer> \ 
NPCM8XX_GRP(mmccd), <token> <answer> \ 
NPCM8XX_GRP(mmcrst), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(mmc8), 
<token> \ <answer> NPCM8XX_GRP(r1), 
NPCM8XX_GRP(r1err), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(r1md), 
<token> \ <answer> NPCM8XX_GRP(r2), 
NPCM8XX_GRP(r2err), <token> <answer> \ 
NPCM8XX_GRP(r2md), <token> <answer> \ 
NPCM8XX_GRP(sd1), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(sd1pwr), 
NPCM8XX_GRP(wdog1), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(wdog2), 
<token> \ <answer> NPCM8XX_GRP(scipme), 
NPCM8XX_GRP(smi), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(serirq), 
NPCM8XX_GRP(jtag2), <token> <answer> \ 
NPCM8XX_GRP(spix), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(spixcs1), 
NPCM8XX_GRP(spi1), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(pspi), 
NPCM8XX_GRP(ddc), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(clkreq), 
NPCM8XX_GRP(clkout), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(spi3), 
NPCM8XX_GRP(spi3cs1), <token> <answer> \ 
NPCM8XX_GRP(spi3quad), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(spi3cs2), 
NPCM8XX_GRP(spi3cs3), <token> <answer> \ 
NPCM8XX_GRP(spi0cs1), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(lpc), 
NPCM8XX_GRP(lpcclk), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(espi), 
<token> \ <answer> NPCM8XX_GRP(lkgpo0), 
<token> \ <answer> NPCM8XX_GRP(lkgpo1), 
NPCM8XX_GRP(lkgpo2), <token> <answer> \ 
NPCM8XX_GRP(nprd_smi), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(hgpio0), 
NPCM8XX_GRP(hgpio1), <token> <answer> \ 
NPCM8XX_GRP(hgpio2), <token> <answer> \ 
NPCM8XX_GRP(hgpio3), <token> <answer> \ 
NPCM8XX_GRP(hgpio4), <token> <answer> \ 
<token> \ <answer> NPCM8XX_GRP(hgpio5), 
<token> \ <answer> NPCM8XX_GRP(hgpio6), 
NPCM8XX_GRP(hgpio7), <token> <answer> \ 
enum <token> <answer> { 
#define NPCM8XX_GRP(x) fn_ ## <token> <answer> x 
#undef <token> <answer> NPCM8XX_GRP 
<token> struct npcm8xx_pingroup npcm8xx_pingroups[] = { <answer> static 
#define NPCM8XX_GRP(x) { .name = #x, .pins = <token> ## _pins, \ <answer> x 
.npins <token> ARRAY_SIZE(x ## _pins) } <answer> = 
<token> NPCM8XX_GRP <answer> #undef 
#define <token> NPCM8XX_FUNC(a, #a) <answer> NPCM8XX_SFUNC(a) 
#define NPCM8XX_FUNC(a, b...) static const char <token> ## _grp[] = { b } <answer> *a 
#define NPCM8XX_MKFUNC(nm) <token> .name = #nm, .ngroups = ARRAY_SIZE(nm ## _grp), \ <answer> { 
.groups = <token> ## _grp } <answer> nm 
struct <token> { <answer> npcm8xx_func 
const char <token> <answer> *name; 
const unsigned int <token> <answer> ngroups; 
const char *const <token> <answer> *groups; 
<token> <linux/err.h> <answer> #include 
<token> <linux/init.h> <answer> #include 
#include <token> <answer> <linux/mod_devicetable.h> 
#include <token> <answer> <linux/platform_device.h> 
<token> "pinctrl-spear.h" <answer> #include 
<token> DRIVER_NAME "spear1340-pinmux" <answer> #define 
static <token> unsigned pads_as_gpio_pins[] = { 12, 88, 89, 251 }; <answer> const 
static struct spear_muxreg pads_as_gpio_muxreg[] = <token> <answer> { 
.reg <token> PAD_FUNCTION_EN_1, <answer> = 
<token> = PADS_AS_GPIO_REG0_MASK, <answer> .mask 
.val = <token> <answer> 0x0, 
}, <token> <answer> { 
.reg <token> PAD_FUNCTION_EN_2, <answer> = 
.mask = <token> <answer> PADS_AS_GPIO_REGS_MASK, 
.val <token> 0x0, <answer> = 
}, <token> <answer> { 
<token> = PAD_FUNCTION_EN_3, <answer> .reg 
.mask = <token> <answer> PADS_AS_GPIO_REGS_MASK, 
<token> = 0x0, <answer> .val 
<token> { <answer> }, 
<token> = PAD_FUNCTION_EN_4, <answer> .reg 
.mask <token> PADS_AS_GPIO_REGS_MASK, <answer> = 
<token> = 0x0, <answer> .val 
}, <token> <answer> { 
.reg <token> PAD_FUNCTION_EN_5, <answer> = 
.mask = <token> <answer> PADS_AS_GPIO_REGS_MASK, 
<token> = 0x0, <answer> .val 
<token> { <answer> }, 
.reg = <token> <answer> PAD_FUNCTION_EN_6, 
.mask = <token> <answer> PADS_AS_GPIO_REGS_MASK, 
<token> = 0x0, <answer> .val 
<token> { <answer> }, 
<token> = PAD_FUNCTION_EN_7, <answer> .reg 
.mask <token> PADS_AS_GPIO_REGS_MASK, <answer> = 
<token> = 0x0, <answer> .val 
}, <token> <answer> { 
.reg = <token> <answer> PAD_FUNCTION_EN_8, 
<token> = PADS_AS_GPIO_REG7_MASK, <answer> .mask 
.val <token> 0x0, <answer> = 
static struct spear_modemux pads_as_gpio_modemux[] <token> { <answer> = 
.muxregs = <token> <answer> pads_as_gpio_muxreg, 
.nmuxregs <token> ARRAY_SIZE(pads_as_gpio_muxreg), <answer> = 
static struct spear_pingroup pads_as_gpio_pingroup = <token> <answer> { 
<token> = "pads_as_gpio_grp", <answer> .name 
.pins = <token> <answer> pads_as_gpio_pins, 
<token> = ARRAY_SIZE(pads_as_gpio_pins), <answer> .npins 
<token> = pads_as_gpio_modemux, <answer> .modemuxs 
<token> = ARRAY_SIZE(pads_as_gpio_modemux), <answer> .nmodemuxs 
static const char *const <token> = { "pads_as_gpio_grp" }; <answer> pads_as_gpio_grps[] 
static struct <token> pads_as_gpio_function = { <answer> spear_function 
.name <token> "pads_as_gpio", <answer> = 
.groups <token> pads_as_gpio_grps, <answer> = 
<token> = ARRAY_SIZE(pads_as_gpio_grps), <answer> .ngroups 
<token> <linux/clk.h> <answer> #include 
#include <token> <answer> <linux/clocksource.h> 
#include <token> <answer> "soc.h" 
<token> "common.h" <answer> #include 
#include <token> <answer> "control.h" 
#include <token> <answer> "omap-secure.h" 
<token> REALTIME_COUNTER_BASE 0x48243200 <answer> #define 
<token> INCREMENTER_NUMERATOR_OFFSET 0x10 <answer> #define 
<token> INCREMENTER_DENUMERATOR_RELOAD_OFFSET 0x14 <answer> #define 
#define NUMERATOR_DENUMERATOR_MASK <token> <answer> 0xfffff000 
static unsigned <token> arch_timer_freq; <answer> long 
<token> set_cntfreq(void) <answer> void 
<token> arch_timer_freq); <answer> omap_smc1(OMAP5_DRA7_MON_SET_CNTFRQ_INDEX, 
<token> void __init realtime_counter_init(void) <answer> static 
void <token> *base; <answer> __iomem 
static struct <token> *sys_clk; <answer> clk 
unsigned <token> rate; <answer> long 
<token> int reg; <answer> unsigned 
unsigned long long <token> den; <answer> num, 
base = <token> SZ_32); <answer> ioremap(REALTIME_COUNTER_BASE, 
<token> (!base) { <answer> if 
pr_err("%s: ioremap <token> __func__); <answer> failed\n", 
sys_clk = clk_get(NULL, <token> <answer> "sys_clkin"); 
if <token> { <answer> (IS_ERR(sys_clk)) 
pr_err("%s: failed to get system clock handle\n", <token> <answer> __func__); 
<token> = clk_get_rate(sys_clk); <answer> rate 
if <token> { <answer> (soc_is_dra7xx()) 
<token> = omap_ctrl_readl(DRA7_CTRL_CORE_BOOTSTRAP); <answer> reg 
if (reg <token> DRA7_SPEEDSELECT_MASK) { <answer> & 
<token> = 75; <answer> num 
<token> = 244; <answer> den 
<token> sysclk1_based; <answer> goto 
<token> <linux/interrupt.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/slab.h> <answer> #include 
<token> "vdec_drv_if.h" <answer> #include 
#include <token> <answer> "mtk_vcodec_dec.h" 
<token> "vdec_drv_base.h" <answer> #include 
<token> "mtk_vcodec_dec_pm.h" <answer> #include 
int vdec_if_init(struct mtk_vcodec_dec_ctx *ctx, unsigned int <token> <answer> fourcc) 
<token> mtk_vdec_hw_arch hw_arch = ctx->dev->vdec_pdata->hw_arch; <answer> enum 
int <token> = 0; <answer> ret 
switch <token> { <answer> (fourcc) 
<token> V4L2_PIX_FMT_H264_SLICE: <answer> case 
if (!ctx->dev->vdec_pdata->is_subdev_supported) <token> <answer> { 
ctx->dec_if <token> &vdec_h264_slice_if; <answer> = 
<token> = MTK_VDEC_CORE; <answer> ctx->hw_id 
<token> else { <answer> } 
ctx->dec_if <token> &vdec_h264_slice_multi_if; <answer> = 
ctx->hw_id = IS_VDEC_LAT_ARCH(hw_arch) <token> MTK_VDEC_LAT0 : MTK_VDEC_CORE; <answer> ? 
<token> V4L2_PIX_FMT_H264: <answer> case 
ctx->dec_if <token> &vdec_h264_if; <answer> = 
ctx->hw_id = <token> <answer> MTK_VDEC_CORE; 
<token> V4L2_PIX_FMT_VP8_FRAME: <answer> case 
<token> = &vdec_vp8_slice_if; <answer> ctx->dec_if 
ctx->hw_id = <token> <answer> MTK_VDEC_CORE; 
<token> V4L2_PIX_FMT_VP8: <answer> case 
ctx->dec_if = <token> <answer> &vdec_vp8_if; 
ctx->hw_id <token> MTK_VDEC_CORE; <answer> = 
<token> V4L2_PIX_FMT_VP9: <answer> case 
ctx->dec_if <token> &vdec_vp9_if; <answer> = 
ctx->hw_id = <token> <answer> MTK_VDEC_CORE; 
case <token> <answer> V4L2_PIX_FMT_VP9_FRAME: 
ctx->dec_if <token> &vdec_vp9_slice_lat_if; <answer> = 
ctx->hw_id = IS_VDEC_LAT_ARCH(hw_arch) <token> MTK_VDEC_LAT0 : MTK_VDEC_CORE; <answer> ? 
<token> V4L2_PIX_FMT_HEVC_SLICE: <answer> case 
ctx->dec_if = <token> <answer> &vdec_hevc_slice_multi_if; 
<token> = MTK_VDEC_LAT0; <answer> ctx->hw_id 
case <token> <answer> V4L2_PIX_FMT_AV1_FRAME: 
<token> = &vdec_av1_slice_lat_if; <answer> ctx->dec_if 
<token> = MTK_VDEC_LAT0; <answer> ctx->hw_id 
return <token> <answer> -EINVAL; 
<token> ctx->hw_id); <answer> mtk_vcodec_dec_enable_hardware(ctx, 
<token> = ctx->dec_if->init(ctx); <answer> ret 
mtk_vcodec_dec_disable_hardware(ctx, <token> <answer> ctx->hw_id); 
<token> ret; <answer> return 
int vdec_if_decode(struct mtk_vcodec_dec_ctx *ctx, struct <token> *bs, <answer> mtk_vcodec_mem 
struct vdec_fb *fb, <token> *res_chg) <answer> bool 
int <token> = 0; <answer> ret 
if (bs) <token> <answer> { 
if ((bs->dma_addr & 63) <token> 0) { <answer> != 
mtk_v4l2_vdec_err(ctx, "bs dma_addr should 64 byte <token> <answer> align"); 
<token> -EINVAL; <answer> return 
<token> (fb) { <answer> if 
if (((fb->base_y.dma_addr & 511) != 0) <token> <answer> || 
((fb->base_c.dma_addr <token> 511) != 0)) { <answer> & 
mtk_v4l2_vdec_err(ctx, "frame buffer dma_addr should 512 <token> align"); <answer> byte 
<token> -EINVAL; <answer> return 
if <token> <answer> (!ctx->drv_handle) 
<token> -EIO; <answer> return 
mtk_vcodec_dec_enable_hardware(ctx, <token> <answer> ctx->hw_id); 
mtk_vcodec_set_curr_ctx(ctx->dev, <token> ctx->hw_id); <answer> ctx, 
ret = ctx->dec_if->decode(ctx->drv_handle, bs, fb, <token> <answer> res_chg); 
<token> NULL, ctx->hw_id); <answer> mtk_vcodec_set_curr_ctx(ctx->dev, 
<token> ctx->hw_id); <answer> mtk_vcodec_dec_disable_hardware(ctx, 
return <token> <answer> ret; 
int vdec_if_get_param(struct mtk_vcodec_dec_ctx <token> enum vdec_get_param_type type, <answer> *ctx, 
<token> *out) <answer> void 
int ret = <token> <answer> 0; 
if <token> <answer> (!ctx->drv_handle) 
return <token> <answer> -EIO; 
ret = ctx->dec_if->get_param(ctx->drv_handle, <token> out); <answer> type, 
<token> ret; <answer> return 
void vdec_if_deinit(struct <token> *ctx) <answer> mtk_vcodec_dec_ctx 
if <token> <answer> (!ctx->drv_handle) 
<token> ctx->hw_id); <answer> mtk_vcodec_dec_enable_hardware(ctx, 
mtk_vcodec_dec_disable_hardware(ctx, <token> <answer> ctx->hw_id); 
<token> = NULL; <answer> ctx->drv_handle 
<token> <linux/bpf.h> <answer> #include 
#include <token> <answer> <bpf/bpf_helpers.h> 
<token> { <answer> struct 
<token> BPF_MAP_TYPE_PROG_ARRAY); <answer> __uint(type, 
__uint(max_entries, <token> <answer> 1); 
<token> sizeof(__u32)); <answer> __uint(key_size, 
__uint(value_size, <token> <answer> sizeof(__u32)); 
} jmp_table <token> <answer> SEC(".maps"); 
int count = <token> <answer> 0; 
<token> classifier_0(struct __sk_buff *skb) <answer> int 
bpf_tail_call_static(skb, <token> 0); <answer> &jmp_table, 
return <token> <answer> 1; 
int <token> __sk_buff *skb) <answer> entry(struct 
bpf_tail_call_static(skb, <token> 0); <answer> &jmp_table, 
return <token> <answer> 0; 
<token> __license[] SEC("license") = "GPL"; <answer> char 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/module.h> <answer> #include 
<token> <linux/random.h> <answer> #include 
<token> <linux/hdreg.h> <answer> #include 
<token> <linux/kthread.h> <answer> #include 
#include <token> <answer> <linux/freezer.h> 
#include <token> <answer> <linux/sysfs.h> 
<token> <linux/bitops.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/mtd/nand-ecc-sw-hamming.h> 
#include <token> <answer> "nand/raw/sm_common.h" 
#include <token> <answer> "sm_ftl.h" 
<token> struct workqueue_struct *cache_flush_workqueue; <answer> static 
static int cache_timeout <token> 1000; <answer> = 
module_param(cache_timeout, int, <token> <answer> S_IRUGO); 
"Timeout (in ms) for cache flush <token> ms default"); <answer> (1000 
<token> int debug; <answer> static 
module_param(debug, int, <token> | S_IWUSR); <answer> S_IRUGO 
MODULE_PARM_DESC(debug, <token> level (0-2)"); <answer> "Debug 
static int sm_read_lba(struct sm_oob <token> <answer> *oob) 
static <token> uint32_t erased_pattern[4] = { <answer> const 
0xFFFFFFFF, 0xFFFFFFFF, <token> 0xFFFFFFFF }; <answer> 0xFFFFFFFF, 
uint16_t <token> <answer> lba_test; 
int <token> <answer> lba; 
if (zone == <token> && block == ftl->cis_block && boffset == <answer> 0 
return <token> <answer> ret; 
ret = mtd_read_oob(mtd, sm_mkoffset(ftl, zone, <token> boffset), &ops); <answer> block, 
if (sm_erase_block(ftl, <token> block, 0)) <answer> zone, 
<token> -EIO; <answer> return 
<token> = 1; <answer> retry 
goto <token> <answer> restart; 
<token> else { <answer> } 
<token> zone, block); <answer> sm_mark_block_bad(ftl, 
return <token> <answer> -EIO; 
return <token> <answer> 0; 
for (boffset = 0; boffset <token> ftl->block_size; boffset += SM_SECTOR_SIZE) <answer> < 
sm_write_sector(ftl, <token> block, boffset, NULL, &oob); <answer> zone, 
static int sm_erase_block(struct sm_ftl <token> int zone_num, uint16_t block, <answer> *ftl, 
<token> put_free) <answer> int 
struct <token> *zone = &ftl->zones[zone_num]; <answer> ftl_zone 
struct mtd_info *mtd = <token> <answer> ftl->trans->mtd; 
struct <token> erase; <answer> erase_info 
erase.addr <token> sm_mkoffset(ftl, zone_num, block, 0); <answer> = 
erase.len <token> ftl->block_size; <answer> = 
if <token> <answer> (ftl->unstable) 
return <token> <answer> -EIO; 
if (zone_num == 0 && (block == <token> || block == 0)) { <answer> ftl->cis_block 
sm_printk("attempted to erase the <token> <answer> CIS!"); 
<token> -EIO; <answer> return 
if (mtd_erase(mtd, <token> { <answer> &erase)) 
sm_printk("erase of block %d in zone %d <token> <answer> failed", 
block, <token> <answer> zone_num); 
goto <token> <answer> error; 
if <token> <answer> (put_free) 
<token> unsigned char *)&block, sizeof(block)); <answer> (const 
return <token> <answer> 0; 
sm_mark_block_bad(ftl, zone_num, <token> <answer> block); 
return <token> <answer> -EIO; 
for <token> = 0; boffset < ftl->block_size; <answer> (boffset 
boffset += SM_SECTOR_SIZE) <token> <answer> { 
static int sm_get_media_info(struct sm_ftl <token> struct mtd_info *mtd) <answer> *ftl, 
int <token> <answer> i; 
int size_in_megs <token> mtd->size / (1024 * 1024); <answer> = 
ftl->readonly = <token> == MTD_ROM; <answer> mtd->type 
<token> (size_in_megs >= 16) { <answer> if 
ftl->zone_count <token> size_in_megs / 16; <answer> = 
ftl->zone_size = <token> <answer> 1024; 
ftl->max_lba <token> 1000; <answer> = 
ftl->block_size = 32 * <token> <answer> SM_SECTOR_SIZE; 
<token> (sm_block_erased(&oob)) { <answer> if 
(unsigned <token> *)&block, 2); <answer> char 
<token> (!sm_block_valid(&oob)) { <answer> if 
dbg("PH <token> <-> <marked bad>", block); <answer> %04d 
lba = <token> <answer> sm_read_lba(&oob); 
if (lba == <token> || lba >= ftl->max_lba) { <answer> -2 
dbg("PH %04d <-> LBA %04d(bad)", <token> lba); <answer> block, 
if (zone->lba_to_phys_table[lba] < <token> { <answer> 0) 
<token> %04d <-> LBA %04d", block, lba); <answer> dbg_verbose("PH 
zone->lba_to_phys_table[lba] <token> block; <answer> = 
" of LBA %d between blocks %d and %d <token> zone %d", <answer> in 
lba, <token> block, zone_num); <answer> zone->lba_to_phys_table[lba], 
sm_printk("both blocks are valid, <token> the later"); <answer> erasing 
<token> zone_num, block, 1); <answer> sm_erase_block(ftl, 
dbg("zone <token> <answer> initialized"); 
zone->initialized <token> 1; <answer> = 
if (!kfifo_len(&zone->free_sectors)) <token> <answer> { 
sm_printk("no free blocks in zone %d", <token> <answer> zone_num); 
<token> 0; <answer> return 
if <token> <answer> (kfifo_out(&zone->free_sectors, 
(unsigned char *)&write_sector, 2) != 2) <token> <answer> { 
<token> free sectors for write!"); <answer> dbg("no 
return <token> <answer> -EIO; 
if <token> ftl->cache_data, zone_num, write_sector, <answer> (sm_write_block(ftl, 
<token> ftl->cache_data_invalid_bitmap)) <answer> ftl->cache_block, 
<token> restart; <answer> goto 
<token> <stdio.h> <answer> #include 
<token> <stdlib.h> <answer> #include 
#include <token> <answer> <stdint.h> 
#include <token> <answer> <unistd.h> 
<token> <errno.h> <answer> #include 
<token> <fcntl.h> <answer> #include 
#include <token> <answer> <sys/types.h> 
<token> <sys/stat.h> <answer> #include 
#define <token> 32 <answer> MCPU 
<token> MSR_FIDVID_STATUS 0xc0010042 <answer> #define 
#define <token> 0x0000001f <answer> MSR_S_HI_CURRENT_VID 
#define <token> 0x0000003f <answer> MSR_S_LO_CURRENT_FID 
static int <token> cpu, uint32_t *fid, uint32_t *vid) <answer> get_fidvid(uint32_t 
int <token> = 1; <answer> err 
<token> msr = 0; <answer> uint64_t 
<token> fd; <answer> int 
char <token> <answer> file[20]; 
<token> (cpu > MCPU) <answer> if 
<token> out; <answer> goto 
sprintf(file, "/dev/cpu/%d/msr", <token> <answer> cpu); 
<token> = open(file, O_RDONLY); <answer> fd 
if (fd <token> 0) <answer> < 
<token> out; <answer> goto 
lseek(fd, <token> SEEK_CUR); <answer> MSR_FIDVID_STATUS, 
if (read(fd, &msr, 8) <token> 8) <answer> != 
<token> err1; <answer> goto 
*fid = ((uint32_t )(msr & 0xffffffffull)) <token> MSR_S_LO_CURRENT_FID; <answer> & 
*vid = ((uint32_t )(msr>>32 & <token> & MSR_S_HI_CURRENT_VID; <answer> 0xffffffffull)) 
err <token> 0; <answer> = 
<token> err; <answer> return 
#include <token> <answer> "fpa11.h" 
<token> "softfloat.h" <answer> #include 
#include <token> <answer> "fpopcode.h" 
<token> "fpsr.h" <answer> #include 
#include <token> <answer> "fpmodule.h" 
<token> "fpmodule.inl" <answer> #include 
#ifdef <token> <answer> CONFIG_FPE_NWFPE_XP 
const floatx80 <token> = { <answer> floatx80Constant[] 
#include <token> <answer> <linux/kernel.h> 
#include <token> <answer> <linux/module.h> 
<token> <linux/io.h> <answer> #include 
<token> <linux/slab.h> <answer> #include 
#include <token> <answer> <linux/of.h> 
<token> <linux/of_platform.h> <answer> #include 
#include <token> <answer> <linux/platform_device.h> 
#include <token> <answer> <linux/regmap.h> 
#include <token> <answer> <linux/mailbox_controller.h> 
<token> QCOM_APCS_IPC_BITS 32 <answer> #define 
struct qcom_apcs_ipc <token> <answer> { 
<token> mbox_controller mbox; <answer> struct 
struct mbox_chan <token> <answer> mbox_chans[QCOM_APCS_IPC_BITS]; 
struct regmap <token> <answer> *regmap; 
<token> long offset; <answer> unsigned 
struct <token> *clk; <answer> platform_device 
<token> qcom_apcs_ipc_data { <answer> struct 
int <token> <answer> offset; 
<token> *clk_name; <answer> char 
static const <token> qcom_apcs_ipc_data ipq6018_apcs_data = { <answer> struct 
<token> = 8, .clk_name = "qcom,apss-ipq6018-clk" <answer> .offset 
static const <token> qcom_apcs_ipc_data msm8916_apcs_data = { <answer> struct 
.offset = <token> .clk_name = "qcom-apcs-msm8916-clk" <answer> 8, 
static <token> struct qcom_apcs_ipc_data msm8994_apcs_data = { <answer> const 
<token> = 8, .clk_name = NULL <answer> .offset 
static const struct qcom_apcs_ipc_data msm8996_apcs_data = <token> <answer> { 
.offset = 16, .clk_name = <token> <answer> "qcom-apcs-msm8996-clk" 
static const <token> qcom_apcs_ipc_data apps_shared_apcs_data = { <answer> struct 
.offset = 12, .clk_name <token> NULL <answer> = 
static const struct qcom_apcs_ipc_data <token> = { <answer> sdx55_apcs_data 
.offset <token> 0x1008, .clk_name = "qcom-sdx55-acps-clk" <answer> = 
static const struct regmap_config apcs_regmap_config <token> { <answer> = 
.reg_bits = <token> <answer> 32, 
.reg_stride = <token> <answer> 4, 
.val_bits <token> 32, <answer> = 
<token> = 0x1008, <answer> .max_register 
<token> = true, <answer> .fast_io 
static int qcom_apcs_ipc_send_data(struct <token> *chan, void *data) <answer> mbox_chan 
struct <token> *apcs = container_of(chan->mbox, <answer> qcom_apcs_ipc 
struct qcom_apcs_ipc, <token> <answer> mbox); 
unsigned <token> idx = (unsigned long)chan->con_priv; <answer> long 
return <token> apcs->offset, BIT(idx)); <answer> regmap_write(apcs->regmap, 
static const struct mbox_chan_ops qcom_apcs_ipc_ops <token> { <answer> = 
<token> = qcom_apcs_ipc_send_data, <answer> .send_data 
static int qcom_apcs_ipc_probe(struct <token> *pdev) <answer> platform_device 
struct <token> *apcs; <answer> qcom_apcs_ipc 
const <token> qcom_apcs_ipc_data *apcs_data; <answer> struct 
struct regmap <token> <answer> *regmap; 
<token> __iomem *base; <answer> void 
unsigned long <token> <answer> i; 
int <token> <answer> ret; 
apcs = devm_kzalloc(&pdev->dev, <token> GFP_KERNEL); <answer> sizeof(*apcs), 
if <token> <answer> (!apcs) 
return <token> <answer> -ENOMEM; 
<token> = devm_platform_ioremap_resource(pdev, 0); <answer> base 
if <token> <answer> (IS_ERR(base)) 
<token> PTR_ERR(base); <answer> return 
regmap = devm_regmap_init_mmio(&pdev->dev, <token> &apcs_regmap_config); <answer> base, 
if <token> <answer> (IS_ERR(regmap)) 
return <token> <answer> PTR_ERR(regmap); 
apcs_data = <token> <answer> of_device_get_match_data(&pdev->dev); 
<token> = regmap; <answer> apcs->regmap 
apcs->offset = <token> <answer> apcs_data->offset; 
<token> "ramnv40.h" <answer> #include 
nv49_ram_new(struct <token> *fb, struct nvkm_ram **pram) <answer> nvkm_fb 
struct nvkm_device *device = <token> <answer> fb->subdev.device; 
u32 <token> = nvkm_rd32(device, 0x10020c) & 0xff000000; <answer> size 
u32 fb914 = nvkm_rd32(device, <token> <answer> 0x100914); 
<token> nvkm_ram_type type = NVKM_RAM_TYPE_UNKNOWN; <answer> enum 
int <token> <answer> ret; 
switch (fb914 <token> 0x00000003) { <answer> & 
case 0x00000000: <token> = NVKM_RAM_TYPE_DDR1 ; break; <answer> type 
<token> 0x00000001: type = NVKM_RAM_TYPE_DDR2 ; break; <answer> case 
case <token> type = NVKM_RAM_TYPE_GDDR3; break; <answer> 0x00000002: 
<token> 0x00000003: break; <answer> case 
ret = nv40_ram_new_(fb, type, size, <token> <answer> pram); 
<token> (ret) <answer> if 
return <token> <answer> ret; 
(*pram)->parts = (nvkm_rd32(device, 0x100200) & 0x00000003) <token> 1; <answer> + 
<token> 0; <answer> return 
#include <token> <answer> <linux/cpu.h> 
<token> <linux/cpumask.h> <answer> #include 
#include <token> <answer> <linux/kernel.h> 
<token> <linux/nmi.h> <answer> #include 
<token> <linux/percpu-defs.h> <answer> #include 
static cpumask_t <token> watchdog_cpus; <answer> __read_mostly 
static unsigned <token> watchdog_next_cpu(unsigned int cpu) <answer> int 
unsigned <token> next_cpu; <answer> int 
next_cpu = cpumask_next(cpu, <token> <answer> &watchdog_cpus); 
if <token> >= nr_cpu_ids) <answer> (next_cpu 
<token> = cpumask_first(&watchdog_cpus); <answer> next_cpu 
<token> (next_cpu == cpu) <answer> if 
return <token> <answer> nr_cpu_ids; 
return <token> <answer> next_cpu; 
<token> __init watchdog_hardlockup_probe(void) <answer> int 
<token> 0; <answer> return 
void <token> int cpu) <answer> watchdog_hardlockup_enable(unsigned 
unsigned <token> next_cpu; <answer> int 
<token> = watchdog_next_cpu(cpu); <answer> next_cpu 
<token> (next_cpu < nr_cpu_ids) <answer> if 
<token> &watchdog_cpus); <answer> cpumask_set_cpu(cpu, 
void <token> int cpu) <answer> watchdog_hardlockup_disable(unsigned 
<token> int next_cpu = watchdog_next_cpu(cpu); <answer> unsigned 
<token> (next_cpu < nr_cpu_ids) <answer> if 
<token> &watchdog_cpus); <answer> cpumask_clear_cpu(cpu, 
void watchdog_buddy_check_hardlockup(int <token> <answer> hrtimer_interrupts) 
unsigned int <token> <answer> next_cpu; 
if (hrtimer_interrupts <token> 3 != 0) <answer> % 
watchdog_hardlockup_check(next_cpu, <token> <answer> NULL); 
<token> <linux/mfd/wl1273-core.h> <answer> #include 
#include <token> <answer> <linux/slab.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <sound/pcm.h> 
<token> <sound/pcm_params.h> <answer> #include 
<token> <sound/soc.h> <answer> #include 
#include <token> <answer> <sound/initval.h> 
#include <token> <answer> "wl1273.h" 
enum wl1273_mode { WL1273_MODE_BT, <token> WL1273_MODE_FM_TX }; <answer> WL1273_MODE_FM_RX, 
static <token> char * const wl1273_audio_route[] = { "Bt", "FmRx", "FmTx" }; <answer> const 
static <token> snd_wl1273_set_audio_route(struct snd_kcontrol *kcontrol, <answer> int 
<token> snd_ctl_elem_value *ucontrol) <answer> struct 
struct snd_soc_component <token> = snd_soc_kcontrol_component(kcontrol); <answer> *component 
struct wl1273_priv *wl1273 = <token> <answer> snd_soc_component_get_drvdata(component); 
if (wl1273->mode == <token> <answer> ucontrol->value.enumerated.item[0]) 
<token> 0; <answer> return 
#include <token> <answer> <linux/if_ether.h> 
<token> <linux/if_vlan.h> <answer> #include 
<token> "opa_vnic_internal.h" <answer> #include 
static void <token> hlist_head *mactbl) <answer> opa_vnic_free_mac_tbl(struct 
<token> opa_vnic_mac_tbl_node *node; <answer> struct 
<token> hlist_node *tmp; <answer> struct 
int <token> <answer> bkt; 
<token> (!mactbl) <answer> if 
vnic_hash_for_each_safe(mactbl, <token> tmp, node, hlist) { <answer> bkt, 
<token> struct hlist_head *opa_vnic_alloc_mac_tbl(void) <answer> static 
<token> size = sizeof(struct hlist_head) * OPA_VNIC_MAC_TBL_SIZE; <answer> u32 
struct <token> *mactbl; <answer> hlist_head 
mactbl = kzalloc(size, <token> <answer> GFP_KERNEL); 
<token> (!mactbl) <answer> if 
return <token> <answer> ERR_PTR(-ENOMEM); 
<token> mactbl; <answer> return 
void opa_vnic_query_mac_tbl(struct opa_vnic_adapter <token> <answer> *adapter, 
struct <token> *tbl) <answer> opa_veswport_mactable 
<token> opa_vnic_mac_tbl_node *node; <answer> struct 
<token> hlist_head *mactbl; <answer> struct 
int <token> <answer> bkt; 
<token> loffset, lnum_entries; <answer> u16 
mactbl <token> rcu_dereference(adapter->mactbl); <answer> = 
<token> (!mactbl) <answer> if 
<token> get_mac_done; <answer> goto 
<token> = be16_to_cpu(tbl->offset); <answer> loffset 
<token> = be16_to_cpu(tbl->num_entries); <answer> lnum_entries 
vnic_hash_for_each(mactbl, bkt, node, hlist) <token> <answer> { 
<token> __opa_vnic_mactable_entry *nentry = &node->entry; <answer> struct 
<token> opa_veswport_mactable_entry *entry; <answer> struct 
if <token> < loffset) || <answer> ((node->index 
(node->index >= <token> + lnum_entries))) <answer> (loffset 
<token> opa_vnic_update_mac_tbl(struct opa_vnic_adapter *adapter, <answer> int 
struct <token> *tbl) <answer> opa_veswport_mactable 
struct <token> *node, *new_node; <answer> opa_vnic_mac_tbl_node 
struct <token> *new_mactbl, *old_mactbl; <answer> hlist_head 
int i, bkt, rc = <token> <answer> 0; 
<token> key; <answer> u8 
u16 <token> lnum_entries; <answer> loffset, 
#include <token> <answer> <linux/sched.h> 
<token> <linux/linkage.h> <answer> #include 
#include <token> <answer> <linux/ptrace.h> 
<token> <linux/errno.h> <answer> #include 
<token> <linux/kernel_stat.h> <answer> #include 
<token> <linux/signal.h> <answer> #include 
<token> <linux/mm.h> <answer> #include 
#include <token> <answer> <linux/interrupt.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/random.h> <answer> #include 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/proc_fs.h> 
#include <token> <answer> <linux/seq_file.h> 
#include <token> <answer> <linux/ftrace.h> 
#include <token> <answer> <linux/irq.h> 
#include <token> <answer> <asm/ptrace.h> 
#include <token> <answer> <asm/processor.h> 
#include <token> <answer> <linux/atomic.h> 
<token> <asm/irq.h> <answer> #include 
<token> <asm/io.h> <answer> #include 
<token> <asm/iommu.h> <answer> #include 
<token> <asm/upa.h> <answer> #include 
<token> <asm/oplib.h> <answer> #include 
<token> <asm/prom.h> <answer> #include 
<token> <asm/timer.h> <answer> #include 
#include <token> <answer> <asm/smp.h> 
#include <token> <answer> <asm/starfire.h> 
#include <token> <answer> <linux/uaccess.h> 
<token> <asm/cache.h> <answer> #include 
#include <token> <answer> <asm/cpudata.h> 
<token> <asm/auxio.h> <answer> #include 
<token> <asm/head.h> <answer> #include 
#include <token> <answer> <asm/hypervisor.h> 
<token> <asm/cacheflush.h> <answer> #include 
#include <token> <answer> <asm/softirq_stack.h> 
<token> "entry.h" <answer> #include 
<token> "cpumap.h" <answer> #include 
<token> "kstack.h" <answer> #include 
<token> ino_bucket *ivector_table; <answer> struct 
unsigned long <token> <answer> ivector_table_pa; 
static unsigned long bucket_get_chain_pa(unsigned <token> bucket_pa) <answer> long 
unsigned <token> ret; <answer> long 
__asm__ __volatile__("ldxa [%1] %2, <token> <answer> %0" 
: <token> (ret) <answer> "=&r" 
<token> "r" (bucket_pa + <answer> : 
<token> ino_bucket, <answer> offsetof(struct 
"i" <token> <answer> (ASI_PHYS_USE_EC)); 
<token> ret; <answer> return 
static void <token> long bucket_pa) <answer> bucket_clear_chain_pa(unsigned 
__asm__ <token> %%g0, [%0] %1" <answer> __volatile__("stxa 
<token> bool sun4v_cookie_only_virqs(void) <answer> static 
<token> (hv_irq_version >= 3) <answer> if 
return <token> <answer> true; 
<token> false; <answer> return 
static <token> __init irq_init_hv(void) <answer> void 
<token> long hv_error, major, minor = 0; <answer> unsigned 
if (tlb_type <token> hypervisor) <answer> != 
<token> (hvirq_major) <answer> if 
major <token> hvirq_major; <answer> = 
<token> = 3; <answer> major 
<token> = sun4v_hvapi_register(HV_GRP_INTR, major, &minor); <answer> hv_error 
<token> (!hv_error) <answer> if 
hv_irq_version <token> major; <answer> = 
hv_irq_version = <token> <answer> 1; 
pr_info("SUN4V: Using IRQ API major <token> cookie only virqs %s\n", <answer> %d, 
sun4v_cookie_only_virqs() <token> "enabled" : "disabled"); <answer> ? 
int arch_show_interrupts(struct seq_file *p, int <token> <answer> prec) 
int <token> <answer> j; 
seq_printf(p, <token> "); <answer> "NMI: 
seq_printf(p, "%10u ", <token> <answer> cpu_data(j).__nmi_count); 
seq_printf(p, " Non-maskable <token> <answer> interrupts\n"); 
return <token> <answer> 0; 
<token> unsigned int sun4u_compute_tid(unsigned long imap, unsigned long cpuid) <answer> static 
unsigned <token> tid; <answer> int 
<token> (this_is_starfire) { <answer> if 
tid <token> starfire_translate(imap, cpuid); <answer> = 
tid <<= <token> <answer> IMAP_TID_SHIFT; 
<token> &= IMAP_TID_UPA; <answer> tid 
} <token> { <answer> else 
if (tlb_type == cheetah || tlb_type <token> cheetah_plus) { <answer> == 
unsigned long <token> <answer> ver; 
__asm__ ("rdpr <token> %0" : "=r" (ver)); <answer> %%ver, 
if ((ver >> <token> == __JALAPENO_ID || <answer> 32UL) 
(ver <token> 32UL) == __SERRANO_ID) { <answer> >> 
tid = <token> << IMAP_TID_SHIFT; <answer> cpuid 
<token> &= IMAP_TID_JBUS; <answer> tid 
} <token> { <answer> else 
unsigned int a = <token> & 0x1f; <answer> cpuid 
unsigned int n = <token> >> 5) & 0x1f; <answer> (cpuid 
tid = ((a <token> IMAP_AID_SHIFT) | <answer> << 
<token> << IMAP_NID_SHIFT)); <answer> (n 
tid <token> (IMAP_AID_SAFARI | <answer> &= 
<token> else { <answer> } 
tid = <token> << IMAP_TID_SHIFT; <answer> cpuid 
<token> &= IMAP_TID_UPA; <answer> tid 
<token> tid; <answer> return 
<token> CONFIG_SMP <answer> #ifdef 
static <token> irq_choose_cpu(unsigned int irq, const struct cpumask *affinity) <answer> int 
<token> mask; <answer> cpumask_t 
<token> cpuid; <answer> int 
cpumask_copy(&mask, <token> <answer> affinity); 
<token> (cpumask_equal(&mask, cpu_online_mask)) { <answer> if 
cpuid = <token> <answer> map_to_cpu(irq); 
} else <token> <answer> { 
<token> tmp; <answer> cpumask_t 
cpumask_and(&tmp, <token> &mask); <answer> cpu_online_mask, 
cpuid = <token> ? map_to_cpu(irq) : cpumask_first(&tmp); <answer> cpumask_empty(&tmp) 
<token> cpuid; <answer> return 
#define irq_choose_cpu(irq, <token> \ <answer> affinity) 
static void sun4u_irq_enable(struct irq_data <token> <answer> *data) 
<token> irq_handler_data *handler_data; <answer> struct 
<token> = irq_data_get_irq_handler_data(data); <answer> handler_data 
if <token> { <answer> (likely(handler_data)) 
<token> long cpuid, imap, val; <answer> unsigned 
unsigned int <token> <answer> tid; 
<token> = irq_choose_cpu(data->irq, <answer> cpuid 
imap <token> handler_data->imap; <answer> = 
tid = <token> cpuid); <answer> sun4u_compute_tid(imap, 
val = <token> <answer> upa_readq(imap); 
val &= ~(IMAP_TID_UPA | IMAP_TID_JBUS <token> <answer> | 
IMAP_AID_SAFARI | <token> <answer> IMAP_NID_SAFARI); 
val |= tid <token> IMAP_VALID; <answer> | 
upa_writeq(val, <token> <answer> imap); 
upa_writeq(ICLR_IDLE, <token> <answer> handler_data->iclr); 
static int sun4u_set_affinity(struct irq_data <token> <answer> *data, 
<token> struct cpumask *mask, bool force) <answer> const 
<token> irq_handler_data *handler_data; <answer> struct 
<token> = irq_data_get_irq_handler_data(data); <answer> handler_data 
<token> (likely(handler_data)) { <answer> if 
unsigned <token> cpuid, imap, val; <answer> long 
unsigned <token> tid; <answer> int 
cpuid = irq_choose_cpu(data->irq, <token> <answer> mask); 
<token> = handler_data->imap; <answer> imap 
tid <token> sun4u_compute_tid(imap, cpuid); <answer> = 
<token> = upa_readq(imap); <answer> val 
val &= <token> | IMAP_TID_JBUS | <answer> ~(IMAP_TID_UPA 
<token> | IMAP_NID_SAFARI); <answer> IMAP_AID_SAFARI 
<token> |= tid | IMAP_VALID; <answer> val 
upa_writeq(val, <token> <answer> imap); 
<token> handler_data->iclr); <answer> upa_writeq(ICLR_IDLE, 
<token> 0; <answer> return 
static void <token> irq_data *data) <answer> sun4u_irq_disable(struct 
static void sun4u_irq_eoi(struct <token> *data) <answer> irq_data 
<token> irq_handler_data *handler_data; <answer> struct 
<token> = irq_data_get_irq_handler_data(data); <answer> handler_data 
<token> (likely(handler_data)) <answer> if 
<token> handler_data->iclr); <answer> upa_writeq(ICLR_IDLE, 
static void <token> irq_data *data) <answer> sun4v_irq_enable(struct 
unsigned long cpuid <token> irq_choose_cpu(data->irq, <answer> = 
unsigned int <token> = irq_data_to_sysino(data); <answer> ino 
int <token> <answer> err; 
err <token> sun4v_intr_settarget(ino, cpuid); <answer> = 
if (err != <token> <answer> HV_EOK) 
<token> "sun4v_intr_settarget(%x,%lu): " <answer> printk(KERN_ERR 
"err(%d)\n", ino, <token> err); <answer> cpuid, 
err = sun4v_intr_setstate(ino, <token> <answer> HV_INTR_STATE_IDLE); 
<token> (err != HV_EOK) <answer> if 
printk(KERN_ERR "sun4v_intr_setstate(%x): <token> <answer> " 
"err(%d)\n", <token> err); <answer> ino, 
err = <token> HV_INTR_ENABLED); <answer> sun4v_intr_setenabled(ino, 
if <token> != HV_EOK) <answer> (err 
printk(KERN_ERR <token> err(%d)\n", <answer> "sun4v_intr_setenabled(%x): 
ino, <token> <answer> err); 
static int sun4v_set_affinity(struct irq_data <token> <answer> *data, 
const struct cpumask <token> bool force) <answer> *mask, 
unsigned long cpuid = irq_choose_cpu(data->irq, <token> <answer> mask); 
unsigned int <token> = irq_data_to_sysino(data); <answer> ino 
int <token> <answer> err; 
err = sun4v_intr_settarget(ino, <token> <answer> cpuid); 
if (err != <token> <answer> HV_EOK) 
printk(KERN_ERR <token> " <answer> "sun4v_intr_settarget(%x,%lu): 
"err(%d)\n", ino, cpuid, <token> <answer> err); 
<token> 0; <answer> return 
static void <token> irq_data *data) <answer> sun4v_irq_disable(struct 
unsigned <token> ino = irq_data_to_sysino(data); <answer> int 
<token> err; <answer> int 
err = sun4v_intr_setenabled(ino, <token> <answer> HV_INTR_DISABLED); 
if (err != <token> <answer> HV_EOK) 
<token> "sun4v_intr_setenabled(%x): " <answer> printk(KERN_ERR 
<token> ino, err); <answer> "err(%d)\n", 
static void sun4v_irq_eoi(struct <token> *data) <answer> irq_data 
<token> int ino = irq_data_to_sysino(data); <answer> unsigned 
int <token> <answer> err; 
err = <token> HV_INTR_STATE_IDLE); <answer> sun4v_intr_setstate(ino, 
<token> (err != HV_EOK) <answer> if 
printk(KERN_ERR "sun4v_intr_setstate(%x): <token> <answer> " 
"err(%d)\n", <token> err); <answer> ino, 
<token> void sun4v_virq_enable(struct irq_data *data) <answer> static 
unsigned <token> dev_handle = irq_data_to_handle(data); <answer> long 
<token> long dev_ino = irq_data_to_ino(data); <answer> unsigned 
unsigned <token> cpuid; <answer> long 
int <token> <answer> err; 
cpuid <token> irq_choose_cpu(data->irq, irq_data_get_affinity_mask(data)); <answer> = 
<token> = sun4v_vintr_set_target(dev_handle, dev_ino, cpuid); <answer> err 
<token> (err != HV_EOK) <answer> if 
printk(KERN_ERR "sun4v_vintr_set_target(%lx,%lx,%lu): <token> <answer> " 
dev_handle, dev_ino, cpuid, <token> <answer> err); 
<token> = sun4v_vintr_set_state(dev_handle, dev_ino, <answer> err 
if (err <token> HV_EOK) <answer> != 
printk(KERN_ERR <token> <answer> "sun4v_vintr_set_state(%lx,%lx," 
"HV_INTR_STATE_IDLE): <token> <answer> err(%d)\n", 
<token> dev_ino, err); <answer> dev_handle, 
err = sun4v_vintr_set_valid(dev_handle, <token> <answer> dev_ino, 
if <token> != HV_EOK) <answer> (err 
<token> "sun4v_vintr_set_state(%lx,%lx," <answer> printk(KERN_ERR 
<token> err(%d)\n", <answer> "HV_INTR_ENABLED): 
dev_handle, <token> err); <answer> dev_ino, 
static int <token> irq_data *data, <answer> sun4v_virt_set_affinity(struct 
const struct <token> *mask, bool force) <answer> cpumask 
unsigned long <token> = irq_data_to_handle(data); <answer> dev_handle 
unsigned long dev_ino = <token> <answer> irq_data_to_ino(data); 
<token> long cpuid; <answer> unsigned 
int <token> <answer> err; 
cpuid <token> irq_choose_cpu(data->irq, mask); <answer> = 
err = sun4v_vintr_set_target(dev_handle, <token> cpuid); <answer> dev_ino, 
if (err != <token> <answer> HV_EOK) 
printk(KERN_ERR <token> " <answer> "sun4v_vintr_set_target(%lx,%lx,%lu): 
<token> dev_ino, cpuid, err); <answer> dev_handle, 
<token> 0; <answer> return 
<token> void sun4v_virq_disable(struct irq_data *data) <answer> static 
unsigned long <token> = irq_data_to_handle(data); <answer> dev_handle 
unsigned <token> dev_ino = irq_data_to_ino(data); <answer> long 
int <token> <answer> err; 
err = sun4v_vintr_set_valid(dev_handle, <token> <answer> dev_ino, 
<token> (err != HV_EOK) <answer> if 
printk(KERN_ERR <token> <answer> "sun4v_vintr_set_state(%lx,%lx," 
<token> err(%d)\n", <answer> "HV_INTR_DISABLED): 
<token> dev_ino, err); <answer> dev_handle, 
<token> void sun4v_virq_eoi(struct irq_data *data) <answer> static 
unsigned long <token> = irq_data_to_handle(data); <answer> dev_handle 
unsigned long dev_ino <token> irq_data_to_ino(data); <answer> = 
int <token> <answer> err; 
err = <token> dev_ino, <answer> sun4v_vintr_set_state(dev_handle, 
if <token> != HV_EOK) <answer> (err 
<token> "sun4v_vintr_set_state(%lx,%lx," <answer> printk(KERN_ERR 
"HV_INTR_STATE_IDLE): <token> <answer> err(%d)\n", 
dev_handle, dev_ino, <token> <answer> err); 
static struct irq_chip <token> = { <answer> sun4u_irq 
.name = <token> <answer> "sun4u", 
<token> = sun4u_irq_enable, <answer> .irq_enable 
.irq_disable = <token> <answer> sun4u_irq_disable, 
.irq_eoi <token> sun4u_irq_eoi, <answer> = 
.irq_set_affinity <token> sun4u_set_affinity, <answer> = 
<token> = IRQCHIP_EOI_IF_HANDLED, <answer> .flags 
static struct <token> sun4v_irq = { <answer> irq_chip 
.name <token> "sun4v", <answer> = 
.irq_enable = <token> <answer> sun4v_irq_enable, 
.irq_disable <token> sun4v_irq_disable, <answer> = 
<token> = sun4v_irq_eoi, <answer> .irq_eoi 
.irq_set_affinity <token> sun4v_set_affinity, <answer> = 
<token> = IRQCHIP_EOI_IF_HANDLED, <answer> .flags 
<token> struct irq_chip sun4v_virq = { <answer> static 
.name <token> "vsun4v", <answer> = 
<token> = sun4v_virq_enable, <answer> .irq_enable 
.irq_disable = <token> <answer> sun4v_virq_disable, 
.irq_eoi = <token> <answer> sun4v_virq_eoi, 
.irq_set_affinity <token> sun4v_virt_set_affinity, <answer> = 
<token> = IRQCHIP_EOI_IF_HANDLED, <answer> .flags 
<token> int build_irq(int inofixup, unsigned long iclr, unsigned long imap) <answer> unsigned 
<token> irq_handler_data *handler_data; <answer> struct 
struct <token> *bucket; <answer> ino_bucket 
unsigned <token> irq; <answer> int 
int <token> <answer> ino; 
<token> == hypervisor); <answer> BUG_ON(tlb_type 
ino = (upa_readq(imap) & (IMAP_IGN | IMAP_INO)) + <token> <answer> inofixup; 
bucket <token> &ivector_table[ino]; <answer> = 
irq <token> bucket_get_irq(__pa(bucket)); <answer> = 
<token> (!irq) { <answer> if 
irq = irq_alloc(0, <token> <answer> ino); 
<token> irq); <answer> bucket_set_irq(__pa(bucket), 
irq_set_chip_and_handler_name(irq, <token> <answer> &sun4u_irq, 
<token> "IVEC"); <answer> handle_fasteoi_irq, 
handler_data = <token> <answer> irq_get_handler_data(irq); 
<token> (unlikely(handler_data)) <answer> if 
goto <token> <answer> out; 
handler_data = <token> irq_handler_data), GFP_ATOMIC); <answer> kzalloc(sizeof(struct 
if (unlikely(!handler_data)) <token> <answer> { 
prom_printf("IRQ: kzalloc(irq_handler_data) <token> <answer> failed.\n"); 
irq_set_handler_data(irq, <token> <answer> handler_data); 
handler_data->imap = <token> <answer> imap; 
handler_data->iclr = <token> <answer> iclr; 
<token> irq; <answer> return 
<token> unsigned int sun4v_build_common(u32 devhandle, unsigned int devino, <answer> static 
void <token> irq_handler_data *data, <answer> (*handler_data_init)(struct 
u32 <token> unsigned int devino), <answer> devhandle, 
<token> irq_chip *chip) <answer> struct 
<token> irq_handler_data *data; <answer> struct 
unsigned int <token> <answer> irq; 
irq <token> irq_alloc(devhandle, devino); <answer> = 
if <token> <answer> (!irq) 
goto <token> <answer> out; 
data = kzalloc(sizeof(struct irq_handler_data), <token> <answer> GFP_ATOMIC); 
<token> (unlikely(!data)) { <answer> if 
pr_err("IRQ handler data allocation <token> <answer> failed.\n"); 
<token> = 0; <answer> irq 
goto <token> <answer> out; 
irq_set_handler_data(irq, <token> <answer> data); 
<token> devhandle, devino); <answer> handler_data_init(data, 
irq_set_chip_and_handler_name(irq, chip, <token> "IVEC"); <answer> handle_fasteoi_irq, 
data->imap <token> ~0UL; <answer> = 
<token> = ~0UL; <answer> data->iclr 
<token> irq; <answer> return 
static unsigned long cookie_assign(unsigned int irq, u32 <token> <answer> devhandle, 
unsigned int <token> <answer> devino) 
<token> irq_handler_data *ihd = irq_get_handler_data(irq); <answer> struct 
unsigned <token> hv_error, cookie; <answer> long 
<token> = irq; <answer> ihd->bucket.__irq 
cookie <token> ~__pa(&ihd->bucket); <answer> = 
<token> = sun4v_vintr_set_cookie(devhandle, devino, cookie); <answer> hv_error 
if <token> <answer> (hv_error) 
pr_err("HV vintr set cookie failed = <token> hv_error); <answer> %ld\n", 
<token> hv_error; <answer> return 
static void cookie_handler_data(struct irq_handler_data <token> <answer> *data, 
u32 devhandle, unsigned int <token> <answer> devino) 
data->dev_handle = <token> <answer> devhandle; 
<token> = devino; <answer> data->dev_ino 
static unsigned int cookie_build_irq(u32 devhandle, unsigned <token> devino, <answer> int 
struct <token> *chip) <answer> irq_chip 
unsigned <token> hv_error; <answer> long 
<token> int irq; <answer> unsigned 
irq = sun4v_build_common(devhandle, devino, <token> chip); <answer> cookie_handler_data, 
<token> = cookie_assign(irq, devhandle, devino); <answer> hv_error 
if (hv_error) <token> <answer> { 
<token> = 0; <answer> irq 
return <token> <answer> irq; 
static unsigned int sun4v_build_cookie(u32 devhandle, <token> int devino) <answer> unsigned 
unsigned int <token> <answer> irq; 
irq = cookie_exists(devhandle, <token> <answer> devino); 
<token> (irq) <answer> if 
goto <token> <answer> out; 
irq <token> cookie_build_irq(devhandle, devino, &sun4v_virq); <answer> = 
<token> irq; <answer> return 
<token> void sysino_set_bucket(unsigned int irq) <answer> static 
struct irq_handler_data *ihd <token> irq_get_handler_data(irq); <answer> = 
struct <token> *bucket; <answer> ino_bucket 
unsigned <token> sysino; <answer> long 
sysino <token> sun4v_devino_to_sysino(ihd->dev_handle, ihd->dev_ino); <answer> = 
BUG_ON(sysino >= <token> <answer> nr_ivec); 
<token> = &ivector_table[sysino]; <answer> bucket 
bucket_set_irq(__pa(bucket), <token> <answer> irq); 
<token> void sysino_handler_data(struct irq_handler_data *data, <answer> static 
u32 devhandle, <token> int devino) <answer> unsigned 
<token> long sysino; <answer> unsigned 
sysino <token> sun4v_devino_to_sysino(devhandle, devino); <answer> = 
data->sysino = <token> <answer> sysino; 
static unsigned <token> sysino_build_irq(u32 devhandle, unsigned int devino, <answer> int 
struct <token> *chip) <answer> irq_chip 
unsigned int <token> <answer> irq; 
irq = sun4v_build_common(devhandle, <token> sysino_handler_data, chip); <answer> devino, 
<token> (!irq) <answer> if 
<token> out; <answer> goto 
return <token> <answer> irq; 
static int sun4v_build_sysino(u32 <token> unsigned int devino) <answer> devhandle, 
<token> irq; <answer> int 
irq = <token> devino); <answer> sysino_exists(devhandle, 
<token> (irq) <answer> if 
goto <token> <answer> out; 
irq = sysino_build_irq(devhandle, <token> &sun4v_irq); <answer> devino, 
<token> irq; <answer> return 
unsigned int sun4v_build_irq(u32 devhandle, unsigned int <token> <answer> devino) 
unsigned int <token> <answer> irq; 
<token> (sun4v_cookie_only_virqs()) <answer> if 
irq = <token> devino); <answer> sun4v_build_cookie(devhandle, 
<token> = sun4v_build_sysino(devhandle, devino); <answer> irq 
<token> irq; <answer> return 
unsigned int sun4v_build_virq(u32 <token> unsigned int devino) <answer> devhandle, 
<token> irq; <answer> int 
irq = <token> devino, &sun4v_virq); <answer> cookie_build_irq(devhandle, 
if <token> <answer> (!irq) 
goto <token> <answer> out; 
<token> IRQ_NOAUTOEN); <answer> irq_set_status_flags(irq, 
<token> irq; <answer> return 
<token> *hardirq_stack[NR_CPUS]; <answer> void 
void <token> <answer> *softirq_stack[NR_CPUS]; 
<token> __irq_entry handler_irq(int pil, struct pt_regs *regs) <answer> void 
<token> long pstate, bucket_pa; <answer> unsigned 
<token> pt_regs *old_regs; <answer> struct 
void <token> <answer> *orig_sp; 
clear_softint(1 << <token> <answer> pil); 
<token> = set_irq_regs(regs); <answer> old_regs 
if <token> { <answer> (!dp) 
prom_timers <token> (struct sun5_timer *) 0; <answer> = 
<token> = 0; <answer> prom_timers->limit0 
<token> = 0; <answer> prom_timers->limit1 
static void notrace <token> long paddr, unsigned long type, <answer> register_one_mondo(unsigned 
<token> long qmask) <answer> unsigned 
unsigned long num_entries = (qmask + <token> / 64; <answer> 1) 
unsigned <token> status; <answer> long 
<token> = sun4v_cpu_qconf(type, paddr, num_entries); <answer> status 
if <token> != HV_EOK) { <answer> (status 
prom_printf("SUN4V: <token> failed, " <answer> sun4v_cpu_qconf(%lu:%lx:%lu) 
"err %lu\n", <token> paddr, num_entries, status); <answer> type, 
void <token> sun4v_register_mondo_queues(int this_cpu) <answer> notrace 
struct trap_per_cpu <token> = &trap_block[this_cpu]; <answer> *tb 
register_one_mondo(tb->cpu_mondo_pa, <token> <answer> HV_CPU_QUEUE_CPU_MONDO, 
<token> HV_CPU_QUEUE_DEVICE_MONDO, <answer> register_one_mondo(tb->dev_mondo_pa, 
register_one_mondo(tb->resum_mondo_pa, <token> <answer> HV_CPU_QUEUE_RES_ERROR, 
register_one_mondo(tb->nonresum_mondo_pa, <token> <answer> HV_CPU_QUEUE_NONRES_ERROR, 
<token> void __init alloc_one_queue(unsigned long *pa_ptr, unsigned long qmask) <answer> static 
<token> long size = PAGE_ALIGN(qmask + 1); <answer> unsigned 
unsigned long order = <token> <answer> get_order(size); 
unsigned long <token> <answer> p; 
p <token> __get_free_pages(GFP_KERNEL | __GFP_ZERO, order); <answer> = 
<token> (!p) { <answer> if 
prom_printf("SUN4V: Error, cannot allocate <token> <answer> queue.\n"); 
*pa_ptr = <token> <answer> __pa(p); 
static <token> __init init_cpu_send_mondo_info(struct trap_per_cpu *tb) <answer> void 
<token> CONFIG_SMP <answer> #ifdef 
unsigned long <token> <answer> page; 
<token> *mondo, *p; <answer> void 
BUILD_BUG_ON((NR_CPUS * sizeof(u16)) <token> PAGE_SIZE); <answer> > 
<token> (sun4v_cookie_only_virqs()) <answer> if 
ivecs = <token> <answer> size_nr_ivec(); 
size = sizeof(struct ino_bucket) <token> ivecs; <answer> * 
<token> = get_order(size); <answer> order 
ivector_table = (struct <token> *) <answer> ino_bucket 
__get_free_pages(GFP_KERNEL | __GFP_ZERO, <token> <answer> order); 
<token> (!ivector_table) { <answer> if 
prom_printf("Fatal error, cannot <token> ivector_table\n"); <answer> allocate 
__flush_dcache_range((unsigned long) <token> <answer> ivector_table, 
((unsigned <token> ivector_table) + size); <answer> long) 
ivector_table_pa = <token> <answer> __pa(ivector_table); 
__asm__ <token> %%pstate, %%g1\n\t" <answer> __volatile__("rdpr 
"or <token> %0, %%g1\n\t" <answer> %%g1, 
<token> %%g1, 0x0, %%pstate" <answer> "wrpr 
<token> <linux/module.h> <answer> #include 
<token> <linux/kernel.h> <answer> #include 
<token> <linux/errno.h> <answer> #include 
#include <token> <answer> <linux/string.h> 
#include <token> <answer> <linux/delay.h> 
#include <token> <answer> <linux/init.h> 
#include <token> <answer> <linux/fb.h> 
#include <token> <answer> <linux/mm.h> 
#include <token> <answer> <linux/of.h> 
#include <token> <answer> <linux/platform_device.h> 
<token> <asm/io.h> <answer> #include 
#include <token> <answer> <asm/fbio.h> 
<token> "sbuslib.h" <answer> #include 
static int cg3_setcolreg(unsigned, unsigned, <token> unsigned, <answer> unsigned, 
unsigned, struct fb_info <token> <answer> *); 
<token> int cg3_blank(int, struct fb_info *); <answer> static 
static int cg3_sbusfb_mmap(struct <token> *info, struct vm_area_struct *vma); <answer> fb_info 
static int cg3_sbusfb_ioctl(struct <token> *info, unsigned int cmd, unsigned long arg); <answer> fb_info 
static const struct fb_ops cg3_ops <token> { <answer> = 
.owner <token> THIS_MODULE, <answer> = 
.fb_setcolreg <token> cg3_setcolreg, <answer> = 
.fb_blank <token> cg3_blank, <answer> = 
static int cg3_setcolreg(unsigned <token> <answer> regno, 
unsigned red, unsigned green, unsigned <token> <answer> blue, 
unsigned transp, struct fb_info <token> <answer> *info) 
struct cg3_par *par = (struct <token> *) info->par; <answer> cg3_par 
struct bt_regs __iomem *bt = <token> <answer> &par->regs->cmap; 
<token> long flags; <answer> unsigned 
<token> *p32; <answer> u32 
u8 <token> <answer> *p8; 
int <token> <answer> count; 
if <token> >= 256) <answer> (regno 
<token> 1; <answer> return 
red >>= <token> <answer> 8; 
green <token> 8; <answer> >>= 
blue >>= <token> <answer> 8; 
spin_lock_irqsave(&par->lock, <token> <answer> flags); 
p8 = (u8 *)par->sw_cmap + <token> * 3); <answer> (regno 
p8[0] <token> red; <answer> = 
p8[1] = <token> <answer> green; 
p8[2] <token> blue; <answer> = 
<token> int cg3_blank(int blank, struct fb_info *info) <answer> static 
struct cg3_par <token> = (struct cg3_par *) info->par; <answer> *par 
struct cg3_regs __iomem *regs = <token> <answer> par->regs; 
<token> long flags; <answer> unsigned 
<token> val; <answer> u8 
spin_lock_irqsave(&par->lock, <token> <answer> flags); 
switch <token> { <answer> (blank) 
<token> void cg3_init_fix(struct fb_info *info, int linebytes, <answer> static 
struct device_node <token> <answer> *dp) 
snprintf(info->fix.id, sizeof(info->fix.id), <token> dp); <answer> "%pOFn", 
<token> = FB_TYPE_PACKED_PIXELS; <answer> info->fix.type 
<token> = FB_VISUAL_PSEUDOCOLOR; <answer> info->fix.visual 
info->fix.line_length <token> linebytes; <answer> = 
info->fix.accel = <token> <answer> FB_ACCEL_SUN_CGTHREE; 
static void <token> fb_var_screeninfo *var, <answer> cg3_rdi_maybe_fixup_var(struct 
<token> device_node *dp) <answer> struct 
<token> char *params; <answer> const 
char <token> <answer> *p; 
int ww, <token> <answer> hh; 
<token> = of_get_property(dp, "params", NULL); <answer> params 
if <token> { <answer> (params) 
<token> = simple_strtoul(params, &p, 10); <answer> ww 
if (ww && *p == 'x') <token> <answer> { 
hh = simple_strtoul(p + 1, &p, <token> <answer> 10); 
if (hh && *p == '-') <token> <answer> { 
if <token> != ww || <answer> (var->xres 
var->yres <token> hh) { <answer> != 
var->xres = <token> = ww; <answer> var->xres_virtual 
var->yres = <token> = hh; <answer> var->yres_virtual 
<token> <linux/netdevice.h> <answer> #include 
#include <token> <answer> <linux/mctp.h> 
#include <token> <answer> <linux/if_arp.h> 
#include <token> <answer> <net/mctp.h> 
#include <token> <answer> <net/mctpdevice.h> 
#include <token> <answer> <net/pkt_sched.h> 
#include <token> <answer> "utils.h" 
static <token> mctp_test_dev_tx(struct sk_buff *skb, <answer> netdev_tx_t 
<token> net_device *ndev) <answer> struct 
return <token> <answer> NETDEV_TX_OK; 
static const struct <token> mctp_test_netdev_ops = { <answer> net_device_ops 
.ndo_start_xmit <token> mctp_test_dev_tx, <answer> = 
<token> void mctp_test_dev_setup(struct net_device *ndev) <answer> static 
ndev->type = <token> <answer> ARPHRD_MCTP; 
ndev->mtu <token> MCTP_DEV_TEST_MTU; <answer> = 
ndev->hard_header_len <token> 0; <answer> = 
ndev->addr_len = <token> <answer> 0; 
<token> = DEFAULT_TX_QUEUE_LEN; <answer> ndev->tx_queue_len 
ndev->flags = <token> <answer> IFF_NOARP; 
ndev->netdev_ops <token> &mctp_test_netdev_ops; <answer> = 
ndev->needs_free_netdev = <token> <answer> true; 
<token> mctp_test_dev *mctp_test_create_dev(void) <answer> struct 
<token> mctp_test_dev *dev; <answer> struct 
struct <token> *ndev; <answer> net_device 
int <token> <answer> rc; 
ndev = alloc_netdev(sizeof(*dev), "mctptest%d", <token> <answer> NET_NAME_ENUM, 
<token> (!ndev) <answer> if 
return <token> <answer> NULL; 
dev = <token> <answer> netdev_priv(ndev); 
<token> = ndev; <answer> dev->ndev 
rc = <token> <answer> register_netdev(ndev); 
if (rc) <token> <answer> { 
return <token> <answer> NULL; 
<token> = __mctp_dev_get(ndev); <answer> dev->mdev 
dev->mdev->net = <token> <answer> mctp_default_net(dev_net(ndev)); 
<token> dev; <answer> return 
void mctp_test_destroy_dev(struct <token> *dev) <answer> mctp_test_dev 
#define pr_fmt(fmt) <token> ": " fmt <answer> KBUILD_MODNAME 
#include <token> <answer> <linux/bitops.h> 
#include <token> <answer> <linux/device.h> 
#include <token> <answer> <linux/err.h> 
#include <token> <answer> <linux/gfp.h> 
<token> <linux/hwmon.h> <answer> #include 
<token> <linux/idr.h> <answer> #include 
<token> <linux/kstrtox.h> <answer> #include 
#include <token> <answer> <linux/list.h> 
#include <token> <answer> <linux/module.h> 
#include <token> <answer> <linux/pci.h> 
#include <token> <answer> <linux/property.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/string.h> <answer> #include 
<token> <linux/thermal.h> <answer> #include 
<token> CREATE_TRACE_POINTS <answer> #define 
#include <token> <answer> <trace/events/hwmon.h> 
<token> HWMON_ID_PREFIX "hwmon" <answer> #define 
<token> HWMON_ID_FORMAT HWMON_ID_PREFIX "%d" <answer> #define 
<token> hwmon_device { <answer> struct 
<token> char *name; <answer> const 
const <token> *label; <answer> char 
struct device <token> <answer> dev; 
const struct hwmon_chip_info <token> <answer> *chip; 
struct list_head <token> <answer> tzdata; 
<token> attribute_group group; <answer> struct 
const struct attribute_group <token> <answer> **groups; 
<token> to_hwmon_device(d) container_of(d, struct hwmon_device, dev) <answer> #define 
#define <token> 32 <answer> MAX_SYSFS_ATTR_NAME_LENGTH 
struct <token> { <answer> hwmon_device_attribute 
struct device_attribute <token> <answer> dev_attr; 
const <token> hwmon_ops *ops; <answer> struct 
enum hwmon_sensor_types <token> <answer> type; 
<token> attr; <answer> u32 
<token> index; <answer> int 
char <token> <answer> name[MAX_SYSFS_ATTR_NAME_LENGTH]; 
<token> to_hwmon_attr(d) \ <answer> #define 
<token> struct hwmon_device_attribute, dev_attr) <answer> container_of(d, 
#define to_dev_attr(a) <token> struct device_attribute, attr) <answer> container_of(a, 
struct hwmon_thermal_data <token> <answer> { 
#ifdef <token> <answer> CONFIG_THERMAL_OF 
static int hwmon_thermal_get_temp(struct thermal_zone_device *tz, int <token> <answer> *temp) 
struct hwmon_thermal_data <token> = thermal_zone_device_priv(tz); <answer> *tdata 
<token> hwmon_device *hwdev = to_hwmon_device(tdata->dev); <answer> struct 
<token> ret; <answer> int 
<token> t; <answer> long 
ret = hwdev->chip->ops->read(tdata->dev, hwmon_temp, <token> <answer> hwmon_temp_input, 
tdata->index, <token> <answer> &t); 
if (ret <token> 0) <answer> < 
return <token> <answer> ret; 
*temp = <token> <answer> t; 
<token> 0; <answer> return 
static int hwmon_thermal_set_trips(struct thermal_zone_device *tz, <token> low, int high) <answer> int 
struct hwmon_thermal_data *tdata = <token> <answer> thermal_zone_device_priv(tz); 
<token> hwmon_device *hwdev = to_hwmon_device(tdata->dev); <answer> struct 
const <token> hwmon_chip_info *chip = hwdev->chip; <answer> struct 
const struct hwmon_channel_info * const *info <token> chip->info; <answer> = 
unsigned int <token> <answer> i; 
int <token> <answer> err; 
if <token> <answer> (!chip->ops->write) 
return <token> <answer> 0; 
<token> (i = 0; info[i] && info[i]->type != hwmon_temp; i++) <answer> for 
if <token> <answer> (!info[i]) 
return <token> <answer> 0; 
if (info[i]->config[tdata->index] & <token> { <answer> HWMON_T_MIN) 
<token> = chip->ops->write(tdata->dev, hwmon_temp, <answer> err 
hwmon_temp_min, <token> low); <answer> tdata->index, 
if <token> && err != -EOPNOTSUPP) <answer> (err 
return <token> <answer> err; 
if <token> & HWMON_T_MAX) { <answer> (info[i]->config[tdata->index] 
<token> = chip->ops->write(tdata->dev, hwmon_temp, <answer> err 
hwmon_temp_max, <token> high); <answer> tdata->index, 
if (err && err <token> -EOPNOTSUPP) <answer> != 
return <token> <answer> err; 
return <token> <answer> 0; 
static const struct thermal_zone_device_ops <token> = { <answer> hwmon_thermal_ops 
.get_temp <token> hwmon_thermal_get_temp, <answer> = 
.set_trips = <token> <answer> hwmon_thermal_set_trips, 
<token> void hwmon_thermal_remove_sensor(void *data) <answer> static 
static int hwmon_thermal_add_sensor(struct device *dev, <token> index) <answer> int 
struct hwmon_device <token> = to_hwmon_device(dev); <answer> *hwdev 
struct <token> *tdata; <answer> hwmon_thermal_data 
struct <token> *tzd; <answer> thermal_zone_device 
int <token> <answer> err; 
tdata = devm_kzalloc(dev, <token> GFP_KERNEL); <answer> sizeof(*tdata), 
if <token> <answer> (!tdata) 
<token> -ENOMEM; <answer> return 
tdata->dev <token> dev; <answer> = 
tdata->index = <token> <answer> index; 
tzd = devm_thermal_of_zone_register(dev, index, <token> <answer> tdata, 
<token> (IS_ERR(tzd)) { <answer> if 
if <token> != -ENODEV) <answer> (PTR_ERR(tzd) 
return <token> <answer> PTR_ERR(tzd); 
dev_info(dev, "temp%d_input <token> attached to any thermal zone\n", <answer> not 
<token> + 1); <answer> index 
devm_kfree(dev, <token> <answer> tdata); 
return <token> <answer> 0; 
err = devm_add_action(dev, hwmon_thermal_remove_sensor, <token> <answer> &tdata->node); 
<token> (err) <answer> if 
return <token> <answer> err; 
tdata->tzd = <token> <answer> tzd; 
list_add(&tdata->node, <token> <answer> &hwdev->tzdata); 
<token> 0; <answer> return 
static int <token> device *dev) <answer> hwmon_thermal_register_sensors(struct 
<token> hwmon_device *hwdev = to_hwmon_device(dev); <answer> struct 
const <token> hwmon_chip_info *chip = hwdev->chip; <answer> struct 
const struct <token> * const *info = chip->info; <answer> hwmon_channel_info 
<token> *drvdata = dev_get_drvdata(dev); <answer> void 
<token> i; <answer> int 
for (i = <token> info[i]; i++) { <answer> 1; 
int <token> <answer> j; 
if <token> != hwmon_temp) <answer> (info[i]->type 
for (j = 0; info[i]->config[j]; <token> { <answer> j++) 
<token> err; <answer> int 
if <token> & HWMON_T_INPUT) || <answer> (!(info[i]->config[j] 
!chip->ops->is_visible(drvdata, <token> <answer> hwmon_temp, 
hwmon_temp_input, <token> <answer> j)) 
err = hwmon_thermal_add_sensor(dev, <token> <answer> j); 
if <token> <answer> (err) 
return <token> <answer> err; 
return <token> <answer> 0; 
static <token> hwmon_thermal_notify(struct device *dev, int index) <answer> void 
struct hwmon_device *hwdev = <token> <answer> to_hwmon_device(dev); 
<token> hwmon_thermal_data *tzdata; <answer> struct 
list_for_each_entry(tzdata, &hwdev->tzdata, <token> { <answer> node) 
if (tzdata->index == index) <token> <answer> { 
static int hwmon_thermal_register_sensors(struct <token> *dev) <answer> device 
<token> 0; <answer> return 
static void hwmon_thermal_notify(struct device *dev, int <token> { } <answer> index) 
<token> const char * const hwmon_chip_attrs[] = { <answer> static 
[hwmon_chip_temp_reset_history] <token> "temp_reset_history", <answer> = 
[hwmon_chip_in_reset_history] <token> "in_reset_history", <answer> = 
[hwmon_chip_curr_reset_history] <token> "curr_reset_history", <answer> = 
[hwmon_chip_power_reset_history] <token> "power_reset_history", <answer> = 
[hwmon_chip_update_interval] = <token> <answer> "update_interval", 
<token> = "alarms", <answer> [hwmon_chip_alarms] 
<token> = "samples", <answer> [hwmon_chip_samples] 
[hwmon_chip_curr_samples] <token> "curr_samples", <answer> = 
[hwmon_chip_in_samples] = <token> <answer> "in_samples", 
[hwmon_chip_power_samples] = <token> <answer> "power_samples", 
[hwmon_chip_temp_samples] = <token> <answer> "temp_samples", 
<token> = "beep_enable", <answer> [hwmon_chip_beep_enable] 
<token> const char * const hwmon_temp_attr_templates[] = { <answer> static 
<token> = "temp%d_enable", <answer> [hwmon_temp_enable] 
<token> = "temp%d_input", <answer> [hwmon_temp_input] 
[hwmon_temp_type] <token> "temp%d_type", <answer> = 
[hwmon_temp_lcrit] = <token> <answer> "temp%d_lcrit", 
<token> = "temp%d_lcrit_hyst", <answer> [hwmon_temp_lcrit_hyst] 
[hwmon_temp_min] <token> "temp%d_min", <answer> = 
<token> = "temp%d_min_hyst", <answer> [hwmon_temp_min_hyst] 
[hwmon_temp_max] <token> "temp%d_max", <answer> = 
[hwmon_temp_max_hyst] <token> "temp%d_max_hyst", <answer> = 
[hwmon_temp_crit] = <token> <answer> "temp%d_crit", 
[hwmon_temp_crit_hyst] = <token> <answer> "temp%d_crit_hyst", 
[hwmon_temp_emergency] = <token> <answer> "temp%d_emergency", 
[hwmon_temp_emergency_hyst] = <token> <answer> "temp%d_emergency_hyst", 
<token> = "temp%d_alarm", <answer> [hwmon_temp_alarm] 
[hwmon_temp_lcrit_alarm] = <token> <answer> "temp%d_lcrit_alarm", 
<token> = "temp%d_min_alarm", <answer> [hwmon_temp_min_alarm] 
[hwmon_temp_max_alarm] <token> "temp%d_max_alarm", <answer> = 
<token> = "temp%d_crit_alarm", <answer> [hwmon_temp_crit_alarm] 
[hwmon_temp_emergency_alarm] <token> "temp%d_emergency_alarm", <answer> = 
[hwmon_temp_fault] = <token> <answer> "temp%d_fault", 
<token> = "temp%d_offset", <answer> [hwmon_temp_offset] 
[hwmon_temp_label] = <token> <answer> "temp%d_label", 
[hwmon_temp_lowest] <token> "temp%d_lowest", <answer> = 
<token> = "temp%d_highest", <answer> [hwmon_temp_highest] 
[hwmon_temp_reset_history] <token> "temp%d_reset_history", <answer> = 
[hwmon_temp_rated_min] = <token> <answer> "temp%d_rated_min", 
[hwmon_temp_rated_max] <token> "temp%d_rated_max", <answer> = 
<token> = "temp%d_beep", <answer> [hwmon_temp_beep] 
static const char * <token> hwmon_in_attr_templates[] = { <answer> const 
[hwmon_in_enable] <token> "in%d_enable", <answer> = 
[hwmon_in_input] <token> "in%d_input", <answer> = 
[hwmon_in_min] = <token> <answer> "in%d_min", 
[hwmon_in_max] = <token> <answer> "in%d_max", 
<token> = "in%d_lcrit", <answer> [hwmon_in_lcrit] 
[hwmon_in_crit] = <token> <answer> "in%d_crit", 
[hwmon_in_average] = <token> <answer> "in%d_average", 
[hwmon_in_lowest] = <token> <answer> "in%d_lowest", 
<token> = "in%d_highest", <answer> [hwmon_in_highest] 
[hwmon_in_reset_history] = <token> <answer> "in%d_reset_history", 
[hwmon_in_label] = <token> <answer> "in%d_label", 
[hwmon_in_alarm] = <token> <answer> "in%d_alarm", 
<token> = "in%d_min_alarm", <answer> [hwmon_in_min_alarm] 
<token> = "in%d_max_alarm", <answer> [hwmon_in_max_alarm] 
<token> = "in%d_lcrit_alarm", <answer> [hwmon_in_lcrit_alarm] 
[hwmon_in_crit_alarm] = <token> <answer> "in%d_crit_alarm", 
[hwmon_in_rated_min] = <token> <answer> "in%d_rated_min", 
[hwmon_in_rated_max] = <token> <answer> "in%d_rated_max", 
<token> = "in%d_beep", <answer> [hwmon_in_beep] 
[hwmon_in_fault] = <token> <answer> "in%d_fault", 
<token> const char * const hwmon_curr_attr_templates[] = { <answer> static 
<token> = "curr%d_enable", <answer> [hwmon_curr_enable] 
<token> = "curr%d_input", <answer> [hwmon_curr_input] 
[hwmon_curr_min] = <token> <answer> "curr%d_min", 
[hwmon_curr_max] <token> "curr%d_max", <answer> = 
[hwmon_curr_lcrit] <token> "curr%d_lcrit", <answer> = 
[hwmon_curr_crit] <token> "curr%d_crit", <answer> = 
[hwmon_curr_average] = <token> <answer> "curr%d_average", 
[hwmon_curr_lowest] <token> "curr%d_lowest", <answer> = 
[hwmon_curr_highest] <token> "curr%d_highest", <answer> = 
<token> = "curr%d_reset_history", <answer> [hwmon_curr_reset_history] 
[hwmon_curr_label] <token> "curr%d_label", <answer> = 
<token> = "curr%d_alarm", <answer> [hwmon_curr_alarm] 
[hwmon_curr_min_alarm] <token> "curr%d_min_alarm", <answer> = 
<token> = "curr%d_max_alarm", <answer> [hwmon_curr_max_alarm] 
[hwmon_curr_lcrit_alarm] = <token> <answer> "curr%d_lcrit_alarm", 
<token> = "curr%d_crit_alarm", <answer> [hwmon_curr_crit_alarm] 
[hwmon_curr_rated_min] = <token> <answer> "curr%d_rated_min", 
[hwmon_curr_rated_max] <token> "curr%d_rated_max", <answer> = 
[hwmon_curr_beep] = <token> <answer> "curr%d_beep", 
<token> const char * const hwmon_power_attr_templates[] = { <answer> static 
<token> = "power%d_enable", <answer> [hwmon_power_enable] 
<token> = "power%d_average", <answer> [hwmon_power_average] 
[hwmon_power_average_interval] <token> "power%d_average_interval", <answer> = 
[hwmon_power_average_interval_max] = <token> <answer> "power%d_interval_max", 
[hwmon_power_average_interval_min] = <token> <answer> "power%d_interval_min", 
[hwmon_power_average_highest] = <token> <answer> "power%d_average_highest", 
<token> = "power%d_average_lowest", <answer> [hwmon_power_average_lowest] 
<token> = "power%d_average_max", <answer> [hwmon_power_average_max] 
[hwmon_power_average_min] = <token> <answer> "power%d_average_min", 
<token> = "power%d_input", <answer> [hwmon_power_input] 
[hwmon_power_input_highest] <token> "power%d_input_highest", <answer> = 
[hwmon_power_input_lowest] <token> "power%d_input_lowest", <answer> = 
[hwmon_power_reset_history] = <token> <answer> "power%d_reset_history", 
<token> = "power%d_accuracy", <answer> [hwmon_power_accuracy] 
<token> = "power%d_cap", <answer> [hwmon_power_cap] 
<token> = "power%d_cap_hyst", <answer> [hwmon_power_cap_hyst] 
<token> = "power%d_cap_max", <answer> [hwmon_power_cap_max] 
<token> = "power%d_cap_min", <answer> [hwmon_power_cap_min] 
[hwmon_power_min] = <token> <answer> "power%d_min", 
[hwmon_power_max] <token> "power%d_max", <answer> = 
[hwmon_power_lcrit] <token> "power%d_lcrit", <answer> = 
[hwmon_power_crit] <token> "power%d_crit", <answer> = 
[hwmon_power_label] <token> "power%d_label", <answer> = 
[hwmon_power_alarm] <token> "power%d_alarm", <answer> = 
[hwmon_power_cap_alarm] <token> "power%d_cap_alarm", <answer> = 
[hwmon_power_min_alarm] = <token> <answer> "power%d_min_alarm", 
[hwmon_power_max_alarm] = <token> <answer> "power%d_max_alarm", 
[hwmon_power_lcrit_alarm] = <token> <answer> "power%d_lcrit_alarm", 
[hwmon_power_crit_alarm] = <token> <answer> "power%d_crit_alarm", 
[hwmon_power_rated_min] <token> "power%d_rated_min", <answer> = 
<token> = "power%d_rated_max", <answer> [hwmon_power_rated_max] 
static <token> char * const hwmon_energy_attr_templates[] = { <answer> const 
<token> = "energy%d_enable", <answer> [hwmon_energy_enable] 
<token> = "energy%d_input", <answer> [hwmon_energy_input] 
[hwmon_energy_label] <token> "energy%d_label", <answer> = 
static const char * const hwmon_humidity_attr_templates[] <token> { <answer> = 
<token> = "humidity%d_enable", <answer> [hwmon_humidity_enable] 
<token> = "humidity%d_input", <answer> [hwmon_humidity_input] 
<token> = "humidity%d_label", <answer> [hwmon_humidity_label] 
[hwmon_humidity_min] <token> "humidity%d_min", <answer> = 
<token> = "humidity%d_min_hyst", <answer> [hwmon_humidity_min_hyst] 
[hwmon_humidity_max] = <token> <answer> "humidity%d_max", 
[hwmon_humidity_max_hyst] = <token> <answer> "humidity%d_max_hyst", 
[hwmon_humidity_alarm] = <token> <answer> "humidity%d_alarm", 
[hwmon_humidity_fault] <token> "humidity%d_fault", <answer> = 
[hwmon_humidity_rated_min] = <token> <answer> "humidity%d_rated_min", 
<token> = "humidity%d_rated_max", <answer> [hwmon_humidity_rated_max] 
[hwmon_humidity_min_alarm] <token> "humidity%d_min_alarm", <answer> = 
[hwmon_humidity_max_alarm] = <token> <answer> "humidity%d_max_alarm", 
static <token> char * const hwmon_fan_attr_templates[] = { <answer> const 
<token> = "fan%d_enable", <answer> [hwmon_fan_enable] 
<token> = "fan%d_input", <answer> [hwmon_fan_input] 
<token> = "fan%d_label", <answer> [hwmon_fan_label] 
[hwmon_fan_min] = <token> <answer> "fan%d_min", 
<token> = "fan%d_max", <answer> [hwmon_fan_max] 
[hwmon_fan_div] <token> "fan%d_div", <answer> = 
[hwmon_fan_pulses] = <token> <answer> "fan%d_pulses", 
[hwmon_fan_target] = <token> <answer> "fan%d_target", 
<token> = "fan%d_alarm", <answer> [hwmon_fan_alarm] 
[hwmon_fan_min_alarm] = <token> <answer> "fan%d_min_alarm", 
<token> = "fan%d_max_alarm", <answer> [hwmon_fan_max_alarm] 
[hwmon_fan_fault] = <token> <answer> "fan%d_fault", 
<token> = "fan%d_beep", <answer> [hwmon_fan_beep] 
static const char * const <token> = { <answer> hwmon_pwm_attr_templates[] 
[hwmon_pwm_input] = <token> <answer> "pwm%d", 
[hwmon_pwm_enable] <token> "pwm%d_enable", <answer> = 
[hwmon_pwm_mode] <token> "pwm%d_mode", <answer> = 
[hwmon_pwm_freq] = <token> <answer> "pwm%d_freq", 
[hwmon_pwm_auto_channels_temp] <token> "pwm%d_auto_channels_temp", <answer> = 
static const char <token> const hwmon_intrusion_attr_templates[] = { <answer> * 
[hwmon_intrusion_alarm] = <token> <answer> "intrusion%d_alarm", 
<token> = "intrusion%d_beep", <answer> [hwmon_intrusion_beep] 
static const char * const <token> = { <answer> *__templates[] 
<token> = hwmon_chip_attrs, <answer> [hwmon_chip] 
[hwmon_temp] = <token> <answer> hwmon_temp_attr_templates, 
[hwmon_in] <token> hwmon_in_attr_templates, <answer> = 
[hwmon_curr] <token> hwmon_curr_attr_templates, <answer> = 
[hwmon_power] <token> hwmon_power_attr_templates, <answer> = 
<token> = hwmon_energy_attr_templates, <answer> [hwmon_energy] 
[hwmon_humidity] <token> hwmon_humidity_attr_templates, <answer> = 
[hwmon_fan] <token> hwmon_fan_attr_templates, <answer> = 
[hwmon_pwm] = <token> <answer> hwmon_pwm_attr_templates, 
[hwmon_intrusion] = <token> <answer> hwmon_intrusion_attr_templates, 
<token> const int __templates_size[] = { <answer> static 
[hwmon_chip] = <token> <answer> ARRAY_SIZE(hwmon_chip_attrs), 
[hwmon_temp] <token> ARRAY_SIZE(hwmon_temp_attr_templates), <answer> = 
[hwmon_in] = <token> <answer> ARRAY_SIZE(hwmon_in_attr_templates), 
[hwmon_curr] <token> ARRAY_SIZE(hwmon_curr_attr_templates), <answer> = 
<token> = ARRAY_SIZE(hwmon_power_attr_templates), <answer> [hwmon_power] 
[hwmon_energy] <token> ARRAY_SIZE(hwmon_energy_attr_templates), <answer> = 
<token> = ARRAY_SIZE(hwmon_humidity_attr_templates), <answer> [hwmon_humidity] 
[hwmon_fan] = <token> <answer> ARRAY_SIZE(hwmon_fan_attr_templates), 
[hwmon_pwm] <token> ARRAY_SIZE(hwmon_pwm_attr_templates), <answer> = 
[hwmon_intrusion] <token> ARRAY_SIZE(hwmon_intrusion_attr_templates), <answer> = 
int hwmon_notify_event(struct device *dev, enum hwmon_sensor_types <token> <answer> type, 
<token> attr, int channel) <answer> u32 
char <token> + 5]; <answer> event[MAX_SYSFS_ATTR_NAME_LENGTH 
char <token> <answer> sattr[MAX_SYSFS_ATTR_NAME_LENGTH]; 
char *envp[] = { event, <token> }; <answer> NULL 
const char * const <token> <answer> *templates; 
<token> char *template; <answer> const 
<token> base; <answer> int 
if (type <token> ARRAY_SIZE(__templates)) <answer> >= 
<token> -EINVAL; <answer> return 
if (attr >= <token> <answer> __templates_size[type]) 
<token> -EINVAL; <answer> return 
templates <token> __templates[type]; <answer> = 
template = <token> <answer> templates[attr]; 
base = <token> <answer> hwmon_attr_base(type); 
scnprintf(sattr, MAX_SYSFS_ATTR_NAME_LENGTH, <token> base + channel); <answer> template, 
scnprintf(event, sizeof(event), <token> sattr); <answer> "NAME=%s", 
sysfs_notify(&dev->kobj, NULL, <token> <answer> sattr); 
<token> KOBJ_CHANGE, envp); <answer> kobject_uevent_env(&dev->kobj, 
if <token> == hwmon_temp) <answer> (type 
hwmon_thermal_notify(dev, <token> <answer> channel); 
return <token> <answer> 0; 
<token> int hwmon_num_channel_attrs(const struct hwmon_channel_info *info) <answer> static 
int i, <token> <answer> n; 
for (i = <token> = 0; info->config[i]; i++) <answer> n 
<token> += hweight32(info->config[i]); <answer> n 
return <token> <answer> n; 
static int hwmon_genattrs(const void <token> <answer> *drvdata, 
struct <token> **attrs, <answer> attribute 
const struct <token> *ops, <answer> hwmon_ops 
const struct <token> *info) <answer> hwmon_channel_info 
const char * const <token> <answer> *templates; 
<token> template_size; <answer> int 
int i, <token> = 0; <answer> aindex 
<token> (info->type >= ARRAY_SIZE(__templates)) <answer> if 
<token> -EINVAL; <answer> return 
<token> = __templates[info->type]; <answer> templates 
template_size <token> __templates_size[info->type]; <answer> = 
for (i = 0; <token> i++) { <answer> info->config[i]; 
u32 attr_mask <token> info->config[i]; <answer> = 
<token> attr; <answer> u32 
while (attr_mask) <token> <answer> { 
<token> attribute *a; <answer> struct 
attr <token> __ffs(attr_mask); <answer> = 
attr_mask <token> ~BIT(attr); <answer> &= 
<token> (attr >= template_size) <answer> if 
return <token> <answer> -EINVAL; 
a <token> hwmon_genattr(drvdata, info->type, attr, i, <answer> = 
templates[attr], <token> <answer> ops); 
<token> (IS_ERR(a)) { <answer> if 
if (PTR_ERR(a) <token> -ENOENT) <answer> != 
return <token> <answer> PTR_ERR(a); 
attrs[aindex++] <token> a; <answer> = 
<token> aindex; <answer> return 
static struct <token> ** <answer> attribute 
__hwmon_create_attrs(const void *drvdata, const struct <token> *chip) <answer> hwmon_chip_info 
int ret, i, aindex = 0, nattrs <token> 0; <answer> = 
<token> attribute **attrs; <answer> struct 
for (i = 0; <token> i++) <answer> chip->info[i]; 
nattrs += <token> <answer> hwmon_num_channel_attrs(chip->info[i]); 
if <token> == 0) <answer> (nattrs 
return <token> <answer> ERR_PTR(-EINVAL); 
attrs = kcalloc(nattrs <token> 1, sizeof(*attrs), GFP_KERNEL); <answer> + 
if <token> <answer> (!attrs) 
return <token> <answer> ERR_PTR(-ENOMEM); 
for (i = 0; chip->info[i]; <token> { <answer> i++) 
ret = hwmon_genattrs(drvdata, <token> chip->ops, <answer> &attrs[aindex], 
if (ret <token> 0) { <answer> < 
return <token> <answer> ERR_PTR(ret); 
aindex += <token> <answer> ret; 
return <token> <answer> attrs; 
static struct <token> * <answer> device 
__hwmon_device_register(struct device *dev, const char *name, void <token> <answer> *drvdata, 
const struct <token> *chip, <answer> hwmon_chip_info 
const <token> attribute_group **groups) <answer> struct 
struct <token> *hwdev; <answer> hwmon_device 
<token> char *label; <answer> const 
struct <token> *hdev; <answer> device 
<token> device *tdev = dev; <answer> struct 
int i, <token> id; <answer> err, 
<token> ida_remove; <answer> goto 
<token> hdev; <answer> return 
<token> id); <answer> ida_free(&hwmon_ida, 
<token> ERR_PTR(err); <answer> return 
struct device <token> <answer> * 
hwmon_device_register_with_groups(struct device *dev, const char <token> <answer> *name, 
<token> *drvdata, <answer> void 
const struct attribute_group <token> <answer> **groups) 
<token> (!name) <answer> if 
return <token> <answer> ERR_PTR(-EINVAL); 
return <token> name, drvdata, NULL, groups); <answer> __hwmon_device_register(dev, 
<token> device * <answer> struct 
hwmon_device_register_with_info(struct <token> *dev, const char *name, <answer> device 
void <token> <answer> *drvdata, 
const <token> hwmon_chip_info *chip, <answer> struct 
const struct <token> **extra_groups) <answer> attribute_group 
<token> (!dev || !name || !chip) <answer> if 
return <token> <answer> ERR_PTR(-EINVAL); 
if (!chip->ops || <token> || !chip->info) <answer> !chip->ops->is_visible 
<token> ERR_PTR(-EINVAL); <answer> return 
return __hwmon_device_register(dev, name, drvdata, chip, <token> <answer> extra_groups); 
struct device <token> <answer> * 
hwmon_device_register_for_thermal(struct device *dev, const char <token> <answer> *name, 
<token> *drvdata) <answer> void 
<token> (!name || !dev) <answer> if 
<token> ERR_PTR(-EINVAL); <answer> return 
return __hwmon_device_register(dev, <token> drvdata, NULL, NULL); <answer> name, 
<token> HWMON_THERMAL); <answer> EXPORT_SYMBOL_NS_GPL(hwmon_device_register_for_thermal, 
<token> device *hwmon_device_register(struct device *dev) <answer> struct 
"hwmon_device_register() is deprecated. Please <token> the driver to use hwmon_device_register_with_info().\n"); <answer> convert 
<token> __hwmon_device_register(dev, NULL, NULL, NULL, NULL); <answer> return 
void <token> device *dev) <answer> hwmon_device_unregister(struct 
<token> id; <answer> int 
if (likely(sscanf(dev_name(dev), HWMON_ID_FORMAT, &id) <token> 1)) { <answer> == 
ida_free(&hwmon_ida, <token> <answer> id); 
} <token> <answer> else 
"hwmon_device_unregister() <token> bad class ID!\n"); <answer> failed: 
static void devm_hwmon_release(struct device *dev, void <token> <answer> *res) 
struct device <token> = *(struct device **)res; <answer> *hwdev 
struct device <token> <answer> * 
devm_hwmon_device_register_with_groups(struct device <token> const char *name, <answer> *dev, 
void <token> <answer> *drvdata, 
const <token> attribute_group **groups) <answer> struct 
struct device <token> *hwdev; <answer> **ptr, 
<token> (!dev) <answer> if 
<token> ERR_PTR(-EINVAL); <answer> return 
<token> = devres_alloc(devm_hwmon_release, sizeof(*ptr), GFP_KERNEL); <answer> ptr 
if <token> <answer> (!ptr) 
return <token> <answer> ERR_PTR(-ENOMEM); 
<token> = hwmon_device_register_with_groups(dev, name, drvdata, groups); <answer> hwdev 
if <token> <answer> (IS_ERR(hwdev)) 
goto <token> <answer> error; 
*ptr = <token> <answer> hwdev; 
devres_add(dev, <token> <answer> ptr); 
<token> hwdev; <answer> return 
return <token> <answer> hwdev; 
struct <token> * <answer> device 
devm_hwmon_device_register_with_info(struct device *dev, const <token> *name, <answer> char 
void <token> <answer> *drvdata, 
<token> struct hwmon_chip_info *chip, <answer> const 
const struct <token> **extra_groups) <answer> attribute_group 
struct <token> **ptr, *hwdev; <answer> device 
<token> (!dev) <answer> if 
<token> ERR_PTR(-EINVAL); <answer> return 
<token> = devres_alloc(devm_hwmon_release, sizeof(*ptr), GFP_KERNEL); <answer> ptr 
if <token> <answer> (!ptr) 
<token> ERR_PTR(-ENOMEM); <answer> return 
hwdev = hwmon_device_register_with_info(dev, name, <token> chip, <answer> drvdata, 
if <token> <answer> (IS_ERR(hwdev)) 
goto <token> <answer> error; 
<token> = hwdev; <answer> *ptr 
devres_add(dev, <token> <answer> ptr); 
<token> hwdev; <answer> return 
<token> hwdev; <answer> return 
static <token> devm_hwmon_match(struct device *dev, void *res, void *data) <answer> int 
struct device **hwdev = <token> <answer> res; 
return *hwdev <token> data; <answer> == 
void devm_hwmon_device_unregister(struct device <token> <answer> *dev) 
WARN_ON(devres_release(dev, devm_hwmon_release, devm_hwmon_match, <token> <answer> dev)); 
<token> char *__hwmon_sanitize_name(struct device *dev, const char *old_name) <answer> static 
char <token> *p; <answer> *name, 
<token> (dev) <answer> if 
name <token> devm_kstrdup(dev, old_name, GFP_KERNEL); <answer> = 
name = <token> GFP_KERNEL); <answer> kstrdup(old_name, 
<token> (!name) <answer> if 
return <token> <answer> ERR_PTR(-ENOMEM); 
for (p <token> name; *p; p++) <answer> = 
<token> (hwmon_is_bad_char(*p)) <answer> if 
<token> = '_'; <answer> *p 
<token> name; <answer> return 
<token> *hwmon_sanitize_name(const char *name) <answer> char 
<token> __hwmon_sanitize_name(NULL, name); <answer> return 
char *devm_hwmon_sanitize_name(struct <token> *dev, const char *name) <answer> device 
if <token> <answer> (!dev) 
return <token> <answer> ERR_PTR(-EINVAL); 
return <token> name); <answer> __hwmon_sanitize_name(dev, 
static <token> __init hwmon_pci_quirks(void) <answer> void 
<token> defined CONFIG_X86 && defined CONFIG_PCI <answer> #if 
<token> pci_dev *sb; <answer> struct 
<token> base; <answer> u16 
u8 <token> <answer> enable; 
#include <token> <answer> <linux/types.h> 
#include <token> <answer> <linux/slab.h> 
<token> <linux/in.h> <answer> #include 
#include <token> <answer> <linux/in6.h> 
<token> <linux/sunrpc/clnt.h> <answer> #include 
#include <token> <answer> <linux/sunrpc/addr.h> 
<token> <linux/sunrpc/svc.h> <answer> #include 
<token> <linux/lockd/lockd.h> <answer> #include 
#include <token> <answer> <linux/mutex.h> 
<token> <linux/sunrpc/svc_xprt.h> <answer> #include 
<token> <net/ipv6.h> <answer> #include 
#include <token> <answer> "netns.h" 
#define NLMDBG_FACILITY <token> <answer> NLMDBG_HOSTCACHE 
#define NLM_HOST_NRHASH <token> <answer> 32 
#define <token> (60 * HZ) <answer> NLM_HOST_REBIND 
#define <token> (300 * HZ) <answer> NLM_HOST_EXPIRE 
#define NLM_HOST_COLLECT (120 * <token> <answer> HZ) 
static struct <token> nlm_server_hosts[NLM_HOST_NRHASH]; <answer> hlist_head 
static struct hlist_head <token> <answer> nlm_client_hosts[NLM_HOST_NRHASH]; 
#define for_each_host(host, <token> table) \ <answer> chain, 
for ((chain) <token> (table); \ <answer> = 
(chain) < (table) + NLM_HOST_NRHASH; ++(chain)) <token> <answer> \ 
<token> (chain), h_hash) <answer> hlist_for_each_entry((host), 
#define for_each_host_safe(host, next, chain, <token> \ <answer> table) 
for ((chain) <token> (table); \ <answer> = 
(chain) < (table) + <token> ++(chain)) \ <answer> NLM_HOST_NRHASH; 
hlist_for_each_entry_safe((host), <token> \ <answer> (next), 
(chain), <token> <answer> h_hash) 
static unsigned long <token> <answer> nrhosts; 
static <token> <answer> DEFINE_MUTEX(nlm_host_mutex); 
static void nlm_gc_hosts(struct net <token> <answer> *net); 
struct <token> { <answer> nlm_lookup_host_info 
static <token> int __nlm_hash32(const __be32 n) <answer> unsigned 
unsigned int hash <token> (__force u32)n ^ ((__force u32)n >> 16); <answer> = 
<token> hash ^ (hash >> 8); <answer> return 
static unsigned <token> __nlm_hash_addr4(const struct sockaddr *sap) <answer> int 
<token> struct sockaddr_in *sin = (struct sockaddr_in *)sap; <answer> const 
return <token> <answer> __nlm_hash32(sin->sin_addr.s_addr); 
static unsigned int __nlm_hash_addr6(const struct sockaddr <token> <answer> *sap) 
const struct sockaddr_in6 *sin6 = (struct <token> *)sap; <answer> sockaddr_in6 
const struct <token> addr = sin6->sin6_addr; <answer> in6_addr 
return __nlm_hash32(addr.s6_addr32[0]) <token> <answer> ^ 
<token> ^ <answer> __nlm_hash32(addr.s6_addr32[1]) 
<token> ^ <answer> __nlm_hash32(addr.s6_addr32[2]) 
static unsigned int nlm_hash_address(const struct sockaddr <token> <answer> *sap) 
<token> int hash; <answer> unsigned 
switch <token> { <answer> (sap->sa_family) 
case <token> <answer> AF_INET: 
hash = <token> <answer> __nlm_hash_addr4(sap); 
<token> AF_INET6: <answer> case 
hash = <token> <answer> __nlm_hash_addr6(sap); 
<token> = 0; <answer> hash 
return hash & (NLM_HOST_NRHASH <token> 1); <answer> - 
<token> struct nlm_host *nlm_alloc_host(struct nlm_lookup_host_info *ni, <answer> static 
struct <token> *nsm) <answer> nsm_handle 
<token> nlm_host *host = NULL; <answer> struct 
unsigned long <token> = jiffies; <answer> now 
if (nsm <token> NULL) <answer> != 
<token> { <answer> else 
<token> = NULL; <answer> host 
nsm = <token> ni->sap, ni->salen, <answer> nsm_get_handle(ni->net, 
ni->hostname, <token> <answer> ni->hostname_len); 
if (unlikely(nsm <token> NULL)) { <answer> == 
<token> %s failed; no nsm handle\n", <answer> dprintk("lockd: 
goto <token> <answer> out; 
<token> = kmalloc(sizeof(*host), GFP_KERNEL); <answer> host 
<token> (unlikely(host == NULL)) { <answer> if 
dprintk("lockd: %s failed; <token> memory\n", __func__); <answer> no 
<token> out; <answer> goto 
memcpy(nlm_addr(host), <token> ni->salen); <answer> ni->sap, 
<token> = ni->salen; <answer> host->h_addrlen 
rpc_set_port(nlm_addr(host), <token> <answer> 0); 
host->h_srcaddrlen = <token> <answer> 0; 
host->h_rpcclnt <token> NULL; <answer> = 
<token> = nsm->sm_name; <answer> host->h_name 
<token> = ni->version; <answer> host->h_version 
host->h_proto = <token> <answer> ni->protocol; 
host->h_reclaiming <token> 0; <answer> = 
<token> = ni->server; <answer> host->h_server 
host->h_noresvport = <token> <answer> ni->noresvport; 
host->h_inuse <token> 0; <answer> = 
<token> = 0; <answer> host->h_state 
host->h_nsmstate <token> 0; <answer> = 
host->h_pidcount <token> 0; <answer> = 
refcount_set(&host->h_count, <token> <answer> 1); 
host->h_nextrebind <token> now + NLM_HOST_REBIND; <answer> = 
host->h_expires = now + <token> <answer> NLM_HOST_EXPIRE; 
<token> = nsm; <answer> host->h_nsmhandle 
host->h_addrbuf = <token> <answer> nsm->sm_addrbuf; 
host->net = <token> <answer> ni->net; 
host->h_cred = <token> <answer> get_cred(ni->cred); 
<token> utsname()->nodename, sizeof(host->nodename)); <answer> strscpy(host->nodename, 
return <token> <answer> host; 
static void nlm_destroy_host_locked(struct <token> *host) <answer> nlm_host 
<token> rpc_clnt *clnt; <answer> struct 
struct lockd_net *ln = net_generic(host->net, <token> <answer> lockd_net_id); 
<token> destroy host %s\n", host->h_name); <answer> dprintk("lockd: 
<token> = host->h_rpcclnt; <answer> clnt 
if (clnt != <token> <answer> NULL) 
struct nlm_host *nlmclnt_lookup_host(const struct sockaddr <token> <answer> *sap, 
const size_t <token> <answer> salen, 
const unsigned short <token> <answer> protocol, 
<token> u32 version, <answer> const 
<token> char *hostname, <answer> const 
int <token> <answer> noresvport, 
<token> net *net, <answer> struct 
const struct <token> *cred) <answer> cred 
struct nlm_lookup_host_info ni = <token> <answer> { 
.server <token> 0, <answer> = 
.sap <token> sap, <answer> = 
.salen <token> salen, <answer> = 
.protocol = <token> <answer> protocol, 
<token> = version, <answer> .version 
.hostname <token> hostname, <answer> = 
<token> = strlen(hostname), <answer> .hostname_len 
.noresvport = <token> <answer> noresvport, 
<token> = net, <answer> .net 
<token> = cred, <answer> .cred 
<token> hlist_head *chain; <answer> struct 
struct <token> *host; <answer> nlm_host 
struct nsm_handle *nsm <token> NULL; <answer> = 
struct lockd_net *ln <token> net_generic(net, lockd_net_id); <answer> = 
dprintk("lockd: %s(host='%s', <token> proto=%s)\n", __func__, <answer> vers=%u, 
(hostname ? <token> : "<none>"), version, <answer> hostname 
